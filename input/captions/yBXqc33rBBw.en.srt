1
00:00:00,280 --> 00:00:05,960
thank you everyone and good morning um

2
00:00:03,280 --> 00:00:08,000
I'm Dr Keith deer I'm former expert

3
00:00:05,960 --> 00:00:10,200
adviser to the UK prime minister on

4
00:00:08,000 --> 00:00:12,759
Science and Tech in the context of our

5
00:00:10,200 --> 00:00:14,240
International in security strategy I'm a

6
00:00:12,759 --> 00:00:15,679
20-year intelligence officer in the

7
00:00:14,240 --> 00:00:17,199
Royal Air Force where I continue to

8
00:00:15,679 --> 00:00:19,240
advise the chief of the air staff on

9
00:00:17,199 --> 00:00:21,480
where science and technology is taking

10
00:00:19,240 --> 00:00:23,240
us and today I speak to you as managing

11
00:00:21,480 --> 00:00:26,000
director of fij Jitsu Center for

12
00:00:23,240 --> 00:00:28,039
Cognitive and Advanced Technologies the

13
00:00:26,000 --> 00:00:30,000
first Insight I want to share though uh

14
00:00:28,039 --> 00:00:31,160
I stress um is probably the most

15
00:00:30,000 --> 00:00:33,079
interesting and I'm going to share it in

16
00:00:31,160 --> 00:00:35,840
a personal capacity for that reason take

17
00:00:33,079 --> 00:00:38,200
a bit more risk our contention in the

18
00:00:35,840 --> 00:00:40,039
center is that artificial intelligence

19
00:00:38,200 --> 00:00:42,640
digital twins a whole raft of emerging

20
00:00:40,039 --> 00:00:44,760
Technologies are increasingly cognitive

21
00:00:42,640 --> 00:00:46,520
Technologies they allow us to imagine

22
00:00:44,760 --> 00:00:49,280
and test alternative Futures which is

23
00:00:46,520 --> 00:00:51,680
the defining feature of human cognition

24
00:00:49,280 --> 00:00:55,440
the thing that separates us from animals

25
00:00:51,680 --> 00:00:58,160
in the way that we think if that's true

26
00:00:55,440 --> 00:01:00,359
you can begin to see it will profoundly

27
00:00:58,160 --> 00:01:01,879
revolutionize how we make decision ision

28
00:01:00,359 --> 00:01:04,519
because decisions is ultimately where

29
00:01:01,879 --> 00:01:06,479
cognition manifests it's what cognition

30
00:01:04,519 --> 00:01:08,320
evolved for to Keep Us Alive by allowing

31
00:01:06,479 --> 00:01:10,320
us to imagine well hey if I take this

32
00:01:08,320 --> 00:01:12,920
approach does it Advantage me socially

33
00:01:10,320 --> 00:01:14,439
does it Advantage me um physically am I

34
00:01:12,920 --> 00:01:16,400
more likely to survive in this scenario

35
00:01:14,439 --> 00:01:18,360
if I do x y and Zed cognition evolved to

36
00:01:16,400 --> 00:01:19,960
Keep Us Alive cognition evolved to help

37
00:01:18,360 --> 00:01:21,680
us make better decisions and in order to

38
00:01:19,960 --> 00:01:23,560
make better decisions you're going to

39
00:01:21,680 --> 00:01:26,159
have to revolutionize the way in which

40
00:01:23,560 --> 00:01:28,200
your organizations are structured which

41
00:01:26,159 --> 00:01:30,079
brings us to the hor old point of

42
00:01:28,200 --> 00:01:31,479
transformation it's going to be about

43
00:01:30,079 --> 00:01:33,799
transformation transforming your

44
00:01:31,479 --> 00:01:35,920
organization that's most

45
00:01:33,799 --> 00:01:37,880
important right now the need for that

46
00:01:35,920 --> 00:01:39,960
transformation is so urgent because of

47
00:01:37,880 --> 00:01:42,200
three principal reasons and antha talked

48
00:01:39,960 --> 00:01:44,960
a moment ago about the deciding what to

49
00:01:42,200 --> 00:01:46,240
bet on well right now the median

50
00:01:44,960 --> 00:01:48,360
estimate on the world's largest

51
00:01:46,240 --> 00:01:50,520
forecasting site for when we all have

52
00:01:48,360 --> 00:01:52,960
artificial general intelligence one at

53
00:01:50,520 --> 00:01:54,719
the 70th percen or more or less of human

54
00:01:52,960 --> 00:01:57,119
performance is

55
00:01:54,719 --> 00:01:59,240
2027 the median estimate for one will

56
00:01:57,119 --> 00:02:01,960
have Oracle AGI one that outperforms

57
00:01:59,240 --> 00:02:03,039
humans in all cognitive tasks one way to

58
00:02:01,960 --> 00:02:07,039
understand that is anything that you can

59
00:02:03,039 --> 00:02:09,000
do sat at a computer 2029 and the median

60
00:02:07,039 --> 00:02:10,720
estimate on metaculus for when we will

61
00:02:09,000 --> 00:02:12,440
reach artificial super intelligence one

62
00:02:10,720 --> 00:02:15,000
that exceeds Us in all dimensions of

63
00:02:12,440 --> 00:02:17,160
cognition and adds proprioception

64
00:02:15,000 --> 00:02:19,440
Locomotion and dexterity things that

65
00:02:17,160 --> 00:02:21,879
traditionally machines find hard and we

66
00:02:19,440 --> 00:02:23,160
find easy that median estimate for when

67
00:02:21,879 --> 00:02:25,920
that will arrive is

68
00:02:23,160 --> 00:02:27,879
2032 and all of those things mean that

69
00:02:25,920 --> 00:02:30,000
the we profoundly need to change how

70
00:02:27,879 --> 00:02:31,040
organizations work we need to understand

71
00:02:30,000 --> 00:02:33,239
that we're going to be increasingly

72
00:02:31,040 --> 00:02:35,280
reliant on machines to advise us on the

73
00:02:33,239 --> 00:02:36,840
decisions that we make to understand the

74
00:02:35,280 --> 00:02:38,560
implications to imagine and test those

75
00:02:36,840 --> 00:02:41,080
alternative Futures and to give us

76
00:02:38,560 --> 00:02:42,599
insights on which we can rely the pace

77
00:02:41,080 --> 00:02:44,159
of change is such as well that one

78
00:02:42,599 --> 00:02:45,319
approach to this saying hey here's one

79
00:02:44,159 --> 00:02:46,800
where we want to get to and we're going

80
00:02:45,319 --> 00:02:49,000
there is not going to work you've got to

81
00:02:46,800 --> 00:02:50,720
be experimenting continuously and so

82
00:02:49,000 --> 00:02:52,319
what I'm going to share in the time that

83
00:02:50,720 --> 00:02:54,080
remains to us is that one approach is

84
00:02:52,319 --> 00:02:55,200
not enough you need to be doing a number

85
00:02:54,080 --> 00:02:56,720
of things and you need to understand

86
00:02:55,200 --> 00:02:59,319
that those things you are doing will be

87
00:02:56,720 --> 00:03:01,120
constantly overtaken by the pace of

88
00:02:59,319 --> 00:03:02,959
change so we'll go through a few of

89
00:03:01,120 --> 00:03:04,760
those things as a sort of Tor reason of

90
00:03:02,959 --> 00:03:06,400
things that are happening at Fujitsu as

91
00:03:04,760 --> 00:03:08,040
we try to wrestle with this profound

92
00:03:06,400 --> 00:03:09,560
challenge of what de cognitive

93
00:03:08,040 --> 00:03:10,760
Technologies mean for the future of all

94
00:03:09,560 --> 00:03:12,720
of our

95
00:03:10,760 --> 00:03:15,000
organizations first of all new market

96
00:03:12,720 --> 00:03:16,799
development if you accept the premise

97
00:03:15,000 --> 00:03:19,280
one that I argued for in the UK's

98
00:03:16,799 --> 00:03:23,400
International strategy in 2020 that

99
00:03:19,280 --> 00:03:26,000
automation Robotics and AI reduce

100
00:03:23,400 --> 00:03:29,840
companies and countries dependent on

101
00:03:26,000 --> 00:03:32,599
people to create wealth um and to scale

102
00:03:29,840 --> 00:03:34,080
AR services to deter or fight so if it

103
00:03:32,599 --> 00:03:35,840
reduces our dependence on people to

104
00:03:34,080 --> 00:03:38,080
create wealth to create products and

105
00:03:35,840 --> 00:03:39,200
services you're still going to need in

106
00:03:38,080 --> 00:03:40,519
these organizations that were able to

107
00:03:39,200 --> 00:03:42,439
churn things out independent of

108
00:03:40,519 --> 00:03:43,760
demography independent of people you're

109
00:03:42,439 --> 00:03:45,120
still going to need new markets to sell

110
00:03:43,760 --> 00:03:46,840
them into and you need to be moving

111
00:03:45,120 --> 00:03:48,799
therefore constantly into the most

112
00:03:46,840 --> 00:03:50,360
dynamic markets in the world we've

113
00:03:48,799 --> 00:03:51,680
chosen to do that in Japan because we

114
00:03:50,360 --> 00:03:53,319
think there's a huge opportunity there

115
00:03:51,680 --> 00:03:55,200
where the UK and Japan complement each

116
00:03:53,319 --> 00:03:57,360
other I won't overdo this but you can

117
00:03:55,200 --> 00:03:59,360
see on the right hand side UK leadership

118
00:03:57,360 --> 00:04:01,239
in a number of areas Japanese leadership

119
00:03:59,360 --> 00:04:02,920
in a number of areas those things where

120
00:04:01,239 --> 00:04:04,920
we are both really strong and we think

121
00:04:02,920 --> 00:04:06,200
those things are complementary where you

122
00:04:04,920 --> 00:04:08,200
can learn from each other but of course

123
00:04:06,200 --> 00:04:09,920
you could put many countries around the

124
00:04:08,200 --> 00:04:11,519
world side by side like that and

125
00:04:09,920 --> 00:04:13,079
understanding those relative strengths

126
00:04:11,519 --> 00:04:15,280
of both and how they might complement

127
00:04:13,079 --> 00:04:16,320
each other is key to understanding which

128
00:04:15,280 --> 00:04:18,639
Market you're going to enter and being

129
00:04:16,320 --> 00:04:20,959
able to to articulate the rationale for

130
00:04:18,639 --> 00:04:22,919
why but it's also not just strength

131
00:04:20,959 --> 00:04:25,120
sometimes it's weakness in the UK we're

132
00:04:22,919 --> 00:04:27,639
first for research globally um every

133
00:04:25,120 --> 00:04:30,320
year since 2007 by research by citation

134
00:04:27,639 --> 00:04:31,840
waiting Japan is 11th

135
00:04:30,320 --> 00:04:33,600
on that same scale so that is real

136
00:04:31,840 --> 00:04:35,919
leadership but our ability to

137
00:04:33,600 --> 00:04:39,240
commercialize to develop the develop of

138
00:04:35,919 --> 00:04:40,360
R&D the UK was 27th out of the EU 28

139
00:04:39,240 --> 00:04:42,720
when we left and we've been going

140
00:04:40,360 --> 00:04:45,240
backwards ever since Japan is 13th

141
00:04:42,720 --> 00:04:47,880
globally in its ability to turn turn

142
00:04:45,240 --> 00:04:49,360
that world leading Research into new to

143
00:04:47,880 --> 00:04:51,639
Market New to firm inventions into

144
00:04:49,360 --> 00:04:53,560
technologies that scale that's a huge

145
00:04:51,639 --> 00:04:55,800
opportunity for any country do company

146
00:04:53,560 --> 00:04:57,160
doing Market entry to the UK and Japan

147
00:04:55,800 --> 00:04:59,320
you can seize on world leading

148
00:04:57,160 --> 00:05:01,080
ecosystems and then you can begin to to

149
00:04:59,320 --> 00:05:02,520
break into those areas to do the kind of

150
00:05:01,080 --> 00:05:06,240
development those countries urgently

151
00:05:02,520 --> 00:05:08,080
need know they need um all of those

152
00:05:06,240 --> 00:05:09,720
countries many countries around the

153
00:05:08,080 --> 00:05:11,240
world well there are no countries in the

154
00:05:09,720 --> 00:05:13,160
world that are achieving the levels of

155
00:05:11,240 --> 00:05:15,759
productivity increase and economic

156
00:05:13,160 --> 00:05:17,479
growth that the US currently is and what

157
00:05:15,759 --> 00:05:21,000
that means for companies in the US

158
00:05:17,479 --> 00:05:23,520
looking to do Market entry into um areas

159
00:05:21,000 --> 00:05:24,759
over overseas is that you'll often find

160
00:05:23,520 --> 00:05:26,160
most of those countries are trying to

161
00:05:24,759 --> 00:05:27,600
build their own MIT they're trying to

162
00:05:26,160 --> 00:05:29,720
build their own Silicon Valley and I

163
00:05:27,600 --> 00:05:31,759
know MIT engages to try and recreate the

164
00:05:29,720 --> 00:05:33,960
ecosystems it has here all around the

165
00:05:31,759 --> 00:05:35,720
world you'll find yourself as a company

166
00:05:33,960 --> 00:05:37,039
doing that market entry if you do it the

167
00:05:35,720 --> 00:05:39,039
right way which I'll come to Next in

168
00:05:37,039 --> 00:05:40,720
remedy being welcomed into the

169
00:05:39,039 --> 00:05:42,039
Ministries in those countries as

170
00:05:40,720 --> 00:05:43,680
somebody that can help them understand

171
00:05:42,039 --> 00:05:44,880
what they need to do and as somebody

172
00:05:43,680 --> 00:05:47,000
that can help them build the kind of

173
00:05:44,880 --> 00:05:48,919
innovative startups that bring that

174
00:05:47,000 --> 00:05:51,000
dynamism to the economy so new companies

175
00:05:48,919 --> 00:05:52,639
are formed in part out of old companies

176
00:05:51,000 --> 00:05:54,840
as as people are recycled through them

177
00:05:52,639 --> 00:05:56,720
and you need that exit rate and dynamism

178
00:05:54,840 --> 00:05:57,759
so getting the diagnosis right and

179
00:05:56,720 --> 00:06:00,199
understanding where the opportunities

180
00:05:57,759 --> 00:06:02,600
are is as important as understanding how

181
00:06:00,199 --> 00:06:05,000
you go um understanding the

182
00:06:02,600 --> 00:06:06,520
complimentary strengths there's a macro

183
00:06:05,000 --> 00:06:07,840
policy level therefore being able to

184
00:06:06,520 --> 00:06:09,919
really understand what the country is

185
00:06:07,840 --> 00:06:11,759
doing to address its economic challenges

186
00:06:09,919 --> 00:06:13,280
but there's also a micro policy thing

187
00:06:11,759 --> 00:06:15,759
here which I think is important like

188
00:06:13,280 --> 00:06:17,240
what you can do so going in with very

189
00:06:15,759 --> 00:06:19,280
clear thought leadership about what the

190
00:06:17,240 --> 00:06:20,960
problems are in a country not just the

191
00:06:19,280 --> 00:06:23,680
product you're offering to sell but how

192
00:06:20,960 --> 00:06:24,840
it might contribute to to wider dynamism

193
00:06:23,680 --> 00:06:26,919
is absolutely key and I'll give you an

194
00:06:24,840 --> 00:06:28,319
example of how we've done that you need

195
00:06:26,919 --> 00:06:29,759
to be partner Le if you're a large

196
00:06:28,319 --> 00:06:31,160
corporate and I suspect that most people

197
00:06:29,759 --> 00:06:32,120
in this room are large representing

198
00:06:31,160 --> 00:06:33,960
large

199
00:06:32,120 --> 00:06:35,880
corporates what most countries are

200
00:06:33,960 --> 00:06:37,039
looking for is not you it's might be

201
00:06:35,880 --> 00:06:38,880
looking for your investment but it's

202
00:06:37,039 --> 00:06:40,520
looking for that investment to drive the

203
00:06:38,880 --> 00:06:42,000
kind of dynamic startups that are going

204
00:06:40,520 --> 00:06:43,880
to disrupt their economy over and over

205
00:06:42,000 --> 00:06:45,800
again to increase the exit rate and

206
00:06:43,880 --> 00:06:47,440
entry rate of new companies and so

207
00:06:45,800 --> 00:06:50,000
allowing those startups to lead and

208
00:06:47,440 --> 00:06:53,039
putting yourself in in support is

209
00:06:50,000 --> 00:06:54,720
discomforting but essential you need to

210
00:06:53,039 --> 00:06:56,160
think interests you need to be interest

211
00:06:54,720 --> 00:06:58,000
L that's not just your interest that's

212
00:06:56,160 --> 00:06:59,360
also the countries and the companies

213
00:06:58,000 --> 00:07:01,360
with which you're engaging in our case

214
00:06:59,360 --> 00:07:03,360
in Japan but it could be anywhere like

215
00:07:01,360 --> 00:07:05,199
what do they want out of this really

216
00:07:03,360 --> 00:07:06,599
understanding those early on is crucial

217
00:07:05,199 --> 00:07:08,800
and then distilling all these insights

218
00:07:06,599 --> 00:07:10,120
into microscripts I think if you do

219
00:07:08,800 --> 00:07:12,199
those you can play a real role in

220
00:07:10,120 --> 00:07:13,960
helping to drive the solution in many of

221
00:07:12,199 --> 00:07:15,759
these countries whilst also exporting

222
00:07:13,960 --> 00:07:17,840
from your own the solutions that are

223
00:07:15,759 --> 00:07:19,960
going to most help um your potential

224
00:07:17,840 --> 00:07:22,199
Partners so an example of one of those

225
00:07:19,960 --> 00:07:23,919
micros scripts we worked with a a small

226
00:07:22,199 --> 00:07:25,400
UK drone manufacturer that's

227
00:07:23,919 --> 00:07:27,800
manufacturing drones that are currently

228
00:07:25,400 --> 00:07:30,319
operating in Ukraine for one the cost of

229
00:07:27,800 --> 00:07:32,319
1 F35 you can buy a thousand of these

230
00:07:30,319 --> 00:07:34,120
drones and what we talk about the dollar

231
00:07:32,319 --> 00:07:35,599
cost dollar damage ratio how much you

232
00:07:34,120 --> 00:07:38,160
damage you can inflict for how much the

233
00:07:35,599 --> 00:07:40,319
equipment costs is vastly in favor of

234
00:07:38,160 --> 00:07:41,879
the drones my friend Mike horovitz

235
00:07:40,319 --> 00:07:44,720
recently wrote an ask in foreign affairs

236
00:07:41,879 --> 00:07:47,159
talking about the age of precision Mass

237
00:07:44,720 --> 00:07:48,800
um and this is exactly that now in Japan

238
00:07:47,159 --> 00:07:50,039
where we were doing business um but I

239
00:07:48,800 --> 00:07:52,240
would suggest anywhere in the world

240
00:07:50,039 --> 00:07:53,479
right now there is still an over

241
00:07:52,240 --> 00:07:55,440
Alliance on these kind of Exquisite

242
00:07:53,479 --> 00:07:57,440
large scale systems and less of the

243
00:07:55,440 --> 00:07:58,840
milit of the military startup ecosystem

244
00:07:57,440 --> 00:08:00,400
that you need beneath that to provide

245
00:07:58,840 --> 00:08:01,960
these kind of things

246
00:08:00,400 --> 00:08:03,800
what we were able to go in is explain

247
00:08:01,960 --> 00:08:06,080
how startups supporting the war in

248
00:08:03,800 --> 00:08:08,599
Ukraine can move with real speed was the

249
00:08:06,080 --> 00:08:10,639
first thing so going from new uh

250
00:08:08,599 --> 00:08:12,360
requirement to a new capability in less

251
00:08:10,639 --> 00:08:14,759
than six weeks and continuously doing

252
00:08:12,360 --> 00:08:17,000
that Innovation cycle how they were

253
00:08:14,759 --> 00:08:18,319
doing that at scale able to manufacture

254
00:08:17,000 --> 00:08:21,120
I can't give the precise numbers but

255
00:08:18,319 --> 00:08:22,720
many hundreds of these every month and

256
00:08:21,120 --> 00:08:24,520
then Supply the need to understand your

257
00:08:22,720 --> 00:08:25,919
supply chains in much greater detail

258
00:08:24,520 --> 00:08:27,759
than many countries currently do so

259
00:08:25,919 --> 00:08:29,720
three micros scripts speed scale and

260
00:08:27,759 --> 00:08:31,240
supply and explaining how there were

261
00:08:29,720 --> 00:08:32,919
lessons from Ukraine for the defense of

262
00:08:31,240 --> 00:08:36,080
Japan starting with a thought leadership

263
00:08:32,919 --> 00:08:38,399
piece that really gave value to our

264
00:08:36,080 --> 00:08:39,919
Japanese Partners in explaining like how

265
00:08:38,399 --> 00:08:41,479
the the war in Ukraine might affect

266
00:08:39,919 --> 00:08:43,440
their own security and therefore why

267
00:08:41,479 --> 00:08:44,880
they might be interested and indeed this

268
00:08:43,440 --> 00:08:46,120
has been so successful that yes we've

269
00:08:44,880 --> 00:08:48,680
moved on of course with the the

270
00:08:46,120 --> 00:08:50,360
nitty-gritty business of sales of

271
00:08:48,680 --> 00:08:51,720
equipment uh in that country and

272
00:08:50,360 --> 00:08:53,800
building Partnerships and building

273
00:08:51,720 --> 00:08:55,800
factories and learning from Japan about

274
00:08:53,800 --> 00:08:57,920
how you do um automation at scale for

275
00:08:55,800 --> 00:09:00,680
the UK company that we've partnered

276
00:08:57,920 --> 00:09:02,480
with but also what we've done through

277
00:09:00,680 --> 00:09:03,920
this process is is create a kind of

278
00:09:02,480 --> 00:09:05,680
repeatable business model where now we

279
00:09:03,920 --> 00:09:08,000
can go in with other startups that can

280
00:09:05,680 --> 00:09:09,680
offer um key advantages that help drive

281
00:09:08,000 --> 00:09:10,959
that dynamism into the economy I've

282
00:09:09,680 --> 00:09:12,279
started having Venture capitalists

283
00:09:10,959 --> 00:09:14,279
coming to me to ask well can you help us

284
00:09:12,279 --> 00:09:15,680
do Market entry into Japan can you

285
00:09:14,279 --> 00:09:17,200
advise on like the thought leadership

286
00:09:15,680 --> 00:09:19,600
piece where we tell our story about how

287
00:09:17,200 --> 00:09:21,320
we disrupt and that helps us to jointly

288
00:09:19,600 --> 00:09:23,240
enable the kind of reforms that these

289
00:09:21,320 --> 00:09:24,720
countries need I think that that's just

290
00:09:23,240 --> 00:09:26,040
as true something you could do equally

291
00:09:24,720 --> 00:09:27,880
well in Korea and I think you could do

292
00:09:26,040 --> 00:09:31,160
it in many countries across the Indo

293
00:09:27,880 --> 00:09:34,200
Pacific and so I I share an example that

294
00:09:31,160 --> 00:09:36,720
is from Fujitsu from UK entering Japan

295
00:09:34,200 --> 00:09:38,360
but I think is globally applicable um

296
00:09:36,720 --> 00:09:40,360
and it relates back to where we started

297
00:09:38,360 --> 00:09:42,320
because many of these countries need the

298
00:09:40,360 --> 00:09:43,720
kind of dynamism in the economy that

299
00:09:42,320 --> 00:09:45,360
these kind of Partnerships can bring if

300
00:09:43,720 --> 00:09:48,440
they're to keep up with that constant

301
00:09:45,360 --> 00:09:50,360
speed of innovation in in cognitive

302
00:09:48,440 --> 00:09:51,720
Technologies the other thing you

303
00:09:50,360 --> 00:09:53,560
obviously need to do is new product

304
00:09:51,720 --> 00:09:56,600
development but often not in the way

305
00:09:53,560 --> 00:09:58,800
that you have been doing it today so um

306
00:09:56,600 --> 00:10:01,519
about two and a half gusting three years

307
00:09:58,800 --> 00:10:04,120
ago in fij Jitsu um before there were

308
00:10:01,519 --> 00:10:06,040
llms we kicked off a neuros symbolic AI

309
00:10:04,120 --> 00:10:08,480
program called cibil and I'll talk a

310
00:10:06,040 --> 00:10:10,240
little bit about what that was and at

311
00:10:08,480 --> 00:10:12,000
the time we were looking at how we could

312
00:10:10,240 --> 00:10:15,040
apply knowledge graphs to deliver

313
00:10:12,000 --> 00:10:16,880
explainable AI when we launched it I was

314
00:10:15,040 --> 00:10:18,600
able to say with confidence that the

315
00:10:16,880 --> 00:10:21,000
only person I knew apart from me

316
00:10:18,600 --> 00:10:22,920
globally speaking publicly about how the

317
00:10:21,000 --> 00:10:26,240
future of AI would be neuros symbolic

318
00:10:22,920 --> 00:10:29,839
and not purely neural networks was yanon

319
00:10:26,240 --> 00:10:32,920
at um at meta um and then

320
00:10:29,839 --> 00:10:35,320
uh llms came out of generative AI with a

321
00:10:32,920 --> 00:10:38,800
um a neural network based architecture

322
00:10:35,320 --> 00:10:41,399
and now we're back with chat GPT uh zero

323
00:10:38,800 --> 00:10:42,600
um to neuros symbolic Solutions so it's

324
00:10:41,399 --> 00:10:44,120
an example of how we started off with

325
00:10:42,600 --> 00:10:45,639
something that was unique we then were

326
00:10:44,120 --> 00:10:47,399
sort of overtaken by innovation in the

327
00:10:45,639 --> 00:10:48,720
things that we were betting against and

328
00:10:47,399 --> 00:10:50,279
now we're back to where neuros symbolic

329
00:10:48,720 --> 00:10:51,639
is actually really important and the

330
00:10:50,279 --> 00:10:53,000
reason it's important is many of the

331
00:10:51,639 --> 00:10:55,519
challenges faced by llms are

332
00:10:53,000 --> 00:10:56,800
inaccuracies biases hallucinations

333
00:10:55,519 --> 00:10:58,600
fundamentally that they are not

334
00:10:56,800 --> 00:11:00,440
explainable in the recommendations that

335
00:10:58,600 --> 00:11:02,000
they give you so you can revolutionize

336
00:11:00,440 --> 00:11:04,560
decision-making but if you can't audit

337
00:11:02,000 --> 00:11:07,639
the recommendations you receive then you

338
00:11:04,560 --> 00:11:10,200
can't rely on them what what we do is we

339
00:11:07,639 --> 00:11:11,720
brought the neuro of neural networks so

340
00:11:10,200 --> 00:11:14,120
often superhuman performance like in

341
00:11:11,720 --> 00:11:15,959
alphao Z for example but fundamentally

342
00:11:14,120 --> 00:11:18,160
not explainable together with the

343
00:11:15,959 --> 00:11:20,720
symbolic of good oldfashioned AI the if

344
00:11:18,160 --> 00:11:23,480
then else structured approach to

345
00:11:20,720 --> 00:11:25,160
encoding um symbolically how we

346
00:11:23,480 --> 00:11:26,480
understand the world and feeding all

347
00:11:25,160 --> 00:11:28,160
that into a knowledge graph that could

348
00:11:26,480 --> 00:11:30,200
ultimately output text but tell you

349
00:11:28,160 --> 00:11:32,480
where that had come from so an abstract

350
00:11:30,200 --> 00:11:34,160
level that's the new product development

351
00:11:32,480 --> 00:11:35,399
another way analogously of thinking of

352
00:11:34,160 --> 00:11:37,279
this is the murder board that you might

353
00:11:35,399 --> 00:11:39,200
see in any kind of movie Thriller right

354
00:11:37,279 --> 00:11:40,760
that connects objects entities and

355
00:11:39,200 --> 00:11:42,040
events with the red string and he's

356
00:11:40,760 --> 00:11:43,279
trying to explain how something happened

357
00:11:42,040 --> 00:11:44,519
by connecting everything up and then

358
00:11:43,279 --> 00:11:46,480
being able to explain both the

359
00:11:44,519 --> 00:11:48,560
individual pieces of data and the

360
00:11:46,480 --> 00:11:50,920
connections between them so cibil was

361
00:11:48,560 --> 00:11:53,360
designed to build that kind of Knowledge

362
00:11:50,920 --> 00:11:54,880
Graph through neuros symbolic approaches

363
00:11:53,360 --> 00:11:56,360
which massively reduces the amount of

364
00:11:54,880 --> 00:11:58,360
power that you need the energy challenge

365
00:11:56,360 --> 00:12:00,839
that we talked about earlier um but also

366
00:11:58,360 --> 00:12:02,360
allows you to explain L um and it we

367
00:12:00,839 --> 00:12:03,760
built it in a way that allowed you to

368
00:12:02,360 --> 00:12:05,760
ask problems in natural language

369
00:12:03,760 --> 00:12:08,880
questions but remember this is before

370
00:12:05,760 --> 00:12:10,800
chat GPT um and so what we found is we

371
00:12:08,880 --> 00:12:12,199
started this workof developed real depth

372
00:12:10,800 --> 00:12:14,760
of understanding and then suddenly we're

373
00:12:12,199 --> 00:12:16,800
overtaken by technology you know we were

374
00:12:14,760 --> 00:12:18,040
um presenting this internally of look we

375
00:12:16,800 --> 00:12:20,279
can now build a knowledge graph from

376
00:12:18,040 --> 00:12:21,760
unstructured data looks a bit like this

377
00:12:20,279 --> 00:12:25,160
when you just take a small extract of it

378
00:12:21,760 --> 00:12:27,000
we were using it for um sanctions um

379
00:12:25,160 --> 00:12:28,959
sanctions monitoring and sanctions

380
00:12:27,000 --> 00:12:31,920
implementation and sanctions enforcement

381
00:12:28,959 --> 00:12:34,000
so this is O der Pasa hello o uh this

382
00:12:31,920 --> 00:12:35,920
was O der Pasa and some of his interests

383
00:12:34,000 --> 00:12:37,600
around the world um and whether they may

384
00:12:35,920 --> 00:12:39,120
or may not be subject to sanctions I

385
00:12:37,600 --> 00:12:40,920
have no idea if they actually were quick

386
00:12:39,120 --> 00:12:44,160
qualifier but that was the example we

387
00:12:40,920 --> 00:12:45,880
were using um then the output that we

388
00:12:44,160 --> 00:12:47,480
would get was ultimately explainable so

389
00:12:45,880 --> 00:12:49,199
it would say bat mining limited is a

390
00:12:47,480 --> 00:12:50,839
company blah blah blah but it would also

391
00:12:49,199 --> 00:12:52,920
output allow you to understand where

392
00:12:50,839 --> 00:12:54,480
that data had come from so now you

393
00:12:52,920 --> 00:12:57,199
haven't got just the generative AI

394
00:12:54,480 --> 00:12:59,480
output that may have also hallucinated

395
00:12:57,199 --> 00:13:01,480
um the sources that it comes from you've

396
00:12:59,480 --> 00:13:03,399
got an explainable output in a knowledge

397
00:13:01,480 --> 00:13:05,880
graph that you can look back at and you

398
00:13:03,399 --> 00:13:08,480
can see how you got to the answer what

399
00:13:05,880 --> 00:13:10,120
I'm trying to emphasize here is not so

400
00:13:08,480 --> 00:13:11,959
much the technology itself as the

401
00:13:10,120 --> 00:13:13,320
importance of investing in things and

402
00:13:11,959 --> 00:13:14,720
keeping going with them sometimes even

403
00:13:13,320 --> 00:13:16,920
when they're overtaken by things like

404
00:13:14,720 --> 00:13:18,920
chat GPT because ultimately that

405
00:13:16,920 --> 00:13:20,760
knowledge has gone into Fujitsu Global's

406
00:13:18,920 --> 00:13:22,320
project called homes hyper relational

407
00:13:20,760 --> 00:13:24,560
knowledge Gras for multihop questioning

408
00:13:22,320 --> 00:13:26,639
answering using llms it's supporting

409
00:13:24,560 --> 00:13:29,440
fujitsu's work with coh here building

410
00:13:26,639 --> 00:13:31,000
their next um llm a multilingual model

411
00:13:29,440 --> 00:13:32,480
which is specifically focused sector by

412
00:13:31,000 --> 00:13:34,800
sector on boosting productivity and

413
00:13:32,480 --> 00:13:36,800
efficiency as a service that's a Fujitsu

414
00:13:34,800 --> 00:13:38,880
collaboration um and so what we have

415
00:13:36,800 --> 00:13:40,440
done here is we've we've built the

416
00:13:38,880 --> 00:13:42,800
fundamental understanding that now can

417
00:13:40,440 --> 00:13:44,760
move into some of these more upto-date

418
00:13:42,800 --> 00:13:46,480
kazuchi solutions that Fujitsu offers

419
00:13:44,760 --> 00:13:47,560
all all around the world and so I want

420
00:13:46,480 --> 00:13:49,120
to make the point that it's worth

421
00:13:47,560 --> 00:13:52,120
investing sometimes even when what you

422
00:13:49,120 --> 00:13:54,120
do is ultimately overtaken by technology

423
00:13:52,120 --> 00:13:56,279
um I think I'll skip over that

424
00:13:54,120 --> 00:13:57,880
one well we've moved to in the fusion

425
00:13:56,279 --> 00:13:59,839
cell within the the Center for Cognitive

426
00:13:57,880 --> 00:14:02,120
technologies that I've I run now is

427
00:13:59,839 --> 00:14:04,320
investing in showing the value of new

428
00:14:02,120 --> 00:14:06,000
technologies from Partners so um

429
00:14:04,320 --> 00:14:08,399
productivity and transformation in the

430
00:14:06,000 --> 00:14:09,720
Long Hall of adoption so for example

431
00:14:08,399 --> 00:14:12,160
there are studies like this that show

432
00:14:09,720 --> 00:14:14,480
the jagged Frontier of AI capabilities

433
00:14:12,160 --> 00:14:15,759
um working in this case with um Boston

434
00:14:14,480 --> 00:14:17,399
the Boston Consulting Group with this

435
00:14:15,759 --> 00:14:19,120
wasn't us this is a study from the wton

436
00:14:17,399 --> 00:14:21,040
business school if I recall correctly

437
00:14:19,120 --> 00:14:23,160
showing that when Boston Consulting

438
00:14:21,040 --> 00:14:25,519
Group Consultants worked with chat GPT

439
00:14:23,160 --> 00:14:29,360
they could produce complete 12% more

440
00:14:25,519 --> 00:14:31,279
tasks 25% faster 40% increase in quality

441
00:14:29,360 --> 00:14:32,880
the point here is not the detail the

442
00:14:31,279 --> 00:14:35,880
point is that this translates into real

443
00:14:32,880 --> 00:14:37,959
world terms the advantages of adopting

444
00:14:35,880 --> 00:14:39,079
emerging Technologies another one here

445
00:14:37,959 --> 00:14:41,160
that shows how you can be much more

446
00:14:39,079 --> 00:14:42,720
creative by using llms what we're

447
00:14:41,160 --> 00:14:44,880
investing in now is not just the new

448
00:14:42,720 --> 00:14:47,079
technologies but partner Technologies

449
00:14:44,880 --> 00:14:48,440
with our customers to produce studies

450
00:14:47,079 --> 00:14:50,440
like these that will be out in the next

451
00:14:48,440 --> 00:14:52,320
12 months that will show when you use

452
00:14:50,440 --> 00:14:55,320
this particular solution here is the

453
00:14:52,320 --> 00:14:56,279
very specific value that it creates but

454
00:14:55,320 --> 00:14:58,519
here is how you're going to have to

455
00:14:56,279 --> 00:15:00,519
change your organization to adopt it so

456
00:14:58,519 --> 00:15:02,480
try to invest not just in R&D in the

457
00:15:00,519 --> 00:15:05,480
technology but R&D in how the technology

458
00:15:02,480 --> 00:15:08,480
is applied is just as crucial for

459
00:15:05,480 --> 00:15:09,759
keeping up um just as crucial for

460
00:15:08,480 --> 00:15:11,959
keeping up with the speed of te

461
00:15:09,759 --> 00:15:13,440
technological advance and also you need

462
00:15:11,959 --> 00:15:14,959
to invest sometimes in spinning out

463
00:15:13,440 --> 00:15:18,360
things that will work better outside

464
00:15:14,959 --> 00:15:19,839
than they will work inside so um many of

465
00:15:18,360 --> 00:15:22,079
you will be familiar with the science of

466
00:15:19,839 --> 00:15:23,560
super forecasting the idea that if you

467
00:15:22,079 --> 00:15:25,399
take the median estima of a crowd

468
00:15:23,560 --> 00:15:27,320
forecast it consistently outperforms

469
00:15:25,399 --> 00:15:29,000
individual forecasts the idea that

470
00:15:27,320 --> 00:15:30,839
humans when we assuming we're not a room

471
00:15:29,000 --> 00:15:32,920
for the super forecasters when we make

472
00:15:30,839 --> 00:15:34,560
forecasts we are no better than dart

473
00:15:32,920 --> 00:15:37,480
throwing chimps we are no better than

474
00:15:34,560 --> 00:15:39,120
chance we're about 50% accurate my

475
00:15:37,480 --> 00:15:40,880
insight a while ago was that super

476
00:15:39,120 --> 00:15:42,120
forecasting is is going to be the future

477
00:15:40,880 --> 00:15:44,959
of forecasting but it's likely to be

478
00:15:42,120 --> 00:15:46,319
driven in part by AI um and also the

479
00:15:44,959 --> 00:15:47,759
fundamental problem we have is that we

480
00:15:46,319 --> 00:15:49,160
often face our forecast in the wrong

481
00:15:47,759 --> 00:15:50,880
direction if you're not forecasting the

482
00:15:49,160 --> 00:15:53,560
right things they don't help to close

483
00:15:50,880 --> 00:15:54,839
organizational blind spots but if you

484
00:15:53,560 --> 00:15:56,600
bring collective intelligence the

485
00:15:54,839 --> 00:15:57,800
science of human and machines thinking

486
00:15:56,600 --> 00:16:00,000
together with the science of super

487
00:15:57,800 --> 00:16:03,720
forecasting you can do fundamentally new

488
00:16:00,000 --> 00:16:05,199
things in fundamental new ways so we

489
00:16:03,720 --> 00:16:07,160
built a product called hive mind which

490
00:16:05,199 --> 00:16:09,440
will likely spin out as a new business

491
00:16:07,160 --> 00:16:11,240
it helps increase forecasting accuracy

492
00:16:09,440 --> 00:16:13,160
by allowing you to ask better questions

493
00:16:11,240 --> 00:16:14,959
to deliver better outcomes it both

494
00:16:13,160 --> 00:16:17,440
crowdsource questions and increasingly

495
00:16:14,959 --> 00:16:19,480
uses AI to generate the most important

496
00:16:17,440 --> 00:16:21,959
questions associated with any given

497
00:16:19,480 --> 00:16:23,800
outcome so it's an elicitation tool

498
00:16:21,959 --> 00:16:25,519
first of all it cuts through corporate

499
00:16:23,800 --> 00:16:28,240
strategy by saying what do you really

500
00:16:25,519 --> 00:16:29,240
want to achieve you need to be specific

501
00:16:28,240 --> 00:16:31,160
in what it is you're trying to achieve

502
00:16:29,240 --> 00:16:33,399
and if you can tell me that I can then

503
00:16:31,160 --> 00:16:35,680
run it through the crowdsourcing and AI

504
00:16:33,399 --> 00:16:37,519
um engine I can break it into the top

505
00:16:35,680 --> 00:16:39,279
five 10 or million factors for its

506
00:16:37,519 --> 00:16:41,240
achievement and then I can use

507
00:16:39,279 --> 00:16:44,120
forecasting both from Ai and super

508
00:16:41,240 --> 00:16:47,040
forecasters to assign probabilities to

509
00:16:44,120 --> 00:16:48,720
it what does that mean for you now it

510
00:16:47,040 --> 00:16:50,399
allows you to put numbers on anything it

511
00:16:48,720 --> 00:16:51,800
allows you to know like what probability

512
00:16:50,399 --> 00:16:53,880
is it that I will achieve the outcome

513
00:16:51,800 --> 00:16:55,399
that I want in a given time frame what

514
00:16:53,880 --> 00:16:56,920
probability is it that these factors

515
00:16:55,399 --> 00:16:58,959
that are crucial for that outcome will

516
00:16:56,920 --> 00:17:00,560
resolve in the way that I want and then

517
00:16:58,959 --> 00:17:02,199
can ask what if questions what if I did

518
00:17:00,560 --> 00:17:04,400
this how would it change the likelihood

519
00:17:02,199 --> 00:17:06,120
of success now we don't think about

520
00:17:04,400 --> 00:17:08,760
decisions like that when we're in the

521
00:17:06,120 --> 00:17:10,000
sea Suite or the um you know the command

522
00:17:08,760 --> 00:17:11,640
group in the military or the private

523
00:17:10,000 --> 00:17:14,600
office of a government department or

524
00:17:11,640 --> 00:17:16,000
whatever you call that in the US um we

525
00:17:14,600 --> 00:17:17,559
we tend to sit around the table there's

526
00:17:16,000 --> 00:17:18,720
only ever so much diversity around that

527
00:17:17,559 --> 00:17:20,000
table that you cannot have all the

528
00:17:18,720 --> 00:17:21,880
diversity you need so you won't have

529
00:17:20,000 --> 00:17:24,480
enough lenses on the problem whereas we

530
00:17:21,880 --> 00:17:27,000
can bring that kind of um that kind of

531
00:17:24,480 --> 00:17:28,520
divers customizable diversity profile we

532
00:17:27,000 --> 00:17:30,600
can use both the AI and people we can

533
00:17:28,520 --> 00:17:32,120
allow you put numbers on anything and we

534
00:17:30,600 --> 00:17:34,280
can allow you to do it to your adversary

535
00:17:32,120 --> 00:17:35,679
or your competitor strategy to

536
00:17:34,280 --> 00:17:37,880
understand what you could do to

537
00:17:35,679 --> 00:17:39,919
maximally um reduce their chances of

538
00:17:37,880 --> 00:17:42,160
success how does it work well it's an

539
00:17:39,919 --> 00:17:44,400
elicitation tool so it elices the

540
00:17:42,160 --> 00:17:46,960
decision makers desired outcomes it's an

541
00:17:44,400 --> 00:17:49,120
aggregation call tool it allows you to

542
00:17:46,960 --> 00:17:50,400
gather diverse Insight um to understand

543
00:17:49,120 --> 00:17:51,919
what the most important questions and

544
00:17:50,400 --> 00:17:53,760
factors are for the achievement of your

545
00:17:51,919 --> 00:17:55,679
outcome and then ultimately it's a

546
00:17:53,760 --> 00:17:57,559
divination tool in that it will help you

547
00:17:55,679 --> 00:17:58,919
to spot factors and and ways of

548
00:17:57,559 --> 00:18:00,039
achieving your goal that you would never

549
00:17:58,919 --> 00:18:02,400
have thought

550
00:18:00,039 --> 00:18:03,640
of a little proof point for some of the

551
00:18:02,400 --> 00:18:06,240
things that we've been able to do within

552
00:18:03,640 --> 00:18:07,720
that program we entered metaculus is um

553
00:18:06,240 --> 00:18:09,360
so the world's largest crowd sourcing

554
00:18:07,720 --> 00:18:11,520
platform they ran a forecasting

555
00:18:09,360 --> 00:18:13,480
tournament for Bots for AIS we built an

556
00:18:11,520 --> 00:18:15,360
ensembl of bots we entered it you can

557
00:18:13,480 --> 00:18:17,640
see Fujitsu researcher there number one

558
00:18:15,360 --> 00:18:20,039
we won that competition the distance

559
00:18:17,640 --> 00:18:21,600
between us and second place is the same

560
00:18:20,039 --> 00:18:23,400
as the distance between second place and

561
00:18:21,600 --> 00:18:24,760
sixth place if you want to imagine what

562
00:18:23,400 --> 00:18:26,840
that kind of a win looks like imagine

563
00:18:24,760 --> 00:18:28,520
Usain Bolt crossing the 100 meter Finish

564
00:18:26,840 --> 00:18:30,640
Line and how far everybody else usually

565
00:18:28,520 --> 00:18:32,320
is behind him it's a useful visual image

566
00:18:30,640 --> 00:18:34,679
for understanding just how successful we

567
00:18:32,320 --> 00:18:36,400
were we were able to cover questions

568
00:18:34,679 --> 00:18:39,120
across such a huge range so question

569
00:18:36,400 --> 00:18:41,960
will the Chicago White Socks lose 124

570
00:18:39,120 --> 00:18:43,919
games in the 2024 MLB baseball season

571
00:18:41,960 --> 00:18:46,600
that was asked on the 16th of September

572
00:18:43,919 --> 00:18:49,320
at the time humans were betting 75% yes

573
00:18:46,600 --> 00:18:51,120
Cassie our bot bet no and the result was

574
00:18:49,320 --> 00:18:52,880
no the point I want to make here also is

575
00:18:51,120 --> 00:18:54,880
that as a Brit my team had absolutely no

576
00:18:52,880 --> 00:18:56,159
idea about baseball but by calibrating

577
00:18:54,880 --> 00:18:58,039
the bot we were able to get a really

578
00:18:56,159 --> 00:18:59,640
accurate forecast and look at the

579
00:18:58,039 --> 00:19:00,960
breadth here I'll sort of dance through

580
00:18:59,640 --> 00:19:02,799
these a bit because the detail matters

581
00:19:00,960 --> 00:19:04,240
less but the the breadth of things here

582
00:19:02,799 --> 00:19:06,320
where we outperformed where the bot

583
00:19:04,240 --> 00:19:08,159
outperformed humans is really

584
00:19:06,320 --> 00:19:09,600
significant so this was 300 measles

585
00:19:08,159 --> 00:19:12,600
cases being reported in the United

586
00:19:09,600 --> 00:19:14,760
States in 2024 then really obscure like

587
00:19:12,600 --> 00:19:16,360
more Spanish Wikipedia articles than two

588
00:19:14,760 --> 00:19:18,280
million by October the 1st like who who

589
00:19:16,360 --> 00:19:20,679
knows that but the bot got a much better

590
00:19:18,280 --> 00:19:22,240
estimate than humans did um a really

591
00:19:20,679 --> 00:19:23,679
consequential one will Intel get dropped

592
00:19:22,240 --> 00:19:25,640
from the Dow Jones Industrial Average

593
00:19:23,679 --> 00:19:28,720
before October the 1st

594
00:19:25,640 --> 00:19:30,640
2024 will Russia control po rosk before

595
00:19:28,720 --> 00:19:32,440
October the 1st 2024 humans thought it

596
00:19:30,640 --> 00:19:35,240
thought they would Cassie said no Cassie

597
00:19:32,440 --> 00:19:36,480
was right um and then here 28%

598
00:19:35,240 --> 00:19:38,520
incidentally is a threshold in the

599
00:19:36,480 --> 00:19:40,799
German election so will alternative for

600
00:19:38,520 --> 00:19:43,600
deuts land a far-right party in in

601
00:19:40,799 --> 00:19:45,600
Germany get more than 208% less than 30

602
00:19:43,600 --> 00:19:48,280
in the brandenberg state election people

603
00:19:45,600 --> 00:19:49,799
bet no Cassie bet yes answer was yes the

604
00:19:48,280 --> 00:19:52,159
point there is that we're now moving

605
00:19:49,799 --> 00:19:54,840
into an era where we can generate 2,500

606
00:19:52,159 --> 00:19:56,880
predictions forecasts in one day against

607
00:19:54,840 --> 00:19:58,120
any outcome that you want we can assign

608
00:19:56,880 --> 00:19:59,960
probabilities we can put numbers on

609
00:19:58,120 --> 00:20:01,720
things you could never put numbers on

610
00:19:59,960 --> 00:20:04,039
before and the point I want to make in

611
00:20:01,720 --> 00:20:06,440
that huge sort of Tor Reon in just just

612
00:20:04,039 --> 00:20:08,679
15 minutes that your R&D strategy can't

613
00:20:06,440 --> 00:20:10,600
be one thing some of the things that you

614
00:20:08,679 --> 00:20:12,559
build will be overtaken and pivot and

615
00:20:10,600 --> 00:20:13,840
need to be Amalgamated some of the

616
00:20:12,559 --> 00:20:15,679
things you need to focus on how you

617
00:20:13,840 --> 00:20:16,960
create value and some of the things on

618
00:20:15,679 --> 00:20:19,039
the far side of that are really going to

619
00:20:16,960 --> 00:20:20,400
revolutionize how we make decisions and

620
00:20:19,039 --> 00:20:21,840
I think that we have built one of those

621
00:20:20,400 --> 00:20:26,280
and I'm looking forward to exploiting it

622
00:20:21,840 --> 00:20:26,280
in the months ahead any thanks

623
00:20:30,640 --> 00:20:37,880
thank you um we'll now um try to have

624
00:20:34,919 --> 00:20:40,000
some questions how will the Innovations

625
00:20:37,880 --> 00:20:42,760
from your research be deployed or

626
00:20:40,000 --> 00:20:45,240
commercialized through the HQ team of

627
00:20:42,760 --> 00:20:47,000
fuk well so if I take the example of

628
00:20:45,240 --> 00:20:49,799
cibil that that project reached the end

629
00:20:47,000 --> 00:20:51,440
of its life in the UK um under um Al

630
00:20:49,799 --> 00:20:52,799
Brown I'd like to give full credit to

631
00:20:51,440 --> 00:20:55,559
her because it was him that led that and

632
00:20:52,799 --> 00:20:56,760
did an incredible job so cibil um for

633
00:20:55,559 --> 00:20:59,159
for what we would Now call retrieval

634
00:20:56,760 --> 00:21:00,919
augmented um generation

635
00:20:59,159 --> 00:21:02,720
the idea of using graphs to improve the

636
00:21:00,919 --> 00:21:04,400
performance of llms he finished that

637
00:21:02,720 --> 00:21:06,600
work he handed it off to Fujitsu

638
00:21:04,400 --> 00:21:08,799
research in India who were doing not to

639
00:21:06,600 --> 00:21:10,720
similar work to us they then integrated

640
00:21:08,799 --> 00:21:14,120
it into homes my understanding is that

641
00:21:10,720 --> 00:21:15,679
all of that work is now in Fujitsu HQ

642
00:21:14,120 --> 00:21:17,039
and being used to directly inform the

643
00:21:15,679 --> 00:21:19,720
work that the global Corporation is

644
00:21:17,039 --> 00:21:21,520
doing with Co coh and sakuna Ai and

645
00:21:19,720 --> 00:21:22,960
others and the point I wanted to make is

646
00:21:21,520 --> 00:21:24,120
that is that when you do these kind of

647
00:21:22,960 --> 00:21:25,919
things like sometimes it doesn't get

648
00:21:24,120 --> 00:21:27,840
commercialized directly as a new product

649
00:21:25,919 --> 00:21:29,320
or a new service sometimes it goes in

650
00:21:27,840 --> 00:21:31,279
and the knowhow becomes what's really

651
00:21:29,320 --> 00:21:32,640
valuable into the next thing that you do

652
00:21:31,279 --> 00:21:34,200
and as a large corporation you just need

653
00:21:32,640 --> 00:21:35,720
to accept that so that's one specific

654
00:21:34,200 --> 00:21:37,279
example they they all have slightly

655
00:21:35,720 --> 00:21:38,320
different stories and we'll take up the

656
00:21:37,279 --> 00:21:40,720
whole five minutes if I try and tell

657
00:21:38,320 --> 00:21:43,559
them all but that's a that's a good one

658
00:21:40,720 --> 00:21:45,720
thank you and next question what did you

659
00:21:43,559 --> 00:21:47,159
learn from your research being disrupted

660
00:21:45,720 --> 00:21:49,600
by open

661
00:21:47,159 --> 00:21:51,559
AI so one of one of the things I think

662
00:21:49,600 --> 00:21:53,320
we learned and I talk about a lot is if

663
00:21:51,559 --> 00:21:54,799
if you if you accept that right now we

664
00:21:53,320 --> 00:21:56,640
need some new information we need some

665
00:21:54,799 --> 00:21:58,120
evidence that scaling laws have peaked

666
00:21:56,640 --> 00:22:00,559
because if they continue we are on a

667
00:21:58,120 --> 00:22:01,559
path to AI like you need new information

668
00:22:00,559 --> 00:22:02,720
now there are some people betting

669
00:22:01,559 --> 00:22:04,360
against the saying no no current

670
00:22:02,720 --> 00:22:05,640
architectures have reached their their

671
00:22:04,360 --> 00:22:06,960
maximum but there's no evidence that

672
00:22:05,640 --> 00:22:08,400
that's the case and until there is we

673
00:22:06,960 --> 00:22:10,640
should probably expect the trend to

674
00:22:08,400 --> 00:22:12,799
continue so so I think the main thing I

675
00:22:10,640 --> 00:22:14,559
learned was a kind of um perspiration on

676
00:22:12,799 --> 00:22:16,679
Palms moment of like right now we really

677
00:22:14,559 --> 00:22:19,120
are on a path to AGI and and and if

678
00:22:16,679 --> 00:22:20,799
you're not betting on it you're betting

679
00:22:19,120 --> 00:22:23,400
against it and if you're betting against

680
00:22:20,799 --> 00:22:25,240
it you better hope you're right so um

681
00:22:23,400 --> 00:22:26,760
increasingly in in what I do and I speak

682
00:22:25,240 --> 00:22:28,120
in a personal capacity here but in the

683
00:22:26,760 --> 00:22:29,760
things that we do I'm trying to think

684
00:22:28,120 --> 00:22:31,880
okay well how how do we make sure that

685
00:22:29,760 --> 00:22:33,320
if AGI were to arrive on the timelines

686
00:22:31,880 --> 00:22:34,440
that I discussed we would be ready for

687
00:22:33,320 --> 00:22:36,320
it because if you're not betting on it

688
00:22:34,440 --> 00:22:38,159
you're betting against it and and that

689
00:22:36,320 --> 00:22:39,799
would be that would be my primary lesson

690
00:22:38,159 --> 00:22:41,200
is is the pace of Change Is Such don't

691
00:22:39,799 --> 00:22:42,960
bet against it and assume it's

692
00:22:41,200 --> 00:22:45,279
continuing and then uh try and build

693
00:22:42,960 --> 00:22:47,640
your plans

694
00:22:45,279 --> 00:22:49,480
accordingly and how much do you think

695
00:22:47,640 --> 00:22:52,720
collaboration with generative AI is

696
00:22:49,480 --> 00:22:55,559
limited by the current um constraints on

697
00:22:52,720 --> 00:22:58,240
real time and realistic user

698
00:22:55,559 --> 00:23:00,240
experiences that's interesting I I think

699
00:22:58,240 --> 00:23:02,480
I'm going to challenge the question

700
00:23:00,240 --> 00:23:04,799
Gabriel wherever you are I'm afraid I

701
00:23:02,480 --> 00:23:06,320
think that the primary constraint is not

702
00:23:04,799 --> 00:23:08,120
about real time and realistic user

703
00:23:06,320 --> 00:23:10,720
experiences it's about changing how we

704
00:23:08,120 --> 00:23:13,279
make decisions I think most most

705
00:23:10,720 --> 00:23:14,640
organizations are used to just having um

706
00:23:13,279 --> 00:23:16,400
well in the military we talk about

707
00:23:14,640 --> 00:23:17,600
bogats a bunch of guys sat around a

708
00:23:16,400 --> 00:23:18,960
table I don't I don't know if that's a

709
00:23:17,600 --> 00:23:21,000
socially acceptable way of describing it

710
00:23:18,960 --> 00:23:22,159
these days but uh like most decisions

711
00:23:21,000 --> 00:23:24,200
that's that's how they're that's how

712
00:23:22,159 --> 00:23:26,000
they're made and what you need is to be

713
00:23:24,200 --> 00:23:28,640
much more reliant on data and evidence

714
00:23:26,000 --> 00:23:30,440
and interrogating the logic and an AI

715
00:23:28,640 --> 00:23:32,440
drives rigor into decision- making that

716
00:23:30,440 --> 00:23:33,960
frankly is just absent in most large

717
00:23:32,440 --> 00:23:35,880
organizations both government and

718
00:23:33,960 --> 00:23:37,679
corporate so I think it's not really

719
00:23:35,880 --> 00:23:39,840
real time and realistic user experiences

720
00:23:37,679 --> 00:23:42,559
that limit our adoption of generative AI

721
00:23:39,840 --> 00:23:44,159
It's a combination of risk aversion um

722
00:23:42,559 --> 00:23:45,559
and kind of calcified practice that

723
00:23:44,159 --> 00:23:47,480
nobody wants to change because that

724
00:23:45,559 --> 00:23:49,559
would mean re redesigning so much more

725
00:23:47,480 --> 00:23:52,559
about your organization than many people

726
00:23:49,559 --> 00:23:54,799
are prepared to but my argument would be

727
00:23:52,559 --> 00:23:56,080
well if you're not betting on AGI you're

728
00:23:54,799 --> 00:23:57,559
betting against it and if you're betting

729
00:23:56,080 --> 00:24:00,000
on it you should start transforming your

730
00:23:57,559 --> 00:24:03,679
organization now

731
00:24:00,000 --> 00:24:05,480
thank you um we'll do one last question

732
00:24:03,679 --> 00:24:07,159
uh is there a first step to jump into

733
00:24:05,480 --> 00:24:10,360
Innovation that you would recommend to

734
00:24:07,159 --> 00:24:11,640
fellow industry innovators yeah um

735
00:24:10,360 --> 00:24:13,360
despite what I've said about the speed

736
00:24:11,640 --> 00:24:15,120
of change I gave a talk and wrote some

737
00:24:13,360 --> 00:24:18,000
stuff on this earlier this year so I I

738
00:24:15,120 --> 00:24:20,039
think when the speed of Advance is such

739
00:24:18,000 --> 00:24:21,400
as it currently is trying to follow

740
00:24:20,039 --> 00:24:23,080
means all you're going to do is fall

741
00:24:21,400 --> 00:24:24,640
fall further and further behind right

742
00:24:23,080 --> 00:24:26,559
like it's like trying to follow an

743
00:24:24,640 --> 00:24:27,600
Olympic sprint around the track they're

744
00:24:26,559 --> 00:24:28,720
faster than you and you're not going to

745
00:24:27,600 --> 00:24:30,799
keep up so if all you're doing is

746
00:24:28,720 --> 00:24:33,279
following Tech Trends in what you do

747
00:24:30,799 --> 00:24:34,919
you're you're probably going to lose I

748
00:24:33,279 --> 00:24:37,480
think you have to do what the US did

749
00:24:34,919 --> 00:24:39,240
with ass salt breaker um in in Dara in

750
00:24:37,480 --> 00:24:40,880
the 1970s you have to say like what what

751
00:24:39,240 --> 00:24:42,360
do we need what's our theory of Victory

752
00:24:40,880 --> 00:24:43,640
how are we going to win in 2030 I think

753
00:24:42,360 --> 00:24:45,039
Jeff bezels talks about working

754
00:24:43,640 --> 00:24:46,880
backwards as a kind of commercial

755
00:24:45,039 --> 00:24:49,399
example like where are we going to be in

756
00:24:46,880 --> 00:24:51,279
say 2030 what and therefore what

757
00:24:49,399 --> 00:24:52,399
technologies are we going to need to win

758
00:24:51,279 --> 00:24:54,880
if that's where we think we're going to

759
00:24:52,399 --> 00:24:56,720
be and start building technology now so

760
00:24:54,880 --> 00:24:58,840
a kind of neat micros script for saying

761
00:24:56,720 --> 00:25:00,360
that you need an R&D strategy

762
00:24:58,840 --> 00:25:02,360
that starts by building technologies

763
00:25:00,360 --> 00:25:03,840
that don't currently exist against a

764
00:25:02,360 --> 00:25:05,440
very clear theory of winning how are we

765
00:25:03,840 --> 00:25:08,480
going to achieve competitive advantage

766
00:25:05,440 --> 00:25:10,480
in for example 2030 because following

767
00:25:08,480 --> 00:25:12,080
Tech Trends is not going to work and the

768
00:25:10,480 --> 00:25:14,240
problem is in most large organization

769
00:25:12,080 --> 00:25:15,679
following Tech Trends is safer trying to

770
00:25:14,240 --> 00:25:17,360
bet on technologies that already exist

771
00:25:15,679 --> 00:25:18,799
you can explain to senior exx well

772
00:25:17,360 --> 00:25:21,240
here's why you should invest whereas

773
00:25:18,799 --> 00:25:22,720
betting in really high-risk um new areas

774
00:25:21,240 --> 00:25:24,399
is much harder to persuade investment

775
00:25:22,720 --> 00:25:25,679
committees to hand you money over for

776
00:25:24,399 --> 00:25:26,760
but I think it's essential otherwise you

777
00:25:25,679 --> 00:25:28,799
are just going to fall further and

778
00:25:26,760 --> 00:25:30,399
further behind

779
00:25:28,799 --> 00:25:33,960
thank you very much Keith for your

780
00:25:30,399 --> 00:25:33,960
interesting talk


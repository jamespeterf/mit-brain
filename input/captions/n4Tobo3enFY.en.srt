1
00:00:00,359 --> 00:00:05,440
so while while we're doing this I'll so

2
00:00:02,399 --> 00:00:09,040
explain the reason I have an Emmy is I

3
00:00:05,440 --> 00:00:11,679
developed a system for CBS broadcast of

4
00:00:09,040 --> 00:00:14,559
the PGA Tour um and if you want to have

5
00:00:11,679 --> 00:00:16,520
a disaster of of broadcast trying try

6
00:00:14,559 --> 00:00:19,039
being the director in in sort of

7
00:00:16,520 --> 00:00:20,880
broadcasting live golf you have the

8
00:00:19,039 --> 00:00:22,519
director screaming profanities over the

9
00:00:20,880 --> 00:00:24,160
airwav trying to get shots across the

10
00:00:22,519 --> 00:00:26,320
playing field which is the entire golf

11
00:00:24,160 --> 00:00:28,199
course so spent a lot of time sort of

12
00:00:26,320 --> 00:00:29,199
crawling around golf courses doing that

13
00:00:28,199 --> 00:00:31,720
so that's not what I'm going to talk

14
00:00:29,199 --> 00:00:34,399
about today um today I'll talk about

15
00:00:31,720 --> 00:00:37,040
smart factories data analytics and and

16
00:00:34,399 --> 00:00:39,239
sort of try to frame a couple different

17
00:00:37,040 --> 00:00:42,559
machine learning AI tools through the

18
00:00:39,239 --> 00:00:44,559
lens of manufacturing so the exciting

19
00:00:42,559 --> 00:00:47,120
opportunity being a mechanical engineer

20
00:00:44,559 --> 00:00:50,239
computer scientist is to look at at our

21
00:00:47,120 --> 00:00:52,680
Factories at our supply chains as data

22
00:00:50,239 --> 00:00:55,239
sources they we make product there's raw

23
00:00:52,680 --> 00:00:57,160
material in hopefully product out

24
00:00:55,239 --> 00:01:00,680
there's data in and data out and how do

25
00:00:57,160 --> 00:01:02,399
we leverage those data with content

26
00:01:00,680 --> 00:01:05,280
right so to be really dangerous and

27
00:01:02,399 --> 00:01:06,880
really powerful in this AI smart

28
00:01:05,280 --> 00:01:08,960
industry for whatever you want to call

29
00:01:06,880 --> 00:01:11,320
it it's actually having some data

30
00:01:08,960 --> 00:01:14,000
science knowledge and the contextual

31
00:01:11,320 --> 00:01:17,159
knowledge with which to apply simple

32
00:01:14,000 --> 00:01:19,080
tools so the key idea is smart digital

33
00:01:17,159 --> 00:01:21,040
it's not new right our ability to

34
00:01:19,080 --> 00:01:23,640
leverage data and high computational

35
00:01:21,040 --> 00:01:25,840
knowledge with sort of context domain

36
00:01:23,640 --> 00:01:27,520
knowledge is quite critical for us to be

37
00:01:25,840 --> 00:01:29,320
successful right so we need to bring

38
00:01:27,520 --> 00:01:31,320
these two worlds together so

39
00:01:29,320 --> 00:01:33,880
realizations what's not changed sort of

40
00:01:31,320 --> 00:01:36,960
think the world varies uh there's we

41
00:01:33,880 --> 00:01:39,399
need to control sort of for M raw

42
00:01:36,960 --> 00:01:43,159
material variation people variation

43
00:01:39,399 --> 00:01:44,320
machine Weare um we need to have models

44
00:01:43,159 --> 00:01:46,360
you know where those models come from

45
00:01:44,320 --> 00:01:48,680
physics we need to understand some have

46
00:01:46,360 --> 00:01:50,680
some physical intuition for why the way

47
00:01:48,680 --> 00:01:53,439
why things work in a particular way and

48
00:01:50,680 --> 00:01:55,240
use models to predict what's going to

49
00:01:53,439 --> 00:01:58,479
happen to sort of compare against what

50
00:01:55,240 --> 00:02:00,240
actually does happen um so why smart now

51
00:01:58,479 --> 00:02:02,119
so cost and ubiquity of tools the

52
00:02:00,240 --> 00:02:03,600
ability to sort of I left my cell phone

53
00:02:02,119 --> 00:02:05,240
over there but so the ability to get

54
00:02:03,600 --> 00:02:08,599
data from point A to point B without

55
00:02:05,240 --> 00:02:10,319
wires certainly the the AI tools that

56
00:02:08,599 --> 00:02:12,400
we're deploying now have been around for

57
00:02:10,319 --> 00:02:13,800
decades we've reached the point now

58
00:02:12,400 --> 00:02:16,000
where we have somebody else's computer

59
00:02:13,800 --> 00:02:17,760
the cloud and we have some Innovations

60
00:02:16,000 --> 00:02:20,760
and how we train these models that have

61
00:02:17,760 --> 00:02:22,160
and the access to data that is allowing

62
00:02:20,760 --> 00:02:25,120
us to be a lot more

63
00:02:22,160 --> 00:02:26,519
powerful but it's building on the

64
00:02:25,120 --> 00:02:28,760
context of what we're trying to do as

65
00:02:26,519 --> 00:02:30,360
manufacturers so in your industry you

66
00:02:28,760 --> 00:02:32,440
you need that context

67
00:02:30,360 --> 00:02:34,040
you understand well how to machines

68
00:02:32,440 --> 00:02:35,519
operate what what's the sort of the

69
00:02:34,040 --> 00:02:37,120
point of the what you're trying to make

70
00:02:35,519 --> 00:02:39,159
having the intuition for the types of

71
00:02:37,120 --> 00:02:41,360
questions to ask and then you need to

72
00:02:39,159 --> 00:02:43,560
have the data science folks either

73
00:02:41,360 --> 00:02:46,000
embodied in one team or embodied in one

74
00:02:43,560 --> 00:02:47,599
person to know well here are the types

75
00:02:46,000 --> 00:02:49,640
of algorithms that you can use some that

76
00:02:47,599 --> 00:02:50,879
are are interpretable which means a

77
00:02:49,640 --> 00:02:52,519
person can look at them and understand

78
00:02:50,879 --> 00:02:56,120
what they're doing by opening up the

79
00:02:52,519 --> 00:02:57,440
hood or or not um and sort of understand

80
00:02:56,120 --> 00:02:59,200
well how do I bring these two things

81
00:02:57,440 --> 00:03:01,239
together the data science and the

82
00:02:59,200 --> 00:03:02,480
manufacturing

83
00:03:01,239 --> 00:03:07,120
okay so if you want to think about how

84
00:03:02,480 --> 00:03:09,040
we approach a smart ear in data tensive

85
00:03:07,120 --> 00:03:10,680
system take your system take your

86
00:03:09,040 --> 00:03:13,319
machine take your oil field take

87
00:03:10,680 --> 00:03:14,720
whatever it is what is the sort of the

88
00:03:13,319 --> 00:03:17,120
physical intuition what's your sort of

89
00:03:14,720 --> 00:03:19,159
mental model the engineering model for

90
00:03:17,120 --> 00:03:21,239
how that thing operates and what do the

91
00:03:19,159 --> 00:03:22,640
sensors give us this this world of data

92
00:03:21,239 --> 00:03:24,760
the data comes from a sensor from

93
00:03:22,640 --> 00:03:26,640
someplace so you should be your best

94
00:03:24,760 --> 00:03:29,040
practice you should be good using good

95
00:03:26,640 --> 00:03:30,280
analog filtering you should be doing

96
00:03:29,040 --> 00:03:32,640
good instrumentation you should be

97
00:03:30,280 --> 00:03:35,439
satisfying nwis and collecting your data

98
00:03:32,640 --> 00:03:37,480
fast enough and as an aside I spend a

99
00:03:35,439 --> 00:03:39,239
lot of time working with companies that

100
00:03:37,480 --> 00:03:40,360
are asking hey we saw this wonderful

101
00:03:39,239 --> 00:03:41,840
paper that you put out on deep

102
00:03:40,360 --> 00:03:43,360
reinforcement learning applied to

103
00:03:41,840 --> 00:03:46,200
process control and we'll get to that as

104
00:03:43,360 --> 00:03:48,040
the last topic but six months into

105
00:03:46,200 --> 00:03:50,239
working with a company say yeah actually

106
00:03:48,040 --> 00:03:53,280
you know what this data that you told us

107
00:03:50,239 --> 00:03:55,840
had been collected at 1 second interval

108
00:03:53,280 --> 00:03:59,120
uniformly yeah sometimes it's acquired

109
00:03:55,840 --> 00:04:01,439
every 1.5 seconds sometimes every 0.5

110
00:03:59,120 --> 00:04:03,799
seconds and just the basics of

111
00:04:01,439 --> 00:04:05,959
understanding what's the time what what

112
00:04:03,799 --> 00:04:07,280
is time associated with your data if you

113
00:04:05,959 --> 00:04:09,480
don't do that you can't do some of the

114
00:04:07,280 --> 00:04:10,920
basics like understand the frequency

115
00:04:09,480 --> 00:04:12,560
content of your data use the thing

116
00:04:10,920 --> 00:04:15,360
called the 4A transform which is the

117
00:04:12,560 --> 00:04:17,400
underpinning of all of signal processing

118
00:04:15,360 --> 00:04:19,919
and it's what allows you to do fast

119
00:04:17,400 --> 00:04:21,560
convolutions so some of the basics are

120
00:04:19,919 --> 00:04:23,840
some of the things that

121
00:04:21,560 --> 00:04:25,240
are just the housekeeping that needs to

122
00:04:23,840 --> 00:04:27,520
be put in place to be able to take

123
00:04:25,240 --> 00:04:28,840
advantage of the advanced tools so what

124
00:04:27,520 --> 00:04:31,199
do we want to visualize how do you

125
00:04:28,840 --> 00:04:34,560
visualize it and bring these two things

126
00:04:31,199 --> 00:04:37,240
together um so do your

127
00:04:34,560 --> 00:04:39,320
data give you consistent Insight with

128
00:04:37,240 --> 00:04:40,759
what you expect physically and if not if

129
00:04:39,320 --> 00:04:42,720
you see patterns and things that you

130
00:04:40,759 --> 00:04:44,199
don't understand do I need to do some

131
00:04:42,720 --> 00:04:46,240
additional experiments there's my mental

132
00:04:44,199 --> 00:04:49,039
model for what the operation is actually

133
00:04:46,240 --> 00:04:51,560
wrong design experiments and iterate in

134
00:04:49,039 --> 00:04:54,759
this sort of simultaneous physical model

135
00:04:51,560 --> 00:04:57,759
and digital and data model so this is my

136
00:04:54,759 --> 00:04:59,360
digital twin you know the the the clean

137
00:04:57,759 --> 00:05:01,440
clean shaven version of it I'm winner

138
00:04:59,360 --> 00:05:02,639
Rising I will be bleached in at the end

139
00:05:01,440 --> 00:05:05,000
of the week I'll be Santa Claus by the

140
00:05:02,639 --> 00:05:07,960
end of the year um and then I'll Dy it

141
00:05:05,000 --> 00:05:11,360
red for New Year's anybody want to

142
00:05:07,960 --> 00:05:13,840
Define what a digital twin

143
00:05:11,360 --> 00:05:15,960
is I don't really like the term digital

144
00:05:13,840 --> 00:05:17,759
twin I don't like giving new names to

145
00:05:15,960 --> 00:05:20,680
things that have existed for a long time

146
00:05:17,759 --> 00:05:22,600
so a digital twin is a model and the

147
00:05:20,680 --> 00:05:25,240
subtle difference that I'll sort of all

148
00:05:22,600 --> 00:05:26,880
accept where what we call a digital twin

149
00:05:25,240 --> 00:05:29,000
versus a model is a digital twin

150
00:05:26,880 --> 00:05:30,800
presumptively is something that is a

151
00:05:29,000 --> 00:05:33,319
model that you're dating it's a model

152
00:05:30,800 --> 00:05:36,639
that with some regularity you're getting

153
00:05:33,319 --> 00:05:38,400
additional data and improving the model

154
00:05:36,639 --> 00:05:41,160
in some way but you're using this twin

155
00:05:38,400 --> 00:05:43,319
you're using this model to predict to as

156
00:05:41,160 --> 00:05:45,160
an engineer as a designer as an operator

157
00:05:43,319 --> 00:05:46,720
to predict what's going to happen when

158
00:05:45,160 --> 00:05:47,800
you don't get what you expect to try to

159
00:05:46,720 --> 00:05:53,000
improve the

160
00:05:47,800 --> 00:05:55,000
model and go on and so models digital

161
00:05:53,000 --> 00:05:57,960
twins models that have some kind of at

162
00:05:55,000 --> 00:06:00,280
some time scale real time digital update

163
00:05:57,960 --> 00:06:03,520
and there can be models twins of of of

164
00:06:00,280 --> 00:06:07,039
process of product of factory of supply

165
00:06:03,520 --> 00:06:10,120
chain so my if you put um create a into

166
00:06:07,039 --> 00:06:11,520
a dolly your chat GPT create a a graphic

167
00:06:10,120 --> 00:06:13,639
that represents that that's this is what

168
00:06:11,520 --> 00:06:15,759
you get sort of the brain sort of

169
00:06:13,639 --> 00:06:17,720
ingesting sort of the data that with

170
00:06:15,759 --> 00:06:19,840
some physical model of the real world

171
00:06:17,720 --> 00:06:22,599
and doing some type of analytics off of

172
00:06:19,840 --> 00:06:26,199
that okay so

173
00:06:22,599 --> 00:06:29,080
models can come from to oversimplify

174
00:06:26,199 --> 00:06:31,039
purely data or purely physics or

175
00:06:29,080 --> 00:06:32,840
someplace in between and I would argue

176
00:06:31,039 --> 00:06:36,160
that the place where we can be really

177
00:06:32,840 --> 00:06:38,360
and where we have to be most focused in

178
00:06:36,160 --> 00:06:40,639
manufacturing and in operations is is

179
00:06:38,360 --> 00:06:43,199
really that gray box area meaning that

180
00:06:40,639 --> 00:06:45,160
we have some Physics we don't have all

181
00:06:43,199 --> 00:06:46,880
the physics we may be able to run

182
00:06:45,160 --> 00:06:49,560
computational fluid dynamics models we

183
00:06:46,880 --> 00:06:50,800
may be able to run bite element models

184
00:06:49,560 --> 00:06:53,000
um but we can augment that with

185
00:06:50,800 --> 00:06:54,599
additional data as opposed to well let's

186
00:06:53,000 --> 00:06:56,280
try to capture everything in the physics

187
00:06:54,599 --> 00:06:58,960
that's going to take you a long time and

188
00:06:56,280 --> 00:07:01,520
Flying Blind by just using your data in

189
00:06:58,960 --> 00:07:03,800
a black model doesn't really make any

190
00:07:01,520 --> 00:07:05,360
sense right because you don't you need

191
00:07:03,800 --> 00:07:06,639
to understand the context and sort of

192
00:07:05,360 --> 00:07:08,680
relate it to the things that you care

193
00:07:06,639 --> 00:07:14,000
about on the factory floor in the

194
00:07:08,680 --> 00:07:18,160
field so a way that I'd like to explain

195
00:07:14,000 --> 00:07:20,400
smart digital industry for

196
00:07:18,160 --> 00:07:22,840
digitalization it's really applied

197
00:07:20,400 --> 00:07:24,280
instrumentation and we we acquire data

198
00:07:22,840 --> 00:07:27,080
we try to interpret the data we try to

199
00:07:24,280 --> 00:07:28,879
develop models from that data and it's

200
00:07:27,080 --> 00:07:31,759
not a lot more complex than that and I

201
00:07:28,879 --> 00:07:33,840
would argue that we do that now and a

202
00:07:31,759 --> 00:07:35,800
lot of what I spend time working with

203
00:07:33,840 --> 00:07:37,360
companies about is like listen you're

204
00:07:35,800 --> 00:07:38,960
already doing AI machine learning you

205
00:07:37,360 --> 00:07:41,160
may not call it that you may call it

206
00:07:38,960 --> 00:07:43,479
things like real-time process control

207
00:07:41,160 --> 00:07:46,280
you may call it statistical process

208
00:07:43,479 --> 00:07:49,680
control and that's often a good place to

209
00:07:46,280 --> 00:07:51,879
start in demystifying within your

210
00:07:49,680 --> 00:07:54,039
organization bringing people along on

211
00:07:51,879 --> 00:07:56,639
the journey say listen AI is not this

212
00:07:54,039 --> 00:07:59,759
phenomenal new thing that is something

213
00:07:56,639 --> 00:08:01,039
we haven't been doing we do real time

214
00:07:59,759 --> 00:08:03,599
feedback control with Fe feedback

215
00:08:01,039 --> 00:08:06,440
control often you'll have a model a twin

216
00:08:03,599 --> 00:08:09,879
of a process and you're measuring

217
00:08:06,440 --> 00:08:11,840
temperature time your rate heat and

218
00:08:09,879 --> 00:08:14,280
you're trying to maintain a certain

219
00:08:11,840 --> 00:08:16,199
temperature over time or or rate of

220
00:08:14,280 --> 00:08:17,759
deposition over time and I have a

221
00:08:16,199 --> 00:08:19,080
controller typically a PID a

222
00:08:17,759 --> 00:08:21,360
proportional integral derivative

223
00:08:19,080 --> 00:08:23,720
controller that monitors that process

224
00:08:21,360 --> 00:08:25,159
and tells the Machinery go faster put

225
00:08:23,720 --> 00:08:26,919
more current into that motor to go

226
00:08:25,159 --> 00:08:30,360
faster or increase the amount of heat

227
00:08:26,919 --> 00:08:32,959
drill faster to try to Main main a set

228
00:08:30,360 --> 00:08:35,760
point and then typically after we do

229
00:08:32,959 --> 00:08:37,240
that real time control shown on the left

230
00:08:35,760 --> 00:08:39,599
there is this

231
00:08:37,240 --> 00:08:41,880
divide where we say okay great after

232
00:08:39,599 --> 00:08:44,440
things are using a real-time controller

233
00:08:41,880 --> 00:08:47,519
to deal with arguably deterministic

234
00:08:44,440 --> 00:08:49,839
sources of variation we then ask the

235
00:08:47,519 --> 00:08:52,519
question well is the process in control

236
00:08:49,839 --> 00:08:54,279
from a statistical perspective and what

237
00:08:52,519 --> 00:08:56,560
does it mean to be within control from a

238
00:08:54,279 --> 00:08:59,440
statistical perspective that means that

239
00:08:56,560 --> 00:09:01,320
the variation that remains after you

240
00:08:59,440 --> 00:09:02,720
you've done this after you've used the

241
00:09:01,320 --> 00:09:04,160
best physics models and you have a

242
00:09:02,720 --> 00:09:07,680
real-time controller trying to maintain

243
00:09:04,160 --> 00:09:10,000
a rate a temperature it's like okay well

244
00:09:07,680 --> 00:09:11,360
now what is the normal VAR we're never

245
00:09:10,000 --> 00:09:13,399
going to get rid of all variation

246
00:09:11,360 --> 00:09:14,760
variation is going to happen but what it

247
00:09:13,399 --> 00:09:16,720
means to be in control from a

248
00:09:14,760 --> 00:09:19,839
statistical perspective is like is the

249
00:09:16,720 --> 00:09:22,240
mean value sort of stable is the

250
00:09:19,839 --> 00:09:24,519
variance stable is it drifting off over

251
00:09:22,240 --> 00:09:26,519
time is the mean shifting and if either

252
00:09:24,519 --> 00:09:28,480
of those two questions are yes then

253
00:09:26,519 --> 00:09:30,920
you're not in control from a statistical

254
00:09:28,480 --> 00:09:32,680
perspective and then somebody crosses

255
00:09:30,920 --> 00:09:35,000
this line back over here and figures out

256
00:09:32,680 --> 00:09:36,760
well deterministic source of error what

257
00:09:35,000 --> 00:09:39,079
is it is it is it raw material variation

258
00:09:36,760 --> 00:09:42,399
is it operator variation and we sort of

259
00:09:39,079 --> 00:09:43,959
ping-pong back and forth generally now

260
00:09:42,399 --> 00:09:48,399
in sort of these two ways of thinking

261
00:09:43,959 --> 00:09:50,079
about control so this is we we are this

262
00:09:48,399 --> 00:09:51,640
is Big Data the statistical process

263
00:09:50,079 --> 00:09:53,120
control it's big data where we assume

264
00:09:51,640 --> 00:09:54,399
the world is normal we assume the world

265
00:09:53,120 --> 00:09:56,760
is a bell curve and we're looking for

266
00:09:54,399 --> 00:09:57,959
deviations from that bell curve and the

267
00:09:56,760 --> 00:10:00,079
things that we're doing here we're using

268
00:09:57,959 --> 00:10:03,120
models we're using digital twins to

269
00:10:00,079 --> 00:10:04,600
predict so one of the opportunities not

270
00:10:03,120 --> 00:10:07,839
the only opportunity one of the

271
00:10:04,600 --> 00:10:09,680
opportunities in how you can accelerate

272
00:10:07,839 --> 00:10:12,120
the rate of awareness and appreciation

273
00:10:09,680 --> 00:10:13,720
for what machine learning is it is

274
00:10:12,120 --> 00:10:15,600
contextualizing it within your

275
00:10:13,720 --> 00:10:17,640
organization say hey we do realtime

276
00:10:15,600 --> 00:10:19,800
feedback control we do statistical

277
00:10:17,640 --> 00:10:21,920
process control one of the opportunities

278
00:10:19,800 --> 00:10:23,440
is to sort of do these better and one of

279
00:10:21,920 --> 00:10:25,720
the opportunities is to break down the

280
00:10:23,440 --> 00:10:27,560
wall between these two things and and

281
00:10:25,720 --> 00:10:30,480
allow the big data that we're collecting

282
00:10:27,560 --> 00:10:33,000
over long-term Trend to actually

283
00:10:30,480 --> 00:10:34,880
automatically cross this divide instead

284
00:10:33,000 --> 00:10:37,480
of having a person try to go tweak and

285
00:10:34,880 --> 00:10:39,279
adjust a model have automatic knowledge

286
00:10:37,480 --> 00:10:42,040
that's propagating back over here to the

287
00:10:39,279 --> 00:10:45,880
models that we're using to control our

288
00:10:42,040 --> 00:10:48,120
process so I want to use some three case

289
00:10:45,880 --> 00:10:49,760
studies with increasing complexity a I'm

290
00:10:48,120 --> 00:10:51,680
going to give you a test or a couple

291
00:10:49,760 --> 00:10:53,519
different tests see how well you

292
00:10:51,680 --> 00:10:55,360
understand your machine learning tools

293
00:10:53,519 --> 00:10:59,399
um and and try again to say listen you

294
00:10:55,360 --> 00:11:01,440
can do a lot with some very simple tools

295
00:10:59,399 --> 00:11:03,000
so first case example and this is a

296
00:11:01,440 --> 00:11:05,240
project that we did with

297
00:11:03,000 --> 00:11:07,680
tetrapack um making packaging material

298
00:11:05,240 --> 00:11:11,399
your milk containers what have you um a

299
00:11:07,680 --> 00:11:13,760
virtual wear sensor and sort of this is

300
00:11:11,399 --> 00:11:15,519
in this opportunity exposing the iot

301
00:11:13,760 --> 00:11:18,480
meaning exposing the real-time data that

302
00:11:15,519 --> 00:11:22,000
we have to do something a little bit

303
00:11:18,480 --> 00:11:23,320
different before I do that and see I'm

304
00:11:22,000 --> 00:11:25,079
as I don't have my slides in front of me

305
00:11:23,320 --> 00:11:27,240
I have to figure

306
00:11:25,079 --> 00:11:31,079
out this is the Machinery that we're

307
00:11:27,240 --> 00:11:33,920
going to talk about before I get there I

308
00:11:31,079 --> 00:11:35,839
want to go and talk about a very simple

309
00:11:33,920 --> 00:11:39,959
example to motivate something that's

310
00:11:35,839 --> 00:11:43,600
called a decision tree anybody heard of

311
00:11:39,959 --> 00:11:46,079
a decision tree okay anybody be able to

312
00:11:43,600 --> 00:11:49,000
explain to your direct reports or to

313
00:11:46,079 --> 00:11:52,760
your supervisor how a decision tree

314
00:11:49,000 --> 00:11:55,360
works you know some some okay maybe okay

315
00:11:52,760 --> 00:11:57,440
but a decision tree is is is basically

316
00:11:55,360 --> 00:12:00,200
it's a bunch of questions right decision

317
00:11:57,440 --> 00:12:02,240
tree is looking at our data and in some

318
00:12:00,200 --> 00:12:04,440
way looking at our data and figuring out

319
00:12:02,240 --> 00:12:08,079
well where what are the information Rich

320
00:12:04,440 --> 00:12:10,160
questions that we can ask of our data

321
00:12:08,079 --> 00:12:12,079
and that's a key key point so the the

322
00:12:10,160 --> 00:12:15,760
the sort of the Insight with this thing

323
00:12:12,079 --> 00:12:19,360
called a decision tree is it's trained

324
00:12:15,760 --> 00:12:21,440
by quantifying the information content

325
00:12:19,360 --> 00:12:24,240
how if I if I look at something that

326
00:12:21,440 --> 00:12:26,959
happens very rarely and I get that event

327
00:12:24,240 --> 00:12:28,440
I'm surprised if I if I tell you that

328
00:12:26,959 --> 00:12:29,720
the sun is going to come up tomorrow

329
00:12:28,440 --> 00:12:31,639
you're not very surpised Ur I didn't

330
00:12:29,720 --> 00:12:33,519
give you much information but if I tell

331
00:12:31,639 --> 00:12:35,680
you with 100% certainty that I know the

332
00:12:33,519 --> 00:12:37,399
sun's not coming up tomorrow a you

333
00:12:35,680 --> 00:12:38,760
wouldn't believe me but if it were true

334
00:12:37,399 --> 00:12:40,240
that's that you're really surprised

335
00:12:38,760 --> 00:12:42,320
there's a lot of information that I've

336
00:12:40,240 --> 00:12:43,959
conveyed to you and telling you that

337
00:12:42,320 --> 00:12:45,480
that answer to the question you didn't

338
00:12:43,959 --> 00:12:48,240
ask but if you ask me the sun came up

339
00:12:45,480 --> 00:12:50,399
and I said no okay you're surprised so I

340
00:12:48,240 --> 00:12:53,519
want to quantify that notion of

341
00:12:50,399 --> 00:12:55,560
surprise so here pretend to sort of

342
00:12:53,519 --> 00:12:58,560
frame this pretend that these 10 data

343
00:12:55,560 --> 00:13:00,360
points are big data so it's it's 10 data

344
00:12:58,560 --> 00:13:02,880
point data but it's big data or it's a

345
00:13:00,360 --> 00:13:04,519
data set and the other problem the other

346
00:13:02,880 --> 00:13:06,440
opportunity SL challenge in

347
00:13:04,519 --> 00:13:07,720
manufacturing is often you don't have

348
00:13:06,440 --> 00:13:09,959
big data sometimes you really just do

349
00:13:07,720 --> 00:13:11,639
have small data and sort of context is

350
00:13:09,959 --> 00:13:13,399
important to sort of make best use of

351
00:13:11,639 --> 00:13:15,839
that small data but here let's just

352
00:13:13,399 --> 00:13:19,040
pretend it's big data or big enough data

353
00:13:15,839 --> 00:13:21,360
and this is data that comes from a a um

354
00:13:19,040 --> 00:13:23,880
a printing operation printing a flexible

355
00:13:21,360 --> 00:13:25,600
circuit board and we have two different

356
00:13:23,880 --> 00:13:28,160
types of machines machine H and machine

357
00:13:25,600 --> 00:13:29,959
a three different bat sizes the machine

358
00:13:28,160 --> 00:13:31,560
can be autof fed or not

359
00:13:29,959 --> 00:13:33,079
it can be lined in different ways

360
00:13:31,560 --> 00:13:35,720
different speeds and we as the

361
00:13:33,079 --> 00:13:38,560
manufacturing experts have decided that

362
00:13:35,720 --> 00:13:41,519
we'd like one of these observations we

363
00:13:38,560 --> 00:13:43,720
like a configuration where we get 95%

364
00:13:41,519 --> 00:13:47,240
yield or higher so we say hey we're

365
00:13:43,720 --> 00:13:50,160
going to flag this thing our our

366
00:13:47,240 --> 00:13:51,880
human supervised learning our human

367
00:13:50,160 --> 00:13:54,120
information is telling us like okay we

368
00:13:51,880 --> 00:13:56,000
we're going to label these data good bad

369
00:13:54,120 --> 00:13:59,240
past fail based on what we want to

370
00:13:56,000 --> 00:14:01,360
achieve in terms of a 95% yield on the

371
00:13:59,240 --> 00:14:03,759
configuration of this machine so we have

372
00:14:01,360 --> 00:14:07,600
some of these configurations that have

373
00:14:03,759 --> 00:14:09,560
over 95% yield as a pass and some not

374
00:14:07,600 --> 00:14:11,800
and a very reasonable thing to do is

375
00:14:09,560 --> 00:14:15,000
like well given this past given this

376
00:14:11,800 --> 00:14:16,880
history we've designed a new product and

377
00:14:15,000 --> 00:14:19,360
the designers of said product would like

378
00:14:16,880 --> 00:14:22,320
to use this configuration a very

379
00:14:19,360 --> 00:14:24,560
reasonable question to ask is well given

380
00:14:22,320 --> 00:14:26,920
this configuration what is our

381
00:14:24,560 --> 00:14:28,560
expectation of success meaning do we

382
00:14:26,920 --> 00:14:31,199
expect that we're going to get 95% yield

383
00:14:28,560 --> 00:14:32,759
or higher or not now this particular

384
00:14:31,199 --> 00:14:35,880
thing this particular configuration does

385
00:14:32,759 --> 00:14:37,639
not sit in our big data it it may and it

386
00:14:35,880 --> 00:14:39,920
may you may have multiple observations

387
00:14:37,639 --> 00:14:42,360
but pretend again this is a sort of a a

388
00:14:39,920 --> 00:14:44,320
toy problem to motivate a

389
00:14:42,360 --> 00:14:46,600
tool that's a question that we would

390
00:14:44,320 --> 00:14:48,959
like to ask put in the X Vector the

391
00:14:46,600 --> 00:14:52,240
machine bat size autof fed no Center

392
00:14:48,959 --> 00:14:54,360
alignment fast and say does our model

393
00:14:52,240 --> 00:14:58,240
tell us does it model predict they're

394
00:14:54,360 --> 00:15:00,480
going to get 95% yield or higher so here

395
00:14:58,240 --> 00:15:03,880
in one slide I'm just going to

396
00:15:00,480 --> 00:15:06,000
explain what r or mat lab or python

397
00:15:03,880 --> 00:15:07,959
would do for you if you gave it this

398
00:15:06,000 --> 00:15:10,839
data and said hey give me this

399
00:15:07,959 --> 00:15:14,000
interpretable AI tool give me a decision

400
00:15:10,839 --> 00:15:16,880
tree that's going to help me make a

401
00:15:14,000 --> 00:15:19,320
classifier that predicts passor fail

402
00:15:16,880 --> 00:15:21,680
based on my historical data and it

403
00:15:19,320 --> 00:15:23,880
hinges at the bottom on this idea that

404
00:15:21,680 --> 00:15:24,959
I'm I'm sorting my data in Excel just to

405
00:15:23,880 --> 00:15:27,639
show you show you what's going on but

406
00:15:24,959 --> 00:15:30,160
I'm sorting this data based on the idea

407
00:15:27,639 --> 00:15:31,720
that I can quantify information

408
00:15:30,160 --> 00:15:33,800
and just happens mathematically and

409
00:15:31,720 --> 00:15:35,759
there's a lot of theory around sort of

410
00:15:33,800 --> 00:15:37,720
why this sort of mathematical expression

411
00:15:35,759 --> 00:15:40,560
of the amount of information in a

412
00:15:37,720 --> 00:15:42,319
question is negative log base 2 of the

413
00:15:40,560 --> 00:15:44,079
probability of an answer right what that

414
00:15:42,319 --> 00:15:47,079
means is if it's a very surprising

415
00:15:44,079 --> 00:15:48,480
answer the amount of information is high

416
00:15:47,079 --> 00:15:50,680
if it's not a surprising answer the

417
00:15:48,480 --> 00:15:52,360
amount of information is low and the way

418
00:15:50,680 --> 00:15:55,079
that we can

419
00:15:52,360 --> 00:15:56,519
determine the probability of something

420
00:15:55,079 --> 00:15:58,519
is well let's look at all the data we

421
00:15:56,519 --> 00:16:00,720
collected look at the statistics of the

422
00:15:58,519 --> 00:16:02,759
data look at the statistics of well how

423
00:16:00,720 --> 00:16:05,800
much did batch size matter how much did

424
00:16:02,759 --> 00:16:07,639
auto feed matter and so here let's see

425
00:16:05,800 --> 00:16:09,600
if they get the laser pointer here we go

426
00:16:07,639 --> 00:16:12,160
here I've sorted the data at the top and

427
00:16:09,600 --> 00:16:14,759
I apologize as an ey chart but I've

428
00:16:12,160 --> 00:16:17,600
sorted my data on batch size and why is

429
00:16:14,759 --> 00:16:20,600
that an information Rich question well

430
00:16:17,600 --> 00:16:23,120
here you'll notice that every single

431
00:16:20,600 --> 00:16:25,720
time it's only three times but it's big

432
00:16:23,120 --> 00:16:29,079
data pretend every single time that it's

433
00:16:25,720 --> 00:16:31,319
500 or 900 it fails do that tell tells

434
00:16:29,079 --> 00:16:34,199
me a lot say hey if it's 500 or

435
00:16:31,319 --> 00:16:36,440
900 yeah it's not going to work and if

436
00:16:34,199 --> 00:16:39,079
it's 700 well sometimes it passes

437
00:16:36,440 --> 00:16:42,040
sometimes it fails so a very information

438
00:16:39,079 --> 00:16:44,079
Rich question to ask and answer is let's

439
00:16:42,040 --> 00:16:45,519
first ask a question about batch size

440
00:16:44,079 --> 00:16:49,079
I'm G to ask a question about batch size

441
00:16:45,519 --> 00:16:50,560
if it's 500 900 my series of questions

442
00:16:49,079 --> 00:16:53,720
are right off the bat going to tell me

443
00:16:50,560 --> 00:16:55,160
500 900 it's a fail and if it's 700 it's

444
00:16:53,720 --> 00:16:58,000
a little more nuanced than that I need

445
00:16:55,160 --> 00:17:00,600
to ask another question so there on the

446
00:16:58,000 --> 00:17:03,720
next table of pulled out just the 700

447
00:17:00,600 --> 00:17:06,160
data and I've sorted it now on machine

448
00:17:03,720 --> 00:17:08,000
every time that it's machine a it passes

449
00:17:06,160 --> 00:17:10,880
every time that it's machine H well

450
00:17:08,000 --> 00:17:14,559
sometimes it passes sometimes it

451
00:17:10,880 --> 00:17:17,880
fails and we go on so this now a

452
00:17:14,559 --> 00:17:20,039
decision Tre as a tool is often the very

453
00:17:17,880 --> 00:17:23,039
first thing if you know no other tool to

454
00:17:20,039 --> 00:17:25,039
use it's the first out of the boox thing

455
00:17:23,039 --> 00:17:26,839
hey let's try it because I can

456
00:17:25,039 --> 00:17:28,679
understand say hey it's a series of

457
00:17:26,839 --> 00:17:31,480
questions this sort of this complex set

458
00:17:28,679 --> 00:17:33,400
of data I I quantify information in this

459
00:17:31,480 --> 00:17:35,440
way but the result is a series of

460
00:17:33,400 --> 00:17:37,240
questions it's like paying playing 20

461
00:17:35,440 --> 00:17:39,480
questions with your kid and you want to

462
00:17:37,240 --> 00:17:40,880
guess the thing that's on your head um

463
00:17:39,480 --> 00:17:42,039
you want to ask information Rich

464
00:17:40,880 --> 00:17:44,600
questions to be able to figure it out

465
00:17:42,039 --> 00:17:48,559
with the fewest number of questions that

466
00:17:44,600 --> 00:17:49,960
you can and so this is now an easy to

467
00:17:48,559 --> 00:17:51,679
understand easy to interpret thing it

468
00:17:49,960 --> 00:17:53,600
has limitations right but it's a great

469
00:17:51,679 --> 00:17:56,600
way to get started say is there some

470
00:17:53,600 --> 00:17:59,280
signal in the data can I sort of get a

471
00:17:56,600 --> 00:18:00,640
first Baseline prediction of the thing

472
00:17:59,280 --> 00:18:02,919
that I want to know which is in this

473
00:18:00,640 --> 00:18:06,159
case is well am I going to get over 95%

474
00:18:02,919 --> 00:18:07,679
yield or not so now that is all I'm

475
00:18:06,159 --> 00:18:10,120
going to tell you about a decision Tree

476
00:18:07,679 --> 00:18:12,520
in practice you'll actually not just use

477
00:18:10,120 --> 00:18:14,039
a tree but you'll use a forest what's a

478
00:18:12,520 --> 00:18:16,039
forest a forest is a bunch of trees

479
00:18:14,039 --> 00:18:18,919
trained in slightly randomized ways to

480
00:18:16,039 --> 00:18:19,960
make it more use an on Ensemble which is

481
00:18:18,919 --> 00:18:22,039
he just a bunch of different trees

482
00:18:19,960 --> 00:18:23,400
working together we'd like adding all

483
00:18:22,039 --> 00:18:26,640
these new complex words to things that

484
00:18:23,400 --> 00:18:29,360
are just quite intuitive um so here's

485
00:18:26,640 --> 00:18:30,880
the tool now

486
00:18:29,360 --> 00:18:33,120
now we're going to turn our our

487
00:18:30,880 --> 00:18:36,760
engineering and our sort of production

488
00:18:33,120 --> 00:18:39,440
hats on for a bit so we want to apply

489
00:18:36,760 --> 00:18:40,760
that tool to this case where now we have

490
00:18:39,440 --> 00:18:43,679
a packaging

491
00:18:40,760 --> 00:18:46,840
system and this packaging system takes

492
00:18:43,679 --> 00:18:49,799
as input on a conveyor belt bottles in

493
00:18:46,840 --> 00:18:51,679
six packs 12 packs nine packs and wraps

494
00:18:49,799 --> 00:18:53,720
them with a piece of plastic cuts the

495
00:18:51,679 --> 00:18:55,080
plastic shrink wraps the plastic and

496
00:18:53,720 --> 00:18:57,440
pushes the bottle

497
00:18:55,080 --> 00:18:59,400
along and the question on the table is

498
00:18:57,440 --> 00:19:02,280
like well okay we have

499
00:18:59,400 --> 00:19:04,400
all of these data that is the real-time

500
00:19:02,280 --> 00:19:06,559
Control Data coming from every package

501
00:19:04,400 --> 00:19:10,200
that goes through so this data is the

502
00:19:06,559 --> 00:19:12,799
torque versus time of the blade of the

503
00:19:10,200 --> 00:19:14,200
of the um motor that's controlling the

504
00:19:12,799 --> 00:19:17,919
the knife edge that's cutting the Saran

505
00:19:14,200 --> 00:19:20,280
Wrap we have positions oops we have

506
00:19:17,919 --> 00:19:22,400
positions and accelerations of the Saran

507
00:19:20,280 --> 00:19:25,600
of the plastic wrap of the blade of the

508
00:19:22,400 --> 00:19:27,400
material and this is for one package

509
00:19:25,600 --> 00:19:28,760
going through this is time series data

510
00:19:27,400 --> 00:19:30,760
for one package as it passes through

511
00:19:28,760 --> 00:19:32,320
through so we have the time series data

512
00:19:30,760 --> 00:19:34,200
and then over here we have just the

513
00:19:32,320 --> 00:19:36,520
histogram of that time series

514
00:19:34,200 --> 00:19:38,440
data and the question is well I would

515
00:19:36,520 --> 00:19:40,200
like to I know any mechanical system

516
00:19:38,440 --> 00:19:42,919
whether it be a rotating piece of

517
00:19:40,200 --> 00:19:46,159
Machinery or not wears over time we lose

518
00:19:42,919 --> 00:19:48,440
lubrication bearings wear things wear

519
00:19:46,159 --> 00:19:51,080
mechanical things wear and I'd like to

520
00:19:48,440 --> 00:19:53,520
say I'd like to take these data without

521
00:19:51,080 --> 00:19:55,799
adding an additional sensor without

522
00:19:53,520 --> 00:19:58,120
adding anything any additional cost from

523
00:19:55,799 --> 00:19:59,200
a hardware perspective I would like to

524
00:19:58,120 --> 00:20:01,600
say

525
00:19:59,200 --> 00:20:03,600
using these data can I also predict the

526
00:20:01,600 --> 00:20:05,000
health of the machine like these are

527
00:20:03,600 --> 00:20:06,919
these are data that I'm getting that are

528
00:20:05,000 --> 00:20:09,000
just from the the operation of the the

529
00:20:06,919 --> 00:20:12,840
system the doing its job wrapping this

530
00:20:09,000 --> 00:20:14,440
plastic wrap but I would like to also

531
00:20:12,840 --> 00:20:16,880
take better use of this data to do some

532
00:20:14,440 --> 00:20:18,960
predictive maintenance are there

533
00:20:16,880 --> 00:20:21,600
signatures in this data that are going

534
00:20:18,960 --> 00:20:23,679
to start to tell me when the machine is

535
00:20:21,600 --> 00:20:25,280
changing right so what is a what is a

536
00:20:23,679 --> 00:20:27,720
real-time controller doing a real-time

537
00:20:25,280 --> 00:20:30,000
controller is compensating for the

538
00:20:27,720 --> 00:20:32,159
things that it can compens for if if

539
00:20:30,000 --> 00:20:33,960
material varies maybe I need to do

540
00:20:32,159 --> 00:20:35,840
something different if it's if if the

541
00:20:33,960 --> 00:20:37,480
material is off axis I need to shift it

542
00:20:35,840 --> 00:20:39,000
over a little bit so it's it's moving

543
00:20:37,480 --> 00:20:41,960
things around trying to compensate for

544
00:20:39,000 --> 00:20:44,320
the variation that naturally occurs so

545
00:20:41,960 --> 00:20:47,440
now if I have a system I want to take

546
00:20:44,320 --> 00:20:49,520
both my physics View and my data view so

547
00:20:47,440 --> 00:20:51,880
what your physics view this is the first

548
00:20:49,520 --> 00:20:55,360
question first test what's your physics

549
00:20:51,880 --> 00:20:57,760
view do I I have these data these types

550
00:20:55,360 --> 00:20:58,880
of data for hundreds and thousands of

551
00:20:57,760 --> 00:21:00,600
packages that go through through this

552
00:20:58,880 --> 00:21:02,840
production

553
00:21:00,600 --> 00:21:04,960
line is there

554
00:21:02,840 --> 00:21:08,039
information about the health of the

555
00:21:04,960 --> 00:21:11,360
machine about that's narrow it down

556
00:21:08,039 --> 00:21:13,440
about the the health of the blade that's

557
00:21:11,360 --> 00:21:15,520
cutting the plastic wrap is there

558
00:21:13,440 --> 00:21:17,840
something in this data that would tell

559
00:21:15,520 --> 00:21:21,400
me about the health of that

560
00:21:17,840 --> 00:21:24,080
blade I see some heads nodding yes what

561
00:21:21,400 --> 00:21:25,480
wh why why is are those head nods yes

562
00:21:24,080 --> 00:21:28,159
what's your physical intuition that

563
00:21:25,480 --> 00:21:30,440
tells you that this data that's coming

564
00:21:28,159 --> 00:21:32,000
from the automatic operation of moving

565
00:21:30,440 --> 00:21:35,080
things around cutting a piece of plastic

566
00:21:32,000 --> 00:21:37,799
wrap heating it why is there something

567
00:21:35,080 --> 00:21:40,720
physical about the machine embedded in

568
00:21:37,799 --> 00:21:43,039
these data anybody want to venture a

569
00:21:40,720 --> 00:21:43,039
brave

570
00:21:45,159 --> 00:21:50,600
answer so the controller is

571
00:21:48,120 --> 00:21:53,720
responding the torque okay so why why

572
00:21:50,600 --> 00:21:53,720
the torque

573
00:21:58,880 --> 00:22:02,919
okay so if I gave you a scissors and I

574
00:22:01,440 --> 00:22:05,799
asked you to cut a piece of

575
00:22:02,919 --> 00:22:07,840
paper if I give you a dull scissors

576
00:22:05,799 --> 00:22:09,600
versus a sharp scissors I'm going to

577
00:22:07,840 --> 00:22:11,400
need a lot less torque a lot less Force

578
00:22:09,600 --> 00:22:13,880
to cut the same thing with the sharp

579
00:22:11,400 --> 00:22:18,000
scissors so indeed if the blade that's

580
00:22:13,880 --> 00:22:20,080
attached to a motor is sharp and I apply

581
00:22:18,000 --> 00:22:21,320
a torque it's going to be less torque

582
00:22:20,080 --> 00:22:23,120
required and it may take a little bit

583
00:22:21,320 --> 00:22:26,760
longer but at least from sort of a

584
00:22:23,120 --> 00:22:28,720
baseline physical like domain expertise

585
00:22:26,760 --> 00:22:30,520
I expect some information about the

586
00:22:28,720 --> 00:22:31,840
machine to be embedded in this so that's

587
00:22:30,520 --> 00:22:33,919
sort of the starting point like yeah

588
00:22:31,840 --> 00:22:35,480
okay great I have a tool that can I can

589
00:22:33,919 --> 00:22:36,240
use as a regressor as a classifier I'm

590
00:22:35,480 --> 00:22:38,159
going to use this thing called a

591
00:22:36,240 --> 00:22:40,559
decision tree but don't even bother

592
00:22:38,159 --> 00:22:42,360
applying it unless you have some insight

593
00:22:40,559 --> 00:22:44,320
some contextual knowledge that says yeah

594
00:22:42,360 --> 00:22:46,320
I expect some type of success and here's

595
00:22:44,320 --> 00:22:49,039
where I expect some of the information

596
00:22:46,320 --> 00:22:50,840
to be embedded and indeed there's

597
00:22:49,039 --> 00:22:52,520
information embedded in everything here

598
00:22:50,840 --> 00:22:53,919
because it's it's a control system and

599
00:22:52,520 --> 00:22:55,880
everything's interconnected but at

600
00:22:53,919 --> 00:22:58,120
minimum you know the amount of torque

601
00:22:55,880 --> 00:22:59,960
should be revealing so now that being

602
00:22:58,120 --> 00:23:01,279
said great I can actually just take

603
00:22:59,960 --> 00:23:02,480
these data and there's a whole bunch of

604
00:23:01,279 --> 00:23:05,960
other stuff that you'll need to do it's

605
00:23:02,480 --> 00:23:07,640
like well what is my what's my input

606
00:23:05,960 --> 00:23:10,159
data what's my output prediction my

607
00:23:07,640 --> 00:23:12,600
input data could be like here are these

608
00:23:10,159 --> 00:23:14,919
all these time series data package 23

609
00:23:12,600 --> 00:23:17,720
comes through package 24 package 3,000

610
00:23:14,919 --> 00:23:20,679
comes through do I pass into my machine

611
00:23:17,720 --> 00:23:22,080
learning tool um all of these time

612
00:23:20,679 --> 00:23:25,279
series

613
00:23:22,080 --> 00:23:28,120
data maybe you could that's that would

614
00:23:25,279 --> 00:23:30,080
be a naive approach maybe I can do some

615
00:23:28,120 --> 00:23:32,080
feat engineering to give another fancy

616
00:23:30,080 --> 00:23:34,200
term to it I can do some pre-processing

617
00:23:32,080 --> 00:23:36,520
of my data and I can say well actually

618
00:23:34,200 --> 00:23:38,159
let's first just try for each package

619
00:23:36,520 --> 00:23:39,600
worth of data let's extract the mean and

620
00:23:38,159 --> 00:23:41,480
the standard deviation of all these time

621
00:23:39,600 --> 00:23:43,200
series or or maybe do a frequency

622
00:23:41,480 --> 00:23:44,600
analysis and say well where is most

623
00:23:43,200 --> 00:23:46,320
where is more of the energy in different

624
00:23:44,600 --> 00:23:48,159
frequency bands and do some of that

625
00:23:46,320 --> 00:23:50,840
feature engineering that pre-processing

626
00:23:48,159 --> 00:23:52,200
that us as the experts say hey let's

627
00:23:50,840 --> 00:23:54,000
help the machine learning tool to

628
00:23:52,200 --> 00:23:57,039
extract the things that we care about

629
00:23:54,000 --> 00:23:58,799
now if we do all that then we can indeed

630
00:23:57,039 --> 00:24:00,720
we can say hey I'm going to dump these

631
00:23:58,799 --> 00:24:03,279
data Maybe with some feature engineering

632
00:24:00,720 --> 00:24:05,279
dump it into python mat lab or R and I

633
00:24:03,279 --> 00:24:06,360
can indeed develop a set of questions

634
00:24:05,279 --> 00:24:08,000
they're going to take as input the

635
00:24:06,360 --> 00:24:10,159
speeds positions torque and tell me

636
00:24:08,000 --> 00:24:12,279
level of where and it would look

637
00:24:10,159 --> 00:24:15,039
something like this the the deals are

638
00:24:12,279 --> 00:24:17,440
not that important and if I were then to

639
00:24:15,039 --> 00:24:19,360
compare if I had split my data into

640
00:24:17,440 --> 00:24:21,159
training and validation you know sort of

641
00:24:19,360 --> 00:24:22,679
take my data like let's train on some of

642
00:24:21,159 --> 00:24:25,840
it and use some of it to see how well

643
00:24:22,679 --> 00:24:28,679
that our model is is working and we

644
00:24:25,840 --> 00:24:30,640
plotted the the residuals the errors on

645
00:24:28,679 --> 00:24:33,320
the things that we didn't use for our

646
00:24:30,640 --> 00:24:35,480
training a perfect model would say well

647
00:24:33,320 --> 00:24:36,760
the the error between what we predict

648
00:24:35,480 --> 00:24:38,399
and what we actually measured for the

649
00:24:36,760 --> 00:24:40,880
data that we didn't train on should be

650
00:24:38,399 --> 00:24:42,799
zero a perfect model says the level of

651
00:24:40,880 --> 00:24:44,600
of where in this case we're using a

652
00:24:42,799 --> 00:24:47,080
surrogate for where we're using the age

653
00:24:44,600 --> 00:24:49,640
of the blade but a perfect model would

654
00:24:47,080 --> 00:24:52,200
be the residuals the errors would be

655
00:24:49,640 --> 00:24:54,960
zeros we've developed a model that looks

656
00:24:52,200 --> 00:24:56,640
really really really bad potentially

657
00:24:54,960 --> 00:24:58,000
like we have there's a lot of zeros

658
00:24:56,640 --> 00:24:59,760
where the model is actually predicting

659
00:24:58,000 --> 00:25:01,240
what the reality is but we have

660
00:24:59,760 --> 00:25:03,279
situations where we're predicting the

661
00:25:01,240 --> 00:25:07,720
blade is actually 8 months older or 8

662
00:25:03,279 --> 00:25:11,080
months younger than it actually is do we

663
00:25:07,720 --> 00:25:13,000
care so here the axis the these this is

664
00:25:11,080 --> 00:25:16,399
sort of package

665
00:25:13,000 --> 00:25:17,919
number now this is a noisy sensor and

666
00:25:16,399 --> 00:25:20,880
what do you do with a noisy

667
00:25:17,919 --> 00:25:23,480
sensor you may filter it you may average

668
00:25:20,880 --> 00:25:26,799
I don't care for each package that comes

669
00:25:23,480 --> 00:25:28,880
through I don't need to predict well

670
00:25:26,799 --> 00:25:31,000
what's the apparent age of the blade for

671
00:25:28,880 --> 00:25:33,760
package number 24 package number 25

672
00:25:31,000 --> 00:25:36,120
package number 26 I care about a larger

673
00:25:33,760 --> 00:25:38,760
time scale is look at the like the last

674
00:25:36,120 --> 00:25:40,080
100 packages and I can sort of filter

675
00:25:38,760 --> 00:25:41,559
this data and from a physical

676
00:25:40,080 --> 00:25:44,039
perspective that makes sense you know my

677
00:25:41,559 --> 00:25:46,520
model can be really really really noisy

678
00:25:44,039 --> 00:25:48,080
for any one observation but when I

679
00:25:46,520 --> 00:25:49,799
filter it and average it over time at a

680
00:25:48,080 --> 00:25:52,919
time scale that makes sense for my

681
00:25:49,799 --> 00:25:55,000
context I can get down to sort of a a 2%

682
00:25:52,919 --> 00:25:58,080
error rate that I can predict within

683
00:25:55,000 --> 00:26:00,399
plus or minus a month how old this blade

684
00:25:58,080 --> 00:26:02,200
how much wear is apparent on this blade

685
00:26:00,399 --> 00:26:05,200
and use this now as a very simple

686
00:26:02,200 --> 00:26:08,039
without with minimal cost with just a

687
00:26:05,200 --> 00:26:09,880
little bit of physical insight and a

688
00:26:08,039 --> 00:26:12,640
machine learning tool that's painfully

689
00:26:09,880 --> 00:26:14,679
easy to use and painfully easy to train

690
00:26:12,640 --> 00:26:16,360
and get significant added value now in

691
00:26:14,679 --> 00:26:18,559
being able to do predictive and

692
00:26:16,360 --> 00:26:20,760
preventive maintenance and so this is

693
00:26:18,559 --> 00:26:22,000
sort of one project that is an example

694
00:26:20,760 --> 00:26:23,960
of some of the things you can do with

695
00:26:22,000 --> 00:26:25,559
just a little bit of that sort of you

696
00:26:23,960 --> 00:26:27,840
know not using a complex tool but with a

697
00:26:25,559 --> 00:26:31,240
little physical knowledge so now let's

698
00:26:27,840 --> 00:26:34,240
up the complexity a little bit um this

699
00:26:31,240 --> 00:26:37,080
is a project that we're working on with

700
00:26:34,240 --> 00:26:40,159
Nissan um and ultimately what they would

701
00:26:37,080 --> 00:26:42,880
like to do is improve the ability of

702
00:26:40,159 --> 00:26:44,880
their quality control of a new variable

703
00:26:42,880 --> 00:26:46,159
compression rate engine manufacturing

704
00:26:44,880 --> 00:26:47,720
these new engines they an internal

705
00:26:46,159 --> 00:26:49,840
combustion engine with a bunch of

706
00:26:47,720 --> 00:26:51,559
additional mechanical part parts to

707
00:26:49,840 --> 00:26:54,360
allow mechanical changing of the

708
00:26:51,559 --> 00:26:56,480
compression ratio and this is an example

709
00:26:54,360 --> 00:26:58,000
of we're sort of we're we're moving

710
00:26:56,480 --> 00:27:00,240
beyond sort of assuming the world is

711
00:26:58,000 --> 00:27:04,159
normal noral uh and sort of my my

712
00:27:00,240 --> 00:27:07,679
opportunities here um so

713
00:27:04,159 --> 00:27:10,360
first before I do that okay so a couple

714
00:27:07,679 --> 00:27:11,840
of you nodded your heads yes with

715
00:27:10,360 --> 00:27:13,559
explaining thinking that you could

716
00:27:11,840 --> 00:27:16,000
explain to your direct reports or to

717
00:27:13,559 --> 00:27:18,760
your supervisor to your family a

718
00:27:16,000 --> 00:27:23,000
decision tree who would like to explain

719
00:27:18,760 --> 00:27:23,000
to my seven-year-old how a neural net

720
00:27:24,679 --> 00:27:30,159
Works anybody want to try how would you

721
00:27:26,840 --> 00:27:30,159
explain a neural net

722
00:27:30,880 --> 00:27:35,840
works like a brain okay and I'm not sure

723
00:27:32,799 --> 00:27:38,880
my my seven-year-old doesn't understand

724
00:27:35,840 --> 00:27:41,240
that how how do what is what is a neural

725
00:27:38,880 --> 00:27:43,840
net what is it doing and I would argue

726
00:27:41,240 --> 00:27:46,960
that a great way to demystify a neural

727
00:27:43,840 --> 00:27:50,159
net is neural Nets and a lot of machine

728
00:27:46,960 --> 00:27:52,159
learning looks just like line fitting if

729
00:27:50,159 --> 00:27:54,120
you oversimplify a lot of supervised

730
00:27:52,159 --> 00:27:56,360
learning you we either going to classify

731
00:27:54,120 --> 00:27:57,919
something meaning past fail good bad

732
00:27:56,360 --> 00:27:59,080
which is what we did with the packaging

733
00:27:57,919 --> 00:28:03,159
or we're going to try to predict a

734
00:27:59,080 --> 00:28:05,919
continuous parameter not dissimilar from

735
00:28:03,159 --> 00:28:07,440
this toy data so what have I done here I

736
00:28:05,919 --> 00:28:10,440
have a bunch of data points the red

737
00:28:07,440 --> 00:28:11,519
things and I fit a digital twin okay

738
00:28:10,440 --> 00:28:12,880
maybe it's not a twin because I'm not

739
00:28:11,519 --> 00:28:15,039
continuously updating it but it's a

740
00:28:12,880 --> 00:28:16,720
model and I looked at this data say hey

741
00:28:15,039 --> 00:28:18,760
a line looks like the right thing maybe

742
00:28:16,720 --> 00:28:20,919
this data is coming from a spring and so

743
00:28:18,760 --> 00:28:23,039
I know there's a linear op relationship

744
00:28:20,919 --> 00:28:26,159
between stiffness and and Forest for

745
00:28:23,039 --> 00:28:28,360
example but I've decided as having the

746
00:28:26,159 --> 00:28:29,279
context domain knowledge that a a

747
00:28:28,360 --> 00:28:32,440
straight

748
00:28:29,279 --> 00:28:35,559
line is a reasonable model to use and I

749
00:28:32,440 --> 00:28:37,919
could go to Excel and I can say fit a

750
00:28:35,559 --> 00:28:40,360
line so I've done a couple really

751
00:28:37,919 --> 00:28:42,760
powerful things a I picked the model I I

752
00:28:40,360 --> 00:28:45,240
picked the mathematical structure I said

753
00:28:42,760 --> 00:28:47,720
hey for whatever reason whe whether it's

754
00:28:45,240 --> 00:28:49,480
I visualized the data or I had some good

755
00:28:47,720 --> 00:28:51,720
contextualized knowledge about it's a

756
00:28:49,480 --> 00:28:53,519
spring that I'm characterizing I picked

757
00:28:51,720 --> 00:28:55,840
something that is the right physical

758
00:28:53,519 --> 00:28:57,640
structure that mathematically can be

759
00:28:55,840 --> 00:28:59,600
described anybody remember the equation

760
00:28:57,640 --> 00:29:01,480
for

761
00:28:59,600 --> 00:29:03,880
yal MX plus b and that's it can be

762
00:29:01,480 --> 00:29:06,720
described by a slope and an intercept so

763
00:29:03,880 --> 00:29:08,840
the act of learning when I take this

764
00:29:06,720 --> 00:29:10,519
data and I fit it to the line like I

765
00:29:08,840 --> 00:29:13,320
picked the mathematical structure the

766
00:29:10,519 --> 00:29:16,000
learning activity is finding what is the

767
00:29:13,320 --> 00:29:18,919
optimal slope and what's the optimal

768
00:29:16,000 --> 00:29:21,120
intercept some notion of optimality to

769
00:29:18,919 --> 00:29:22,399
put this line through the data and it

770
00:29:21,120 --> 00:29:23,799
you know the human eye looks at this and

771
00:29:22,399 --> 00:29:26,519
say yeah that seems like a reasonable

772
00:29:23,799 --> 00:29:28,159
thing I didn't draw a line that went up

773
00:29:26,519 --> 00:29:30,080
like this I didn't draw a line that went

774
00:29:28,159 --> 00:29:31,679
like this I didn't draw one that sort of

775
00:29:30,080 --> 00:29:34,200
went this way either I picked in some

776
00:29:31,679 --> 00:29:37,080
way this

777
00:29:34,200 --> 00:29:40,200
line so I

778
00:29:37,080 --> 00:29:41,919
can here we go uh and I have these

779
00:29:40,200 --> 00:29:43,320
clouds here not to represent anything

780
00:29:41,919 --> 00:29:45,320
other than don't really pay attention to

781
00:29:43,320 --> 00:29:47,039
the details you can if you want it's

782
00:29:45,320 --> 00:29:48,960
here for completeness but I can write

783
00:29:47,039 --> 00:29:51,240
down first principles I can write down

784
00:29:48,960 --> 00:29:55,200
analytically given a bunch of data given

785
00:29:51,240 --> 00:29:56,640
my X and Y data points and given the

786
00:29:55,200 --> 00:29:59,200
thing that I want to determine which a

787
00:29:56,640 --> 00:30:01,600
slope in the intercept and given that

788
00:29:59,200 --> 00:30:02,480
okay I'm going to choose this a notion

789
00:30:01,600 --> 00:30:06,559
of

790
00:30:02,480 --> 00:30:08,000
optimality meaning I have the prediction

791
00:30:06,559 --> 00:30:10,399
for for some model that I haven't

792
00:30:08,000 --> 00:30:12,000
determined yet it's going to predict an

793
00:30:10,399 --> 00:30:14,279
output I'm going to compare that output

794
00:30:12,000 --> 00:30:15,600
to my measured output and I'm going to

795
00:30:14,279 --> 00:30:18,320
square those and I'm going to add them

796
00:30:15,600 --> 00:30:20,480
all up and I want to minimize that thing

797
00:30:18,320 --> 00:30:22,799
I'm going to say my my measure of

798
00:30:20,480 --> 00:30:25,840
optimality is I want to drive that sum

799
00:30:22,799 --> 00:30:28,480
of square error to zero as or get it as

800
00:30:25,840 --> 00:30:29,880
low as possible once I done that I'm

801
00:30:28,480 --> 00:30:32,120
going to go through calculus I'm going

802
00:30:29,880 --> 00:30:34,039
to set first derivatives equal to zero

803
00:30:32,120 --> 00:30:36,000
that you think back to calculus it's

804
00:30:34,039 --> 00:30:37,519
back there someplace right set you want

805
00:30:36,000 --> 00:30:39,240
to find you know what's the peak what's

806
00:30:37,519 --> 00:30:40,600
the valley of something find where the

807
00:30:39,240 --> 00:30:42,000
the derivatives are equal to zero

808
00:30:40,600 --> 00:30:44,799
confirm the second derivative is either

809
00:30:42,000 --> 00:30:46,200
a peak or a valley um but I can sort of

810
00:30:44,799 --> 00:30:48,480
go through a little bit of mathematics

811
00:30:46,200 --> 00:30:50,720
really relying on calculus and say well

812
00:30:48,480 --> 00:30:53,559
given my model that has that can be

813
00:30:50,720 --> 00:30:56,000
described by an A and A B given my data

814
00:30:53,559 --> 00:30:58,440
I can just write down what the optimal a

815
00:30:56,000 --> 00:31:00,600
and what the optimal B are

816
00:30:58,440 --> 00:31:02,559
based on my data my data are given

817
00:31:00,600 --> 00:31:04,080
they're fixed I'm trying to find the

818
00:31:02,559 --> 00:31:06,159
slope of the intercept and I can just

819
00:31:04,080 --> 00:31:10,039
tell you what they are given that this

820
00:31:06,159 --> 00:31:11,919
is my error metric so that's exactly

821
00:31:10,039 --> 00:31:15,880
what we do with a neuron

822
00:31:11,919 --> 00:31:17,799
net with a line we're trying to find for

823
00:31:15,880 --> 00:31:20,240
the mathematical structure described by

824
00:31:17,799 --> 00:31:22,519
a line and I can write it down easily Y

825
00:31:20,240 --> 00:31:24,600
is equal MX plus b I can find these

826
00:31:22,519 --> 00:31:28,799
parameters in a neural net it's a little

827
00:31:24,600 --> 00:31:30,600
bit more complex so a neural net

828
00:31:28,799 --> 00:31:33,360
has for

829
00:31:30,600 --> 00:31:36,360
example here's three neurons on the

830
00:31:33,360 --> 00:31:40,279
input layer here's one neuron on the

831
00:31:36,360 --> 00:31:42,279
output layer and what I'm doing

832
00:31:40,279 --> 00:31:43,880
graphically and typically a neuron net

833
00:31:42,279 --> 00:31:45,559
is just described by a bunch of circles

834
00:31:43,880 --> 00:31:48,240
with connections but what actually the

835
00:31:45,559 --> 00:31:50,320
mathematics under that is well I have in

836
00:31:48,240 --> 00:31:52,880
this situation an input Vector that has

837
00:31:50,320 --> 00:31:55,039
an X1 X2 and X3 so three

838
00:31:52,880 --> 00:31:58,039
parameters and it's I'm trying to

839
00:31:55,039 --> 00:31:59,840
predict some output y

840
00:31:58,039 --> 00:32:02,159
and this neuron what what does this

841
00:31:59,840 --> 00:32:05,320
neuron do this neuron takes parameter 1

842
00:32:02,159 --> 00:32:08,120
2 and three multiplies it by a weight

843
00:32:05,320 --> 00:32:10,720
weight one weight 2 weight three adds a

844
00:32:08,120 --> 00:32:11,760
a a a bias to it and then passes it

845
00:32:10,720 --> 00:32:13,679
through this thing that we call an

846
00:32:11,760 --> 00:32:15,279
activation function which is just a a

847
00:32:13,679 --> 00:32:18,279
function for which we have the

848
00:32:15,279 --> 00:32:20,519
mathematical equation and I do that for

849
00:32:18,279 --> 00:32:23,919
these three neurons I do that for this

850
00:32:20,519 --> 00:32:25,519
neuron and so for this neuron net I've

851
00:32:23,919 --> 00:32:27,000
picked a mathematical structure that I

852
00:32:25,519 --> 00:32:30,200
can write down I can't write it down as

853
00:32:27,000 --> 00:32:32,360
cleanly as = MX plus b but each thing

854
00:32:30,200 --> 00:32:35,360
here is like I have well this neuron has

855
00:32:32,360 --> 00:32:38,159
three parameters of Weights a bias I

856
00:32:35,360 --> 00:32:39,880
multiply my X by a weight X2 by a weight

857
00:32:38,159 --> 00:32:42,480
X3 by a weight and I do that for each

858
00:32:39,880 --> 00:32:44,399
neuron and so it's exactly like line

859
00:32:42,480 --> 00:32:45,480
fitting because now after I've done this

860
00:32:44,399 --> 00:32:47,880
all I'm going to do is I'm going to

861
00:32:45,480 --> 00:32:50,039
Define an error metric some a square

862
00:32:47,880 --> 00:32:51,960
error and I'm going to go through some

863
00:32:50,039 --> 00:32:55,120
calculus now the calculus I can't write

864
00:32:51,960 --> 00:32:57,120
down analytically anymore so I need to

865
00:32:55,120 --> 00:32:58,639
go to an optimization algorithm a

866
00:32:57,120 --> 00:33:00,360
training algorithm that's going to

867
00:32:58,639 --> 00:33:02,120
iteratively using something called

868
00:33:00,360 --> 00:33:05,120
gradient descent which really just means

869
00:33:02,120 --> 00:33:07,519
I'm going to iteratively apply calculus

870
00:33:05,120 --> 00:33:10,720
to figure out how to change my weights

871
00:33:07,519 --> 00:33:12,360
and biases iteratively slowly over time

872
00:33:10,720 --> 00:33:14,480
until I get to a point where I found

873
00:33:12,360 --> 00:33:17,960
weights and biases that are the best

874
00:33:14,480 --> 00:33:21,080
possible to make this mathematical

875
00:33:17,960 --> 00:33:23,639
structure the best that it can be in

876
00:33:21,080 --> 00:33:26,000
mapping my input to my output that I the

877
00:33:23,639 --> 00:33:28,000
data that I have but it's just like line

878
00:33:26,000 --> 00:33:30,240
fitting I can't write it down analytic

879
00:33:28,000 --> 00:33:32,000
anymore I need a and I have maybe a lot

880
00:33:30,240 --> 00:33:34,600
more data so I can't load all my data

881
00:33:32,000 --> 00:33:37,720
into memory but it's just like line

882
00:33:34,600 --> 00:33:39,440
fitting so given that now okay that's

883
00:33:37,720 --> 00:33:40,799
all you need to know today so hopefully

884
00:33:39,440 --> 00:33:42,880
you can explain to my seven-year-old

885
00:33:40,799 --> 00:33:44,320
that it's hey you can do it in Excel my

886
00:33:42,880 --> 00:33:46,000
seven-year-old can actually use Excel so

887
00:33:44,320 --> 00:33:48,360
maybe not every seven-year-old can

888
00:33:46,000 --> 00:33:52,080
Google Sheets actually um but you know

889
00:33:48,360 --> 00:33:54,919
so you can do neural Nets are just like

890
00:33:52,080 --> 00:33:56,679
lines so now given that now let's put

891
00:33:54,919 --> 00:33:58,559
this into the context of how we can use

892
00:33:56,679 --> 00:34:00,679
this tool now the wonderful sidebar

893
00:33:58,559 --> 00:34:03,480
interesting thing about neural Nets is

894
00:34:00,679 --> 00:34:06,159
that there's a very nice elegant sort of

895
00:34:03,480 --> 00:34:09,040
notion that a neural net neural Nets as

896
00:34:06,159 --> 00:34:11,079
a structure can be used to represent any

897
00:34:09,040 --> 00:34:13,000
function now the the sort of The

898
00:34:11,079 --> 00:34:15,320
iterative Secret Sauce the art of neural

899
00:34:13,000 --> 00:34:17,839
Nets saying yeah that particular neural

900
00:34:15,320 --> 00:34:20,200
net I picked three neurons here a neuron

901
00:34:17,839 --> 00:34:21,679
there I don't know how many neurons I

902
00:34:20,200 --> 00:34:23,119
need and what the activation functions

903
00:34:21,679 --> 00:34:24,760
are but a neuronet can be used to

904
00:34:23,119 --> 00:34:27,760
represent any mathematical function

905
00:34:24,760 --> 00:34:29,679
that's sort of the the power of them um

906
00:34:27,760 --> 00:34:31,040
so now okay what's the problem this the

907
00:34:29,679 --> 00:34:32,800
what's the manufacturing problem so here

908
00:34:31,040 --> 00:34:35,839
we have this variable compression rate

909
00:34:32,800 --> 00:34:37,679
engine and in this engine you know we

910
00:34:35,839 --> 00:34:39,280
won't I won't play the video now but it

911
00:34:37,679 --> 00:34:42,000
it mechanically sort of Alters the

912
00:34:39,280 --> 00:34:43,480
compression ratio um and in the

913
00:34:42,000 --> 00:34:45,679
manufacturer of this engine it goes

914
00:34:43,480 --> 00:34:49,000
through multiple

915
00:34:45,679 --> 00:34:52,879
stations and at each station a different

916
00:34:49,000 --> 00:34:55,320
mechanical member is bolted together uh

917
00:34:52,879 --> 00:34:58,640
it goes from station to one station

918
00:34:55,320 --> 00:35:02,000
two they may um take some Dimensions

919
00:34:58,640 --> 00:35:03,320
from the gaps of between a a part one

920
00:35:02,000 --> 00:35:04,839
and part two after it's been bolted

921
00:35:03,320 --> 00:35:06,680
together at each station so there a lot

922
00:35:04,839 --> 00:35:08,680
of data that comes from each station and

923
00:35:06,680 --> 00:35:10,119
we want to use this data want to

924
00:35:08,680 --> 00:35:12,280
describe I'll describe the data a little

925
00:35:10,119 --> 00:35:14,599
bit more we want to take the data that

926
00:35:12,280 --> 00:35:17,000
we have from assembly and given that

927
00:35:14,599 --> 00:35:19,960
this is a relatively new engine Nissan

928
00:35:17,000 --> 00:35:21,400
does a functional test of every engine

929
00:35:19,960 --> 00:35:24,560
and that functional test is very

930
00:35:21,400 --> 00:35:26,359
timeconsuming very costly and and very

931
00:35:24,560 --> 00:35:29,119
we'd like to get to a point where

932
00:35:26,359 --> 00:35:30,839
instead of doing all of the assembly

933
00:35:29,119 --> 00:35:33,480
operations which are never going to go

934
00:35:30,839 --> 00:35:35,200
away assembly is never going to go away

935
00:35:33,480 --> 00:35:37,160
can we start to reduce the amount of

936
00:35:35,200 --> 00:35:39,119
physical testing that we need to do to

937
00:35:37,160 --> 00:35:41,839
prevent a bad engine from exiting the

938
00:35:39,119 --> 00:35:43,560
factory so the question is can we

939
00:35:41,839 --> 00:35:45,480
develop a a

940
00:35:43,560 --> 00:35:46,680
model relying we're going to use a

941
00:35:45,480 --> 00:35:48,040
neural net to gave that away and we're

942
00:35:46,680 --> 00:35:51,079
going to use some physical intuition to

943
00:35:48,040 --> 00:35:53,920
sort of gather like do we expect success

944
00:35:51,079 --> 00:35:54,920
um can we develop a model that will map

945
00:35:53,920 --> 00:35:57,280
all these data that we're going to

946
00:35:54,920 --> 00:35:59,319
collect from assembly to some notion of

947
00:35:57,280 --> 00:36:01,880
the assem assembly or I'm sorry to some

948
00:35:59,319 --> 00:36:05,599
notion of the physical functional test

949
00:36:01,880 --> 00:36:09,079
so the data is on assembly we have the

950
00:36:05,599 --> 00:36:10,920
dimensions of all the parts we have all

951
00:36:09,079 --> 00:36:12,839
the torque versus time curves through

952
00:36:10,920 --> 00:36:15,359
all the 100 plus bolts that are used to

953
00:36:12,839 --> 00:36:17,880
assemble all these these parts together

954
00:36:15,359 --> 00:36:21,200
and then once the engine is assembled we

955
00:36:17,880 --> 00:36:23,000
then put the engine on a Shaker table

956
00:36:21,200 --> 00:36:24,520
and we put an accelerometer on the

957
00:36:23,000 --> 00:36:25,960
engine we shake the engine and we say

958
00:36:24,520 --> 00:36:28,200
well we just record the data like how

959
00:36:25,960 --> 00:36:30,280
much is the engine shaken shaking

960
00:36:28,200 --> 00:36:32,760
for the this while sitting on the table

961
00:36:30,280 --> 00:36:34,480
and we also will pressurize the engine

962
00:36:32,760 --> 00:36:36,480
and we'll ask the question we'll measure

963
00:36:34,480 --> 00:36:38,200
the amount of torque that's required to

964
00:36:36,480 --> 00:36:41,160
BL break static friction and then how

965
00:36:38,200 --> 00:36:43,200
much torque is required to keep the

966
00:36:41,160 --> 00:36:46,200
shaft moving after you've broken static

967
00:36:43,200 --> 00:36:47,680
friction and so the question is well do

968
00:36:46,200 --> 00:36:50,079
we

969
00:36:47,680 --> 00:36:53,240
expect if our data that we have on

970
00:36:50,079 --> 00:36:55,880
assembly is all these torqus versus time

971
00:36:53,240 --> 00:36:57,960
dimensions of all components dimensions

972
00:36:55,880 --> 00:37:00,319
of the gaps between a assembled

973
00:36:57,960 --> 00:37:03,240
components can we take all this assembly

974
00:37:00,319 --> 00:37:05,599
data and predict something about the

975
00:37:03,240 --> 00:37:07,480
functional test meaning how's the engine

976
00:37:05,599 --> 00:37:13,000
shake how does it vibrate when I shake

977
00:37:07,480 --> 00:37:15,240
it and how much torque does it withstand

978
00:37:13,000 --> 00:37:16,800
when it's been pressurized what's the

979
00:37:15,240 --> 00:37:18,000
physical do I have I know this is a

980
00:37:16,800 --> 00:37:19,839
little bit more complex than cutting a

981
00:37:18,000 --> 00:37:21,960
piece of plastic but is do I have a

982
00:37:19,839 --> 00:37:24,599
physical intuition for why I might

983
00:37:21,960 --> 00:37:25,880
expect success in being able to develop

984
00:37:24,599 --> 00:37:30,280
a

985
00:37:25,880 --> 00:37:32,880
model data pure at the moment that Maps

986
00:37:30,280 --> 00:37:36,520
as input all of the assembly data that I

987
00:37:32,880 --> 00:37:36,520
have to the functional

988
00:37:36,720 --> 00:37:41,920
test and now it's the end of the

989
00:37:39,119 --> 00:37:43,240
day well what happens if I don't bolt

990
00:37:41,920 --> 00:37:45,720
the engine very

991
00:37:43,240 --> 00:37:47,079
tightly it's going to shake a lot it's

992
00:37:45,720 --> 00:37:50,319
going to shake a lot differently than if

993
00:37:47,079 --> 00:37:52,720
I bolted it together well and what's

994
00:37:50,319 --> 00:37:55,160
going to happen if I have a big gap

995
00:37:52,720 --> 00:37:56,119
between the piston and the Piston wall

996
00:37:55,160 --> 00:37:57,520
it's not going to pressure it's not

997
00:37:56,119 --> 00:37:58,560
going to hold very much pressure and so

998
00:37:57,520 --> 00:38:00,280
it's not going to take much torque to

999
00:37:58,560 --> 00:38:02,119
break static friction and it's not going

1000
00:38:00,280 --> 00:38:05,000
to take much torque to keep it moving

1001
00:38:02,119 --> 00:38:06,560
right so at at base yeah hey if I if I

1002
00:38:05,000 --> 00:38:08,720
have big gaps in things it's not going

1003
00:38:06,560 --> 00:38:11,599
to pressurize if I don't bolt things

1004
00:38:08,720 --> 00:38:13,240
down very well how it shakes is going to

1005
00:38:11,599 --> 00:38:16,640
change so I I have some physical

1006
00:38:13,240 --> 00:38:20,480
intuition and so indeed if I do that I

1007
00:38:16,640 --> 00:38:23,079
can then with indeed some iteration

1008
00:38:20,480 --> 00:38:25,640
terms of the structure of the neural net

1009
00:38:23,079 --> 00:38:27,800
but it's a neural net Bunches of neurons

1010
00:38:25,640 --> 00:38:29,599
connected together and each neural n is

1011
00:38:27,800 --> 00:38:32,200
just a bunch of weights and biases and I

1012
00:38:29,599 --> 00:38:33,640
can take my data do line fitting and

1013
00:38:32,200 --> 00:38:36,599
find out what those weights and biases

1014
00:38:33,640 --> 00:38:39,319
are and indeed I can take all that data

1015
00:38:36,599 --> 00:38:42,079
from thousands of engines learn in your

1016
00:38:39,319 --> 00:38:44,680
own net learn the weights the slope and

1017
00:38:42,079 --> 00:38:47,440
The Intercept equivalent so I can map

1018
00:38:44,680 --> 00:38:49,640
assembly to test functional test and

1019
00:38:47,440 --> 00:38:50,680
here there are hundreds of dimensions in

1020
00:38:49,640 --> 00:38:53,040
this but here we're just showing for

1021
00:38:50,680 --> 00:38:55,839
example assembly generic assembly

1022
00:38:53,040 --> 00:38:57,599
parameter 1 generic assembly parameter 2

1023
00:38:55,839 --> 00:38:59,680
that predicts

1024
00:38:57,599 --> 00:39:03,160
the the colorful surface here is the

1025
00:38:59,680 --> 00:39:04,839
surface that the neural net mathematics

1026
00:39:03,160 --> 00:39:07,520
gives us after it's been trained

1027
00:39:04,839 --> 00:39:09,880
compared to the real data points in

1028
00:39:07,520 --> 00:39:11,640
blue and so the takeaway here is like

1029
00:39:09,880 --> 00:39:13,280
yeah indeed okay there is a Surface a

1030
00:39:11,640 --> 00:39:14,839
structure where this curve has gone

1031
00:39:13,280 --> 00:39:16,920
through my data in some appropriate way

1032
00:39:14,839 --> 00:39:18,920
so indeed I can take these data feed

1033
00:39:16,920 --> 00:39:21,000
them into a neural net and and develop

1034
00:39:18,920 --> 00:39:23,599
this mapping now if you're if you're

1035
00:39:21,000 --> 00:39:25,480
Nissan you don't yet trust the fact that

1036
00:39:23,599 --> 00:39:27,480
okay this is a relatively new technique

1037
00:39:25,480 --> 00:39:29,440
a relatively new approach and we're not

1038
00:39:27,480 --> 00:39:32,000
yet going to go from testing every

1039
00:39:29,440 --> 00:39:33,599
engine to testing no engines and we're

1040
00:39:32,000 --> 00:39:36,119
actually we're just going to still fully

1041
00:39:33,599 --> 00:39:39,160
test every single engine and so what

1042
00:39:36,119 --> 00:39:44,240
we're going to do is we're going to

1043
00:39:39,160 --> 00:39:46,040
indeed use our trained model take our

1044
00:39:44,240 --> 00:39:47,720
assembly data for a new engine predict

1045
00:39:46,040 --> 00:39:49,839
what the functional test would be

1046
00:39:47,720 --> 00:39:52,319
compare that functional test to the real

1047
00:39:49,839 --> 00:39:54,079
test that we still do and now we

1048
00:39:52,319 --> 00:39:56,319
actually have a quality signal that

1049
00:39:54,079 --> 00:39:58,440
we've been able to use to bin the

1050
00:39:56,319 --> 00:40:00,960
engines every engine passes but we're

1051
00:39:58,440 --> 00:40:04,079
able to we've demonstrated be able to

1052
00:40:00,960 --> 00:40:06,400
predict like these really good these

1053
00:40:04,079 --> 00:40:08,520
engines are good enough to pass but we

1054
00:40:06,400 --> 00:40:10,800
can now use these in a in a creative way

1055
00:40:08,520 --> 00:40:12,319
to help us get some additional Insight

1056
00:40:10,800 --> 00:40:14,960
um in terms of the quality of the

1057
00:40:12,319 --> 00:40:16,440
engines okay so um I'm assuming the

1058
00:40:14,960 --> 00:40:19,280
timer started when I actually started

1059
00:40:16,440 --> 00:40:20,359
talking as opposed to given all the the

1060
00:40:19,280 --> 00:40:22,200
sort of the rig roll that we went

1061
00:40:20,359 --> 00:40:24,400
through to get slides going but the the

1062
00:40:22,200 --> 00:40:25,839
last thing that I want to share with you

1063
00:40:24,400 --> 00:40:29,560
just to complete the

1064
00:40:25,839 --> 00:40:32,560
story is okay case one very simple easy

1065
00:40:29,560 --> 00:40:34,000
to understand easy to interpret tool

1066
00:40:32,560 --> 00:40:35,960
decision tree hey I can see what the

1067
00:40:34,000 --> 00:40:37,599
questions are neural net it's a little

1068
00:40:35,960 --> 00:40:39,200
harder to understand I don't know what

1069
00:40:37,599 --> 00:40:40,960
the weights and biases mean I just know

1070
00:40:39,200 --> 00:40:43,319
that they are what they are to give me a

1071
00:40:40,960 --> 00:40:47,040
result and I need to iteratively explore

1072
00:40:43,319 --> 00:40:50,520
them so here I I'll show just

1073
00:40:47,040 --> 00:40:52,640
briefly um a paper that has led to sort

1074
00:40:50,520 --> 00:40:53,960
of a lot of interesting conversations

1075
00:40:52,640 --> 00:40:55,280
with companies and a lot of interesting

1076
00:40:53,960 --> 00:40:59,440
research and a lot of interesting

1077
00:40:55,280 --> 00:41:02,839
deployments we first use this um a full

1078
00:40:59,440 --> 00:41:05,079
melding if you will of real time control

1079
00:41:02,839 --> 00:41:07,800
and statistical process

1080
00:41:05,079 --> 00:41:11,000
control in this thing that we give a new

1081
00:41:07,800 --> 00:41:13,560
name deep reinforcement learning so deep

1082
00:41:11,000 --> 00:41:16,800
reinforcement learning

1083
00:41:13,560 --> 00:41:18,599
is I'll skip to this slide right there

1084
00:41:16,800 --> 00:41:20,480
so this is a graphical representation of

1085
00:41:18,599 --> 00:41:22,880
the mathematics of this thing called

1086
00:41:20,480 --> 00:41:24,880
Deep reinforcement learning but I guess

1087
00:41:22,880 --> 00:41:26,880
the point that I want to make here is

1088
00:41:24,880 --> 00:41:30,720
through the lens of manufacturing if I

1089
00:41:26,880 --> 00:41:33,400
sort of break down this thing that is

1090
00:41:30,720 --> 00:41:35,960
simultaneously trying to control the

1091
00:41:33,400 --> 00:41:39,280
process of in this case fiber

1092
00:41:35,960 --> 00:41:42,119
Extrusion um and figure out how to do

1093
00:41:39,280 --> 00:41:43,800
the realtime adjustments to get 125

1094
00:41:42,119 --> 00:41:45,440
extruded Micron fiber which is the

1095
00:41:43,800 --> 00:41:47,920
backbone of our wireless communication

1096
00:41:45,440 --> 00:41:49,839
Network Glass fiber that's embedded

1097
00:41:47,920 --> 00:41:53,200
under the ground under the ocean every

1098
00:41:49,839 --> 00:41:56,640
place um and I want to

1099
00:41:53,200 --> 00:41:58,800
simultaneously do realtime control and

1100
00:41:56,640 --> 00:42:00,800
collect the historical data of what I'm

1101
00:41:58,800 --> 00:42:02,480
doing and passes through this thing

1102
00:42:00,800 --> 00:42:04,760
called an actor critic Network that's

1103
00:42:02,480 --> 00:42:06,560
not important what I'm really doing is

1104
00:42:04,760 --> 00:42:08,560
this is realtime control and this is

1105
00:42:06,560 --> 00:42:11,319
statistical process control in one

1106
00:42:08,560 --> 00:42:13,560
mathematical structure and so instead of

1107
00:42:11,319 --> 00:42:15,839
saying there's a wall between realtime

1108
00:42:13,560 --> 00:42:17,640
control and statistical process control

1109
00:42:15,839 --> 00:42:19,359
my mathematical structure is at

1110
00:42:17,640 --> 00:42:22,000
different time scales doing real-time

1111
00:42:19,359 --> 00:42:23,839
control here seeing what the long-term

1112
00:42:22,000 --> 00:42:26,200
trends are and based on those long-term

1113
00:42:23,839 --> 00:42:28,200
trends slowly updating the models that

1114
00:42:26,200 --> 00:42:30,839
we use for our field our real-time

1115
00:42:28,200 --> 00:42:32,200
control um so just showing that you know

1116
00:42:30,839 --> 00:42:34,079
that that piece looks like realtime

1117
00:42:32,200 --> 00:42:35,559
control that looks like a realtime

1118
00:42:34,079 --> 00:42:37,440
controller and all this other pieces

1119
00:42:35,559 --> 00:42:39,400
just the memory the thing that the

1120
00:42:37,440 --> 00:42:42,839
long-term data where we don't and we no

1121
00:42:39,400 --> 00:42:45,280
longer assume that it looks like normal

1122
00:42:42,839 --> 00:42:46,880
distribution and we no longer have a

1123
00:42:45,280 --> 00:42:48,960
somebody that needs to hey well we see

1124
00:42:46,880 --> 00:42:50,520
that our run charts are going off let's

1125
00:42:48,960 --> 00:42:52,720
figure out what was the deterministic

1126
00:42:50,520 --> 00:42:55,319
source of error that stuff happens

1127
00:42:52,720 --> 00:42:57,440
automatically now in all

1128
00:42:55,319 --> 00:42:58,960
honesty companies have been coming to me

1129
00:42:57,440 --> 00:43:00,359
say hey we saw this paper we'd like to

1130
00:42:58,960 --> 00:43:01,520
apply this to Coffee Roasting which

1131
00:43:00,359 --> 00:43:03,800
we've done we've applied this to

1132
00:43:01,520 --> 00:43:05,160
packaging but I'd say there have been 20

1133
00:43:03,800 --> 00:43:06,880
companies that have come to us and said

1134
00:43:05,160 --> 00:43:09,400
hey we think this is going to solve our

1135
00:43:06,880 --> 00:43:10,839
problem and six months to a year into

1136
00:43:09,400 --> 00:43:12,400
the Endeavor I say actually you know

1137
00:43:10,839 --> 00:43:14,640
what you don't need this you just need

1138
00:43:12,400 --> 00:43:17,200
to do better PID controllers you just

1139
00:43:14,640 --> 00:43:19,760
need actually your your your your your

1140
00:43:17,200 --> 00:43:21,200
sensor over here was not grounded uh the

1141
00:43:19,760 --> 00:43:24,559
data that we found the data that we're

1142
00:43:21,200 --> 00:43:27,440
using so like we of if if for no other

1143
00:43:24,559 --> 00:43:29,359
reason the advanced tools are driving

1144
00:43:27,440 --> 00:43:31,160
putting into place what best practice

1145
00:43:29,359 --> 00:43:33,680
should be with current tools that's a

1146
00:43:31,160 --> 00:43:35,079
plus that's a huge win right ignoring

1147
00:43:33,680 --> 00:43:38,119
sort of all the advanced things but the

1148
00:43:35,079 --> 00:43:39,680
advanced things AI still can be cast as

1149
00:43:38,119 --> 00:43:42,440
real-time control and statistical

1150
00:43:39,680 --> 00:43:44,240
process control um and I'll skip over

1151
00:43:42,440 --> 00:43:46,200
these in the in in the interest of time

1152
00:43:44,240 --> 00:43:48,079
I do want to end I'm going to skip over

1153
00:43:46,200 --> 00:43:50,720
that that we talked about data security

1154
00:43:48,079 --> 00:43:53,599
for a moment um I want to end with this

1155
00:43:50,720 --> 00:43:55,680
with a sort of a a a a please reach out

1156
00:43:53,599 --> 00:43:59,079
to me

1157
00:43:55,680 --> 00:44:01,440
um couple weeks ago um we talked a

1158
00:43:59,079 --> 00:44:02,640
little bit I think um Liz talked a

1159
00:44:01,440 --> 00:44:04,680
little bit about the manufacturing

1160
00:44:02,640 --> 00:44:08,359
institutes um there's things like aim

1161
00:44:04,680 --> 00:44:10,240
photonics NEX Flex uh MDX that are these

1162
00:44:08,359 --> 00:44:12,079
these fronhofer leg organizations in the

1163
00:44:10,240 --> 00:44:14,160
US that are intended to bridge the gap

1164
00:44:12,079 --> 00:44:16,040
between manufacturing innovations that

1165
00:44:14,160 --> 00:44:18,359
are happening both in universities and

1166
00:44:16,040 --> 00:44:19,599
companies in sort of the the at scale

1167
00:44:18,359 --> 00:44:22,000
Department of Commerce has been

1168
00:44:19,599 --> 00:44:24,720
competing two one the the semiconductor

1169
00:44:22,000 --> 00:44:27,480
digital twin one has been announced this

1170
00:44:24,720 --> 00:44:29,720
proposal is due in the end of January in

1171
00:44:27,480 --> 00:44:31,640
MIT there are three teams that I'm aware

1172
00:44:29,720 --> 00:44:33,480
of Nationwide and as a company you

1173
00:44:31,640 --> 00:44:34,720
should engage with I would love for you

1174
00:44:33,480 --> 00:44:36,520
to engage with our team but you should

1175
00:44:34,720 --> 00:44:37,920
engage with every team because one

1176
00:44:36,520 --> 00:44:38,920
team's going to win and everybody's

1177
00:44:37,920 --> 00:44:41,319
going to work with that team because

1178
00:44:38,920 --> 00:44:43,880
it's a national resource but the idea is

1179
00:44:41,319 --> 00:44:45,960
that these this will be an Institute

1180
00:44:43,880 --> 00:44:49,839
that has some some funds from the

1181
00:44:45,960 --> 00:44:52,920
government um to accelerate sort of

1182
00:44:49,839 --> 00:44:56,319
commercial use of said funds to try to

1183
00:44:52,920 --> 00:44:58,520
help to accelerate how we deploy AI in

1184
00:44:56,319 --> 00:45:00,520
small companies and big companies and

1185
00:44:58,520 --> 00:45:03,680
having both sort of pillars within how

1186
00:45:00,520 --> 00:45:05,520
we use AI in design in operations and

1187
00:45:03,680 --> 00:45:07,400
supply chain and then taking a

1188
00:45:05,520 --> 00:45:09,640
significant lead as well and well how do

1189
00:45:07,400 --> 00:45:11,960
we actually figure out the best ways to

1190
00:45:09,640 --> 00:45:15,319
train the workforce both the the

1191
00:45:11,960 --> 00:45:17,880
entrenched worker and the sort of upand

1192
00:45:15,319 --> 00:45:20,000
cominging worker and we're looking for

1193
00:45:17,880 --> 00:45:21,280
um partners with which to Pilot

1194
00:45:20,000 --> 00:45:23,520
companies that have data that would

1195
00:45:21,280 --> 00:45:25,440
they' be willing to share companies that

1196
00:45:23,520 --> 00:45:28,880
would be openly willing to engage in

1197
00:45:25,440 --> 00:45:30,680
co-investment to get this uh Institute

1198
00:45:28,880 --> 00:45:33,280
going forward so I'd love to if anybody

1199
00:45:30,680 --> 00:45:36,319
has an interest in learning more please

1200
00:45:33,280 --> 00:45:38,040
do reach out um we're feverishly as the

1201
00:45:36,319 --> 00:45:40,480
days been going by I've been feverishly

1202
00:45:38,040 --> 00:45:41,920
communicating with the team of multiple

1203
00:45:40,480 --> 00:45:44,599
universities multiple companies that are

1204
00:45:41,920 --> 00:45:47,200
putting this proposal together um so

1205
00:45:44,599 --> 00:45:49,000
it's an exciting opportunity um to sort

1206
00:45:47,200 --> 00:45:51,240
of bring together both Federal

1207
00:45:49,000 --> 00:45:52,920
investment uh and and Company investment

1208
00:45:51,240 --> 00:45:55,839
do really try to accelerate how we use

1209
00:45:52,920 --> 00:45:58,920
and teach and understand the use of AI

1210
00:45:55,839 --> 00:45:58,920
um in manufacturing


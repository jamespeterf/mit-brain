1
00:00:00,160 --> 00:00:06,080
Hi. Uh my name is Johannes. I'm the CEO

2
00:00:02,879 --> 00:00:08,400
and co-founder of Defraction. Um and at

3
00:00:06,080 --> 00:00:09,840
Defraction we do two things that will uh

4
00:00:08,400 --> 00:00:13,840
guide you through it. One, we see

5
00:00:09,840 --> 00:00:16,160
further and two we think faster.

6
00:00:13,840 --> 00:00:19,520
So the problem when you look at visual

7
00:00:16,160 --> 00:00:23,199
AI today um and you have a camera plus a

8
00:00:19,520 --> 00:00:25,760
sensor behind an processor is that um

9
00:00:23,199 --> 00:00:28,480
you have a couple limitations which um

10
00:00:25,760 --> 00:00:30,880
are necessary for things like if you

11
00:00:28,480 --> 00:00:33,520
operate in space or a high frequency

12
00:00:30,880 --> 00:00:36,399
manufacturing line. So one you have a

13
00:00:33,520 --> 00:00:38,399
limited resolution of your image which

14
00:00:36,399 --> 00:00:41,120
comes from the fact um that you lose

15
00:00:38,399 --> 00:00:43,680
information every time you process that

16
00:00:41,120 --> 00:00:46,160
information and secondly um you lose

17
00:00:43,680 --> 00:00:49,039
also time as you go from your camera

18
00:00:46,160 --> 00:00:50,960
sensor afterwards to your processor and

19
00:00:49,039 --> 00:00:52,559
then having to output some sort of

20
00:00:50,960 --> 00:00:54,719
intelligence for example what kind of

21
00:00:52,559 --> 00:00:56,399
bubble am I seeing or is this a

22
00:00:54,719 --> 00:00:59,680
satellite that I'm seeing up there or

23
00:00:56,399 --> 00:01:02,079
not. Our inspiration was the eye. So, if

24
00:00:59,680 --> 00:01:04,720
you've seen a sparrow catching a bug

25
00:01:02,079 --> 00:01:06,720
midair in flight, um it's a very

26
00:01:04,720 --> 00:01:09,760
impressive thing to do. And I was taught

27
00:01:06,720 --> 00:01:11,520
in high school that uh the eye actually

28
00:01:09,760 --> 00:01:13,920
is just a camera. But that's not true.

29
00:01:11,520 --> 00:01:16,320
An eye has some intelligence and can

30
00:01:13,920 --> 00:01:18,080
detect shapes and fastm moving things,

31
00:01:16,320 --> 00:01:20,320
trajectories, and that actually

32
00:01:18,080 --> 00:01:23,200
intelligence in the eye allows the

33
00:01:20,320 --> 00:01:24,720
sparrow to catch that fly moving very

34
00:01:23,200 --> 00:01:27,759
fast.

35
00:01:24,720 --> 00:01:29,759
Now taking this um we applied it to our

36
00:01:27,759 --> 00:01:32,960
visual sensing and processing unit and

37
00:01:29,759 --> 00:01:35,360
we built a better eye. Um now this one

38
00:01:32,960 --> 00:01:38,000
replaces the camera and a GPU. It's two

39
00:01:35,360 --> 00:01:40,560
in one. You can see further 20 times

40
00:01:38,000 --> 00:01:42,320
further than the defraction limit which

41
00:01:40,560 --> 00:01:43,759
I always explain with the last letter

42
00:01:42,320 --> 00:01:46,159
that you can see when you go to the

43
00:01:43,759 --> 00:01:47,920
optometrist like when it gets blurry.

44
00:01:46,159 --> 00:01:49,920
That's your defraction limit. We give

45
00:01:47,920 --> 00:01:53,040
you a 20 times better defraction limit

46
00:01:49,920 --> 00:01:55,360
than any camera can do today. And we can

47
00:01:53,040 --> 00:01:57,680
also think faster because the processor

48
00:01:55,360 --> 00:01:59,759
inside is photonic. We can think up to a

49
00:01:57,680 --> 00:02:01,119
thousand times faster and understand

50
00:01:59,759 --> 00:02:03,280
what we're looking at at a thousand

51
00:02:01,119 --> 00:02:06,719
times faster with a thousand times lower

52
00:02:03,280 --> 00:02:08,640
energy consumption. Why it works is that

53
00:02:06,719 --> 00:02:11,360
we developed this technology with my

54
00:02:08,640 --> 00:02:14,640
co-founder Sikad Kua. He's a professor

55
00:02:11,360 --> 00:02:17,840
at university at MIT and University of

56
00:02:14,640 --> 00:02:20,959
Maryland. He also did his PhD at MIT. Um

57
00:02:17,840 --> 00:02:22,879
I'm also an MIT grad and uh he in the

58
00:02:20,959 --> 00:02:25,120
last 10 years developed this TRL4

59
00:02:22,879 --> 00:02:27,760
exclusive use patent and tech uh with

60
00:02:25,120 --> 00:02:30,000
NASA and DARPA and the idea is that the

61
00:02:27,760 --> 00:02:31,840
scene coming through a lens is being

62
00:02:30,000 --> 00:02:34,640
defracted by different plates that are

63
00:02:31,840 --> 00:02:36,720
optimized based on our algorithm that we

64
00:02:34,640 --> 00:02:39,440
patented and gives us the maximum

65
00:02:36,720 --> 00:02:41,120
resolution by quantum mechanics. So on

66
00:02:39,440 --> 00:02:43,120
the right you can see a recent paper

67
00:02:41,120 --> 00:02:44,560
published where uh we reached this

68
00:02:43,120 --> 00:02:46,239
defraction limit which is the last

69
00:02:44,560 --> 00:02:48,560
letter you could see in this case on the

70
00:02:46,239 --> 00:02:50,640
left is a star on the right we could see

71
00:02:48,560 --> 00:02:52,800
actually that those were two stars and

72
00:02:50,640 --> 00:02:55,519
one was hiding 25 times further behind

73
00:02:52,800 --> 00:02:58,560
the other one. Um we also have a project

74
00:02:55,519 --> 00:03:01,840
with DARPA uh that an SBI director phase

75
00:02:58,560 --> 00:03:04,879
2 of $ 1.5 million um that we have uh

76
00:03:01,840 --> 00:03:07,599
already been working on. So if you see

77
00:03:04,879 --> 00:03:10,319
about here in in our against our

78
00:03:07,599 --> 00:03:12,879
competitors both on GPUs but also on

79
00:03:10,319 --> 00:03:14,959
SMOS cameras we can see 20 times

80
00:03:12,879 --> 00:03:18,400
further. So if you can see something at

81
00:03:14,959 --> 00:03:20,080
130 m we can see it at 2.4 km. And if

82
00:03:18,400 --> 00:03:22,080
you can react to something in 100

83
00:03:20,080 --> 00:03:24,159
milliseconds or so we can do it in

84
00:03:22,080 --> 00:03:26,480
microsconds.

85
00:03:24,159 --> 00:03:28,800
So our camera has a very broad

86
00:03:26,480 --> 00:03:31,360
potential. Um we are starting in space

87
00:03:28,800 --> 00:03:33,599
awareness um and the air defense golden

88
00:03:31,360 --> 00:03:36,239
dome and earth observation. Uh but then

89
00:03:33,599 --> 00:03:38,640
we are also expanding to drones and

90
00:03:36,239 --> 00:03:41,280
detection systems but very importantly

91
00:03:38,640 --> 00:03:43,519
also to quality control. So fastm moving

92
00:03:41,280 --> 00:03:46,239
conveyor belts uh for quality control of

93
00:03:43,519 --> 00:03:47,760
bottles, electronics, semiconductors and

94
00:03:46,239 --> 00:03:49,599
of course robotics and autonomous

95
00:03:47,760 --> 00:03:52,159
driving.

96
00:03:49,599 --> 00:03:54,720
So for the ask uh to all the members

97
00:03:52,159 --> 00:03:57,840
here, we would love to partner and find

98
00:03:54,720 --> 00:03:59,920
use cases where you require an very high

99
00:03:57,840 --> 00:04:03,280
speed, very high resolution, very low

100
00:03:59,920 --> 00:04:05,760
energy consumption by processor. Um and

101
00:04:03,280 --> 00:04:08,239
it can be both in defense and space. So

102
00:04:05,760 --> 00:04:10,000
in drone, earth imaging, space domain in

103
00:04:08,239 --> 00:04:12,159
quality control like food beverage,

104
00:04:10,000 --> 00:04:14,799
semiconductors, batteries, visual

105
00:04:12,159 --> 00:04:17,759
inspections of utilities and agriculture

106
00:04:14,799 --> 00:04:20,880
from space or if you're purchasing data

107
00:04:17,759 --> 00:04:23,520
today from satellite imaging um or

108
00:04:20,880 --> 00:04:25,440
inspections from drones, then uh this is

109
00:04:23,520 --> 00:04:28,400
something where this technology would

110
00:04:25,440 --> 00:04:32,080
also excel. So yeah, thank you very much

111
00:04:28,400 --> 00:04:32,080
and I'll move on to questions.


1
00:00:01,400 --> 00:00:05,120
my name is

2
00:00:02,560 --> 00:00:07,680
Francesca and we all work with this

3
00:00:05,120 --> 00:00:10,280
dyamic data promic data transcriptomic

4
00:00:07,680 --> 00:00:13,320
data and we know it's super complex to

5
00:00:10,280 --> 00:00:16,240
work with high dimensional much so much

6
00:00:13,320 --> 00:00:19,160
noise um so our job is to try to find

7
00:00:16,240 --> 00:00:21,359
the important relationships in that data

8
00:00:19,160 --> 00:00:24,320
and we find that with more data and more

9
00:00:21,359 --> 00:00:27,439
computational power we can make more use

10
00:00:24,320 --> 00:00:30,000
of deep learning models that really um

11
00:00:27,439 --> 00:00:31,079
work with our data to find a more like

12
00:00:30,000 --> 00:00:33,960
concise

13
00:00:31,079 --> 00:00:36,440
representation so for example um we've

14
00:00:33,960 --> 00:00:40,200
been interested in protein language

15
00:00:36,440 --> 00:00:43,960
models so a type of foundation model and

16
00:00:40,200 --> 00:00:46,160
well so for example the es esm2 model is

17
00:00:43,960 --> 00:00:49,480
this protein language model and it is

18
00:00:46,160 --> 00:00:51,800
really only trained on the data to

19
00:00:49,480 --> 00:00:53,359
represent that so in our case that would

20
00:00:51,800 --> 00:00:55,079
be protein

21
00:00:53,359 --> 00:00:58,600
sequences

22
00:00:55,079 --> 00:01:00,440
and what we get with this model

23
00:00:58,600 --> 00:01:02,760
is um

24
00:01:00,440 --> 00:01:03,799
a representation of each data point in a

25
00:01:02,760 --> 00:01:08,119
vector

26
00:01:03,799 --> 00:01:10,880
space and that can be of a model defined

27
00:01:08,119 --> 00:01:14,080
Dimension and that's what we call the

28
00:01:10,880 --> 00:01:17,119
embedding and we would want to hope that

29
00:01:14,080 --> 00:01:18,799
points that are closely related in the

30
00:01:17,119 --> 00:01:20,799
initial data would be closely together

31
00:01:18,799 --> 00:01:22,560
in the Spector space but we still want

32
00:01:20,799 --> 00:01:23,799
to retain that information about the

33
00:01:22,560 --> 00:01:26,600
differences as

34
00:01:23,799 --> 00:01:29,439
well okay so this is very helpful

35
00:01:26,600 --> 00:01:31,799
because now we can use this Vector space

36
00:01:29,439 --> 00:01:35,000
to train models that are more task

37
00:01:31,799 --> 00:01:37,280
specific so like smaller machine

38
00:01:35,000 --> 00:01:40,600
learning models on top that will be task

39
00:01:37,280 --> 00:01:43,479
specific we've been interested in um

40
00:01:40,600 --> 00:01:46,240
looking into understanding where within

41
00:01:43,479 --> 00:01:48,119
a cell a protein will be located so

42
00:01:46,240 --> 00:01:50,479
would it be like in the nucleus or would

43
00:01:48,119 --> 00:01:52,479
it be in the cell membrane so that would

44
00:01:50,479 --> 00:01:55,799
be like a task that will be

45
00:01:52,479 --> 00:01:59,119
train down um on top of these

46
00:01:55,799 --> 00:02:01,119
embeddings the problem is that what is

47
00:01:59,119 --> 00:02:04,600
what is learned by the foundation model

48
00:02:01,119 --> 00:02:06,759
or what is captured is often not very

49
00:02:04,600 --> 00:02:10,200
clear and that's kind of the information

50
00:02:06,759 --> 00:02:12,040
we want to know um it's nice to know

51
00:02:10,200 --> 00:02:16,239
that they work but it be even nicer to

52
00:02:12,040 --> 00:02:18,800
know why um so one thing that we can

53
00:02:16,239 --> 00:02:20,400
compare the growing amount of foundation

54
00:02:18,800 --> 00:02:23,040
models with different architectures

55
00:02:20,400 --> 00:02:24,800
different training data at the moment is

56
00:02:23,040 --> 00:02:27,120
what we do is we take the foundation

57
00:02:24,800 --> 00:02:29,920
models like the first one and then we

58
00:02:27,120 --> 00:02:31,800
take the next one and we train them on

59
00:02:29,920 --> 00:02:34,800
all these Downstream

60
00:02:31,800 --> 00:02:37,040
tasks we get an embedding again we train

61
00:02:34,800 --> 00:02:40,200
machine learning models on each of the

62
00:02:37,040 --> 00:02:41,840
tasks and then we start to compare how

63
00:02:40,200 --> 00:02:43,560
well they are performing on specific

64
00:02:41,840 --> 00:02:46,120
tasks and that's how we say okay well it

65
00:02:43,560 --> 00:02:48,519
captures the subcellular localization or

66
00:02:46,120 --> 00:02:50,720
it doesn't capture that as well so this

67
00:02:48,519 --> 00:02:52,200
is kind of the State ofth art but the

68
00:02:50,720 --> 00:02:53,959
more models we get and the more

69
00:02:52,200 --> 00:02:56,040
benchmarking TS we get we're going to

70
00:02:53,959 --> 00:02:58,440
run into more problems of of doing all

71
00:02:56,040 --> 00:02:59,879
these Tas specific models so we were

72
00:02:58,440 --> 00:03:02,760
interested in how much can we already

73
00:02:59,879 --> 00:03:04,680
already see in this point when we just

74
00:03:02,760 --> 00:03:09,599
compare the embedding spaces of the

75
00:03:04,680 --> 00:03:11,879
models so we we want to share some

76
00:03:09,599 --> 00:03:14,159
thoughts and strategies that we could

77
00:03:11,879 --> 00:03:16,840
have a look into the embedding spaces

78
00:03:14,159 --> 00:03:18,640
and we summarize that in our framework

79
00:03:16,840 --> 00:03:22,360
is called

80
00:03:18,640 --> 00:03:25,519
M okay so what we do

81
00:03:22,360 --> 00:03:28,200
here is really

82
00:03:25,519 --> 00:03:30,120
compare embedding spaces from different

83
00:03:28,200 --> 00:03:32,560
foundational models and I'm going to

84
00:03:30,120 --> 00:03:35,239
draw it in 2D so we can all kind of

85
00:03:32,560 --> 00:03:36,760
perceive all the dimensions but please

86
00:03:35,239 --> 00:03:40,319
imagine that to be a very high

87
00:03:36,760 --> 00:03:43,439
dimensional Vector the problem is that

88
00:03:40,319 --> 00:03:45,879
if we have our sample being projected

89
00:03:43,439 --> 00:03:48,120
into two spaces we cannot compare the

90
00:03:45,879 --> 00:03:49,760
vectors itself because the spaces will

91
00:03:48,120 --> 00:03:52,959
be different have different dimensions

92
00:03:49,760 --> 00:03:54,720
and so forth so what we try to uh so

93
00:03:52,959 --> 00:03:56,959
what we are coming up with how we want

94
00:03:54,720 --> 00:04:00,959
to do is that we project a set of

95
00:03:56,959 --> 00:04:03,040
proteins in our case into the space

96
00:04:00,959 --> 00:04:06,000
and then we look where they end

97
00:04:03,040 --> 00:04:08,680
up and what we now see is that if we

98
00:04:06,000 --> 00:04:10,560
compare like the distance between the

99
00:04:08,680 --> 00:04:12,920
different um data points in the

100
00:04:10,560 --> 00:04:14,560
embedding space is that for example the

101
00:04:12,920 --> 00:04:17,280
circle and the triangle will be very

102
00:04:14,560 --> 00:04:20,880
close to each other in both spaces but

103
00:04:17,280 --> 00:04:23,040
suddenly this this like Circle and the

104
00:04:20,880 --> 00:04:26,040
square get very far away compared to the

105
00:04:23,040 --> 00:04:29,400
other ining space so this is what we're

106
00:04:26,040 --> 00:04:31,800
basing most of our um analysis on these

107
00:04:29,400 --> 00:04:33,680
pair wise distance

108
00:04:31,800 --> 00:04:35,680
is

109
00:04:33,680 --> 00:04:40,120
um

110
00:04:35,680 --> 00:04:42,600
and also we really want to work with um

111
00:04:40,120 --> 00:04:46,120
developing quantitative measures in

112
00:04:42,600 --> 00:04:49,400
metrics and how to quantify those rather

113
00:04:46,120 --> 00:04:49,400
than just

114
00:04:49,479 --> 00:04:54,000
visually and on top we found that we

115
00:04:52,199 --> 00:04:55,680
looked into natural language processing

116
00:04:54,000 --> 00:04:57,880
there are some interesting approaches to

117
00:04:55,680 --> 00:05:00,080
compare embedding spaces but they often

118
00:04:57,880 --> 00:05:02,039
work with just looking at the individual

119
00:05:00,080 --> 00:05:04,919
data points with just their name and we

120
00:05:02,039 --> 00:05:06,840
realize for proteins or damic data it's

121
00:05:04,919 --> 00:05:09,479
often not very helpful if I just tell

122
00:05:06,840 --> 00:05:10,960
you to UNI prod names and ask you to say

123
00:05:09,479 --> 00:05:12,919
if that's relevant that they're close

124
00:05:10,960 --> 00:05:14,479
together it might be more difficult

125
00:05:12,919 --> 00:05:17,600
rather than if I tell you that they're

126
00:05:14,479 --> 00:05:20,160
both from like a common protein family

127
00:05:17,600 --> 00:05:23,280
so we really want to

128
00:05:20,160 --> 00:05:26,840
include um what we call feature data or

129
00:05:23,280 --> 00:05:29,440
metadata so any kind of information you

130
00:05:26,840 --> 00:05:33,120
have on those on those samples you look

131
00:05:29,440 --> 00:05:36,960
at so if we have our data

132
00:05:33,120 --> 00:05:39,639
points um any sort of classification

133
00:05:36,960 --> 00:05:43,759
that we already know from our data point

134
00:05:39,639 --> 00:05:45,120
um databases so for example on these

135
00:05:43,759 --> 00:05:47,240
subcellular

136
00:05:45,120 --> 00:05:49,080
localizations then we know okay there's

137
00:05:47,240 --> 00:05:51,080
like sample one is in the membrane

138
00:05:49,080 --> 00:05:53,440
sample two as well sample three is in

139
00:05:51,080 --> 00:05:55,400
the nucleus it could also be something

140
00:05:53,440 --> 00:05:56,880
like we were looking at here like

141
00:05:55,400 --> 00:05:59,919
information about the function of the

142
00:05:56,880 --> 00:06:04,319
proteins or the family

143
00:05:59,919 --> 00:06:06,440
okay so what we're analyzing now in this

144
00:06:04,319 --> 00:06:07,880
framework is that we have a set of

145
00:06:06,440 --> 00:06:10,120
samples that we choose that we're

146
00:06:07,880 --> 00:06:12,599
interested in in our case that will be

147
00:06:10,120 --> 00:06:14,479
protein sequences we put them through a

148
00:06:12,599 --> 00:06:18,319
range of foundation models and we get a

149
00:06:14,479 --> 00:06:22,120
range of embedding spaces so these could

150
00:06:18,319 --> 00:06:24,120
be these could be just um models that

151
00:06:22,120 --> 00:06:28,360
are trained on like slightly different

152
00:06:24,120 --> 00:06:31,720
data or um models pre and post

153
00:06:28,360 --> 00:06:33,599
fine-tuning or even models uh trained on

154
00:06:31,720 --> 00:06:35,240
different data modalities so protein

155
00:06:33,599 --> 00:06:38,000
language models they're also structure

156
00:06:35,240 --> 00:06:40,319
aware versus not structure

157
00:06:38,000 --> 00:06:42,199
aware okay so we end up with different

158
00:06:40,319 --> 00:06:45,599
inverting spaces I'm just going to call

159
00:06:42,199 --> 00:06:46,680
them V1 V2 V3 and we also have a our

160
00:06:45,599 --> 00:06:49,560
feature

161
00:06:46,680 --> 00:06:52,000
data so there are many things we can do

162
00:06:49,560 --> 00:06:54,080
with this we want to draw your attention

163
00:06:52,000 --> 00:06:56,319
to two things we've been working on

164
00:06:54,080 --> 00:06:57,960
which is the first one is if you have

165
00:06:56,319 --> 00:06:59,800
any of those two embedding spaces

166
00:06:57,960 --> 00:07:01,400
similar to what we did here you just

167
00:06:59,800 --> 00:07:04,440
want to know like do they capture the

168
00:07:01,400 --> 00:07:06,120
same information or did they think that

169
00:07:04,440 --> 00:07:09,599
our samples are somehow differently

170
00:07:06,120 --> 00:07:13,120
related so we call this a

171
00:07:09,599 --> 00:07:13,120
pairwise space

172
00:07:13,520 --> 00:07:17,560
comparison

173
00:07:15,080 --> 00:07:19,879
um and the second thing we're looking

174
00:07:17,560 --> 00:07:21,800
into is more if you're specifically

175
00:07:19,879 --> 00:07:24,599
interested in specific feature like we

176
00:07:21,800 --> 00:07:27,840
were in subcellular

177
00:07:24,599 --> 00:07:29,800
localization how is that distributed in

178
00:07:27,840 --> 00:07:33,479
the different spaces

179
00:07:29,800 --> 00:07:36,280
um so really going starting with the

180
00:07:33,479 --> 00:07:38,120
with the feature and looking at its

181
00:07:36,280 --> 00:07:41,240
distribution

182
00:07:38,120 --> 00:07:43,039
okay so looking back at this first

183
00:07:41,240 --> 00:07:46,639
approach again this is really what we

184
00:07:43,039 --> 00:07:49,720
did here we look at the pairwise

185
00:07:46,639 --> 00:07:54,360
distances in one space that V1 and then

186
00:07:49,720 --> 00:07:56,879
the pair distances in V2 and maybe two

187
00:07:54,360 --> 00:08:00,560
points are very closely

188
00:07:56,879 --> 00:08:03,720
together in V1 and V2 so we see them

189
00:08:00,560 --> 00:08:06,800
somehow here but maybe another point is

190
00:08:03,720 --> 00:08:08,680
very far away from from the point one in

191
00:08:06,800 --> 00:08:12,159
one space but very close in the second

192
00:08:08,680 --> 00:08:15,159
space so far away in V1 but like close

193
00:08:12,159 --> 00:08:16,840
on V2 it would end up somewhere here so

194
00:08:15,159 --> 00:08:18,800
all the points that have like similar

195
00:08:16,840 --> 00:08:20,240
relationships or pair of points that

196
00:08:18,800 --> 00:08:22,879
have similar relationships will be on

197
00:08:20,240 --> 00:08:26,240
this diagonal and points that are

198
00:08:22,879 --> 00:08:29,720
somehow differently will be

199
00:08:26,240 --> 00:08:33,120
off okay now we can identify those kind

200
00:08:29,720 --> 00:08:35,560
of outliers and use our feature data to

201
00:08:33,120 --> 00:08:38,000
understand is there any correlation of

202
00:08:35,560 --> 00:08:41,719
these data points with a specific Gene

203
00:08:38,000 --> 00:08:43,320
family a specific location is one model

204
00:08:41,719 --> 00:08:45,560
learning something that the other one

205
00:08:43,320 --> 00:08:48,200
didn't capture or is this more like an

206
00:08:45,560 --> 00:08:50,160
artifact that we did not expect so we

207
00:08:48,200 --> 00:08:51,200
can start asking these questions about

208
00:08:50,160 --> 00:08:53,560
the

209
00:08:51,200 --> 00:08:57,040
models this is the first approach the

210
00:08:53,560 --> 00:08:59,839
second approach again talking about like

211
00:08:57,040 --> 00:09:02,880
a specific feature

212
00:08:59,839 --> 00:09:05,440
here for example the subcell

213
00:09:02,880 --> 00:09:07,640
localization what we can go do is look

214
00:09:05,440 --> 00:09:09,720
into each of the

215
00:09:07,640 --> 00:09:12,640
spaces

216
00:09:09,720 --> 00:09:15,519
and now we're interested in how is this

217
00:09:12,640 --> 00:09:18,600
um feature captured in the distances of

218
00:09:15,519 --> 00:09:21,880
the space so say we look into V1 and

219
00:09:18,600 --> 00:09:23,000
then we pick a data point and say it's

220
00:09:21,880 --> 00:09:26,519
in the

221
00:09:23,000 --> 00:09:28,200
plasma then we choose a k and we do a k

222
00:09:26,519 --> 00:09:31,000
nearest neighbors approach and we find

223
00:09:28,200 --> 00:09:34,720
all the three neighbors of the data

224
00:09:31,000 --> 00:09:36,399
point we then look at the um classes for

225
00:09:34,720 --> 00:09:41,040
the feature that we're looking into for

226
00:09:36,399 --> 00:09:44,680
these data points and we see oh okay two

227
00:09:41,040 --> 00:09:48,120
out of the three neighbors are also

228
00:09:44,680 --> 00:09:50,800
triangles and one is not so we assign

229
00:09:48,120 --> 00:09:53,839
this um this data point a score of two

230
00:09:50,800 --> 00:09:55,800
2/3 two of them have the same feature

231
00:09:53,839 --> 00:09:59,240
and that's what we call the cane and

232
00:09:55,800 --> 00:09:59,240
Alignment score

233
00:10:00,560 --> 00:10:05,480
um and if the score is higher that means

234
00:10:03,320 --> 00:10:08,120
more more similarity is in the

235
00:10:05,480 --> 00:10:10,720
neighborhood of each point now what we

236
00:10:08,120 --> 00:10:12,240
can do is that we can look at these

237
00:10:10,720 --> 00:10:15,079
scores and the distribution of the

238
00:10:12,240 --> 00:10:16,800
scores across different um embedding

239
00:10:15,079 --> 00:10:18,920
spaces from different

240
00:10:16,800 --> 00:10:22,160
models and see if they are like

241
00:10:18,920 --> 00:10:25,600
generally higher so more of this featur

242
00:10:22,160 --> 00:10:28,360
is captured in the in the local

243
00:10:25,600 --> 00:10:30,160
neighborhoods in one space compared to

244
00:10:28,360 --> 00:10:33,320
another so maybe maybe that information

245
00:10:30,160 --> 00:10:36,000
is already more Rel relatively easy

246
00:10:33,320 --> 00:10:38,920
available in the distance metrix of the

247
00:10:36,000 --> 00:10:41,920
space further what we can do is we can

248
00:10:38,920 --> 00:10:44,440
stratify that information the scores for

249
00:10:41,920 --> 00:10:48,720
each space again but this time for each

250
00:10:44,440 --> 00:10:52,360
class so say we look for all points with

251
00:10:48,720 --> 00:10:54,519
a triangle like what is the mean score

252
00:10:52,360 --> 00:10:56,160
and maybe it's very high for the

253
00:10:54,519 --> 00:10:57,959
triangles meaning the triangles are

254
00:10:56,160 --> 00:11:02,360
generally close to other

255
00:10:57,959 --> 00:11:04,360
triangles um maybe in all spaces but but

256
00:11:02,360 --> 00:11:06,839
the the another class might be very

257
00:11:04,360 --> 00:11:09,399
poorly represented in its

258
00:11:06,839 --> 00:11:11,360
neighborhood so a last approach that

259
00:11:09,399 --> 00:11:13,800
we've been working on is looking then

260
00:11:11,360 --> 00:11:16,760
back into the embedding

261
00:11:13,800 --> 00:11:20,000
space um and saying okay if we have this

262
00:11:16,760 --> 00:11:22,959
data point if we look at each data point

263
00:11:20,000 --> 00:11:26,000
again and we look at the nearest

264
00:11:22,959 --> 00:11:27,720
neighbors of each data point now for

265
00:11:26,000 --> 00:11:30,920
each data point we don't want to count

266
00:11:27,720 --> 00:11:35,079
how many have like same feature but in

267
00:11:30,920 --> 00:11:36,279
generally like how many have like any of

268
00:11:35,079 --> 00:11:38,680
the feature

269
00:11:36,279 --> 00:11:40,760
classes for this data point it would be

270
00:11:38,680 --> 00:11:44,360
like two would have also a triangle and

271
00:11:40,760 --> 00:11:47,360
then there's zero squares and one one

272
00:11:44,360 --> 00:11:49,639
Circle and again we can aggregate that

273
00:11:47,360 --> 00:11:52,079
and and we get a metric and a matrix

274
00:11:49,639 --> 00:11:54,920
that will tell you how close different

275
00:11:52,079 --> 00:11:58,880
classes are in an embedding

276
00:11:54,920 --> 00:12:00,360
space okay so these are some thoughts we

277
00:11:58,880 --> 00:12:02,959
gathered

278
00:12:00,360 --> 00:12:04,600
on already looking at into the embedding

279
00:12:02,959 --> 00:12:08,320
spaces before you do more resource

280
00:12:04,600 --> 00:12:10,320
intensive um training and we found that

281
00:12:08,320 --> 00:12:14,000
for person language models we could

282
00:12:10,320 --> 00:12:16,519
really for some task look into Which

283
00:12:14,000 --> 00:12:19,519
models might be more worth taking into

284
00:12:16,519 --> 00:12:21,360
more uh into F tuning which one models

285
00:12:19,519 --> 00:12:23,199
have already like a very good

286
00:12:21,360 --> 00:12:26,120
representation in the distances of the

287
00:12:23,199 --> 00:12:28,320
features we're interested in um and we

288
00:12:26,120 --> 00:12:30,040
have a python implementation of that if

289
00:12:28,320 --> 00:12:32,199
you're interested

290
00:12:30,040 --> 00:12:33,839
um and if you have any embedding spaces

291
00:12:32,199 --> 00:12:36,199
that you are very excited about I would

292
00:12:33,839 --> 00:12:38,760
love to hear about them it's very task

293
00:12:36,199 --> 00:12:40,480
and data agnostic so you can just use

294
00:12:38,760 --> 00:12:43,079
whatever embedding space you have if you

295
00:12:40,480 --> 00:12:45,560
have some feature data um we'd be very

296
00:12:43,079 --> 00:12:47,760
interested to hear how that looks like

297
00:12:45,560 --> 00:12:47,760
for

298
00:12:50,760 --> 00:12:57,279
you I used to work on latent variable

299
00:12:54,399 --> 00:13:01,600
models for gene expression and um

300
00:12:57,279 --> 00:13:04,600
multiomic data uh so we I guess all know

301
00:13:01,600 --> 00:13:06,880
there you get a latent representation

302
00:13:04,600 --> 00:13:10,800
set which is usually highly compressed

303
00:13:06,880 --> 00:13:13,839
with maybe 20 to 200 Dimensions um and

304
00:13:10,800 --> 00:13:19,160
typically this will be visualized in a

305
00:13:13,839 --> 00:13:21,760
PCA or map um and the extent to which

306
00:13:19,160 --> 00:13:24,519
this is interpretable is usually

307
00:13:21,760 --> 00:13:27,880
clustering maybe bat effect removal to

308
00:13:24,519 --> 00:13:29,959
see if integration is good um and we had

309
00:13:27,880 --> 00:13:32,800
been working on things like making

310
00:13:29,959 --> 00:13:35,440
models more flexible to be able to do

311
00:13:32,800 --> 00:13:38,880
things like in cical perturbations where

312
00:13:35,440 --> 00:13:40,839
you'll be able to see how uh a cell

313
00:13:38,880 --> 00:13:43,680
changes I don't know if you can see this

314
00:13:40,839 --> 00:13:46,120
tiny Arrow but how the Laten space and

315
00:13:43,680 --> 00:13:49,240
expression profile changes uh of a cell

316
00:13:46,120 --> 00:13:53,320
if you say they change a gene or a set

317
00:13:49,240 --> 00:13:55,199
of genes um but I found that well or

318
00:13:53,320 --> 00:13:57,199
many people find that this is still not

319
00:13:55,199 --> 00:14:00,560
really enough to understand what these

320
00:13:57,199 --> 00:14:04,600
models actually learn um so fairly

321
00:14:00,560 --> 00:14:10,240
recently there was this really cool work

322
00:14:04,600 --> 00:14:12,759
um that hypothesized that there are no

323
00:14:10,240 --> 00:14:12,759
super

324
00:14:13,160 --> 00:14:20,120
positions and superpositions basically

325
00:14:16,639 --> 00:14:22,920
describe that especially in sparse data

326
00:14:20,120 --> 00:14:25,839
which we often deal with in multiomics

327
00:14:22,920 --> 00:14:30,519
that you have let's say two Dimensions

328
00:14:25,839 --> 00:14:33,759
D1 D2 um that could be two neurons and

329
00:14:30,519 --> 00:14:36,800
these will actually encode many more

330
00:14:33,759 --> 00:14:38,920
features than just um two so let's say

331
00:14:36,800 --> 00:14:42,240
in this example we

332
00:14:38,920 --> 00:14:44,800
have four feature vectors uh that are

333
00:14:42,240 --> 00:14:47,320
squished into these two Dimensions so

334
00:14:44,800 --> 00:14:51,519
these are superp position vectors in two

335
00:14:47,320 --> 00:14:51,519
dimensions and what do I mean with

336
00:14:51,880 --> 00:14:57,399
features this can be pretty vague uh so

337
00:14:55,440 --> 00:15:00,360
you can think of many things whether it

338
00:14:57,399 --> 00:15:04,120
be some sources of variation in the data

339
00:15:00,360 --> 00:15:07,720
or um specific patterns so we can think

340
00:15:04,120 --> 00:15:11,320
of let's say we have face images uh we

341
00:15:07,720 --> 00:15:13,880
again have two dimensions and we could

342
00:15:11,320 --> 00:15:17,079
represent for example one feature is a

343
00:15:13,880 --> 00:15:19,800
circle then there's some features with

344
00:15:17,079 --> 00:15:23,079
dots and a curve and now we have a

345
00:15:19,800 --> 00:15:25,800
smiley represented by four features in

346
00:15:23,079 --> 00:15:29,759
biology this could also mean uh a

347
00:15:25,800 --> 00:15:33,199
transcription factor or a pathway maybe

348
00:15:29,759 --> 00:15:36,240
a protein function or domain um or this

349
00:15:33,199 --> 00:15:38,199
has first been applied to text where we

350
00:15:36,240 --> 00:15:41,519
see that some features are just like

351
00:15:38,199 --> 00:15:44,160
single characters like an at or um a

352
00:15:41,519 --> 00:15:47,399
whole citation uh as a

353
00:15:44,160 --> 00:15:51,240
concept uh so the question now is how

354
00:15:47,399 --> 00:15:55,279
can we extract these features in superp

355
00:15:51,240 --> 00:15:58,120
position and this has been presented by

356
00:15:55,279 --> 00:16:01,399
taking an old trick out of the box uh

357
00:15:58,120 --> 00:16:04,519
that's called a sparse Auto

358
00:16:01,399 --> 00:16:07,880
encoder and what this does is basically

359
00:16:04,519 --> 00:16:13,000
we take our two dimensions in Laten

360
00:16:07,880 --> 00:16:14,519
space now very simplified um and then we

361
00:16:13,000 --> 00:16:16,440
basically

362
00:16:14,519 --> 00:16:19,680
build an

363
00:16:16,440 --> 00:16:23,519
overcomplete auto encoder so we just

364
00:16:19,680 --> 00:16:26,920
blow up this Dimension into multiple

365
00:16:23,519 --> 00:16:28,360
fold um we'll call this activations

366
00:16:26,920 --> 00:16:30,959
these latent vectors because it's really

367
00:16:28,360 --> 00:16:35,360
hard to tell about multiple embeddings

368
00:16:30,959 --> 00:16:37,399
um and then we enforce sparsity uh so

369
00:16:35,360 --> 00:16:40,160
that we make sure a lot of these neurons

370
00:16:37,399 --> 00:16:42,839
are dead and we'll have only a few

371
00:16:40,160 --> 00:16:46,160
neurons that represent these different

372
00:16:42,839 --> 00:16:48,240
vectors in superp position and this is

373
00:16:46,160 --> 00:16:50,839
actually really really simple to train

374
00:16:48,240 --> 00:16:54,480
in the most basic form uh it's simply

375
00:16:50,839 --> 00:16:56,759
trained with the loss as the mean squ

376
00:16:54,480 --> 00:17:00,920
error or anything for reconstruction

377
00:16:56,759 --> 00:17:02,759
plus an L1 Norm on these activations and

378
00:17:00,920 --> 00:17:04,760
this enforces the L1 Norm enforces

379
00:17:02,759 --> 00:17:07,520
sparsities and this is applied to these

380
00:17:04,760 --> 00:17:12,280
activations and then ideally we should

381
00:17:07,520 --> 00:17:15,480
get activations that in this case have

382
00:17:12,280 --> 00:17:19,240
four so-called active or live

383
00:17:15,480 --> 00:17:21,439
neurons and they can then disentangle

384
00:17:19,240 --> 00:17:24,120
separate uh these

385
00:17:21,439 --> 00:17:26,720
features now that we've separated them

386
00:17:24,120 --> 00:17:30,320
we still have to actually be able to

387
00:17:26,720 --> 00:17:32,400
interpret them and um you can do this

388
00:17:30,320 --> 00:17:34,520
manually if you have a given concept

389
00:17:32,400 --> 00:17:37,640
that you think you should find in your

390
00:17:34,520 --> 00:17:41,120
model but this can be quite tedious um

391
00:17:37,640 --> 00:17:43,960
so a good solution is uh so-called

392
00:17:41,120 --> 00:17:43,960
reverse

393
00:17:44,559 --> 00:17:51,919
engineering um where we will basically

394
00:17:48,039 --> 00:17:51,919
build a concept

395
00:17:52,000 --> 00:17:57,320
Library so let's say we are in the

396
00:17:55,000 --> 00:18:01,240
protein space which uh this has already

397
00:17:57,320 --> 00:18:03,360
been uh done for um there they took all

398
00:18:01,240 --> 00:18:06,600
functional and structural annotations

399
00:18:03,360 --> 00:18:08,919
from swissprot and built a concept

400
00:18:06,600 --> 00:18:10,919
library of a certain set of these

401
00:18:08,919 --> 00:18:13,960
Concepts so it could be a specific

402
00:18:10,919 --> 00:18:17,240
catalytic activity um even just s single

403
00:18:13,960 --> 00:18:20,880
amino acids or charges uh are included

404
00:18:17,240 --> 00:18:22,520
we have all our samples and then we take

405
00:18:20,880 --> 00:18:24,799
all our

406
00:18:22,520 --> 00:18:26,960
activations um for each

407
00:18:24,799 --> 00:18:30,440
sample and in order to like

408
00:18:26,960 --> 00:18:33,240
automatically assign some information of

409
00:18:30,440 --> 00:18:36,280
what each feature might represent we can

410
00:18:33,240 --> 00:18:40,760
simply uh compute either correlation or

411
00:18:36,280 --> 00:18:43,320
similarity Matrix M metric between uh

412
00:18:40,760 --> 00:18:46,320
the concepts and our

413
00:18:43,320 --> 00:18:49,960
activations and this as I already

414
00:18:46,320 --> 00:18:54,080
mentioned has been applied already in

415
00:18:49,960 --> 00:18:57,240
biology uh to protein language

416
00:18:54,080 --> 00:19:00,400
models uh where we have Concepts

417
00:18:57,240 --> 00:19:02,880
represented by at the moment Swiss prod

418
00:19:00,400 --> 00:19:05,200
annotations um but this can already be

419
00:19:02,880 --> 00:19:08,480
very useful you can think of as if you

420
00:19:05,200 --> 00:19:11,600
have these disentangled feature vectors

421
00:19:08,480 --> 00:19:14,600
then you can do some function steering

422
00:19:11,600 --> 00:19:18,320
so uh they tested it for example on

423
00:19:14,600 --> 00:19:21,480
these repeat glycine um uh patterns and

424
00:19:18,320 --> 00:19:23,400
you can basically uh change in a given

425
00:19:21,480 --> 00:19:25,080
model that hasn't been even trained on

426
00:19:23,400 --> 00:19:27,159
function you can change a certain

427
00:19:25,080 --> 00:19:29,799
pattern or functionality uh with

428
00:19:27,159 --> 00:19:32,679
steering these vectors or uh what I have

429
00:19:29,799 --> 00:19:35,880
been working on were um omix latent

430
00:19:32,679 --> 00:19:39,000
variable models because I had that lying

431
00:19:35,880 --> 00:19:42,000
around um and basically what I did there

432
00:19:39,000 --> 00:19:45,440
is and I am very inspired by Isabella to

433
00:19:42,000 --> 00:19:49,640
try this out next is I took for each

434
00:19:45,440 --> 00:19:53,360
activation the highly active and the

435
00:19:49,640 --> 00:19:55,840
lowest activity feature uh sampled sorry

436
00:19:53,360 --> 00:19:58,200
and then performed a differential gene

437
00:19:55,840 --> 00:20:00,600
expression analysis and Gene enrichment

438
00:19:58,200 --> 00:20:03,919
with this case as an example just Gene

439
00:20:00,600 --> 00:20:06,480
onology but basically um with having

440
00:20:03,919 --> 00:20:08,440
these Gene sets from Gene from

441
00:20:06,480 --> 00:20:10,520
differential gene expression analysis

442
00:20:08,440 --> 00:20:14,000
and then the enrichment I was able to

443
00:20:10,520 --> 00:20:16,480
annotate over 80% of a model that I

444
00:20:14,000 --> 00:20:18,880
think is not even that good yet so I

445
00:20:16,480 --> 00:20:20,760
think with better omx models we'll be

446
00:20:18,880 --> 00:20:23,919
better uh we'll be able to get much

447
00:20:20,760 --> 00:20:26,280
better functionality um and yeah if

448
00:20:23,919 --> 00:20:28,400
you're interested in some of the uh

449
00:20:26,280 --> 00:20:31,559
specific cases of some features uh you

450
00:20:28,400 --> 00:20:34,360
can read the paper or if you have ideas

451
00:20:31,559 --> 00:20:36,799
of more interesting biological um

452
00:20:34,360 --> 00:20:39,159
problems that this could be applied to

453
00:20:36,799 --> 00:20:41,640
uh feel free to reach out to me I'm

454
00:20:39,159 --> 00:20:41,640
happy to

455
00:20:44,799 --> 00:20:49,960
explore today I'm going to be talking

456
00:20:47,000 --> 00:20:52,799
about a project that started with a

457
00:20:49,960 --> 00:20:56,240
collaboration that we have with Jeff

458
00:20:52,799 --> 00:20:59,200
moffit's group at uh Boston Children's

459
00:20:56,240 --> 00:21:01,120
Hospital um and it start started just as

460
00:20:59,200 --> 00:21:03,600
a collaboration on one data set and then

461
00:21:01,120 --> 00:21:06,240
it's really sort of grown into a more a

462
00:21:03,600 --> 00:21:08,120
more General method um so first I'll

463
00:21:06,240 --> 00:21:10,600
explain the problem that they they came

464
00:21:08,120 --> 00:21:14,919
to us with so they have this very large

465
00:21:10,600 --> 00:21:17,640
Mish so spatial transcriptomics data set

466
00:21:14,919 --> 00:21:20,120
um consisting of measurements from from

467
00:21:17,640 --> 00:21:22,440
the mouse colon and so they have

468
00:21:20,120 --> 00:21:25,400
hundreds of of slides and thousands of

469
00:21:22,440 --> 00:21:28,159
genes profiled and here I'm just showing

470
00:21:25,400 --> 00:21:31,279
you example of one of these slices so

471
00:21:28,159 --> 00:21:34,240
each dot is a cell and then colored by

472
00:21:31,279 --> 00:21:35,960
the expression of of two different genes

473
00:21:34,240 --> 00:21:37,919
and what they noticed is that the the

474
00:21:35,960 --> 00:21:40,440
genes that are spatially variable they

475
00:21:37,919 --> 00:21:43,159
tended to fall into one of two

476
00:21:40,440 --> 00:21:47,240
categories the first is like this gene

477
00:21:43,159 --> 00:21:50,240
on the left um they call patchy so you

478
00:21:47,240 --> 00:21:52,240
can see that there's a burst in just one

479
00:21:50,240 --> 00:21:54,880
region of the colon there's a burst and

480
00:21:52,240 --> 00:21:57,120
expression and it's it's it's low in the

481
00:21:54,880 --> 00:22:00,880
other locations of the

482
00:21:57,120 --> 00:22:03,360
colon um on the the other hand this this

483
00:22:00,880 --> 00:22:05,720
these other genes have a gradient

484
00:22:03,360 --> 00:22:08,120
pattern where the expression is high on

485
00:22:05,720 --> 00:22:11,640
the outside and then as you move towards

486
00:22:08,120 --> 00:22:13,320
the inside it goes from high to low um

487
00:22:11,640 --> 00:22:16,799
or alternatively there are genes that

488
00:22:13,320 --> 00:22:18,840
are that go from low to high and the

489
00:22:16,799 --> 00:22:20,640
question that they they wanted us to

490
00:22:18,840 --> 00:22:22,159
answer is they wanted us to just go

491
00:22:20,640 --> 00:22:27,240
through

492
00:22:22,159 --> 00:22:29,279
the all 200 slices and just find genes

493
00:22:27,240 --> 00:22:32,679
that have either the patch or the

494
00:22:29,279 --> 00:22:35,200
gradient pattern of expression and so

495
00:22:32,679 --> 00:22:36,880
what we found is that so what I would

496
00:22:35,200 --> 00:22:39,400
say the standard approach to find

497
00:22:36,880 --> 00:22:41,880
spatially variable genes is is to use

498
00:22:39,400 --> 00:22:44,320
right a hypothesis test for for spatial

499
00:22:41,880 --> 00:22:47,159
variability and what we found here is

500
00:22:44,320 --> 00:22:49,120
that's not really that useful because

501
00:22:47,159 --> 00:22:52,919
right the P value for both of these

502
00:22:49,120 --> 00:22:55,240
genes will be like 10 the minus 100 or

503
00:22:52,919 --> 00:22:57,720
something incredibly small they're both

504
00:22:55,240 --> 00:22:59,000
spatially variable but the hypothesis

505
00:22:57,720 --> 00:23:02,440
test doesn't tell

506
00:22:59,000 --> 00:23:05,360
you uh how they're spatially variable

507
00:23:02,440 --> 00:23:11,840
and so that's sort of where we started

508
00:23:05,360 --> 00:23:16,080
Des uh a method um and so the idea is to

509
00:23:11,840 --> 00:23:16,080
use what we call

510
00:23:17,480 --> 00:23:21,120
morphologically relevant

511
00:23:21,799 --> 00:23:26,240
coordinates

512
00:23:23,360 --> 00:23:28,799
so what is that it's a transformation of

513
00:23:26,240 --> 00:23:31,640
the original coordinates for each cell

514
00:23:28,799 --> 00:23:34,320
so

515
00:23:31,640 --> 00:23:38,000
right this might be the original XY

516
00:23:34,320 --> 00:23:38,000
coordinates and we transform

517
00:23:40,840 --> 00:23:48,960
it into these two new coordinates out

518
00:23:43,880 --> 00:23:48,960
called T and R and in this case

519
00:23:49,840 --> 00:23:56,640
T would

520
00:23:52,039 --> 00:24:00,240
summarize right I'll say

521
00:23:56,640 --> 00:24:04,600
longitudinal position

522
00:24:00,240 --> 00:24:07,720
so where along the colon are

523
00:24:04,600 --> 00:24:12,440
you and

524
00:24:07,720 --> 00:24:15,120
RJ would give the the radial

525
00:24:12,440 --> 00:24:18,919
position

526
00:24:15,120 --> 00:24:21,240
right so how close you are from the

527
00:24:18,919 --> 00:24:24,480
inside or versus the

528
00:24:21,240 --> 00:24:26,640
outside and if you are able to make this

529
00:24:24,480 --> 00:24:31,039
transformation then now the problem of

530
00:24:26,640 --> 00:24:34,960
identifying patchy versus gradient genes

531
00:24:31,039 --> 00:24:38,880
um is uh very simple so right so if you

532
00:24:34,960 --> 00:24:40,880
just plotted now as a 1D if you plotted

533
00:24:38,880 --> 00:24:44,000
the expression of the patchy genes as a

534
00:24:40,880 --> 00:24:46,399
function of T right as a function of T

535
00:24:44,000 --> 00:24:48,399
the expression right it'll be low and

536
00:24:46,399 --> 00:24:49,760
then there'll be like a burst and then

537
00:24:48,399 --> 00:24:53,600
it'll be low

538
00:24:49,760 --> 00:24:53,600
again so this would be like

539
00:24:55,279 --> 00:25:00,320
patchy whereas for uh

540
00:25:00,960 --> 00:25:03,279
for

541
00:25:03,440 --> 00:25:08,279
gradient right the variation is in the r

542
00:25:06,520 --> 00:25:10,559
direction if you ploted expression as a

543
00:25:08,279 --> 00:25:14,559
function of r right it might start high

544
00:25:10,559 --> 00:25:16,399
and then and then go low that sort of

545
00:25:14,559 --> 00:25:19,760
the general idea behind these

546
00:25:16,399 --> 00:25:23,360
morphologically relevant coordinates so

547
00:25:19,760 --> 00:25:25,680
now I'll tell you how we can estimate

548
00:25:23,360 --> 00:25:27,039
these so

549
00:25:25,680 --> 00:25:29,279
[Music]

550
00:25:27,039 --> 00:25:32,600
estimation so

551
00:25:29,279 --> 00:25:32,600
we start by assuming

552
00:25:34,080 --> 00:25:41,399
that right the mean of the

553
00:25:37,799 --> 00:25:45,039
coordinates right is given by some

554
00:25:41,399 --> 00:25:48,279
unobserved parametric curve F of T subj

555
00:25:45,039 --> 00:25:48,279
So Right

556
00:25:50,480 --> 00:25:56,840
f is some smooth parametric

557
00:25:53,960 --> 00:25:58,760
curve so it takes as input the the first

558
00:25:56,840 --> 00:26:03,039
coordinate and then

559
00:25:58,760 --> 00:26:06,360
gives me an output in two Dimensions um

560
00:26:03,039 --> 00:26:08,960
so there are many identifiability

561
00:26:06,360 --> 00:26:12,080
constraints in this model um one very

562
00:26:08,960 --> 00:26:14,399
important one um that we need for our

563
00:26:12,080 --> 00:26:18,799
estimation algorithm is the

564
00:26:14,399 --> 00:26:18,799
so-called uh unit speed

565
00:26:20,000 --> 00:26:23,000
constraint

566
00:26:23,320 --> 00:26:28,919
so right in a parametric curve fime of T

567
00:26:26,200 --> 00:26:30,600
is like velocity this is just saying the

568
00:26:28,919 --> 00:26:32,360
magnitude of the Velocity is one at

569
00:26:30,600 --> 00:26:35,000
every Point otherwise we could just

570
00:26:32,360 --> 00:26:36,799
reparameterize T and get the get the

571
00:26:35,000 --> 00:26:42,000
same

572
00:26:36,799 --> 00:26:44,279
curve um and so the way that we can

573
00:26:42,000 --> 00:26:47,880
leverage this constraint for estimation

574
00:26:44,279 --> 00:26:47,880
is that we can note

575
00:26:48,240 --> 00:26:55,679
that

576
00:26:51,000 --> 00:26:59,720
um so I'll do the simpler case where

577
00:26:55,679 --> 00:27:02,480
it's not a loop so where

578
00:26:59,720 --> 00:27:04,679
the curve is not joined at the end um

579
00:27:02,480 --> 00:27:06,880
the idea for extending it to Loops is is

580
00:27:04,679 --> 00:27:09,200
very similar but in this case where the

581
00:27:06,880 --> 00:27:13,760
end points are not joined you can see

582
00:27:09,200 --> 00:27:17,120
that TJ minus TI right we can write this

583
00:27:13,760 --> 00:27:17,120
as the integral of

584
00:27:18,640 --> 00:27:23,399
one right this is just one by the unit

585
00:27:22,000 --> 00:27:25,760
speed

586
00:27:23,399 --> 00:27:28,480
constraint but you might also recognize

587
00:27:25,760 --> 00:27:31,279
this as the formula for arc length along

588
00:27:28,480 --> 00:27:31,279
the parametric

589
00:27:37,360 --> 00:27:45,600
curve between cell I and cell

590
00:27:41,480 --> 00:27:46,760
J along F and this arc length is

591
00:27:45,600 --> 00:27:50,519
something that we

592
00:27:46,760 --> 00:27:54,600
can get a high quality estimate of for

593
00:27:50,519 --> 00:27:54,600
instance using the shortest

594
00:27:56,120 --> 00:28:02,159
path in a k nearest neighbor graph of

595
00:27:59,720 --> 00:28:02,159
the cell

596
00:28:02,640 --> 00:28:06,200
coordinates with K

597
00:28:07,559 --> 00:28:15,440
small so by using this shortest path we

598
00:28:11,120 --> 00:28:18,840
get a a good estimate of TJ minus TI the

599
00:28:15,440 --> 00:28:21,240
distance between TJ and TI then what's

600
00:28:18,840 --> 00:28:23,320
the final step so we have the distances

601
00:28:21,240 --> 00:28:25,679
between every Point how do we get the

602
00:28:23,320 --> 00:28:27,320
original points back well that's exactly

603
00:28:25,679 --> 00:28:30,600
the problem that multi-dimensional

604
00:28:27,320 --> 00:28:32,840
scaling aims to solve so the final step

605
00:28:30,600 --> 00:28:32,840
then

606
00:28:35,679 --> 00:28:40,840
is multi-dimensional scaling and so I

607
00:28:39,039 --> 00:28:43,120
won't go too much into the details but

608
00:28:40,840 --> 00:28:45,279
basically you take this shortest path

609
00:28:43,120 --> 00:28:48,279
distance Matrix

610
00:28:45,279 --> 00:28:48,279
D

611
00:28:49,320 --> 00:28:56,799
so you transform it in some some simple

612
00:28:52,480 --> 00:28:56,799
way and then the top igen vector

613
00:28:58,880 --> 00:29:06,640
of that distance Matrix D that's your

614
00:29:03,480 --> 00:29:08,799
estimate of T your estimate of the first

615
00:29:06,640 --> 00:29:11,960
morphologically relevant

616
00:29:08,799 --> 00:29:13,760
coordinate um and so I said this is for

617
00:29:11,960 --> 00:29:16,480
the case where the parametric curve is

618
00:29:13,760 --> 00:29:18,880
not joined at the end but

619
00:29:16,480 --> 00:29:23,360
right of course in the example that I

620
00:29:18,880 --> 00:29:23,360
showed it it was a loop um and so for

621
00:29:25,919 --> 00:29:31,080
Loops um the only

622
00:29:28,600 --> 00:29:33,279
differences right um so I won't go too

623
00:29:31,080 --> 00:29:35,159
much in the math but you take the top

624
00:29:33,279 --> 00:29:39,519
two vectors of

625
00:29:35,159 --> 00:29:39,519
D the top two igen

626
00:29:42,600 --> 00:29:46,960
vectors and then you take the arc

627
00:29:44,919 --> 00:29:48,799
tangent of the ratio of the second over

628
00:29:46,960 --> 00:29:53,159
the first so the same way like you do

629
00:29:48,799 --> 00:29:56,440
the conversion from cartisian to

630
00:29:53,159 --> 00:29:56,440
Polar it's

631
00:29:56,559 --> 00:30:01,240
like the AR tangent of the the second

632
00:29:59,080 --> 00:30:04,320
one divided by the the first gives you

633
00:30:01,240 --> 00:30:07,000
back your your estimate of the first

634
00:30:04,320 --> 00:30:10,240
coordinate so that that's how how we get

635
00:30:07,000 --> 00:30:10,240
the the first coordinate

636
00:30:10,519 --> 00:30:16,559
then so how do we get this this second

637
00:30:13,559 --> 00:30:19,200
morphologically relevant coordinate RJ

638
00:30:16,559 --> 00:30:19,200
um

639
00:30:24,200 --> 00:30:28,640
well the basic idea is that it should be

640
00:30:26,600 --> 00:30:31,640
the sign residual

641
00:30:28,640 --> 00:30:31,640
from

642
00:30:32,840 --> 00:30:38,240
uh the the cell's coordinate to its

643
00:30:36,039 --> 00:30:41,240
position on the curve so the magnitude

644
00:30:38,240 --> 00:30:44,120
of RJ that should just be the

645
00:30:41,240 --> 00:30:47,440
distance I'll just write the distance

646
00:30:44,120 --> 00:30:47,440
between the

647
00:30:51,200 --> 00:30:55,519
uh the cell's coordinates and its

648
00:30:53,480 --> 00:30:58,600
position on the

649
00:30:55,519 --> 00:31:04,039
curve and then in order to get the sign

650
00:30:58,600 --> 00:31:08,320
of R subj um so

651
00:31:04,039 --> 00:31:08,320
basically if this is the curve

652
00:31:15,679 --> 00:31:22,440
F you have right some velocity frime of

653
00:31:19,320 --> 00:31:25,679
T then you can just look at a vector

654
00:31:22,440 --> 00:31:29,919
orthogonal to this velocity vector and

655
00:31:25,679 --> 00:31:29,919
then you can look at right

656
00:31:30,120 --> 00:31:35,399
cells on this side could get a positive

657
00:31:32,399 --> 00:31:37,600
sign and cells on that side could get a

658
00:31:35,399 --> 00:31:39,720
negative sign so you just need to to

659
00:31:37,600 --> 00:31:42,200
choose the orientation in order to

660
00:31:39,720 --> 00:31:43,919
assign the sign of this this second

661
00:31:42,200 --> 00:31:45,720
coordinate R

662
00:31:43,919 --> 00:31:47,720
subj

663
00:31:45,720 --> 00:31:51,000
um

664
00:31:47,720 --> 00:31:53,240
okay um and so the final step then is

665
00:31:51,000 --> 00:31:55,240
once you have these two morphologically

666
00:31:53,240 --> 00:31:57,919
relevant coordinates how do you actually

667
00:31:55,240 --> 00:32:00,360
do the what regression model do we

668
00:31:57,919 --> 00:32:03,360
recommend to the spatially variable

669
00:32:00,360 --> 00:32:03,360
genes

670
00:32:06,159 --> 00:32:10,519
well right we call that in gene

671
00:32:08,799 --> 00:32:14,080
expression right we're typically dealing

672
00:32:10,519 --> 00:32:16,720
with count data right so y subg could be

673
00:32:14,080 --> 00:32:19,279
the counts for for G G so we recommend

674
00:32:16,720 --> 00:32:22,600
using a generalized additive

675
00:32:19,279 --> 00:32:25,200
model um so right using a count

676
00:32:22,600 --> 00:32:29,799
distribution to to model the expression

677
00:32:25,200 --> 00:32:29,799
data we choose negative binomial

678
00:32:31,799 --> 00:32:39,799
with Su so the J cell with some

679
00:32:36,440 --> 00:32:39,799
mean some

680
00:32:44,519 --> 00:32:51,440
dispersion and the log of the

681
00:32:48,399 --> 00:32:54,440
mean right is equal to some baseline

682
00:32:51,440 --> 00:32:54,440
expression

683
00:33:00,000 --> 00:33:04,840
plus some two unobserved smooth

684
00:33:03,000 --> 00:33:07,039
functions one of the first

685
00:33:04,840 --> 00:33:09,440
morphologically relevant coordinate and

686
00:33:07,039 --> 00:33:14,039
one of the second morphologically

687
00:33:09,440 --> 00:33:16,000
relevant coordinate and then right so

688
00:33:14,039 --> 00:33:19,360
this model can be fit by standard

689
00:33:16,000 --> 00:33:22,039
methods and now like really all you have

690
00:33:19,360 --> 00:33:26,159
to do is then just extract the estimates

691
00:33:22,039 --> 00:33:29,519
of this function H subg and S subg and

692
00:33:26,159 --> 00:33:29,519
that's like

693
00:33:29,880 --> 00:33:36,480
um that's like what we we drew over here

694
00:33:33,080 --> 00:33:39,600
would be like this would be like h of

695
00:33:36,480 --> 00:33:43,200
G and that would

696
00:33:39,600 --> 00:33:44,200
be would be S of of G Prime for the for

697
00:33:43,200 --> 00:33:48,279
the different

698
00:33:44,200 --> 00:33:51,639
Gene um and

699
00:33:48,279 --> 00:33:53,320
uh yeah and so basically in in our paper

700
00:33:51,639 --> 00:33:55,039
we show that like depending on the

701
00:33:53,320 --> 00:33:57,120
scientific question right you can really

702
00:33:55,039 --> 00:33:59,279
do whatever you want with this model you

703
00:33:57,120 --> 00:34:01,320
can look at summary statistics of the

704
00:33:59,279 --> 00:34:03,320
function to see oh like maybe

705
00:34:01,320 --> 00:34:06,840
Expressions we want to look at genes

706
00:34:03,320 --> 00:34:09,599
that have a very specific shape um or or

707
00:34:06,840 --> 00:34:14,200
whatnot um so it's a very

708
00:34:09,599 --> 00:34:17,119
flexible model that allows you to to

709
00:34:14,200 --> 00:34:21,159
answer partic particular scientific

710
00:34:17,119 --> 00:34:21,159
questions about spatially variable

711
00:34:23,760 --> 00:34:30,240
genes hi so my name is OA and today I

712
00:34:27,960 --> 00:34:32,800
want to talk about uh kind of similar to

713
00:34:30,240 --> 00:34:35,240
Philip also some methods for looking at

714
00:34:32,800 --> 00:34:37,919
spatial gene expression

715
00:34:35,240 --> 00:34:40,480
dat so the way that we can study the

716
00:34:37,919 --> 00:34:42,760
spatial gene expression as Philip had

717
00:34:40,480 --> 00:34:45,399
shown some pictures of before is through

718
00:34:42,760 --> 00:34:47,760
a technology called spatial

719
00:34:45,399 --> 00:34:49,720
transcriptomic and so what this looks

720
00:34:47,760 --> 00:34:52,720
like um kind of laying it out in a

721
00:34:49,720 --> 00:34:55,320
picture is that you have like a tissue

722
00:34:52,720 --> 00:34:57,800
slice maybe it has like a weird shape uh

723
00:34:55,320 --> 00:34:59,400
I'll just draw in this box um and you

724
00:34:57,800 --> 00:35:02,320
should imagine this as like the X and

725
00:34:59,400 --> 00:35:03,920
the Y directions and you have you can

726
00:35:02,320 --> 00:35:06,760
measure different quantities at like

727
00:35:03,920 --> 00:35:08,680
different points in this uh

728
00:35:06,760 --> 00:35:11,119
tissue and so you should you can think

729
00:35:08,680 --> 00:35:13,240
of these for example as like different

730
00:35:11,119 --> 00:35:14,440
uh cells sometimes they might contain

731
00:35:13,240 --> 00:35:15,920
more than one cell but that's not too

732
00:35:14,440 --> 00:35:18,240
important you have a bunch of these

733
00:35:15,920 --> 00:35:20,760
points and what you can measure are two

734
00:35:18,240 --> 00:35:22,920
things one is that you can measure the

735
00:35:20,760 --> 00:35:25,160
coordinates uh kind of these

736
00:35:22,920 --> 00:35:27,680
XY and then the other is that you

737
00:35:25,160 --> 00:35:29,680
measure this uh what's called a gene

738
00:35:27,680 --> 00:35:33,119
ression

739
00:35:29,680 --> 00:35:35,000
Vector which is this High dimensional um

740
00:35:33,119 --> 00:35:37,079
Vector it's not too important what the

741
00:35:35,000 --> 00:35:38,880
kind of quantity is but there's about

742
00:35:37,079 --> 00:35:42,640
let's say like 20,000 different

743
00:35:38,880 --> 00:35:46,119
components so it's very high

744
00:35:42,640 --> 00:35:48,400
dimensional um and

745
00:35:46,119 --> 00:35:50,520
so if you have kind of this data in

746
00:35:48,400 --> 00:35:52,800
space typically in single cell omix as

747
00:35:50,520 --> 00:35:54,440
some of the previous talks looked at you

748
00:35:52,800 --> 00:35:55,920
just have these gene expression vectors

749
00:35:54,440 --> 00:35:58,079
but while now we have these measurements

750
00:35:55,920 --> 00:35:59,440
in space and so one of the very natural

751
00:35:58,079 --> 00:36:01,640
questions that you can ask is if you

752
00:35:59,440 --> 00:36:03,520
have this data how does it vary

753
00:36:01,640 --> 00:36:08,160
spatially um how do these different

754
00:36:03,520 --> 00:36:11,960
genes vary um throughout my tissue and

755
00:36:08,160 --> 00:36:14,520
space and so this is a very kind of

756
00:36:11,960 --> 00:36:15,839
General problem and kind of what I would

757
00:36:14,520 --> 00:36:17,240
say a good way to think about it is you

758
00:36:15,839 --> 00:36:19,240
should think about this in terms of a

759
00:36:17,240 --> 00:36:22,040
function so let's say you have a

760
00:36:19,240 --> 00:36:25,400
function in space this uh F and this

761
00:36:22,040 --> 00:36:30,160
function's Vector value so each uh Point

762
00:36:25,400 --> 00:36:33,119
XY each of these coordinates you measure

763
00:36:30,160 --> 00:36:35,359
um let's say d g different genes each of

764
00:36:33,119 --> 00:36:37,440
these is like a kind of scalar

765
00:36:35,359 --> 00:36:39,040
function and each of these functions

766
00:36:37,440 --> 00:36:41,599
should tell you in practice how your

767
00:36:39,040 --> 00:36:44,319
different genes vary in space and so for

768
00:36:41,599 --> 00:36:46,319
example maybe this is one gene here you

769
00:36:44,319 --> 00:36:48,160
could imagine if I just looked at how

770
00:36:46,319 --> 00:36:52,319
this Gene looks like in space as a

771
00:36:48,160 --> 00:36:52,319
function of X and Y

772
00:36:52,720 --> 00:36:58,240
um maybe this Gene kind of increases in

773
00:36:55,720 --> 00:37:00,319
space and so maybe um

774
00:36:58,240 --> 00:37:02,160
sorry I should have prepared slides I

775
00:37:00,319 --> 00:37:04,240
guess but I'm going to try and draw this

776
00:37:02,160 --> 00:37:06,599
like you have a bunch of these points in

777
00:37:04,240 --> 00:37:08,480
space these are your different cells and

778
00:37:06,599 --> 00:37:11,000
maybe this Gene it's

779
00:37:08,480 --> 00:37:12,760
like it's increasing this direction so

780
00:37:11,000 --> 00:37:15,400
maybe it starts out let's say like it's

781
00:37:12,760 --> 00:37:16,839
10 here it increases to 11 maybe it

782
00:37:15,400 --> 00:37:19,520
increases to sorry these are kind of

783
00:37:16,839 --> 00:37:21,160
hard to see it's like 12's here maybe

784
00:37:19,520 --> 00:37:23,880
there's like a

785
00:37:21,160 --> 00:37:26,839
13 it's like 14 so it's sort of

786
00:37:23,880 --> 00:37:27,920
increasing I'm plotting here F1 of XY

787
00:37:26,839 --> 00:37:30,079
and you can see it's sort of like

788
00:37:27,920 --> 00:37:32,079
increasing sort of in that

789
00:37:30,079 --> 00:37:33,640
direction you can have other spatial

790
00:37:32,079 --> 00:37:34,800
patterns too so maybe I didn't quite

791
00:37:33,640 --> 00:37:38,200
write this out but maybe let's look at

792
00:37:34,800 --> 00:37:40,520
like a separate Gene x uh

793
00:37:38,200 --> 00:37:42,440
F2 maybe this gen has a different

794
00:37:40,520 --> 00:37:44,440
pattern maybe it's kind of decreasing in

795
00:37:42,440 --> 00:37:48,040
this

796
00:37:44,440 --> 00:37:49,920
direction so let's say instead maybe uh

797
00:37:48,040 --> 00:37:52,400
it kind of starts out really high it's

798
00:37:49,920 --> 00:37:54,359
it could be like 99 and it's like maybe

799
00:37:52,400 --> 00:37:56,720
70 I don't know I'm just kind of writing

800
00:37:54,359 --> 00:37:58,319
numbers maybe it's like 50 here and it's

801
00:37:56,720 --> 00:38:02,280
sort of getting small smaller as you go

802
00:37:58,319 --> 00:38:02,280
in this direction it's like 20

803
00:38:03,319 --> 00:38:07,040
here so kind of intuitively at least you

804
00:38:05,880 --> 00:38:09,920
can see that you might have these

805
00:38:07,040 --> 00:38:11,280
different patterns in Space the way that

806
00:38:09,920 --> 00:38:13,560
you can quantify all these different

807
00:38:11,280 --> 00:38:16,680
patterns though is through this uh

808
00:38:13,560 --> 00:38:19,480
through the language of calculus and

809
00:38:16,680 --> 00:38:23,280
namely you model spatial variation in

810
00:38:19,480 --> 00:38:23,280
terms of a something called a spatial

811
00:38:24,000 --> 00:38:28,040
gradient so this spatial gradient is

812
00:38:26,720 --> 00:38:29,720
really just

813
00:38:28,040 --> 00:38:32,200
uh the gradient if you recall from like

814
00:38:29,720 --> 00:38:34,280
multivariable calculus at every point

815
00:38:32,200 --> 00:38:38,560
and so this gradient gives you the

816
00:38:34,280 --> 00:38:40,760
direction of uh maximum

817
00:38:38,560 --> 00:38:43,359
change in your measurements at every

818
00:38:40,760 --> 00:38:45,920
point in space and so for example maybe

819
00:38:43,359 --> 00:38:47,880
for this Gene at this point from 99 to

820
00:38:45,920 --> 00:38:50,560
70 the gradient kind of points in like

821
00:38:47,880 --> 00:38:52,520
this direction because

822
00:38:50,560 --> 00:38:54,480
uh I guess it should be the direction of

823
00:38:52,520 --> 00:38:57,440
Maximum

824
00:38:54,480 --> 00:38:58,880
increase so maybe here uh if you go from

825
00:38:57,440 --> 00:39:02,240
10 it's kind of increasing in this

826
00:38:58,880 --> 00:39:05,560
direction so at kind of this point XY

827
00:39:02,240 --> 00:39:07,800
this gradient Vector this gradient of FG

828
00:39:05,560 --> 00:39:11,040
of I guess this is

829
00:39:07,800 --> 00:39:13,280
F1 points in this direction and if you

830
00:39:11,040 --> 00:39:14,880
plot all of these gradients um at

831
00:39:13,280 --> 00:39:17,000
different points in space you get this

832
00:39:14,880 --> 00:39:20,079
Vector

833
00:39:17,000 --> 00:39:22,000
field and so maybe in this Gene Gene one

834
00:39:20,079 --> 00:39:25,040
this Vector field kind of points in this

835
00:39:22,000 --> 00:39:26,599
direction and this is telling you uh

836
00:39:25,040 --> 00:39:28,599
this Gene is increasing in this

837
00:39:26,599 --> 00:39:30,480
direction maybe for this Gene the

838
00:39:28,599 --> 00:39:32,240
radians kind of point in this opposite

839
00:39:30,480 --> 00:39:34,480
direction because from 70 to 90 is the

840
00:39:32,240 --> 00:39:35,880
direction of increase and so you get a

841
00:39:34,480 --> 00:39:37,880
vector fi that kind of looks like this

842
00:39:35,880 --> 00:39:39,119
instead and you could imagine General

843
00:39:37,880 --> 00:39:40,880
you could have many different types of

844
00:39:39,119 --> 00:39:42,200
vector Fields depending on these

845
00:39:40,880 --> 00:39:43,480
different genes and how they look like

846
00:39:42,200 --> 00:39:46,400
in

847
00:39:43,480 --> 00:39:47,640
space one of the major Challen and so

848
00:39:46,400 --> 00:39:49,160
what you would want to learn are these

849
00:39:47,640 --> 00:39:51,760
different spatial gradients at different

850
00:39:49,160 --> 00:39:54,319
points and space but one of the major

851
00:39:51,760 --> 00:39:56,240
challenges in learning this uh these

852
00:39:54,319 --> 00:39:59,319
gradients is that in most tissues your

853
00:39:56,240 --> 00:39:59,319
data is really

854
00:39:59,480 --> 00:40:04,839
you have like 70% or more zeros at many

855
00:40:02,359 --> 00:40:07,359
points in space and so in practice you

856
00:40:04,839 --> 00:40:10,240
don't get these very nice neat pictures

857
00:40:07,359 --> 00:40:11,880
but um instead your data Maybe looks

858
00:40:10,240 --> 00:40:14,000
like this

859
00:40:11,880 --> 00:40:16,599
where there's just going to be a bunch

860
00:40:14,000 --> 00:40:16,599
of different

861
00:40:18,119 --> 00:40:21,960
zeros maybe I did see a 10 here but

862
00:40:20,640 --> 00:40:24,319
there's like a zero here instead and a

863
00:40:21,960 --> 00:40:27,319
zero here maybe there's a zero here and

864
00:40:24,319 --> 00:40:31,319
it's like a 12 a zero it's like most

865
00:40:27,319 --> 00:40:33,520
most Zer and like maybe for this gen um

866
00:40:31,319 --> 00:40:36,359
I also don't see all of these like kind

867
00:40:33,520 --> 00:40:36,359
of nice large

868
00:40:36,560 --> 00:40:40,960
measurements instead maybe for this Gene

869
00:40:38,960 --> 00:40:43,520
it's like I saw this 90 down here but

870
00:40:40,960 --> 00:40:47,200
there's another zero maybe this was like

871
00:40:43,520 --> 00:40:51,079
I forget the numbers I put 70 I

872
00:40:47,200 --> 00:40:52,440
think 30 I I don't remember but now when

873
00:40:51,079 --> 00:40:54,359
you have all this data with many

874
00:40:52,440 --> 00:40:55,960
different zeros it's very hard to tell

875
00:40:54,359 --> 00:40:57,839
what direction should these gradients be

876
00:40:55,960 --> 00:40:59,560
pointing in because here looks like it's

877
00:40:57,839 --> 00:41:01,880
increasing from 0 to 20 so it's the

878
00:40:59,560 --> 00:41:04,280
gradient pointing this way um maybe it

879
00:41:01,880 --> 00:41:05,920
should be pointing that way in general

880
00:41:04,280 --> 00:41:08,079
learning these gradients kind of hard or

881
00:41:05,920 --> 00:41:12,040
very impossible if you have very sparse

882
00:41:08,079 --> 00:41:14,599
or general like low um dynamic range

883
00:41:12,040 --> 00:41:16,880
data and so over the last several years

884
00:41:14,599 --> 00:41:18,640
we've kind of found that even though

885
00:41:16,880 --> 00:41:21,040
learning each of these gradients these

886
00:41:18,640 --> 00:41:23,599
like this measure spatial variation can

887
00:41:21,040 --> 00:41:25,119
be very hard for individual genes if you

888
00:41:23,599 --> 00:41:27,920
actually place a few geometric

889
00:41:25,119 --> 00:41:30,440
assumptions on these function these

890
00:41:27,920 --> 00:41:34,079
gradients then you can learn them um

891
00:41:30,440 --> 00:41:34,079
even from highly sparse spatial

892
00:41:35,040 --> 00:41:39,240
data and so I'll briefly describe some

893
00:41:37,920 --> 00:41:41,800
of these

894
00:41:39,240 --> 00:41:45,160
assumptions and so the first assumption

895
00:41:41,800 --> 00:41:50,000
that uh we make is that for each

896
00:41:45,160 --> 00:41:52,040
gene uh all genes share the same uh

897
00:41:50,000 --> 00:41:53,960
directions of these

898
00:41:52,040 --> 00:41:55,359
gradients and so if you imagine what

899
00:41:53,960 --> 00:41:57,480
this looks like in your tissue you have

900
00:41:55,359 --> 00:42:00,839
a point XY

901
00:41:57,480 --> 00:42:04,200
maybe Gene one kind of

902
00:42:00,839 --> 00:42:05,880
points in this direction maybe Gene 2

903
00:42:04,200 --> 00:42:07,720
kind of like looking at this that tissue

904
00:42:05,880 --> 00:42:09,119
for example you have a gradient that

905
00:42:07,720 --> 00:42:11,839
points in the opposite direction but

906
00:42:09,119 --> 00:42:15,720
like kind of in the same plane maybe a

907
00:42:11,839 --> 00:42:15,720
third Gene Gene 3

908
00:42:16,560 --> 00:42:22,520
uh maybe Gene three points like also in

909
00:42:20,599 --> 00:42:25,280
the same direction but we assume that

910
00:42:22,520 --> 00:42:27,200
they all point in like the same 1D plane

911
00:42:25,280 --> 00:42:30,160
and that in fact there's a single vector

912
00:42:27,200 --> 00:42:33,200
field uh capital V that's shared by all

913
00:42:30,160 --> 00:42:34,760
genes and so you can write this out um

914
00:42:33,200 --> 00:42:37,559
as the gradients for each gene are

915
00:42:34,760 --> 00:42:40,319
proportional to a single Vector field

916
00:42:37,559 --> 00:42:42,880
this like shared Vector

917
00:42:40,319 --> 00:42:44,280
fi and then the second assumption is you

918
00:42:42,880 --> 00:42:46,000
also have to place some assumptions on

919
00:42:44,280 --> 00:42:48,839
what this specific Vector field looks

920
00:42:46,000 --> 00:42:51,040
like and so kind of motivated by

921
00:42:48,839 --> 00:42:52,359
physical applications we assume this

922
00:42:51,040 --> 00:42:55,319
that this Vector field is something

923
00:42:52,359 --> 00:42:56,960
called a conservative Vector field which

924
00:42:55,319 --> 00:42:58,119
again these are kind of maybe Notions

925
00:42:56,960 --> 00:43:00,400
that at least I forgot from

926
00:42:58,119 --> 00:43:01,960
multivariable calculus and what this

927
00:43:00,400 --> 00:43:04,520
means is that this Vector field doesn't

928
00:43:01,960 --> 00:43:06,319
really curl around its space and so you

929
00:43:04,520 --> 00:43:08,480
can't really have a case where your

930
00:43:06,319 --> 00:43:10,000
vector field sort of looks like this

931
00:43:08,480 --> 00:43:12,240
like you can't have it like loop around

932
00:43:10,000 --> 00:43:14,720
in space intuitively maybe that makes

933
00:43:12,240 --> 00:43:16,240
sense because if your gene expression is

934
00:43:14,720 --> 00:43:18,200
kind of increasing in a loop it should

935
00:43:16,240 --> 00:43:20,040
like increase forever that's kind of a

936
00:43:18,200 --> 00:43:22,720
case that we don't really

937
00:43:20,040 --> 00:43:24,880
want it turns out um this is equivalent

938
00:43:22,720 --> 00:43:27,680
to actually a different assumption that

939
00:43:24,880 --> 00:43:29,359
this Vector field is the uh sorry this

940
00:43:27,680 --> 00:43:33,559
is again a bunch of calculus but this

941
00:43:29,359 --> 00:43:33,559
Vector field is the gradient of a scalar

942
00:43:34,359 --> 00:43:38,440
function and in physics this kind of

943
00:43:36,720 --> 00:43:41,960
function is sometimes called a potential

944
00:43:38,440 --> 00:43:43,680
function so for example you have like uh

945
00:43:41,960 --> 00:43:45,440
gravitational potential which is like

946
00:43:43,680 --> 00:43:47,359
your height um there's electric

947
00:43:45,440 --> 00:43:49,880
potential and here you can think of this

948
00:43:47,359 --> 00:43:52,280
as maybe like a gene expression

949
00:43:49,880 --> 00:43:53,359
potential and the nice thing here

950
00:43:52,280 --> 00:43:55,400
actually is that under these two

951
00:43:53,359 --> 00:43:57,599
assumptions you can actually show that

952
00:43:55,400 --> 00:44:00,920
your gene expression

953
00:43:57,599 --> 00:44:03,599
which um is a function of these two

954
00:44:00,920 --> 00:44:05,280
spatial coordinates X and Y it'll really

955
00:44:03,599 --> 00:44:07,440
be a function of a single spatial

956
00:44:05,280 --> 00:44:09,480
coordinate this potential function D of

957
00:44:07,440 --> 00:44:11,000
XY so here you have this kind of

958
00:44:09,480 --> 00:44:14,800
dimensionality reduction where you start

959
00:44:11,000 --> 00:44:16,520
with two coordinates XY and then you

960
00:44:14,800 --> 00:44:18,400
place some mild assumptions and you get

961
00:44:16,520 --> 00:44:20,720
this single

962
00:44:18,400 --> 00:44:23,720
uh uh coordinate that describes your

963
00:44:20,720 --> 00:44:28,280
gene expression sorry this is kind of

964
00:44:23,720 --> 00:44:31,599
the extent at which I can write but um

965
00:44:28,280 --> 00:44:33,000
and so what's nice then is that I guess

966
00:44:31,599 --> 00:44:35,160
once you have everything in terms of a

967
00:44:33,000 --> 00:44:37,800
single spatial function it allows you to

968
00:44:35,160 --> 00:44:39,720
aggregate measurements across space and

969
00:44:37,800 --> 00:44:43,160
so for example maybe this potential

970
00:44:39,720 --> 00:44:44,520
function Let's uh of use this like Gene

971
00:44:43,160 --> 00:44:46,599
maybe this potential function looks like

972
00:44:44,520 --> 00:44:49,280
this it's like zero here maybe it's like

973
00:44:46,599 --> 00:44:50,640
one here it's two it's like increasing

974
00:44:49,280 --> 00:44:52,640
in this

975
00:44:50,640 --> 00:44:54,640
direction then what you have are you

976
00:44:52,640 --> 00:44:56,760
have these like different Contours so

977
00:44:54,640 --> 00:44:59,240
this might be the line D equals Zer this

978
00:44:56,760 --> 00:45:03,400
is the the line D equal 1 this the line

979
00:44:59,240 --> 00:45:05,319
D equals 2 and by writing expression in

980
00:45:03,400 --> 00:45:07,240
kind of your function as a function of

981
00:45:05,319 --> 00:45:08,680
the single spatial coordinate you can

982
00:45:07,240 --> 00:45:10,160
aggregate gene expression your

983
00:45:08,680 --> 00:45:14,040
measurements across these different

984
00:45:10,160 --> 00:45:16,040
contour lines and so for example here we

985
00:45:14,040 --> 00:45:17,599
have a bunch of zeros but if you like

986
00:45:16,040 --> 00:45:20,040
aggregate gene expression along these

987
00:45:17,599 --> 00:45:21,880
different contour lines and you sort of

988
00:45:20,040 --> 00:45:24,319
visualize how gene expression varies as

989
00:45:21,880 --> 00:45:26,760
a function of this potential it's very

990
00:45:24,319 --> 00:45:28,800
sparse in 2D but if you look in 1D you

991
00:45:26,760 --> 00:45:34,119
might see that gene expression if this

992
00:45:28,800 --> 00:45:34,119
is like 0 one two maybe it kind of looks

993
00:45:34,480 --> 00:45:39,240
like uh it's like decreasing in space

994
00:45:37,800 --> 00:45:40,880
and so you can visualize this kind of

995
00:45:39,240 --> 00:45:42,640
like pattern this would be like a

996
00:45:40,880 --> 00:45:46,280
negative gradient and maybe for this

997
00:45:42,640 --> 00:45:48,440
Gene instead it looks like this

998
00:45:46,280 --> 00:45:50,200
instead and it lets you visualize these

999
00:45:48,440 --> 00:45:53,880
different gradient

1000
00:45:50,200 --> 00:45:55,480
directions um and so finally you might

1001
00:45:53,880 --> 00:45:59,400
ask how can you actually learn this kind

1002
00:45:55,480 --> 00:46:00,880
of potential function from data and over

1003
00:45:59,400 --> 00:46:02,480
the past several years we've worked on a

1004
00:46:00,880 --> 00:46:05,200
couple different approaches to learn

1005
00:46:02,480 --> 00:46:06,559
this uh this potential function run out

1006
00:46:05,200 --> 00:46:08,480
of space but

1007
00:46:06,559 --> 00:46:12,359
uh kind of

1008
00:46:08,480 --> 00:46:15,079
here and so kind of in a paper from

1009
00:46:12,359 --> 00:46:17,040
2022 a couple years ago we first

1010
00:46:15,079 --> 00:46:19,480
developed a supervised approach to learn

1011
00:46:17,040 --> 00:46:21,200
this function D where we modeled it uh

1012
00:46:19,480 --> 00:46:23,520
using the heat equation so you can think

1013
00:46:21,200 --> 00:46:25,160
of this as potential function as sort of

1014
00:46:23,520 --> 00:46:27,720
measuring a heat potential in your

1015
00:46:25,160 --> 00:46:30,319
tissue and then more recently um this

1016
00:46:27,720 --> 00:46:31,480
was an algorithm for a layered tissue so

1017
00:46:30,319 --> 00:46:33,240
we called it the layer because it's

1018
00:46:31,480 --> 00:46:35,960
supposed to be a plan words on rock

1019
00:46:33,240 --> 00:46:38,240
climbing um and then more recently we

1020
00:46:35,960 --> 00:46:41,079
developed an unsupervised approach uh

1021
00:46:38,240 --> 00:46:43,079
using deep learning where the idea is

1022
00:46:41,079 --> 00:46:45,599
that if you parameterize these two

1023
00:46:43,079 --> 00:46:47,720
functions with neural networks it turns

1024
00:46:45,599 --> 00:46:49,480
out to be equivalent to training a

1025
00:46:47,720 --> 00:46:51,960
neural network on your data that has a

1026
00:46:49,480 --> 00:46:53,880
very specific form where the input is

1027
00:46:51,960 --> 00:46:56,000
spatial

1028
00:46:53,880 --> 00:46:58,839
coordinates the output is your gene

1029
00:46:56,000 --> 00:46:58,839
expression

1030
00:47:00,119 --> 00:47:03,520
and then there's a hidden layer in the

1031
00:47:01,680 --> 00:47:05,599
middle and maybe a bunch of like other

1032
00:47:03,520 --> 00:47:07,319
hidden layers but there's like one

1033
00:47:05,599 --> 00:47:09,559
hidden layer in the middle that has a

1034
00:47:07,319 --> 00:47:12,040
single node and this single node is your

1035
00:47:09,559 --> 00:47:12,040
potential

1036
00:47:14,079 --> 00:47:18,839
function and so yeah this is this kind

1037
00:47:16,839 --> 00:47:20,640
of General framework we set up and we

1038
00:47:18,839 --> 00:47:22,160
looking at many different uh extensions

1039
00:47:20,640 --> 00:47:23,720
for example relaxing these two

1040
00:47:22,160 --> 00:47:26,440
assumptions so you can find multiple

1041
00:47:23,720 --> 00:47:28,599
coordinates multiple gradient directions

1042
00:47:26,440 --> 00:47:29,760
uh you can also relax the assumption

1043
00:47:28,599 --> 00:47:31,400
that maybe this Vector field doesn't

1044
00:47:29,760 --> 00:47:34,920
have to be conservative maybe it doesn't

1045
00:47:31,400 --> 00:47:36,200
have to vary continuously in space um

1046
00:47:34,920 --> 00:47:39,960
but yeah this is kind of General

1047
00:47:36,200 --> 00:47:41,559
framework and we called this uh gene

1048
00:47:39,960 --> 00:47:44,079
expression

1049
00:47:41,559 --> 00:47:46,440
topography because one example of this

1050
00:47:44,079 --> 00:47:48,359
potential function is height and in

1051
00:47:46,440 --> 00:47:50,520
topographic maps you often see like

1052
00:47:48,359 --> 00:47:51,880
height in space and so if you look at

1053
00:47:50,520 --> 00:47:53,520
these kind of maps with these different

1054
00:47:51,880 --> 00:47:55,240
Contours they kind of if you like squint

1055
00:47:53,520 --> 00:47:56,880
your eyes maybe they kind of look like

1056
00:47:55,240 --> 00:48:00,319
topographic maps for example when you're

1057
00:47:56,880 --> 00:48:00,319
going hike it


1
00:00:00,719 --> 00:00:06,120
good morning everyone welcome to today's

2
00:00:03,399 --> 00:00:09,320
MPG primer and also welcome back to MPG

3
00:00:06,120 --> 00:00:12,519
after the lovely and all still cold and

4
00:00:09,320 --> 00:00:14,960
snowy fall uh winter break so Dr Hillary

5
00:00:12,519 --> 00:00:17,119
fukin is a distinguished statistical

6
00:00:14,960 --> 00:00:19,359
geneticist renowned for her Innovative

7
00:00:17,119 --> 00:00:22,519
work in understanding the genetic basis

8
00:00:19,359 --> 00:00:24,320
of complex traits and diseases Hillary

9
00:00:22,519 --> 00:00:27,000
is an assistant professor at Harvard

10
00:00:24,320 --> 00:00:29,080
Medical School and Massachusetts General

11
00:00:27,000 --> 00:00:30,800
Hospital as well as an associate member

12
00:00:29,080 --> 00:00:33,440
of the broo in

13
00:00:30,800 --> 00:00:35,120
Institute Hillary earned her PhD in

14
00:00:33,440 --> 00:00:37,719
Applied Mathematics at

15
00:00:35,120 --> 00:00:39,800
Mat did I say MIT I don't know what I

16
00:00:37,719 --> 00:00:42,520
said before where she was supported by a

17
00:00:39,800 --> 00:00:44,719
prestigious Herz Foundation Fellowship

18
00:00:42,520 --> 00:00:46,520
Hillary also holds a Masters of Science

19
00:00:44,719 --> 00:00:48,680
in theoretical computer science from The

20
00:00:46,520 --> 00:00:50,800
wisman Institute of Science and a

21
00:00:48,680 --> 00:00:53,600
Bachelor of Arts and Mathematics from

22
00:00:50,800 --> 00:00:55,520
Harvard among her many honors she is a

23
00:00:53,600 --> 00:00:57,920
recipient of the National Institutes of

24
00:00:55,520 --> 00:01:01,480
Health director's early Independence

25
00:00:57,920 --> 00:01:03,359
award the fukan lab develops and applies

26
00:01:01,480 --> 00:01:06,119
novel statistical and computational

27
00:01:03,359 --> 00:01:08,360
methods to integrate genetic molecular

28
00:01:06,119 --> 00:01:10,320
and functional data to elucidate how

29
00:01:08,360 --> 00:01:12,640
genetic variation contributes to disease

30
00:01:10,320 --> 00:01:14,119
risk and thereby enance our

31
00:01:12,640 --> 00:01:16,159
understanding of human health and

32
00:01:14,119 --> 00:01:18,600
disease Hillary has said that you can

33
00:01:16,159 --> 00:01:20,200
take um questions she'll take questions

34
00:01:18,600 --> 00:01:21,720
throughout the talk and also what's

35
00:01:20,200 --> 00:01:25,200
really interesting about her talk today

36
00:01:21,720 --> 00:01:26,640
it's going to be a chalk talk um so this

37
00:01:25,200 --> 00:01:28,680
is something we're kind of demoing out

38
00:01:26,640 --> 00:01:31,360
with Hillary and if if please give us

39
00:01:28,680 --> 00:01:33,240
your feedback um after the talk or later

40
00:01:31,360 --> 00:01:35,119
in the year about what you thought of

41
00:01:33,240 --> 00:01:38,119
this different way to engage with the

42
00:01:35,119 --> 00:01:40,600
material all right take it away Hillary

43
00:01:38,119 --> 00:01:42,920
thanks so much Nico

44
00:01:40,600 --> 00:01:46,000
um all

45
00:01:42,920 --> 00:01:49,399
right um hi everyone I'm looking forward

46
00:01:46,000 --> 00:01:52,200
to uh uh trying out this uh talk format

47
00:01:49,399 --> 00:01:56,600
um and is there could we do the screen

48
00:01:52,200 --> 00:01:59,920
awesome okay great um so um my plan

49
00:01:56,600 --> 00:02:01,320
today is not to go deep on any one topic

50
00:01:59,920 --> 00:02:02,799
I think most everything that I'm going

51
00:02:01,320 --> 00:02:04,640
to touch on there's a separate primer

52
00:02:02,799 --> 00:02:06,799
that actually goes deep but my goal

53
00:02:04,640 --> 00:02:08,039
instead is to kind of give an overview

54
00:02:06,799 --> 00:02:10,959
that shows how these different things

55
00:02:08,039 --> 00:02:12,959
are connected and um is kind of like a

56
00:02:10,959 --> 00:02:14,480
framework that and my experience has

57
00:02:12,959 --> 00:02:15,560
really helped clarify some things that

58
00:02:14,480 --> 00:02:17,040
feel like they're really sticky

59
00:02:15,560 --> 00:02:18,800
technical stuff when actually if you

60
00:02:17,040 --> 00:02:20,280
kind of back up and write down the model

61
00:02:18,800 --> 00:02:24,000
then things uh tend to make a lot more

62
00:02:20,280 --> 00:02:25,720
sense um and so what are oh and and like

63
00:02:24,000 --> 00:02:27,239
Nicole said please do ask questions even

64
00:02:25,720 --> 00:02:28,680
if it's just like oh I didn't understand

65
00:02:27,239 --> 00:02:30,560
can you say that again I think this

66
00:02:28,680 --> 00:02:34,239
group is um small enough that that you

67
00:02:30,560 --> 00:02:38,959
can just raise your hand and ask um okay

68
00:02:34,239 --> 00:02:38,959
so what are we going to talk about today

69
00:02:40,040 --> 00:02:46,680
um so today what we're going to talk

70
00:02:42,560 --> 00:02:50,480
about is what are uses of

71
00:02:46,680 --> 00:02:58,400
models of the

72
00:02:50,480 --> 00:03:01,840
form y i = Su over J and S x i j beta J

73
00:02:58,400 --> 00:03:01,840
plus Epsilon I

74
00:03:02,560 --> 00:03:07,680
where Yi is the

75
00:03:08,120 --> 00:03:17,920
phenotype of an

76
00:03:11,239 --> 00:03:21,840
individual I um x i j is the

77
00:03:17,920 --> 00:03:24,879
genotype of individual I

78
00:03:21,840 --> 00:03:30,000
at a variant

79
00:03:24,879 --> 00:03:31,640
J um beta J is the

80
00:03:30,000 --> 00:03:34,040
effect

81
00:03:31,640 --> 00:03:36,360
size

82
00:03:34,040 --> 00:03:41,120
variant

83
00:03:36,360 --> 00:03:46,599
j s is a set

84
00:03:41,120 --> 00:03:48,640
of variance and Epsilon I is a

85
00:03:46,599 --> 00:03:49,959
residual one thing I like about Chalk

86
00:03:48,640 --> 00:03:51,439
Talks by the way is they take the pace

87
00:03:49,959 --> 00:03:52,680
down a little bit and then that gives

88
00:03:51,439 --> 00:03:54,159
everybody a chance to kind of think

89
00:03:52,680 --> 00:03:58,120
about what it is that they find uh

90
00:03:54,159 --> 00:04:01,720
confusing um so first I'm going to make

91
00:03:58,120 --> 00:04:04,000
one um note about this so and that's

92
00:04:01,720 --> 00:04:06,840
that this crucially this is kind of one

93
00:04:04,000 --> 00:04:10,920
of the main punchlines of today this

94
00:04:06,840 --> 00:04:13,040
depends on the set s so if we're going

95
00:04:10,920 --> 00:04:14,360
to write down a linear model so so to

96
00:04:13,040 --> 00:04:16,639
give kind of an overview of what I'm

97
00:04:14,360 --> 00:04:19,359
about to say this kind of model shows up

98
00:04:16,639 --> 00:04:22,240
in a lot of places so if s just has one

99
00:04:19,359 --> 00:04:25,000
snip and you're fitting a like one model

100
00:04:22,240 --> 00:04:27,120
separately for every single snip um then

101
00:04:25,000 --> 00:04:28,919
beta J this is no sampling noise no

102
00:04:27,120 --> 00:04:30,000
error anything the true beta J that

103
00:04:28,919 --> 00:04:32,600
you're trying to estimate is the

104
00:04:30,000 --> 00:04:34,759
marginal effect size um and so for

105
00:04:32,600 --> 00:04:36,800
example if snip J is an LD with some

106
00:04:34,759 --> 00:04:38,880
other snip and that other snip is causal

107
00:04:36,800 --> 00:04:40,960
and snip J is not causal the true beta

108
00:04:38,880 --> 00:04:43,000
is still going to be nonzero on the

109
00:04:40,960 --> 00:04:45,000
other hand if you have a really dense

110
00:04:43,000 --> 00:04:47,880
set of snips that's got every possible

111
00:04:45,000 --> 00:04:49,400
variant in some Locus uh then you can

112
00:04:47,880 --> 00:04:51,199
under you know some extra assumptions

113
00:04:49,400 --> 00:04:53,440
start to interpret beta J as true causal

114
00:04:51,199 --> 00:04:55,880
effect sizes um maybe you're doing

115
00:04:53,440 --> 00:04:58,080
polygenic risk uh prediction using a

116
00:04:55,880 --> 00:05:01,680
model that's something like this uh

117
00:04:58,080 --> 00:05:03,039
which uh how how you choose to um

118
00:05:01,680 --> 00:05:05,639
incorporate effect sizes is going to

119
00:05:03,039 --> 00:05:09,479
depend a lot on whether you've LD pruned

120
00:05:05,639 --> 00:05:11,919
for example or have not LD pruned um so

121
00:05:09,479 --> 00:05:13,240
uh what this model is telling us and

122
00:05:11,919 --> 00:05:14,680
specifically what the effect sizes in

123
00:05:13,240 --> 00:05:16,600
the model are is going to entirely

124
00:05:14,680 --> 00:05:19,720
depend on what set we put there because

125
00:05:16,600 --> 00:05:20,919
um these are joint joint effect sizes um

126
00:05:19,720 --> 00:05:24,479
I'm also going to put a couple of

127
00:05:20,919 --> 00:05:25,840
assumptions down um yeah or notes I

128
00:05:24,479 --> 00:05:30,440
guess

129
00:05:25,840 --> 00:05:33,360
um so I'm only going to talk today about

130
00:05:30,440 --> 00:05:36,039
um quantitative traits so you can think

131
00:05:33,360 --> 00:05:37,680
of height as an example um a lot of the

132
00:05:36,039 --> 00:05:40,240
methods that work for quantitative

133
00:05:37,680 --> 00:05:43,400
traits really directly carry over to

134
00:05:40,240 --> 00:05:46,919
disease um and other case control traits

135
00:05:43,400 --> 00:05:48,520
uh this um I have come to appreciate

136
00:05:46,919 --> 00:05:50,520
that this is in some ways specific to

137
00:05:48,520 --> 00:05:52,319
this thing where we're working with uh

138
00:05:50,520 --> 00:05:53,919
um common diseases and complex traits

139
00:05:52,319 --> 00:05:56,039
because our effect sizes tend to be

140
00:05:53,919 --> 00:05:57,560
pretty small and so a lot of you know

141
00:05:56,039 --> 00:06:00,319
there have been some derivations of why

142
00:05:57,560 --> 00:06:02,160
it's okay to pretend like our binary

143
00:06:00,319 --> 00:06:04,000
traits are continuous um and usually

144
00:06:02,160 --> 00:06:06,120
there's a a tailor approximation that

145
00:06:04,000 --> 00:06:07,440
works really well um somewhere in there

146
00:06:06,120 --> 00:06:08,639
and tailor approximations work really

147
00:06:07,440 --> 00:06:10,479
well when your effect sizes are really

148
00:06:08,639 --> 00:06:11,400
small so that's kind of intuitively why

149
00:06:10,479 --> 00:06:13,319
I'm going to only talk about

150
00:06:11,400 --> 00:06:14,680
quantitative traits but why basically

151
00:06:13,319 --> 00:06:17,080
every method I'm going to write down has

152
00:06:14,680 --> 00:06:19,319
been applied very successfully um for

153
00:06:17,080 --> 00:06:20,759
case control traits um and then the

154
00:06:19,319 --> 00:06:23,919
other thing is just for Simplicity I'm

155
00:06:20,759 --> 00:06:27,560
going to Omit covariates

156
00:06:23,919 --> 00:06:29,160
um uh in practice when this uh um

157
00:06:27,560 --> 00:06:31,400
actually gets used then you know there's

158
00:06:29,160 --> 00:06:35,000
a bunch of Co variates here um age and

159
00:06:31,400 --> 00:06:36,120
sex and an An ancestry and so forth um

160
00:06:35,000 --> 00:06:40,319
but just for Simplicity I'm not going to

161
00:06:36,120 --> 00:06:42,360
write those down okay um so my plan is

162
00:06:40,319 --> 00:06:43,759
um to talk about there's five more

163
00:06:42,360 --> 00:06:47,080
panels on this board I'm going to talk

164
00:06:43,759 --> 00:06:49,720
about five uh uh instantiations of this

165
00:06:47,080 --> 00:06:53,319
model um to kind of emphasize the

166
00:06:49,720 --> 00:06:55,160
differences and how um this exact same

167
00:06:53,319 --> 00:06:57,599
basic equation can be useful for all of

168
00:06:55,160 --> 00:07:00,560
these different things okay so to start

169
00:06:57,599 --> 00:07:04,240
with let's talk about um

170
00:07:00,560 --> 00:07:04,240
basic Association

171
00:07:05,080 --> 00:07:14,360
mapping IE i e

172
00:07:09,440 --> 00:07:15,919
g um okay so what's the goal here as I

173
00:07:14,360 --> 00:07:17,319
said earlier the goal is not to identify

174
00:07:15,919 --> 00:07:19,000
the causal variance the goal is to

175
00:07:17,319 --> 00:07:21,720
identify regions of the genome that are

176
00:07:19,000 --> 00:07:24,199
associated to a phenotype um so let me

177
00:07:21,720 --> 00:07:25,919
write that down

178
00:07:24,199 --> 00:07:31,319
identify

179
00:07:25,919 --> 00:07:31,319
regions of the genome

180
00:07:35,879 --> 00:07:40,800
Associated

181
00:07:37,400 --> 00:07:43,800
typ and what's our particular

182
00:07:40,800 --> 00:07:45,840
instantiation of this model um well as I

183
00:07:43,800 --> 00:07:50,919
said before there's no summation we're

184
00:07:45,840 --> 00:07:53,479
just going to say x i j beta J um plus

185
00:07:50,919 --> 00:07:56,919
Epsilon I um and there's going to be a

186
00:07:53,479 --> 00:07:58,879
different model for every snip um and

187
00:07:56,919 --> 00:07:59,960
what are we interested in when we do

188
00:07:58,879 --> 00:08:02,319
this

189
00:07:59,960 --> 00:08:04,639
uh so you can think of this is

190
00:08:02,319 --> 00:08:05,840
um when we fit this model what is the

191
00:08:04,639 --> 00:08:08,520
thing that we actually care about and

192
00:08:05,840 --> 00:08:10,560
that we want to be well calibrated um

193
00:08:08,520 --> 00:08:15,360
and for the most part what we care about

194
00:08:10,560 --> 00:08:21,120
is um a P value for the null

195
00:08:15,360 --> 00:08:24,159
hypothesis the beta J is zero um and so

196
00:08:21,120 --> 00:08:31,039
the intuition there is

197
00:08:24,159 --> 00:08:31,039
um is there a causal variant

198
00:08:32,320 --> 00:08:37,000
n

199
00:08:34,000 --> 00:08:37,000
LD

200
00:08:37,599 --> 00:08:42,839
with variant

201
00:08:39,880 --> 00:08:47,399
J

202
00:08:42,839 --> 00:08:47,399
um we also are often

203
00:08:48,440 --> 00:08:54,040
um uh uh interested in in um uh

204
00:08:51,880 --> 00:08:58,279
estimates of the marginal effect size of

205
00:08:54,040 --> 00:09:00,440
SJ um so let me see if there's any other

206
00:08:58,279 --> 00:09:03,399
notes about that yeah so I think that

207
00:09:00,440 --> 00:09:06,720
that's um in a gwas what we do is we go

208
00:09:03,399 --> 00:09:08,839
one step at a time we fit this model um

209
00:09:06,720 --> 00:09:11,680
and then we look for for p values that

210
00:09:08,839 --> 00:09:14,680
are significant after multiple testing

211
00:09:11,680 --> 00:09:18,440
um one thing that I'll mention is that

212
00:09:14,680 --> 00:09:20,160
the set of um results from a gwas are

213
00:09:18,440 --> 00:09:21,839
often referred to as summary statistics

214
00:09:20,160 --> 00:09:23,040
I'll come back to this later in the talk

215
00:09:21,839 --> 00:09:25,040
but a lot of the methods that we're

216
00:09:23,040 --> 00:09:27,200
using for fine mapping or for

217
00:09:25,040 --> 00:09:29,440
heritability estimation of various sorts

218
00:09:27,200 --> 00:09:33,519
or for risk prediction can be done using

219
00:09:29,440 --> 00:09:36,640
um summary statistics um that's right

220
00:09:33,519 --> 00:09:36,640
okay so now let's talk about

221
00:09:36,959 --> 00:09:43,079
methods and there's two uh two general

222
00:09:40,240 --> 00:09:45,920
categories of methods here in one case

223
00:09:43,079 --> 00:09:48,600
we have uh actually I'm going to make

224
00:09:45,920 --> 00:09:48,600
this the vector

225
00:09:51,680 --> 00:09:56,240
Epsilon so and

226
00:10:01,600 --> 00:10:04,920
so I haven't um specifically talked

227
00:10:03,800 --> 00:10:06,839
about what the distribution of this

228
00:10:04,920 --> 00:10:08,680
residual is and in the simplest case

229
00:10:06,839 --> 00:10:10,200
we're just going to assume that it's IID

230
00:10:08,680 --> 00:10:11,920
normal for all individuals so this is

231
00:10:10,200 --> 00:10:14,360
kind of this most standard linear

232
00:10:11,920 --> 00:10:17,800
regression that you could do um in this

233
00:10:14,360 --> 00:10:21,000
case we'll just do ordinary least

234
00:10:17,800 --> 00:10:22,320
squares um and then there's another

235
00:10:21,000 --> 00:10:25,360
family of

236
00:10:22,320 --> 00:10:30,240
methods in which you make a different

237
00:10:25,360 --> 00:10:30,240
assumption now you have two components

238
00:10:42,480 --> 00:10:47,680
um um so if we want to instead assume

239
00:10:45,639 --> 00:10:49,160
that our residuals can be correlated

240
00:10:47,680 --> 00:10:50,480
across individuals and that those

241
00:10:49,160 --> 00:10:52,440
correlations are reflected in a

242
00:10:50,480 --> 00:10:58,399
relatedness matrix then now we're

243
00:10:52,440 --> 00:10:58,399
talking about um um linear mixed models

244
00:11:00,959 --> 00:11:05,320
and there's been a whole lot of work on

245
00:11:02,040 --> 00:11:07,399
linear mixed models and um how to uh

246
00:11:05,320 --> 00:11:09,200
first of all estimate these parameters

247
00:11:07,399 --> 00:11:12,120
then how to estimate the parameters in a

248
00:11:09,200 --> 00:11:13,839
way that uh increases your power and

249
00:11:12,120 --> 00:11:15,800
then how to estimate them in a

250
00:11:13,839 --> 00:11:18,200
computationally efficient way so this is

251
00:11:15,800 --> 00:11:19,560
kind of an interesting subfield because

252
00:11:18,200 --> 00:11:22,839
the problem gets so much harder once you

253
00:11:19,560 --> 00:11:24,680
make it complicated in this way um so

254
00:11:22,839 --> 00:11:27,440
that's all I'm going to say about jwas

255
00:11:24,680 --> 00:11:28,959
um for for this per for these purposes

256
00:11:27,440 --> 00:11:31,200
um and maybe I'll pause before I move on

257
00:11:28,959 --> 00:11:34,160
to um the next section and ask if

258
00:11:31,200 --> 00:11:34,160
there's any questions so

259
00:11:37,120 --> 00:11:40,120
far

260
00:11:42,079 --> 00:11:47,480
yes yeah so there's been a lot of work

261
00:11:45,360 --> 00:11:51,560
on that one common thing to do is

262
00:11:47,480 --> 00:11:53,000
inverse rank transform it um where I

263
00:11:51,560 --> 00:11:54,839
guess there's a couple of ways to think

264
00:11:53,000 --> 00:11:56,959
about this one way to think about it is

265
00:11:54,839 --> 00:11:58,800
that there's some true underlying

266
00:11:56,959 --> 00:12:00,079
heritable trait that's normally

267
00:11:58,800 --> 00:12:01,760
distribut and that that got

268
00:12:00,079 --> 00:12:03,920
monotonically transformed to give you

269
00:12:01,760 --> 00:12:06,320
some weird distribution and so then you

270
00:12:03,920 --> 00:12:08,959
can recover this original uh you know

271
00:12:06,320 --> 00:12:10,720
maximally heritable trait by um just

272
00:12:08,959 --> 00:12:13,279
using the ranks and forcing it to be

273
00:12:10,720 --> 00:12:17,279
normally distributed um and I think that

274
00:12:13,279 --> 00:12:18,600
that has been um surprisingly successful

275
00:12:17,279 --> 00:12:20,440
in a lot of cases even though it's like

276
00:12:18,600 --> 00:12:22,279
a pretty strong assumption um but a lot

277
00:12:20,440 --> 00:12:25,279
of folks you know uh will look at the

278
00:12:22,279 --> 00:12:26,240
data take logs remove outliers um the

279
00:12:25,279 --> 00:12:27,959
kind of stuff that I think is pretty

280
00:12:26,240 --> 00:12:31,360
standard linear models there has been

281
00:12:27,959 --> 00:12:33,480
some work so um several years back uh

282
00:12:31,360 --> 00:12:36,440
there was some work by Nicolo fousy at

283
00:12:33,480 --> 00:12:38,800
Microsoft research learning the

284
00:12:36,440 --> 00:12:41,800
underlying monotonic transformation that

285
00:12:38,800 --> 00:12:42,920
maximized the heritability um which I

286
00:12:41,800 --> 00:12:46,160
thought was kind of an interesting way

287
00:12:42,920 --> 00:12:49,000
to think about it um so yeah but I think

288
00:12:46,160 --> 00:12:51,440
that there this intuition that

289
00:12:49,000 --> 00:12:53,279
um well okay and also I guess if we're

290
00:12:51,440 --> 00:12:55,360
going to move Beyond quantitative to you

291
00:12:53,279 --> 00:12:56,720
know um case control or count or ordinal

292
00:12:55,360 --> 00:12:59,880
or that kind of thing then there's you

293
00:12:56,720 --> 00:13:01,240
know um a large family of methods for

294
00:12:59,880 --> 00:13:04,279
dealing dealing with that kind of thing

295
00:13:01,240 --> 00:13:04,279
as well

296
00:13:06,199 --> 00:13:13,120
yeah awesome all right so next I'm going

297
00:13:09,000 --> 00:13:14,560
to talk about Let me give this a box so

298
00:13:13,120 --> 00:13:18,920
that it stands

299
00:13:14,560 --> 00:13:18,920
out so next I'm going to talk about fine

300
00:13:22,320 --> 00:13:26,959
mapping and what is our goal when we're

301
00:13:24,760 --> 00:13:30,959
fine mapping now we actually want to

302
00:13:26,959 --> 00:13:30,959
identify the causal variance

303
00:13:32,839 --> 00:13:36,360
um to go back to this for a second this

304
00:13:34,279 --> 00:13:38,000
is kind of Genius right like it's saying

305
00:13:36,360 --> 00:13:39,600
we're going to start with a problem

306
00:13:38,000 --> 00:13:41,880
that's an easier problem to solve that

307
00:13:39,600 --> 00:13:47,000
can be solved with a simpler statistical

308
00:13:41,880 --> 00:13:48,920
method and then it's really uh uh

309
00:13:47,000 --> 00:13:51,519
robust when we're trying to estimate

310
00:13:48,920 --> 00:13:53,639
these marginal um these marginal

311
00:13:51,519 --> 00:13:57,720
Association statistics

312
00:13:53,639 --> 00:13:59,279
uh we um you know the result for one for

313
00:13:57,720 --> 00:14:01,920
one snip it doesn't depend on the other

314
00:13:59,279 --> 00:14:03,399
Snips and empirically it's been true

315
00:14:01,920 --> 00:14:05,800
that we've been able to replicate

316
00:14:03,399 --> 00:14:08,920
results from one study in another study

317
00:14:05,800 --> 00:14:11,639
um uh quite reliably so this now is like

318
00:14:08,920 --> 00:14:14,440
this Rock Solid it's it's more or less a

319
00:14:11,639 --> 00:14:17,160
solved problem how we do uh basic

320
00:14:14,440 --> 00:14:19,519
Association mapping um and the reason

321
00:14:17,160 --> 00:14:21,880
that it's so thoroughly established and

322
00:14:19,519 --> 00:14:23,360
so reliable um is because we're not

323
00:14:21,880 --> 00:14:25,279
trying to identify the causal variance

324
00:14:23,360 --> 00:14:27,720
yet we've we've set for ourselves a goal

325
00:14:25,279 --> 00:14:29,519
that can be solved um by fitting one SNP

326
00:14:27,720 --> 00:14:32,560
at a time um and we've gotten really

327
00:14:29,519 --> 00:14:33,720
good at that as a field I mean um but

328
00:14:32,560 --> 00:14:35,040
now we want to identify the causal

329
00:14:33,720 --> 00:14:37,279
variant this is the more interesting

330
00:14:35,040 --> 00:14:40,440
goal and it is way way way harder okay

331
00:14:37,279 --> 00:14:43,360
so why is it way harder

332
00:14:40,440 --> 00:14:47,519
um what's the model that we're

333
00:14:43,360 --> 00:14:47,519
fitting the model that we're fitting

334
00:14:53,320 --> 00:15:01,040
now so this looks very similar but now

335
00:14:56,440 --> 00:15:01,040
um what we have is uh

336
00:15:09,279 --> 00:15:18,959
so dense is the key word here

337
00:15:13,680 --> 00:15:21,800
um ah right right right at

338
00:15:18,959 --> 00:15:23,880
Locus um so now what we're going to do

339
00:15:21,800 --> 00:15:25,160
is we're going to um specify one Locus

340
00:15:23,880 --> 00:15:26,600
we're now again we're not going to fit

341
00:15:25,160 --> 00:15:27,839
one model for the entire genome because

342
00:15:26,600 --> 00:15:29,600
we don't need to do that here instead

343
00:15:27,839 --> 00:15:31,160
we're going to choose a at which there's

344
00:15:29,600 --> 00:15:32,440
an association we think that there is a

345
00:15:31,160 --> 00:15:34,079
causal variant somewhere here we want to

346
00:15:32,440 --> 00:15:35,759
know which one is the causal variant so

347
00:15:34,079 --> 00:15:38,399
we're going to um fit a model just at

348
00:15:35,759 --> 00:15:40,000
that Locus um how you define loai that

349
00:15:38,399 --> 00:15:41,720
can be a bit of a thing I won't go into

350
00:15:40,000 --> 00:15:43,440
that um and now what we're going to do

351
00:15:41,720 --> 00:15:45,560
is we're going to have as dense as

352
00:15:43,440 --> 00:15:47,720
possible a set of variants at that Locus

353
00:15:45,560 --> 00:15:50,160
because in order to have the

354
00:15:47,720 --> 00:15:51,839
interpretation that we want um which is

355
00:15:50,160 --> 00:15:53,440
that beta J is the true causal effect

356
00:15:51,839 --> 00:15:54,680
size there's a number of assumptions

357
00:15:53,440 --> 00:15:56,279
that have to be satisfied and one of

358
00:15:54,680 --> 00:15:57,560
them is the true causal variant has to

359
00:15:56,279 --> 00:15:59,800
be one of the ones that we included in

360
00:15:57,560 --> 00:16:04,000
our model um

361
00:15:59,800 --> 00:16:08,120
and so uh uh let's

362
00:16:04,000 --> 00:16:08,120
see so

363
00:16:26,959 --> 00:16:33,920
um um

364
00:16:29,480 --> 00:16:33,920
okay so what are we interested

365
00:16:36,360 --> 00:16:40,959
in usually we're now going to think

366
00:16:38,560 --> 00:16:42,800
about this in evasion framework because

367
00:16:40,959 --> 00:16:44,319
the kind of an intuitive thing to think

368
00:16:42,800 --> 00:16:47,959
about is that we want to know what the

369
00:16:44,319 --> 00:16:49,880
probability is that beta J is not zero

370
00:16:47,959 --> 00:16:53,519
given all of our data so we want to know

371
00:16:49,880 --> 00:16:55,959
what's the probability that um

372
00:16:53,519 --> 00:16:58,160
um that the true underlying causal

373
00:16:55,959 --> 00:17:02,759
effect is nonzero I.E you know that this

374
00:16:58,160 --> 00:17:05,520
variant is a causal variant and

375
00:17:02,759 --> 00:17:08,799
um so why is this difficult one reason

376
00:17:05,520 --> 00:17:10,880
this is difficult is because of LD um if

377
00:17:08,799 --> 00:17:14,880
you have two Snips that are in perfect

378
00:17:10,880 --> 00:17:16,160
LD then you uh there's no way to have um

379
00:17:14,880 --> 00:17:18,039
total confidence that one of them is

380
00:17:16,160 --> 00:17:19,919
causal and not the other one um you just

381
00:17:18,039 --> 00:17:21,480
can't it is the same information encoded

382
00:17:19,919 --> 00:17:24,120
twice you can't you can't disentangle

383
00:17:21,480 --> 00:17:25,720
that um it's nice in that case to be

384
00:17:24,120 --> 00:17:27,760
beijan because then you can say if I

385
00:17:25,720 --> 00:17:29,120
think only one of them is uh causal if

386
00:17:27,760 --> 00:17:30,559
you're prior in code some kind of

387
00:17:29,120 --> 00:17:32,200
sparsity then your posterior

388
00:17:30,559 --> 00:17:34,320
probabilities will be close to 5050 for

389
00:17:32,200 --> 00:17:37,600
the two variants that are in perfect LD

390
00:17:34,320 --> 00:17:38,559
um and um there have been other folks

391
00:17:37,600 --> 00:17:40,200
who have thought about this from a

392
00:17:38,559 --> 00:17:42,039
frequentist point of view thinking about

393
00:17:40,200 --> 00:17:44,039
sets of snips um that are likely to

394
00:17:42,039 --> 00:17:45,840
contain a causal snip um which is also a

395
00:17:44,039 --> 00:17:47,160
useful framework but a lot of the

396
00:17:45,840 --> 00:17:52,280
methods that are most commonly used

397
00:17:47,160 --> 00:17:54,480
right now are ban um so let's talk about

398
00:17:52,280 --> 00:17:56,480
methods and this again I think is the

399
00:17:54,480 --> 00:17:58,679
topic of an entire primer so I won't

400
00:17:56,480 --> 00:18:00,400
spend too much time on it um but I will

401
00:17:58,679 --> 00:18:03,440
say say that there's

402
00:18:00,400 --> 00:18:04,440
um uh several families of methods and

403
00:18:03,440 --> 00:18:06,640
I'll I'll write down some

404
00:18:04,440 --> 00:18:09,840
classifications so one is um single

405
00:18:06,640 --> 00:18:09,840
causal variant um

406
00:18:14,000 --> 00:18:17,520
methods so this is the exception to what

407
00:18:16,240 --> 00:18:18,840
I was just saying if you're willing to

408
00:18:17,520 --> 00:18:19,919
assume that there's only one causal

409
00:18:18,840 --> 00:18:22,720
variant in the locus then everything

410
00:18:19,919 --> 00:18:24,200
gets really easy um and I won't do the

411
00:18:22,720 --> 00:18:25,840
derivation on the board but you can

412
00:18:24,200 --> 00:18:29,600
write down you know you're now looking

413
00:18:25,840 --> 00:18:32,799
for a posterior uh over

414
00:18:29,600 --> 00:18:34,640
uh size of s configurations so you're

415
00:18:32,799 --> 00:18:35,840
just ch there's s possible outcomes

416
00:18:34,640 --> 00:18:37,039
because you know exactly one of these

417
00:18:35,840 --> 00:18:38,480
variants is causal because that's what

418
00:18:37,039 --> 00:18:39,880
you assumed and now you just need to

419
00:18:38,480 --> 00:18:42,280
know what the posterior probability is

420
00:18:39,880 --> 00:18:44,520
of each of those um each of those

421
00:18:42,280 --> 00:18:46,799
outcomes uh so things are super easy in

422
00:18:44,520 --> 00:18:49,840
that case um the problem is once you get

423
00:18:46,799 --> 00:18:49,840
into multiple causal

424
00:18:52,919 --> 00:18:56,559
variants uh and of course the Trey part

425
00:18:55,080 --> 00:18:57,960
is we know that there are multiple

426
00:18:56,559 --> 00:19:00,000
causal variants at a very large number

427
00:18:57,960 --> 00:19:01,880
of rosi it's very nice and convenient

428
00:19:00,000 --> 00:19:04,720
that we can do one causal variant uh

429
00:19:01,880 --> 00:19:06,520
fine mapping but that uh loses a lot

430
00:19:04,720 --> 00:19:09,640
because we know that the assumption is

431
00:19:06,520 --> 00:19:10,960
violated in a lot of cases um so now

432
00:19:09,640 --> 00:19:12,120
let's try to make some more realistic

433
00:19:10,960 --> 00:19:14,480
assumptions let's say that we want to

434
00:19:12,120 --> 00:19:16,120
have multiple causal variants um so this

435
00:19:14,480 --> 00:19:18,600
is where things get really tricky right

436
00:19:16,120 --> 00:19:20,159
um if you wanted to say um I'm not going

437
00:19:18,600 --> 00:19:21,960
to put any restriction on the number of

438
00:19:20,159 --> 00:19:24,039
causal variants I'm going to put some

439
00:19:21,960 --> 00:19:26,320
kind of Prior on the probability that

440
00:19:24,039 --> 00:19:27,720
you know that a variant is causal and

441
00:19:26,320 --> 00:19:30,640
then I'm going to do exact basian

442
00:19:27,720 --> 00:19:32,960
inference that then the number of of

443
00:19:30,640 --> 00:19:36,080
states in your prior now is going to be

444
00:19:32,960 --> 00:19:38,360
exponential in the size of s because

445
00:19:36,080 --> 00:19:39,799
there's any possible subset of s could

446
00:19:38,360 --> 00:19:41,320
be your set of causal variant and now

447
00:19:39,799 --> 00:19:44,240
you need to get posteriors for every

448
00:19:41,320 --> 00:19:45,919
possible subset of s so um exact basent

449
00:19:44,240 --> 00:19:48,960
inference um

450
00:19:45,919 --> 00:19:52,520
is uh very challenging uh

451
00:19:48,960 --> 00:19:57,000
computationally so I'm going to say

452
00:19:52,520 --> 00:19:57,000
exact evasion inference is

453
00:19:57,320 --> 00:20:02,320
hard you know folks who do this kind of

454
00:19:59,600 --> 00:20:04,280
thing really hate discreet uh uh uh

455
00:20:02,320 --> 00:20:08,240
spaces and this

456
00:20:04,280 --> 00:20:09,480
is very as discreet as they come okay so

457
00:20:08,240 --> 00:20:11,960
what are some solutions that people have

458
00:20:09,480 --> 00:20:14,480
done um one thing that folks have done

459
00:20:11,960 --> 00:20:16,720
so this was mostly in the early days is

460
00:20:14,480 --> 00:20:20,960
um just to restrict the problem to

461
00:20:16,720 --> 00:20:26,600
restrict um uh both the size of s and

462
00:20:20,960 --> 00:20:26,600
also restrict um the number of causal

463
00:20:26,960 --> 00:20:30,520
variants so we're not going to say one

464
00:20:29,080 --> 00:20:32,080
causal variant we're going to say three

465
00:20:30,520 --> 00:20:34,520
causal variants which already actually

466
00:20:32,080 --> 00:20:36,880
that that helps a lot um but the reason

467
00:20:34,520 --> 00:20:38,880
that this uh can be tricky is because if

468
00:20:36,880 --> 00:20:40,200
you're still going to do you know exact

469
00:20:38,880 --> 00:20:42,000
enumeration of all possible

470
00:20:40,200 --> 00:20:44,000
configurations then you need to make S

471
00:20:42,000 --> 00:20:48,360
really small the reason that that's

472
00:20:44,000 --> 00:20:50,520
tough is because if you um uh uh in your

473
00:20:48,360 --> 00:20:52,000
model you leave out a causal variant

474
00:20:50,520 --> 00:20:53,520
that has LD to the variants that are in

475
00:20:52,000 --> 00:20:54,559
your model then that's a really bad

476
00:20:53,520 --> 00:20:56,400
model

477
00:20:54,559 --> 00:20:59,240
violation so what are some other things

478
00:20:56,400 --> 00:21:01,200
that people have done um

479
00:20:59,240 --> 00:21:05,000
one thing that people have done uh is

480
00:21:01,200 --> 00:21:07,440
really uh uh I'll say like

481
00:21:05,000 --> 00:21:11,760
explore a

482
00:21:07,440 --> 00:21:11,760
subset of the posterior

483
00:21:11,880 --> 00:21:17,080
space there's been so so now we get into

484
00:21:15,480 --> 00:21:18,679
like really smart and creative things

485
00:21:17,080 --> 00:21:20,039
that a lot of people have done um in

486
00:21:18,679 --> 00:21:23,799
previous years in a lot of different

487
00:21:20,039 --> 00:21:25,919
groups so one thing has been to do um uh

488
00:21:23,799 --> 00:21:27,520
deterministic search algorithms to try

489
00:21:25,919 --> 00:21:28,919
to find the configurations of causal

490
00:21:27,520 --> 00:21:30,440
variant that cover most most of the

491
00:21:28,919 --> 00:21:32,640
posterior probability but are of a

492
00:21:30,440 --> 00:21:35,760
tractable size there's also been

493
00:21:32,640 --> 00:21:39,720
stochastic versions of that um uh uh

494
00:21:35,760 --> 00:21:41,640
using Randomness in order to um uh uh

495
00:21:39,720 --> 00:21:44,559
design an algorithm that also is

496
00:21:41,640 --> 00:21:46,720
exploring the sets the you know the

497
00:21:44,559 --> 00:21:48,799
large subsets of the posterior

498
00:21:46,720 --> 00:21:51,360
probability and so we're not trying now

499
00:21:48,799 --> 00:21:53,720
to um accurately write down the

500
00:21:51,360 --> 00:21:55,440
posterior probability of every very

501
00:21:53,720 --> 00:21:57,279
unlikely configuration we only care

502
00:21:55,440 --> 00:22:00,520
about the most likely ones and we have

503
00:21:57,279 --> 00:22:03,159
some kind of um handle on how we might

504
00:22:00,520 --> 00:22:06,200
go about finding the most likely

505
00:22:03,159 --> 00:22:10,360
configurations um then another thing

506
00:22:06,200 --> 00:22:13,240
that uh we might want to do is

507
00:22:10,360 --> 00:22:15,919
um uh uh conditional

508
00:22:13,240 --> 00:22:17,440
analysis so I guess I should have uh put

509
00:22:15,919 --> 00:22:20,080
put this

510
00:22:17,440 --> 00:22:23,080
above because this is also um before we

511
00:22:20,080 --> 00:22:25,480
get into um large scale proximate

512
00:22:23,080 --> 00:22:28,679
Invasion algorithms uh conditional

513
00:22:25,480 --> 00:22:32,520
analysis can be we assume that uh the

514
00:22:28,679 --> 00:22:33,760
most significant uh uh snip reflects one

515
00:22:32,520 --> 00:22:35,200
causal variant and then once we

516
00:22:33,760 --> 00:22:38,080
condition on that then we can f map the

517
00:22:35,200 --> 00:22:41,679
next one um and there's other ways that

518
00:22:38,080 --> 00:22:44,960
folks have tried to split into

519
00:22:41,679 --> 00:22:46,679
signals so maybe we have a Locus maybe

520
00:22:44,960 --> 00:22:47,880
we think the locus has multiple causal

521
00:22:46,679 --> 00:22:49,400
variants but we think there's literally

522
00:22:47,880 --> 00:22:50,520
enough LD among the different causal

523
00:22:49,400 --> 00:22:52,799
variants that we're going to be able to

524
00:22:50,520 --> 00:22:54,840
take the locus split it up into you know

525
00:22:52,799 --> 00:22:56,120
in some way that's informed by the data

526
00:22:54,840 --> 00:22:57,880
um split it up into different signals

527
00:22:56,120 --> 00:23:00,000
and apply our fine mapping for the to

528
00:22:57,880 --> 00:23:02,039
each of the different um signals and

529
00:23:00,000 --> 00:23:03,919
then the last one that I'll write is uh

530
00:23:02,039 --> 00:23:08,000
iterative conditional

531
00:23:03,919 --> 00:23:11,039
analysis which turns out to be

532
00:23:08,000 --> 00:23:14,600
conditional analysis which turns out to

533
00:23:11,039 --> 00:23:14,600
be equivalent to variational

534
00:23:17,720 --> 00:23:22,480
inference um where your variational

535
00:23:20,799 --> 00:23:25,120
assumption now is independence of the

536
00:23:22,480 --> 00:23:26,679
locations of each of the causal Snips um

537
00:23:25,120 --> 00:23:29,559
rather than independence of each of the

538
00:23:26,679 --> 00:23:33,080
beta JS um

539
00:23:29,559 --> 00:23:35,120
and so that's kind of a some of the

540
00:23:33,080 --> 00:23:37,240
different ways that different folks have

541
00:23:35,120 --> 00:23:39,279
um uh solved this problem where you want

542
00:23:37,240 --> 00:23:42,080
to get a basian posterior you want the

543
00:23:39,279 --> 00:23:44,039
basian posterior to be to allow for the

544
00:23:42,080 --> 00:23:45,240
possibility of multiple causal variants

545
00:23:44,039 --> 00:23:46,799
um but you don't want to enumerate two

546
00:23:45,240 --> 00:23:49,720
to the S possible

547
00:23:46,799 --> 00:23:53,080
configurations um and I'm not writing

548
00:23:49,720 --> 00:23:56,640
down specific um references here um I

549
00:23:53,080 --> 00:24:00,400
think this one was caviar this is uh dap

550
00:23:56,640 --> 00:24:01,840
G or also fine map um this is

551
00:24:00,400 --> 00:24:04,919
conditional analysis and this one is

552
00:24:01,840 --> 00:24:06,960
Suzie um and the exact references are in

553
00:24:04,919 --> 00:24:10,400
notes that I'll post online if anybody's

554
00:24:06,960 --> 00:24:12,120
interested um and so then what are some

555
00:24:10,400 --> 00:24:14,039
other uh uh approaches that folks have

556
00:24:12,120 --> 00:24:17,240
taken to this kind of in combination

557
00:24:14,039 --> 00:24:20,559
with one or two um one is to incorporate

558
00:24:17,240 --> 00:24:20,559
functional data

559
00:24:22,200 --> 00:24:29,279
incorporate uh functional data so here

560
00:24:26,399 --> 00:24:31,200
maybe what we want to do is um say that

561
00:24:29,279 --> 00:24:33,399
well we know that coding variants are

562
00:24:31,200 --> 00:24:36,000
more likely to be causal than non-coding

563
00:24:33,399 --> 00:24:38,120
variants or we know that uh conserved

564
00:24:36,000 --> 00:24:41,159
variants are more likely to be causal

565
00:24:38,120 --> 00:24:42,320
than um unconserved variants and so it

566
00:24:41,159 --> 00:24:43,720
would be stupid to just throw that

567
00:24:42,320 --> 00:24:45,919
information away so we've got to

568
00:24:43,720 --> 00:24:47,399
incorporate it in the form of a prior so

569
00:24:45,919 --> 00:24:51,240
that we wind up getting posteriors that

570
00:24:47,399 --> 00:24:53,960
reflect that um that fact and

571
00:24:51,240 --> 00:24:56,440
um what's interesting there is well

572
00:24:53,960 --> 00:24:58,080
exactly how much should you upweight

573
00:24:56,440 --> 00:24:59,200
coding variants compared to non-coding

574
00:24:58,080 --> 00:25:01,159
variant

575
00:24:59,200 --> 00:25:04,159
you could kind of subjectively say well

576
00:25:01,159 --> 00:25:07,320
my prior is you know five or 10 or

577
00:25:04,159 --> 00:25:09,600
whatever or uh there have been a couple

578
00:25:07,320 --> 00:25:11,679
of different algorithms for using the

579
00:25:09,600 --> 00:25:14,360
data either in the locus itself or

580
00:25:11,679 --> 00:25:16,000
across manyi to inform what the relative

581
00:25:14,360 --> 00:25:18,440
weights should be of these variants and

582
00:25:16,000 --> 00:25:21,880
um that have these different properties

583
00:25:18,440 --> 00:25:23,080
um and then the other um the last thing

584
00:25:21,880 --> 00:25:24,880
that I'll write is just that cross

585
00:25:23,080 --> 00:25:27,880
population analysis can be complicated

586
00:25:24,880 --> 00:25:27,880
here

587
00:25:31,559 --> 00:25:38,360
um so uh and that's because uh well for

588
00:25:36,279 --> 00:25:42,559
a couple of different reasons one is a

589
00:25:38,360 --> 00:25:45,720
lot of the analyses um uh are most

590
00:25:42,559 --> 00:25:47,960
easily done by splitting apart um the

591
00:25:45,720 --> 00:25:49,360
summary statistics from the LD um and

592
00:25:47,960 --> 00:25:50,600
the LD can be different in different

593
00:25:49,360 --> 00:25:52,480
populations and so you have to be a

594
00:25:50,600 --> 00:25:53,880
little bit thoughtful when you um do

595
00:25:52,480 --> 00:25:57,399
that kind of analysis and there's been

596
00:25:53,880 --> 00:25:58,799
some um uh methods development work in a

597
00:25:57,399 --> 00:26:00,960
couple of different places

598
00:25:58,799 --> 00:26:03,440
uh trying to do that in as rigorous as

599
00:26:00,960 --> 00:26:05,919
possible a way um uh and it seems like

600
00:26:03,440 --> 00:26:08,240
it really does give uh a big boost for

601
00:26:05,919 --> 00:26:10,399
power when that can be done successfully

602
00:26:08,240 --> 00:26:12,440
can I ask a question Hillary what do you

603
00:26:10,399 --> 00:26:14,799
think is more powerful incorporating

604
00:26:12,440 --> 00:26:16,600
more diversity of people in your gws or

605
00:26:14,799 --> 00:26:19,520
just increasing the end of your

606
00:26:16,600 --> 00:26:21,240
homogeneous population yeah I think

607
00:26:19,520 --> 00:26:24,640
that's a great question I think that in

608
00:26:21,240 --> 00:26:27,679
theory if we had perfect methods then um

609
00:26:24,640 --> 00:26:29,399
diversity uh well okay I guess it's a

610
00:26:27,679 --> 00:26:31,159
trade-off right like just you know it

611
00:26:29,399 --> 00:26:33,559
depends a lot on where you are and

612
00:26:31,159 --> 00:26:36,080
actually um a Pap paper from Hong's

613
00:26:33,559 --> 00:26:37,360
group um I think I think if I

614
00:26:36,080 --> 00:26:39,559
remembering right it has some figures

615
00:26:37,360 --> 00:26:41,279
about exactly that question like at what

616
00:26:39,559 --> 00:26:42,799
point does it become a better idea to

617
00:26:41,279 --> 00:26:44,520
switch from just increasing your sample

618
00:26:42,799 --> 00:26:46,799
size to increasing your diversity

619
00:26:44,520 --> 00:26:51,080
because if you've got a really small

620
00:26:46,799 --> 00:26:53,360
sample size and if it's too diverse um

621
00:26:51,080 --> 00:26:56,960
ancestrally to be able to do a good job

622
00:26:53,360 --> 00:26:58,760
of um accounting for ancestry uh and

623
00:26:56,960 --> 00:27:00,679
potential confounding my ancestry

624
00:26:58,760 --> 00:27:03,520
then you're really in trouble right so I

625
00:27:00,679 --> 00:27:04,960
think that um uh yeah and we've seen

626
00:27:03,520 --> 00:27:07,080
examples before of data sets where

627
00:27:04,960 --> 00:27:09,240
because um they're studying some

628
00:27:07,080 --> 00:27:13,200
molecular phenotype um the sample sizes

629
00:27:09,240 --> 00:27:15,240
are much smaller uh but then if you um

630
00:27:13,200 --> 00:27:17,960
don't yet have the methods to account

631
00:27:15,240 --> 00:27:19,640
for the confounding that you might see

632
00:27:17,960 --> 00:27:20,919
then that can create problems on the

633
00:27:19,640 --> 00:27:22,919
other hand if you can choose between two

634
00:27:20,919 --> 00:27:24,640
big gwas of the same ancestry or two gws

635
00:27:22,919 --> 00:27:26,000
of different ancestries then the fact

636
00:27:24,640 --> 00:27:27,559
that you've got this different LD really

637
00:27:26,000 --> 00:27:29,360
helps break down you know this main

638
00:27:27,559 --> 00:27:32,000
challenge of mapping which is that LD

639
00:27:29,360 --> 00:27:33,520
makes it difficult and so I think that

640
00:27:32,000 --> 00:27:35,600
we need the statistical methods so that

641
00:27:33,520 --> 00:27:37,159
the answer is always diversity and I

642
00:27:35,600 --> 00:27:38,720
don't think our statistical methods are

643
00:27:37,159 --> 00:27:39,679
quite there yet so I don't think that's

644
00:27:38,720 --> 00:27:41,559
always

645
00:27:39,679 --> 00:27:44,559
answer

646
00:27:41,559 --> 00:27:44,559
yeah

647
00:27:45,320 --> 00:27:48,320
yeah

648
00:27:49,120 --> 00:27:53,880
yeah yeah thanks but originally how do

649
00:27:52,039 --> 00:27:55,960
you define it is like you have a jwa

650
00:27:53,880 --> 00:27:58,320
signal and you say okay I just take um I

651
00:27:55,960 --> 00:28:00,919
don't know 100kb on both sides or you

652
00:27:58,320 --> 00:28:02,919
use LD or like what is the I guess the

653
00:28:00,919 --> 00:28:04,640
easiest is by size but I feel it's not

654
00:28:02,919 --> 00:28:06,440
the smartest way so I was wondering what

655
00:28:04,640 --> 00:28:09,000
the state-of-the-art way to do it would

656
00:28:06,440 --> 00:28:11,960
be yeah yeah that's a good question so I

657
00:28:09,000 --> 00:28:14,960
think different folks have done this

658
00:28:11,960 --> 00:28:16,360
differently one way that you can do it

659
00:28:14,960 --> 00:28:19,519
is

660
00:28:16,360 --> 00:28:22,760
um uh so one way you can do it is by LD

661
00:28:19,519 --> 00:28:24,320
that is computationally intensive um one

662
00:28:22,760 --> 00:28:26,799
argument for doing it by size is if you

663
00:28:24,320 --> 00:28:29,640
do it by size and you do it big enough

664
00:28:26,799 --> 00:28:31,480
um then if you've got your Locus that

665
00:28:29,640 --> 00:28:34,200
you're fine mapping right here and now

666
00:28:31,480 --> 00:28:38,039
you include everything um that could

667
00:28:34,200 --> 00:28:39,360
plausibly be an LD with it um then maybe

668
00:28:38,039 --> 00:28:40,960
that'll be tricky you know if you're

669
00:28:39,360 --> 00:28:42,760
trying to interpret really strong

670
00:28:40,960 --> 00:28:44,159
signals out at the edges of your of your

671
00:28:42,760 --> 00:28:45,679
Locus but really what you care about is

672
00:28:44,159 --> 00:28:46,960
what right what's what's in the middle

673
00:28:45,679 --> 00:28:48,159
and so you'll get much more accurate

674
00:28:46,960 --> 00:28:50,200
results for the middle as long as your

675
00:28:48,159 --> 00:28:52,159
Locus includes the things that are in LD

676
00:28:50,200 --> 00:28:55,399
with the the locus that you most care

677
00:28:52,159 --> 00:28:57,440
about um but I think um I'm trying to

678
00:28:55,399 --> 00:28:59,799
think if I've can think of any

679
00:28:57,440 --> 00:29:00,919
references off the top of my head for

680
00:28:59,799 --> 00:29:04,120
yeah yeah no but I think people have

681
00:29:00,919 --> 00:29:04,120
done it in both ways

682
00:29:05,440 --> 00:29:10,480
yeah

683
00:29:07,440 --> 00:29:11,919
yeah that point it will be a tradeoff

684
00:29:10,480 --> 00:29:14,760
right because at some point if you

685
00:29:11,919 --> 00:29:17,200
include too many sleeps you might have

686
00:29:14,760 --> 00:29:20,159
might be violating the single causal

687
00:29:17,200 --> 00:29:21,600
variant uh hypothesis right so

688
00:29:20,159 --> 00:29:23,640
definitely yeah single causal variant F

689
00:29:21,600 --> 00:29:26,519
mapping on really large low s i I agree

690
00:29:23,640 --> 00:29:26,519
would would be

691
00:29:26,720 --> 00:29:29,840
fraud the might

692
00:29:28,679 --> 00:29:31,320
the reason why I'm just running around

693
00:29:29,840 --> 00:29:33,440
is just for the people online it's a

694
00:29:31,320 --> 00:29:35,120
little bit it can be hard to hear so

695
00:29:33,440 --> 00:29:36,360
there's mics up here or I can get more

696
00:29:35,120 --> 00:29:38,159
exercise this

697
00:29:36,360 --> 00:29:39,799
morning

698
00:29:38,159 --> 00:29:43,120
great

699
00:29:39,799 --> 00:29:45,200
um so one other thing that I'll say um

700
00:29:43,120 --> 00:29:47,960
uh that my group has done some work on

701
00:29:45,200 --> 00:29:50,240
is once you start to you know if you say

702
00:29:47,960 --> 00:29:52,559
okay I've got my model I've got the data

703
00:29:50,240 --> 00:29:54,000
uh I've got my inference algorithm and

704
00:29:52,559 --> 00:29:56,559
I'm going to get a posterior that's one

705
00:29:54,000 --> 00:29:58,480
thing if you say I have some intuition

706
00:29:56,559 --> 00:30:00,000
for what I want to be able to do but now

707
00:29:58,480 --> 00:30:02,519
what I actually have access to is

708
00:30:00,000 --> 00:30:05,360
summary statistics from a meta analysis

709
00:30:02,519 --> 00:30:06,720
um then the number of you know we're

710
00:30:05,360 --> 00:30:08,600
always making assumptions we're always

711
00:30:06,720 --> 00:30:09,640
violating the assumptions it turns out

712
00:30:08,600 --> 00:30:12,200
that the assumptions that you're

713
00:30:09,640 --> 00:30:14,000
violating when you find map um from

714
00:30:12,200 --> 00:30:15,600
summary statistics from a meta analysis

715
00:30:14,000 --> 00:30:18,519
can sometimes be so bad that you wind up

716
00:30:15,600 --> 00:30:19,840
getting really unreliable results um so

717
00:30:18,519 --> 00:30:21,519
when you're doing basion inference you

718
00:30:19,840 --> 00:30:23,200
know a lot of times the initial

719
00:30:21,519 --> 00:30:25,000
derivation will be I'm going to say I

720
00:30:23,200 --> 00:30:26,279
have all of my y's I have all of my x's

721
00:30:25,000 --> 00:30:29,279
and now I'm going to get a posterior

722
00:30:26,279 --> 00:30:32,200
conditioned on y and x and then um you

723
00:30:29,279 --> 00:30:33,559
can uh do derivations showing that well

724
00:30:32,200 --> 00:30:35,440
actually everything only depends on X

725
00:30:33,559 --> 00:30:37,120
transpose x and x transpose Y which are

726
00:30:35,440 --> 00:30:39,240
closely related to summary statistics in

727
00:30:37,120 --> 00:30:41,200
LD and so now my math says I can use

728
00:30:39,240 --> 00:30:44,440
summary statistics in LD and then you

729
00:30:41,200 --> 00:30:46,880
make a huge leap to say I don't actually

730
00:30:44,440 --> 00:30:48,880
have the exact LD Matrix from my

731
00:30:46,880 --> 00:30:51,559
specific set of genotypes I have a

732
00:30:48,880 --> 00:30:53,799
reference panel and um when I talk about

733
00:30:51,559 --> 00:30:55,039
heritability I'll I'll say why that

734
00:30:53,799 --> 00:30:58,679
sometimes works in the case of

735
00:30:55,039 --> 00:31:01,120
heritability for fine mapping um uh you

736
00:30:58,679 --> 00:31:02,799
know uh many different Works including

737
00:31:01,120 --> 00:31:04,880
works from our group but also um from

738
00:31:02,799 --> 00:31:07,360
other folks have shown that that can um

739
00:31:04,880 --> 00:31:11,159
really um uh cause issues with fine

740
00:31:07,360 --> 00:31:13,200
mapping and um when you're doing a meta

741
00:31:11,159 --> 00:31:15,559
analysis then on top of that often you

742
00:31:13,200 --> 00:31:17,120
have um several different LD matrices

743
00:31:15,559 --> 00:31:19,480
from several different cohorts none of

744
00:31:17,120 --> 00:31:21,200
which you have access to um and then

745
00:31:19,480 --> 00:31:23,240
once you combine that with you know

746
00:31:21,200 --> 00:31:24,519
other types of heterogeneity where

747
00:31:23,240 --> 00:31:26,159
you've got different genotyping and

748
00:31:24,519 --> 00:31:29,720
different cohorts and different utation

749
00:31:26,159 --> 00:31:30,960
panels um then the set of complications

750
00:31:29,720 --> 00:31:33,399
that you're brushing under the rug

751
00:31:30,960 --> 00:31:34,760
becomes um problematically large even

752
00:31:33,399 --> 00:31:36,159
though there's always complications that

753
00:31:34,760 --> 00:31:37,600
we have to you know brush under the rug

754
00:31:36,159 --> 00:31:39,919
to do inference under any

755
00:31:37,600 --> 00:31:42,080
model um so that's one thing that I'll

756
00:31:39,919 --> 00:31:44,360
say is uh doing this from summary

757
00:31:42,080 --> 00:31:46,080
statistics can be um um difficult if the

758
00:31:44,360 --> 00:31:48,960
summary statistics are not exactly

759
00:31:46,080 --> 00:31:51,360
derived from your

760
00:31:48,960 --> 00:31:55,399
cohort okay

761
00:31:51,360 --> 00:31:59,440
so now I'll go over here oh and I will

762
00:31:55,399 --> 00:32:00,960
quickly talk about heritability okay

763
00:31:59,440 --> 00:32:03,039
sorry that was that was my bad the

764
00:32:00,960 --> 00:32:06,679
clock's been there the whole time okay

765
00:32:03,039 --> 00:32:09,679
so um I'm going to talk about

766
00:32:06,679 --> 00:32:09,679
heritability

767
00:32:09,919 --> 00:32:17,720
heritability um based

768
00:32:14,279 --> 00:32:23,159
analyses so this covers all three of

769
00:32:17,720 --> 00:32:23,159
these so there's um basic heritability

770
00:32:23,919 --> 00:32:27,600
estimation credability

771
00:32:29,760 --> 00:32:33,200
estimation genetic

772
00:32:38,240 --> 00:32:43,039
correlation and um partition terit

773
00:32:50,279 --> 00:32:54,240
ability and the reason that I'm writing

774
00:32:52,559 --> 00:32:56,880
them all under the same category is

775
00:32:54,240 --> 00:33:00,600
because they use the same s basically um

776
00:32:56,880 --> 00:33:06,720
and so in particular here um what we've

777
00:33:00,600 --> 00:33:08,320
got is uh again some over J and S x i j

778
00:33:06,720 --> 00:33:11,919
beta

779
00:33:08,320 --> 00:33:15,480
J Epsilon I and this time

780
00:33:11,919 --> 00:33:18,480
s is a sentinel call this

781
00:33:15,480 --> 00:33:18,480
parability

782
00:33:25,799 --> 00:33:29,880
um and what we're interested in so this

783
00:33:28,360 --> 00:33:33,720
is the

784
00:33:29,880 --> 00:33:33,720
model we're interested

785
00:33:36,159 --> 00:33:42,919
in is what is the variance of uh I'll

786
00:33:40,080 --> 00:33:42,919
call it

787
00:33:51,679 --> 00:33:56,919
g so if we say that this is a genetic

788
00:33:54,200 --> 00:33:58,840
component um due to genotype Snips plus

789
00:33:56,919 --> 00:34:00,200
some residual that has all the rest of

790
00:33:58,840 --> 00:34:02,360
the genetics that's not tagged by

791
00:34:00,200 --> 00:34:04,000
genotyped Snips like ultra rare variants

792
00:34:02,360 --> 00:34:06,080
or things like that plus all the

793
00:34:04,000 --> 00:34:07,360
environmental components then snip parit

794
00:34:06,080 --> 00:34:08,639
ability is asking how much of the

795
00:34:07,360 --> 00:34:10,320
variation in the phenotype What

796
00:34:08,639 --> 00:34:13,480
proportion of that variation can be

797
00:34:10,320 --> 00:34:15,280
explained by genotype Snips and one in

798
00:34:13,480 --> 00:34:17,159
intuition for what this quantity is that

799
00:34:15,280 --> 00:34:19,440
we're trying to estimate is if some

800
00:34:17,159 --> 00:34:21,399
Oracle told me what the true betas were

801
00:34:19,440 --> 00:34:23,800
then what's the best possible prediction

802
00:34:21,399 --> 00:34:27,040
r squared that I could get if all I have

803
00:34:23,800 --> 00:34:28,359
access to is a set of genotype Snips um

804
00:34:27,040 --> 00:34:29,560
so one thing that I'll notice the betas

805
00:34:28,359 --> 00:34:30,839
here aren't actually that interesting

806
00:34:29,560 --> 00:34:32,839
they're not marginal they're also not

807
00:34:30,839 --> 00:34:36,800
causal the the set of snips is not

808
00:34:32,839 --> 00:34:39,520
particularly dense um and so um this is

809
00:34:36,800 --> 00:34:41,599
this is good because it means that we

810
00:34:39,520 --> 00:34:43,119
can now start to do genome wide modeling

811
00:34:41,599 --> 00:34:44,599
and genom wide modeling is good because

812
00:34:43,119 --> 00:34:46,000
now we can estimate this quantity that

813
00:34:44,599 --> 00:34:47,480
we care about which is just the total

814
00:34:46,000 --> 00:34:49,679
amount of variation that's explained by

815
00:34:47,480 --> 00:34:51,240
the set of snips it also allows us to do

816
00:34:49,679 --> 00:34:52,879
genomewide estimation of genetic

817
00:34:51,240 --> 00:34:54,520
correlation which is a closely related

818
00:34:52,879 --> 00:34:56,399
model and also of partitioned

819
00:34:54,520 --> 00:34:58,280
heritability where we want to know

820
00:34:56,399 --> 00:35:00,240
what's the what's the contrib for

821
00:34:58,280 --> 00:35:02,359
example of snips in brain enhancers

822
00:35:00,240 --> 00:35:03,960
genomewide and now there's no particular

823
00:35:02,359 --> 00:35:05,480
Locus that we care about so much that we

824
00:35:03,960 --> 00:35:07,560
want to throw all of our computational

825
00:35:05,480 --> 00:35:10,320
resources into you know fitting some

826
00:35:07,560 --> 00:35:12,480
really dense set of snips um but we also

827
00:35:10,320 --> 00:35:15,240
don't want to just do marginal marginal

828
00:35:12,480 --> 00:35:17,000
um analysis and so instead there's kind

829
00:35:15,240 --> 00:35:18,400
of this uh intermediate thing where the

830
00:35:17,000 --> 00:35:20,160
betas themselves are not that

831
00:35:18,400 --> 00:35:22,200
interesting but the model as a whole is

832
00:35:20,160 --> 00:35:23,599
still going to allow us to estimate um

833
00:35:22,200 --> 00:35:27,760
these genome wide quantities that are

834
00:35:23,599 --> 00:35:30,680
really interesting um and so um with

835
00:35:27,760 --> 00:35:32,599
genetic correlation um maybe I won't

836
00:35:30,680 --> 00:35:34,520
write down well yeah no I think I have

837
00:35:32,599 --> 00:35:38,480
time okay so with genetic correlation

838
00:35:34,520 --> 00:35:40,520
what we want to know is um so the

839
00:35:38,480 --> 00:35:43,880
goal

840
00:35:40,520 --> 00:35:46,680
is how much

841
00:35:43,880 --> 00:35:49,839
do these

842
00:35:46,680 --> 00:35:52,839
two traits

843
00:35:49,839 --> 00:35:52,839
have

844
00:35:55,319 --> 00:36:00,200
shared basis

845
00:35:58,400 --> 00:36:04,760
and the model that we're going to write

846
00:36:00,200 --> 00:36:07,560
now is um just an I

847
00:36:04,760 --> 00:36:10,920
here we now have two phenotypes we have

848
00:36:07,560 --> 00:36:14,079
y i a and we have y i so this might be I

849
00:36:10,920 --> 00:36:16,400
don't know your your height and your BMI

850
00:36:14,079 --> 00:36:18,839
or something like that um and now this

851
00:36:16,400 --> 00:36:18,839
is going to

852
00:36:21,760 --> 00:36:26,400
be and we have um phenotype specific

853
00:36:25,040 --> 00:36:29,560
effect sizes of course because that's

854
00:36:26,400 --> 00:36:29,560
what we got to have

855
00:36:35,560 --> 00:36:43,960
um and so if we call this for example

856
00:36:39,640 --> 00:36:46,520
GI um B then now we can say what we want

857
00:36:43,960 --> 00:36:46,520
to know

858
00:36:48,160 --> 00:36:53,480
is what's the correlation

859
00:36:51,359 --> 00:36:55,839
between the genetic component for

860
00:36:53,480 --> 00:36:59,800
phenotype a the genetic component for

861
00:36:55,839 --> 00:37:03,680
phenotype B um um

862
00:36:59,800 --> 00:37:03,680
and when

863
00:37:03,839 --> 00:37:09,760
so uh yeah so for partition heritability

864
00:37:07,240 --> 00:37:09,760
the goal

865
00:37:16,800 --> 00:37:19,800
is

866
00:37:20,040 --> 00:37:23,400
explained

867
00:37:21,880 --> 00:37:26,520
set

868
00:37:23,400 --> 00:37:28,480
of snips and so for example if this set

869
00:37:26,520 --> 00:37:31,680
of snips is all of the Snips that lie

870
00:37:28,480 --> 00:37:33,920
within 100 KB of the of a gene that's

871
00:37:31,680 --> 00:37:36,000
highly expressed in a certain tissue

872
00:37:33,920 --> 00:37:37,400
then this type of analysis being able to

873
00:37:36,000 --> 00:37:38,920
um estimate this type of heritability

874
00:37:37,400 --> 00:37:40,920
can start to tell you about which

875
00:37:38,920 --> 00:37:44,680
tissues are most relevant for particular

876
00:37:40,920 --> 00:37:46,240
phenotypes um from their genetic signal

877
00:37:44,680 --> 00:37:50,280
um and

878
00:37:46,240 --> 00:37:53,599
so uh here one the model that we're

879
00:37:50,280 --> 00:37:56,160
fitting is to now start to break up um

880
00:37:53,599 --> 00:37:58,119
this genetic term into multiple genetic

881
00:37:56,160 --> 00:38:01,800
terms so you can say

882
00:37:58,119 --> 00:38:01,800
uh y I

883
00:38:16,839 --> 00:38:20,760
be and so if we call

884
00:38:24,280 --> 00:38:29,280
this then interested in

885
00:38:41,720 --> 00:38:46,160
so out of all of the genetic signal What

886
00:38:44,200 --> 00:38:47,640
proportion is explained by this set of

887
00:38:46,160 --> 00:38:48,920
snips which as I said you know you'll

888
00:38:47,640 --> 00:38:50,480
choose to be some interesting set of

889
00:38:48,920 --> 00:38:53,800
snips where you care about how important

890
00:38:50,480 --> 00:38:55,560
they are for the phenotype um and so

891
00:38:53,800 --> 00:38:56,880
then to talk about methods so now I'm

892
00:38:55,560 --> 00:38:58,319
going to talk about methods for all

893
00:38:56,880 --> 00:39:00,800
three

894
00:38:58,319 --> 00:39:02,240
because the methods are are are shared

895
00:39:00,800 --> 00:39:03,760
uh in general when someone develops a

896
00:39:02,240 --> 00:39:05,680
method for one of them then you can kind

897
00:39:03,760 --> 00:39:09,560
of apply them to apply the method to

898
00:39:05,680 --> 00:39:09,560
solve these different ones and

899
00:39:10,680 --> 00:39:16,200
so the most

900
00:39:13,160 --> 00:39:18,800
um most of the methods assume that beta

901
00:39:16,200 --> 00:39:20,319
Is Random so they add an extra layer to

902
00:39:18,800 --> 00:39:22,400
this model where they say beta is drawn

903
00:39:20,319 --> 00:39:25,880
from some distribution and now we're

904
00:39:22,400 --> 00:39:28,400
going to um relate what we are estim to

905
00:39:25,880 --> 00:39:30,560
properties of the distribution of B beta

906
00:39:28,400 --> 00:39:33,560
um which I won't go into much more

907
00:39:30,560 --> 00:39:35,400
detail about but I'll just say um once

908
00:39:33,560 --> 00:39:38,079
you say beta is random then you can say

909
00:39:35,400 --> 00:39:39,800
either I am going to

910
00:39:38,079 --> 00:39:44,800
require

911
00:39:39,800 --> 00:39:44,800
um full genotype and phenotype

912
00:39:44,880 --> 00:39:51,160
information genotype information or just

913
00:39:48,520 --> 00:39:51,160
do summary

914
00:39:52,680 --> 00:39:58,440
statistics and we can make like a table

915
00:39:55,599 --> 00:40:00,400
here um where now the rows of the table

916
00:39:58,440 --> 00:40:02,400
are going to be I want to do something

917
00:40:00,400 --> 00:40:04,680
that's likelihood

918
00:40:02,400 --> 00:40:05,839
based or I want to do something that's

919
00:40:04,680 --> 00:40:09,760
moments

920
00:40:05,839 --> 00:40:14,800
based or I want to do something that's

921
00:40:09,760 --> 00:40:17,119
bean and it turns out so we've got

922
00:40:14,800 --> 00:40:19,400
gcta we've got H

923
00:40:17,119 --> 00:40:22,640
regression and this is uh not

924
00:40:19,400 --> 00:40:25,800
comprehensive of course H

925
00:40:22,640 --> 00:40:27,880
regression and then this older method B

926
00:40:25,800 --> 00:40:31,760
slmm and over

927
00:40:27,880 --> 00:40:35,480
here uh the last time I gave this talk

928
00:40:31,760 --> 00:40:38,160
there wasn't a method in this uh slot

929
00:40:35,480 --> 00:40:41,480
but now there is

930
00:40:38,160 --> 00:40:43,640
ldsc and RSS so there's lots of

931
00:40:41,480 --> 00:40:46,200
different methods for solving this kind

932
00:40:43,640 --> 00:40:48,160
of large family of problems um but for a

933
00:40:46,200 --> 00:40:50,560
lot of them you can think of what kind

934
00:40:48,160 --> 00:40:52,359
of data are we requiring and then are we

935
00:40:50,560 --> 00:40:54,040
going to uh do something that's full

936
00:40:52,359 --> 00:40:56,200
likelihood based based only on moments

937
00:40:54,040 --> 00:40:57,599
or Vision um and there can be advantages

938
00:40:56,200 --> 00:41:01,440
and disadvantages of each of those

939
00:40:57,599 --> 00:41:03,880
different um uh uh different approaches

940
00:41:01,440 --> 00:41:05,760
and this all assumes that beta Is Random

941
00:41:03,880 --> 00:41:06,960
so then separately there is some work

942
00:41:05,760 --> 00:41:09,800
trying to actually solve it for when

943
00:41:06,960 --> 00:41:12,000
beta is fixed which uh makes it a little

944
00:41:09,800 --> 00:41:13,280
trickier in a lot of ways um and so the

945
00:41:12,000 --> 00:41:18,480
main method that I know that goes on

946
00:41:13,280 --> 00:41:21,920
turn that category is the method um so

947
00:41:18,480 --> 00:41:25,319
then if we want to come back and say

948
00:41:21,920 --> 00:41:28,119
uh why does all of this matter for for

949
00:41:25,319 --> 00:41:29,400
example risk prediction so a lot of

950
00:41:28,119 --> 00:41:31,400
times with risk

951
00:41:29,400 --> 00:41:33,839
prediction what you want to do is write

952
00:41:31,400 --> 00:41:34,880
down a linear model that looks a lot

953
00:41:33,839 --> 00:41:36,920
like the model that we're writing down

954
00:41:34,880 --> 00:41:38,040
over and over and over again um and then

955
00:41:36,920 --> 00:41:39,800
you want to include some estimates of

956
00:41:38,040 --> 00:41:41,280
beta and I think that for example if

957
00:41:39,800 --> 00:41:43,520
you're trying to decide whether the LD

958
00:41:41,280 --> 00:41:45,119
prune or not um well if you got your

959
00:41:43,520 --> 00:41:49,359
estimates of beta from a model that's

960
00:41:45,119 --> 00:41:50,720
different for every snip um then um in

961
00:41:49,359 --> 00:41:52,160
order for that to make sense in the

962
00:41:50,720 --> 00:41:54,119
context of a larger model where you're

963
00:41:52,160 --> 00:41:56,440
summing across Snips then you need to

964
00:41:54,119 --> 00:41:58,960
show that it's okay to plug in you know

965
00:41:56,440 --> 00:42:00,920
these um uh marginal effects into what's

966
00:41:58,960 --> 00:42:02,680
effectively a joint model for um risk

967
00:42:00,920 --> 00:42:05,359
prediction that turns out to be okay

968
00:42:02,680 --> 00:42:07,920
only if there's um no LD among the

969
00:42:05,359 --> 00:42:09,800
different Snips um but a lot of if

970
00:42:07,920 --> 00:42:13,480
you're interested in for example

971
00:42:09,800 --> 00:42:15,160
cross-population risk prediction um then

972
00:42:13,480 --> 00:42:17,200
now the question of whether you're

973
00:42:15,160 --> 00:42:21,480
interpreting your betas as true causal

974
00:42:17,200 --> 00:42:24,160
betas or marginal betas or betas that

975
00:42:21,480 --> 00:42:26,000
are somewhere in between you know they

976
00:42:24,160 --> 00:42:29,960
uh they're not true causal betas they

977
00:42:26,000 --> 00:42:31,839
include some effect from the tagged uh

978
00:42:29,960 --> 00:42:34,599
uh Snips that are not included in the

979
00:42:31,839 --> 00:42:37,000
model so marginal anything that's not

980
00:42:34,599 --> 00:42:39,960
truly causal is going to be influenced

981
00:42:37,000 --> 00:42:41,319
by the LD patterns of the population so

982
00:42:39,960 --> 00:42:43,640
if you're trying to do cross-population

983
00:42:41,319 --> 00:42:45,640
risk prediction just as an example

984
00:42:43,640 --> 00:42:47,319
application um then you have to think

985
00:42:45,640 --> 00:42:50,559
really carefully about whether the true

986
00:42:47,319 --> 00:42:51,920
underlying betas um are they causal in

987
00:42:50,559 --> 00:42:54,880
which case you can assume they're the

988
00:42:51,920 --> 00:42:57,720
same across um populations pretty safely

989
00:42:54,880 --> 00:43:01,240
um with a uh depending on how you're

990
00:42:57,720 --> 00:43:03,720
scaling or uh when you say beta do you

991
00:43:01,240 --> 00:43:05,440
actually mean um some combination of

992
00:43:03,720 --> 00:43:06,680
effects of variants that are tagged in

993
00:43:05,440 --> 00:43:08,319
which case now the true betas are going

994
00:43:06,680 --> 00:43:10,640
to vary across population because LD and

995
00:43:08,319 --> 00:43:11,960
AAL frequency vary across population um

996
00:43:10,640 --> 00:43:13,520
so sometimes it can just be helpful to

997
00:43:11,960 --> 00:43:14,839
think carefully about I'm going to write

998
00:43:13,520 --> 00:43:17,280
down this linear model and now I'm going

999
00:43:14,839 --> 00:43:19,079
to think carefully about uh what the

1000
00:43:17,280 --> 00:43:20,400
even before I start estimating anything

1001
00:43:19,079 --> 00:43:22,520
I just need to think about what the beta

1002
00:43:20,400 --> 00:43:24,000
itself means in that model now we can

1003
00:43:22,520 --> 00:43:26,400
start estimating and you know worrying

1004
00:43:24,000 --> 00:43:28,079
about power and noise and bias and so

1005
00:43:26,400 --> 00:43:29,640
forth um but sometimes even just

1006
00:43:28,079 --> 00:43:31,960
starting before you do all of that with

1007
00:43:29,640 --> 00:43:33,520
saying when I say beta what do I mean um

1008
00:43:31,960 --> 00:43:36,280
can be really helpful so I'm going to

1009
00:43:33,520 --> 00:43:38,880
stop there and I am happy to take two

1010
00:43:36,280 --> 00:43:38,880
minutes of

1011
00:43:45,000 --> 00:43:51,240
questions for the genetic correlation is

1012
00:43:47,960 --> 00:43:53,839
the assumption that you have the full

1013
00:43:51,240 --> 00:43:56,599
set of traits associated with each

1014
00:43:53,839 --> 00:43:59,200
phenotype because if you if you see that

1015
00:43:56,599 --> 00:44:01,760
there's one shared variant but you don't

1016
00:43:59,200 --> 00:44:03,520
know about 50 other different variants

1017
00:44:01,760 --> 00:44:06,400
you wouldn't you think that they're

1018
00:44:03,520 --> 00:44:08,040
perfectly correlated these two traits

1019
00:44:06,400 --> 00:44:09,839
wait so can you can you say that again

1020
00:44:08,040 --> 00:44:11,240
you're wondering if there's if you like

1021
00:44:09,839 --> 00:44:14,160
do gwas on two traits and you see

1022
00:44:11,240 --> 00:44:15,400
there's one Locus that's shared well for

1023
00:44:14,160 --> 00:44:18,640
yeah maybe I'm misunderstanding the

1024
00:44:15,400 --> 00:44:22,040
model but if you have one shared variant

1025
00:44:18,640 --> 00:44:23,720
between two traits but that there's 50

1026
00:44:22,040 --> 00:44:25,640
different variants between the traits

1027
00:44:23,720 --> 00:44:27,559
that you don't know about you might

1028
00:44:25,640 --> 00:44:29,040
think that your traits are perfectly

1029
00:44:27,559 --> 00:44:30,640
generically correlated oh I see what

1030
00:44:29,040 --> 00:44:31,680
you're saying so I think that in that

1031
00:44:30,640 --> 00:44:32,839
case you would get something that's not

1032
00:44:31,680 --> 00:44:36,079
a perfect correlation because a lot of

1033
00:44:32,839 --> 00:44:39,440
your betas would be zero here um right

1034
00:44:36,079 --> 00:44:42,599
so like you can imagine you've got uh

1035
00:44:39,440 --> 00:44:44,800
like beta a and beta B and maybe you've

1036
00:44:42,599 --> 00:44:46,960
got something where you've got like a a

1037
00:44:44,800 --> 00:44:48,920
shared maybe it has the same effect size

1038
00:44:46,960 --> 00:44:50,000
for the two variants but then you've got

1039
00:44:48,920 --> 00:44:51,400
I'm just going to use ones and zeros

1040
00:44:50,000 --> 00:44:52,839
you've got a bunch of ones and zeros

1041
00:44:51,400 --> 00:44:57,440
here and then you've got a bunch of ones

1042
00:44:52,839 --> 00:44:59,680
and zeros here um so that uh this Cor is

1043
00:44:57,440 --> 00:45:01,839
going to be really far from one and when

1044
00:44:59,680 --> 00:45:03,839
you start like uh when you plug this

1045
00:45:01,839 --> 00:45:06,359
into this and you get this then the

1046
00:45:03,839 --> 00:45:09,000
correlation is going to be far from one

1047
00:45:06,359 --> 00:45:11,160
in the case you don't know those other

1048
00:45:09,000 --> 00:45:11,160
you

1049
00:45:12,920 --> 00:45:16,440
only yeah yeah so this gets again at the

1050
00:45:15,400 --> 00:45:18,280
difference between what we're trying to

1051
00:45:16,440 --> 00:45:19,440
estimate and what we are estimating so I

1052
00:45:18,280 --> 00:45:22,680
think you'll agree what we're trying to

1053
00:45:19,440 --> 00:45:26,119
estimate is um uh is definitely far from

1054
00:45:22,680 --> 00:45:28,480
zero um the methods for doing this um

1055
00:45:26,119 --> 00:45:30,400
don't Begin by looking only at

1056
00:45:28,480 --> 00:45:33,440
genomewide significant Losi so they

1057
00:45:30,400 --> 00:45:36,480
actually do incorporate uh uh data

1058
00:45:33,440 --> 00:45:38,119
genomewide rather whether or not the um

1059
00:45:36,480 --> 00:45:40,359
the locus has reached genomewide

1060
00:45:38,119 --> 00:45:41,720
significance and so then I I guess I

1061
00:45:40,359 --> 00:45:43,839
really haven't gone into any detail

1062
00:45:41,720 --> 00:45:47,040
about this but once you write down you

1063
00:45:43,839 --> 00:45:49,920
know let's say our model is that um um

1064
00:45:47,040 --> 00:45:53,040
uh the ordered pair beta ja beta JB um

1065
00:45:49,920 --> 00:45:55,319
is drawn IID from some byari normal

1066
00:45:53,040 --> 00:45:57,440
distribution where the IID is over Snips

1067
00:45:55,319 --> 00:46:00,280
J and now we want to infer

1068
00:45:57,440 --> 00:46:03,599
um parameters of that distribution so

1069
00:46:00,280 --> 00:46:06,319
you can um start with that as your model

1070
00:46:03,599 --> 00:46:08,880
and then derive uh properties of the

1071
00:46:06,319 --> 00:46:11,680
distribution of X and Y that let you

1072
00:46:08,880 --> 00:46:14,760
then do you know valid inference on the

1073
00:46:11,680 --> 00:46:14,760
properties of beta to begin

1074
00:46:15,400 --> 00:46:19,760
with I think with that we're out of time

1075
00:46:18,000 --> 00:46:22,000
but I'm sure Hillary could take a few

1076
00:46:19,760 --> 00:46:25,520
questions afterwards um so let's thank

1077
00:46:22,000 --> 00:46:25,520
her one more time


1
00:00:00,240 --> 00:00:04,480
And with that, I'd like to present you

2
00:00:02,399 --> 00:00:07,600
Altastata. Thank you.

3
00:00:04,480 --> 00:00:10,800
>> Hello everyone. My name is Silvski. I'm

4
00:00:07,600 --> 00:00:13,120
a former MIT link and lab researcher now

5
00:00:10,800 --> 00:00:17,199
CEO of Alastata.

6
00:00:13,120 --> 00:00:19,920
And we secure AI supply chain with the

7
00:00:17,199 --> 00:00:22,720
encryption.

8
00:00:19,920 --> 00:00:25,920
The supply chain starts with multiple

9
00:00:22,720 --> 00:00:29,840
silos and collaboration with partner

10
00:00:25,920 --> 00:00:32,160
sources and it ends up with inference in

11
00:00:29,840 --> 00:00:36,000
production. So there are several

12
00:00:32,160 --> 00:00:39,360
potential problems data set poisoning

13
00:00:36,000 --> 00:00:41,280
compromising model storage rack document

14
00:00:39,360 --> 00:00:44,399
poisoning

15
00:00:41,280 --> 00:00:47,120
and so what are the two key security

16
00:00:44,399 --> 00:00:49,440
problem for AI? First of all is data

17
00:00:47,120 --> 00:00:54,160
integrity. Google report says that

18
00:00:49,440 --> 00:00:57,520
attacker only needs to control 0.01%

19
00:00:54,160 --> 00:01:01,199
of the data set to completely poison the

20
00:00:57,520 --> 00:01:04,000
model. The other one is partners trust.

21
00:01:01,199 --> 00:01:07,920
So when you use AI data center that

22
00:01:04,000 --> 00:01:10,080
provides you GPUs energy, you lose the

23
00:01:07,920 --> 00:01:12,880
control of your data because it's beyond

24
00:01:10,080 --> 00:01:17,040
the perimeter of your organization.

25
00:01:12,880 --> 00:01:20,080
The solution is autoata.

26
00:01:17,040 --> 00:01:22,479
Our product is fortified data lake. It

27
00:01:20,080 --> 00:01:26,080
can be established in any cloud or

28
00:01:22,479 --> 00:01:29,439
private storage. It supports any file

29
00:01:26,080 --> 00:01:32,320
formats. It protect the model in

30
00:01:29,439 --> 00:01:34,799
training and in use. So we provide

31
00:01:32,320 --> 00:01:37,600
userfriendly application

32
00:01:34,799 --> 00:01:40,079
seamless integration with data platforms

33
00:01:37,600 --> 00:01:43,040
like datab bricks pytor torch and if you

34
00:01:40,079 --> 00:01:46,720
use confidential containers you have end

35
00:01:43,040 --> 00:01:48,880
to end fully homamorphic encryption.

36
00:01:46,720 --> 00:01:52,880
Additionally, we provide the tools for

37
00:01:48,880 --> 00:01:54,960
compliance like GDPR, AI act, NIS, RMF

38
00:01:52,880 --> 00:01:58,240
and others.

39
00:01:54,960 --> 00:02:00,799
That all ensures invisible security when

40
00:01:58,240 --> 00:02:04,320
data scientist can focus on their core

41
00:02:00,799 --> 00:02:07,280
tasks. An auto starta handles security

42
00:02:04,320 --> 00:02:09,759
transparently in the background.

43
00:02:07,280 --> 00:02:15,280
Each file is encrypted with a separate

44
00:02:09,759 --> 00:02:17,599
key also verified and compressed.

45
00:02:15,280 --> 00:02:20,800
So while

46
00:02:17,599 --> 00:02:23,599
we combine security and efficiency for

47
00:02:20,800 --> 00:02:26,319
AI. So security means full control

48
00:02:23,599 --> 00:02:29,360
beyond the perimeter of the of your

49
00:02:26,319 --> 00:02:33,280
organization likewise inside your

50
00:02:29,360 --> 00:02:36,080
organization and also data immutability.

51
00:02:33,280 --> 00:02:38,800
Nobody can change this data. An

52
00:02:36,080 --> 00:02:42,080
efficiency for AI means seamless

53
00:02:38,800 --> 00:02:45,440
integration with AI data platforms and

54
00:02:42,080 --> 00:02:49,519
also realtime performance. The solution

55
00:02:45,440 --> 00:02:52,720
is based on patent that embraces

56
00:02:49,519 --> 00:02:55,200
automatic key management and unique data

57
00:02:52,720 --> 00:02:58,239
structure optimized for fast AI

58
00:02:55,200 --> 00:03:00,720
processing. Additionally, our data

59
00:02:58,239 --> 00:03:03,120
compression enables to work with

60
00:03:00,720 --> 00:03:06,720
encrypted data three times faster than

61
00:03:03,120 --> 00:03:11,519
even with unencrypted data and also it

62
00:03:06,720 --> 00:03:13,920
provides 63% of costsaving on storage.

63
00:03:11,519 --> 00:03:17,360
So let's see some particular use case.

64
00:03:13,920 --> 00:03:20,159
This is Massachusetts open cloud that

65
00:03:17,360 --> 00:03:23,280
supports Boston hospitals

66
00:03:20,159 --> 00:03:26,239
and Boston hospital want to conduct

67
00:03:23,280 --> 00:03:28,239
collaborative medical research with CR

68
00:03:26,239 --> 00:03:30,959
CRO

69
00:03:28,239 --> 00:03:33,519
clinical research organization

70
00:03:30,959 --> 00:03:36,239
and eliminate data breaches or data

71
00:03:33,519 --> 00:03:39,200
poisoning. So the solution for such

72
00:03:36,239 --> 00:03:41,280
approach is data clean room and they get

73
00:03:39,200 --> 00:03:44,959
it from alterata.

74
00:03:41,280 --> 00:03:48,640
Uh for each partata data lake provides

75
00:03:44,959 --> 00:03:51,599
secure boxes. So each party shares their

76
00:03:48,640 --> 00:03:56,080
encrypted data sets with training

77
00:03:51,599 --> 00:03:58,640
applications only not with humans not

78
00:03:56,080 --> 00:04:00,959
with each other. uh they also

79
00:03:58,640 --> 00:04:05,360
collaborate with startup which is data

80
00:04:00,959 --> 00:04:08,159
partner that enables them remotely

81
00:04:05,360 --> 00:04:11,680
accessing encrypted data without

82
00:04:08,159 --> 00:04:14,080
duplication. When the model is trained

83
00:04:11,680 --> 00:04:16,479
it goes to production and they can start

84
00:04:14,080 --> 00:04:19,440
data processing on encrypted data in

85
00:04:16,479 --> 00:04:23,520
real time. So what the key benefits of

86
00:04:19,440 --> 00:04:26,160
this approach? It's zero trust. So by

87
00:04:23,520 --> 00:04:30,080
encryption it supports uh red hot open

88
00:04:26,160 --> 00:04:33,040
shift and confidential computers. It's

89
00:04:30,080 --> 00:04:34,639
no data duplication and it's also cost

90
00:04:33,040 --> 00:04:38,320
savings.

91
00:04:34,639 --> 00:04:41,040
We are MIT based team. Our solution is

92
00:04:38,320 --> 00:04:45,199
cross industry cross geography. We

93
00:04:41,040 --> 00:04:47,600
partnering with AWS, Microsoft, Red Hat

94
00:04:45,199 --> 00:04:50,560
and for Red Hat uh we have direct

95
00:04:47,600 --> 00:04:54,080
support of their global CTO.

96
00:04:50,560 --> 00:04:56,560
So what we ask if you share our vision

97
00:04:54,080 --> 00:04:59,440
uh we would love to learn your use cases

98
00:04:56,560 --> 00:05:04,560
and run pilots. Please connect me on

99
00:04:59,440 --> 00:05:06,960
LinkedIn uh and contact via email.

100
00:05:04,560 --> 00:05:08,720
>> Thank you so much Serge. Um great to

101
00:05:06,960 --> 00:05:10,560
hear your presentation. We have a

102
00:05:08,720 --> 00:05:13,039
question from the audience. Um how do

103
00:05:10,560 --> 00:05:16,039
you deal with the data exfiltration ilk

104
00:05:13,039 --> 00:05:16,039
exfiltration

105
00:05:17,680 --> 00:05:22,240
>> with data exfiltration? We don't we

106
00:05:19,759 --> 00:05:24,560
don't do data exfiltration. We we

107
00:05:22,240 --> 00:05:26,720
partner with companies they do it but in

108
00:05:24,560 --> 00:05:29,680
general in case of alterata there is no

109
00:05:26,720 --> 00:05:33,280
need to do data exfiltration because we

110
00:05:29,680 --> 00:05:37,280
encrypt the entire data set. So you

111
00:05:33,280 --> 00:05:39,919
cannot breach it or poison.

112
00:05:37,280 --> 00:05:41,440
>> Thank you. And one more question why is

113
00:05:39,919 --> 00:05:44,240
Redhead so interesting partnering with

114
00:05:41,440 --> 00:05:46,880
Altata and at the CTO level?

115
00:05:44,240 --> 00:05:50,080
>> Yeah because we have actually similar

116
00:05:46,880 --> 00:05:53,919
strategy. So we're also multicloud.

117
00:05:50,080 --> 00:05:56,720
We also work with AI data centers and

118
00:05:53,919 --> 00:05:59,280
Red Hat actually builds this AI data

119
00:05:56,720 --> 00:06:01,840
centers and we collaborate with

120
00:05:59,280 --> 00:06:05,039
confidential containers group at Red

121
00:06:01,840 --> 00:06:07,520
Hat. So together with autoata it builds

122
00:06:05,039 --> 00:06:10,520
full homamorphic postquantum

123
00:06:07,520 --> 00:06:10,520
computation.


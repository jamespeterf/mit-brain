1
00:00:00,199 --> 00:00:05,839
let me introduce our first keynote

2
00:00:02,560 --> 00:00:10,679
speaker Professor Simon Johnson for many

3
00:00:05,839 --> 00:00:13,639
of you I'm sure you know him he's so uh

4
00:00:10,679 --> 00:00:15,719
well known across the world but I still

5
00:00:13,639 --> 00:00:18,680
want to follow the pattern follow the

6
00:00:15,719 --> 00:00:22,279
procedure to make a brief

7
00:00:18,680 --> 00:00:26,039
introduction Professor Sim Simon Johnson

8
00:00:22,279 --> 00:00:29,080
is Ronald Co professor of

9
00:00:26,039 --> 00:00:32,239
Entrepreneurship and professor of global

10
00:00:29,080 --> 00:00:36,000
economics and the management in s School

11
00:00:32,239 --> 00:00:37,280
of Management here Salon is the head of

12
00:00:36,000 --> 00:00:39,800
the global

13
00:00:37,280 --> 00:00:42,559
economics and Management

14
00:00:39,800 --> 00:00:47,399
Group he co-chaired the

15
00:00:42,559 --> 00:00:49,920
CFA Institute Sy systemic risk Council

16
00:00:47,399 --> 00:00:56,000
and served as

17
00:00:49,920 --> 00:00:58,120
IMF Chief econom Economist Economist in

18
00:00:56,000 --> 00:01:03,920
2007 to

19
00:00:58,120 --> 00:01:06,200
2008 among many other duties titles and

20
00:01:03,920 --> 00:01:12,360
achievements he also

21
00:01:06,200 --> 00:01:15,439
cheer uh MIT shaping the future of work

22
00:01:12,360 --> 00:01:19,040
initiative um I also want to mention his

23
00:01:15,439 --> 00:01:22,960
recent book called power and

24
00:01:19,040 --> 00:01:26,280
progress which is highly recommended by

25
00:01:22,960 --> 00:01:29,600
McKenzie for corporate

26
00:01:26,280 --> 00:01:31,810
Executives now let's welcome Professor

27
00:01:29,600 --> 00:01:33,970
uh

28
00:01:31,810 --> 00:01:37,060
[Applause]

29
00:01:33,970 --> 00:01:37,060
[Music]

30
00:01:41,960 --> 00:01:48,000
Johnson uh thank thanks very much for

31
00:01:44,240 --> 00:01:51,040
those uh kind words of introduction um

32
00:01:48,000 --> 00:01:54,560
welcome to MIT H it's a great pleasure

33
00:01:51,040 --> 00:01:58,039
to have you here I I I first um set foot

34
00:01:54,560 --> 00:02:00,840
on the MIT campus 39 years ago I came to

35
00:01:58,039 --> 00:02:02,719
get my my PhD I was 10 let's be very

36
00:02:00,840 --> 00:02:05,439
clear about

37
00:02:02,719 --> 00:02:06,799
that and and and I've um been away and

38
00:02:05,439 --> 00:02:07,799
done various other things as gray

39
00:02:06,799 --> 00:02:09,720
mentioned including being Chief

40
00:02:07,799 --> 00:02:13,080
Economist of the IMF but I'm always

41
00:02:09,720 --> 00:02:14,920
pulled back to MIT to the campus to all

42
00:02:13,080 --> 00:02:16,519
of the invention that takes place here

43
00:02:14,920 --> 00:02:18,560
I'm not an engineer I'm not a scientist

44
00:02:16,519 --> 00:02:20,920
I'm an economist and I want to talk to

45
00:02:18,560 --> 00:02:23,000
you today about what we know and a lot

46
00:02:20,920 --> 00:02:26,360
about what we don't know about the

47
00:02:23,000 --> 00:02:30,280
potential economic and management uh

48
00:02:26,360 --> 00:02:31,599
impact of the latest wave of Technology

49
00:02:30,280 --> 00:02:34,920
which we're putting Under The Heading of

50
00:02:31,599 --> 00:02:37,480
of generative AI um I have written a

51
00:02:34,920 --> 00:02:39,879
book grae was kind enough to mention uh

52
00:02:37,480 --> 00:02:42,519
Power and progress our 1,000 year

53
00:02:39,879 --> 00:02:44,400
struggle over technology and prosperity

54
00:02:42,519 --> 00:02:45,959
it's it's a great read and and it's

55
00:02:44,400 --> 00:02:48,000
really good for thumping the podium and

56
00:02:45,959 --> 00:02:49,440
it'll shut people up at Thanksgiving if

57
00:02:48,000 --> 00:02:52,400
you want to quiet down those relatives

58
00:02:49,440 --> 00:02:54,159
give them this but uh you you can also

59
00:02:52,400 --> 00:02:55,640
uh read the free summaries on our

60
00:02:54,159 --> 00:02:56,920
website at the shape in the future of

61
00:02:55,640 --> 00:02:58,000
work initiative where we have policy

62
00:02:56,920 --> 00:03:00,640
papers and we have various other

63
00:02:58,000 --> 00:03:02,360
presentations of it um

64
00:03:00,640 --> 00:03:04,920
the the key points uh that I that I want

65
00:03:02,360 --> 00:03:06,760
to address or or or or or land with you

66
00:03:04,920 --> 00:03:07,920
today are on my first slide which has

67
00:03:06,760 --> 00:03:09,200
already been up for a couple of minutes

68
00:03:07,920 --> 00:03:10,560
so you've taken photographs of it

69
00:03:09,200 --> 00:03:12,599
perhaps some of you already these slides

70
00:03:10,560 --> 00:03:15,120
will all be available um to everybody

71
00:03:12,599 --> 00:03:17,080
subsequently and uh you know I think

72
00:03:15,120 --> 00:03:19,360
people like you legitimately and and

73
00:03:17,080 --> 00:03:21,760
should want to know the bottom line how

74
00:03:19,360 --> 00:03:23,480
how big an impact are we talking about

75
00:03:21,760 --> 00:03:25,040
and and of course A lot of the things

76
00:03:23,480 --> 00:03:26,599
that you going to see today and a lot of

77
00:03:25,040 --> 00:03:29,439
things we see around us are still fairly

78
00:03:26,599 --> 00:03:31,200
small scale um sometimes people or

79
00:03:29,439 --> 00:03:32,799
perhaps at a moment where there was a

80
00:03:31,200 --> 00:03:34,120
lot of enthusiasm some people are saying

81
00:03:32,799 --> 00:03:36,319
well a lot of this stuff looks

82
00:03:34,120 --> 00:03:38,360
relatively trivial let's remember that

83
00:03:36,319 --> 00:03:40,200
the internet uh when we first started to

84
00:03:38,360 --> 00:03:42,799
to see it emerge in the early 1990s also

85
00:03:40,200 --> 00:03:46,159
seemed relatively small scale and now

86
00:03:42,799 --> 00:03:48,000
we're uh we use digital as our password

87
00:03:46,159 --> 00:03:50,959
passcode on asking questions and do

88
00:03:48,000 --> 00:03:52,640
please put your questions through um

89
00:03:50,959 --> 00:03:54,560
pigeon hole as as greme suggested and

90
00:03:52,640 --> 00:03:57,239
we'll we'll I have at least 10 minutes

91
00:03:54,560 --> 00:03:59,439
at the end to talk about those so what

92
00:03:57,239 --> 00:04:02,400
what you hear what look what I hear and

93
00:03:59,439 --> 00:04:04,920
probably what you hear is is a range of

94
00:04:02,400 --> 00:04:08,040
views about the impact of AI including

95
00:04:04,920 --> 00:04:09,799
some people who are extremely optimistic

96
00:04:08,040 --> 00:04:12,319
and and there are certainly very

97
00:04:09,799 --> 00:04:15,480
credible well- financed brilliant people

98
00:04:12,319 --> 00:04:16,959
who say congratulations humans will soon

99
00:04:15,480 --> 00:04:19,759
never have to work again that view is

100
00:04:16,959 --> 00:04:21,320
out there there's other views of course

101
00:04:19,759 --> 00:04:23,320
which you also hear and these are also

102
00:04:21,320 --> 00:04:26,199
very smart people uh in the technology

103
00:04:23,320 --> 00:04:28,360
space also um who say that we're going

104
00:04:26,199 --> 00:04:30,520
to get mass unemployment that will lose

105
00:04:28,360 --> 00:04:32,800
jobs and and we won't actually boost

106
00:04:30,520 --> 00:04:34,560
marginal productivity which is the the

107
00:04:32,800 --> 00:04:36,120
Cornerstone of of what determines how

108
00:04:34,560 --> 00:04:37,840
much I get paid how much you get paid

109
00:04:36,120 --> 00:04:39,520
how much everyone gets paid so that may

110
00:04:37,840 --> 00:04:41,759
not actually we may not actually benefit

111
00:04:39,520 --> 00:04:45,479
that much and we we could end up with

112
00:04:41,759 --> 00:04:47,560
either very polarized Society or just

113
00:04:45,479 --> 00:04:48,880
um a lot of benefits in the hands of

114
00:04:47,560 --> 00:04:51,600
very few people which is an extreme form

115
00:04:48,880 --> 00:04:54,199
of polarization uh if you only want to

116
00:04:51,600 --> 00:04:55,479
read one book after I speak today you

117
00:04:54,199 --> 00:04:56,960
should read power and progress It's a

118
00:04:55,479 --> 00:04:59,280
great read but if you want to read two

119
00:04:56,960 --> 00:05:01,680
books Kurt vet's play a piano which was

120
00:04:59,280 --> 00:05:03,080
written in the late 1940s I think it was

121
00:05:01,680 --> 00:05:05,600
published actually in the early 1950s

122
00:05:03,080 --> 00:05:07,160
his first novel is really interesting

123
00:05:05,600 --> 00:05:10,560
because he picked up a lot of the ideas

124
00:05:07,160 --> 00:05:12,800
that were swirling around um Automation

125
00:05:10,560 --> 00:05:15,960
in in that period as computers obviously

126
00:05:12,800 --> 00:05:17,600
were just beginning to emerge um and

127
00:05:15,960 --> 00:05:19,720
what was Norbert weiner who's a

128
00:05:17,600 --> 00:05:22,160
professor in it called cybernetics which

129
00:05:19,720 --> 00:05:23,680
is a forerunner of today's AI people

130
00:05:22,160 --> 00:05:24,560
were worried about some of the exact

131
00:05:23,680 --> 00:05:28,880
same

132
00:05:24,560 --> 00:05:30,759
issues so uh our Baseline scenario then

133
00:05:28,880 --> 00:05:32,360
this is myself and my colleagues I'll

134
00:05:30,759 --> 00:05:34,360
mention their names again in a moment on

135
00:05:32,360 --> 00:05:36,240
the next slide our Baseline scenario and

136
00:05:34,360 --> 00:05:38,319
so looking at let's say 10 to 20 years

137
00:05:36,240 --> 00:05:40,440
which is a stretch honestly and it's

138
00:05:38,319 --> 00:05:41,400
beyond the The Horizon that that many

139
00:05:40,440 --> 00:05:43,120
people would be comfortable making

140
00:05:41,400 --> 00:05:44,960
forecasts when technology is changing

141
00:05:43,120 --> 00:05:47,880
this much but at least based on what we

142
00:05:44,960 --> 00:05:50,039
see currently and I'll go through uh

143
00:05:47,880 --> 00:05:51,840
many of the Salient details in in a

144
00:05:50,039 --> 00:05:53,880
moment the US Progressive growth will

145
00:05:51,840 --> 00:05:56,440
remain as it is as as we've seen it as

146
00:05:53,880 --> 00:05:57,919
it as it has been so it's not a big jump

147
00:05:56,440 --> 00:05:59,759
up in productivity growth it's not a

148
00:05:57,919 --> 00:06:01,639
deceleration in productivity growth also

149
00:05:59,759 --> 00:06:03,919
which is helpful given other things

150
00:06:01,639 --> 00:06:05,560
happening in our society we do think

151
00:06:03,919 --> 00:06:07,759
there'll be more polarization of the job

152
00:06:05,560 --> 00:06:09,599
market and I will try to pass that out

153
00:06:07,759 --> 00:06:11,560
for you in in various ways so it means

154
00:06:09,599 --> 00:06:13,479
some people win and some people don't

155
00:06:11,560 --> 00:06:15,880
win from the way this technology will be

156
00:06:13,479 --> 00:06:17,880
deployed um and and there's also

157
00:06:15,880 --> 00:06:20,280
dimensions of of global inequality that

158
00:06:17,880 --> 00:06:22,000
I will flag for you extremely early days

159
00:06:20,280 --> 00:06:23,319
to be making statements about that but I

160
00:06:22,000 --> 00:06:24,960
I think that's a little bit of an

161
00:06:23,319 --> 00:06:26,440
important context and that will tie into

162
00:06:24,960 --> 00:06:28,880
some of the speakers you hear later this

163
00:06:26,440 --> 00:06:30,599
afternoon but here's the key point and

164
00:06:28,880 --> 00:06:32,960
this is what I emphasize with you and

165
00:06:30,599 --> 00:06:33,960
and with audiences all across the US and

166
00:06:32,960 --> 00:06:37,759
actually the world who want to talk

167
00:06:33,960 --> 00:06:39,520
about this there is absolutely nothing

168
00:06:37,759 --> 00:06:42,599
in any technological Revolution

169
00:06:39,520 --> 00:06:44,840
including this one that is pre-ordained

170
00:06:42,599 --> 00:06:48,039
or happens necessarily or it just

171
00:06:44,840 --> 00:06:50,800
happens to be this way technology is not

172
00:06:48,039 --> 00:06:53,080
that technology is a tool technology is

173
00:06:50,800 --> 00:06:55,039
malleable technology is subject to

174
00:06:53,080 --> 00:06:56,639
social choices now where are those

175
00:06:55,039 --> 00:06:58,280
choices made a lot of those choices are

176
00:06:56,639 --> 00:06:59,879
made in the United States because at the

177
00:06:58,280 --> 00:07:01,400
Forefront of inventing lot of those

178
00:06:59,879 --> 00:07:02,919
choices are made around technical

179
00:07:01,400 --> 00:07:04,280
universities like MIT because that's

180
00:07:02,919 --> 00:07:05,879
where people at the Forefront but a lot

181
00:07:04,280 --> 00:07:07,680
of those choices frankly made by you

182
00:07:05,879 --> 00:07:09,599
because you are in business and you are

183
00:07:07,680 --> 00:07:11,360
deciding where to deploy Capital how to

184
00:07:09,599 --> 00:07:13,039
move labor who should get trained who

185
00:07:11,360 --> 00:07:15,599
needs to be let go and so on so these

186
00:07:13,039 --> 00:07:18,199
are major choices that we're making I

187
00:07:15,599 --> 00:07:21,319
mean pretty much on a daily basis in

188
00:07:18,199 --> 00:07:23,360
this Society at this moment a and I

189
00:07:21,319 --> 00:07:25,360
think it's quite fair and reasonable and

190
00:07:23,360 --> 00:07:27,120
not at all anti-technology I can't be

191
00:07:25,360 --> 00:07:29,840
anti-technology I've worked at MIT for

192
00:07:27,120 --> 00:07:31,360
40 years it's in my title the team is

193
00:07:29,840 --> 00:07:33,000
technology right I'm not actually

194
00:07:31,360 --> 00:07:35,160
technology I'm saying we can shape

195
00:07:33,000 --> 00:07:38,280
technology we can choose technological

196
00:07:35,160 --> 00:07:40,199
paths we have chosen better paths in in

197
00:07:38,280 --> 00:07:42,000
the past we've also chosen some paths

198
00:07:40,199 --> 00:07:44,800
that were not so advantageous for more

199
00:07:42,000 --> 00:07:46,759
people and I'll go through that so those

200
00:07:44,800 --> 00:07:48,639
are the questions I want to put to you

201
00:07:46,759 --> 00:07:50,400
today and and and that's what we

202
00:07:48,639 --> 00:07:53,479
continue to Grapple with in in our

203
00:07:50,400 --> 00:07:55,360
initiative this is um joint work uh with

204
00:07:53,479 --> 00:07:58,360
donon asoglu who's a professor Institute

205
00:07:55,360 --> 00:08:00,520
professor at MIT an economist uh and a

206
00:07:58,360 --> 00:08:02,400
specialist on economic growth and and

207
00:08:00,520 --> 00:08:04,280
political economy and David orter who's

208
00:08:02,400 --> 00:08:06,039
one of the country's most famous labor

209
00:08:04,280 --> 00:08:09,199
economists we have an initiative called

210
00:08:06,039 --> 00:08:10,440
shaping the future of work and um we

211
00:08:09,199 --> 00:08:12,319
have a website where you can see a lot

212
00:08:10,440 --> 00:08:15,800
more about our work and we have the book

213
00:08:12,319 --> 00:08:17,440
that I already mentioned the the tagline

214
00:08:15,800 --> 00:08:19,240
and and and I you know this is a very

215
00:08:17,440 --> 00:08:20,639
memorable conversation I had with a

216
00:08:19,240 --> 00:08:23,599
leading entrepreneur in this space so I

217
00:08:20,639 --> 00:08:25,800
won't name um when when I asked this

218
00:08:23,599 --> 00:08:27,720
person what will be the job market

219
00:08:25,800 --> 00:08:30,080
consequences of this technology in the

220
00:08:27,720 --> 00:08:32,919
full deployment mode this person said we

221
00:08:30,080 --> 00:08:35,240
will all be gods and he meant it

222
00:08:32,919 --> 00:08:37,560
somewhat literally as in you will have

223
00:08:35,240 --> 00:08:39,599
the tools necessary to manipulate the

224
00:08:37,560 --> 00:08:42,279
universe around you which which is a

225
00:08:39,599 --> 00:08:44,159
pretty extraordinary and extreme claim

226
00:08:42,279 --> 00:08:46,600
and and I think we can talk about that

227
00:08:44,159 --> 00:08:48,839
if you want this talk and our focus is

228
00:08:46,600 --> 00:08:51,480
much more on who gets a good job and who

229
00:08:48,839 --> 00:08:53,240
doesn't because our view based on a lot

230
00:08:51,480 --> 00:08:56,360
of history and and what we see around us

231
00:08:53,240 --> 00:08:59,040
is that it's that um

232
00:08:56,360 --> 00:09:01,240
employment decision it's the matching of

233
00:08:59,040 --> 00:09:04,720
people and Technology it's the way in

234
00:09:01,240 --> 00:09:07,680
which jobs change that's what drives

235
00:09:04,720 --> 00:09:09,079
both aggregate Prosperity as well as who

236
00:09:07,680 --> 00:09:11,279
wins and who loses in these

237
00:09:09,079 --> 00:09:13,160
technological

238
00:09:11,279 --> 00:09:17,680
Transformations and and I think it's

239
00:09:13,160 --> 00:09:17,680
very important to to say at the

240
00:09:18,120 --> 00:09:21,920
beginning something that's probably

241
00:09:20,079 --> 00:09:25,279
fairly obvious to you but it's still

242
00:09:21,920 --> 00:09:27,079
important to to establish which is

243
00:09:25,279 --> 00:09:29,480
nothing happens in a vacuum every

244
00:09:27,079 --> 00:09:31,920
technological Revolution happens in a

245
00:09:29,480 --> 00:09:33,880
place it happens in a society it happens

246
00:09:31,920 --> 00:09:35,880
with a system of incentives and I and I

247
00:09:33,880 --> 00:09:39,399
think it's very important to ask

248
00:09:35,880 --> 00:09:41,000
ourselves where are we today um and and

249
00:09:39,399 --> 00:09:43,839
what have we experienced particularly

250
00:09:41,000 --> 00:09:45,720
over the past 40 years I'll do more

251
00:09:43,839 --> 00:09:49,120
longer term American history in a few

252
00:09:45,720 --> 00:09:51,600
moments but what's really striking about

253
00:09:49,120 --> 00:09:53,800
the the US economy since 1980 is that

254
00:09:51,600 --> 00:09:56,880
we've continued to innovate obviously we

255
00:09:53,800 --> 00:09:59,760
were coming into the 1970s and into the

256
00:09:56,880 --> 00:10:02,120
1980s with a remarkably successful a

257
00:09:59,760 --> 00:10:05,279
broad-based economic well some people

258
00:10:02,120 --> 00:10:07,760
call it Miracle it was certainly uh uh a

259
00:10:05,279 --> 00:10:09,560
very impressive and somewhat or even

260
00:10:07,760 --> 00:10:11,880
substantially surprising economic

261
00:10:09,560 --> 00:10:13,760
performance in the three decades after

262
00:10:11,880 --> 00:10:15,519
World War II the US exceeded

263
00:10:13,760 --> 00:10:17,279
expectations and and the fears of Kurt

264
00:10:15,519 --> 00:10:19,839
vona in the late 1940s did not

265
00:10:17,279 --> 00:10:22,000
materialize we did not have a more

266
00:10:19,839 --> 00:10:26,040
polarized Society in 1980 than we'd had

267
00:10:22,000 --> 00:10:28,920
in 1949 for example um but since the

268
00:10:26,040 --> 00:10:31,279
1940s this has changed and and I don't

269
00:10:28,920 --> 00:10:34,920
want to suggest that any particular

270
00:10:31,279 --> 00:10:36,920
person or company or even set of ideas

271
00:10:34,920 --> 00:10:38,000
was to blame for this I think this is

272
00:10:36,920 --> 00:10:40,079
something that just happened in the

273
00:10:38,000 --> 00:10:41,560
society around us the consequence of all

274
00:10:40,079 --> 00:10:45,440
those social decisions I was mentioning

275
00:10:41,560 --> 00:10:48,959
earlier but we shifted from a view of

276
00:10:45,440 --> 00:10:51,839
workers as a resource to be cultivated

277
00:10:48,959 --> 00:10:53,839
and enhanced and improved I'll talk

278
00:10:51,839 --> 00:10:55,920
about the history of that to to a to a

279
00:10:53,839 --> 00:10:58,040
view that wages are a cost to be

280
00:10:55,920 --> 00:11:00,519
minimized in an increasingly globalized

281
00:10:58,040 --> 00:11:05,079
economy we can use technology to

282
00:11:00,519 --> 00:11:08,000
automate and to cut labor costs and that

283
00:11:05,079 --> 00:11:10,279
has driven it's not the only driver but

284
00:11:08,000 --> 00:11:12,839
it's a major driver perhaps the major

285
00:11:10,279 --> 00:11:15,760
driver of the picture that you see at

286
00:11:12,839 --> 00:11:18,040
the top which is what's happened to real

287
00:11:15,760 --> 00:11:20,200
work weekly earnings I've got men at the

288
00:11:18,040 --> 00:11:23,040
top women at the bottom the pattern is

289
00:11:20,200 --> 00:11:26,600
similar for women but less dramatic um

290
00:11:23,040 --> 00:11:28,880
which is you see from um the 1960s that

291
00:11:26,600 --> 00:11:30,639
men with graduate degrees and Bachelor

292
00:11:28,880 --> 00:11:32,480
degrees which I'm guessing is most

293
00:11:30,639 --> 00:11:36,040
people in in this room have done

294
00:11:32,480 --> 00:11:39,440
relatively well um in real terms people

295
00:11:36,040 --> 00:11:41,800
who only finished high school barely

296
00:11:39,440 --> 00:11:43,920
improved and people who um dropped out

297
00:11:41,800 --> 00:11:46,560
of high school have not experienced

298
00:11:43,920 --> 00:11:48,639
improved improved earnings so we've had

299
00:11:46,560 --> 00:11:50,519
a what economists like to call skill

300
00:11:48,639 --> 00:11:52,079
biased Technologies just means that the

301
00:11:50,519 --> 00:11:54,200
technology is more advantageous to

302
00:11:52,079 --> 00:11:57,279
people who have more formal education in

303
00:11:54,200 --> 00:12:00,000
this in this context and it's quite

304
00:11:57,279 --> 00:12:02,240
likely

305
00:12:00,000 --> 00:12:03,959
but not necessarily the case that AI

306
00:12:02,240 --> 00:12:06,760
will continue these relatively

307
00:12:03,959 --> 00:12:09,000
polarizing trends when when I asked um

308
00:12:06,760 --> 00:12:12,920
one CEO

309
00:12:09,000 --> 00:12:15,040
about who could be replaced with AI the

310
00:12:12,920 --> 00:12:17,959
CEO used a term and it's not my term

311
00:12:15,040 --> 00:12:19,800
it's his term um but he said he thought

312
00:12:17,959 --> 00:12:22,120
it was people who had what he called cut

313
00:12:19,800 --> 00:12:23,880
and paste jobs it means jobs that have

314
00:12:22,120 --> 00:12:25,480
some repetitive element in them not

315
00:12:23,880 --> 00:12:27,800
entirely repetitious otherwise they

316
00:12:25,480 --> 00:12:32,680
would would already have been automated

317
00:12:27,800 --> 00:12:34,399
but um if you you look at um the wage

318
00:12:32,680 --> 00:12:36,600
distribution of people who are present

319
00:12:34,399 --> 00:12:39,480
on active on LinkedIn for example it's

320
00:12:36,600 --> 00:12:42,680
between the 20th and 30th percentile

321
00:12:39,480 --> 00:12:44,040
it's people who have um what's sometimes

322
00:12:42,680 --> 00:12:45,720
regarded as pretty good white collar

323
00:12:44,040 --> 00:12:48,920
jobs but they have this

324
00:12:45,720 --> 00:12:50,959
repetitious um Dimension to them they

325
00:12:48,920 --> 00:12:53,720
are absolutely in the line of fire for

326
00:12:50,959 --> 00:12:56,959
this um grahe mentioned McKenzie a

327
00:12:53,720 --> 00:12:59,839
moment ago I helped um McKenzie Paris

328
00:12:56,959 --> 00:13:01,720
office do a report just now came out a

329
00:12:59,839 --> 00:13:03,360
few months ago comparing the US and

330
00:13:01,720 --> 00:13:06,240
Europe in terms of Labor Market

331
00:13:03,360 --> 00:13:08,480
Transitions and what is required in

332
00:13:06,240 --> 00:13:10,519
terms of the change of jobs and people

333
00:13:08,480 --> 00:13:12,800
being retrained or retraining themselves

334
00:13:10,519 --> 00:13:14,639
to new positions at least in the

335
00:13:12,800 --> 00:13:17,519
Mackenzie analysis which I commend you

336
00:13:14,639 --> 00:13:19,399
to look at the US has a lot of work to

337
00:13:17,519 --> 00:13:21,320
do but would have the same sort of

338
00:13:19,399 --> 00:13:23,839
turnover of the labor market that we

339
00:13:21,320 --> 00:13:26,120
experienced um in the decades in the

340
00:13:23,839 --> 00:13:29,199
decade at least before covid the problem

341
00:13:26,120 --> 00:13:30,880
for Europe is actually um more substan

342
00:13:29,199 --> 00:13:32,839
anal Europe will need to people to

343
00:13:30,880 --> 00:13:34,680
change jobs and find new jobs and

344
00:13:32,839 --> 00:13:37,760
acquire new skills at roughly the rate

345
00:13:34,680 --> 00:13:39,760
they did during covid so it happened but

346
00:13:37,760 --> 00:13:41,160
that was a very intense Sprint on the

347
00:13:39,760 --> 00:13:43,360
part of the European economy and that's

348
00:13:41,160 --> 00:13:44,720
a major adjustment if they're able to Su

349
00:13:43,360 --> 00:13:48,079
for them to sustain that over the next

350
00:13:44,720 --> 00:13:50,560
let's say uh 10 years in addition that

351
00:13:48,079 --> 00:13:52,000
there are obviously risks that are that

352
00:13:50,560 --> 00:13:53,160
we talk about we work on in our

353
00:13:52,000 --> 00:13:56,480
initiative but it's not the main main

354
00:13:53,160 --> 00:13:57,680
focus today about what happens to the um

355
00:13:56,480 --> 00:13:59,600
what's the impact of AI on

356
00:13:57,680 --> 00:14:01,880
misinformation on social media and on

357
00:13:59,600 --> 00:14:05,480
democracy and our our ability to make

358
00:14:01,880 --> 00:14:08,920
reasonable decisions I I I attended a a

359
00:14:05,480 --> 00:14:11,079
a briefing um I was a I was a witness a

360
00:14:08,920 --> 00:14:13,079
panelist at at a briefing for a a a

361
00:14:11,079 --> 00:14:14,519
congressional panel earlier this year

362
00:14:13,079 --> 00:14:16,199
that Congressional panel was held behind

363
00:14:14,519 --> 00:14:19,240
closed doors there was no cameras there

364
00:14:16,199 --> 00:14:21,160
was no publicity it was an extremely

365
00:14:19,240 --> 00:14:22,720
sensible reasonable bipartisan

366
00:14:21,160 --> 00:14:24,320
discussion with a lot of different views

367
00:14:22,720 --> 00:14:26,120
on different sides of the aisle you

368
00:14:24,320 --> 00:14:27,160
would have been quite impressed if you'd

369
00:14:26,120 --> 00:14:28,759
been there but you weren't there because

370
00:14:27,160 --> 00:14:30,600
it was Private en closed and it was out

371
00:14:28,759 --> 00:14:32,120
of the public light and I think that's a

372
00:14:30,600 --> 00:14:34,120
little bit of a problem is that once

373
00:14:32,120 --> 00:14:36,040
when when we're in this public space

374
00:14:34,120 --> 00:14:38,560
where the view views can get magnified

375
00:14:36,040 --> 00:14:40,000
exaggerated or distorted um we are not

376
00:14:38,560 --> 00:14:43,279
doing so

377
00:14:40,000 --> 00:14:44,600
well now there's a couple more technical

378
00:14:43,279 --> 00:14:47,120
pieces here that I'm not going to dwell

379
00:14:44,600 --> 00:14:48,680
on um but they're in the slides and you

380
00:14:47,120 --> 00:14:51,199
can look at

381
00:14:48,680 --> 00:14:53,880
them one thing that economists care a

382
00:14:51,199 --> 00:14:55,279
lot about and look at and we have pretty

383
00:14:53,880 --> 00:14:58,360
good data on this over long periods of

384
00:14:55,279 --> 00:15:00,880
time is how much of GDP how much of the

385
00:14:58,360 --> 00:15:03,160
income that we earn in the country

386
00:15:00,880 --> 00:15:05,079
obviously we track GDP on on a weekly

387
00:15:03,160 --> 00:15:06,560
basis that's our news headlines but how

388
00:15:05,079 --> 00:15:09,120
much of that goes to labor versus

389
00:15:06,560 --> 00:15:10,600
capital and and one dramatic striking

390
00:15:09,120 --> 00:15:13,000
thing about the US is we used to have a

391
00:15:10,600 --> 00:15:15,920
lot of GDP earned by labor so that's

392
00:15:13,000 --> 00:15:17,399
wages um it declined and you can see

393
00:15:15,920 --> 00:15:19,600
it's bumpy there's some ups and there

394
00:15:17,399 --> 00:15:23,560
some some downs and there's a big up in

395
00:15:19,600 --> 00:15:25,959
in um in the in in the late 1990s which

396
00:15:23,560 --> 00:15:27,839
is when we had the it boom um but you

397
00:15:25,959 --> 00:15:30,800
can see that it's declined fairly

398
00:15:27,839 --> 00:15:33,040
steadily we do however still have quite

399
00:15:30,800 --> 00:15:36,000
a high labor share of GDP relative to

400
00:15:33,040 --> 00:15:37,639
other countries so there's no sense in

401
00:15:36,000 --> 00:15:39,040
which we've somehow bottomed out or it

402
00:15:37,639 --> 00:15:41,680
couldn't get any lower than this or it

403
00:15:39,040 --> 00:15:42,839
couldn't be the case that Capital wins

404
00:15:41,680 --> 00:15:45,040
uh more than labor actually I think

405
00:15:42,839 --> 00:15:47,319
Capital will win more than labor from

406
00:15:45,040 --> 00:15:47,319
from

407
00:15:47,959 --> 00:15:52,480
this and and let me just PL plant a flag

408
00:15:50,720 --> 00:15:55,720
in in in the question about what happens

409
00:15:52,480 --> 00:15:56,839
to Global in inequality among the many

410
00:15:55,720 --> 00:15:59,399
important speakers you're going to hear

411
00:15:56,839 --> 00:16:00,759
this afternoon John Hart who's the uh

412
00:15:59,399 --> 00:16:03,720
chair of the mechanical engineering

413
00:16:00,759 --> 00:16:06,279
department will talk to you about Ai and

414
00:16:03,720 --> 00:16:07,920
Manufacturing and um he and I and some

415
00:16:06,279 --> 00:16:11,240
other colleagues have projects looking

416
00:16:07,920 --> 00:16:13,560
at this and and I didn't talk to Jon the

417
00:16:11,240 --> 00:16:15,360
last couple of days so we'll see if I

418
00:16:13,560 --> 00:16:16,680
mean it's not surprising is it happens

419
00:16:15,360 --> 00:16:19,199
at MIT that people make dramatic

420
00:16:16,680 --> 00:16:21,160
progress but last um conversations we'

421
00:16:19,199 --> 00:16:23,240
had suggested that this is still in the

422
00:16:21,160 --> 00:16:26,279
pipeline and not

423
00:16:23,240 --> 00:16:28,120
yet transforming economies but I think

424
00:16:26,279 --> 00:16:29,800
when AI comes to factories and when it

425
00:16:28,120 --> 00:16:32,279
affects manufactur facturing it's going

426
00:16:29,800 --> 00:16:34,720
to have a really profound implication

427
00:16:32,279 --> 00:16:37,360
it's already affecting the um allocation

428
00:16:34,720 --> 00:16:39,120
of Labor across white colar jobs it

429
00:16:37,360 --> 00:16:41,000
Outsourcing in some ways we'll see what

430
00:16:39,120 --> 00:16:42,199
the net effect is on the Indian economy

431
00:16:41,000 --> 00:16:45,560
what it does for

432
00:16:42,199 --> 00:16:47,519
manufacturing um in countries like China

433
00:16:45,560 --> 00:16:49,319
and others that have used manufacturing

434
00:16:47,519 --> 00:16:51,360
and the export of manufacturing to power

435
00:16:49,319 --> 00:16:53,440
their economies that remains to be seen

436
00:16:51,360 --> 00:16:56,240
and and I think this is this is a major

437
00:16:53,440 --> 00:16:57,319
additional well concern that that needs

438
00:16:56,240 --> 00:17:00,240
to be on your

439
00:16:57,319 --> 00:17:03,639
radar now that that all might sound a

440
00:17:00,240 --> 00:17:06,120
little bit negative or a little bit

441
00:17:03,639 --> 00:17:07,600
downbeat at least and we're in a

442
00:17:06,120 --> 00:17:08,880
technology conference and we're talking

443
00:17:07,600 --> 00:17:10,679
about the future and you know I think

444
00:17:08,880 --> 00:17:12,959
it's conventional to be inspirational

445
00:17:10,679 --> 00:17:14,360
and and there is an enormous amount of

446
00:17:12,959 --> 00:17:17,000
American history with regard to

447
00:17:14,360 --> 00:17:18,679
technology that is inspirational and and

448
00:17:17,000 --> 00:17:20,640
to to just put that in a little bit of

449
00:17:18,679 --> 00:17:24,240
context in

450
00:17:20,640 --> 00:17:25,640
1851 the British held the first great

451
00:17:24,240 --> 00:17:27,439
exhibition this is the great exhibition

452
00:17:25,640 --> 00:17:29,240
of Crystal Palace where they wanted they

453
00:17:27,439 --> 00:17:31,000
invited the world to come and show their

454
00:17:29,240 --> 00:17:33,400
industrial Wares their new technology

455
00:17:31,000 --> 00:17:36,520
1851 the industrial revolution had

456
00:17:33,400 --> 00:17:38,919
really was really uh well established in

457
00:17:36,520 --> 00:17:40,440
Britain they wanted it was catching hold

458
00:17:38,919 --> 00:17:42,880
in other places they wanted people to

459
00:17:40,440 --> 00:17:44,120
show up and and and and and they were

460
00:17:42,880 --> 00:17:45,679
really interested in what was going on

461
00:17:44,120 --> 00:17:49,600
around the world the Americans sent an

462
00:17:45,679 --> 00:17:51,160
exhibit they showed up with um some guns

463
00:17:49,600 --> 00:17:53,200
and some animals they they' shot with

464
00:17:51,160 --> 00:17:55,000
those guns those were the two primary

465
00:17:53,200 --> 00:17:56,120
initial American exhibits and they got a

466
00:17:55,000 --> 00:17:57,520
little bit of stick for that I have to

467
00:17:56,120 --> 00:17:59,880
say from the British

468
00:17:57,520 --> 00:18:01,360
press for 40 years later the United

469
00:17:59,880 --> 00:18:04,039
States was the greatest manufacturing

470
00:18:01,360 --> 00:18:05,520
power in the world by a long way and

471
00:18:04,039 --> 00:18:07,840
just getting going and you can see that

472
00:18:05,520 --> 00:18:10,360
in this chart so how did this happen

473
00:18:07,840 --> 00:18:12,760
what was the transformation uh what was

474
00:18:10,360 --> 00:18:15,919
that transformation about well the the

475
00:18:12,760 --> 00:18:17,960
core piece of that was what we and many

476
00:18:15,919 --> 00:18:20,000
others have called worker augmentation

477
00:18:17,960 --> 00:18:21,799
and in a in in and there's a a term for

478
00:18:20,000 --> 00:18:23,880
it actually in economic

479
00:18:21,799 --> 00:18:25,559
history the they call it the American

480
00:18:23,880 --> 00:18:27,159
system of manufacturing and and if you

481
00:18:25,559 --> 00:18:29,080
think about it makes a lot of sense so

482
00:18:27,159 --> 00:18:31,720
who was coming to America in the in the

483
00:18:29,080 --> 00:18:33,240
early mid 19th century quite a lot of

484
00:18:31,720 --> 00:18:36,440
immigrants from different parts of

485
00:18:33,240 --> 00:18:38,480
Europe in particular without much skill

486
00:18:36,440 --> 00:18:40,159
the US was attracting and continued to

487
00:18:38,480 --> 00:18:42,919
attract throughout the 19th century a

488
00:18:40,159 --> 00:18:45,400
lot of relatively unskilled uneducated

489
00:18:42,919 --> 00:18:46,480
immigrants highly skilled people stayed

490
00:18:45,400 --> 00:18:47,520
behind in Europe because they had good

491
00:18:46,480 --> 00:18:49,320
jobs they had good incomes they didn't

492
00:18:47,520 --> 00:18:50,480
want to leave coming to the UN was a US

493
00:18:49,320 --> 00:18:53,480
was a risky

494
00:18:50,480 --> 00:18:56,880
proposition um so what did people like

495
00:18:53,480 --> 00:18:58,960
you do your exactly people like you 170

496
00:18:56,880 --> 00:19:01,000
years ago they found ways to use

497
00:18:58,960 --> 00:19:02,960
machines to boost the productivity of

498
00:19:01,000 --> 00:19:05,919
workers including workers who didn't

499
00:19:02,960 --> 00:19:09,320
have much formal education uh and the

500
00:19:05,919 --> 00:19:12,760
key balance that any economy needs to

501
00:19:09,320 --> 00:19:13,919
strike with regard to any technology

502
00:19:12,760 --> 00:19:16,640
certainly the kinds of Technologies

503
00:19:13,919 --> 00:19:20,159
we're talking about in the 19th century

504
00:19:16,640 --> 00:19:21,600
and again today is you're replacing

505
00:19:20,159 --> 00:19:23,480
workers with machines there's some

506
00:19:21,600 --> 00:19:26,520
automation there but you're also

507
00:19:23,480 --> 00:19:29,200
creating new tasks for the workers by

508
00:19:26,520 --> 00:19:31,559
deploying those machines so what V saw

509
00:19:29,200 --> 00:19:33,679
in 1949 in play a piano was automation

510
00:19:31,559 --> 00:19:35,400
replacing workers and what vut didn't

511
00:19:33,679 --> 00:19:36,960
see and I'm not blaming him because it

512
00:19:35,400 --> 00:19:38,200
was hard to see or hard it's hard to see

513
00:19:36,960 --> 00:19:40,799
this in the moment was that those

514
00:19:38,200 --> 00:19:42,640
machines in that social context created

515
00:19:40,799 --> 00:19:44,200
a lot of new tasks for workers that

516
00:19:42,640 --> 00:19:46,480
required new skills that encourag people

517
00:19:44,200 --> 00:19:48,960
to get more education and this

518
00:19:46,480 --> 00:19:50,200
technology um this American Technology

519
00:19:48,960 --> 00:19:51,480
you can see it in sewing machines you

520
00:19:50,200 --> 00:19:52,799
can see it in farm equipment you can see

521
00:19:51,480 --> 00:19:54,679
it in automobiles this spread around the

522
00:19:52,799 --> 00:19:56,880
world this had massive positive effects

523
00:19:54,679 --> 00:19:59,520
on lots of other economies and higher

524
00:19:56,880 --> 00:20:02,320
wages um for those workers were made

525
00:19:59,520 --> 00:20:04,640
possible by higher marginal productivity

526
00:20:02,320 --> 00:20:06,039
although I have to also give a big shout

527
00:20:04,640 --> 00:20:08,400
out to trade

528
00:20:06,039 --> 00:20:09,919
unions um who played a role in making

529
00:20:08,400 --> 00:20:13,080
sure that this High productivity

530
00:20:09,919 --> 00:20:15,000
high-profit firms actually did pay their

531
00:20:13,080 --> 00:20:20,799
workers more money that's an important

532
00:20:15,000 --> 00:20:20,799
part of American History so the

533
00:20:21,039 --> 00:20:27,520
um managerial story there is that we

534
00:20:24,799 --> 00:20:31,280
created again globally but the US was in

535
00:20:27,520 --> 00:20:34,520
the Forefront of this um a new class of

536
00:20:31,280 --> 00:20:37,080
engineer managers who came out of um

537
00:20:34,520 --> 00:20:39,159
skilled Crafts People Artisans I'm from

538
00:20:37,080 --> 00:20:41,400
Sheffield in the north of England and

539
00:20:39,159 --> 00:20:44,400
when I go when I trace my family history

540
00:20:41,400 --> 00:20:46,640
back as far as I can um it is uh

541
00:20:44,400 --> 00:20:49,600
carpenters and it's people who bashed

542
00:20:46,640 --> 00:20:52,080
metal and my family made screws for a

543
00:20:49,600 --> 00:20:55,799
hundred years and I would appreciate no

544
00:20:52,080 --> 00:20:58,039
jokes about that in the Q&A uh but that

545
00:20:55,799 --> 00:20:59,480
that on on my birth certificate it says

546
00:20:58,039 --> 00:21:01,320
father's occup patient screw

547
00:20:59,480 --> 00:21:03,240
manufacturer that was a family business

548
00:21:01,320 --> 00:21:07,799
for a long time so that that those small

549
00:21:03,240 --> 00:21:09,799
businesses aggregated up changed um or

550
00:21:07,799 --> 00:21:11,960
brought to us many new technologies the

551
00:21:09,799 --> 00:21:16,159
one that I would flag in terms of

552
00:21:11,960 --> 00:21:17,480
changing mindsets and possibilities and

553
00:21:16,159 --> 00:21:19,200
many Technologies upstream and

554
00:21:17,480 --> 00:21:20,600
downstream is the the locomotive and

555
00:21:19,200 --> 00:21:22,000
Railway systems and then there's a

556
00:21:20,600 --> 00:21:25,080
picture of the original George

557
00:21:22,000 --> 00:21:27,600
Stevenson's rocket from 1829 and and by

558
00:21:25,080 --> 00:21:29,440
the 1880s the the the British and and

559
00:21:27,600 --> 00:21:30,720
the Americans even more so we're running

560
00:21:29,440 --> 00:21:35,279
these incredibly impressive and

561
00:21:30,720 --> 00:21:38,600
efficient um highspeed for the day uh

562
00:21:35,279 --> 00:21:40,679
Railway systems the key thing is they

563
00:21:38,600 --> 00:21:43,200
were you needed a lot of skill you could

564
00:21:40,679 --> 00:21:44,840
acquire the skill on the job um the

565
00:21:43,200 --> 00:21:46,559
railway companies wanted their workers

566
00:21:44,840 --> 00:21:49,559
to show up they wanted to be diligent

567
00:21:46,559 --> 00:21:51,520
they wanted them to be um good with

568
00:21:49,559 --> 00:21:54,440
customers and they paid them good money

569
00:21:51,520 --> 00:21:59,120
uh to to match that and and Chang the

570
00:21:54,440 --> 00:22:00,760
economy Henry Ford transformed uh the US

571
00:21:59,120 --> 00:22:02,400
economy and well Auto automobile

572
00:22:00,760 --> 00:22:05,200
production but much more broadly in two

573
00:22:02,400 --> 00:22:06,799
ways Henry Ford is not I'm not

574
00:22:05,200 --> 00:22:10,120
recommending Henry Ford's personal views

575
00:22:06,799 --> 00:22:12,520
they're not at all Pleasant um but Henry

576
00:22:10,120 --> 00:22:15,440
for without question did two things he

577
00:22:12,520 --> 00:22:16,679
brought um car assembly onto a moving

578
00:22:15,440 --> 00:22:19,240
production line and he brought

579
00:22:16,679 --> 00:22:22,559
electricity to that production

580
00:22:19,240 --> 00:22:25,960
line when Ford started in Detroit around

581
00:22:22,559 --> 00:22:29,120
1900 uh the US made 20,000 cars with

582
00:22:25,960 --> 00:22:31,720
about 20,000 workers uh in 1929

583
00:22:29,120 --> 00:22:33,880
the US made well GM and Ford combined

584
00:22:31,720 --> 00:22:37,360
made 3 million cars and the industry

585
00:22:33,880 --> 00:22:39,880
employed 400,000 workers so Ford

586
00:22:37,360 --> 00:22:42,039
automated production he autom he used

587
00:22:39,880 --> 00:22:44,960
machines to replace workers assembling

588
00:22:42,039 --> 00:22:48,480
cars but the way in which that happened

589
00:22:44,960 --> 00:22:51,440
generated so many new tasks Upstream

590
00:22:48,480 --> 00:22:54,159
Downstream complimentary to production

591
00:22:51,440 --> 00:22:55,400
that there was a a big boom in in in

592
00:22:54,159 --> 00:22:57,080
employment in the Auto industry a

593
00:22:55,400 --> 00:22:59,440
massive boom obviously in cars and what

594
00:22:57,080 --> 00:23:01,240
you could do with cars and

595
00:22:59,440 --> 00:23:03,760
again let's not forget that the trade

596
00:23:01,240 --> 00:23:06,600
unions played a role and it was a very

597
00:23:03,760 --> 00:23:08,520
difficult time and and a lot of um a lot

598
00:23:06,600 --> 00:23:10,440
of anger and a lot of protest behind

599
00:23:08,520 --> 00:23:12,440
demanding higher wages to match their

600
00:23:10,440 --> 00:23:14,760
higher productivity because they had

601
00:23:12,440 --> 00:23:16,760
become a lot more

602
00:23:14,760 --> 00:23:19,159
productive now if you look at what

603
00:23:16,760 --> 00:23:21,360
happened to American wages and these are

604
00:23:19,159 --> 00:23:23,279
there's a very interesting data set that

605
00:23:21,360 --> 00:23:25,360
we have on wages around the world which

606
00:23:23,279 --> 00:23:26,600
is focused on low-skilled workers and

607
00:23:25,360 --> 00:23:29,320
you can look at the data set to see how

608
00:23:26,600 --> 00:23:31,000
that's defined but we're looking here at

609
00:23:29,320 --> 00:23:33,159
those production line type workers and

610
00:23:31,000 --> 00:23:35,360
we're looking at people who are um as I

611
00:23:33,159 --> 00:23:37,919
said potentially vulnerable to effect of

612
00:23:35,360 --> 00:23:39,279
AI and and so on and and you can see two

613
00:23:37,919 --> 00:23:42,120
I think quite dramatic things in this

614
00:23:39,279 --> 00:23:44,799
picture the first is and and I'm looking

615
00:23:42,120 --> 00:23:48,880
at nominal wages here so I'll show you

616
00:23:44,799 --> 00:23:51,400
real wages in in a in a few moments but

617
00:23:48,880 --> 00:23:53,240
um there is definitely an increase in

618
00:23:51,400 --> 00:23:56,679
nominal and real wages adjusting for

619
00:23:53,240 --> 00:23:58,440
inflation in the US after World War II

620
00:23:56,679 --> 00:24:02,600
and and it continues to increase into

621
00:23:58,440 --> 00:24:03,840
into the 19 uh into the 1980s um the

622
00:24:02,600 --> 00:24:05,720
real picture unfortunately after the

623
00:24:03,840 --> 00:24:08,520
1980s I said is is not so positive for

624
00:24:05,720 --> 00:24:10,279
these people I would also note um that a

625
00:24:08,520 --> 00:24:12,840
couple other countries on here I've got

626
00:24:10,279 --> 00:24:14,480
um India China and Japan I'll come back

627
00:24:12,840 --> 00:24:17,320
to India and China but look at the

628
00:24:14,480 --> 00:24:19,440
success of Japan this is what economic

629
00:24:17,320 --> 00:24:22,039
development is supposed to deliver this

630
00:24:19,440 --> 00:24:24,440
is what people wanted to see and hoped

631
00:24:22,039 --> 00:24:28,919
to see in that post-war period which is

632
00:24:24,440 --> 00:24:31,840
a country like Japan um which had some

633
00:24:28,919 --> 00:24:33,120
strong technology previously but really

634
00:24:31,840 --> 00:24:35,000
integrated itself into the global

635
00:24:33,120 --> 00:24:38,039
economy figured out how to export

636
00:24:35,000 --> 00:24:40,440
obviously sold very good cars um

637
00:24:38,039 --> 00:24:43,120
vehicles and and and and other equipment

638
00:24:40,440 --> 00:24:45,159
to the world and and their wages in

639
00:24:43,120 --> 00:24:47,880
nominal US dollar terms you see rising

640
00:24:45,159 --> 00:24:50,200
up towards us levels that is success in

641
00:24:47,880 --> 00:24:52,200
the global economy for our partners and

642
00:24:50,200 --> 00:24:54,159
of course we hope and and we believe

643
00:24:52,200 --> 00:24:55,600
that as people become wealthier they'll

644
00:24:54,159 --> 00:24:56,520
buy goods from us as well as us buying

645
00:24:55,600 --> 00:24:59,559
goods from

646
00:24:56,520 --> 00:25:01,200
them so what about AI

647
00:24:59,559 --> 00:25:03,760
where do we where where do we stand or

648
00:25:01,200 --> 00:25:05,200
what do we think AI could do now well

649
00:25:03,760 --> 00:25:06,919
it's obviously going to automate there's

650
00:25:05,200 --> 00:25:10,080
no question about that it's going to

651
00:25:06,919 --> 00:25:13,080
you're replacing workers with algorithms

652
00:25:10,080 --> 00:25:14,600
um that does not necessarily boost the

653
00:25:13,080 --> 00:25:17,120
marginal productivity of workers it does

654
00:25:14,600 --> 00:25:19,799
not necessarily raise wages in the early

655
00:25:17,120 --> 00:25:19,799
brtish Industrial

656
00:25:20,360 --> 00:25:24,520
Revolution I say 1780 1840 there was an

657
00:25:23,120 --> 00:25:26,679
enormous amount of Automation in the

658
00:25:24,520 --> 00:25:29,000
cotton industry and the production of

659
00:25:26,679 --> 00:25:31,559
cotton goods and very little increase in

660
00:25:29,000 --> 00:25:33,679
in wages uh for most people in fact for

661
00:25:31,559 --> 00:25:36,799
people who' worked in traditional

662
00:25:33,679 --> 00:25:39,120
handmade cotton Goods it was a problem

663
00:25:36,799 --> 00:25:41,039
their real wages went down quite a lot

664
00:25:39,120 --> 00:25:43,399
but if you can create new tasks with

665
00:25:41,039 --> 00:25:46,200
this AI then you can have the kind of

666
00:25:43,399 --> 00:25:48,880
economic Miracle or boom that we had in

667
00:25:46,200 --> 00:25:50,320
the US after World War II so David arter

668
00:25:48,880 --> 00:25:53,000
again as I mentioned one of my

669
00:25:50,320 --> 00:25:56,360
colleagues um has figured out that more

670
00:25:53,000 --> 00:25:59,279
than 60% of the jobs we have or had in

671
00:25:56,360 --> 00:26:02,000
the US in 2018 did not exist in

672
00:25:59,279 --> 00:26:03,799
1940 so that's the good news right

673
00:26:02,000 --> 00:26:06,440
that's what we want we want to create

674
00:26:03,799 --> 00:26:08,679
entirely new categories of jobs that

675
00:26:06,440 --> 00:26:10,720
you've never heard of and when your kids

676
00:26:08,679 --> 00:26:12,320
come to you and say Mom and Dad I want

677
00:26:10,720 --> 00:26:14,679
to create I want my careator be this and

678
00:26:12,320 --> 00:26:15,880
you say what the heck is that cut them

679
00:26:14,679 --> 00:26:18,240
some slack okay because that's the

680
00:26:15,880 --> 00:26:20,600
future new task creation and that new

681
00:26:18,240 --> 00:26:23,640
task creation has to be fast enough to

682
00:26:20,600 --> 00:26:24,600
match or exceed the pace of job loss

683
00:26:23,640 --> 00:26:27,600
through

684
00:26:24,600 --> 00:26:31,440
automation right so it was fast enough

685
00:26:27,600 --> 00:26:33,360
1940 1980 that's good that means we we

686
00:26:31,440 --> 00:26:35,520
had a rising tide that lifted all boats

687
00:26:33,360 --> 00:26:38,360
after 1980 the new task creation did not

688
00:26:35,520 --> 00:26:39,559
keep up uh with Automation and that's

689
00:26:38,360 --> 00:26:42,080
what's behind that that increased

690
00:26:39,559 --> 00:26:44,760
dispersion now there there is some there

691
00:26:42,080 --> 00:26:47,919
are some microeconomic studies specific

692
00:26:44,760 --> 00:26:50,440
looking at how chat GPT and and now

693
00:26:47,919 --> 00:26:52,880
other um generative AI Technologies can

694
00:26:50,440 --> 00:26:54,520
be used in the workplace and we do know

695
00:26:52,880 --> 00:26:57,960
that in in some context you can use it

696
00:26:54,520 --> 00:26:59,720
to complete writing tasks um based on

697
00:26:57,960 --> 00:27:00,799
what my students turn in I would say you

698
00:26:59,720 --> 00:27:02,840
need to be a look careful with some of

699
00:27:00,799 --> 00:27:03,960
those tasks uh it has improved grades in

700
00:27:02,840 --> 00:27:06,200
some cases so you can use it as a

701
00:27:03,960 --> 00:27:09,240
learning tool um and it may lessen grade

702
00:27:06,200 --> 00:27:12,039
inequality so there are very encouraging

703
00:27:09,240 --> 00:27:16,240
signs here and let's say uh a real

704
00:27:12,039 --> 00:27:18,360
potential for individuals to become more

705
00:27:16,240 --> 00:27:20,440
productive which is as I said the the

706
00:27:18,360 --> 00:27:23,520
what you need for as the basis for for

707
00:27:20,440 --> 00:27:24,679
for wage increases um it also seems that

708
00:27:23,520 --> 00:27:27,320
in some cases for example in the

709
00:27:24,679 --> 00:27:28,760
customer service um been studed by Eric

710
00:27:27,320 --> 00:27:30,039
Bolson

711
00:27:28,760 --> 00:27:31,760
my former colleague here and Danielle

712
00:27:30,039 --> 00:27:35,320
Lee who's in the business school slone

713
00:27:31,760 --> 00:27:38,039
school with me um people using the AI

714
00:27:35,320 --> 00:27:40,159
may actually become um more job

715
00:27:38,039 --> 00:27:42,640
satisfied with their job as well as the

716
00:27:40,159 --> 00:27:44,480
people who they're helping they may able

717
00:27:42,640 --> 00:27:46,919
to give them better advice

718
00:27:44,480 --> 00:27:49,039
however that category of jobs my my

719
00:27:46,919 --> 00:27:51,640
colleagues feel is highly vulnerable to

720
00:27:49,039 --> 00:27:53,799
full automation so in this interim stage

721
00:27:51,640 --> 00:27:55,880
people may feel empowered that's great

722
00:27:53,799 --> 00:27:57,640
but if we're heading towards more

723
00:27:55,880 --> 00:27:59,080
complete automation there's still a

724
00:27:57,640 --> 00:28:00,240
question of what what else are those

725
00:27:59,080 --> 00:28:02,679
people going to

726
00:28:00,240 --> 00:28:04,760
do there are also skill gaps and

727
00:28:02,679 --> 00:28:06,760
mismatches um

728
00:28:04,760 --> 00:28:08,760
and Graham standing up but I have 3

729
00:28:06,760 --> 00:28:11,279
minutes and 45 seconds gram I've got it

730
00:28:08,760 --> 00:28:13,640
okay uh that's before I go before I go

731
00:28:11,279 --> 00:28:17,399
for yeah don't worry before I go for Q&A

732
00:28:13,640 --> 00:28:21,360
um so um this is in the McKenzie report

733
00:28:17,399 --> 00:28:23,039
that that I mentioned um and um and and

734
00:28:21,360 --> 00:28:25,080
a couple other references there's an

735
00:28:23,039 --> 00:28:26,880
Amazon report that that there the bottom

736
00:28:25,080 --> 00:28:30,440
here

737
00:28:26,880 --> 00:28:32,600
so even even in the best case where

738
00:28:30,440 --> 00:28:34,559
we're going to create new tasks we still

739
00:28:32,600 --> 00:28:36,080
have to redeploy people from their

740
00:28:34,559 --> 00:28:38,159
previous jobs that are being automated

741
00:28:36,080 --> 00:28:40,480
away into those new tasks now we did a

742
00:28:38,159 --> 00:28:42,279
hug this is um economists call this

743
00:28:40,480 --> 00:28:44,480
labor market transitions or labor market

744
00:28:42,279 --> 00:28:46,279
labor turnover we did a huge amount of

745
00:28:44,480 --> 00:28:48,279
this during covid so one one thing that

746
00:28:46,279 --> 00:28:50,840
happened in Co that was a big

747
00:28:48,279 --> 00:28:52,360
surprise and somewhat positive in an

748
00:28:50,840 --> 00:28:54,440
economic sense although I understand Co

749
00:28:52,360 --> 00:28:57,240
itself was a disaster for many people

750
00:28:54,440 --> 00:28:59,519
was that people um left jobs that they

751
00:28:57,240 --> 00:29:01,799
weren't very happy with and weren't very

752
00:28:59,519 --> 00:29:03,080
productive in because those jobs didn't

753
00:29:01,799 --> 00:29:04,279
exist or they weren't getting good money

754
00:29:03,080 --> 00:29:05,679
and a lot of them went onto new

755
00:29:04,279 --> 00:29:07,320
positions that they found more

756
00:29:05,679 --> 00:29:09,159
satisfying they got better money and

757
00:29:07,320 --> 00:29:11,600
actually at the lower end of the labor

758
00:29:09,159 --> 00:29:14,200
market David otter has shown that people

759
00:29:11,600 --> 00:29:18,000
have ended up with better outcomes more

760
00:29:14,200 --> 00:29:19,840
money now what you need in AI is with

761
00:29:18,000 --> 00:29:21,919
the as AI rolls out is a version of the

762
00:29:19,840 --> 00:29:25,559
same thing but not a Sprint it's a

763
00:29:21,919 --> 00:29:28,840
sustained transition over well you tell

764
00:29:25,559 --> 00:29:31,559
me 5 to 10 years let's say um making

765
00:29:28,840 --> 00:29:32,679
that transition requires people to

766
00:29:31,559 --> 00:29:34,320
understand what they're what what's

767
00:29:32,679 --> 00:29:37,120
going on to be able to see what kind of

768
00:29:34,320 --> 00:29:38,880
skills they need to have um leadership

769
00:29:37,120 --> 00:29:40,440
from people like yourself in terms of

770
00:29:38,880 --> 00:29:42,039
this is where our labor force is going

771
00:29:40,440 --> 00:29:43,559
this is what you need and oh I just

772
00:29:42,039 --> 00:29:45,240
changed our mind because AI is do

773
00:29:43,559 --> 00:29:47,120
something different so let's pivot over

774
00:29:45,240 --> 00:29:49,159
here I mean to the extent that that's

775
00:29:47,120 --> 00:29:51,679
something that business can deliver I

776
00:29:49,159 --> 00:29:54,240
think you will uh find a lot of people

777
00:29:51,679 --> 00:29:57,200
pleased and and gratified and

778
00:29:54,240 --> 00:29:58,760
loyal um and then if we're worried about

779
00:29:57,200 --> 00:30:00,720
skill mismatches which we are worried we

780
00:29:58,760 --> 00:30:03,399
can break it down and say okay who is

781
00:30:00,720 --> 00:30:05,840
more likely to be impacted who is going

782
00:30:03,399 --> 00:30:06,679
to be less able to make the change and

783
00:30:05,840 --> 00:30:09,080
you

784
00:30:06,679 --> 00:30:10,799
know I I don't we're not doing this to

785
00:30:09,080 --> 00:30:14,600
disparage anyone or to discourage anyone

786
00:30:10,799 --> 00:30:16,200
we're doing it to try and um you know

787
00:30:14,600 --> 00:30:17,600
shed a little bit of light on what may

788
00:30:16,200 --> 00:30:19,440
happen and then track it over time so

789
00:30:17,600 --> 00:30:21,360
that we can help people like my bipers

790
00:30:19,440 --> 00:30:23,840
and friends on Capitol Hill um think

791
00:30:21,360 --> 00:30:25,200
about are there government programs are

792
00:30:23,840 --> 00:30:26,840
there ways government can government can

793
00:30:25,200 --> 00:30:29,159
encourage business is this entirely a

794
00:30:26,840 --> 00:30:32,000
private sector or Italian individual

795
00:30:29,159 --> 00:30:34,519
decision which is honestly what we tend

796
00:30:32,000 --> 00:30:36,760
to default to in the United States um

797
00:30:34,519 --> 00:30:37,799
but you can you can see um that there

798
00:30:36,760 --> 00:30:41,200
are

799
00:30:37,799 --> 00:30:43,960
some concerns from Specialists that

800
00:30:41,200 --> 00:30:47,519
women for example may be more negatively

801
00:30:43,960 --> 00:30:51,640
impacted on net um and it may be some

802
00:30:47,519 --> 00:30:53,240
younger people also who who have more um

803
00:30:51,640 --> 00:30:56,360
trouble gaining that initial foothold in

804
00:30:53,240 --> 00:30:58,200
the labor market including um or or

805
00:30:56,360 --> 00:31:01,080
specifically because of the what what

806
00:30:58,200 --> 00:31:02,080
what generative AI is able to do now

807
00:31:01,080 --> 00:31:05,200
there are some very optimistic

808
00:31:02,080 --> 00:31:07,320
macroeconomic forecasts um I think that

809
00:31:05,200 --> 00:31:10,399
those are a little bit exaggerated donon

810
00:31:07,320 --> 00:31:13,840
asoglu my colleague has a very uh well

811
00:31:10,399 --> 00:31:14,960
regarded paper uh that suggests that

812
00:31:13,840 --> 00:31:16,480
would be some productivity gains but

813
00:31:14,960 --> 00:31:18,720
they're all pretty small the the quote

814
00:31:16,480 --> 00:31:20,159
that I like here is emphasizes the one

815
00:31:18,720 --> 00:31:22,120
from John Williams who's the president

816
00:31:20,159 --> 00:31:24,320
of the New York fed New York fed uh

817
00:31:22,120 --> 00:31:25,760
president is the uh Vice chair of the

818
00:31:24,320 --> 00:31:27,440
federal OpenMarket committee that sets

819
00:31:25,760 --> 00:31:29,600
interest rates in the United States and

820
00:31:27,440 --> 00:31:31,039
and John says and I've talked about this

821
00:31:29,600 --> 00:31:34,639
directly and I think it's a Well found

822
00:31:31,039 --> 00:31:36,360
of view that AI will come AI will have

823
00:31:34,639 --> 00:31:37,760
impact but it's going to be generating

824
00:31:36,360 --> 00:31:40,240
about the same productivity growth as

825
00:31:37,760 --> 00:31:43,799
we've seen in the US of late which is

826
00:31:40,240 --> 00:31:45,279
between 1 and 1.5% so it's good it's

827
00:31:43,799 --> 00:31:48,080
positive on the productivity front it's

828
00:31:45,279 --> 00:31:49,880
a concern on the polarization front um

829
00:31:48,080 --> 00:31:52,159
and it's

830
00:31:49,880 --> 00:31:53,360
it's stories of economic Miracles seem

831
00:31:52,159 --> 00:31:57,120
to have been somewhat

832
00:31:53,360 --> 00:31:59,000
exaggerated now um if we had more time

833
00:31:57,120 --> 00:32:00,720
I'd talk about uh China and and the

834
00:31:59,000 --> 00:32:01,960
pressures from China and Global

835
00:32:00,720 --> 00:32:03,760
competition but Graham definitely wants

836
00:32:01,960 --> 00:32:05,440
me to go to questions just point out

837
00:32:03,760 --> 00:32:07,080
here that Chinese productivity has

838
00:32:05,440 --> 00:32:08,720
increased Chinese wages have increased

839
00:32:07,080 --> 00:32:12,399
nowhere near as much as Japanese wages

840
00:32:08,720 --> 00:32:15,440
and that's a very important pressure on

841
00:32:12,399 --> 00:32:17,559
our economy and on other high wage

842
00:32:15,440 --> 00:32:19,480
economies and there are many ways in

843
00:32:17,559 --> 00:32:21,720
which we could choose and push for

844
00:32:19,480 --> 00:32:23,200
policies and we do recommend these um

845
00:32:21,720 --> 00:32:25,360
that would give you a more worker

846
00:32:23,200 --> 00:32:27,480
friendly version of AI a version that

847
00:32:25,360 --> 00:32:29,519
would actually boost productivity and

848
00:32:27,480 --> 00:32:33,039
and more likely to turn into higher

849
00:32:29,519 --> 00:32:35,320
wages um and that is the book power and

850
00:32:33,039 --> 00:32:39,039
progress so I'm going to turn now to two

851
00:32:35,320 --> 00:32:41,080
questions which are going to appear

852
00:32:39,039 --> 00:32:44,840
miraculously on my on on my confidence

853
00:32:41,080 --> 00:32:48,279
monitor here with your votes or

854
00:32:44,840 --> 00:32:50,399
something you

855
00:32:48,279 --> 00:32:52,440
question yeah you can give me a round of

856
00:32:50,399 --> 00:32:54,200
applause that's good I like that oh

857
00:32:52,440 --> 00:32:56,120
that's that's

858
00:32:54,200 --> 00:32:57,279
important and and now and now we have

859
00:32:56,120 --> 00:33:00,559
about 10 minutes for me to answer

860
00:32:57,279 --> 00:33:00,559
questions are there any

861
00:33:01,399 --> 00:33:05,600
questions uh I will start the first okay

862
00:33:03,840 --> 00:33:08,080
gram gets the first question yeah yeah

863
00:33:05,600 --> 00:33:12,080
um I know you're running you you're

864
00:33:08,080 --> 00:33:15,200
leading this uh MIT initiative which

865
00:33:12,080 --> 00:33:18,519
is uh about the shaping the future of

866
00:33:15,200 --> 00:33:20,639
work and I've heard from many companies

867
00:33:18,519 --> 00:33:25,000
they they they're facing challenges how

868
00:33:20,639 --> 00:33:29,240
they can uh strategically reshape or

869
00:33:25,000 --> 00:33:30,240
upgrade or retrain their proes can you

870
00:33:29,240 --> 00:33:32,799
make some

871
00:33:30,240 --> 00:33:35,480
comments related to your research in

872
00:33:32,799 --> 00:33:38,440
this initiative sure and and I and I can

873
00:33:35,480 --> 00:33:40,120
fold that in with this um first question

874
00:33:38,440 --> 00:33:42,240
here why do you think women and younger

875
00:33:40,120 --> 00:33:45,600
jobs are anticipated to be more impacted

876
00:33:42,240 --> 00:33:48,399
by AI so the the the the field of study

877
00:33:45,600 --> 00:33:50,000
that has taken off uh existed before but

878
00:33:48,399 --> 00:33:52,880
is really getting a lot of attention now

879
00:33:50,000 --> 00:33:55,279
is is um the the technical term is Task

880
00:33:52,880 --> 00:33:57,960
exposure so um and David otter is a

881
00:33:55,279 --> 00:33:59,679
pioneer of this in we we we think of

882
00:33:57,960 --> 00:34:01,159
ourselves is having jobs and the job has

883
00:33:59,679 --> 00:34:03,120
various element and you can break those

884
00:34:01,159 --> 00:34:04,639
elements down into tasks what is exactly

885
00:34:03,120 --> 00:34:06,840
you do on a certain day or a certain

886
00:34:04,639 --> 00:34:09,159
week what is it that people um who work

887
00:34:06,840 --> 00:34:11,720
for you do and and if you look at those

888
00:34:09,159 --> 00:34:13,599
tasks you can attempt to determine how

889
00:34:11,720 --> 00:34:16,280
much of that task is at all repetitive

890
00:34:13,599 --> 00:34:18,960
it's similar this week you do pretty

891
00:34:16,280 --> 00:34:21,919
much the same as you did uh last week

892
00:34:18,960 --> 00:34:23,440
and when you look at task exposure more

893
00:34:21,919 --> 00:34:25,800
repetitive is more likely to be

894
00:34:23,440 --> 00:34:28,399
automated this is in the white collar

895
00:34:25,800 --> 00:34:31,800
space at the moment um by by generative

896
00:34:28,399 --> 00:34:33,480
AI so it's women hold more of those

897
00:34:31,800 --> 00:34:34,800
kinds of jobs with that task exposure in

898
00:34:33,480 --> 00:34:36,919
the studies that I cited and you can go

899
00:34:34,800 --> 00:34:40,760
look at the papers and younger people

900
00:34:36,919 --> 00:34:43,119
you know I think the the concern for um

901
00:34:40,760 --> 00:34:45,159
I have two College age children and and

902
00:34:43,119 --> 00:34:46,599
and the the issue is always like okay

903
00:34:45,159 --> 00:34:47,919
how do I break into a space what's the

904
00:34:46,599 --> 00:34:49,480
first thing I'm going to do and as you

905
00:34:47,919 --> 00:34:51,240
know a lot of times straight out of

906
00:34:49,480 --> 00:34:52,960
college or straight out of graduate

907
00:34:51,240 --> 00:34:55,359
school you might get relatively routine

908
00:34:52,960 --> 00:34:57,280
tasks learn the process you know have a

909
00:34:55,359 --> 00:34:59,480
bit of an apprenticeship uh for a couple

910
00:34:57,280 --> 00:35:01,480
of years but if you don't need that kind

911
00:34:59,480 --> 00:35:03,880
of work in your Law Firm or in your

912
00:35:01,480 --> 00:35:05,920
chemistry lab or in your uh

913
00:35:03,880 --> 00:35:06,960
environmental science firm why should

914
00:35:05,920 --> 00:35:08,400
you employ those young people there

915
00:35:06,960 --> 00:35:09,760
going to be additional cost let somebody

916
00:35:08,400 --> 00:35:11,400
else train them and you'll hire them

917
00:35:09,760 --> 00:35:12,640
when they've got five years experience I

918
00:35:11,400 --> 00:35:14,400
think that's the that's the pressure

919
00:35:12,640 --> 00:35:16,160
point that we're worried about and and

920
00:35:14,400 --> 00:35:18,680
that we're flagging and so greme I think

921
00:35:16,160 --> 00:35:21,480
the issue for companies that's very fair

922
00:35:18,680 --> 00:35:23,040
is to say you know I is this your

923
00:35:21,480 --> 00:35:25,920
problem or is it a social problem that

924
00:35:23,040 --> 00:35:28,000
someone else should solve and I

925
00:35:25,920 --> 00:35:31,079
understand that you know it's very to

926
00:35:28,000 --> 00:35:32,520
say the government should solve this our

927
00:35:31,079 --> 00:35:34,520
government has not been particularly

928
00:35:32,520 --> 00:35:36,880
good at helping people retrain and move

929
00:35:34,520 --> 00:35:38,640
on acquire those new skills and become

930
00:35:36,880 --> 00:35:39,480
more productive over the past 40 years

931
00:35:38,640 --> 00:35:41,440
now maybe we can come up with some

932
00:35:39,480 --> 00:35:42,720
better programs I like public private

933
00:35:41,440 --> 00:35:46,280
Partnerships I that's a core part

934
00:35:42,720 --> 00:35:47,760
obviously what we do at MIT um but I

935
00:35:46,280 --> 00:35:49,960
think we're talking about a much broader

936
00:35:47,760 --> 00:35:52,560
range of skills and jobs than we cover

937
00:35:49,960 --> 00:35:55,200
at MIT and and I think that's um that

938
00:35:52,560 --> 00:35:57,440
that's a that's a that's a problem okay

939
00:35:55,200 --> 00:35:59,079
next question is about it seems related

940
00:35:57,440 --> 00:36:01,040
uh what changes will need to happen to

941
00:35:59,079 --> 00:36:03,760
the US and Global education system to

942
00:36:01,040 --> 00:36:05,920
help put uh people workers at the center

943
00:36:03,760 --> 00:36:07,800
of this AI

944
00:36:05,920 --> 00:36:12,079
Revolution

945
00:36:07,800 --> 00:36:14,839
so some sometimes I like to say my my my

946
00:36:12,079 --> 00:36:16,599
audiences um the the question before us

947
00:36:14,839 --> 00:36:18,920
is which Neil Stevenson novel we will

948
00:36:16,599 --> 00:36:20,920
live in there are some very apocalyptic

949
00:36:18,920 --> 00:36:22,400
negative ones I think snow crash will be

950
00:36:20,920 --> 00:36:24,599
in that category but there's another

951
00:36:22,400 --> 00:36:27,079
Neil Stevenson novel called The Diamond

952
00:36:24,599 --> 00:36:28,480
age in which he imagines I mean this guy

953
00:36:27,079 --> 00:36:29,960
is amazing because he imagines things a

954
00:36:28,480 --> 00:36:31,960
long time before the rest of us get the

955
00:36:29,960 --> 00:36:34,079
memo but he imagined in the late 1990s

956
00:36:31,960 --> 00:36:35,880
that you could have individual personal

957
00:36:34,079 --> 00:36:39,720
devices that would help young people

958
00:36:35,880 --> 00:36:42,680
learn skills and become productive and

959
00:36:39,720 --> 00:36:44,880
and and and full members of society um

960
00:36:42,680 --> 00:36:46,359
in a way that was um decoupled from the

961
00:36:44,880 --> 00:36:47,920
formal education system he actually

962
00:36:46,359 --> 00:36:50,960
focused on young women in China in that

963
00:36:47,920 --> 00:36:52,400
particular story but I I think that the

964
00:36:50,960 --> 00:36:54,640
the interesting thing here or the

965
00:36:52,400 --> 00:36:58,560
possibility is to

966
00:36:54,640 --> 00:37:00,839
empower families young people

967
00:36:58,560 --> 00:37:02,040
uh whether you want to put more digital

968
00:37:00,839 --> 00:37:06,720
devices in the hands of children is of

969
00:37:02,040 --> 00:37:09,160
course a very fra issue but um enabling

970
00:37:06,720 --> 00:37:12,720
people to lowering barriers to to the

971
00:37:09,160 --> 00:37:15,440
acquisition of knowledge and enabling

972
00:37:12,720 --> 00:37:17,520
those access to that knowledge to become

973
00:37:15,440 --> 00:37:19,040
skills that you would recognize and that

974
00:37:17,520 --> 00:37:20,520
you would say yes this person has

975
00:37:19,040 --> 00:37:23,200
learned these things this person is

976
00:37:20,520 --> 00:37:27,079
useful to me I will hire

977
00:37:23,200 --> 00:37:28,960
them and we could do that through our

978
00:37:27,079 --> 00:37:30,319
K12 existing systems we can do it

979
00:37:28,960 --> 00:37:32,440
through

980
00:37:30,319 --> 00:37:33,599
universities I think we have struggled

981
00:37:32,440 --> 00:37:36,520
with it I know we've struggled with this

982
00:37:33,599 --> 00:37:37,720
over the last 40 years and I think we

983
00:37:36,520 --> 00:37:40,359
are

984
00:37:37,720 --> 00:37:42,920
um hoping for and recommending and and

985
00:37:40,359 --> 00:37:45,599
Advising much more profound

986
00:37:42,920 --> 00:37:48,760
transformation at least of um vocational

987
00:37:45,599 --> 00:37:51,200
education and skills acquisition for

988
00:37:48,760 --> 00:37:53,640
people who don't have a lot of formal

989
00:37:51,200 --> 00:37:55,960
education to to bridge those gaps and

990
00:37:53,640 --> 00:37:58,760
and to become more productive with uh

991
00:37:55,960 --> 00:38:01,440
with AI tools all right next question

992
00:37:58,760 --> 00:38:01,440
can you show me the list

993
00:38:04,040 --> 00:38:08,240
again

994
00:38:05,800 --> 00:38:12,200
uh why do you need McKenzie when you've

995
00:38:08,240 --> 00:38:13,200
got chat GPT uh 17 votes uh yeah you

996
00:38:12,200 --> 00:38:15,240
should take that up with MacKenzie

997
00:38:13,200 --> 00:38:16,839
absolutely yeah I ask them that I ask

998
00:38:15,240 --> 00:38:20,720
that all the

999
00:38:16,839 --> 00:38:23,440
time I think seriously seriously that

1000
00:38:20,720 --> 00:38:27,079
the um why do you need any why do you

1001
00:38:23,440 --> 00:38:28,680
need any analytical um capability or any

1002
00:38:27,079 --> 00:38:31,720
analytical people why do you need any

1003
00:38:28,680 --> 00:38:33,520
management if you got chat GPT why why

1004
00:38:31,720 --> 00:38:35,280
don't we just you know put a bot in

1005
00:38:33,520 --> 00:38:37,200
place and have it run a business model

1006
00:38:35,280 --> 00:38:40,079
and tell it to maximize profits and hope

1007
00:38:37,200 --> 00:38:42,599
it doesn't destroy the world uh and and

1008
00:38:40,079 --> 00:38:43,640
I think that uh you know based on our

1009
00:38:42,599 --> 00:38:44,960
current understanding obviously you're

1010
00:38:43,640 --> 00:38:46,599
going to have a very deep dive on this

1011
00:38:44,960 --> 00:38:48,040
today so you may have a different view

1012
00:38:46,599 --> 00:38:51,119
at the end of the day but based on what

1013
00:38:48,040 --> 00:38:52,839
I see and and and understand from the

1014
00:38:51,119 --> 00:38:54,760
technologist um and from how the

1015
00:38:52,839 --> 00:38:57,200
technology works is

1016
00:38:54,760 --> 00:38:59,240
that uh the the form of AI we have right

1017
00:38:57,200 --> 00:39:02,760
now

1018
00:38:59,240 --> 00:39:04,240
is good at aggregating the sum of human

1019
00:39:02,760 --> 00:39:05,640
knowledge or the way humans have

1020
00:39:04,240 --> 00:39:07,200
answered certain kinds of emails or

1021
00:39:05,640 --> 00:39:08,480
whatever you want to say that if you're

1022
00:39:07,200 --> 00:39:10,640
looking for something different

1023
00:39:08,480 --> 00:39:13,800
something humans have never

1024
00:39:10,640 --> 00:39:16,079
imagined it's less clear yes there are

1025
00:39:13,800 --> 00:39:19,319
some specific

1026
00:39:16,079 --> 00:39:21,119
um uh processes and I think chemistry

1027
00:39:19,319 --> 00:39:22,319
and Material Science is coming up this

1028
00:39:21,119 --> 00:39:23,960
morning because they've led the way on

1029
00:39:22,319 --> 00:39:25,599
this yes there happen some specific

1030
00:39:23,960 --> 00:39:27,839
instances uh like the folding of

1031
00:39:25,599 --> 00:39:29,359
proteins where uh AI is done remarkable

1032
00:39:27,839 --> 00:39:32,240
things but once you get Beyond those

1033
00:39:29,359 --> 00:39:33,880
well specified problems it's harder to

1034
00:39:32,240 --> 00:39:35,839
imagine and and if you go back and look

1035
00:39:33,880 --> 00:39:38,319
at you know how do humans invent things

1036
00:39:35,839 --> 00:39:40,000
it's not usually the high status people

1037
00:39:38,319 --> 00:39:41,560
the people at the very top of the ladder

1038
00:39:40,000 --> 00:39:43,160
the people who've built their careers

1039
00:39:41,560 --> 00:39:44,720
with one view of the world who come up

1040
00:39:43,160 --> 00:39:47,319
with a new view of the world and change

1041
00:39:44,720 --> 00:39:49,680
science or engineering or practice It's

1042
00:39:47,319 --> 00:39:51,800
usually the scrappy people The Outsiders

1043
00:39:49,680 --> 00:39:53,640
the people who are you know the the the

1044
00:39:51,800 --> 00:39:57,160
sand and the oyster that that's where we

1045
00:39:53,640 --> 00:40:00,040
get a lot of our human creativity that's

1046
00:39:57,160 --> 00:40:02,440
what we encourage at MIT and that is

1047
00:40:00,040 --> 00:40:05,640
what has served us really well over the

1048
00:40:02,440 --> 00:40:07,640
past 100 150 years so McKenzie may need

1049
00:40:05,640 --> 00:40:10,760
to reposition MIT may need to reposition

1050
00:40:07,640 --> 00:40:13,040
absolutely um I I don't think this is

1051
00:40:10,760 --> 00:40:15,800
the end I don't think chat GPT and its

1052
00:40:13,040 --> 00:40:17,400
successes will will deliver to you what

1053
00:40:15,800 --> 00:40:20,280
you're hoping for in terms of of

1054
00:40:17,400 --> 00:40:21,800
creativity and and new

1055
00:40:20,280 --> 00:40:26,839
thinking

1056
00:40:21,800 --> 00:40:28,480
uh okay do do you think AI progress

1057
00:40:26,839 --> 00:40:30,480
implementation will be hindered more by

1058
00:40:28,480 --> 00:40:32,319
governmental and business regulations or

1059
00:40:30,480 --> 00:40:33,839
our ability to develop and utilize the

1060
00:40:32,319 --> 00:40:36,520
technology successfully in an accepted

1061
00:40:33,839 --> 00:40:38,760
way look the

1062
00:40:36,520 --> 00:40:40,160
um the overwhelming sentiment in

1063
00:40:38,760 --> 00:40:42,760
Washington and I spend quite a lot of

1064
00:40:40,160 --> 00:40:45,079
time there and I talk to people about

1065
00:40:42,760 --> 00:40:47,599
this technology and other Technologies

1066
00:40:45,079 --> 00:40:49,079
the prevailing view among officials you

1067
00:40:47,599 --> 00:40:50,440
hear this in public but it's very

1068
00:40:49,079 --> 00:40:52,240
strongly articulated perhaps more in

1069
00:40:50,440 --> 00:40:53,359
private is that they do not want to get

1070
00:40:52,240 --> 00:40:56,160
in the way of

1071
00:40:53,359 --> 00:40:57,960
innovation the us as I said from the

1072
00:40:56,160 --> 00:40:59,440
19th century has led the world in terms

1073
00:40:57,960 --> 00:41:02,240
of innovation it's Innovation that

1074
00:40:59,440 --> 00:41:05,440
Propel propelled us to a world um

1075
00:41:02,240 --> 00:41:07,960
leading production role and and in

1076
00:41:05,440 --> 00:41:12,560
1940 Vana Bush who was a former dean of

1077
00:41:07,960 --> 00:41:14,079
engineering um at MIT went in to see

1078
00:41:12,560 --> 00:41:16,280
President Roosevelt in the White House

1079
00:41:14,079 --> 00:41:18,760
and said you know big global war 1940

1080
00:41:16,280 --> 00:41:21,480
the US was not in the

1081
00:41:18,760 --> 00:41:23,960
war bush veva bush

1082
00:41:21,480 --> 00:41:26,520
said big glob war is coming we need to

1083
00:41:23,960 --> 00:41:28,640
tie we need to figure out how to use our

1084
00:41:26,520 --> 00:41:31,000
engineering and science knowledge to

1085
00:41:28,640 --> 00:41:33,520
defend the United States

1086
00:41:31,000 --> 00:41:36,880
in to to enhance our national security

1087
00:41:33,520 --> 00:41:39,079
in modern language and um FDR famously

1088
00:41:36,880 --> 00:41:41,720
wrote okay on this memo and out of this

1089
00:41:39,079 --> 00:41:44,319
came a big push in the US to do exactly

1090
00:41:41,720 --> 00:41:46,920
that apply science to Military and and

1091
00:41:44,319 --> 00:41:48,200
production needs and after World War II

1092
00:41:46,920 --> 00:41:50,119
was was an

1093
00:41:48,200 --> 00:41:52,240
enormous conceptual and political

1094
00:41:50,119 --> 00:41:56,000
breakthrough to to further develop

1095
00:41:52,240 --> 00:41:57,400
science in the interest of the economy

1096
00:41:56,000 --> 00:41:59,400
in the interest of shared prosperity in

1097
00:41:57,400 --> 00:42:00,720
the interest of National Security now we

1098
00:41:59,400 --> 00:42:02,040
haven't always done a good job on that

1099
00:42:00,720 --> 00:42:04,480
we

1100
00:42:02,040 --> 00:42:05,480
um could do better I have another book

1101
00:42:04,480 --> 00:42:06,800
that came out a few years ago called

1102
00:42:05,480 --> 00:42:09,359
jump starting America where we talk

1103
00:42:06,800 --> 00:42:12,640
about exactly that but I think basically

1104
00:42:09,359 --> 00:42:15,119
nobody in a position of power wants to

1105
00:42:12,640 --> 00:42:17,160
stop Innovation or prevent Innovation

1106
00:42:15,119 --> 00:42:18,359
from developing now they may regret

1107
00:42:17,160 --> 00:42:20,240
things later there's a lot of discussion

1108
00:42:18,359 --> 00:42:23,000
about could we what can we do about

1109
00:42:20,240 --> 00:42:24,440
social media today but even if you wind

1110
00:42:23,000 --> 00:42:25,480
the clock back and say okay what's the

1111
00:42:24,440 --> 00:42:26,880
moment in which you would have said no

1112
00:42:25,480 --> 00:42:28,520
to social media before you saw the

1113
00:42:26,880 --> 00:42:30,599
effect

1114
00:42:28,520 --> 00:42:31,640
I I mean maybe with hindsight you can

1115
00:42:30,599 --> 00:42:33,440
imagine that I don't think the

1116
00:42:31,640 --> 00:42:35,440
politicians would have gone for it at at

1117
00:42:33,440 --> 00:42:36,680
the time so the US bottom line here is

1118
00:42:35,440 --> 00:42:38,960
we are going to innovate We Can't Stop

1119
00:42:36,680 --> 00:42:41,240
ourselves we can guide it we can push it

1120
00:42:38,960 --> 00:42:43,800
in certain directions but as far as the

1121
00:42:41,240 --> 00:42:45,839
US is concerned in political economy and

1122
00:42:43,800 --> 00:42:47,680
and I think leading business it's it's

1123
00:42:45,839 --> 00:42:49,240
always Full Speed Ahead on Innovation

1124
00:42:47,680 --> 00:42:52,760
and that will include generative AI

1125
00:42:49,240 --> 00:42:52,760
thank you very much


1
00:00:00,080 --> 00:00:04,200
I'm so delighted to be here with you

2
00:00:02,080 --> 00:00:06,160
guys today not only am I a native

3
00:00:04,200 --> 00:00:08,000
houstonian but I went to high school one

4
00:00:06,160 --> 00:00:09,920
mile away from here at Westchester High

5
00:00:08,000 --> 00:00:12,519
School those of you that are younger

6
00:00:09,920 --> 00:00:14,040
might remember uh Stratford High School

7
00:00:12,519 --> 00:00:16,680
I was actually in the first class that

8
00:00:14,040 --> 00:00:18,520
graduated from Stratford High School um

9
00:00:16,680 --> 00:00:20,880
and then Westchester closed and now it's

10
00:00:18,520 --> 00:00:23,760
all one big High School area so maybe

11
00:00:20,880 --> 00:00:25,480
some of your kids go to Stratford um my

12
00:00:23,760 --> 00:00:27,279
dad was a professor at the University of

13
00:00:25,480 --> 00:00:29,960
Houston so I remember the University of

14
00:00:27,279 --> 00:00:32,399
Houston sign uh I was a professor at the

15
00:00:29,960 --> 00:00:35,079
University of Texas for a few years and

16
00:00:32,399 --> 00:00:37,800
about seven years ago I moved to Boston

17
00:00:35,079 --> 00:00:40,320
part-time I live in Austin part-time uh

18
00:00:37,800 --> 00:00:43,079
and I run this research group at MIT

19
00:00:40,320 --> 00:00:45,520
called cyber security at MIT Sloan I

20
00:00:43,079 --> 00:00:47,760
have to tell you that I've had a very um

21
00:00:45,520 --> 00:00:50,239
colorful career I guess not only as a

22
00:00:47,760 --> 00:00:53,120
professor but also as a practitioner

23
00:00:50,239 --> 00:00:54,879
I've been a CIO I've been a consultant

24
00:00:53,120 --> 00:00:57,199
I'm started my career as a systems

25
00:00:54,879 --> 00:00:59,079
analyst I was very techy and then when I

26
00:00:57,199 --> 00:01:02,480
did my doctoral work I moved into the

27
00:00:59,079 --> 00:01:04,879
behavioral side of Technology how we use

28
00:01:02,480 --> 00:01:07,640
people uh in our organizations and how

29
00:01:04,879 --> 00:01:10,040
we marry people's skills with technology

30
00:01:07,640 --> 00:01:13,320
skills and that translated really well

31
00:01:10,040 --> 00:01:15,200
into this role in cyber security uh when

32
00:01:13,320 --> 00:01:17,479
Professor madnick maybe some of you know

33
00:01:15,200 --> 00:01:20,119
Stu madnick when you were at MIT still

34
00:01:17,479 --> 00:01:22,640
there uh he's a Meritus which means in

35
00:01:20,119 --> 00:01:24,600
his world he he doesn't go play golf he

36
00:01:22,640 --> 00:01:27,320
just does his research so instead of 80

37
00:01:24,600 --> 00:01:30,000
to 90 hours a week he does research 40

38
00:01:27,320 --> 00:01:32,720
hours a week and uh and we work with him

39
00:01:30,000 --> 00:01:34,520
he is our faculty adviser so uh when Stu

40
00:01:32,720 --> 00:01:38,119
asked me to come on and be the executive

41
00:01:34,520 --> 00:01:39,640
director of cams um I told him sure but

42
00:01:38,119 --> 00:01:41,640
I didn't know anything about cyber I

43
00:01:39,640 --> 00:01:43,240
know about it that's where I spent my

44
00:01:41,640 --> 00:01:45,000
career and he's like oh don't worry

45
00:01:43,240 --> 00:01:47,200
we'll teach you the Cyber stuff and it's

46
00:01:45,000 --> 00:01:49,079
so got I drank the Kool-Aid it was so

47
00:01:47,200 --> 00:01:50,799
fascinating for me I've started up my

48
00:01:49,079 --> 00:01:54,000
own research um which I'm going to

49
00:01:50,799 --> 00:01:55,520
report to you today and uh um I'm also

50
00:01:54,000 --> 00:01:58,439
the executive director so I keep the

51
00:01:55,520 --> 00:02:00,600
trains running I make sure we um have

52
00:01:58,439 --> 00:02:01,960
money to run our research and we hire

53
00:02:00,600 --> 00:02:03,960
the right people and all of the

54
00:02:01,960 --> 00:02:05,600
operational things that have to happen

55
00:02:03,960 --> 00:02:07,080
so today what we're going to talk about

56
00:02:05,600 --> 00:02:09,080
is cyber

57
00:02:07,080 --> 00:02:11,239
resilience so let me just start with a

58
00:02:09,080 --> 00:02:13,599
little audience participation so raise

59
00:02:11,239 --> 00:02:15,319
your hand if you are in a cyber security

60
00:02:13,599 --> 00:02:18,040
role in your company anybody here a

61
00:02:15,319 --> 00:02:19,000
cyber person couple people okay awesome

62
00:02:18,040 --> 00:02:20,360
don't worry I'm not putting you on the

63
00:02:19,000 --> 00:02:22,720
spot I just kind of want to get a sense

64
00:02:20,360 --> 00:02:25,120
of who you are um any of you ever

65
00:02:22,720 --> 00:02:26,879
received a fishing email I expect 100%

66
00:02:25,120 --> 00:02:29,000
here okay so you all have a little

67
00:02:26,879 --> 00:02:30,640
experience with uh you can hear my Texas

68
00:02:29,000 --> 00:02:33,680
accent yall have a little experience

69
00:02:30,640 --> 00:02:35,680
with cyber security okay um is your

70
00:02:33,680 --> 00:02:37,800
company make you take has your company

71
00:02:35,680 --> 00:02:40,080
make you make you take a training class

72
00:02:37,800 --> 00:02:41,959
in cyber security almost all of you and

73
00:02:40,080 --> 00:02:44,599
I assume most of those are either an

74
00:02:41,959 --> 00:02:46,319
annual check the box requirement or

75
00:02:44,599 --> 00:02:49,360
maybe when you started your company it

76
00:02:46,319 --> 00:02:51,640
was a um orientation kind of of program

77
00:02:49,360 --> 00:02:54,080
okay all right so I don't have to tell

78
00:02:51,640 --> 00:02:55,800
you that cyber security is a big concern

79
00:02:54,080 --> 00:02:57,800
you know this already you've seen the

80
00:02:55,800 --> 00:03:00,000
headlines you probably remember while we

81
00:02:57,800 --> 00:03:02,200
were all pandemic Facebook was was

82
00:03:00,000 --> 00:03:04,080
breached 90 million people's information

83
00:03:02,200 --> 00:03:05,840
was poured out on the internet we all

84
00:03:04,080 --> 00:03:08,440
got really nervous that our information

85
00:03:05,840 --> 00:03:10,280
maybe our kids information was out there

86
00:03:08,440 --> 00:03:12,840
but if your words with friends player

87
00:03:10,280 --> 00:03:14,680
Zinga was breach if you've ever stated a

88
00:03:12,840 --> 00:03:17,400
Marriott your your information was

89
00:03:14,680 --> 00:03:20,120
probably collected in this um breach in

90
00:03:17,400 --> 00:03:22,080
2020 if you drive a Honda or you drink

91
00:03:20,120 --> 00:03:24,000
Jack Daniels you might be interested to

92
00:03:22,080 --> 00:03:26,360
know that they were victims of Ransom

93
00:03:24,000 --> 00:03:28,879
weere you might remember Twitter being

94
00:03:26,360 --> 00:03:31,680
hacked uh back in uh while we were all

95
00:03:28,879 --> 00:03:33,560
pandemic this was 2020 they took over

96
00:03:31,680 --> 00:03:35,959
some famous people's account and they

97
00:03:33,560 --> 00:03:38,760
said if you'll give us a mill $1,000 in

98
00:03:35,959 --> 00:03:40,120
Bitcoin we'll give you $2,000 in Bitcoin

99
00:03:38,760 --> 00:03:41,640
and when you say why would you do that

100
00:03:40,120 --> 00:03:43,760
well we're rich and we know you're

101
00:03:41,640 --> 00:03:45,400
struggling and we want to help you and

102
00:03:43,760 --> 00:03:49,159
you'd be surprised how much money they

103
00:03:45,400 --> 00:03:51,519
made so solar winds was another hack uh

104
00:03:49,159 --> 00:03:53,079
that really threw a a wrench into the

105
00:03:51,519 --> 00:03:54,599
way we thought about cyber security

106
00:03:53,079 --> 00:03:57,360
because it came through our supply chain

107
00:03:54,599 --> 00:04:00,040
it was supply chain hack the Federal

108
00:03:57,360 --> 00:04:02,959
Trade Commission uh uh had this article

109
00:04:00,040 --> 00:04:05,000
about log 4J a new type of attack that

110
00:04:02,959 --> 00:04:06,519
hit our logging systems all of our

111
00:04:05,000 --> 00:04:08,120
computers do what they do because they

112
00:04:06,519 --> 00:04:11,239
are logs that keep track of what it's

113
00:04:08,120 --> 00:04:13,680
doing and that's the system that was hit

114
00:04:11,239 --> 00:04:15,400
there the point here isn't each one of

115
00:04:13,680 --> 00:04:17,880
these headlines the point here is all

116
00:04:15,400 --> 00:04:19,560
the headlines we're probably immune to

117
00:04:17,880 --> 00:04:22,840
so many of these different headlines at

118
00:04:19,560 --> 00:04:24,720
this point because cyber is such a um a

119
00:04:22,840 --> 00:04:27,160
pervasive risk that all of our

120
00:04:24,720 --> 00:04:28,880
businesses take on and we spend tons of

121
00:04:27,160 --> 00:04:32,280
money trying to manage our cyber

122
00:04:28,880 --> 00:04:34,160
security even in this case the uh uh

123
00:04:32,280 --> 00:04:36,800
right before this one the US Department

124
00:04:34,160 --> 00:04:38,840
of Homeland Security had a hack if they

125
00:04:36,800 --> 00:04:41,880
can't keep themselves secure what chance

126
00:04:38,840 --> 00:04:44,600
do we have so uh Stu madnick published

127
00:04:41,880 --> 00:04:46,000
this article uh earlier this year at uh

128
00:04:44,600 --> 00:04:47,840
Wall Street Journal saying you know if

129
00:04:46,000 --> 00:04:49,919
companies are so focused on cyber

130
00:04:47,840 --> 00:04:52,360
security why do we see the number of

131
00:04:49,919 --> 00:04:54,560
data breaches still rising and that is

132
00:04:52,360 --> 00:04:57,000
the question we spend so much money

133
00:04:54,560 --> 00:04:58,639
trying to manage our cyber security

134
00:04:57,000 --> 00:05:00,320
trying to prevent the bad guys from

135
00:04:58,639 --> 00:05:01,960
getting into our system

136
00:05:00,320 --> 00:05:03,880
and yet we still see all of these

137
00:05:01,960 --> 00:05:06,520
breaches and we still see all of this

138
00:05:03,880 --> 00:05:08,600
damage and we still see all of this risk

139
00:05:06,520 --> 00:05:10,440
so the good guys are getting good are

140
00:05:08,600 --> 00:05:12,039
good we're the good guys I hope I hope

141
00:05:10,440 --> 00:05:14,600
you're all the good guys we're the good

142
00:05:12,039 --> 00:05:17,240
guys we get we're good but the bad guys

143
00:05:14,600 --> 00:05:19,400
continue to get better faster than us

144
00:05:17,240 --> 00:05:21,400
they are very Innovative they are very

145
00:05:19,400 --> 00:05:23,440
organized you don't have to actually be

146
00:05:21,400 --> 00:05:25,160
a programmer to be a bad guy all you

147
00:05:23,440 --> 00:05:27,600
have to do is be a business person with

148
00:05:25,160 --> 00:05:29,199
bad morals you go to the dark web you

149
00:05:27,600 --> 00:05:30,919
can buy all the software you need you

150
00:05:29,199 --> 00:05:33,240
can even get a help desk to tell you how

151
00:05:30,919 --> 00:05:35,280
to launch the attack you want to launch

152
00:05:33,240 --> 00:05:36,840
it's not that the that that they some

153
00:05:35,280 --> 00:05:38,199
some bad guys are technical I'm not

154
00:05:36,840 --> 00:05:40,800
saying they're not but you don't have to

155
00:05:38,199 --> 00:05:42,479
be that so it's really easy to be a bad

156
00:05:40,800 --> 00:05:43,720
don't go do this but it's really easy to

157
00:05:42,479 --> 00:05:46,280
be a bad

158
00:05:43,720 --> 00:05:48,360
guy the incidents are increasing in

159
00:05:46,280 --> 00:05:50,880
sophistication and in frequency and

160
00:05:48,360 --> 00:05:53,199
frankly AI promises to speed this up

161
00:05:50,880 --> 00:05:55,120
that's the bad news AI promises to make

162
00:05:53,199 --> 00:05:57,479
this even worse because the bad guys can

163
00:05:55,120 --> 00:05:59,199
now imitate the good guys they can do

164
00:05:57,479 --> 00:06:01,560
things like deep fakes they can pretend

165
00:05:59,199 --> 00:06:03,280
to be your boss and ask you to send

166
00:06:01,560 --> 00:06:05,039
money someplace and you wouldn't even

167
00:06:03,280 --> 00:06:07,599
know that it wasn't really your boss

168
00:06:05,039 --> 00:06:09,560
that's asking for the money our families

169
00:06:07,599 --> 00:06:12,520
and our our organizations large and

170
00:06:09,560 --> 00:06:13,919
small are all inadequately prepared we

171
00:06:12,520 --> 00:06:16,639
don't even know where where it's coming

172
00:06:13,919 --> 00:06:18,880
from we don't know what the next bad um

173
00:06:16,639 --> 00:06:21,440
attack Vector is going to be and it's

174
00:06:18,880 --> 00:06:23,199
impossible to be 100% protected and yet

175
00:06:21,440 --> 00:06:25,560
we keep throwing money at protection we

176
00:06:23,199 --> 00:06:27,280
keep saying we need to up our um

177
00:06:25,560 --> 00:06:29,319
identity and access management we need

178
00:06:27,280 --> 00:06:32,880
to do more penetration testing we need

179
00:06:29,319 --> 00:06:34,400
to find new defenses to put in place to

180
00:06:32,880 --> 00:06:36,800
keep the bad guys

181
00:06:34,400 --> 00:06:39,280
out then and the true fact here is

182
00:06:36,800 --> 00:06:40,880
recovery once you've had a breach I

183
00:06:39,280 --> 00:06:42,720
nobody has to answer this question but

184
00:06:40,880 --> 00:06:45,280
anybody experience a

185
00:06:42,720 --> 00:06:46,840
breach yeah it's pretty costly it it

186
00:06:45,280 --> 00:06:48,720
brings your company down it could hurt

187
00:06:46,840 --> 00:06:50,639
your reputation it could have a

188
00:06:48,720 --> 00:06:52,440
financial impact it could hurt your

189
00:06:50,639 --> 00:06:55,120
operations it could destroy your

190
00:06:52,440 --> 00:06:57,479
reputation I mean the recovery is very

191
00:06:55,120 --> 00:06:59,240
costly if it's even possible we see many

192
00:06:57,479 --> 00:07:01,960
organizations particularly small and

193
00:06:59,240 --> 00:07:04,479
medium Enterprises struggle to recover

194
00:07:01,960 --> 00:07:06,199
from a cyber incident cyber security

195
00:07:04,479 --> 00:07:07,840
today is more than stealing credit card

196
00:07:06,199 --> 00:07:09,919
information it's more than just trying

197
00:07:07,840 --> 00:07:12,080
to get your customer information it's

198
00:07:09,919 --> 00:07:14,919
really about making money for the bad

199
00:07:12,080 --> 00:07:17,199
guys malware disrupting your business

200
00:07:14,919 --> 00:07:19,319
through things like ransomware or maybe

201
00:07:17,199 --> 00:07:21,759
using you and your business to get to

202
00:07:19,319 --> 00:07:24,400
your customers businesses that's supply

203
00:07:21,759 --> 00:07:25,960
chain it might even be about nation

204
00:07:24,400 --> 00:07:28,240
states trying to steal your IP and

205
00:07:25,960 --> 00:07:30,120
particularly in this world in Houston

206
00:07:28,240 --> 00:07:32,080
with all of the energy

207
00:07:30,120 --> 00:07:34,800
and and oil and gas and Innovative

208
00:07:32,080 --> 00:07:36,479
things going on here many of the cyber

209
00:07:34,800 --> 00:07:39,479
attacks that would be facing you be

210
00:07:36,479 --> 00:07:42,479
facing would potentially be uh IP nation

211
00:07:39,479 --> 00:07:44,639
states trying to get at your uh your IP

212
00:07:42,479 --> 00:07:48,080
so that's where we come in my group is

213
00:07:44,639 --> 00:07:50,360
called cams cyber security at MIT Sloan

214
00:07:48,080 --> 00:07:53,000
we focus on the managerial

215
00:07:50,360 --> 00:07:55,800
organizational strategic governance the

216
00:07:53,000 --> 00:07:58,280
business side of cyber security Now

217
00:07:55,800 --> 00:08:00,319
Technologies on our name we MIT we are

218
00:07:58,280 --> 00:08:02,840
we're technical my backg is computer

219
00:08:00,319 --> 00:08:05,199
science and Applied Mathematics um my

220
00:08:02,840 --> 00:08:07,319
colleagues are computer scientists but

221
00:08:05,199 --> 00:08:09,120
we really focus on the managerial issues

222
00:08:07,319 --> 00:08:10,440
that are uh that that we face and we

223
00:08:09,120 --> 00:08:13,560
like to look at the really tough

224
00:08:10,440 --> 00:08:16,000
questions in cyber security leadership

225
00:08:13,560 --> 00:08:18,159
we're funded by a Consortium model so

226
00:08:16,000 --> 00:08:20,440
companies like yours join our Consortium

227
00:08:18,159 --> 00:08:22,599
you can see some of the companies here

228
00:08:20,440 --> 00:08:24,479
uh and uh and the money that we raise

229
00:08:22,599 --> 00:08:27,599
through our Consortium is what funds our

230
00:08:24,479 --> 00:08:29,840
research so not only do we do we try to

231
00:08:27,599 --> 00:08:32,000
answer the most difficult questions but

232
00:08:29,840 --> 00:08:34,479
we're very action oriented our goal is

233
00:08:32,000 --> 00:08:36,159
to produce actionable insights that

234
00:08:34,479 --> 00:08:38,880
management that companies particularly

235
00:08:36,159 --> 00:08:40,959
our our Consortium companies can use so

236
00:08:38,880 --> 00:08:43,719
that they can be more cyber

237
00:08:40,959 --> 00:08:45,920
resilient so the main the main idea I

238
00:08:43,719 --> 00:08:48,120
want to leave you with today is we need

239
00:08:45,920 --> 00:08:50,680
new mechanisms to be cyber resilient and

240
00:08:48,120 --> 00:08:53,320
our research looks at these four areas

241
00:08:50,680 --> 00:08:55,720
um our beag you might remember Jim

242
00:08:53,320 --> 00:08:57,920
colins from many years ago talking about

243
00:08:55,720 --> 00:09:00,000
Good the great and so I took on this

244
00:08:57,920 --> 00:09:01,720
concept Jim Collins was a class of mine

245
00:09:00,000 --> 00:09:04,720
actually at Stanford before he was

246
00:09:01,720 --> 00:09:07,600
famous and uh and so I love his work on

247
00:09:04,720 --> 00:09:09,560
a big hairy audacious goal and our big

248
00:09:07,600 --> 00:09:11,680
hary audacious goal is to create

249
00:09:09,560 --> 00:09:14,240
groundbreaking ideas for cyber

250
00:09:11,680 --> 00:09:16,200
resilience resilience being the key word

251
00:09:14,240 --> 00:09:18,200
here now here's a list of the most

252
00:09:16,200 --> 00:09:20,200
common types of cyber attacks from this

253
00:09:18,200 --> 00:09:21,920
year this is sort of my throwaway slide

254
00:09:20,200 --> 00:09:23,560
I'm not going to go into each of these

255
00:09:21,920 --> 00:09:24,839
You' you know what most of these are

256
00:09:23,560 --> 00:09:27,720
you've seen them you've read the

257
00:09:24,839 --> 00:09:29,360
headlines um but the the attacks are the

258
00:09:27,720 --> 00:09:31,240
same it's actually the same list from

259
00:09:29,360 --> 00:09:32,480
2023 I looked at it last week just to

260
00:09:31,240 --> 00:09:34,480
make sure they hadn't changed they

261
00:09:32,480 --> 00:09:36,680
haven't changed malware denial of

262
00:09:34,480 --> 00:09:38,399
service fishing and social engineering

263
00:09:36,680 --> 00:09:39,839
those are the top three and those are

264
00:09:38,399 --> 00:09:42,519
the ones we keep throwing money at to

265
00:09:39,839 --> 00:09:44,800
try to keep the bad guys from doing that

266
00:09:42,519 --> 00:09:46,360
but today AI introduces new types of

267
00:09:44,800 --> 00:09:47,959
attacks I'm not actually going to show

268
00:09:46,360 --> 00:09:49,320
you this YouTube video but if you

269
00:09:47,959 --> 00:09:50,959
haven't seen it you should go take a

270
00:09:49,320 --> 00:09:56,800
look at it and you can just do a search

271
00:09:50,959 --> 00:09:59,720
on YouTube um uh Jordan Peele the the um

272
00:09:56,800 --> 00:10:03,160
prolific and very out there guy did a

273
00:09:59,720 --> 00:10:06,920
video where he um was a uh it was a deep

274
00:10:03,160 --> 00:10:10,000
fake of Obama and it really drives home

275
00:10:06,920 --> 00:10:12,600
how accurate and how the naked eye our

276
00:10:10,000 --> 00:10:15,160
eyes and our brains cannot differentiate

277
00:10:12,600 --> 00:10:17,040
between a deep fake and a real video of

278
00:10:15,160 --> 00:10:18,519
somebody so I'm not going to show it in

279
00:10:17,040 --> 00:10:19,959
the interest of time but if you haven't

280
00:10:18,519 --> 00:10:21,959
seen this I encourage you to go to

281
00:10:19,959 --> 00:10:23,760
YouTube and take a look at it and it

282
00:10:21,959 --> 00:10:26,920
really shows us how AI is really

283
00:10:23,760 --> 00:10:28,720
changing the playing field once again so

284
00:10:26,920 --> 00:10:31,519
if we can't keep our organizations

285
00:10:28,720 --> 00:10:34,160
completely protected from cyber attacks

286
00:10:31,519 --> 00:10:36,120
what do we do what can we do we're not

287
00:10:34,160 --> 00:10:38,320
defenseless we need to we need to put

288
00:10:36,120 --> 00:10:40,079
defenses in place don't hear from me

289
00:10:38,320 --> 00:10:42,040
that I I'm not telling you not to be

290
00:10:40,079 --> 00:10:43,240
protected I'm telling you be protected

291
00:10:42,040 --> 00:10:45,360
but what I'm telling you is we need

292
00:10:43,240 --> 00:10:46,639
something else because it's not adequate

293
00:10:45,360 --> 00:10:49,480
and the something else that we talk

294
00:10:46,639 --> 00:10:51,120
about at cams is cyber resilience now we

295
00:10:49,480 --> 00:10:53,399
talked about supply chain resilience

296
00:10:51,120 --> 00:10:56,160
earlier this morning and supply chain

297
00:10:53,399 --> 00:10:58,279
resilience is actually uh a component of

298
00:10:56,160 --> 00:11:00,519
cyber resilience but we think about

299
00:10:58,279 --> 00:11:02,240
cyber Supply chain resilience is not

300
00:11:00,519 --> 00:11:04,360
being attacked from our supply chain

301
00:11:02,240 --> 00:11:06,600
building a resilient supply chain from

302
00:11:04,360 --> 00:11:07,760
the cyber security perspective I'm not

303
00:11:06,600 --> 00:11:09,440
actually going to go into that here

304
00:11:07,760 --> 00:11:11,440
today but I'm happy to answer questions

305
00:11:09,440 --> 00:11:13,160
about that later I want to talk about a

306
00:11:11,440 --> 00:11:15,440
few other things about what resilience

307
00:11:13,160 --> 00:11:17,839
looks like at a higher level in our

308
00:11:15,440 --> 00:11:20,680
cyber security work so I'm going to talk

309
00:11:17,839 --> 00:11:23,079
about a few projects that my research

310
00:11:20,680 --> 00:11:25,040
team is doing at MIT right now so that

311
00:11:23,079 --> 00:11:26,760
you can get a flavor of the kind of um

312
00:11:25,040 --> 00:11:28,040
of actionable insights and hopefully I

313
00:11:26,760 --> 00:11:29,760
leave each of you with something you can

314
00:11:28,040 --> 00:11:32,079
do differently when you go back to your

315
00:11:29,760 --> 00:11:34,560
office tomorrow so first of all

316
00:11:32,079 --> 00:11:36,839
protection mindset is a bit different

317
00:11:34,560 --> 00:11:39,160
than resilience mindset protection

318
00:11:36,839 --> 00:11:40,880
mindset says let's keep the bad guys out

319
00:11:39,160 --> 00:11:42,760
let's put on all these protection and

320
00:11:40,880 --> 00:11:44,880
many of you may know that the prevailing

321
00:11:42,760 --> 00:11:47,360
way to protect our organization is

322
00:11:44,880 --> 00:11:49,560
called defense in depth we put defense

323
00:11:47,360 --> 00:11:51,279
after defense after defense in in a in a

324
00:11:49,560 --> 00:11:53,399
sequence and the bad guys have to wind

325
00:11:51,279 --> 00:11:55,959
their way through our defenses to get to

326
00:11:53,399 --> 00:11:58,200
our crown jewels and that works to a

327
00:11:55,959 --> 00:12:00,079
point but every time we put in a new

328
00:11:58,200 --> 00:12:02,040
defense the bad guys come up with a new

329
00:12:00,079 --> 00:12:04,680
attack and it gets around that defense

330
00:12:02,040 --> 00:12:07,240
and it's just not adequate and we can't

331
00:12:04,680 --> 00:12:09,079
invest enough in our defenses so we need

332
00:12:07,240 --> 00:12:12,320
a new way to think about it and what I

333
00:12:09,079 --> 00:12:13,920
propose is resilience mindset which says

334
00:12:12,320 --> 00:12:16,320
the bad guys we need to keep the bad

335
00:12:13,920 --> 00:12:18,600
guys out but we need to for a moment

336
00:12:16,320 --> 00:12:20,639
assume that the bad guys might get into

337
00:12:18,600 --> 00:12:22,959
our systems and what are we going to do

338
00:12:20,639 --> 00:12:24,519
about it we want to be prepared should

339
00:12:22,959 --> 00:12:26,959
the bad guys get into us and we going to

340
00:12:24,519 --> 00:12:31,040
be resilient we would like to see

341
00:12:26,959 --> 00:12:33,639
ideally um no uh uh oops that wrong

342
00:12:31,040 --> 00:12:36,199
slide we'd like to see no damage to our

343
00:12:33,639 --> 00:12:39,360
reputation we'd like to see no Financial

344
00:12:36,199 --> 00:12:41,480
damage no operational shutdowns no

345
00:12:39,360 --> 00:12:43,000
compromised passwords no data stolen

346
00:12:41,480 --> 00:12:45,199
wouldn't it be awesome if we had a Cyber

347
00:12:43,000 --> 00:12:47,120
attack and nothing happened that's

348
00:12:45,199 --> 00:12:49,079
resilience thinking it's not that they

349
00:12:47,120 --> 00:12:51,760
that that we don't put Protections in

350
00:12:49,079 --> 00:12:54,680
place it's that we built so many so many

351
00:12:51,760 --> 00:12:56,360
um responses that we could respond if

352
00:12:54,680 --> 00:12:59,240
not instantly pretty

353
00:12:56,360 --> 00:13:01,760
quickly so we've written about this um

354
00:12:59,240 --> 00:13:04,320
in uh Sloan management review published

355
00:13:01,760 --> 00:13:07,399
an article for us on how to be cyber

356
00:13:04,320 --> 00:13:08,600
resilient and um we talk about many

357
00:13:07,399 --> 00:13:10,360
different ways you can do that and I'm

358
00:13:08,600 --> 00:13:13,160
going to dive into a few of those in the

359
00:13:10,360 --> 00:13:14,839
next few minutes here so these are the

360
00:13:13,160 --> 00:13:16,800
three projects I'm going to cover very

361
00:13:14,839 --> 00:13:18,680
quickly I'm again happy to answer any

362
00:13:16,800 --> 00:13:20,440
questions for you but these are three of

363
00:13:18,680 --> 00:13:22,639
the components of building cyber

364
00:13:20,440 --> 00:13:24,519
resilience the first one is around a

365
00:13:22,639 --> 00:13:26,600
culture of cyber security now we talked

366
00:13:24,519 --> 00:13:28,399
about culture earlier this morning I'm

367
00:13:26,600 --> 00:13:30,800
going to take a little bit different uh

368
00:13:28,399 --> 00:13:33,720
uh angle on culture and talk about how

369
00:13:30,800 --> 00:13:35,680
do we create a culture of cyber security

370
00:13:33,720 --> 00:13:38,760
in our organizations cyber security

371
00:13:35,680 --> 00:13:41,160
thinking our hypothesis is everybody in

372
00:13:38,760 --> 00:13:43,279
the organization has a role to play in

373
00:13:41,160 --> 00:13:44,920
keeping our organization secure now not

374
00:13:43,279 --> 00:13:47,399
everybody's rle is the same I wouldn't

375
00:13:44,920 --> 00:13:49,199
expect most people to figure out what

376
00:13:47,399 --> 00:13:51,199
the identity and access management tool

377
00:13:49,199 --> 00:13:52,600
ought to be but I would expect every

378
00:13:51,199 --> 00:13:54,160
single one of you who raised your hand

379
00:13:52,600 --> 00:13:56,959
that you've got a fishing email to not

380
00:13:54,160 --> 00:13:59,320
click on it or to report it or to do

381
00:13:56,959 --> 00:14:00,959
something that's Ro appropriate to help

382
00:13:59,320 --> 00:14:04,480
keep our organization

383
00:14:00,959 --> 00:14:06,240
secure so we asked uh in 2017 what does

384
00:14:04,480 --> 00:14:08,040
that look like and we've come up with

385
00:14:06,240 --> 00:14:11,320
this definition of a cyber security

386
00:14:08,040 --> 00:14:13,639
culture it's the values attitudes and

387
00:14:11,320 --> 00:14:15,440
beliefs that drive behaviors in our

388
00:14:13,639 --> 00:14:16,839
organization values attitudes and

389
00:14:15,440 --> 00:14:19,040
beliefs that drive cyber secure

390
00:14:16,839 --> 00:14:21,920
behaviors and this is the model that we

391
00:14:19,040 --> 00:14:24,920
have for building a culture now many of

392
00:14:21,920 --> 00:14:26,320
you think do things like training your

393
00:14:24,920 --> 00:14:27,959
your people you all took a training

394
00:14:26,320 --> 00:14:30,639
class your organizations think if we

395
00:14:27,959 --> 00:14:32,920
train you you will will be secure and we

396
00:14:30,639 --> 00:14:34,040
know and you know that's not enough you

397
00:14:32,920 --> 00:14:35,440
might have sat through the training

398
00:14:34,040 --> 00:14:37,800
program if it was something that you had

399
00:14:35,440 --> 00:14:38,680
to do for compliance for example you

400
00:14:37,800 --> 00:14:40,279
might have been sitting through the

401
00:14:38,680 --> 00:14:42,240
training program with your phone open

402
00:14:40,279 --> 00:14:44,480
answering emails because who has time to

403
00:14:42,240 --> 00:14:47,079
take an hourlong class we've got to be

404
00:14:44,480 --> 00:14:49,279
doing other things to that are directly

405
00:14:47,079 --> 00:14:50,839
related to our work and so you're

406
00:14:49,279 --> 00:14:52,279
absorbing some of the information in the

407
00:14:50,839 --> 00:14:54,480
training program but you're really not

408
00:14:52,279 --> 00:14:56,199
absorbing everything training programs

409
00:14:54,480 --> 00:14:58,720
are super important for setting

410
00:14:56,199 --> 00:14:59,639
guidelines and they help to change the

411
00:14:58,720 --> 00:15:01,199
oops

412
00:14:59,639 --> 00:15:02,959
wrong button they help to change the

413
00:15:01,199 --> 00:15:04,839
values attitudes and beliefs they tell

414
00:15:02,959 --> 00:15:07,440
us some things we should that our

415
00:15:04,839 --> 00:15:08,720
organization thinks are important but

416
00:15:07,440 --> 00:15:10,959
what we really need to know from this

417
00:15:08,720 --> 00:15:12,680
model is that to really change behaviors

418
00:15:10,959 --> 00:15:15,079
we need to think about how do we set the

419
00:15:12,680 --> 00:15:16,639
right values attitudes and beliefs and

420
00:15:15,079 --> 00:15:19,759
those values attitudes and beliefs are

421
00:15:16,639 --> 00:15:22,440
driven not only by training programs but

422
00:15:19,759 --> 00:15:23,759
by things like what Executives do you

423
00:15:22,440 --> 00:15:25,759
know you as an executive in your

424
00:15:23,759 --> 00:15:28,519
organization your words are super

425
00:15:25,759 --> 00:15:30,279
powerful and if you turned your uh to

426
00:15:28,519 --> 00:15:32,759
your team and you said to them you know

427
00:15:30,279 --> 00:15:34,160
I know we do this project or this work

428
00:15:32,759 --> 00:15:35,720
but it's also important for us to be

429
00:15:34,160 --> 00:15:38,680
cyber secure and I want you to think

430
00:15:35,720 --> 00:15:40,680
about how you can be cyber secure in our

431
00:15:38,680 --> 00:15:41,839
company that that you're going to change

432
00:15:40,680 --> 00:15:43,279
behaviors you're going to change the

433
00:15:41,839 --> 00:15:44,920
values attitudes and beliefs people are

434
00:15:43,279 --> 00:15:46,319
going to know it's important to you if

435
00:15:44,920 --> 00:15:48,319
it's important to you it becomes

436
00:15:46,319 --> 00:15:51,759
important to the people below you that's

437
00:15:48,319 --> 00:15:54,240
not training we also see things like um

438
00:15:51,759 --> 00:15:57,759
uh reward systems one organization we

439
00:15:54,240 --> 00:16:00,600
worked with uh they rewarded people who

440
00:15:57,759 --> 00:16:02,839
came forth with a cyber security idea

441
00:16:00,600 --> 00:16:05,680
they rewarded them with cookies not the

442
00:16:02,839 --> 00:16:07,639
electronic kind the chocolate chip kind

443
00:16:05,680 --> 00:16:09,160
and they ran out of cookies the the

444
00:16:07,639 --> 00:16:12,199
Evangelist who was doing this project

445
00:16:09,160 --> 00:16:14,040
ran out of cookies within an hour he had

446
00:16:12,199 --> 00:16:16,319
dozens of cookies but people were so

447
00:16:14,040 --> 00:16:18,959
interested in getting the reward that

448
00:16:16,319 --> 00:16:20,639
they took on the task of coming up with

449
00:16:18,959 --> 00:16:23,040
cyber secure behaviors that they thought

450
00:16:20,639 --> 00:16:24,880
would be useful another organization an

451
00:16:23,040 --> 00:16:27,680
oil and gas company that we worked with

452
00:16:24,880 --> 00:16:29,880
that's um from this area they punished

453
00:16:27,680 --> 00:16:31,360
people who couldn't do cyber secure

454
00:16:29,880 --> 00:16:34,279
behaviors they use punishment they use

455
00:16:31,360 --> 00:16:36,160
the stick method in their world if you

456
00:16:34,279 --> 00:16:38,600
click on a fishing email the first time

457
00:16:36,160 --> 00:16:40,839
you get a warning the second time you're

458
00:16:38,600 --> 00:16:42,560
forced to take a little module an in

459
00:16:40,839 --> 00:16:45,440
micro module of learning that would

460
00:16:42,560 --> 00:16:47,440
teach you um what you should recognize

461
00:16:45,440 --> 00:16:49,120
the third time you met with your boss

462
00:16:47,440 --> 00:16:51,319
the fourth time you met with HR and the

463
00:16:49,120 --> 00:16:54,000
fifth time you click on a fishing email

464
00:16:51,319 --> 00:16:56,079
a test email you're fired now you might

465
00:16:54,000 --> 00:16:58,240
say wow that's that's really punitive

466
00:16:56,079 --> 00:17:00,240
and in their in most worlds that culture

467
00:16:58,240 --> 00:17:01,920
that wouldn't work but in their world

468
00:17:00,240 --> 00:17:04,600
clicking on a fishing email was too big

469
00:17:01,920 --> 00:17:06,559
a risk in their world an industrial

470
00:17:04,600 --> 00:17:09,720
control environment something could blow

471
00:17:06,559 --> 00:17:11,559
up an offshore oil rig could go down if

472
00:17:09,720 --> 00:17:13,520
you got malware into a system and they

473
00:17:11,559 --> 00:17:16,199
couldn't take a chance on having you be

474
00:17:13,520 --> 00:17:18,600
someone that couldn't learn to not click

475
00:17:16,199 --> 00:17:20,079
on fishing emails now that doesn't work

476
00:17:18,600 --> 00:17:21,520
in every organization that's not the

477
00:17:20,079 --> 00:17:23,039
culture I'm not suggesting you fire

478
00:17:21,520 --> 00:17:25,280
people who click on fishing emails but

479
00:17:23,039 --> 00:17:27,559
I'm saying you can see the impact that

480
00:17:25,280 --> 00:17:29,360
that would have that's not training but

481
00:17:27,559 --> 00:17:31,360
that does Drive behaviors

482
00:17:29,360 --> 00:17:33,520
so once we realize that it's values

483
00:17:31,360 --> 00:17:35,400
attitudes and beliefs that drive

484
00:17:33,520 --> 00:17:37,559
behaviors we have a whole bunch of other

485
00:17:35,400 --> 00:17:39,760
managerial mechanisms that help us

486
00:17:37,559 --> 00:17:42,080
change values attitudes and beliefs and

487
00:17:39,760 --> 00:17:44,080
that's what this research is all about

488
00:17:42,080 --> 00:17:47,000
so this research has been around for a

489
00:17:44,080 --> 00:17:48,320
few years um we've now extended it in a

490
00:17:47,000 --> 00:17:50,640
number of different areas and I'm going

491
00:17:48,320 --> 00:17:52,600
to talk about maturity culture maturity

492
00:17:50,640 --> 00:17:54,720
and ai's impact on culture in just a

493
00:17:52,600 --> 00:17:57,039
minute but I want to point out that it's

494
00:17:54,720 --> 00:17:58,960
also been used it's been cited by almost

495
00:17:57,039 --> 00:18:00,600
a hundred other Studies have cited our

496
00:17:58,960 --> 00:18:02,840
research and building a culture of cyber

497
00:18:00,600 --> 00:18:04,960
security we're really proud of this fact

498
00:18:02,840 --> 00:18:06,919
that our work has really impacted not

499
00:18:04,960 --> 00:18:09,039
just the managerial and the the

500
00:18:06,919 --> 00:18:10,799
organizational side but other research

501
00:18:09,039 --> 00:18:13,919
has come off come have been has been

502
00:18:10,799 --> 00:18:16,240
generated by these ideas so let me talk

503
00:18:13,919 --> 00:18:17,919
a little bit about this project going on

504
00:18:16,240 --> 00:18:19,679
right now and if you're interested in

505
00:18:17,919 --> 00:18:22,600
this project I have a QR code you can

506
00:18:19,679 --> 00:18:24,240
literally jump in today and contribute

507
00:18:22,600 --> 00:18:27,360
personally contribute to our research

508
00:18:24,240 --> 00:18:29,000
and I'll tell you how so we looked at

509
00:18:27,360 --> 00:18:30,480
culture and we said okay culture this

510
00:18:29,000 --> 00:18:32,720
makes sense we have certain set of

511
00:18:30,480 --> 00:18:34,559
values attitudes and beliefs we can look

512
00:18:32,720 --> 00:18:37,000
at managerial mechanisms and see what

513
00:18:34,559 --> 00:18:39,480
your organizations are doing we can even

514
00:18:37,000 --> 00:18:41,240
um we can quantify that but it doesn't

515
00:18:39,480 --> 00:18:43,159
mean that your whole organization is at

516
00:18:41,240 --> 00:18:44,520
the same level of maturity maybe some

517
00:18:43,159 --> 00:18:46,919
parts of your organization are more

518
00:18:44,520 --> 00:18:49,159
mature cyber security maturity than

519
00:18:46,919 --> 00:18:50,919
others and some are less maybe your

520
00:18:49,159 --> 00:18:52,600
organization is more mature than your

521
00:18:50,919 --> 00:18:56,120
competitor's organization is there some

522
00:18:52,600 --> 00:18:58,520
way that we can measure maturity of of

523
00:18:56,120 --> 00:19:01,520
uh culture we came up with this five

524
00:18:58,520 --> 00:19:03,720
different different stages in stage one

525
00:19:01,520 --> 00:19:05,799
uh we call it ad hoc um that's where

526
00:19:03,720 --> 00:19:08,280
cyber security is thought of in an

527
00:19:05,799 --> 00:19:10,400
organization as a technical term it's

528
00:19:08,280 --> 00:19:12,080
something that um you that your

529
00:19:10,400 --> 00:19:13,559
technology people put in place and

530
00:19:12,080 --> 00:19:14,960
everybody in the organization believes

531
00:19:13,559 --> 00:19:18,720
that technology people are going to keep

532
00:19:14,960 --> 00:19:20,000
us safe it's not their job uh and uh um

533
00:19:18,720 --> 00:19:21,440
employees are told what to do in

534
00:19:20,000 --> 00:19:23,080
training and awareness it's just sort of

535
00:19:21,440 --> 00:19:25,320
ad hoc it's something that it's part of

536
00:19:23,080 --> 00:19:27,280
your Technology Group and then you can

537
00:19:25,320 --> 00:19:29,559
see progressing through a few other

538
00:19:27,280 --> 00:19:32,039
levels here where they gets

539
00:19:29,559 --> 00:19:34,840
progressively more mature for I you

540
00:19:32,039 --> 00:19:37,440
might have a manager identified who owns

541
00:19:34,840 --> 00:19:39,360
building a culture of cyber security uh

542
00:19:37,440 --> 00:19:42,120
and that person is taking it Beyond just

543
00:19:39,360 --> 00:19:44,039
the technology people you might have uh

544
00:19:42,120 --> 00:19:46,520
managers actually getting involved that

545
00:19:44,039 --> 00:19:48,200
are not part of your cyber organization

546
00:19:46,520 --> 00:19:51,760
and they're helping promote cyber

547
00:19:48,200 --> 00:19:54,400
security to all employees um at stage

548
00:19:51,760 --> 00:19:57,080
four cyber security is a top priority of

549
00:19:54,400 --> 00:19:59,880
your leaders and they talk about cyber

550
00:19:57,080 --> 00:20:02,480
security and they and they promote the

551
00:19:59,880 --> 00:20:04,440
concept of values attitudes and beliefs

552
00:20:02,480 --> 00:20:06,080
that drive cyber secure behaviors I have

553
00:20:04,440 --> 00:20:08,360
an example there of a company it's a

554
00:20:06,080 --> 00:20:10,640
bank um of course nobody's going to do

555
00:20:08,360 --> 00:20:12,360
business with a bank they don't trust so

556
00:20:10,640 --> 00:20:14,679
you're already in an environment you're

557
00:20:12,360 --> 00:20:18,360
in an industry where cyber security is

558
00:20:14,679 --> 00:20:20,720
critical and in that bank the CEO not a

559
00:20:18,360 --> 00:20:23,640
technical guy starts every All Hands

560
00:20:20,720 --> 00:20:25,240
meeting with a cyber security moment he

561
00:20:23,640 --> 00:20:26,600
sometimes tells a personal story I read

562
00:20:25,240 --> 00:20:28,679
this headline and I wanted to bring it

563
00:20:26,600 --> 00:20:31,000
to your attention he sometimes tells

564
00:20:28,679 --> 00:20:32,440
tells a uh a personal story you know I

565
00:20:31,000 --> 00:20:34,679
got this fishing email did anyone else

566
00:20:32,440 --> 00:20:36,440
in the room get it sometimes he brings

567
00:20:34,679 --> 00:20:39,080
up somebody else to tell a story but the

568
00:20:36,440 --> 00:20:41,280
point is he starts his All Hands meeting

569
00:20:39,080 --> 00:20:43,039
not a cyber meeting with five minutes on

570
00:20:41,280 --> 00:20:44,480
cyber security what do you think that

571
00:20:43,039 --> 00:20:46,080
does to the

572
00:20:44,480 --> 00:20:47,919
organization well it tells the

573
00:20:46,080 --> 00:20:50,120
organization that the CEO thinks cyber

574
00:20:47,919 --> 00:20:51,720
secur is important and if the CEO thinks

575
00:20:50,120 --> 00:20:53,799
it's important his direct reports think

576
00:20:51,720 --> 00:20:57,039
it's important and it just trickles down

577
00:20:53,799 --> 00:21:00,159
the organization so that's an example of

578
00:20:57,039 --> 00:21:01,960
of a stage four company where cyber

579
00:21:00,159 --> 00:21:04,240
security is a top priority it tells the

580
00:21:01,960 --> 00:21:06,480
whole organization that the CEO really

581
00:21:04,240 --> 00:21:08,120
not only says it all of our CEOs say it

582
00:21:06,480 --> 00:21:10,320
nobody's going to say cyber secur is not

583
00:21:08,120 --> 00:21:13,120
important but he actually devotes time

584
00:21:10,320 --> 00:21:14,720
and resource to it and then stage five

585
00:21:13,120 --> 00:21:16,279
which we're still playing with we're not

586
00:21:14,720 --> 00:21:18,640
quite sure what that looks like but in

587
00:21:16,279 --> 00:21:20,840
my mind it's some sort of dynamic

588
00:21:18,640 --> 00:21:23,480
culture that shifts as our environment

589
00:21:20,840 --> 00:21:25,640
shifts as AI becomes a threat the

590
00:21:23,480 --> 00:21:28,840
somehow the culture knows the culture

591
00:21:25,640 --> 00:21:31,120
changes to U en engulf the threat that

592
00:21:28,840 --> 00:21:32,480
cyber security has it's sort of dynamic

593
00:21:31,120 --> 00:21:34,080
not quite sure how that works yet I

594
00:21:32,480 --> 00:21:36,559
don't I don't know one company that does

595
00:21:34,080 --> 00:21:37,880
it but I could imagine that kind of um

596
00:21:36,559 --> 00:21:40,559
of of

597
00:21:37,880 --> 00:21:42,960
culture so um the tool that we've come

598
00:21:40,559 --> 00:21:44,960
up with we're calling Maps it has a

599
00:21:42,960 --> 00:21:47,080
management uh component it has an

600
00:21:44,960 --> 00:21:48,919
attitudes values and beliefs component

601
00:21:47,080 --> 00:21:50,679
has a policies component has a strategy

602
00:21:48,919 --> 00:21:51,880
component let me tell you I struggled

603
00:21:50,679 --> 00:21:54,279
with the name for this because these

604
00:21:51,880 --> 00:21:56,559
letters also spell spam but I didn't

605
00:21:54,279 --> 00:22:00,080
think it was a good idea to call a cyber

606
00:21:56,559 --> 00:22:01,840
secur tool spam so I'm call it maps and

607
00:22:00,080 --> 00:22:03,880
the idea here is that each one of these

608
00:22:01,840 --> 00:22:05,559
four components is something we can

609
00:22:03,880 --> 00:22:06,840
measure we can measure through a survey

610
00:22:05,559 --> 00:22:09,360
we might be able to measure through

611
00:22:06,840 --> 00:22:11,240
observation management would be mo

612
00:22:09,360 --> 00:22:13,159
ownership and motivation for culture

613
00:22:11,240 --> 00:22:15,760
things like is there a culture leader

614
00:22:13,159 --> 00:22:17,960
are there resilience plans attitudes

615
00:22:15,760 --> 00:22:20,320
would be things like Unwritten rules is

616
00:22:17,960 --> 00:22:22,840
there individual empowerment do people

617
00:22:20,320 --> 00:22:25,960
feel individually responsible policies

618
00:22:22,840 --> 00:22:27,520
are things like rules and procedures is

619
00:22:25,960 --> 00:22:29,799
there training programs is there

620
00:22:27,520 --> 00:22:32,039
compliance is there microlearning are

621
00:22:29,799 --> 00:22:33,880
there rewards and consequences and

622
00:22:32,039 --> 00:22:36,200
strategy would be things like goals and

623
00:22:33,880 --> 00:22:37,919
plans is there group collaboration is

624
00:22:36,200 --> 00:22:40,200
there funding for cyber security you can

625
00:22:37,919 --> 00:22:41,720
see where this is going so I have a

626
00:22:40,200 --> 00:22:43,480
survey I know you don't have time to do

627
00:22:41,720 --> 00:22:45,960
it right now but if you're interested in

628
00:22:43,480 --> 00:22:48,480
helping us with this project this is a

629
00:22:45,960 --> 00:22:50,880
QR code and this is a link that I would

630
00:22:48,480 --> 00:22:52,520
love for you to to go to you can do it

631
00:22:50,880 --> 00:22:54,120
after at the break or tomorrow whenever

632
00:22:52,520 --> 00:22:56,440
you have time it's a survey we're

633
00:22:54,120 --> 00:22:58,720
testing out so you would be completing

634
00:22:56,440 --> 00:23:01,000
our survey which is basically asking

635
00:22:58,720 --> 00:23:03,720
questions about all the maps components

636
00:23:01,000 --> 00:23:05,520
and it'll help us to fine-tune this

637
00:23:03,720 --> 00:23:07,320
measurement tool that we're going after

638
00:23:05,520 --> 00:23:09,080
I promise you this is not spam I'm not

639
00:23:07,320 --> 00:23:10,600
tricking you there's no trick here I'm

640
00:23:09,080 --> 00:23:12,320
really trying to figure out if the tool

641
00:23:10,600 --> 00:23:14,000
that we've come up with if the qual

642
00:23:12,320 --> 00:23:16,400
trick survey is working or not so if

643
00:23:14,000 --> 00:23:18,840
you'd like to help us out please do we'd

644
00:23:16,400 --> 00:23:22,520
love to have your uh your input our goal

645
00:23:18,840 --> 00:23:24,840
is to fine-tune this survey and then to

646
00:23:22,520 --> 00:23:26,640
build uh not only a tool that that you

647
00:23:24,840 --> 00:23:28,880
could use and that we could publish and

648
00:23:26,640 --> 00:23:31,120
that would be open to the public but

649
00:23:28,880 --> 00:23:33,080
also once we know what level you're at

650
00:23:31,120 --> 00:23:35,600
to give you prescriptions about how to

651
00:23:33,080 --> 00:23:38,760
get to the next level so if we evaluate

652
00:23:35,600 --> 00:23:40,000
you as a you know level two here's three

653
00:23:38,760 --> 00:23:42,360
things you could do to move your

654
00:23:40,000 --> 00:23:43,320
organization to a level three maturity

655
00:23:42,360 --> 00:23:44,640
that's our goal that's where we're

656
00:23:43,320 --> 00:23:47,200
headed with this

657
00:23:44,640 --> 00:23:49,200
project okay let me talk quickly about

658
00:23:47,200 --> 00:23:52,039
two other projects and then I'm happy to

659
00:23:49,200 --> 00:23:53,919
answer any questions um I know the topic

660
00:23:52,039 --> 00:23:55,760
of this whole meeting was about Ai and

661
00:23:53,919 --> 00:23:57,520
we do have a project one of my

662
00:23:55,760 --> 00:23:58,840
colleagues says AI sucking the air out

663
00:23:57,520 --> 00:24:01,080
of every other topic in in the world

664
00:23:58,840 --> 00:24:03,440
today so you can't come on stage and not

665
00:24:01,080 --> 00:24:06,440
mention Ai and I do have a project that

666
00:24:03,440 --> 00:24:08,679
looks at Ai and impact on culture we are

667
00:24:06,440 --> 00:24:09,919
in the process right now of publishing

668
00:24:08,679 --> 00:24:11,480
we have a working paper and we're

669
00:24:09,919 --> 00:24:13,720
publishing we're trying to publish it in

670
00:24:11,480 --> 00:24:15,240
an academic Journal um so I want to

671
00:24:13,720 --> 00:24:18,039
share with you some of the thoughts from

672
00:24:15,240 --> 00:24:19,840
that project so this is the same model

673
00:24:18,039 --> 00:24:22,159
that I just showed you we have external

674
00:24:19,840 --> 00:24:24,360
influences managerial mechanisms values

675
00:24:22,159 --> 00:24:27,440
attitudes and beliefs and behaviors and

676
00:24:24,360 --> 00:24:28,880
we identified five ways where AI might

677
00:24:27,440 --> 00:24:31,520
impact culture

678
00:24:28,880 --> 00:24:34,279
AI could um generate new external

679
00:24:31,520 --> 00:24:36,880
influences like the bad guys maybe

680
00:24:34,279 --> 00:24:38,360
building deep fakes of um that that

681
00:24:36,880 --> 00:24:41,360
impact our our

682
00:24:38,360 --> 00:24:43,559
organization um AI can modify or change

683
00:24:41,360 --> 00:24:45,840
our values attitudes and beliefs people

684
00:24:43,559 --> 00:24:47,520
might want to start using Ai and that

685
00:24:45,840 --> 00:24:49,520
would make them think that they don't no

686
00:24:47,520 --> 00:24:51,640
longer responsible for some of the work

687
00:24:49,520 --> 00:24:53,240
that they are responsible for or it

688
00:24:51,640 --> 00:24:54,440
might enhance the way they're doing the

689
00:24:53,240 --> 00:24:58,399
work that they're doing so it might

690
00:24:54,440 --> 00:24:59,760
change how they value um or or or use

691
00:24:58,399 --> 00:25:01,919
technology tools

692
00:24:59,760 --> 00:25:04,159
digitization um AI can generate new

693
00:25:01,919 --> 00:25:06,919
managerial mechanisms it can offer us

694
00:25:04,159 --> 00:25:09,399
some guide rails that we can use to

695
00:25:06,919 --> 00:25:12,640
promote cyber secure values attitudes

696
00:25:09,399 --> 00:25:14,600
and beliefs um it can stop the creation

697
00:25:12,640 --> 00:25:17,480
of values attitudes and beliefs again it

698
00:25:14,600 --> 00:25:21,399
could be either through the um use of AI

699
00:25:17,480 --> 00:25:23,399
to generate um uh uh messages um

700
00:25:21,399 --> 00:25:25,840
individually tailored messages that to

701
00:25:23,399 --> 00:25:27,640
individuals based on how they best learn

702
00:25:25,840 --> 00:25:29,880
things that would change the values

703
00:25:27,640 --> 00:25:32,559
attitudes and beliefs that they have or

704
00:25:29,880 --> 00:25:34,120
it might uh get in the way of executing

705
00:25:32,559 --> 00:25:37,320
different values attitudes and beliefs

706
00:25:34,120 --> 00:25:39,279
we could see AI building new barriers so

707
00:25:37,320 --> 00:25:41,919
in this work here we've come up with

708
00:25:39,279 --> 00:25:44,000
five themes we did this through a survey

709
00:25:41,919 --> 00:25:46,159
with one of our research Partners me one

710
00:25:44,000 --> 00:25:49,240
of the members of cams we surveyed about

711
00:25:46,159 --> 00:25:51,799
150 Executives over a couple of months

712
00:25:49,240 --> 00:25:54,360
period we did some follow-up interviews

713
00:25:51,799 --> 00:25:58,279
and we see five surface five themes

714
00:25:54,360 --> 00:26:01,279
surfacing one is that um uh AI cre

715
00:25:58,279 --> 00:26:02,600
creates visibility we can um find those

716
00:26:01,279 --> 00:26:05,240
needles in the hay stack that we

717
00:26:02,600 --> 00:26:07,799
couldn't find before because with AI we

718
00:26:05,240 --> 00:26:09,919
know that the the this the AI can find

719
00:26:07,799 --> 00:26:12,840
the anomalies that maybe we didn't know

720
00:26:09,919 --> 00:26:14,799
to look for we know that AI we found

721
00:26:12,840 --> 00:26:17,840
that AI can increase efficiency it can

722
00:26:14,799 --> 00:26:20,240
reduce the toll of repetitive tasks

723
00:26:17,840 --> 00:26:22,080
through automation uh not replacing

724
00:26:20,240 --> 00:26:24,120
people but U making people more

725
00:26:22,080 --> 00:26:27,880
efficient making our cyber activities

726
00:26:24,120 --> 00:26:29,520
more efficient it can um quantify things

727
00:26:27,880 --> 00:26:32,640
that we couldn't quantify before this is

728
00:26:29,520 --> 00:26:34,919
similar to visibility um but by using AI

729
00:26:32,640 --> 00:26:36,760
tools we can start to build metrics that

730
00:26:34,919 --> 00:26:39,399
we we couldn't have used before because

731
00:26:36,760 --> 00:26:43,520
we have insight into behaviors that we

732
00:26:39,399 --> 00:26:45,240
didn't have um and it can um scale it

733
00:26:43,520 --> 00:26:47,240
can take and and scale actually also

734
00:26:45,240 --> 00:26:49,000
works with personalization one of the

735
00:26:47,240 --> 00:26:51,840
the most interesting themes to me was

736
00:26:49,000 --> 00:26:55,840
this idea of personalization we can use

737
00:26:51,840 --> 00:26:57,960
AI to personalize our messages to our uh

738
00:26:55,840 --> 00:27:00,679
employees uh in a way that they will

739
00:26:57,960 --> 00:27:03,080
most most likely understand and and use

740
00:27:00,679 --> 00:27:05,559
for example um if I'm a person who's

741
00:27:03,080 --> 00:27:08,960
more into videos and I need some

742
00:27:05,559 --> 00:27:11,720
behavior modification the AI could offer

743
00:27:08,960 --> 00:27:14,720
me a lesson in a video format that it

744
00:27:11,720 --> 00:27:17,320
might offer Kathleen in a reading format

745
00:27:14,720 --> 00:27:20,399
or somebody else in a conversational

746
00:27:17,320 --> 00:27:22,840
format or a Class A Course format it can

747
00:27:20,399 --> 00:27:24,080
personalize the messages that go to the

748
00:27:22,840 --> 00:27:26,279
employees that would change their

749
00:27:24,080 --> 00:27:28,760
behaviors so these are five different

750
00:27:26,279 --> 00:27:31,760
ways we're seeing AI being used used in

751
00:27:28,760 --> 00:27:34,600
organizations to modify our cyber

752
00:27:31,760 --> 00:27:36,760
security values attitudes and beliefs

753
00:27:34,600 --> 00:27:39,279
and drive different

754
00:27:36,760 --> 00:27:41,159
behaviors this is a white paper if

755
00:27:39,279 --> 00:27:43,320
you're interested in a copy of it send

756
00:27:41,159 --> 00:27:45,360
me an email remind me that you heard it

757
00:27:43,320 --> 00:27:46,640
here I'm doing several talks this month

758
00:27:45,360 --> 00:27:48,720
so just remind me where you heard it and

759
00:27:46,640 --> 00:27:50,840
I'll send you the right

760
00:27:48,720 --> 00:27:53,279
paper okay and let me quickly tell you

761
00:27:50,840 --> 00:27:55,679
about this last project it's about

762
00:27:53,279 --> 00:27:58,399
preparing for cyber crisis

763
00:27:55,679 --> 00:28:00,159
Communications um this project we

764
00:27:58,399 --> 00:28:03,840
published an article in Sloan management

765
00:28:00,159 --> 00:28:05,880
review earlier this fall on Cyber crisis

766
00:28:03,840 --> 00:28:08,120
communication most of you have business

767
00:28:05,880 --> 00:28:10,399
continuity plans you have crisis

768
00:28:08,120 --> 00:28:11,840
communication plans but what we learned

769
00:28:10,399 --> 00:28:14,559
through our research is those aren't

770
00:28:11,840 --> 00:28:17,320
adequate for a cyber incident for

771
00:28:14,559 --> 00:28:19,320
example one company we talked to they

772
00:28:17,320 --> 00:28:20,919
did have a business continuity plan they

773
00:28:19,320 --> 00:28:22,360
had a cyber incident that locked up

774
00:28:20,919 --> 00:28:23,559
their computers where do you think the

775
00:28:22,360 --> 00:28:24,960
Cyber where do you think the business

776
00:28:23,559 --> 00:28:27,600
continuity plan

777
00:28:24,960 --> 00:28:29,799
was was on the computer they didn't have

778
00:28:27,600 --> 00:28:32,279
access to it they had one it was great

779
00:28:29,799 --> 00:28:34,000
it was perfect but it didn't take into

780
00:28:32,279 --> 00:28:35,559
account what might happen in a cyber

781
00:28:34,000 --> 00:28:38,840
crisis and so they didn't have their

782
00:28:35,559 --> 00:28:40,679
continuity plans available and so a few

783
00:28:38,840 --> 00:28:42,480
years ago we talked about this and we

784
00:28:40,679 --> 00:28:44,120
came up with this the the we didn't come

785
00:28:42,480 --> 00:28:45,840
up with the concept but we realized that

786
00:28:44,120 --> 00:28:48,600
people need to practice you need

787
00:28:45,840 --> 00:28:51,080
tabletop exercises that put you through

788
00:28:48,600 --> 00:28:53,559
cyber um incidences so that you can

789
00:28:51,080 --> 00:28:55,320
start to make decisions ahead of time

790
00:28:53,559 --> 00:28:57,039
and then if and when God forbid you

791
00:28:55,320 --> 00:28:59,279
actually have a cyber crisis you've

792
00:28:57,039 --> 00:29:00,600
already built those muscles to respond

793
00:28:59,279 --> 00:29:02,240
you're never going to see exactly what

794
00:29:00,600 --> 00:29:04,600
you practice it's just like you never do

795
00:29:02,240 --> 00:29:06,559
the exact um uh engineering problem that

796
00:29:04,600 --> 00:29:08,000
you did in your homework but you have

797
00:29:06,559 --> 00:29:10,519
the muscles you have the knowledge

798
00:29:08,000 --> 00:29:12,640
you've built the basis the foundation so

799
00:29:10,519 --> 00:29:15,240
that if and when you have a cyber crisis

800
00:29:12,640 --> 00:29:17,159
you're able to respond quickly well the

801
00:29:15,240 --> 00:29:19,880
same thing happens with Communications

802
00:29:17,159 --> 00:29:22,080
turns out that with your Communications

803
00:29:19,880 --> 00:29:24,200
plan is probably not adequate for a

804
00:29:22,080 --> 00:29:26,000
cyber crisis because of some unique

805
00:29:24,200 --> 00:29:28,399
characteristics of a cyber crisis that

806
00:29:26,000 --> 00:29:31,320
would be different than say a flood or a

807
00:29:28,399 --> 00:29:34,159
tornado or uh uh some other type of

808
00:29:31,320 --> 00:29:37,159
business outage that that you might

809
00:29:34,159 --> 00:29:39,120
experience Communications in uh cyber

810
00:29:37,159 --> 00:29:41,240
security are a little bit unique because

811
00:29:39,120 --> 00:29:43,760
of these four areas first there's a time

812
00:29:41,240 --> 00:29:47,279
crunch um when you have a cyber breach

813
00:29:43,760 --> 00:29:50,320
or a cyber incident or cyber uh uh

814
00:29:47,279 --> 00:29:51,519
activity your ecosystem really wants to

815
00:29:50,320 --> 00:29:53,279
know information and they want to know

816
00:29:51,519 --> 00:29:54,720
it fast and you don't have all the

817
00:29:53,279 --> 00:29:56,120
information at the time about what

818
00:29:54,720 --> 00:29:57,600
happened you might not even have all

819
00:29:56,120 --> 00:29:59,200
that information if you had a hurricane

820
00:29:57,600 --> 00:30:01,159
I mean we get those here in Texas

821
00:29:59,200 --> 00:30:02,799
particularly Houston but everybody's

822
00:30:01,159 --> 00:30:04,240
having a hurricane and so it it when the

823
00:30:02,799 --> 00:30:05,840
hurricane hits so there's a little bit

824
00:30:04,240 --> 00:30:07,840
more understanding of what's going on

825
00:30:05,840 --> 00:30:09,880
but in a cyber crisis it's not

826
00:30:07,840 --> 00:30:11,440
necessarily the case you don't have

827
00:30:09,880 --> 00:30:13,080
concrete information about what's

828
00:30:11,440 --> 00:30:14,720
happening you just know your systems are

829
00:30:13,080 --> 00:30:16,320
down you may know that there's malware

830
00:30:14,720 --> 00:30:18,720
in your system you may not know how far

831
00:30:16,320 --> 00:30:20,399
it's penetrated your systems but you're

832
00:30:18,720 --> 00:30:22,519
getting an influx of stakeholder

833
00:30:20,399 --> 00:30:24,279
inquiries you might even have the Press

834
00:30:22,519 --> 00:30:25,799
depending on who you are you might have

835
00:30:24,279 --> 00:30:27,600
the press in your face trying to get

836
00:30:25,799 --> 00:30:30,159
answers and what you say at the very

837
00:30:27,600 --> 00:30:32,399
beginning can create huge problems later

838
00:30:30,159 --> 00:30:33,840
on you might say well we had a cyber

839
00:30:32,399 --> 00:30:35,320
incident and we're looking into it and

840
00:30:33,840 --> 00:30:36,880
the word incident might be something

841
00:30:35,320 --> 00:30:39,279
that your lawyers come back and say oh

842
00:30:36,880 --> 00:30:41,159
no you know no no no don't call it an

843
00:30:39,279 --> 00:30:43,200
incident once you call it an incident

844
00:30:41,159 --> 00:30:45,600
that sets up all sorts of dominoes and

845
00:30:43,200 --> 00:30:47,600
we don't want those dominoes in effect

846
00:30:45,600 --> 00:30:49,840
so you might say well we're looking into

847
00:30:47,600 --> 00:30:51,120
what happened well now your stakeholders

848
00:30:49,840 --> 00:30:52,799
aren't very happy because you haven't

849
00:30:51,120 --> 00:30:55,159
given them enough information so you can

850
00:30:52,799 --> 00:30:57,120
begin to see that the words you use are

851
00:30:55,159 --> 00:31:00,679
really important and it's not the same

852
00:30:57,120 --> 00:31:02,720
as a general business um crisis and the

853
00:31:00,679 --> 00:31:04,080
stress levels are really high even if

854
00:31:02,720 --> 00:31:05,440
you're not the Cyber person in your

855
00:31:04,080 --> 00:31:07,399
organization if you're a marketing

856
00:31:05,440 --> 00:31:09,240
person you want to make sure that your

857
00:31:07,399 --> 00:31:10,960
customers are happy and that they know

858
00:31:09,240 --> 00:31:12,000
what's that that you're on top of it

859
00:31:10,960 --> 00:31:15,000
that you're helping you want don't want

860
00:31:12,000 --> 00:31:17,000
to erode trust um you might want to uh

861
00:31:15,000 --> 00:31:19,080
think about the words you use so that

862
00:31:17,000 --> 00:31:21,000
you're not setting up future problems

863
00:31:19,080 --> 00:31:23,399
future litigation we've seen several

864
00:31:21,000 --> 00:31:26,200
companies where the initial response

865
00:31:23,399 --> 00:31:28,480
wasn't exactly accurate the it the the

866
00:31:26,200 --> 00:31:29,840
event was muddled through but the fact

867
00:31:28,480 --> 00:31:32,639
that they use the wrong words at the

868
00:31:29,840 --> 00:31:34,480
beginning set up secondary and tertiary

869
00:31:32,639 --> 00:31:37,080
problems later down they their

870
00:31:34,480 --> 00:31:38,279
stakeholder lawsuits that came up that

871
00:31:37,080 --> 00:31:40,360
really shouldn't have ever come up

872
00:31:38,279 --> 00:31:43,440
because of words that were used in the

873
00:31:40,360 --> 00:31:47,760
the very beginning so um we we w we

874
00:31:43,440 --> 00:31:50,880
talked about uh six common impulses that

875
00:31:47,760 --> 00:31:52,679
are wrong terminology being one of them

876
00:31:50,880 --> 00:31:54,919
avoid getting ahead of the facts saying

877
00:31:52,679 --> 00:31:56,399
that you your your team is on top of it

878
00:31:54,919 --> 00:31:58,360
we've already solved the problem when

879
00:31:56,399 --> 00:32:00,240
you haven't solved the problem

880
00:31:58,360 --> 00:32:01,919
equipping your front lines for Success

881
00:32:00,240 --> 00:32:03,720
giving them the terms the words they can

882
00:32:01,919 --> 00:32:06,000
use letting them know what they need to

883
00:32:03,720 --> 00:32:08,080
say in a cyber crisis so that they

884
00:32:06,000 --> 00:32:11,039
aren't setting you up for failure in the

885
00:32:08,080 --> 00:32:13,039
secondary or the third wave of the event

886
00:32:11,039 --> 00:32:15,200
um staying appraised of what your media

887
00:32:13,039 --> 00:32:17,039
narrative is if you have multiple people

888
00:32:15,200 --> 00:32:19,039
in your organization speaking to the

889
00:32:17,039 --> 00:32:21,240
press or possibly speaking to the press

890
00:32:19,039 --> 00:32:23,080
or even on social media or even talking

891
00:32:21,240 --> 00:32:25,399
to friends who are not going to say

892
00:32:23,080 --> 00:32:27,360
anything but maybe do you want to make

893
00:32:25,399 --> 00:32:29,919
sure the narrative is consistent

894
00:32:27,360 --> 00:32:32,159
conveying dedication to cyber security

895
00:32:29,919 --> 00:32:34,159
um and and assuring your stakeholders

896
00:32:32,159 --> 00:32:36,559
that um what what you're doing is

897
00:32:34,159 --> 00:32:39,000
appropriate but not over committing to

898
00:32:36,559 --> 00:32:40,600
things and staying cautious of your tone

899
00:32:39,000 --> 00:32:42,320
you want to keep it serious but at the

900
00:32:40,600 --> 00:32:44,639
same time um you don't want to keep it

901
00:32:42,320 --> 00:32:47,360
so serious that you worry your customer

902
00:32:44,639 --> 00:32:49,440
base or your other stakeholders so

903
00:32:47,360 --> 00:32:51,559
consistency of message and applying it

904
00:32:49,440 --> 00:32:53,399
to different audiences is key my partner

905
00:32:51,559 --> 00:32:55,320
in this was obviously a Communications

906
00:32:53,399 --> 00:32:57,639
person that knows a lot more about the

907
00:32:55,320 --> 00:32:59,440
communication strategies than I but the

908
00:32:57,639 --> 00:33:01,760
IDE idea of really thinking through the

909
00:32:59,440 --> 00:33:03,360
the appropriate angle of the message to

910
00:33:01,760 --> 00:33:06,720
each of your stakeholders is really

911
00:33:03,360 --> 00:33:08,639
critical here and in this project um we

912
00:33:06,720 --> 00:33:11,960
talked about building a Communications

913
00:33:08,639 --> 00:33:13,840
Playbook so that you have a plan for

914
00:33:11,960 --> 00:33:16,399
cyber crisis communication and then

915
00:33:13,840 --> 00:33:18,919
testing it with a maybe tabletop

916
00:33:16,399 --> 00:33:20,600
exercise on a cyber crisis because what

917
00:33:18,919 --> 00:33:22,159
we've learned is cyber crisis as I

918
00:33:20,600 --> 00:33:24,120
mentioned earlier are different than

919
00:33:22,159 --> 00:33:26,440
regular crisis and you want to put your

920
00:33:24,120 --> 00:33:27,799
head in the game of a cyber incident so

921
00:33:26,440 --> 00:33:30,320
that you can test the different

922
00:33:27,799 --> 00:33:32,519
components of your response with a cyber

923
00:33:30,320 --> 00:33:34,760
crisis in mind and we published this in

924
00:33:32,519 --> 00:33:36,360
Sloan back in September this is also

925
00:33:34,760 --> 00:33:37,960
available on our website so if you're

926
00:33:36,360 --> 00:33:40,960
interested in this paper you can email

927
00:33:37,960 --> 00:33:43,480
me about that also okay so just to kind

928
00:33:40,960 --> 00:33:45,120
of conclude here resilience thinking is

929
00:33:43,480 --> 00:33:47,279
a little different than protection

930
00:33:45,120 --> 00:33:48,919
thinking I think I've I've I've pounded

931
00:33:47,279 --> 00:33:50,960
that into you in the last 20 minutes so

932
00:33:48,919 --> 00:33:53,120
hopefully you've seen couple of examples

933
00:33:50,960 --> 00:33:54,799
of how it's a bit different it's about

934
00:33:53,120 --> 00:33:56,760
response planning through things like

935
00:33:54,799 --> 00:33:58,519
tabletop exercises and fire drills

936
00:33:56,760 --> 00:34:01,240
putting your team together whether maybe

937
00:33:58,519 --> 00:34:03,840
your team includes external people like

938
00:34:01,240 --> 00:34:05,440
law enforcement or your customers or

939
00:34:03,840 --> 00:34:07,440
cyber experts you know if you're having

940
00:34:05,440 --> 00:34:09,240
a cyber crisis there's a good chance

941
00:34:07,440 --> 00:34:11,520
somebody else is having a cyber crisis

942
00:34:09,240 --> 00:34:13,440
and the resources you expect to be there

943
00:34:11,520 --> 00:34:15,359
for you might not be there for you they

944
00:34:13,440 --> 00:34:17,040
might be helping another customer at the

945
00:34:15,359 --> 00:34:18,919
same time so you want to check you want

946
00:34:17,040 --> 00:34:21,560
to do your tabletop exercises with your

947
00:34:18,919 --> 00:34:23,320
whole ecosystem that you use cyber

948
00:34:21,560 --> 00:34:25,240
critical Communications planning is

949
00:34:23,320 --> 00:34:26,560
different than other business recovery

950
00:34:25,240 --> 00:34:28,399
plans you want to make sure that they're

951
00:34:26,560 --> 00:34:29,839
not just on your computer that they're

952
00:34:28,399 --> 00:34:32,639
accessible should your computers be

953
00:34:29,839 --> 00:34:34,480
locked up and other other messages you

954
00:34:32,639 --> 00:34:35,800
want a design for cyber security you

955
00:34:34,480 --> 00:34:38,320
want to make sure your products your

956
00:34:35,800 --> 00:34:40,520
services are secure should there be an

957
00:34:38,320 --> 00:34:42,520
incident you know we talk about

958
00:34:40,520 --> 00:34:44,440
technology fault tolerance in our

959
00:34:42,520 --> 00:34:46,599
technology and we build our technology

960
00:34:44,440 --> 00:34:48,720
systems so that if one component goes

961
00:34:46,599 --> 00:34:50,359
down the whole system doesn't go down we

962
00:34:48,720 --> 00:34:52,879
need to use that thinking for our

963
00:34:50,359 --> 00:34:55,440
organizations our processes need to be

964
00:34:52,879 --> 00:34:57,359
resilient our organization structures

965
00:34:55,440 --> 00:34:59,560
need to be resilient how do we think

966
00:34:57,359 --> 00:35:01,240
about those how do we design for

967
00:34:59,560 --> 00:35:03,400
security not just in our products and

968
00:35:01,240 --> 00:35:05,680
our services but in the way we deliver

969
00:35:03,400 --> 00:35:09,160
those products and services to um our

970
00:35:05,680 --> 00:35:11,480
customers and our and our um uh and our

971
00:35:09,160 --> 00:35:12,760
uh ecosystem and then finally and this

972
00:35:11,480 --> 00:35:15,480
is another area that I've written

973
00:35:12,760 --> 00:35:18,400
extensively about is about board and sea

974
00:35:15,480 --> 00:35:20,920
level reporting um the biggest risk we

975
00:35:18,400 --> 00:35:22,400
report the wrong things to our board I'm

976
00:35:20,920 --> 00:35:23,760
on a board I'm on two boards I'm looking

977
00:35:22,400 --> 00:35:26,440
for my third board if somebody's looking

978
00:35:23,760 --> 00:35:29,000
for a board member um the we report the

979
00:35:26,440 --> 00:35:31,200
wrong things we report at least uh some

980
00:35:29,000 --> 00:35:32,839
boards that we studied they looked at

981
00:35:31,200 --> 00:35:34,119
the the the dashboard the board gets

982
00:35:32,839 --> 00:35:35,720
tells them how many people failed the

983
00:35:34,119 --> 00:35:37,160
fishing exercise and how much better

984
00:35:35,720 --> 00:35:38,800
we're going to do tells them what

985
00:35:37,160 --> 00:35:41,079
investment we've made in cyber security

986
00:35:38,800 --> 00:35:44,599
and how we compare to our colleagues our

987
00:35:41,079 --> 00:35:47,040
our compet our um similar companies our

988
00:35:44,599 --> 00:35:49,640
our competitors um it tells might tell

989
00:35:47,040 --> 00:35:51,319
us what technologies we've invested in

990
00:35:49,640 --> 00:35:52,680
which frankly as a board member if I

991
00:35:51,319 --> 00:35:54,119
didn't trust that you were making the

992
00:35:52,680 --> 00:35:56,319
right technology decisions you wouldn't

993
00:35:54,119 --> 00:35:58,880
be in that job anyway what I want to

994
00:35:56,319 --> 00:36:00,640
know as a board member and what most sea

995
00:35:58,880 --> 00:36:02,359
level Executives that aren't in cyber

996
00:36:00,640 --> 00:36:04,400
maybe some of you that aren't currently

997
00:36:02,359 --> 00:36:06,839
in cyber want to know is what's the

998
00:36:04,400 --> 00:36:08,720
biggest risk and what are we doing about

999
00:36:06,839 --> 00:36:10,880
it you know what is the biggest risk to

1000
00:36:08,720 --> 00:36:12,400
our supply chain from cyber security and

1001
00:36:10,880 --> 00:36:14,680
what are we doing about it how are we

1002
00:36:12,400 --> 00:36:17,440
managing that risk what is the biggest

1003
00:36:14,680 --> 00:36:19,359
risk to our financial cash flow and what

1004
00:36:17,440 --> 00:36:21,160
are we doing about it what is the

1005
00:36:19,359 --> 00:36:23,400
biggest risk to our organization our

1006
00:36:21,160 --> 00:36:25,040
people or from our people and what are

1007
00:36:23,400 --> 00:36:26,680
we doing about it so it's the biggest

1008
00:36:25,040 --> 00:36:28,680
risk it's a risk discussion it's a

1009
00:36:26,680 --> 00:36:31,319
business level discussion question and

1010
00:36:28,680 --> 00:36:33,359
what are we doing about it so the way we

1011
00:36:31,319 --> 00:36:34,880
report cyber security is about

1012
00:36:33,359 --> 00:36:36,720
protection and what we really want to

1013
00:36:34,880 --> 00:36:38,640
think about is resilience what's the

1014
00:36:36,720 --> 00:36:41,040
biggest risk where are we where are we

1015
00:36:38,640 --> 00:36:43,359
most um vulnerable and what are we doing

1016
00:36:41,040 --> 00:36:45,240
about it so I hope I'm I'm giving you a

1017
00:36:43,359 --> 00:36:47,720
sense of what resilience thinking is all

1018
00:36:45,240 --> 00:36:49,520
about here so here's my call to action

1019
00:36:47,720 --> 00:36:52,480
for you guys here's four things you can

1020
00:36:49,520 --> 00:36:54,520
do tomorrow one you can start to measure

1021
00:36:52,480 --> 00:36:56,400
your cyber security U maturity your

1022
00:36:54,520 --> 00:36:58,040
culture maturity different parts of your

1023
00:36:56,400 --> 00:36:59,800
organization may have

1024
00:36:58,040 --> 00:37:02,000
maturity you can start to take a look

1025
00:36:59,800 --> 00:37:03,960
and see how how do your employees think

1026
00:37:02,000 --> 00:37:05,720
about cyber security and is it what you

1027
00:37:03,960 --> 00:37:07,119
want them to be thinking about and maybe

1028
00:37:05,720 --> 00:37:08,240
change the way that their values

1029
00:37:07,119 --> 00:37:11,200
attitudes and

1030
00:37:08,240 --> 00:37:13,760
beliefs uh uh uh cover cyber

1031
00:37:11,200 --> 00:37:15,400
security make Heroes out of the be he

1032
00:37:13,760 --> 00:37:17,920
people doing the behaviors that you want

1033
00:37:15,400 --> 00:37:20,240
to see as a leader if you make somebody

1034
00:37:17,920 --> 00:37:21,359
a hero if you give them recognition

1035
00:37:20,240 --> 00:37:23,400
maybe you want to give them a chocolate

1036
00:37:21,359 --> 00:37:24,880
chip cookie like this one company did

1037
00:37:23,400 --> 00:37:26,359
maybe you want to give them a badge that

1038
00:37:24,880 --> 00:37:28,280
puts goes on their email that says

1039
00:37:26,359 --> 00:37:30,319
they're a cyber hero maybe you just want

1040
00:37:28,280 --> 00:37:31,880
to call them out in a meeting but if you

1041
00:37:30,319 --> 00:37:33,400
make Heroes out of people that are doing

1042
00:37:31,880 --> 00:37:35,119
the right stuff that's another way you

1043
00:37:33,400 --> 00:37:38,040
can propagate the values attitudes and

1044
00:37:35,119 --> 00:37:40,040
beliefs about cyber security look at

1045
00:37:38,040 --> 00:37:41,880
your Communications your cyber your

1046
00:37:40,040 --> 00:37:43,880
crisis communication plans what do you

1047
00:37:41,880 --> 00:37:46,160
do do you know what what you're your job

1048
00:37:43,880 --> 00:37:48,319
would be if your company experienced a

1049
00:37:46,160 --> 00:37:49,920
cyber breach and you were shut down what

1050
00:37:48,319 --> 00:37:51,920
is your specific rule what do you do

1051
00:37:49,920 --> 00:37:53,599
first who do you call what if you can't

1052
00:37:51,920 --> 00:37:55,200
use your phones do you email them what

1053
00:37:53,599 --> 00:37:56,640
if you can't use your email what are you

1054
00:37:55,200 --> 00:37:58,200
supposed to do and if you don't know

1055
00:37:56,640 --> 00:37:59,359
what you're supposed to do most people

1056
00:37:58,200 --> 00:38:01,319
in your company probably don't know what

1057
00:37:59,359 --> 00:38:03,040
they're supposed to do so think about

1058
00:38:01,319 --> 00:38:04,839
what your communication plan is

1059
00:38:03,040 --> 00:38:08,240
internally externally make sure that

1060
00:38:04,839 --> 00:38:10,200
it's cyber uh ready and then finally

1061
00:38:08,240 --> 00:38:12,079
create a cyber resilience mindset think

1062
00:38:10,200 --> 00:38:14,160
about this from a how do we make sure

1063
00:38:12,079 --> 00:38:16,079
that we can respond and recover in

1064
00:38:14,160 --> 00:38:19,450
addition to making sure that we're

1065
00:38:16,079 --> 00:38:23,500
protected that's it happy to answer any

1066
00:38:19,450 --> 00:38:23,500
[Applause]

1067
00:38:23,839 --> 00:38:31,720
questions yes sir

1068
00:38:27,839 --> 00:38:33,440
stand like N and cobat is there some

1069
00:38:31,720 --> 00:38:35,280
interplay is there some interplay

1070
00:38:33,440 --> 00:38:37,520
between n and cobat and your work yeah

1071
00:38:35,280 --> 00:38:39,240
so we uh use the N framework all the

1072
00:38:37,520 --> 00:38:42,040
time in our talk and what we talk about

1073
00:38:39,240 --> 00:38:44,280
and what we do um we're not we're kind

1074
00:38:42,040 --> 00:38:48,079
of orthagonal in the sense that we're

1075
00:38:44,280 --> 00:38:49,480
not using those models as it management

1076
00:38:48,079 --> 00:38:52,160
models we're looking more at the

1077
00:38:49,480 --> 00:38:53,520
managerial side not the control side the

1078
00:38:52,160 --> 00:38:56,480
controls are really important that's

1079
00:38:53,520 --> 00:38:58,400
where Coit comes in um at the NY mile is

1080
00:38:56,480 --> 00:39:00,560
definitely the n model is all about

1081
00:38:58,400 --> 00:39:02,599
resilience the this model is overlap in

1082
00:39:00,560 --> 00:39:05,000
terms of tabletop exercises and maybe

1083
00:39:02,599 --> 00:39:06,480
red blue some overlap but most of the

1084
00:39:05,000 --> 00:39:09,119
Coit ones I've seen are more like fire

1085
00:39:06,480 --> 00:39:11,720
drills for technology not managerial and

1086
00:39:09,119 --> 00:39:13,280
board level tabletop exercises okay so

1087
00:39:11,720 --> 00:39:15,200
but if you think about the nist model

1088
00:39:13,280 --> 00:39:17,359
the N cyber security framework model has

1089
00:39:15,200 --> 00:39:20,599
six components

1090
00:39:17,359 --> 00:39:22,880
identify protect detect respond recover

1091
00:39:20,599 --> 00:39:24,920
and govern protect and detect is the

1092
00:39:22,880 --> 00:39:26,839
protection mindset respond and recover

1093
00:39:24,920 --> 00:39:28,400
is a resiliency mindset it's exactly the

1094
00:39:26,839 --> 00:39:31,200
same thing Le when I go to conferences

1095
00:39:28,400 --> 00:39:33,319
they talk about the tabletop as yes a

1096
00:39:31,200 --> 00:39:35,800
part of yeah and and people use the term

1097
00:39:33,319 --> 00:39:38,319
tabletop I do too Loosely it's really

1098
00:39:35,800 --> 00:39:39,760
about practice so um it's what are you

1099
00:39:38,319 --> 00:39:41,560
practicing obviously could practice

1100
00:39:39,760 --> 00:39:43,560
there's a whole Continuum of what you

1101
00:39:41,560 --> 00:39:45,960
could practice what I'm suggesting you

1102
00:39:43,560 --> 00:39:49,319
practice is the organizational response

1103
00:39:45,960 --> 00:39:52,079
okay I see yes yeah other questions yes

1104
00:39:49,319 --> 00:39:54,079
sir so from your like you know survey

1105
00:39:52,079 --> 00:39:55,960
and experience like where is the biggest

1106
00:39:54,079 --> 00:39:57,960
like you know Pitfall and like you know

1107
00:39:55,960 --> 00:39:59,920
following the cyber security practices

1108
00:39:57,960 --> 00:40:01,400
because I see a lot of people try to

1109
00:39:59,920 --> 00:40:03,119
follow the N framework and stuff

1110
00:40:01,400 --> 00:40:05,520
somewhere like know they take like

1111
00:40:03,119 --> 00:40:07,079
compromise some of them but is there

1112
00:40:05,520 --> 00:40:08,680
anything that like you see that like

1113
00:40:07,079 --> 00:40:11,880
know where typically like know they fail

1114
00:40:08,680 --> 00:40:13,480
to recognize versus like you know hey uh

1115
00:40:11,880 --> 00:40:15,720
the management doesn't actually like you

1116
00:40:13,480 --> 00:40:18,760
know give enough like you know funding

1117
00:40:15,720 --> 00:40:20,560
to do certain things so I I think the

1118
00:40:18,760 --> 00:40:23,000
question is where do I see the biggest

1119
00:40:20,560 --> 00:40:25,359
need the biggest hole and I think the

1120
00:40:23,000 --> 00:40:28,880
biggest hole is to have non-cyber people

1121
00:40:25,359 --> 00:40:31,160
Embrace their um capability to impact

1122
00:40:28,880 --> 00:40:33,160
the Cyber in a company I think most

1123
00:40:31,160 --> 00:40:34,920
people think that cyber is not their job

1124
00:40:33,160 --> 00:40:36,640
they do everything else they do whatever

1125
00:40:34,920 --> 00:40:38,599
their job is finance marketing

1126
00:40:36,640 --> 00:40:40,880
operations and somebody else is worrying

1127
00:40:38,599 --> 00:40:42,680
about cyber and I think that um the

1128
00:40:40,880 --> 00:40:44,800
biggest hole is people feeling that

1129
00:40:42,680 --> 00:40:46,760
cyber is a technical question and that

1130
00:40:44,800 --> 00:40:47,960
belongs with the it or the Cyber people

1131
00:40:46,760 --> 00:40:50,359
and it really isn't it's an

1132
00:40:47,960 --> 00:40:51,920
organizational issue and once we can see

1133
00:40:50,359 --> 00:40:53,440
that cyber is an organizational isue we

1134
00:40:51,920 --> 00:40:55,760
can start to close the gap because we

1135
00:40:53,440 --> 00:40:58,000
really need everybody on board it's like

1136
00:40:55,760 --> 00:40:59,839
safety it's like safety really finally

1137
00:40:58,000 --> 00:41:01,200
after what 30 years permeated all our

1138
00:40:59,839 --> 00:41:03,839
companies and everybody's thinking

1139
00:41:01,200 --> 00:41:06,200
safety but cyber isn't quite there yet

1140
00:41:03,839 --> 00:41:08,920
and I would like to see cyber permeated

1141
00:41:06,200 --> 00:41:10,319
just like we see safety permeated last

1142
00:41:08,920 --> 00:41:11,640
question yes sir yeah I was just

1143
00:41:10,319 --> 00:41:14,880
wondering what are your thoughts as far

1144
00:41:11,640 --> 00:41:17,400
as uh fishing attacks on cell phones I

1145
00:41:14,880 --> 00:41:19,359
have I've seen zero effort whatsoever on

1146
00:41:17,400 --> 00:41:20,880
that either when I have a company cell

1147
00:41:19,359 --> 00:41:23,160
phone and I get those fishing there's

1148
00:41:20,880 --> 00:41:24,800
nothing from IT department there's no

1149
00:41:23,160 --> 00:41:26,160
nothing governing that it's just me

1150
00:41:24,800 --> 00:41:28,359
reporting the junk and that's the end of

1151
00:41:26,160 --> 00:41:29,560
it but also on my personal cell phone

1152
00:41:28,359 --> 00:41:31,000
same thing like every day even my

1153
00:41:29,560 --> 00:41:33,119
daughter is 16 she's getting those

1154
00:41:31,000 --> 00:41:36,520
things I'm getting them zero effort from

1155
00:41:33,119 --> 00:41:38,440
the carriers to even attempt to actually

1156
00:41:36,520 --> 00:41:40,560
uh you know combat all those messages

1157
00:41:38,440 --> 00:41:44,560
we're all getting on our cell phones

1158
00:41:40,560 --> 00:41:46,359
cell phones um both text messages and um

1159
00:41:44,560 --> 00:41:47,760
emails everything else on cell phones

1160
00:41:46,359 --> 00:41:50,079
yep I'm seeing I get them all the time

1161
00:41:47,760 --> 00:41:51,280
too um okay so I'm going to say

1162
00:41:50,079 --> 00:41:52,960
something that's probably not very

1163
00:41:51,280 --> 00:41:54,800
popular I think it's our responsibility

1164
00:41:52,960 --> 00:41:57,280
to train ourselves to respond to those

1165
00:41:54,800 --> 00:41:58,880
appropriately I.E delete them and I

1166
00:41:57,280 --> 00:42:00,680
talked at the very beginning sometimes I

1167
00:41:58,880 --> 00:42:02,720
give this talk to organization people

1168
00:42:00,680 --> 00:42:04,480
that aren't all business people and I

1169
00:42:02,720 --> 00:42:06,440
say cyber isn't just a business problem

1170
00:42:04,480 --> 00:42:08,319
it's a family problem you know we got to

1171
00:42:06,440 --> 00:42:09,640
keep our kids secure we got to keep our

1172
00:42:08,319 --> 00:42:11,000
spouses secure we got to keep our

1173
00:42:09,640 --> 00:42:13,839
parents secure I can't tell you the

1174
00:42:11,000 --> 00:42:15,760
number of people I I often tell a story

1175
00:42:13,839 --> 00:42:17,800
I'm the only cyber girl in my Social

1176
00:42:15,760 --> 00:42:19,720
Circle my friends are lawyers and

1177
00:42:17,800 --> 00:42:21,319
doctors and dentists and nail techs and

1178
00:42:19,720 --> 00:42:22,960
real estate people and teachers I mean

1179
00:42:21,319 --> 00:42:24,720
they're they have normal jobs just like

1180
00:42:22,960 --> 00:42:26,640
the rest of us but I'm the only cyber

1181
00:42:24,720 --> 00:42:28,920
person and because I'm these are my

1182
00:42:26,640 --> 00:42:30,720
friends and I they know what I do every

1183
00:42:28,920 --> 00:42:33,520
now and then I I send them an email of

1184
00:42:30,720 --> 00:42:36,079
something a head a headline I saw or a

1185
00:42:33,520 --> 00:42:38,119
story or something just by me sending

1186
00:42:36,079 --> 00:42:39,760
that to them raises their awareness and

1187
00:42:38,119 --> 00:42:41,280
makes them a little bit more secure and

1188
00:42:39,760 --> 00:42:42,640
they're my friends they're not cyber

1189
00:42:41,280 --> 00:42:44,359
people and they're not my employees

1190
00:42:42,640 --> 00:42:46,079
they're not my teammates I'm not

1191
00:42:44,359 --> 00:42:47,520
responsible for the Cyber breach that

1192
00:42:46,079 --> 00:42:49,760
they may or may not have but I think

1193
00:42:47,520 --> 00:42:50,839
it's all of our responsibilities and I

1194
00:42:49,760 --> 00:42:53,000
think that's part of my drinking the

1195
00:42:50,839 --> 00:42:54,559
Kool-Aid too it's our responsibility to

1196
00:42:53,000 --> 00:42:56,119
help all those around us be a little

1197
00:42:54,559 --> 00:42:57,559
more secure because we know how

1198
00:42:56,119 --> 00:42:59,760
important it is we see through that

1199
00:42:57,559 --> 00:43:01,800
Looking Glass about all these these

1200
00:42:59,760 --> 00:43:03,480
vulnerabilities and once you see those

1201
00:43:01,800 --> 00:43:04,920
you can't ignore them whether it's for

1202
00:43:03,480 --> 00:43:07,319
yourself or for your daughter or for

1203
00:43:04,920 --> 00:43:09,040
your family or your friends and so I

1204
00:43:07,319 --> 00:43:10,480
think that that that's the answer I mean

1205
00:43:09,040 --> 00:43:12,440
I don't know that the carriers are doing

1206
00:43:10,480 --> 00:43:14,880
anything I I really I mean I don't see

1207
00:43:12,440 --> 00:43:17,000
it but it's not my research so I can't

1208
00:43:14,880 --> 00:43:19,400
really comment as an expert there but I

1209
00:43:17,000 --> 00:43:21,319
do think as individuals who understand

1210
00:43:19,400 --> 00:43:23,599
that the headlines aren't going away and

1211
00:43:21,319 --> 00:43:26,000
the the threat vectors aren't going away

1212
00:43:23,599 --> 00:43:27,800
we got to help all those around us also

1213
00:43:26,000 --> 00:43:29,480
so okay I'm around round I'm going to be

1214
00:43:27,800 --> 00:43:34,200
on the panel later thank you so much for

1215
00:43:29,480 --> 00:43:34,200
your time and hope you enjoyed our talk


1
00:00:06,120 --> 00:00:11,280
and now to present our keynote talk I'm

2
00:00:08,639 --> 00:00:13,719
privileged to introduce mit's Chancellor

3
00:00:11,280 --> 00:00:16,000
for academic advancement Eric Grimson

4
00:00:13,719 --> 00:00:18,980
the Bernard M Gordon professor of

5
00:00:16,000 --> 00:00:22,219
medical engineering Eric

6
00:00:18,980 --> 00:00:22,219
[Applause]

7
00:00:22,630 --> 00:00:26,630
[Music]

8
00:00:23,950 --> 00:00:31,320
[Applause]

9
00:00:26,630 --> 00:00:32,320
[Music]

10
00:00:31,320 --> 00:00:35,920
good

11
00:00:32,320 --> 00:00:39,200
morning let's try that again good

12
00:00:35,920 --> 00:00:41,239
morning nice to have you here thank you

13
00:00:39,200 --> 00:00:44,399
for joining us today for what I hope is

14
00:00:41,239 --> 00:00:47,440
an informative engaging and interesting

15
00:00:44,399 --> 00:00:50,680
conversation about Ai and its impact on

16
00:00:47,440 --> 00:00:53,440
almost every aspect of uh mit's life

17
00:00:50,680 --> 00:00:55,719
soorry not just mit's life of your life

18
00:00:53,440 --> 00:00:58,039
I'm going to start um by saying what I'd

19
00:00:55,719 --> 00:01:00,320
like to do in this talk is give you a

20
00:00:58,039 --> 00:01:02,920
little bit of the history of AI

21
00:01:00,320 --> 00:01:05,439
especially mit's role in it a little bit

22
00:01:02,920 --> 00:01:06,920
of a review of what AI systems do I know

23
00:01:05,439 --> 00:01:08,759
many of you know this well but it's

24
00:01:06,920 --> 00:01:12,159
worth reminding you of what are the

25
00:01:08,759 --> 00:01:15,439
pieces involved in it and then talk

26
00:01:12,159 --> 00:01:17,920
about what MIT is doing to embed AI

27
00:01:15,439 --> 00:01:19,960
throughout the research at The Institute

28
00:01:17,920 --> 00:01:23,200
and to push it Forward into the future

29
00:01:19,960 --> 00:01:26,159
and so that's my goal um

30
00:01:23,200 --> 00:01:28,320
so AI is

31
00:01:26,159 --> 00:01:30,360
everywhere in the United States if you

32
00:01:28,320 --> 00:01:33,119
watch television and you look at ad adds

33
00:01:30,360 --> 00:01:36,320
it looks like any company that can spell

34
00:01:33,119 --> 00:01:38,640
AI says they're doing it and most of

35
00:01:36,320 --> 00:01:41,280
them are but it doesn't matter what you

36
00:01:38,640 --> 00:01:43,240
pick whether it's Finance it's Health

37
00:01:41,280 --> 00:01:46,759
it's Transportation it's Commerce it's

38
00:01:43,240 --> 00:01:49,000
security AI is here and is having an

39
00:01:46,759 --> 00:01:51,920
impact and so it's worth reminding

40
00:01:49,000 --> 00:01:54,320
ourselves of what is an AI

41
00:01:51,920 --> 00:01:56,560
system and the standard definition from

42
00:01:54,320 --> 00:01:58,799
computer science is that it's

43
00:01:56,560 --> 00:02:00,759
intelligence exhibited by a machine so

44
00:01:58,799 --> 00:02:02,360
it's a rational AG

45
00:02:00,759 --> 00:02:06,200
that perceives this environment it

46
00:02:02,360 --> 00:02:08,759
gathers information it takes actions in

47
00:02:06,200 --> 00:02:10,879
order to try and maximize success at a

48
00:02:08,759 --> 00:02:11,879
particular goal it's the fundamental of

49
00:02:10,879 --> 00:02:15,959
what AI

50
00:02:11,879 --> 00:02:17,800
does often people will say AI is

51
00:02:15,959 --> 00:02:20,280
exhibited by a machine when it does

52
00:02:17,800 --> 00:02:22,680
something that we would associate with a

53
00:02:20,280 --> 00:02:24,440
human hopefully good things that a human

54
00:02:22,680 --> 00:02:27,080
does and not mistakes that the machine

55
00:02:24,440 --> 00:02:30,000
makes and so that involves problem

56
00:02:27,080 --> 00:02:32,560
solving which are those three steps and

57
00:02:30,000 --> 00:02:34,440
it involves machine learning and that's

58
00:02:32,560 --> 00:02:36,319
in essence the definition of AI the

59
00:02:34,440 --> 00:02:39,840
kinds of things that we want to

60
00:02:36,319 --> 00:02:43,080
do as a consequence modern AI systems

61
00:02:39,840 --> 00:02:45,560
really incorporate information from four

62
00:02:43,080 --> 00:02:48,120
different areas obviously computer

63
00:02:45,560 --> 00:02:49,840
science but also from Neuroscience what

64
00:02:48,120 --> 00:02:51,680
goes on in our brains from cognitive

65
00:02:49,840 --> 00:02:54,720
science how we think and from

66
00:02:51,680 --> 00:02:56,720
mathematics especially reasoning about

67
00:02:54,720 --> 00:03:00,519
uncertainty and that we're going to use

68
00:02:56,720 --> 00:03:03,040
to build out an AI system

69
00:03:00,519 --> 00:03:04,760
a little bit of History one can debate

70
00:03:03,040 --> 00:03:06,760
how far back you want to go but most

71
00:03:04,760 --> 00:03:08,480
people would point to the Dartmouth

72
00:03:06,760 --> 00:03:11,360
Workshop

73
00:03:08,480 --> 00:03:14,400
1956 as the founding of modern

74
00:03:11,360 --> 00:03:16,840
AI I was 3 years old at the time so I'm

75
00:03:14,400 --> 00:03:17,720
as old as AI or little little younger

76
00:03:16,840 --> 00:03:20,159
than

77
00:03:17,720 --> 00:03:22,040
AI three of the four Founders or

78
00:03:20,159 --> 00:03:24,040
organizers of that Workshop were MIT

79
00:03:22,040 --> 00:03:27,360
faculty members John McCarthy Marvin

80
00:03:24,040 --> 00:03:29,959
Minsky and Claude Shannon um Rochester

81
00:03:27,360 --> 00:03:31,959
was from IBM McCarthy eventually left to

82
00:03:29,959 --> 00:03:34,159
go found AI at Stanford but we had an

83
00:03:31,959 --> 00:03:36,040
early role in it and you can see the

84
00:03:34,159 --> 00:03:38,560
definition that they gave they said

85
00:03:36,040 --> 00:03:40,920
every aspect of learning or any other

86
00:03:38,560 --> 00:03:43,519
feature of intelligence in their view

87
00:03:40,920 --> 00:03:45,599
can be so precisely described that you

88
00:03:43,519 --> 00:03:48,680
can get a machine to do it that was the

89
00:03:45,599 --> 00:03:53,840
motivation behind the founding of

90
00:03:48,680 --> 00:03:56,640
AI for 20 years early AI was basically

91
00:03:53,840 --> 00:03:58,560
search if you wanted to prove a theem if

92
00:03:56,640 --> 00:04:02,239
you wanted to win a game you started at

93
00:03:58,560 --> 00:04:03,879
some initial position and you executed a

94
00:04:02,239 --> 00:04:06,519
series of steps trying to get to the

95
00:04:03,879 --> 00:04:08,079
goal and if you got to the goal great if

96
00:04:06,519 --> 00:04:09,840
you didn't and you hit a dead end you

97
00:04:08,079 --> 00:04:11,720
backtracked and tried the next thing and

98
00:04:09,840 --> 00:04:14,079
you did that until you explored all the

99
00:04:11,720 --> 00:04:16,280
space or you found a

100
00:04:14,079 --> 00:04:19,280
solution I'm sure you can quickly figure

101
00:04:16,280 --> 00:04:21,120
out this does not scale well it runs

102
00:04:19,280 --> 00:04:22,680
into a combinatorial explosion the

103
00:04:21,120 --> 00:04:27,199
number of things you have to explore

104
00:04:22,680 --> 00:04:30,360
becomes huge and as a consequence for

105
00:04:27,199 --> 00:04:33,639
that first period people looked at very

106
00:04:30,360 --> 00:04:35,600
small examples and they made a lot of ad

107
00:04:33,639 --> 00:04:36,919
hoc assumptions in order to remove

108
00:04:35,600 --> 00:04:38,680
things they didn't want to think about

109
00:04:36,919 --> 00:04:41,639
without any real basis on how well it

110
00:04:38,680 --> 00:04:43,320
was going to work and as a consequence

111
00:04:41,639 --> 00:04:46,479
after about 20 years of funding in the

112
00:04:43,320 --> 00:04:50,280
US and elsewhere we hit the first AI

113
00:04:46,479 --> 00:04:52,400
winter that is funding dried up because

114
00:04:50,280 --> 00:04:54,080
these seen these things were seen as

115
00:04:52,400 --> 00:04:56,520
just not

116
00:04:54,080 --> 00:04:58,639
usable I will point out to you I started

117
00:04:56,520 --> 00:05:01,080
my own work in AI in

118
00:04:58,639 --> 00:05:03,320
1975 in those days it was something you

119
00:05:01,080 --> 00:05:06,240
scraped off the bottom of your shoe it

120
00:05:03,320 --> 00:05:09,400
was not highly respected because it had

121
00:05:06,240 --> 00:05:13,039
these problems it didn't handle problems

122
00:05:09,400 --> 00:05:14,800
well second wave of AI rise of expert

123
00:05:13,039 --> 00:05:18,120
systems in the

124
00:05:14,800 --> 00:05:21,039
1980s this was a focus on a particular

125
00:05:18,120 --> 00:05:22,880
um domain and creating logical rules for

126
00:05:21,039 --> 00:05:24,840
deduction so that you would basically

127
00:05:22,880 --> 00:05:26,880
say given what I want to accomplish here

128
00:05:24,840 --> 00:05:29,800
is the natural way in which I would get

129
00:05:26,880 --> 00:05:32,240
to it there were some early commercial

130
00:05:29,800 --> 00:05:36,240
successes but again one of the struggles

131
00:05:32,240 --> 00:05:38,240
here was that they didn't scale well

132
00:05:36,240 --> 00:05:39,800
even if I built a system to do Campbell

133
00:05:38,240 --> 00:05:42,199
Soup maintenance which was the first

134
00:05:39,800 --> 00:05:44,319
successful AI uh application of which

135
00:05:42,199 --> 00:05:45,840
I'm aware you couldn't apply to some

136
00:05:44,319 --> 00:05:47,840
other problem you had to start over

137
00:05:45,840 --> 00:05:50,759
again it didn't learn it didn't

138
00:05:47,840 --> 00:05:54,800
generalize and that led to the second AI

139
00:05:50,759 --> 00:05:57,199
winter and now we're in the third phase

140
00:05:54,800 --> 00:06:00,520
and the third phase is really driven by

141
00:05:57,199 --> 00:06:02,440
bringing in solid scientific BAS from

142
00:06:00,520 --> 00:06:05,000
mathematics and from

143
00:06:02,440 --> 00:06:06,840
Neuroscience mathematics being able to

144
00:06:05,000 --> 00:06:08,599
reason about problems under uncertainty

145
00:06:06,840 --> 00:06:11,319
and come up with a principled solution

146
00:06:08,599 --> 00:06:13,680
to it and Neuroscience using what we

147
00:06:11,319 --> 00:06:16,319
know about how our brains work to give

148
00:06:13,680 --> 00:06:19,240
us a guide to how we might build real

149
00:06:16,319 --> 00:06:21,199
systems and of course began to see early

150
00:06:19,240 --> 00:06:23,919
on in this phase some successes you'll

151
00:06:21,199 --> 00:06:25,319
decide for yourself but IBM's Deep Blue

152
00:06:23,919 --> 00:06:27,599
System beating the world's chess

153
00:06:25,319 --> 00:06:29,599
champion was certainly an indication of

154
00:06:27,599 --> 00:06:31,080
the power of these systems in early

155
00:06:29,599 --> 00:06:33,240
commercial

156
00:06:31,080 --> 00:06:35,880
successes and today as you all know this

157
00:06:33,240 --> 00:06:38,120
is really then driven by three

158
00:06:35,880 --> 00:06:40,639
Trends deep learning which we're going

159
00:06:38,120 --> 00:06:43,479
to talk about briefly but using

160
00:06:40,639 --> 00:06:46,280
sophisticated statistical methods to

161
00:06:43,479 --> 00:06:49,000
reason under uncertainty about finding

162
00:06:46,280 --> 00:06:50,759
solutions to problems and being driven

163
00:06:49,000 --> 00:06:52,919
in part by what we know about how we

164
00:06:50,759 --> 00:06:54,639
think don't have to be exactly the same

165
00:06:52,919 --> 00:06:57,080
but it needs to be

166
00:06:54,639 --> 00:06:59,280
similar the second one is the incredible

167
00:06:57,080 --> 00:07:00,960
growth of data and this is an issue I

168
00:06:59,280 --> 00:07:03,800
think all of us need to think about as

169
00:07:00,960 --> 00:07:05,440
we build modern AI systems how do we get

170
00:07:03,800 --> 00:07:07,800
access to enough data to train these

171
00:07:05,440 --> 00:07:10,000
systems and how do we have confidence in

172
00:07:07,800 --> 00:07:12,759
the quality of the data and lack of bias

173
00:07:10,000 --> 00:07:15,639
in the data but as I'm sure many of you

174
00:07:12,759 --> 00:07:17,960
know a current modern AI system might

175
00:07:15,639 --> 00:07:20,560
have millions or hundreds of millions of

176
00:07:17,960 --> 00:07:22,479
parameters and you need hundreds of

177
00:07:20,560 --> 00:07:24,240
millions or billions of examples in

178
00:07:22,479 --> 00:07:26,280
order to train all of those parameters

179
00:07:24,240 --> 00:07:28,240
so massive data sets are

180
00:07:26,280 --> 00:07:31,000
important and the third one of course is

181
00:07:28,240 --> 00:07:32,639
an incredible growth in Computing

182
00:07:31,000 --> 00:07:35,440
whether that's standard Computing or

183
00:07:32,639 --> 00:07:36,919
that's GPU chips from Nvidia or AMD or

184
00:07:35,440 --> 00:07:38,919
pick your favorite company that makes

185
00:07:36,919 --> 00:07:42,560
these things the ability to do the

186
00:07:38,919 --> 00:07:44,720
Computing allows you to get to it notice

187
00:07:42,560 --> 00:07:46,879
two correlations though that come out of

188
00:07:44,720 --> 00:07:49,199
this not everybody's going to have

189
00:07:46,879 --> 00:07:50,840
access to the same data sets so there's

190
00:07:49,199 --> 00:07:52,080
going to be an imbalance about who can

191
00:07:50,840 --> 00:07:54,840
succeed in this

192
00:07:52,080 --> 00:07:56,680
space and the climate implications if

193
00:07:54,840 --> 00:07:59,520
you like are the power demands of these

194
00:07:56,680 --> 00:08:01,319
systems to do the training causes other

195
00:07:59,520 --> 00:08:03,599
challenges for companies and governments

196
00:08:01,319 --> 00:08:06,560
to think about how do we want to balance

197
00:08:03,599 --> 00:08:08,680
the advantages with the cost of it but

198
00:08:06,560 --> 00:08:10,759
those are the pieces that let us build a

199
00:08:08,680 --> 00:08:13,319
useful

200
00:08:10,759 --> 00:08:15,159
application now today AI is mostly

201
00:08:13,319 --> 00:08:18,520
machine learning not all of it but most

202
00:08:15,159 --> 00:08:20,639
of it is I'll let you read the joke here

203
00:08:18,520 --> 00:08:23,080
um unfortunately I think this is still

204
00:08:20,639 --> 00:08:24,599
true for lots of application cases you

205
00:08:23,080 --> 00:08:26,400
just throw a bunch of math and a bunch

206
00:08:24,599 --> 00:08:28,120
of data stir it around if you get a good

207
00:08:26,400 --> 00:08:30,680
answer great if you don't just stir it

208
00:08:28,120 --> 00:08:33,120
around until you get an answer you like

209
00:08:30,680 --> 00:08:35,080
not a satisfying way of dealing with

210
00:08:33,120 --> 00:08:36,800
things and so we want to talk a little

211
00:08:35,080 --> 00:08:39,200
bit about how one di better on it but

212
00:08:36,800 --> 00:08:40,599
essentially it's machine learning and

213
00:08:39,200 --> 00:08:42,680
the definition of machine learning

214
00:08:40,599 --> 00:08:45,080
actually comes from the early days of AI

215
00:08:42,680 --> 00:08:46,800
the first machine learning algorithm was

216
00:08:45,080 --> 00:08:48,920
done by an IBM researcher named art

217
00:08:46,800 --> 00:08:51,680
Samuel he wrote a program to learn to

218
00:08:48,920 --> 00:08:54,000
play Checkers that simple little game

219
00:08:51,680 --> 00:08:56,040
not very sophisticated but it learned

220
00:08:54,000 --> 00:08:57,720
and as he said it's the field of study

221
00:08:56,040 --> 00:09:00,320
that gives computers the ability to

222
00:08:57,720 --> 00:09:03,560
learn without being explicitly

223
00:09:00,320 --> 00:09:05,800
programmed all right great so with that

224
00:09:03,560 --> 00:09:08,440
in mind this is a more modern definition

225
00:09:05,800 --> 00:09:10,200
but with that in mind a quick reminder

226
00:09:08,440 --> 00:09:12,040
of what goes into machine learning and

227
00:09:10,200 --> 00:09:13,040
why we want to think carefully about how

228
00:09:12,040 --> 00:09:15,399
we use

229
00:09:13,040 --> 00:09:16,760
it traditional programming you're a

230
00:09:15,399 --> 00:09:19,000
client you give a program a

231
00:09:16,760 --> 00:09:21,440
specification I want my program to do

232
00:09:19,000 --> 00:09:23,800
this particular task with this input I

233
00:09:21,440 --> 00:09:25,120
want this output they write the program

234
00:09:23,800 --> 00:09:26,279
and then you give new inputs you get

235
00:09:25,120 --> 00:09:28,160
good answers

236
00:09:26,279 --> 00:09:31,240
out machine

237
00:09:28,160 --> 00:09:34,480
learning the programmer writes a machine

238
00:09:31,240 --> 00:09:37,880
learning program and takes a collection

239
00:09:34,480 --> 00:09:39,720
of input answer pairs for this input

240
00:09:37,880 --> 00:09:40,399
this is the answer for this input that's

241
00:09:39,720 --> 00:09:44,440
the

242
00:09:40,399 --> 00:09:47,480
answer and the Machine then builds a new

243
00:09:44,440 --> 00:09:49,040
program so that given new inputs it will

244
00:09:47,480 --> 00:09:51,000
give you an answer and you can use it to

245
00:09:49,040 --> 00:09:52,480
make a decision about is this the right

246
00:09:51,000 --> 00:09:55,120
thing I want to do and you are still

247
00:09:52,480 --> 00:09:57,519
involved in that but notice there's an

248
00:09:55,120 --> 00:09:59,839
implicit program there you never create

249
00:09:57,519 --> 00:10:01,600
the program the machine does and one of

250
00:09:59,839 --> 00:10:03,320
the questions is how well does it do it

251
00:10:01,600 --> 00:10:07,120
and does it do it in a manner that

252
00:10:03,320 --> 00:10:09,360
actually meets my goal and notice a

253
00:10:07,120 --> 00:10:11,720
problem that many people

254
00:10:09,360 --> 00:10:14,920
acknowledge the quality of the input

255
00:10:11,720 --> 00:10:16,760
data is going to dramatically affect the

256
00:10:14,920 --> 00:10:20,519
ability of the algorithm that gets

257
00:10:16,760 --> 00:10:23,160
created if you get it really good input

258
00:10:20,519 --> 00:10:25,079
data that covers the space it'll do well

259
00:10:23,160 --> 00:10:27,120
if you give it input data that's missing

260
00:10:25,079 --> 00:10:28,880
elements of the space or has a lot of

261
00:10:27,120 --> 00:10:29,959
incorrect information you're going to

262
00:10:28,880 --> 00:10:33,120
have a problem

263
00:10:29,959 --> 00:10:35,440
problem all right a quick

264
00:10:33,120 --> 00:10:37,120
example you have a set of training data

265
00:10:35,440 --> 00:10:38,880
I might say I hear a set of images that

266
00:10:37,120 --> 00:10:40,760
I know are cats here a set of images

267
00:10:38,880 --> 00:10:43,480
that I know are dogs I want to build a

268
00:10:40,760 --> 00:10:45,560
system that will recognize cats and dogs

269
00:10:43,480 --> 00:10:48,399
I convert each example into a set of

270
00:10:45,560 --> 00:10:49,839
features set of numbers in this case it

271
00:10:48,399 --> 00:10:51,639
might be a set of numbers that talk

272
00:10:49,839 --> 00:10:53,480
about the shape of the nose a set of

273
00:10:51,639 --> 00:10:55,079
numbers that say the color and the

274
00:10:53,480 --> 00:10:57,279
texture the fur a set of numbers that

275
00:10:55,079 --> 00:10:59,800
say the shape of the eye a collection of

276
00:10:57,279 --> 00:11:02,120
pieces like that and then I want to

277
00:10:59,800 --> 00:11:04,399
infer something about the process that

278
00:11:02,120 --> 00:11:06,480
created that and typically here I'll

279
00:11:04,399 --> 00:11:09,519
just use a neuronet I will train a

280
00:11:06,480 --> 00:11:11,519
system on those examples to say how do I

281
00:11:09,519 --> 00:11:13,440
wait the different features to have

282
00:11:11,519 --> 00:11:15,240
something that I think actually captures

283
00:11:13,440 --> 00:11:18,959
the difference between cats and

284
00:11:15,240 --> 00:11:20,839
dogs and then I only use it on new data

285
00:11:18,959 --> 00:11:22,920
to make sure it works so I give it a new

286
00:11:20,839 --> 00:11:25,839
image it says that's a cat give it a new

287
00:11:22,920 --> 00:11:27,399
image it says that's a dog and there's

288
00:11:25,839 --> 00:11:29,959
still a

289
00:11:27,399 --> 00:11:33,240
challenge are these cats

290
00:11:29,959 --> 00:11:35,880
or dogs or very confused

291
00:11:33,240 --> 00:11:38,440
animals I'll let you decide for yourself

292
00:11:35,880 --> 00:11:41,000
I think the one on the left is a dog I

293
00:11:38,440 --> 00:11:42,920
think the one next in is a cat I'm not

294
00:11:41,000 --> 00:11:44,360
certain the one after that and I think

295
00:11:42,920 --> 00:11:45,880
the one on the far right is a cat but

296
00:11:44,360 --> 00:11:47,880
you get the point they're going to be

297
00:11:45,880 --> 00:11:50,279
edge cases that you still need to think

298
00:11:47,880 --> 00:11:52,639
about as you use this

299
00:11:50,279 --> 00:11:54,959
system so that's the Paradigm for

300
00:11:52,639 --> 00:11:57,200
machine learning and I want to come back

301
00:11:54,959 --> 00:11:59,399
to how we use it today but also some of

302
00:11:57,200 --> 00:12:02,399
those challenges in terms of um of the

303
00:11:59,399 --> 00:12:04,120
performance of it um there's a range of

304
00:12:02,399 --> 00:12:05,959
things we want to do most common machine

305
00:12:04,120 --> 00:12:07,880
learning algorithms today are supervised

306
00:12:05,959 --> 00:12:10,560
we give them those feature label Pairs

307
00:12:07,880 --> 00:12:12,399
and we use them it's a whole range of

308
00:12:10,560 --> 00:12:15,199
algorithms many of them dating back to

309
00:12:12,399 --> 00:12:17,120
the 50s that can be used but today Le to

310
00:12:15,199 --> 00:12:19,760
my experience almost everything is some

311
00:12:17,120 --> 00:12:22,079
version of a neural net and of course

312
00:12:19,760 --> 00:12:23,800
the Hot Topic are large language models

313
00:12:22,079 --> 00:12:25,320
which everybody seems to want to use and

314
00:12:23,800 --> 00:12:27,880
we'll talk about that as well but these

315
00:12:25,320 --> 00:12:30,760
are all elements of what the systems

316
00:12:27,880 --> 00:12:32,199
use just a tiny bit more on what those

317
00:12:30,760 --> 00:12:34,240
systems

318
00:12:32,199 --> 00:12:35,800
do basically we're going to use

319
00:12:34,240 --> 00:12:38,160
something called logistic

320
00:12:35,800 --> 00:12:40,199
regression which is going to learn a

321
00:12:38,160 --> 00:12:43,880
probability of assigning a label to a

322
00:12:40,199 --> 00:12:46,440
new example based on that training data

323
00:12:43,880 --> 00:12:50,279
and so I'm going to skip

324
00:12:46,440 --> 00:12:52,160
this tiny bit of math this is an MIT

325
00:12:50,279 --> 00:12:53,880
talk there will be a quiz on the end so

326
00:12:52,160 --> 00:12:55,399
you might want to take a few notes but

327
00:12:53,880 --> 00:12:57,839
everybody will pass the quiz so don't

328
00:12:55,399 --> 00:13:00,079
worry about it and yes by the way my

329
00:12:57,839 --> 00:13:01,680
jokes are all bad but I'm a 10e

330
00:13:00,079 --> 00:13:03,839
professor so you can't do a damn thing

331
00:13:01,680 --> 00:13:05,480
about it all right with that in mind

332
00:13:03,839 --> 00:13:08,000
just it's worth reminding you what that

333
00:13:05,480 --> 00:13:10,399
system does so in logistic regression

334
00:13:08,000 --> 00:13:12,120
I've got a set of feature values in a

335
00:13:10,399 --> 00:13:14,399
modern system that might be tens of

336
00:13:12,120 --> 00:13:16,440
thousands of feature values and the

337
00:13:14,399 --> 00:13:18,959
system is going to learn weights to

338
00:13:16,440 --> 00:13:20,920
assign to those features so that given

339
00:13:18,959 --> 00:13:23,519
an instance it multiplies The Weight by

340
00:13:20,920 --> 00:13:25,360
the feature value adds them all up and

341
00:13:23,519 --> 00:13:28,120
it applies what's called a logistic

342
00:13:25,360 --> 00:13:31,560
function to it and that function is

343
00:13:28,120 --> 00:13:34,639
designed to assign the probability that

344
00:13:31,560 --> 00:13:37,320
this is in fact an example of what I'm

345
00:13:34,639 --> 00:13:38,959
looking for and it's designed to very

346
00:13:37,320 --> 00:13:40,760
quickly push the probability either

347
00:13:38,959 --> 00:13:42,880
towards zero or towards

348
00:13:40,760 --> 00:13:45,399
one and the whole

349
00:13:42,880 --> 00:13:46,680
goal is to find what are the best

350
00:13:45,399 --> 00:13:50,399
weights which is what the learning

351
00:13:46,680 --> 00:13:52,519
algorithms do and then set a

352
00:13:50,399 --> 00:13:54,680
threshold so that when I have a new

353
00:13:52,519 --> 00:13:57,079
instance if I'm above that threshold I'm

354
00:13:54,680 --> 00:13:58,800
going to say this is an instance and if

355
00:13:57,079 --> 00:14:01,839
it's not above that threshold I'm going

356
00:13:58,800 --> 00:14:03,880
to say it's not an instance of it and I

357
00:14:01,839 --> 00:14:05,680
raised the threshold because it's

358
00:14:03,880 --> 00:14:08,079
actually important to think about and

359
00:14:05,680 --> 00:14:10,519
unfortunately many AI systems

360
00:14:08,079 --> 00:14:13,199
don't for example if I'm building a

361
00:14:10,519 --> 00:14:16,880
system for autonomous driving that is

362
00:14:13,199 --> 00:14:19,120
going to try and detect pedestrians I

363
00:14:16,880 --> 00:14:22,600
want to set the threshold so I have very

364
00:14:19,120 --> 00:14:24,279
few false negatives I don't want to not

365
00:14:22,600 --> 00:14:26,079
recognize a pedestrian and have a

366
00:14:24,279 --> 00:14:27,759
disaster so I want very few false

367
00:14:26,079 --> 00:14:29,519
negatives that tells me how to set the

368
00:14:27,759 --> 00:14:30,920
threshold

369
00:14:29,519 --> 00:14:32,600
on the other hand if I'm a faculty

370
00:14:30,920 --> 00:14:34,120
member and I'm running an exam and I'm

371
00:14:32,600 --> 00:14:35,759
looking for cheating I hopefully don't

372
00:14:34,120 --> 00:14:38,680
use this solution which I think comes

373
00:14:35,759 --> 00:14:41,519
from India but I probably want very few

374
00:14:38,680 --> 00:14:43,600
false positives I'd much rather accept a

375
00:14:41,519 --> 00:14:45,720
few kids getting away with cheating than

376
00:14:43,600 --> 00:14:48,519
accuse somebody of of cheating in that

377
00:14:45,720 --> 00:14:50,639
exam so you get the idea the context

378
00:14:48,519 --> 00:14:51,880
really matters here in terms of how I

379
00:14:50,639 --> 00:14:54,279
set the

380
00:14:51,880 --> 00:14:56,800
threshold all right almost start with a

381
00:14:54,279 --> 00:14:59,120
preview so what about neuron

382
00:14:56,800 --> 00:15:00,920
Nets based on our knowledge and neur

383
00:14:59,120 --> 00:15:02,560
physiology how our brain works but

384
00:15:00,920 --> 00:15:04,720
there're essentially a way of learning

385
00:15:02,560 --> 00:15:06,399
those weights in order to set up a

386
00:15:04,720 --> 00:15:08,560
logistic

387
00:15:06,399 --> 00:15:11,079
classifier and so an artificial neuron

388
00:15:08,560 --> 00:15:14,399
net again simplified model what goes on

389
00:15:11,079 --> 00:15:17,160
in the brain I've got a set of inputs

390
00:15:14,399 --> 00:15:20,240
set of feature values number bunch of

391
00:15:17,160 --> 00:15:23,279
numbers I then connect each of those

392
00:15:20,240 --> 00:15:26,720
features to what's called a hidden node

393
00:15:23,279 --> 00:15:28,959
and it takes the product of the weights

394
00:15:26,720 --> 00:15:30,160
and the feature values adds them up and

395
00:15:28,959 --> 00:15:31,839
applies a function to it that gives you

396
00:15:30,160 --> 00:15:34,440
an output of that internal

397
00:15:31,839 --> 00:15:36,079
node the U choice of that function is

398
00:15:34,440 --> 00:15:38,199
really important we'll talk briefly

399
00:15:36,079 --> 00:15:40,959
about that and though those are all

400
00:15:38,199 --> 00:15:43,160
connected up to an output note with an

401
00:15:40,959 --> 00:15:45,480
additional set of weights and that

402
00:15:43,160 --> 00:15:47,800
weighted sum is applied to the input to

403
00:15:45,480 --> 00:15:50,639
the logistic function to say yes this is

404
00:15:47,800 --> 00:15:52,000
a cat or yes this is a dog or I'm not

405
00:15:50,639 --> 00:15:53,800
certain it's one of those confused

406
00:15:52,000 --> 00:15:57,279
examples in

407
00:15:53,800 --> 00:16:00,279
between in the early days artificial

408
00:15:57,279 --> 00:16:02,040
neuron Nets had maybe one hidden layer

409
00:16:00,279 --> 00:16:05,600
mostly because of computational costs

410
00:16:02,040 --> 00:16:07,680
and lack of data today they can be huge

411
00:16:05,600 --> 00:16:10,639
one of my favorite examples from an MIT

412
00:16:07,680 --> 00:16:13,399
spin-off sense time the Hong Kong based

413
00:16:10,639 --> 00:16:15,720
face recognition an AI company their

414
00:16:13,399 --> 00:16:17,279
system has a thousand layers in their

415
00:16:15,720 --> 00:16:19,680
artificial neuronet and I'm sure there

416
00:16:17,279 --> 00:16:22,240
are bigger examples around but that's

417
00:16:19,680 --> 00:16:25,160
basically what we want to

418
00:16:22,240 --> 00:16:28,360
do all right and then deep learning just

419
00:16:25,160 --> 00:16:30,600
refers to a complex neural net trying to

420
00:16:28,360 --> 00:16:32,800
accomplish the this there lots of

421
00:16:30,600 --> 00:16:34,639
variations but most of them and early

422
00:16:32,800 --> 00:16:36,319
ones at least in computer vision go back

423
00:16:34,639 --> 00:16:38,560
to the work of two Harvard

424
00:16:36,319 --> 00:16:41,199
neuroscientists that won the Nobel Prize

425
00:16:38,560 --> 00:16:44,399
David Hubble and Thorston weasel who

426
00:16:41,199 --> 00:16:46,440
discovered cells in primate cortex that

427
00:16:44,399 --> 00:16:48,800
did what we would see today as an

428
00:16:46,440 --> 00:16:50,720
artificial neural net and I'm going to

429
00:16:48,800 --> 00:16:52,680
skip by the examples other than just to

430
00:16:50,720 --> 00:16:55,040
say that a modern neural net can do

431
00:16:52,680 --> 00:16:57,399
things like face recognition character

432
00:16:55,040 --> 00:16:59,680
recognition extremely

433
00:16:57,399 --> 00:17:01,800
well all right

434
00:16:59,680 --> 00:17:04,120
and then large large language

435
00:17:01,800 --> 00:17:06,120
models I'm sure you're all aware of them

436
00:17:04,120 --> 00:17:09,400
they're the current rage I think they

437
00:17:06,120 --> 00:17:12,240
have a lot to to to add to the system

438
00:17:09,400 --> 00:17:15,559
basically I think of these as a deep

439
00:17:12,240 --> 00:17:18,280
neural net that has some interesting

440
00:17:15,559 --> 00:17:20,839
properties in language it's a way of

441
00:17:18,280 --> 00:17:23,360
predicting what's the next word in an

442
00:17:20,839 --> 00:17:26,760
answer I'm constructing based on the

443
00:17:23,360 --> 00:17:28,400
words before it notice the size though

444
00:17:26,760 --> 00:17:30,960
here a word in this system is

445
00:17:28,400 --> 00:17:32,160
represented presented by over 12,000

446
00:17:30,960 --> 00:17:35,160
feature

447
00:17:32,160 --> 00:17:37,760
values a word with a similar meaning is

448
00:17:35,160 --> 00:17:39,840
very close to other ones a word that has

449
00:17:37,760 --> 00:17:41,520
multiple meanings has multiple

450
00:17:39,840 --> 00:17:43,520
representations so that you can deal

451
00:17:41,520 --> 00:17:46,120
with the confusions in language and a

452
00:17:43,520 --> 00:17:49,280
sentence is just a sequence of those

453
00:17:46,120 --> 00:17:50,840
feature vectors one for each word the

454
00:17:49,280 --> 00:17:53,200
magic inside of here is something called

455
00:17:50,840 --> 00:17:55,919
a Transformer which is a system that

456
00:17:53,200 --> 00:17:58,840
basically takes one of those words as a

457
00:17:55,919 --> 00:18:01,760
representation and uses other words to

458
00:17:58,840 --> 00:18:03,960
decide how to disambiguate meaning how

459
00:18:01,760 --> 00:18:05,799
to use context to associate pronouns

460
00:18:03,960 --> 00:18:08,000
with nouns how to use other information

461
00:18:05,799 --> 00:18:11,320
to refine the words so that you can then

462
00:18:08,000 --> 00:18:13,159
run the full system in order to come up

463
00:18:11,320 --> 00:18:15,320
with a

464
00:18:13,159 --> 00:18:17,919
solution to train

465
00:18:15,320 --> 00:18:19,159
this Deep Mind who did one of the first

466
00:18:17,919 --> 00:18:21,840
versions of

467
00:18:19,159 --> 00:18:24,480
this or open AI which is probably the

468
00:18:21,840 --> 00:18:27,360
better example of it they trained their

469
00:18:24,480 --> 00:18:29,480
system on 30 billion

470
00:18:27,360 --> 00:18:31,440
sentences 30

471
00:18:29,480 --> 00:18:33,400
billion by the way all of you are

472
00:18:31,440 --> 00:18:36,159
entitled to a little bit of revenue from

473
00:18:33,400 --> 00:18:38,520
open AI because they probably used your

474
00:18:36,159 --> 00:18:40,640
Facebook page or your LinkedIn page or

475
00:18:38,520 --> 00:18:42,039
something else to gather that data

476
00:18:40,640 --> 00:18:44,520
without your permission you can worry

477
00:18:42,039 --> 00:18:47,200
about the legal ramifications of that

478
00:18:44,520 --> 00:18:50,000
but they met mined massive amounts of

479
00:18:47,200 --> 00:18:52,880
data in order to train this and now

480
00:18:50,000 --> 00:18:55,440
given an input query the system

481
00:18:52,880 --> 00:18:57,880
basically samples words from that query

482
00:18:55,440 --> 00:18:59,840
to start the system and then predicts

483
00:18:57,880 --> 00:19:01,400
probabilistically

484
00:18:59,840 --> 00:19:04,159
what's the likely answer I want to

485
00:19:01,400 --> 00:19:06,600
generate with an input as long as 3,000

486
00:19:04,159 --> 00:19:08,320
words long which is actually

487
00:19:06,600 --> 00:19:10,440
impressive and of course you can

488
00:19:08,320 --> 00:19:13,880
generalize this if you want to create a

489
00:19:10,440 --> 00:19:16,880
chatbot you take as input a sequence of

490
00:19:13,880 --> 00:19:18,600
queries and responses either generated

491
00:19:16,880 --> 00:19:21,559
by chat GPT or it's something that

492
00:19:18,600 --> 00:19:23,600
humans did you scale them or weight them

493
00:19:21,559 --> 00:19:25,280
in terms of what the quality is and then

494
00:19:23,600 --> 00:19:26,600
you retrain the system in order to

495
00:19:25,280 --> 00:19:29,240
create something that gives you

496
00:19:26,600 --> 00:19:31,760
conversations

497
00:19:29,240 --> 00:19:34,640
so probably a longer Preamble than you

498
00:19:31,760 --> 00:19:37,880
needed but those are the elements of

499
00:19:34,640 --> 00:19:40,280
modern Ai and I want to give you a

500
00:19:37,880 --> 00:19:41,480
sense of some of the strengths and some

501
00:19:40,280 --> 00:19:43,919
of the

502
00:19:41,480 --> 00:19:46,760
challenges I want to remind you that a

503
00:19:43,919 --> 00:19:49,360
modern large language model based on all

504
00:19:46,760 --> 00:19:51,799
of this technology gives you a

505
00:19:49,360 --> 00:19:54,960
probability gives you the probability of

506
00:19:51,799 --> 00:19:57,159
a good answer if you run the same query

507
00:19:54,960 --> 00:19:58,880
multiple times you may get slightly

508
00:19:57,159 --> 00:20:01,440
different answers you may get VAR

509
00:19:58,880 --> 00:20:03,880
different answers because it's a

510
00:20:01,440 --> 00:20:06,679
probability if there is bias in your

511
00:20:03,880 --> 00:20:09,039
training data and bias can be incorrect

512
00:20:06,679 --> 00:20:11,600
data but it can also just be things

513
00:20:09,039 --> 00:20:14,320
you're missing it's going to affect the

514
00:20:11,600 --> 00:20:17,280
output in health care this can be a huge

515
00:20:14,320 --> 00:20:19,640
problem a system trained on data from

516
00:20:17,280 --> 00:20:21,840
people that look like me may be very

517
00:20:19,640 --> 00:20:23,120
different than a system applied to data

518
00:20:21,840 --> 00:20:25,360
from people that look like you or

519
00:20:23,120 --> 00:20:28,640
somebody else because of missing data so

520
00:20:25,360 --> 00:20:31,039
bias in the data is huge and these syst

521
00:20:28,640 --> 00:20:34,120
systems don't have the ability to apply

522
00:20:31,039 --> 00:20:35,919
common sense to their answer comes up

523
00:20:34,120 --> 00:20:38,600
with a ridiculous answer you or I would

524
00:20:35,919 --> 00:20:42,280
look at it and say no way system doesn't

525
00:20:38,600 --> 00:20:43,480
have that ability so it's a tool it's

526
00:20:42,280 --> 00:20:45,320
not a

527
00:20:43,480 --> 00:20:46,679
replacement and I want to show you an

528
00:20:45,320 --> 00:20:48,000
example of this I'm stealing a little

529
00:20:46,679 --> 00:20:49,240
bit of Thunder From A couple of my

530
00:20:48,000 --> 00:20:52,799
colleagues but I want to show you very

531
00:20:49,240 --> 00:20:55,080
quickly a little bit of an example of

532
00:20:52,799 --> 00:20:56,760
using an AI system and why you need to

533
00:20:55,080 --> 00:20:58,840
be careful about knowing when to trust

534
00:20:56,760 --> 00:21:00,440
the response it's a study out of the

535
00:20:58,840 --> 00:21:02,400
Sloan School of Management at MIT I

536
00:21:00,440 --> 00:21:05,559
think in collaboration with some other

537
00:21:02,400 --> 00:21:06,559
people they took if I remember right 500

538
00:21:05,559 --> 00:21:09,640
middle

539
00:21:06,559 --> 00:21:11,640
managers HR experts uh management

540
00:21:09,640 --> 00:21:14,720
experts and they divided them up into

541
00:21:11,640 --> 00:21:16,080
three groups a control group a group

542
00:21:14,720 --> 00:21:19,279
that had access to

543
00:21:16,080 --> 00:21:23,440
gp4 and a group that had access to gp4

544
00:21:19,279 --> 00:21:25,440
gp4 and a guide on how to use it and

545
00:21:23,440 --> 00:21:28,600
they gave them two tasks the first task

546
00:21:25,440 --> 00:21:30,919
was designed to fit very squarely in

547
00:21:28,600 --> 00:21:33,640
into the expertise of chat

548
00:21:30,919 --> 00:21:36,000
gp4 it was a coming up with a

549
00:21:33,640 --> 00:21:36,799
description of a new product and notice

550
00:21:36,000 --> 00:21:39,840
the

551
00:21:36,799 --> 00:21:42,159
results the group that had access to gp4

552
00:21:39,840 --> 00:21:45,000
as judged by experts their performance

553
00:21:42,159 --> 00:21:46,400
both in efficiency and in quality

554
00:21:45,000 --> 00:21:49,120
improved

555
00:21:46,400 --> 00:21:51,200
38% and if you were in the lower half

556
00:21:49,120 --> 00:21:53,320
you had less experience less capability

557
00:21:51,200 --> 00:21:55,360
your improvement was 43% if you're more

558
00:21:53,320 --> 00:21:58,720
experienced not surprisingly it still an

559
00:21:55,360 --> 00:22:01,200
improvement of 177% you got better if

560
00:21:58,720 --> 00:22:02,200
you had access to gp4 and a guide on how

561
00:22:01,200 --> 00:22:04,760
to use

562
00:22:02,200 --> 00:22:06,440
it you did even better in terms of

563
00:22:04,760 --> 00:22:09,000
performance this is

564
00:22:06,440 --> 00:22:11,120
great you notice I have blocked out part

565
00:22:09,000 --> 00:22:12,960
of the slide because now you go to a

566
00:22:11,120 --> 00:22:16,080
problem that was designed very

567
00:22:12,960 --> 00:22:18,559
explicitly not to fit well with the

568
00:22:16,080 --> 00:22:22,679
capabilities of

569
00:22:18,559 --> 00:22:27,279
gp4 and there the group using

570
00:22:22,679 --> 00:22:30,200
gp4 their performance decreased by

571
00:22:27,279 --> 00:22:34,799
13% all right right not great and the

572
00:22:30,200 --> 00:22:34,799
group that had gp4 and a guide to use

573
00:22:35,240 --> 00:22:40,559
it their performance decreased even

574
00:22:38,880 --> 00:22:44,000
more

575
00:22:40,559 --> 00:22:46,400
why because they trusted it it's an AI

576
00:22:44,000 --> 00:22:50,279
system has got to be good it must be

577
00:22:46,400 --> 00:22:53,240
right not a good answer my point is it's

578
00:22:50,279 --> 00:22:55,039
a tool and as a user you need to know

579
00:22:53,240 --> 00:22:57,200
how to judge when it is doing something

580
00:22:55,039 --> 00:22:59,240
that's acceptable and when it is not and

581
00:22:57,200 --> 00:23:02,240
I think that's one of the challenges

582
00:22:59,240 --> 00:23:04,480
here nonetheless it's been fascinating

583
00:23:02,240 --> 00:23:05,799
to see the impact of AI and I will

584
00:23:04,480 --> 00:23:08,880
simply point out to you this year's

585
00:23:05,799 --> 00:23:12,679
Nobel Prize and pH physics two of the

586
00:23:08,880 --> 00:23:15,559
awardees are pioneers in uh in um deep

587
00:23:12,679 --> 00:23:18,200
learning Jeff Hinton and John hopfield

588
00:23:15,559 --> 00:23:20,760
Nobel Prize in chemistry Demis Aus

589
00:23:18,200 --> 00:23:23,360
another Pioneer in in neural

590
00:23:20,760 --> 00:23:25,600
Nets hfield spent a year at MIT on

591
00:23:23,360 --> 00:23:28,039
sabatical oops sorry I'll go back there

592
00:23:25,600 --> 00:23:30,080
I went too fast and hbus competed his

593
00:23:28,039 --> 00:23:33,120
post office at MIT so we had a little

594
00:23:30,080 --> 00:23:35,919
bit of effort in in influencing these

595
00:23:33,120 --> 00:23:39,320
people with that in mind where are we

596
00:23:35,919 --> 00:23:42,080
today and what's MIT

597
00:23:39,320 --> 00:23:43,799
doing there are a ton of areas of great

598
00:23:42,080 --> 00:23:45,799
success I've just listed a bunch of my

599
00:23:43,799 --> 00:23:48,279
favorites here um I'm going to show you

600
00:23:45,799 --> 00:23:50,760
four examples of them but there's hardly

601
00:23:48,279 --> 00:23:53,520
an area that hasn't seen an interesting

602
00:23:50,760 --> 00:23:55,360
application of AI into the system

603
00:23:53,520 --> 00:23:57,039
systems mostly built around software but

604
00:23:55,360 --> 00:23:59,159
obviously there are Hardware boosts

605
00:23:57,039 --> 00:24:02,200
certainly gpus but also specialized

606
00:23:59,159 --> 00:24:06,080
chips being built to make these things

607
00:24:02,200 --> 00:24:08,840
go and so success stories you all use

608
00:24:06,080 --> 00:24:11,440
them speech recognition speech

609
00:24:08,840 --> 00:24:13,559
translation remarkably good systems and

610
00:24:11,440 --> 00:24:15,880
a range of them

611
00:24:13,559 --> 00:24:17,720
available my own field is or was

612
00:24:15,880 --> 00:24:20,120
computer vision I find some of these

613
00:24:17,720 --> 00:24:22,000
systems really impressive face

614
00:24:20,120 --> 00:24:24,440
recognition systems today actually

615
00:24:22,000 --> 00:24:26,880
perform better than humans certainly on

616
00:24:24,440 --> 00:24:29,760
face verification and even on face

617
00:24:26,880 --> 00:24:32,159
recognition um a ious

618
00:24:29,760 --> 00:24:34,120
driving should be careful as I say this

619
00:24:32,159 --> 00:24:35,760
I'm not a fan of some of the shortcuts

620
00:24:34,120 --> 00:24:37,799
that Tesla has taken here but there are

621
00:24:35,760 --> 00:24:40,240
some impressive systems for doing

622
00:24:37,799 --> 00:24:42,360
autonomous driving primarily one for me

623
00:24:40,240 --> 00:24:44,159
is uh mobile eye um it does an

624
00:24:42,360 --> 00:24:46,039
incredible job with it but computer

625
00:24:44,159 --> 00:24:48,000
vision has been dramatically

626
00:24:46,039 --> 00:24:50,720
changed

627
00:24:48,000 --> 00:24:52,520
robotics I'm being biased this is an MIT

628
00:24:50,720 --> 00:24:54,399
event these are four MIT spin-off

629
00:24:52,520 --> 00:24:56,880
companies Mobile Life with autonomous

630
00:24:54,399 --> 00:24:59,039
driving iroot and the Roomba with

631
00:24:56,880 --> 00:25:01,520
household robots key are now part of

632
00:24:59,039 --> 00:25:04,440
Amazon with Logistics and perhaps an

633
00:25:01,520 --> 00:25:07,080
interesting one farmwise which does an

634
00:25:04,440 --> 00:25:10,159
AI based Vision system to actually pick

635
00:25:07,080 --> 00:25:12,679
weeds from crops without damaging the

636
00:25:10,159 --> 00:25:16,000
crop in in Practical use

637
00:25:12,679 --> 00:25:17,919
today and of course question answering

638
00:25:16,000 --> 00:25:20,399
early version would be IBM's Watson

639
00:25:17,919 --> 00:25:22,720
system but chat GPT is a great example

640
00:25:20,399 --> 00:25:25,039
of the kinds of things you can do terms

641
00:25:22,720 --> 00:25:29,279
of answering

642
00:25:25,039 --> 00:25:31,320
questions so what's MIT doing

643
00:25:29,279 --> 00:25:33,799
we're essentially embedding Ai and

644
00:25:31,320 --> 00:25:37,480
machine learning across the entire

645
00:25:33,799 --> 00:25:39,080
Institute and we're doing it both at the

646
00:25:37,480 --> 00:25:42,080
curricular level in terms of what we

647
00:25:39,080 --> 00:25:44,559
teach students but also in terms of

648
00:25:42,080 --> 00:25:46,120
research and I think in interest of time

649
00:25:44,559 --> 00:25:47,600
I'm going to skip over the curricular

650
00:25:46,120 --> 00:25:48,960
level they'd be happy to all right sorry

651
00:25:47,600 --> 00:25:51,240
I'd be happy to answer questions but

652
00:25:48,960 --> 00:25:54,559
we're changing how we train and teach

653
00:25:51,240 --> 00:25:56,919
students today to embed computation

654
00:25:54,559 --> 00:25:59,000
throughout the curriculum every student

655
00:25:56,919 --> 00:26:02,720
is learning about

656
00:25:59,000 --> 00:26:04,120
Ai No matter what their major is what I

657
00:26:02,720 --> 00:26:06,399
want to show you is the level of

658
00:26:04,120 --> 00:26:08,919
activity and interest at MIT today in

659
00:26:06,399 --> 00:26:12,200
terms of research using these

660
00:26:08,919 --> 00:26:14,000
systems when we founded the MIT Stephen

661
00:26:12,200 --> 00:26:17,080
a schwarzman college of computing 5

662
00:26:14,000 --> 00:26:19,120
years ago one of the things we said was

663
00:26:17,080 --> 00:26:20,480
we were not only going to Ed computation

664
00:26:19,120 --> 00:26:24,960
throughout the Institute but we were

665
00:26:20,480 --> 00:26:27,399
going to add 50 new faculty lines to The

666
00:26:24,960 --> 00:26:29,559
Institute it's the largest growth at MIT

667
00:26:27,399 --> 00:26:32,840
in 80 years

668
00:26:29,559 --> 00:26:34,520
25 of them are in computer science 25 of

669
00:26:32,840 --> 00:26:36,799
them are bridge faculty they're in

670
00:26:34,520 --> 00:26:38,399
between computer science or the college

671
00:26:36,799 --> 00:26:41,120
if you like and another

672
00:26:38,399 --> 00:26:43,080
discipline and that both changes the

673
00:26:41,120 --> 00:26:46,039
kind of faculty member we hire but it

674
00:26:43,080 --> 00:26:48,799
changes the way we think about using

675
00:26:46,039 --> 00:26:50,960
AI so I know this is a busy slide but

676
00:26:48,799 --> 00:26:54,240
here are examples of the people that we

677
00:26:50,960 --> 00:26:55,279
have hired in The Last 5 Years in these

678
00:26:54,240 --> 00:26:57,679
Bridge

679
00:26:55,279 --> 00:27:00,159
areas in management somebody who does

680
00:26:57,679 --> 00:27:02,760
Behavior economics mechanical

681
00:27:00,159 --> 00:27:04,720
engineering agriculture management

682
00:27:02,760 --> 00:27:07,039
chemical engineering new synthesis

683
00:27:04,720 --> 00:27:12,480
design but then some places that may

684
00:27:07,039 --> 00:27:15,480
surprise you um uh music music

685
00:27:12,480 --> 00:27:17,480
technology we've have an offer out in

686
00:27:15,480 --> 00:27:20,000
Philosophy for somebody who does

687
00:27:17,480 --> 00:27:22,480
computational ethics how do you think

688
00:27:20,000 --> 00:27:25,039
about the ethical use of these

689
00:27:22,480 --> 00:27:26,880
systems and then I have the pleasure

690
00:27:25,039 --> 00:27:29,240
this term of actually co-sharing a

691
00:27:26,880 --> 00:27:33,159
search committee to find somebody who

692
00:27:29,240 --> 00:27:35,039
sits between computation and

693
00:27:33,159 --> 00:27:36,600
history going to be an interesting

694
00:27:35,039 --> 00:27:38,760
challenge to find somebody but there are

695
00:27:36,600 --> 00:27:41,519
some interesting people there but the

696
00:27:38,760 --> 00:27:45,240
idea is that we want to have faculty

697
00:27:41,519 --> 00:27:48,120
that are bridges here two weeks ago MIT

698
00:27:45,240 --> 00:27:51,039
did its review of Faculty members for

699
00:27:48,120 --> 00:27:55,360
promotions and of the I don't know 60

700
00:27:51,039 --> 00:27:58,760
cases that we saw I would say 55 of them

701
00:27:55,360 --> 00:28:00,480
involved somebody using AI

702
00:27:58,760 --> 00:28:02,480
in a department whether that was urban

703
00:28:00,480 --> 00:28:05,000
planning or that was economics or that

704
00:28:02,480 --> 00:28:08,399
was philosophy or that was political

705
00:28:05,000 --> 00:28:10,519
science so there's actually a real

706
00:28:08,399 --> 00:28:12,279
strong interest and let me show you some

707
00:28:10,519 --> 00:28:14,559
examples of

708
00:28:12,279 --> 00:28:16,640
this one of I shouldn't say my favorites

709
00:28:14,559 --> 00:28:18,200
I have lots of favorites two colleagues

710
00:28:16,640 --> 00:28:19,600
built a deep Learning System this is

711
00:28:18,200 --> 00:28:22,880
before chat

712
00:28:19,600 --> 00:28:26,000
GPT that is able to identify new drugs

713
00:28:22,880 --> 00:28:28,120
to kill antibiotic resistant bacterial

714
00:28:26,000 --> 00:28:29,880
infections has a lot of structural

715
00:28:28,120 --> 00:28:31,720
knowledgeable chemistry built in but it

716
00:28:29,880 --> 00:28:35,360
also has a deep Learning System

717
00:28:31,720 --> 00:28:37,279
underneath it in their first trial the

718
00:28:35,360 --> 00:28:39,120
this the sorry the molecule they

719
00:28:37,279 --> 00:28:41,799
selected based on what the system gave

720
00:28:39,120 --> 00:28:46,000
them as recommendations they tested on

721
00:28:41,799 --> 00:28:49,159
25 known antibiotic resistant infections

722
00:28:46,000 --> 00:28:53,840
and that new molecule was shown to be

723
00:28:49,159 --> 00:28:56,679
have an effect on 24 out of 25 it was

724
00:28:53,840 --> 00:28:58,519
one lung infection it didn't deal with

725
00:28:56,679 --> 00:29:01,640
since then they've used it to designed

726
00:28:58,519 --> 00:29:03,120
drugs very specifically for particular

727
00:29:01,640 --> 00:29:05,720
antibiotic resistant bacterial

728
00:29:03,120 --> 00:29:08,720
infections you can see two examples

729
00:29:05,720 --> 00:29:10,080
here can't resist telling you because my

730
00:29:08,720 --> 00:29:12,200
colleagues had discovered a new drug

731
00:29:10,080 --> 00:29:14,559
they got to give it a name and they

732
00:29:12,200 --> 00:29:17,840
chose to call this new drug

733
00:29:14,559 --> 00:29:21,000
halison h i i

734
00:29:17,840 --> 00:29:22,760
n iin that sounds like you know penic

735
00:29:21,000 --> 00:29:26,159
sounds like the name of a drug and where

736
00:29:22,760 --> 00:29:28,440
did HAL come from the AI computer in

737
00:29:26,159 --> 00:29:30,240
2001 of Space Odyssey so they ner

738
00:29:28,440 --> 00:29:32,519
they're Geeks they have a terrible sense

739
00:29:30,240 --> 00:29:35,440
of humor but they have the ability to

740
00:29:32,519 --> 00:29:36,919
actually build it but notice the impact

741
00:29:35,440 --> 00:29:40,120
new drug

742
00:29:36,919 --> 00:29:42,640
Discovery a colleague second colleague

743
00:29:40,120 --> 00:29:45,519
actually a colleague in both of these is

744
00:29:42,640 --> 00:29:47,360
a breast cancer survivor and she become

745
00:29:45,519 --> 00:29:50,039
became fascinated with how can he do a

746
00:29:47,360 --> 00:29:51,279
better job of detection she has built a

747
00:29:50,039 --> 00:29:54,080
deep learning

748
00:29:51,279 --> 00:29:58,880
system which tested on retrospective

749
00:29:54,080 --> 00:30:02,120
data old data she has shown with 85% %

750
00:29:58,880 --> 00:30:04,440
accuracy can spot the early signs of

751
00:30:02,120 --> 00:30:08,399
something that is going to turn into a

752
00:30:04,440 --> 00:30:11,519
tumor 5 years before the radiologist

753
00:30:08,399 --> 00:30:14,000
will detect it it's now in common use at

754
00:30:11,519 --> 00:30:17,720
the Harvard hospitals as a screening

755
00:30:14,000 --> 00:30:21,080
mechanism incredible impact on human

756
00:30:17,720 --> 00:30:22,519
health third example from Health

757
00:30:21,080 --> 00:30:25,120
colleague Dina

758
00:30:22,519 --> 00:30:28,840
katabi he a wireless communication

759
00:30:25,120 --> 00:30:31,080
expert here's a Wi-Fi signal here as I'm

760
00:30:28,840 --> 00:30:34,279
pacing back and forth I am slightly

761
00:30:31,080 --> 00:30:35,760
disrupting that Wi-Fi signal and her

762
00:30:34,279 --> 00:30:38,360
system which could be in the corner of

763
00:30:35,760 --> 00:30:41,519
the room will not only detect that

764
00:30:38,360 --> 00:30:44,440
disruption it will infer what caused it

765
00:30:41,519 --> 00:30:47,480
so things she can do she can detect

766
00:30:44,440 --> 00:30:50,039
vital signs of a patient remotely with

767
00:30:47,480 --> 00:30:52,159
nothing attached to the patient during

768
00:30:50,039 --> 00:30:53,799
Co we used her system in all of the of

769
00:30:52,159 --> 00:30:55,600
the Boston b or not all most of the

770
00:30:53,799 --> 00:30:59,080
Boston based hospitals so that staff

771
00:30:55,600 --> 00:31:01,240
didn't have to go into the ICU

772
00:30:59,080 --> 00:31:04,120
she can actually tell how well I'm

773
00:31:01,240 --> 00:31:05,120
walking so if I happen to be a patient

774
00:31:04,120 --> 00:31:07,360
with

775
00:31:05,120 --> 00:31:10,159
Parkinson's her system can tell a

776
00:31:07,360 --> 00:31:12,360
clinician how the disease is progressing

777
00:31:10,159 --> 00:31:14,000
automatically um she can detect

778
00:31:12,360 --> 00:31:16,679
activities the one that I find

779
00:31:14,000 --> 00:31:20,200
fascinating she can detect disruptions

780
00:31:16,679 --> 00:31:22,679
in sleep which are often a signal of

781
00:31:20,200 --> 00:31:24,760
onset of diseases like Parkinson's all

782
00:31:22,679 --> 00:31:27,159
completely

783
00:31:24,760 --> 00:31:29,159
automatically Transportation obviously

784
00:31:27,159 --> 00:31:31,039
we're working on a autonomous vehicles

785
00:31:29,159 --> 00:31:32,600
extensively we're interested in the

786
00:31:31,039 --> 00:31:34,240
traditional components of it but we're

787
00:31:32,600 --> 00:31:37,000
especially interested in things like

788
00:31:34,240 --> 00:31:38,440
Behavior prediction how do you predict

789
00:31:37,000 --> 00:31:39,679
what a vehicle in front of you is going

790
00:31:38,440 --> 00:31:42,360
to do how do you predict what a

791
00:31:39,679 --> 00:31:44,279
pedestrian is going to do if I were in

792
00:31:42,360 --> 00:31:45,639
Bangkok my apologies how do you predict

793
00:31:44,279 --> 00:31:47,840
what all those scooters are going to do

794
00:31:45,639 --> 00:31:50,480
as they going flying by you uh in the

795
00:31:47,840 --> 00:31:53,880
wrong lane but it's really being able to

796
00:31:50,480 --> 00:31:56,919
do reaction if you like to the

797
00:31:53,880 --> 00:31:59,639
system and then things like M Last Mile

798
00:31:56,919 --> 00:32:02,240
vehicle routing a great Logistics

799
00:31:59,639 --> 00:32:04,880
application an area I think has really

800
00:32:02,240 --> 00:32:08,000
primed for Major Impact is discovery of

801
00:32:04,880 --> 00:32:10,639
new things a young colleague in chemical

802
00:32:08,000 --> 00:32:13,880
engineering has built an AI system that

803
00:32:10,639 --> 00:32:16,480
comes up with new models for catalysis

804
00:32:13,880 --> 00:32:18,279
for building catalysts aimed at coming

805
00:32:16,480 --> 00:32:20,320
up with solutions that are more

806
00:32:18,279 --> 00:32:21,880
efficient less expensive and will

807
00:32:20,320 --> 00:32:24,600
produce good quality

808
00:32:21,880 --> 00:32:26,480
outputs design of new materials again

809
00:32:24,600 --> 00:32:28,760
colleagues have built a system that will

810
00:32:26,480 --> 00:32:31,080
Design or suggest Des designs for new

811
00:32:28,760 --> 00:32:32,639
materials an area of particular interest

812
00:32:31,080 --> 00:32:35,039
for us is things like concrete

813
00:32:32,639 --> 00:32:37,440
production where the system will will

814
00:32:35,039 --> 00:32:39,919
predict ways to come up with new

815
00:32:37,440 --> 00:32:42,639
mixtures with lower costs lower

816
00:32:39,919 --> 00:32:44,919
emissions but these are things creating

817
00:32:42,639 --> 00:32:44,919
new

818
00:32:45,240 --> 00:32:50,880
materials finance my colleagues will

819
00:32:48,399 --> 00:32:54,240
talk about this but studies on the

820
00:32:50,880 --> 00:32:55,519
economic impact of generative AI on jobs

821
00:32:54,240 --> 00:32:57,600
of the future there are a number of

822
00:32:55,519 --> 00:32:59,799
programs going on the one I will simply

823
00:32:57,600 --> 00:33:02,320
highight highlight is work of our most

824
00:32:59,799 --> 00:33:05,000
two recent Nobel Prize winners Deron

825
00:33:02,320 --> 00:33:06,799
asmu and Simon Johnson looking at the

826
00:33:05,000 --> 00:33:09,159
economic impact of what is going to

827
00:33:06,799 --> 00:33:11,639
happen to jobs as we think about AI

828
00:33:09,159 --> 00:33:14,120
there you can see a bottom example there

829
00:33:11,639 --> 00:33:15,600
as well there's a whole range of

830
00:33:14,120 --> 00:33:18,240
examples here of things that are going

831
00:33:15,600 --> 00:33:20,080
on again it is hard to find an area

832
00:33:18,240 --> 00:33:21,000
where there isn't some research going on

833
00:33:20,080 --> 00:33:23,480
at

834
00:33:21,000 --> 00:33:26,760
MIT and the way we think about it is

835
00:33:23,480 --> 00:33:31,960
that machine learning now is the third

836
00:33:26,760 --> 00:33:33,679
leg in the stool of scientific discovery

837
00:33:31,960 --> 00:33:35,200
a good researcher will in at least in

838
00:33:33,679 --> 00:33:37,519
science and engineering will use

839
00:33:35,200 --> 00:33:39,519
mathematics to do a formal model of

840
00:33:37,519 --> 00:33:41,639
something that will make predictions

841
00:33:39,519 --> 00:33:44,480
which they will then gather information

842
00:33:41,639 --> 00:33:46,720
on experiments that they do physically

843
00:33:44,480 --> 00:33:49,039
but they then use Ai and machine

844
00:33:46,720 --> 00:33:51,440
learning to add the computational

845
00:33:49,039 --> 00:33:53,799
component not just to do the analysis

846
00:33:51,440 --> 00:33:55,320
but also to do the simulations to look

847
00:33:53,799 --> 00:33:58,120
at other things that should be tested

848
00:33:55,320 --> 00:34:01,240
here and so we refer to our students in

849
00:33:58,120 --> 00:34:03,840
our faculty now as being computational

850
00:34:01,240 --> 00:34:06,080
bilinguals they speak the language of

851
00:34:03,840 --> 00:34:08,200
chemical engineering and the language of

852
00:34:06,080 --> 00:34:10,159
computation but these are the range of

853
00:34:08,200 --> 00:34:13,399
things that MIT is looking at and our

854
00:34:10,159 --> 00:34:14,760
goal going into the future is to embed

855
00:34:13,399 --> 00:34:17,399
that notion of machine learning

856
00:34:14,760 --> 00:34:19,520
throughout every department at The

857
00:34:17,399 --> 00:34:21,960
Institute it means we're going to hire

858
00:34:19,520 --> 00:34:24,040
new faculty members new kinds of Faculty

859
00:34:21,960 --> 00:34:26,599
members we need to break down

860
00:34:24,040 --> 00:34:28,639
disciplinary boundaries and of course we

861
00:34:26,599 --> 00:34:32,159
have to F sorry we have to face one of

862
00:34:28,639 --> 00:34:34,839
the challenges which is our data needs

863
00:34:32,159 --> 00:34:37,560
our data storage needs and our computing

864
00:34:34,839 --> 00:34:39,079
power needs are growing and we need to

865
00:34:37,560 --> 00:34:40,320
think about how we're going to address

866
00:34:39,079 --> 00:34:41,520
those things which we're actively

867
00:34:40,320 --> 00:34:43,879
working

868
00:34:41,520 --> 00:34:46,760
on I wanted to give you a sense of what

869
00:34:43,879 --> 00:34:48,960
AI thinks about AI sorry what MIT thinks

870
00:34:46,760 --> 00:34:51,919
about AI boy I need a better AI system

871
00:34:48,960 --> 00:34:54,839
here what MIT thinks about AI I wanted

872
00:34:51,919 --> 00:34:56,480
to give you that sense of not only the

873
00:34:54,839 --> 00:34:59,119
history of how we've dealt with it but

874
00:34:56,480 --> 00:35:02,280
especially how we see it moving into the

875
00:34:59,119 --> 00:35:05,760
future new discovery mechanisms New

876
00:35:02,280 --> 00:35:07,720
Management methods New Economic models

877
00:35:05,760 --> 00:35:10,760
but even in places that you wouldn't

878
00:35:07,720 --> 00:35:13,520
expect new planning for design of new

879
00:35:10,760 --> 00:35:16,560
planning of design for cities use of

880
00:35:13,520 --> 00:35:19,480
this in political science use of this in

881
00:35:16,560 --> 00:35:21,760
economics every part of MIT is now using

882
00:35:19,480 --> 00:35:24,040
AI in a different

883
00:35:21,760 --> 00:35:26,760
way before we go to questions I will

884
00:35:24,040 --> 00:35:29,640
simply say as somebody who started in

885
00:35:26,760 --> 00:35:32,040
this field 50 years ago it's been

886
00:35:29,640 --> 00:35:34,400
fascinating to see where it ended up I

887
00:35:32,040 --> 00:35:36,240
hope the next 50 years aren't quite as

888
00:35:34,400 --> 00:35:38,520
tumultuous but that they lead to

889
00:35:36,240 --> 00:35:41,240
something different but even though

890
00:35:38,520 --> 00:35:43,119
there were two AI Winters this one feels

891
00:35:41,240 --> 00:35:46,640
like it's here to stay and we need to

892
00:35:43,119 --> 00:35:48,440
adapt to it adjust to it and use it and

893
00:35:46,640 --> 00:35:50,280
with that um Quan I'm going to let you

894
00:35:48,440 --> 00:35:52,040
pick the questions I see people have um

895
00:35:50,280 --> 00:35:54,920
put things in here but

896
00:35:52,040 --> 00:35:59,000
um you want to where wherever qu is you

897
00:35:54,920 --> 00:35:59,000
want to pull one of them up for me

898
00:36:04,760 --> 00:36:09,560
ah there we go all

899
00:36:07,119 --> 00:36:11,440
right people talk about artificial

900
00:36:09,560 --> 00:36:13,800
general intelligence a lot can you

901
00:36:11,440 --> 00:36:16,599
explain it in plain English and how can

902
00:36:13,800 --> 00:36:18,599
this concept be applied in

903
00:36:16,599 --> 00:36:20,839
business I'm sorry I shouldn't smile

904
00:36:18,599 --> 00:36:22,560
answer to the first question

905
00:36:20,839 --> 00:36:24,920
no I'm

906
00:36:22,560 --> 00:36:28,160
joking the goal of people who are

907
00:36:24,920 --> 00:36:31,440
pushing AGI is to say can we build an AI

908
00:36:28,160 --> 00:36:34,160
system that really does behave the way

909
00:36:31,440 --> 00:36:36,800
we do it's not just built for a task but

910
00:36:34,160 --> 00:36:40,040
it is built to apply intelligence to

911
00:36:36,800 --> 00:36:43,079
anything um as I said

912
00:36:40,040 --> 00:36:44,680
earlier it's an area where to do that

913
00:36:43,079 --> 00:36:46,200
you need to capture Common Sense

914
00:36:44,680 --> 00:36:48,839
reasoning the kinds of things that a

915
00:36:46,200 --> 00:36:51,599
2-year-old knows and an AI system

916
00:36:48,839 --> 00:36:53,680
doesn't uh it's a wonderful goal to have

917
00:36:51,599 --> 00:36:56,960
I will show you my bias I think it's a

918
00:36:53,680 --> 00:36:58,280
long ways away um we'll get closer to it

919
00:36:56,960 --> 00:37:00,319
but I think we're likely to see

920
00:36:58,280 --> 00:37:03,079
successes in particular

921
00:37:00,319 --> 00:37:07,200
areas more more quickly than building a

922
00:37:03,079 --> 00:37:10,480
a a generative a general AI system um if

923
00:37:07,200 --> 00:37:13,200
you had it it'd be great because you

924
00:37:10,480 --> 00:37:16,839
could use one system to do marketing

925
00:37:13,200 --> 00:37:19,280
planning to do customer service to do um

926
00:37:16,839 --> 00:37:21,839
management of of of your finances all of

927
00:37:19,280 --> 00:37:23,480
those sorts of things but again I think

928
00:37:21,839 --> 00:37:26,400
it's much more likely that in the

929
00:37:23,480 --> 00:37:28,400
shorter term you're going to build a

930
00:37:26,400 --> 00:37:31,119
generative AI system for a particular

931
00:37:28,400 --> 00:37:32,400
application um but that's what it's

932
00:37:31,119 --> 00:37:34,640
about there are people who think it's

933
00:37:32,400 --> 00:37:40,400
going to happen I'm a little skeptical

934
00:37:34,640 --> 00:37:40,400
but I may be wrong all right come second

935
00:37:43,400 --> 00:37:48,680
question you're an optimistic group I

936
00:37:45,920 --> 00:37:48,680
like this

937
00:37:50,640 --> 00:37:55,880
um since history is often a predictor of

938
00:37:53,560 --> 00:37:59,920
the future I should be

939
00:37:55,880 --> 00:38:03,400
careful but I think as I said this wave

940
00:37:59,920 --> 00:38:05,359
feels much more real than the two

941
00:38:03,400 --> 00:38:08,960
previous waves in those AI Winters and

942
00:38:05,359 --> 00:38:12,560
why do I say that this wave is built on

943
00:38:08,960 --> 00:38:14,800
much more solid scientific Foundation it

944
00:38:12,560 --> 00:38:16,960
really is built on deep understanding of

945
00:38:14,800 --> 00:38:18,880
the mathematics is built on deep

946
00:38:16,960 --> 00:38:21,599
understanding of at least what we know

947
00:38:18,880 --> 00:38:23,839
about how people

948
00:38:21,599 --> 00:38:26,319
think and you can just see it in terms

949
00:38:23,839 --> 00:38:28,079
of the commercial impact I'm sure you're

950
00:38:26,319 --> 00:38:31,720
all affected in your own companies with

951
00:38:28,079 --> 00:38:34,720
this so will there be another AI winter

952
00:38:31,720 --> 00:38:36,760
possible could be affected by government

953
00:38:34,720 --> 00:38:39,359
agencies deciding not to provide funding

954
00:38:36,760 --> 00:38:41,119
for it um we've just had an interesting

955
00:38:39,359 --> 00:38:43,480
event in Washington yesterday and we'll

956
00:38:41,119 --> 00:38:46,319
see what happens in terms of funding

957
00:38:43,480 --> 00:38:49,280
there but I don't see this having an AI

958
00:38:46,319 --> 00:38:52,160
winter uh anytime really

959
00:38:49,280 --> 00:38:55,079
soon having said all of that as a quick

960
00:38:52,160 --> 00:38:57,000
comment I want to remind you that even

961
00:38:55,079 --> 00:39:00,520
though these current systems are built

962
00:38:57,000 --> 00:39:03,760
on a model of what we think goes on in

963
00:39:00,520 --> 00:39:05,880
the human brain it's not a perfect model

964
00:39:03,760 --> 00:39:07,400
and there may be Alternatives and I'll

965
00:39:05,880 --> 00:39:09,440
give you a very quick example comes from

966
00:39:07,400 --> 00:39:11,800
my college Josh tanom who raised this a

967
00:39:09,440 --> 00:39:13,880
really good point these systems are

968
00:39:11,800 --> 00:39:16,800
impressive but they need to be trained

969
00:39:13,880 --> 00:39:18,119
on hundreds of millions of examples in

970
00:39:16,800 --> 00:39:20,160
order to be

971
00:39:18,119 --> 00:39:21,880
effective for those of you who have

972
00:39:20,160 --> 00:39:22,960
young children or had young children

973
00:39:21,880 --> 00:39:25,960
think about a

974
00:39:22,960 --> 00:39:28,520
2-year-old you can show a 2-year-old a

975
00:39:25,960 --> 00:39:30,119
stack of blocks on a table

976
00:39:28,520 --> 00:39:33,520
and ask them what will happen if you hit

977
00:39:30,119 --> 00:39:35,040
the table and with good reasonable

978
00:39:33,520 --> 00:39:35,839
accuracy they'll be able to tell you

979
00:39:35,040 --> 00:39:39,560
what

980
00:39:35,839 --> 00:39:42,200
happens they don't have hundreds of

981
00:39:39,560 --> 00:39:44,079
millions of training examples but

982
00:39:42,200 --> 00:39:47,599
somehow they learn very quickly how to

983
00:39:44,079 --> 00:39:49,160
predict what happens in a setting and so

984
00:39:47,599 --> 00:39:52,200
there may be Alternatives that we see

985
00:39:49,160 --> 00:39:53,920
that change the path of AI but to the

986
00:39:52,200 --> 00:39:55,880
winter case I don't think it's coming

987
00:39:53,920 --> 00:39:59,680
soon or at least I hope it is

988
00:39:55,880 --> 00:39:59,680
not what's my next

989
00:40:06,040 --> 00:40:10,400
question I'd like to be able to catch a

990
00:40:08,839 --> 00:40:11,920
flight in a couple of days and still get

991
00:40:10,400 --> 00:40:13,520
back to the United States so I'm not

992
00:40:11,920 --> 00:40:16,480
certain how much I want to answer this

993
00:40:13,520 --> 00:40:18,640
question but it is it is a great

994
00:40:16,480 --> 00:40:20,880
question

995
00:40:18,640 --> 00:40:22,599
um let me answer it this way I'm not

996
00:40:20,880 --> 00:40:24,359
going to answer the particular one of is

997
00:40:22,599 --> 00:40:25,560
it a wise decision I'm sorry that just

998
00:40:24,359 --> 00:40:29,280
gets me in

999
00:40:25,560 --> 00:40:31,240
trouble but I do think think and I think

1000
00:40:29,280 --> 00:40:33,520
many companies certainly in the US have

1001
00:40:31,240 --> 00:40:36,800
taken a role in this that we need to

1002
00:40:33,520 --> 00:40:39,520
think about the regulatory issues of how

1003
00:40:36,800 --> 00:40:41,000
you use this where are the places where

1004
00:40:39,520 --> 00:40:42,440
you want guard rails where are the

1005
00:40:41,000 --> 00:40:45,280
places where you're happy to use this

1006
00:40:42,440 --> 00:40:48,000
what are the standards that a a product

1007
00:40:45,280 --> 00:40:51,480
should meet before you allow it to be

1008
00:40:48,000 --> 00:40:52,960
deployed in terms of use I will point to

1009
00:40:51,480 --> 00:40:54,800
the European Union which I think has

1010
00:40:52,960 --> 00:40:57,000
done a really interesting job of this

1011
00:40:54,800 --> 00:40:58,960
way you can quibble with pieces of it

1012
00:40:57,000 --> 00:41:01,160
but they've laid out an interesting

1013
00:40:58,960 --> 00:41:04,440
structure for how you think about the

1014
00:41:01,160 --> 00:41:05,720
regulatory issues here and so I don't

1015
00:41:04,440 --> 00:41:07,000
know whether let's say this way I don't

1016
00:41:05,720 --> 00:41:08,599
know if politics should have an

1017
00:41:07,000 --> 00:41:11,800
influence on this but government

1018
00:41:08,599 --> 00:41:13,680
agencies absolutely should have it but

1019
00:41:11,800 --> 00:41:15,520
working with the companies and I will

1020
00:41:13,680 --> 00:41:17,040
point to you in the US at least my

1021
00:41:15,520 --> 00:41:19,800
recollection my colleagues may be able

1022
00:41:17,040 --> 00:41:22,359
to correct me Microsoft took the lead in

1023
00:41:19,800 --> 00:41:24,880
creating a Consortium of other major US

1024
00:41:22,359 --> 00:41:28,240
companies to begin building a framework

1025
00:41:24,880 --> 00:41:31,079
for what was an ethical use of AI in

1026
00:41:28,240 --> 00:41:33,079
different areas not to maximize their

1027
00:41:31,079 --> 00:41:34,760
profit it would help but to actually

1028
00:41:33,079 --> 00:41:36,400
make sure that it was doing what it

1029
00:41:34,760 --> 00:41:38,720
should which is to protect people while

1030
00:41:36,400 --> 00:41:43,040
building them and so absolutely there

1031
00:41:38,720 --> 00:41:44,960
should be government role in regulatory

1032
00:41:43,040 --> 00:41:47,200
components politics is a little

1033
00:41:44,960 --> 00:41:48,680
different I'll stay away from that one

1034
00:41:47,200 --> 00:41:50,119
all right Quan pick me one that doesn't

1035
00:41:48,680 --> 00:41:52,680
get me in trouble when I try and get

1036
00:41:50,119 --> 00:41:52,680
back into the

1037
00:41:54,960 --> 00:42:00,880
US uh yes um I've heard Masa talk about

1038
00:42:02,160 --> 00:42:08,000
this it's an interesting question I I'll

1039
00:42:05,760 --> 00:42:10,960
um you know how realistic is it I'll do

1040
00:42:08,000 --> 00:42:15,400
it the following way a completely

1041
00:42:10,960 --> 00:42:16,520
General AI I think as I said unlikely in

1042
00:42:15,400 --> 00:42:19,680
10 years

1043
00:42:16,520 --> 00:42:23,880
time but in particular domains an AI

1044
00:42:19,680 --> 00:42:25,200
system that outperforms humans yeah I do

1045
00:42:23,880 --> 00:42:27,640
think it's possible you can already see

1046
00:42:25,200 --> 00:42:30,559
it in some places I'll give you two

1047
00:42:27,640 --> 00:42:31,760
examples just ones I happen to like

1048
00:42:30,559 --> 00:42:34,440
again I'll go back to that face

1049
00:42:31,760 --> 00:42:35,920
recognition system there are ethical

1050
00:42:34,440 --> 00:42:38,040
issues about how you use it that's a

1051
00:42:35,920 --> 00:42:40,400
separate issue but the ability of modern

1052
00:42:38,040 --> 00:42:43,079
face recognition systems it is better

1053
00:42:40,400 --> 00:42:45,160
than humans and it's something that

1054
00:42:43,079 --> 00:42:48,280
really is going to have an impact on

1055
00:42:45,160 --> 00:42:50,200
Safety and Security in in places when I

1056
00:42:48,280 --> 00:42:52,280
flew over here in order to aboard the

1057
00:42:50,200 --> 00:42:55,280
flight basically was using a face

1058
00:42:52,280 --> 00:42:57,640
recognition system the second example I

1059
00:42:55,280 --> 00:43:01,240
personally find impressive is some of

1060
00:42:57,640 --> 00:43:02,680
the autonomous Vehicle Systems and again

1061
00:43:01,240 --> 00:43:04,720
I'll point to mobile ey which I think

1062
00:43:02,680 --> 00:43:07,720
builds a great system I'm biased it's

1063
00:43:04,720 --> 00:43:10,000
the name MIT spin-off but I had the

1064
00:43:07,720 --> 00:43:12,000
pleasure of actually riding in a car

1065
00:43:10,000 --> 00:43:13,440
using that system there was a person

1066
00:43:12,000 --> 00:43:16,599
behind the wheel he never touched the

1067
00:43:13,440 --> 00:43:18,720
wheel uh in the streets of Jerusalem

1068
00:43:16,599 --> 00:43:21,480
lots of narrow places lots of people

1069
00:43:18,720 --> 00:43:24,480
walking across and it was impressive how

1070
00:43:21,480 --> 00:43:27,200
well that system navigated merged into

1071
00:43:24,480 --> 00:43:29,000
traffic um you know didn't use the the

1072
00:43:27,200 --> 00:43:31,480
horn anywhere to honk at anybody which

1073
00:43:29,000 --> 00:43:33,319
in Boston you would use regularly um

1074
00:43:31,480 --> 00:43:35,960
it's an example of something that is

1075
00:43:33,319 --> 00:43:38,000
better than a human and I use that

1076
00:43:35,960 --> 00:43:40,599
example because think about the impact

1077
00:43:38,000 --> 00:43:44,440
if that could actually be brought to

1078
00:43:40,599 --> 00:43:46,520
bear you reduce traffic fatalities

1079
00:43:44,440 --> 00:43:48,160
tremendously I forget the number but

1080
00:43:46,520 --> 00:43:50,359
it's like Millions a year around the

1081
00:43:48,160 --> 00:43:52,880
world you would reduce the cost of that

1082
00:43:50,359 --> 00:43:55,119
tremendously so those are places where I

1083
00:43:52,880 --> 00:43:57,760
think um it is realistic to the I don't

1084
00:43:55,119 --> 00:43:59,720
know if it's 10,000 times smarter but in

1085
00:43:57,760 --> 00:44:02,280
specific areas you will see things that

1086
00:43:59,720 --> 00:44:05,160
certainly outperform humans to our

1087
00:44:02,280 --> 00:44:07,839
benefit I think all right Quan I got

1088
00:44:05,160 --> 00:44:11,480
time I think for one more

1089
00:44:07,839 --> 00:44:13,599
question ah great

1090
00:44:11,480 --> 00:44:16,839
question

1091
00:44:13,599 --> 00:44:18,160
um I guess short answer is I think

1092
00:44:16,839 --> 00:44:21,079
that's a topic of a session this

1093
00:44:18,160 --> 00:44:23,119
afternoon but a slightly longer answer I

1094
00:44:21,079 --> 00:44:27,800
would say is

1095
00:44:23,119 --> 00:44:30,200
um there's no one solution to this

1096
00:44:27,800 --> 00:44:32,640
but our experience at MIT is that if you

1097
00:44:30,200 --> 00:44:36,800
find ways to

1098
00:44:32,640 --> 00:44:37,800
encourage students faculty to explore

1099
00:44:36,800 --> 00:44:40,680
new

1100
00:44:37,800 --> 00:44:42,599
ideas find ways to connect them up with

1101
00:44:40,680 --> 00:44:44,680
sources of funding and find ways to

1102
00:44:42,599 --> 00:44:48,280
connect them up with users in the real

1103
00:44:44,680 --> 00:44:51,079
world you lead to interesting things

1104
00:44:48,280 --> 00:44:52,880
that can happen so for Thailand that is

1105
00:44:51,079 --> 00:44:55,400
your choice but I hope that you will

1106
00:44:52,880 --> 00:44:57,960
work both with your local universities

1107
00:44:55,400 --> 00:45:00,880
but with institutions International

1108
00:44:57,960 --> 00:45:03,640
to identify places where you can have an

1109
00:45:00,880 --> 00:45:06,839
impact and to use it to actually then

1110
00:45:03,640 --> 00:45:09,119
collaborate in that way I'll give you

1111
00:45:06,839 --> 00:45:10,880
one small piece of advice like any piece

1112
00:45:09,119 --> 00:45:13,079
of advice is not worth very much but

1113
00:45:10,880 --> 00:45:16,599
I'll give you one small piece of

1114
00:45:13,079 --> 00:45:18,839
advice I know for my MIT

1115
00:45:16,599 --> 00:45:20,880
colleagues we get many requests to

1116
00:45:18,839 --> 00:45:23,079
collaborate we're always interested in

1117
00:45:20,880 --> 00:45:25,880
listening but often the really

1118
00:45:23,079 --> 00:45:28,880
interesting collaborations are when

1119
00:45:25,880 --> 00:45:31,280
there is something about local setting

1120
00:45:28,880 --> 00:45:33,359
that doesn't exist in Cambridge

1121
00:45:31,280 --> 00:45:35,280
Massachusetts and it will draw the

1122
00:45:33,359 --> 00:45:38,720
faculty member here because they're

1123
00:45:35,280 --> 00:45:40,720
really curious to explore it you will

1124
00:45:38,720 --> 00:45:42,319
know what those are that could be a

1125
00:45:40,720 --> 00:45:43,599
particular disease that could be an

1126
00:45:42,319 --> 00:45:45,400
opportunity to think about

1127
00:45:43,599 --> 00:45:47,400
transportation in a different way it

1128
00:45:45,400 --> 00:45:49,440
could be something else but to the

1129
00:45:47,400 --> 00:45:52,040
extent that you can find those

1130
00:45:49,440 --> 00:45:55,280
opportunities you will draw Talent from

1131
00:45:52,040 --> 00:45:57,640
around the world to come and work on

1132
00:45:55,280 --> 00:46:01,260
it with that

1133
00:45:57,640 --> 00:46:05,359
I have 22 seconds left thank you

1134
00:46:01,260 --> 00:46:05,359
[Applause]

1135
00:46:08,880 --> 00:46:12,280
[Music]


1
00:00:04,240 --> 00:00:12,320
Our next speaker is VJ Gapali. He is a

2
00:00:09,120 --> 00:00:14,480
senior staff member at MIT Lincoln

3
00:00:12,320 --> 00:00:16,000
Laboratory. So, let's give a warm

4
00:00:14,480 --> 00:00:18,400
welcome for VJ.

5
00:00:16,000 --> 00:00:20,320
>> Uh, it's a pleasure to be here today.

6
00:00:18,400 --> 00:00:22,000
So, I'm here. It's pretty funny because

7
00:00:20,320 --> 00:00:24,480
I've never used the title for this slide

8
00:00:22,000 --> 00:00:26,240
before and then I found it on the ILP

9
00:00:24,480 --> 00:00:27,760
website and then I said, you know what?

10
00:00:26,240 --> 00:00:29,519
Let's just run with it. It looks uh

11
00:00:27,760 --> 00:00:30,880
looks like a good title. So, it's the

12
00:00:29,519 --> 00:00:33,280
first time giving a talk with this

13
00:00:30,880 --> 00:00:34,960
title. Um, but it's actually very true,

14
00:00:33,280 --> 00:00:38,480
right? And so, a little bit about

15
00:00:34,960 --> 00:00:40,960
myself. Um, I've, uh, been at MIT for

16
00:00:38,480 --> 00:00:42,399
about 12 years now. Uh, and then over

17
00:00:40,960 --> 00:00:44,719
the past couple years, I've actually

18
00:00:42,399 --> 00:00:46,640
gone out and done few companies that are

19
00:00:44,719 --> 00:00:48,719
focused in this world of AI. And a lot

20
00:00:46,640 --> 00:00:51,120
of our research has been on how to make

21
00:00:48,719 --> 00:00:54,079
AI more efficient. And it essentially

22
00:00:51,120 --> 00:00:56,879
comes down to being able to orchestrate

23
00:00:54,079 --> 00:00:58,879
and schedule things more efficiently.

24
00:00:56,879 --> 00:01:01,520
And we can do so much more with what we

25
00:00:58,879 --> 00:01:04,320
have if we just do so carefully. And so

26
00:01:01,520 --> 00:01:07,119
this has clearly gotten a lot of

27
00:01:04,320 --> 00:01:09,680
attention these days of the power

28
00:01:07,119 --> 00:01:12,720
challenges that are associated with AI.

29
00:01:09,680 --> 00:01:15,200
Um we started a company about four years

30
00:01:12,720 --> 00:01:17,520
ago. This is like around COVID time when

31
00:01:15,200 --> 00:01:19,840
it was tough to get access to Nvidia

32
00:01:17,520 --> 00:01:21,600
GPUs. And what our company did was we

33
00:01:19,840 --> 00:01:23,360
were one of Nvidia's partners. And so we

34
00:01:21,600 --> 00:01:25,280
were able to get supply chain and we

35
00:01:23,360 --> 00:01:28,159
were essentially able to put a bunch of

36
00:01:25,280 --> 00:01:30,720
Nvidia GPUs onto the market. And at that

37
00:01:28,159 --> 00:01:32,479
time that was the big bottleneck for AI

38
00:01:30,720 --> 00:01:34,400
just you couldn't get enough processing.

39
00:01:32,479 --> 00:01:36,560
And now we're at the next phase of okay

40
00:01:34,400 --> 00:01:39,119
now we can get these processors but how

41
00:01:36,560 --> 00:01:41,680
do we actually secure the power uh in

42
00:01:39,119 --> 00:01:43,360
order to run these processors? And so

43
00:01:41,680 --> 00:01:45,600
you're starting to see this even in the

44
00:01:43,360 --> 00:01:48,079
industrial world where large some of the

45
00:01:45,600 --> 00:01:49,759
larger cloud providers are now moving a

46
00:01:48,079 --> 00:01:51,360
little left or right depending on which

47
00:01:49,759 --> 00:01:53,520
side you sit on but moving into the

48
00:01:51,360 --> 00:01:55,200
power side as well because we need to

49
00:01:53,520 --> 00:01:57,759
get that and this is a critical

50
00:01:55,200 --> 00:01:59,680
challenge not just for cloud providers

51
00:01:57,759 --> 00:02:01,680
but for really anyone and I think most

52
00:01:59,680 --> 00:02:03,360
of the speakers have already highlighted

53
00:02:01,680 --> 00:02:05,520
some of the very real challenges. It's

54
00:02:03,360 --> 00:02:08,399
not just AI computing but a whole bunch

55
00:02:05,520 --> 00:02:10,080
of other things that are coming in and I

56
00:02:08,399 --> 00:02:12,319
think we've we've probably seen some

57
00:02:10,080 --> 00:02:15,520
versions of these stats uh today itself

58
00:02:12,319 --> 00:02:18,160
but how quickly AI's energy use is using

59
00:02:15,520 --> 00:02:21,200
what the environmental impact of AI

60
00:02:18,160 --> 00:02:23,440
looks like and even just your small

61
00:02:21,200 --> 00:02:26,560
interactions with an AI system how much

62
00:02:23,440 --> 00:02:29,760
energy it can use

63
00:02:26,560 --> 00:02:32,000
but we often talk about AI and we focus

64
00:02:29,760 --> 00:02:32,959
on this training of large language

65
00:02:32,000 --> 00:02:36,239
models

66
00:02:32,959 --> 00:02:38,239
And as we've looked at the life cycle of

67
00:02:36,239 --> 00:02:40,800
these models, it turns out that a lot of

68
00:02:38,239 --> 00:02:43,120
the energy or the power that is being

69
00:02:40,800 --> 00:02:45,599
used or the energy is really going into

70
00:02:43,120 --> 00:02:47,360
the inference. The amount of people that

71
00:02:45,599 --> 00:02:49,360
are using these systems has scaled

72
00:02:47,360 --> 00:02:50,800
dramatically. I mean, you get it stuffed

73
00:02:49,360 --> 00:02:53,840
down your throat. Even if you don't want

74
00:02:50,800 --> 00:02:56,000
a genai answer, you get one. Um, and so

75
00:02:53,840 --> 00:02:58,800
if you look at the cost parody, about

76
00:02:56,000 --> 00:03:01,599
200 to 500 million inferences is roughly

77
00:02:58,800 --> 00:03:03,040
equivalent to a single training. And you

78
00:03:01,599 --> 00:03:05,519
know, you can think about just in a

79
00:03:03,040 --> 00:03:07,440
given day, you probably do hundreds of

80
00:03:05,519 --> 00:03:10,480
these inferences, just you individually

81
00:03:07,440 --> 00:03:12,560
and everyone else. And so, as we're kind

82
00:03:10,480 --> 00:03:14,560
of looking at these larger systems, it's

83
00:03:12,560 --> 00:03:16,159
really a delicate balancing act of how

84
00:03:14,560 --> 00:03:18,319
do we make sure that the power we're

85
00:03:16,159 --> 00:03:20,800
feeding into the system and the power

86
00:03:18,319 --> 00:03:24,159
that we're consuming across the system

87
00:03:20,800 --> 00:03:26,560
are um are being balanced out and are

88
00:03:24,159 --> 00:03:28,400
being used effectively with each other.

89
00:03:26,560 --> 00:03:31,040
So I don't know why this little symbol

90
00:03:28,400 --> 00:03:33,519
popped up already but uh there's really

91
00:03:31,040 --> 00:03:35,360
a few things that our group here at MIT

92
00:03:33,519 --> 00:03:37,680
and I wanted the last one is a company

93
00:03:35,360 --> 00:03:39,920
that we just started uh a few months ago

94
00:03:37,680 --> 00:03:42,080
in fact and wanted to talk about that.

95
00:03:39,920 --> 00:03:43,599
First is can we just reduce the overall

96
00:03:42,080 --> 00:03:47,040
computing? Right? In order to meet that

97
00:03:43,599 --> 00:03:48,959
balance between power demands and what

98
00:03:47,040 --> 00:03:51,440
we're generating, let's keep the what

99
00:03:48,959 --> 00:03:54,080
we're generating constant because in the

100
00:03:51,440 --> 00:03:55,920
last 10 years, we've only created as

101
00:03:54,080 --> 00:03:57,760
much new energy generation in the United

102
00:03:55,920 --> 00:03:59,200
States as what we're projecting data

103
00:03:57,760 --> 00:04:01,760
centers to use in the next couple of

104
00:03:59,200 --> 00:04:04,560
years. And so it's taken us about 10 to

105
00:04:01,760 --> 00:04:06,959
13 years to put new energy generation

106
00:04:04,560 --> 00:04:08,560
online. And by most of these growth

107
00:04:06,959 --> 00:04:10,080
projections on data centers, even

108
00:04:08,560 --> 00:04:13,120
picking, you know, one end of the

109
00:04:10,080 --> 00:04:15,120
Australia, as Elsa said, um we're still

110
00:04:13,120 --> 00:04:16,880
looking at having to increase the amount

111
00:04:15,120 --> 00:04:18,959
of power that's being used by these

112
00:04:16,880 --> 00:04:21,199
systems by nearly what we've done in

113
00:04:18,959 --> 00:04:23,520
about 10 years of energy uh generation

114
00:04:21,199 --> 00:04:25,040
in the US. So the first thing we can do

115
00:04:23,520 --> 00:04:27,360
is just reduce the overall amount of

116
00:04:25,040 --> 00:04:29,840
compute that's needed. That seems pretty

117
00:04:27,360 --> 00:04:32,080
obvious. Uh the second is to reduce the

118
00:04:29,840 --> 00:04:34,160
energy intensity of the computing we're

119
00:04:32,080 --> 00:04:36,800
doing. So, this is kind of like getting

120
00:04:34,160 --> 00:04:38,720
a car that's more fuel efficient. Can we

121
00:04:36,800 --> 00:04:41,120
travel further with that kilowatt hour

122
00:04:38,720 --> 00:04:43,199
of energy that we're using? Similar to

123
00:04:41,120 --> 00:04:45,520
can we travel farther with a gallon of

124
00:04:43,199 --> 00:04:48,000
gas that we're putting into our car. The

125
00:04:45,520 --> 00:04:50,560
next one is to use lower cost power. Uh

126
00:04:48,000 --> 00:04:54,000
this is really and cost here can mean

127
00:04:50,560 --> 00:04:55,600
many different things. If you are a

128
00:04:54,000 --> 00:04:57,600
person who's looking at the environment,

129
00:04:55,600 --> 00:04:59,919
lower cost could mean lower carbon

130
00:04:57,600 --> 00:05:02,960
power. If you're interested in just

131
00:04:59,919 --> 00:05:05,280
saving money, it could be cheaper power.

132
00:05:02,960 --> 00:05:08,320
Uh if you have other things, it could be

133
00:05:05,280 --> 00:05:10,960
lower water power. It's so opportunities

134
00:05:08,320 --> 00:05:12,400
are endless. And then the final one is I

135
00:05:10,960 --> 00:05:14,639
think one thing that we've really been

136
00:05:12,400 --> 00:05:17,360
looking at these days. Our systems are

137
00:05:14,639 --> 00:05:19,120
broken. They're siloed. We need some way

138
00:05:17,360 --> 00:05:20,639
to bring all the way from energy

139
00:05:19,120 --> 00:05:22,240
generation all the way to where it's

140
00:05:20,639 --> 00:05:23,919
being consumed. We need to bring these

141
00:05:22,240 --> 00:05:26,320
different pieces together. And that's

142
00:05:23,919 --> 00:05:29,520
really about optimizing energy systems,

143
00:05:26,320 --> 00:05:31,280
grid and data centers altogether.

144
00:05:29,520 --> 00:05:34,160
So I'm just going to give you a few

145
00:05:31,280 --> 00:05:35,440
snapshots. This is many many years of

146
00:05:34,160 --> 00:05:39,039
research and so I'm kind of like

147
00:05:35,440 --> 00:05:41,039
cherrypicking a few results um and a few

148
00:05:39,039 --> 00:05:42,639
aspects of the research. But if anyone's

149
00:05:41,039 --> 00:05:44,800
interested in this line of work, please

150
00:05:42,639 --> 00:05:47,039
feel free to reach out. We would love to

151
00:05:44,800 --> 00:05:50,639
love to find more partners. This is uh

152
00:05:47,039 --> 00:05:53,120
uh something that the more the marrier.

153
00:05:50,639 --> 00:05:56,240
So the first thing I talked about is

154
00:05:53,120 --> 00:05:59,360
reducing computing energy demands. Uh so

155
00:05:56,240 --> 00:06:02,320
this is a snapshot that we run an annual

156
00:05:59,360 --> 00:06:05,440
survey of AI accelerators and

157
00:06:02,320 --> 00:06:06,880
processors. This is a 2023 snapshot. A

158
00:06:05,440 --> 00:06:09,600
latest one was just released a couple

159
00:06:06,880 --> 00:06:12,319
weeks ago um at the le Hback. That was

160
00:06:09,600 --> 00:06:14,319
actually last week. Um and what we're

161
00:06:12,319 --> 00:06:17,039
doing is tracking essentially different

162
00:06:14,319 --> 00:06:19,919
hardware accelerators. So on the x-axis

163
00:06:17,039 --> 00:06:21,919
is see if this works. On the x- axis is

164
00:06:19,919 --> 00:06:24,240
peak power. So this is how much power

165
00:06:21,919 --> 00:06:27,120
that processor is using. And on the y

166
00:06:24,240 --> 00:06:29,199
ais is the peak performance. This is how

167
00:06:27,120 --> 00:06:31,199
many operations per watt can that

168
00:06:29,199 --> 00:06:33,919
processor have. And what we've seen is

169
00:06:31,199 --> 00:06:36,560
this cool uh trend over the past few

170
00:06:33,919 --> 00:06:38,639
years where if you looked at the 2019

171
00:06:36,560 --> 00:06:40,800
version of the survey, most of your

172
00:06:38,639 --> 00:06:44,240
processors were sitting at the one terop

173
00:06:40,800 --> 00:06:46,960
per watt line. So over here, wrong

174
00:06:44,240 --> 00:06:49,360
button. So right over there. And we've

175
00:06:46,960 --> 00:06:51,600
now seen a jump to about 10 terops per

176
00:06:49,360 --> 00:06:54,800
watt. So we're we've been able to get

177
00:06:51,600 --> 00:06:56,400
better hardware uh over the past four or

178
00:06:54,800 --> 00:06:58,319
five years. It's almost like Moore's

179
00:06:56,400 --> 00:07:01,520
law, but not really. Um because most of

180
00:06:58,319 --> 00:07:02,880
the tricks are on precision and uh you

181
00:07:01,520 --> 00:07:05,199
know different types of computing that

182
00:07:02,880 --> 00:07:06,560
we're now supporting. But nonetheless,

183
00:07:05,199 --> 00:07:08,720
right, so one of the things that you

184
00:07:06,560 --> 00:07:11,440
might be able to do is use some of this

185
00:07:08,720 --> 00:07:13,840
newer hardware. And so the challenge,

186
00:07:11,440 --> 00:07:16,160
however, is how do we actually schedule

187
00:07:13,840 --> 00:07:18,479
these different types of hardware? How

188
00:07:16,160 --> 00:07:22,080
do you select for a given operation

189
00:07:18,479 --> 00:07:25,680
whether you're going to use the Nvidias,

190
00:07:22,080 --> 00:07:27,520
the AMDs, the Cerebras, the Gros or

191
00:07:25,680 --> 00:07:30,160
maybe all of the above and how do you

192
00:07:27,520 --> 00:07:32,560
choose that given that you might keep uh

193
00:07:30,160 --> 00:07:33,919
changing things around. So this is some

194
00:07:32,560 --> 00:07:36,160
research that we've done where we've

195
00:07:33,919 --> 00:07:38,160
applied Beijian optimization to the

196
00:07:36,160 --> 00:07:40,479
problem. We've essentially defined a

197
00:07:38,160 --> 00:07:42,880
cost function that can find a hard

198
00:07:40,479 --> 00:07:44,639
optimal hardware configuration in order

199
00:07:42,880 --> 00:07:46,639
to meet some quality of service

200
00:07:44,639 --> 00:07:48,479
constraint that you might have. So it

201
00:07:46,639 --> 00:07:50,639
your quality of service constraint here

202
00:07:48,479 --> 00:07:54,000
could be you want to deliver this many

203
00:07:50,639 --> 00:07:56,400
tokens per second uh with a P99 latency

204
00:07:54,000 --> 00:07:58,720
of some number you know 100 milliseconds

205
00:07:56,400 --> 00:08:00,639
for example and what we can do is take

206
00:07:58,720 --> 00:08:03,520
that information we can take information

207
00:08:00,639 --> 00:08:05,599
about the AI hardware as well and then

208
00:08:03,520 --> 00:08:07,599
find a dynamic pool or an optimal

209
00:08:05,599 --> 00:08:10,000
configuration of hardware that can

210
00:08:07,599 --> 00:08:13,199
minimize cost and we've applied this for

211
00:08:10,000 --> 00:08:15,759
example to AWS and Azure where we can

212
00:08:13,199 --> 00:08:17,440
then lower your cloud bills without viol

213
00:08:15,759 --> 00:08:19,599
violating your quality of service

214
00:08:17,440 --> 00:08:21,039
constraints that you have. And this has

215
00:08:19,599 --> 00:08:24,080
been something that's really exciting.

216
00:08:21,039 --> 00:08:26,720
Uh has huge opportunities from energy

217
00:08:24,080 --> 00:08:29,440
reduction to power redu to power

218
00:08:26,720 --> 00:08:31,120
reduction uh carbon reduction and even

219
00:08:29,440 --> 00:08:33,039
cost reduction depending on which way

220
00:08:31,120 --> 00:08:35,039
you're looking at this. So here's just

221
00:08:33,039 --> 00:08:36,959
uh some highlights of these results and

222
00:08:35,039 --> 00:08:38,240
written a number of papers about this

223
00:08:36,959 --> 00:08:42,159
topic if you're interested in learning

224
00:08:38,240 --> 00:08:44,159
more um of applying this towards a uh

225
00:08:42,159 --> 00:08:45,680
recommener model. So a system like what

226
00:08:44,159 --> 00:08:47,360
you would find you know you like these

227
00:08:45,680 --> 00:08:49,440
shoes you might look at shoelaces as

228
00:08:47,360 --> 00:08:50,720
well. uh and we've applied these to a

229
00:08:49,440 --> 00:08:52,880
number of different types of models and

230
00:08:50,720 --> 00:08:56,080
you can see that very often just by

231
00:08:52,880 --> 00:08:58,959
applying this technique um if we want to

232
00:08:56,080 --> 00:09:01,040
maintain the 99th percentile uh we can

233
00:08:58,959 --> 00:09:02,399
still see reductions about 10 to 20% and

234
00:09:01,040 --> 00:09:05,200
if we're willing to adjust our

235
00:09:02,399 --> 00:09:07,120
constraints ever so slightly we can jump

236
00:09:05,200 --> 00:09:08,880
up in terms of the cost savings and here

237
00:09:07,120 --> 00:09:11,519
it's dollars and cents that we're saving

238
00:09:08,880 --> 00:09:14,320
you by nearly 30% just by using this

239
00:09:11,519 --> 00:09:17,120
optimization engine in the middle so the

240
00:09:14,320 --> 00:09:20,880
next thing I want to talk about is how

241
00:09:17,120 --> 00:09:22,560
we can introduce the energy intensity of

242
00:09:20,880 --> 00:09:25,120
computing. And I'm just going to give

243
00:09:22,560 --> 00:09:27,600
you one really uh quick highlight about

244
00:09:25,120 --> 00:09:29,200
this um because it's it's so simple that

245
00:09:27,600 --> 00:09:33,600
it really doesn't need much time to

246
00:09:29,200 --> 00:09:35,279
explain how to do it. Uh we about uh 5

247
00:09:33,600 --> 00:09:37,680
years ago were running into a challenge

248
00:09:35,279 --> 00:09:39,120
with our data center uh and our so we

249
00:09:37,680 --> 00:09:41,120
have a data center that's based out in

250
00:09:39,120 --> 00:09:42,880
Holio, Massachusetts, which is about 100

251
00:09:41,120 --> 00:09:45,360
miles west of here next to a

252
00:09:42,880 --> 00:09:47,519
hydroelectric dam. And so we ran into a

253
00:09:45,360 --> 00:09:50,800
problem of our data center starting to

254
00:09:47,519 --> 00:09:52,560
heat up and we weren't really sure like

255
00:09:50,800 --> 00:09:54,880
how to avoid that apart from turning

256
00:09:52,560 --> 00:09:56,480
things off and you know the MIT

257
00:09:54,880 --> 00:09:58,240
community loves to compute. So turning

258
00:09:56,480 --> 00:09:59,600
it off is not really an option. So we're

259
00:09:58,240 --> 00:10:02,240
really thinking about well what else can

260
00:09:59,600 --> 00:10:04,080
we do to keep these systems running and

261
00:10:02,240 --> 00:10:06,240
so one of uh one of my colleagues who's

262
00:10:04,080 --> 00:10:08,880
an avid gamer just bought one of these.

263
00:10:06,240 --> 00:10:11,040
How many people here are gamers before I

264
00:10:08,880 --> 00:10:14,320
make fun of gamers?

265
00:10:11,040 --> 00:10:18,640
I suck at games. Um but he bought this

266
00:10:14,320 --> 00:10:20,240
like crazy rig. It was a um GPU. He had

267
00:10:18,640 --> 00:10:22,560
water cooling like on this system at

268
00:10:20,240 --> 00:10:24,240
home and you know he started to play

269
00:10:22,560 --> 00:10:25,360
this and he was like I don't know

270
00:10:24,240 --> 00:10:28,160
somebody correct me if I'm wrong but it

271
00:10:25,360 --> 00:10:29,760
was like going at 130 frames per second

272
00:10:28,160 --> 00:10:31,600
and I started to ask him like can you

273
00:10:29,760 --> 00:10:33,600
actually see that or can do you know

274
00:10:31,600 --> 00:10:35,040
what's going on? He's like what's the

275
00:10:33,600 --> 00:10:36,320
frames per second that you you can

276
00:10:35,040 --> 00:10:39,279
perceive? And it was something like 90

277
00:10:36,320 --> 00:10:41,040
or 100. And so like any good scientist,

278
00:10:39,279 --> 00:10:43,680
he comes back the next day, he's drawn a

279
00:10:41,040 --> 00:10:45,200
plot with uh power versus frames per

280
00:10:43,680 --> 00:10:46,800
second. And we found that you can reduce

281
00:10:45,200 --> 00:10:49,200
the amount of power to that GPU. That

282
00:10:46,800 --> 00:10:51,920
was an ampier class at the time. Uh you

283
00:10:49,200 --> 00:10:54,800
can reduce the amount of power by about,

284
00:10:51,920 --> 00:10:56,880
you know, 20% 30% reduction to the power

285
00:10:54,800 --> 00:10:59,760
and still have a frames per second that

286
00:10:56,880 --> 00:11:02,000
is visually looks the exact same to you

287
00:10:59,760 --> 00:11:04,000
or me. And then we said, gee, I wonder

288
00:11:02,000 --> 00:11:05,440
if we can apply that to AI. And so we

289
00:11:04,000 --> 00:11:06,880
did. And so we applied that to our

290
00:11:05,440 --> 00:11:09,040
supercomputer that's running out in

291
00:11:06,880 --> 00:11:10,800
Holio and we have been applying this for

292
00:11:09,040 --> 00:11:12,160
the last couple of years and we have

293
00:11:10,800 --> 00:11:13,839
seen some really really interesting

294
00:11:12,160 --> 00:11:15,440
results. So the idea here there's a

295
00:11:13,839 --> 00:11:17,600
simple setting that you can change where

296
00:11:15,440 --> 00:11:19,040
it says how much power you can just

297
00:11:17,600 --> 00:11:21,519
limit it to some percentage of the

298
00:11:19,040 --> 00:11:24,160
total. We found that you know about 80%

299
00:11:21,519 --> 00:11:27,200
of the max capacity seems to be a good

300
00:11:24,160 --> 00:11:28,800
number. And we've applied this uh across

301
00:11:27,200 --> 00:11:32,079
and it turns out that that one little

302
00:11:28,800 --> 00:11:33,920
change was able to reduce the uh amount

303
00:11:32,079 --> 00:11:36,480
of energy that our data center uses by

304
00:11:33,920 --> 00:11:38,079
somewhere between about 10 to 30%. And

305
00:11:36,480 --> 00:11:40,480
the most exciting part of this and

306
00:11:38,079 --> 00:11:41,920
coming back to the previous talk was a

307
00:11:40,480 --> 00:11:43,920
reduction in the operating temperature

308
00:11:41,920 --> 00:11:46,399
of our GPUs. So we were able to actually

309
00:11:43,920 --> 00:11:48,160
over a year long we saw about a 30 to

310
00:11:46,399 --> 00:11:50,399
40Â° Fahrenheit reduction in the

311
00:11:48,160 --> 00:11:52,560
operating temperature of the GPUs which

312
00:11:50,399 --> 00:11:54,320
means less cooling intensity less

313
00:11:52,560 --> 00:11:57,040
cooling needs and greater hardware

314
00:11:54,320 --> 00:11:59,200
reliability all while saving you money.

315
00:11:57,040 --> 00:12:01,760
So come on right why aren't you doing

316
00:11:59,200 --> 00:12:04,160
this already? Um, it turns out though

317
00:12:01,760 --> 00:12:06,560
nowadays you can get this uh and in fact

318
00:12:04,160 --> 00:12:08,720
as you're buying if you buy some of

319
00:12:06,560 --> 00:12:11,760
these high-end Dell boxes that are out

320
00:12:08,720 --> 00:12:16,160
there, these XC9680s, these have 8way

321
00:12:11,760 --> 00:12:19,519
H100 or B200 or 300 uh processors. They

322
00:12:16,160 --> 00:12:20,720
now power cap by default and I was all

323
00:12:19,519 --> 00:12:22,079
excited because I thought they cared

324
00:12:20,720 --> 00:12:24,399
about the environment and I think they

325
00:12:22,079 --> 00:12:25,600
do, right? uh to be clear, but it also

326
00:12:24,399 --> 00:12:27,519
turns out because of the hardware

327
00:12:25,600 --> 00:12:29,760
reliability aspect of this means less

328
00:12:27,519 --> 00:12:31,760
warranty calls, you're generating a lot

329
00:12:29,760 --> 00:12:33,920
of heat in an 11U box of a computer. And

330
00:12:31,760 --> 00:12:35,519
so this power capping is now kind of

331
00:12:33,920 --> 00:12:37,360
making its way across and we're finding

332
00:12:35,519 --> 00:12:40,079
a lot more people actually using this

333
00:12:37,360 --> 00:12:43,519
technique uh in order to maintain better

334
00:12:40,079 --> 00:12:45,360
operating temperatures.

335
00:12:43,519 --> 00:12:48,160
So the next one is what I call using

336
00:12:45,360 --> 00:12:50,560
lower cost power. And for those of you

337
00:12:48,160 --> 00:12:52,959
who look at energy systems, who use

338
00:12:50,560 --> 00:12:54,639
energy systems, there is a wide variety

339
00:12:52,959 --> 00:12:57,200
in cost. And you'll see I'm using the

340
00:12:54,639 --> 00:12:59,040
word just cost, it can mean anything. If

341
00:12:57,200 --> 00:13:01,360
you look at carbon emissions, you can

342
00:12:59,040 --> 00:13:04,079
see swings within just a given day, the

343
00:13:01,360 --> 00:13:05,600
carbon intensity swinging by 30 to 40%.

344
00:13:04,079 --> 00:13:07,920
Your time of if you're looking at demand

345
00:13:05,600 --> 00:13:10,959
response or time of use pricing, again,

346
00:13:07,920 --> 00:13:14,079
huge variations in the cost. and why are

347
00:13:10,959 --> 00:13:15,760
we then creating our AI systems to not

348
00:13:14,079 --> 00:13:18,079
care about this or not pay attention to

349
00:13:15,760 --> 00:13:20,639
this. So this is a research area that we

350
00:13:18,079 --> 00:13:22,959
kind of think about which is bringing

351
00:13:20,639 --> 00:13:25,200
the environment into software systems

352
00:13:22,959 --> 00:13:26,560
and I think this in my opinion is

353
00:13:25,200 --> 00:13:28,880
probably one of the most exciting

354
00:13:26,560 --> 00:13:31,760
directions for people to be looking at.

355
00:13:28,880 --> 00:13:33,600
Our AI systems today act the same

356
00:13:31,760 --> 00:13:36,240
whether it's hot or cold outside whether

357
00:13:33,600 --> 00:13:38,800
it's sunny or it's dark or whether it's

358
00:13:36,240 --> 00:13:41,200
windy or it's not.

359
00:13:38,800 --> 00:13:43,200
Why? Right, our AI systems, they are now

360
00:13:41,200 --> 00:13:46,240
becoming such large users of power and

361
00:13:43,200 --> 00:13:49,519
energy. Need to start being aware of the

362
00:13:46,240 --> 00:13:51,200
environment around them. My car has more

363
00:13:49,519 --> 00:13:53,440
connection with the environment at this

364
00:13:51,200 --> 00:13:54,800
point than these large AI systems do.

365
00:13:53,440 --> 00:13:57,440
Even though the power of these things

366
00:13:54,800 --> 00:13:59,760
are quite large and so we started to

367
00:13:57,440 --> 00:14:01,600
think about what would that mean, right?

368
00:13:59,760 --> 00:14:03,279
What are some easy ways to incorporate

369
00:14:01,600 --> 00:14:05,839
the environment and make our software

370
00:14:03,279 --> 00:14:08,560
more environmentally aware? And so one

371
00:14:05,839 --> 00:14:10,399
of the uh aspects is bringing in signals

372
00:14:08,560 --> 00:14:13,120
from the environment into the way that

373
00:14:10,399 --> 00:14:14,720
the software program actually operates.

374
00:14:13,120 --> 00:14:16,560
And we've applied this to a number of

375
00:14:14,720 --> 00:14:18,399
different AI problems. One being

376
00:14:16,560 --> 00:14:20,959
computer vision where in the case of a

377
00:14:18,399 --> 00:14:23,440
computer vision algorithm if it's highly

378
00:14:20,959 --> 00:14:26,480
carbon intense or very expensive power

379
00:14:23,440 --> 00:14:28,160
outside we can use a smaller model for a

380
00:14:26,480 --> 00:14:30,240
small period of time and maybe switch

381
00:14:28,160 --> 00:14:33,360
back to the larger model for the other

382
00:14:30,240 --> 00:14:35,199
times on in the world of generative AI.

383
00:14:33,360 --> 00:14:38,160
Maybe we just give shorter answers

384
00:14:35,199 --> 00:14:39,839
during times of peak intensity and kind

385
00:14:38,160 --> 00:14:42,079
of give unconstrained answers during

386
00:14:39,839 --> 00:14:44,399
other times. And it sounds really really

387
00:14:42,079 --> 00:14:47,040
simple and it turns out it's extremely

388
00:14:44,399 --> 00:14:49,360
effective. uh in the world for the

389
00:14:47,040 --> 00:14:53,120
computer vision algorithm that I just

390
00:14:49,360 --> 00:14:55,279
mentioned uh we had looked at applying

391
00:14:53,120 --> 00:14:57,839
uh this technique right so here we were

392
00:14:55,279 --> 00:15:00,880
using different models of yolo which is

393
00:14:57,839 --> 00:15:03,519
a computer vision algorithm

394
00:15:00,880 --> 00:15:05,279
uh applying this over a 48 hour period

395
00:15:03,519 --> 00:15:08,000
we saw a reduction of carbon emissions

396
00:15:05,279 --> 00:15:11,120
by nearly 80% with a reduction of just

397
00:15:08,000 --> 00:15:12,800
about 2 to 3% in the overall accuracy

398
00:15:11,120 --> 00:15:15,760
when compared to sort of the the

399
00:15:12,800 --> 00:15:17,519
non-normalized system and and as I

400
00:15:15,760 --> 00:15:20,959
mentioned we did the same thing and we

401
00:15:17,519 --> 00:15:23,440
applied it towards uh generative AI

402
00:15:20,959 --> 00:15:25,360
problems and here again instead of

403
00:15:23,440 --> 00:15:26,800
giving unconstrained answers we gave

404
00:15:25,360 --> 00:15:29,760
what's called the generation directive

405
00:15:26,800 --> 00:15:30,959
saying keep it short or let it go and

406
00:15:29,760 --> 00:15:33,040
the results here were even more

407
00:15:30,959 --> 00:15:36,000
promising what we found is that we were

408
00:15:33,040 --> 00:15:38,639
able to reduce carbon emissions by 70%

409
00:15:36,000 --> 00:15:41,680
and the answer quality actually was

410
00:15:38,639 --> 00:15:43,760
almost unchanged uh because a short

411
00:15:41,680 --> 00:15:45,440
answer is not wrong a short answer could

412
00:15:43,760 --> 00:15:47,519
just be better. And so we're working

413
00:15:45,440 --> 00:15:50,639
with some companies to make this. Now,

414
00:15:47,519 --> 00:15:54,079
if you How many people here like use

415
00:15:50,639 --> 00:15:55,920
OpenAI's API or Claude's API? Anyone

416
00:15:54,079 --> 00:15:57,519
here? A couple of people. You pay per

417
00:15:55,920 --> 00:15:59,360
token. And so, if we can give you

418
00:15:57,519 --> 00:16:01,199
shorter answers, it also means that your

419
00:15:59,360 --> 00:16:02,480
token rate goes down. So, we're working

420
00:16:01,199 --> 00:16:04,639
with a few companies that want to

421
00:16:02,480 --> 00:16:06,720
incorporate this into their uh system to

422
00:16:04,639 --> 00:16:08,560
almost give a short answer first and

423
00:16:06,720 --> 00:16:10,560
then let people ask for longer answers

424
00:16:08,560 --> 00:16:12,399
afterwards. And then if you can do so

425
00:16:10,560 --> 00:16:14,560
somewhat strategically, you can actually

426
00:16:12,399 --> 00:16:16,800
apply these during types of during times

427
00:16:14,560 --> 00:16:19,519
of peak demand. Uh and then so there's a

428
00:16:16,800 --> 00:16:22,480
really nice cost as well as uh

429
00:16:19,519 --> 00:16:24,079
environmental aspect to this. So this is

430
00:16:22,480 --> 00:16:25,920
sort of just one example of you know

431
00:16:24,079 --> 00:16:28,320
ways to make your software systems

432
00:16:25,920 --> 00:16:29,759
themselves more environmentally aware.

433
00:16:28,320 --> 00:16:31,759
And I'm hoping that we see more

434
00:16:29,759 --> 00:16:33,600
companies starting to do this. Although

435
00:16:31,759 --> 00:16:35,440
it's always seems to be an uphill battle

436
00:16:33,600 --> 00:16:38,399
with getting people to even give

437
00:16:35,440 --> 00:16:40,560
rudimentary uh information about what's

438
00:16:38,399 --> 00:16:42,959
going on in their systems. But we'd love

439
00:16:40,560 --> 00:16:44,959
to get these type of tools and see more

440
00:16:42,959 --> 00:16:46,880
people building tools like this cuz I

441
00:16:44,959 --> 00:16:48,320
think you know I think most of the

442
00:16:46,880 --> 00:16:49,839
speakers have highlighted this AI

443
00:16:48,320 --> 00:16:51,839
systems are no longer just a side

444
00:16:49,839 --> 00:16:53,600
project that's just happening somewhere.

445
00:16:51,839 --> 00:16:56,079
uh but this is now a a part of that

446
00:16:53,600 --> 00:16:58,160
we're planning grid capacity because of

447
00:16:56,079 --> 00:16:59,600
AI doesn't you know shouldn't it kind of

448
00:16:58,160 --> 00:17:01,440
happen the other way around where AI

449
00:16:59,600 --> 00:17:05,120
should also be modifying itself based on

450
00:17:01,440 --> 00:17:07,199
energy and power needs

451
00:17:05,120 --> 00:17:10,319
so the last one I wanted to highlight

452
00:17:07,199 --> 00:17:12,400
this is uh relatively new uh and this is

453
00:17:10,319 --> 00:17:15,280
a company that we started recently

454
00:17:12,400 --> 00:17:18,640
called BayMP compute uh which is focused

455
00:17:15,280 --> 00:17:20,480
on that joint optimization as we kind of

456
00:17:18,640 --> 00:17:21,360
walk through you know how energy is

457
00:17:20,480 --> 00:17:23,760
created

458
00:17:21,360 --> 00:17:25,360
all the way to where it's being used.

459
00:17:23,760 --> 00:17:26,720
They're all different silos and

460
00:17:25,360 --> 00:17:27,919
different organizations that run these

461
00:17:26,720 --> 00:17:29,360
things. And because of that, there's a

462
00:17:27,919 --> 00:17:30,799
lot of inefficiencies that come along

463
00:17:29,360 --> 00:17:33,200
the way, right? Everyone's kind of doing

464
00:17:30,799 --> 00:17:34,880
their part within the silo, but it's the

465
00:17:33,200 --> 00:17:37,360
connections between the silos that are

466
00:17:34,880 --> 00:17:39,039
that are often a challenge. And the one

467
00:17:37,360 --> 00:17:40,799
place where this all meets, where the

468
00:17:39,039 --> 00:17:41,919
computing meets the power, which is in

469
00:17:40,799 --> 00:17:44,080
the data center, is actually one of

470
00:17:41,919 --> 00:17:45,280
those areas that hasn't been studied

471
00:17:44,080 --> 00:17:47,120
that much, right? I think there's some

472
00:17:45,280 --> 00:17:48,799
lots of really like a lot of the talks

473
00:17:47,120 --> 00:17:50,559
today talked about various components

474
00:17:48,799 --> 00:17:52,559
that can go into the data center. the

475
00:17:50,559 --> 00:17:55,600
actual operation of the data center is

476
00:17:52,559 --> 00:17:58,080
something that's often looked past or,

477
00:17:55,600 --> 00:17:59,440
you know, not really concentrated on.

478
00:17:58,080 --> 00:18:01,200
And so I like to think about this. This

479
00:17:59,440 --> 00:18:02,960
was data centers up to about a couple of

480
00:18:01,200 --> 00:18:04,720
years ago. You had a nice lemon tree,

481
00:18:02,960 --> 00:18:07,360
had a lot of lemons in it, put a

482
00:18:04,720 --> 00:18:10,000
lemonade stand under it. Cool, right?

483
00:18:07,360 --> 00:18:12,640
You can just make lemons and keep moving

484
00:18:10,000 --> 00:18:14,320
on. And where we are as of the past

485
00:18:12,640 --> 00:18:15,919
couple of years is a bunch of people

486
00:18:14,320 --> 00:18:17,840
took that same lemon tree, but then they

487
00:18:15,919 --> 00:18:19,760
put four stands under it. And so there's

488
00:18:17,840 --> 00:18:21,200
a little bit of competition for these

489
00:18:19,760 --> 00:18:23,440
lemons and you have to either squeeze

490
00:18:21,200 --> 00:18:24,880
that lemon harder or you have to try to

491
00:18:23,440 --> 00:18:26,960
plant another tree which is going to

492
00:18:24,880 --> 00:18:28,720
take years for lemons to start coming

493
00:18:26,960 --> 00:18:30,080
out of that tree. I don't have a green

494
00:18:28,720 --> 00:18:32,160
thumb but I'm assuming it takes a couple

495
00:18:30,080 --> 00:18:35,039
years for lemon trees to take off.

496
00:18:32,160 --> 00:18:36,559
Anyone can correct me please. And so

497
00:18:35,039 --> 00:18:39,200
this is sort of a trend that we're

498
00:18:36,559 --> 00:18:41,840
seeing across the world. It's not just

499
00:18:39,200 --> 00:18:43,600
in the US. US data center vacancy rates

500
00:18:41,840 --> 00:18:46,400
are under 1% in some of the hotter

501
00:18:43,600 --> 00:18:48,559
markets. And so people are, you know,

502
00:18:46,400 --> 00:18:50,720
skipping the line by creating, you know,

503
00:18:48,559 --> 00:18:52,559
off-grid data centers, but that has a

504
00:18:50,720 --> 00:18:54,160
scalability problem. Also has a huge

505
00:18:52,559 --> 00:18:56,320
sustainability problem because the only

506
00:18:54,160 --> 00:18:58,080
fuel source you can put online that

507
00:18:56,320 --> 00:18:59,840
large and that quickly tends to be

508
00:18:58,080 --> 00:19:02,320
fossil fuel-based. And so you're looking

509
00:18:59,840 --> 00:19:05,039
at Abalene, Louisiana

510
00:19:02,320 --> 00:19:08,160
um and and many other places that are

511
00:19:05,039 --> 00:19:10,160
coming up with these uh and you know

512
00:19:08,160 --> 00:19:13,120
Tennessee most recently that are coming

513
00:19:10,160 --> 00:19:15,679
up with these huge natural gasbased

514
00:19:13,120 --> 00:19:17,600
uh data centers and these are hundreds

515
00:19:15,679 --> 00:19:19,440
of megawws trying to go up to a

516
00:19:17,600 --> 00:19:22,720
gigawatt. So the amount of power that

517
00:19:19,440 --> 00:19:26,240
these things are using are quite large

518
00:19:22,720 --> 00:19:29,200
and even in terms of the market needs

519
00:19:26,240 --> 00:19:31,679
right there's about over a4 trillion

520
00:19:29,200 --> 00:19:34,720
dollars in data center spend and that's

521
00:19:31,679 --> 00:19:38,400
growing quickly. Um if you're trying to

522
00:19:34,720 --> 00:19:40,080
connect a new power source to the grid

523
00:19:38,400 --> 00:19:41,840
it takes over six years. So it's like

524
00:19:40,080 --> 00:19:43,760
the idea of planting a lemon tree in

525
00:19:41,840 --> 00:19:45,840
order to get more lemons to create

526
00:19:43,760 --> 00:19:47,200
another lemonade stand. That's a long

527
00:19:45,840 --> 00:19:48,960
process. And we're looking at, you know,

528
00:19:47,200 --> 00:19:52,000
and I know almost every speaker has had

529
00:19:48,960 --> 00:19:54,240
a version of this plot over here. Uh oh,

530
00:19:52,000 --> 00:19:55,840
it shows up over there. Nice. Um these

531
00:19:54,240 --> 00:19:57,600
changes are occurring in the next 2 to 3

532
00:19:55,840 --> 00:19:59,120
years. So planting a lemon tree is not

533
00:19:57,600 --> 00:20:01,760
going to work all that well for the next

534
00:19:59,120 --> 00:20:04,160
few years. And with all these vacancy

535
00:20:01,760 --> 00:20:07,760
rates uh where they are, it's becoming

536
00:20:04,160 --> 00:20:10,559
uh very difficult to to use it. But even

537
00:20:07,760 --> 00:20:12,400
when you go inside a data center, it's

538
00:20:10,559 --> 00:20:15,120
not like all that power is just feeding

539
00:20:12,400 --> 00:20:16,799
AI, right? The power is going to a bunch

540
00:20:15,120 --> 00:20:19,200
of different things. And so you're

541
00:20:16,799 --> 00:20:21,919
wasting, not wasting, but you're using a

542
00:20:19,200 --> 00:20:25,440
lot of power on systems that don't

543
00:20:21,919 --> 00:20:28,240
necessarily adapt to workloads. And

544
00:20:25,440 --> 00:20:30,159
we've designed our data centers to

545
00:20:28,240 --> 00:20:31,520
really satisfy peak demand. And we're

546
00:20:30,159 --> 00:20:32,799
not really looking at average demand.

547
00:20:31,520 --> 00:20:34,320
It's like, you know, if you have a 100

548
00:20:32,799 --> 00:20:36,240
amp breaker at your house, you've

549
00:20:34,320 --> 00:20:38,080
designed your entire, you know, you try

550
00:20:36,240 --> 00:20:40,480
not to charge your two electric cars

551
00:20:38,080 --> 00:20:42,960
plus run your dryer plus put your oven

552
00:20:40,480 --> 00:20:44,960
on and the stove all at one time. That's

553
00:20:42,960 --> 00:20:46,559
what our data centers are doing today.

554
00:20:44,960 --> 00:20:48,480
they are putting everything on at the

555
00:20:46,559 --> 00:20:50,480
same time like a gee I don't have power

556
00:20:48,480 --> 00:20:52,320
well what if you tried to orchestrate or

557
00:20:50,480 --> 00:20:53,520
move some of these things around and so

558
00:20:52,320 --> 00:20:55,919
that's what our company is really

559
00:20:53,520 --> 00:20:59,600
focused on is using machine learning and

560
00:20:55,919 --> 00:21:00,960
AI in order to help balance what power

561
00:20:59,600 --> 00:21:02,799
is coming in with the power that's

562
00:21:00,960 --> 00:21:04,559
coming out and it turns out there's a

563
00:21:02,799 --> 00:21:08,000
lot of levers that we can adjust within

564
00:21:04,559 --> 00:21:10,799
a data center uh that will give us the

565
00:21:08,000 --> 00:21:12,559
opportunity to um really kind of make

566
00:21:10,799 --> 00:21:14,960
that balance happen right so in your

567
00:21:12,559 --> 00:21:16,880
house you might maybe run the electric

568
00:21:14,960 --> 00:21:19,679
car charging in the night. Uh maybe

569
00:21:16,880 --> 00:21:21,039
you'll schedule the uh dryer to run at

570
00:21:19,679 --> 00:21:22,320
some other time. Maybe you have battery

571
00:21:21,039 --> 00:21:24,559
backup in your house and you're going to

572
00:21:22,320 --> 00:21:26,720
use that to supplement power during high

573
00:21:24,559 --> 00:21:28,960
time of use pricing. And so it's sort of

574
00:21:26,720 --> 00:21:31,520
the same concept here at a much much

575
00:21:28,960 --> 00:21:33,520
larger scale that we're applying to uh

576
00:21:31,520 --> 00:21:35,360
this problem of data center control. And

577
00:21:33,520 --> 00:21:37,200
if anyone's interested in in kind of

578
00:21:35,360 --> 00:21:39,120
talking about this uh afterwards, more

579
00:21:37,200 --> 00:21:41,840
than happy to spend some time discussing

580
00:21:39,120 --> 00:21:44,240
that. But the basic idea is you know we

581
00:21:41,840 --> 00:21:46,240
can uh we built an optimization engine

582
00:21:44,240 --> 00:21:48,000
that can take real time data that's

583
00:21:46,240 --> 00:21:50,000
coming off various elements that are

584
00:21:48,000 --> 00:21:52,559
sitting in the data center. So hardware

585
00:21:50,000 --> 00:21:54,880
that you have in the data center. Uh we

586
00:21:52,559 --> 00:21:57,840
can predict uh certain things such as

587
00:21:54,880 --> 00:22:00,080
when you're going to hit a peak or uh

588
00:21:57,840 --> 00:22:02,159
when you're likely to run into problems

589
00:22:00,080 --> 00:22:04,000
and you can dynamically adjust the

590
00:22:02,159 --> 00:22:06,159
various components. So at certain times

591
00:22:04,000 --> 00:22:08,320
you might adjust HVAC, certain times you

592
00:22:06,159 --> 00:22:10,080
might adjust battery, certain times you

593
00:22:08,320 --> 00:22:12,480
might adjust the IT equipment itself if

594
00:22:10,080 --> 00:22:14,480
that's a possibility. And you can also

595
00:22:12,480 --> 00:22:16,400
change the optimizations. We talked to a

596
00:22:14,480 --> 00:22:17,760
lot of people that really kind of want

597
00:22:16,400 --> 00:22:19,120
to do different things on one day.

598
00:22:17,760 --> 00:22:20,400
Sometimes they, you know, they're

599
00:22:19,120 --> 00:22:22,320
feeling good about the world and they

600
00:22:20,400 --> 00:22:24,559
want to adjust for carbon. Other times

601
00:22:22,320 --> 00:22:26,159
they're, you know, PE firm just took

602
00:22:24,559 --> 00:22:28,240
over, so they now they want to adjust

603
00:22:26,159 --> 00:22:30,240
for money. Um, and so we want to be able

604
00:22:28,240 --> 00:22:32,880
to let them do all of the above, right?

605
00:22:30,240 --> 00:22:35,120
And so we can but how this operates uh

606
00:22:32,880 --> 00:22:36,880
can change and you know even in some of

607
00:22:35,120 --> 00:22:39,039
the more conservative estimates that

608
00:22:36,880 --> 00:22:41,120
we've seen we're seeing a a fairly large

609
00:22:39,039 --> 00:22:42,640
capacity unlock. So that means if you

610
00:22:41,120 --> 00:22:44,880
are if you feel that you have a data

611
00:22:42,640 --> 00:22:46,799
center that's tapped on power we may be

612
00:22:44,880 --> 00:22:49,039
able to help you kind of raise that bar

613
00:22:46,799 --> 00:22:51,840
a little bit uh by essentially raising

614
00:22:49,039 --> 00:22:54,000
the waterline of what you operate at. So

615
00:22:51,840 --> 00:22:56,240
I'll save this uh for another time. It's

616
00:22:54,000 --> 00:22:58,480
just a simple demo video of of this

617
00:22:56,240 --> 00:23:00,159
going on um which I don't know if it's

618
00:22:58,480 --> 00:23:03,760
working or not. Yeah. So just you can

619
00:23:00,159 --> 00:23:07,679
configure different portions um and and

620
00:23:03,760 --> 00:23:09,679
that. So I I wanted to make sure I left

621
00:23:07,679 --> 00:23:13,120
some time for questions which is a

622
00:23:09,679 --> 00:23:14,960
rarity when I speak. Uh so I kind of end

623
00:23:13,120 --> 00:23:17,200
it here but I think that there are huge

624
00:23:14,960 --> 00:23:19,840
opportunities. Uh some of this comes

625
00:23:17,200 --> 00:23:21,280
down to just how can we be flexible with

626
00:23:19,840 --> 00:23:23,679
how things are working. I think we have

627
00:23:21,280 --> 00:23:25,600
one question over there. Um, so it just

628
00:23:23,679 --> 00:23:27,760
comes down to flexibility and how we're

629
00:23:25,600 --> 00:23:29,919
able to leverage flexibility within the

630
00:23:27,760 --> 00:23:32,080
world of AI, whether that's on what

631
00:23:29,919 --> 00:23:35,120
computing platform,

632
00:23:32,080 --> 00:23:37,679
what precision I'm using, uh, when I'm

633
00:23:35,120 --> 00:23:39,120
running it, or just in terms of how I'm

634
00:23:37,679 --> 00:23:43,000
operating my data center. But thank you

635
00:23:39,120 --> 00:23:43,000
very much. Look forward to connecting.

636
00:23:44,559 --> 00:23:51,280
>> Maybe two short ones. the first one like

637
00:23:48,320 --> 00:23:53,600
the power cap example you gave I wonder

638
00:23:51,280 --> 00:23:57,120
did you have to trade anything off like

639
00:23:53,600 --> 00:23:59,360
performance or anything else to get the

640
00:23:57,120 --> 00:24:01,919
>> yeah so so the biggest change was time

641
00:23:59,360 --> 00:24:04,000
right so it's you're essentially

642
00:24:01,919 --> 00:24:06,080
reducing the number of floatingoint

643
00:24:04,000 --> 00:24:08,240
operations you can do per second so it

644
00:24:06,080 --> 00:24:10,320
does take a little bit longer uh so in

645
00:24:08,240 --> 00:24:13,919
the cases that I showed over there

646
00:24:10,320 --> 00:24:16,080
you're seeing a 15 to 20% energy

647
00:24:13,919 --> 00:24:18,960
reduction so for you know let's say

648
00:24:16,080 --> 00:24:20,799
serve serving a thousand LLM inferences,

649
00:24:18,960 --> 00:24:23,840
but the time taken would increase by

650
00:24:20,799 --> 00:24:26,400
about 2 to 3%. So your 100 milliseconds

651
00:24:23,840 --> 00:24:28,000
might become 102 or 103 milliseconds,

652
00:24:26,400 --> 00:24:30,159
but that's roughly what that trade-off

653
00:24:28,000 --> 00:24:34,080
looks like. So we were looking at where

654
00:24:30,159 --> 00:24:37,679
it's, you know, 15 to 20% reduction in

655
00:24:34,080 --> 00:24:39,919
energy with maybe less than 5% increase

656
00:24:37,679 --> 00:24:42,559
or decrease in throughput. But the

657
00:24:39,919 --> 00:24:45,679
answer stays the same. No change to

658
00:24:42,559 --> 00:24:49,840
that. Okay, maybe one last one like in

659
00:24:45,679 --> 00:24:53,200
terms of uh like if data centers pay for

660
00:24:49,840 --> 00:24:55,600
provisional power kind what incentives

661
00:24:53,200 --> 00:24:57,919
do you think they have to actually

662
00:24:55,600 --> 00:24:58,720
reduce power consumption,

663
00:24:57,919 --> 00:25:00,799
right?

664
00:24:58,720 --> 00:25:03,279
>> Yeah. So that the second one is actually

665
00:25:00,799 --> 00:25:05,200
very interesting because they're

666
00:25:03,279 --> 00:25:06,400
extremely incentivized to reduce power

667
00:25:05,200 --> 00:25:08,080
consumption because that means they can

668
00:25:06,400 --> 00:25:09,840
sell again, right? So they're sitting

669
00:25:08,080 --> 00:25:11,440
under a lemon tree that's got no lemons

670
00:25:09,840 --> 00:25:13,360
left and somebody's coming and saying,

671
00:25:11,440 --> 00:25:15,440
"Hey, there's a software solution that

672
00:25:13,360 --> 00:25:16,720
can give you more lemons." Uh so they're

673
00:25:15,440 --> 00:25:19,279
actually quite interested in that

674
00:25:16,720 --> 00:25:20,880
because right now if you're a data

675
00:25:19,279 --> 00:25:23,360
center company that's, you know, 1%

676
00:25:20,880 --> 00:25:25,200
vacancy rate, uh you really don't have a

677
00:25:23,360 --> 00:25:27,360
growth path that does not include major

678
00:25:25,200 --> 00:25:28,799
construction and capital projects. And

679
00:25:27,360 --> 00:25:31,679
so if someone's able to come in and say,

680
00:25:28,799 --> 00:25:33,440
"Hey, look, we can uh really help you

681
00:25:31,679 --> 00:25:35,919
tune the power that you have and that'll

682
00:25:33,440 --> 00:25:37,279
allow you to get more customers." That's

683
00:25:35,919 --> 00:25:39,520
actually something that we're seeing

684
00:25:37,279 --> 00:25:42,080
people quite excited about. And we tried

685
00:25:39,520 --> 00:25:43,760
to keep this as uh

686
00:25:42,080 --> 00:25:45,120
there's no huge changes. You don't need

687
00:25:43,760 --> 00:25:46,400
to go buy new infrastructure to make

688
00:25:45,120 --> 00:25:48,159
this happen. This is using what's

689
00:25:46,400 --> 00:25:50,000
already there. Just optimizing the way

690
00:25:48,159 --> 00:25:53,799
that they actually operate and helping

691
00:25:50,000 --> 00:25:53,799
schedule and time them.

692
00:25:59,600 --> 00:26:06,400
Um in one of your last slides uh about

693
00:26:02,880 --> 00:26:09,600
the dashboards uh of Bay compute there

694
00:26:06,400 --> 00:26:13,200
was one of the uh the the first one

695
00:26:09,600 --> 00:26:16,559
there to predict the peak demand um of

696
00:26:13,200 --> 00:26:18,480
the the compute loads. Um how does that

697
00:26:16,559 --> 00:26:20,240
work or h how do you do that?

698
00:26:18,480 --> 00:26:21,679
>> Yeah. So certainly when you're saying

699
00:26:20,240 --> 00:26:23,200
predicting it does make a few

700
00:26:21,679 --> 00:26:24,799
assumptions that you're not like put on

701
00:26:23,200 --> 00:26:26,080
a brand new customer in there like

702
00:26:24,799 --> 00:26:28,320
yesterday and then we're trying to

703
00:26:26,080 --> 00:26:31,200
predict that. Uh so in the most part

704
00:26:28,320 --> 00:26:32,880
there is a lot of like known variance

705
00:26:31,200 --> 00:26:36,240
amongst different workloads that people

706
00:26:32,880 --> 00:26:38,880
have oop sorry ah that people are using.

707
00:26:36,240 --> 00:26:40,400
So for example between 9 to5 their so

708
00:26:38,880 --> 00:26:43,120
we're we're seeing this sort of like

709
00:26:40,400 --> 00:26:44,799
patterns that emerge. So assuming no big

710
00:26:43,120 --> 00:26:46,720
changes obviously if you're a colo and

711
00:26:44,799 --> 00:26:49,360
you just replace three customers that

712
00:26:46,720 --> 00:26:50,640
prediction may need to be reworked but

713
00:26:49,360 --> 00:26:52,240
there's a lot of patterns in the way

714
00:26:50,640 --> 00:26:54,240
that people actually use these systems.

715
00:26:52,240 --> 00:26:56,559
And so that's what in terms of the

716
00:26:54,240 --> 00:26:58,240
workloads themselves that though

717
00:26:56,559 --> 00:27:00,400
combined with like the environmental

718
00:26:58,240 --> 00:27:02,159
factors which may not follow that same

719
00:27:00,400 --> 00:27:03,840
seasonality. I mean there is still

720
00:27:02,159 --> 00:27:05,440
seasonality but may not like on a

721
00:27:03,840 --> 00:27:06,880
day-to-day basis follow the same path.

722
00:27:05,440 --> 00:27:08,720
So that's the part that we're trying to

723
00:27:06,880 --> 00:27:12,760
really predict. It's kind of bringing

724
00:27:08,720 --> 00:27:12,760
those pieces of information together.

725
00:27:15,360 --> 00:27:21,039
>> U Thank you. I really like your lemon uh

726
00:27:18,400 --> 00:27:22,559
analogy. Right. So for the for the four

727
00:27:21,039 --> 00:27:24,400
approaches you mentioned reduce the

728
00:27:22,559 --> 00:27:26,880
demand, reduce the intensity and and the

729
00:27:24,400 --> 00:27:28,640
cost, right? So consider a a typical

730
00:27:26,880 --> 00:27:30,159
like large scale uh data center

731
00:27:28,640 --> 00:27:31,919
operators.

732
00:27:30,159 --> 00:27:33,840
Which approach do you think is you know

733
00:27:31,919 --> 00:27:35,919
serves like a more of a lower hanging

734
00:27:33,840 --> 00:27:38,400
fruit that they were easy to implement

735
00:27:35,919 --> 00:27:41,039
for them and also like easier from time

736
00:27:38,400 --> 00:27:42,480
time frame and cost frame? Uh which one

737
00:27:41,039 --> 00:27:44,880
is you know what's your thought on that

738
00:27:42,480 --> 00:27:46,240
one? Yeah. So that's a that's a tough we

739
00:27:44,880 --> 00:27:48,159
have to think about how many people

740
00:27:46,240 --> 00:27:50,559
there are in this and everyone's got a

741
00:27:48,159 --> 00:27:52,720
slightly different uh so you have for

742
00:27:50,559 --> 00:27:55,200
example like my uh you know company

743
00:27:52,720 --> 00:27:57,919
radium we're a cloud provider we don't

744
00:27:55,200 --> 00:28:00,240
own any data center we put our equipment

745
00:27:57,919 --> 00:28:03,360
into collocation facilities across

746
00:28:00,240 --> 00:28:05,279
across all over the place but we don't

747
00:28:03,360 --> 00:28:07,279
own the actual physical buildings in

748
00:28:05,279 --> 00:28:09,039
which they run. You then have some

749
00:28:07,279 --> 00:28:11,200
companies which kind of move up one some

750
00:28:09,039 --> 00:28:13,200
of the hyperscalers are like that where

751
00:28:11,200 --> 00:28:14,480
they have the equipment plus they own

752
00:28:13,200 --> 00:28:16,720
the building or at least they control

753
00:28:14,480 --> 00:28:18,480
the building and its operations. Then

754
00:28:16,720 --> 00:28:20,240
you have some that are coming up even

755
00:28:18,480 --> 00:28:22,559
more recently that are all the way from

756
00:28:20,240 --> 00:28:24,159
power you know from energy generation

757
00:28:22,559 --> 00:28:26,480
all the way to the data center they run

758
00:28:24,159 --> 00:28:28,480
and this is like you know Tesla being or

759
00:28:26,480 --> 00:28:30,960
sorry XAI being a good example of that

760
00:28:28,480 --> 00:28:33,200
where they're generating power and

761
00:28:30,960 --> 00:28:36,159
they're using it themselves and so for

762
00:28:33,200 --> 00:28:39,600
every one of them uh there's a different

763
00:28:36,159 --> 00:28:41,120
uh answer if you want to say that uh for

764
00:28:39,600 --> 00:28:43,039
let's say the most restrictive case

765
00:28:41,120 --> 00:28:44,640
which is maybe a collocation data center

766
00:28:43,039 --> 00:28:46,000
provider so probably the one that we

767
00:28:44,640 --> 00:28:48,159
have at the that we showed at the end

768
00:28:46,000 --> 00:28:50,799
which is that optimization is probably

769
00:28:48,159 --> 00:28:54,559
the lowest hanging fruit for them. If

770
00:28:50,799 --> 00:28:57,120
you're a AI company that's making things

771
00:28:54,559 --> 00:29:00,159
available, the software integrated with

772
00:28:57,120 --> 00:29:01,520
your AI is probably a very powerful

773
00:29:00,159 --> 00:29:03,279
technique that you can use because you

774
00:29:01,520 --> 00:29:05,600
may not control the actual

775
00:29:03,279 --> 00:29:08,399
infrastructure itself. And so yeah, I

776
00:29:05,600 --> 00:29:10,559
think it's a little bit of the usual uh

777
00:29:08,399 --> 00:29:12,559
academic response of it depends um

778
00:29:10,559 --> 00:29:15,279
applies here as well, but really which

779
00:29:12,559 --> 00:29:17,440
community you're coming from and what

780
00:29:15,279 --> 00:29:21,480
levers you're allowed to to dial or what

781
00:29:17,440 --> 00:29:21,480
what what you're allowed to adjust.

782
00:29:23,039 --> 00:29:30,080
>> Yeah. So I um I really like I was blown

783
00:29:27,039 --> 00:29:35,279
away by your uh your methods in tackling

784
00:29:30,080 --> 00:29:37,760
the inferencing stage of uh AI and uh

785
00:29:35,279 --> 00:29:40,480
using that to save energy. I think it

786
00:29:37,760 --> 00:29:43,840
was really brilliant but uh at the same

787
00:29:40,480 --> 00:29:46,000
time like using the lemon tree example

788
00:29:43,840 --> 00:29:50,080
uh where you have more than just one

789
00:29:46,000 --> 00:29:52,240
stand. So if you reduce like the service

790
00:29:50,080 --> 00:29:54,159
uh quality or the service level then

791
00:29:52,240 --> 00:29:57,120
it's easy for people to switch to

792
00:29:54,159 --> 00:30:00,000
another AI that's one of the tradeoffs

793
00:29:57,120 --> 00:30:04,080
or the constraints. Uh so like how did

794
00:30:00,000 --> 00:30:07,840
you determine the optimal point to which

795
00:30:04,080 --> 00:30:11,039
like uh you serve people at this like uh

796
00:30:07,840 --> 00:30:14,960
level and also not making people like

797
00:30:11,039 --> 00:30:17,760
move away from your uh products.

798
00:30:14,960 --> 00:30:19,440
>> Yeah. So, and just uh um a lot of the

799
00:30:17,760 --> 00:30:21,200
techniques were developed by folks in my

800
00:30:19,440 --> 00:30:22,880
group, so credit really goes to them. I

801
00:30:21,200 --> 00:30:25,520
just get the opportunity to present some

802
00:30:22,880 --> 00:30:26,960
of their work. Um but on the you know,

803
00:30:25,520 --> 00:30:29,279
coming back to the lemon tree stand,

804
00:30:26,960 --> 00:30:31,360
right? Uh I mean, if you're a Tropicana

805
00:30:29,279 --> 00:30:33,520
and lemon cost skyrocketed, what would

806
00:30:31,360 --> 00:30:35,440
you dilute your lemonade a little bit?

807
00:30:33,520 --> 00:30:37,440
Um so that's sort of like reducing the

808
00:30:35,440 --> 00:30:39,600
man, this lemonade thing is continuing

809
00:30:37,440 --> 00:30:41,600
this analogy. It's like adding a little

810
00:30:39,600 --> 00:30:43,919
bit more water into it is like slowing

811
00:30:41,600 --> 00:30:45,039
down your processing a little bit. Uh

812
00:30:43,919 --> 00:30:45,919
but there's some point at which

813
00:30:45,039 --> 00:30:49,279
customers are going to be like this

814
00:30:45,919 --> 00:30:51,120
tastes really bad. Um and so that's the

815
00:30:49,279 --> 00:30:53,360
so for some of the experiments that we

816
00:30:51,120 --> 00:30:56,000
ran when we came up with that what we

817
00:30:53,360 --> 00:30:58,480
call the P99 tail latency we actually

818
00:30:56,000 --> 00:31:00,640
took that from published works of what

819
00:30:58,480 --> 00:31:02,960
you know a Google or an Amazon when

820
00:31:00,640 --> 00:31:05,520
they're deploying things at scale what

821
00:31:02,960 --> 00:31:07,760
they're striving for. Um and you can go

822
00:31:05,520 --> 00:31:10,000
to something like uh replicate or

823
00:31:07,760 --> 00:31:11,679
together to look at what the latencies

824
00:31:10,000 --> 00:31:12,960
of large language models should be in

825
00:31:11,679 --> 00:31:14,320
terms of that's the product that they

826
00:31:12,960 --> 00:31:16,320
offer. they've usually put an upper

827
00:31:14,320 --> 00:31:17,840
bound on that. And so we sort of took

828
00:31:16,320 --> 00:31:19,919
the numbers from there. We try not to

829
00:31:17,840 --> 00:31:21,440
invent those numbers ourselves. And what

830
00:31:19,919 --> 00:31:23,919
we did then say is look, if you're

831
00:31:21,440 --> 00:31:26,080
willing to adjust 1 or 2% off of that,

832
00:31:23,919 --> 00:31:29,679
right? While there is a race to produce

833
00:31:26,080 --> 00:31:33,279
faster uh lower latency throughput, if

834
00:31:29,679 --> 00:31:34,880
you're allowed to relax that by 1 or 2%.

835
00:31:33,279 --> 00:31:36,399
You suddenly open up. It's, you know, we

836
00:31:34,880 --> 00:31:38,320
have this in the data center world, but

837
00:31:36,399 --> 00:31:40,320
many data centers try to provide three

838
00:31:38,320 --> 00:31:41,600
or four nines of uptime. And I think

839
00:31:40,320 --> 00:31:43,760
there's somebody from uptime institute

840
00:31:41,600 --> 00:31:45,039
over here they can correct me. Um if you

841
00:31:43,760 --> 00:31:46,240
can remove one of those nines you

842
00:31:45,039 --> 00:31:48,080
suddenly have a lot of options

843
00:31:46,240 --> 00:31:49,440
available. And so the question is you

844
00:31:48,080 --> 00:31:51,200
know can we work with and I think we're

845
00:31:49,440 --> 00:31:53,200
getting to the state because power is so

846
00:31:51,200 --> 00:31:54,960
difficult to get your hands on where

847
00:31:53,200 --> 00:31:56,799
people might be more willing to be a tad

848
00:31:54,960 --> 00:32:00,159
bit flexible if that means faster

849
00:31:56,799 --> 00:32:03,640
compute faster access to power.

850
00:32:00,159 --> 00:32:03,640
Okay. Thank you.


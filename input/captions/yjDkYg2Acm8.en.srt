1
00:00:01,760 --> 00:00:05,600
So with that, here we have the startups.

2
00:00:03,840 --> 00:00:06,960
I know you want to hear from them. So

3
00:00:05,600 --> 00:00:09,679
first up, I'd like to introduce

4
00:00:06,960 --> 00:00:12,160
Defraction. It's inspired by the eye and

5
00:00:09,679 --> 00:00:17,000
its intelligent vision, superpowering

6
00:00:12,160 --> 00:00:17,000
machines. So Christine, take it away.

7
00:00:21,520 --> 00:00:25,920
>> Thank you. I'm Christine Wong, the CTO

8
00:00:23,600 --> 00:00:29,119
and co-founder of Depression. My

9
00:00:25,920 --> 00:00:31,920
co-founder and CEO Johannes Gas Hanosa

10
00:00:29,119 --> 00:00:34,399
is an MIT Sloan fellow and researcher

11
00:00:31,920 --> 00:00:38,480
while other co-founder professor Saka

12
00:00:34,399 --> 00:00:40,640
Guha is an MIT alumnus and a professor.

13
00:00:38,480 --> 00:00:43,600
So the problem we are solving is like

14
00:00:40,640 --> 00:00:46,960
although today visual AI is used more

15
00:00:43,600 --> 00:00:50,559
and more but we are still uh it's still

16
00:00:46,960 --> 00:00:52,719
very slow and of low resolution. Why?

17
00:00:50,559 --> 00:00:55,199
because we are essentially using the

18
00:00:52,719 --> 00:00:59,520
same techniques that has been used since

19
00:00:55,199 --> 00:01:02,000
the 1800s, the pinhole camera. And today

20
00:00:59,520 --> 00:01:04,879
uh the way we do visual AI is not that

21
00:01:02,000 --> 00:01:07,760
much different. We capture the scene uh

22
00:01:04,879 --> 00:01:10,640
through a series of lenses of the

23
00:01:07,760 --> 00:01:14,159
telescope or a camera and project it on

24
00:01:10,640 --> 00:01:18,479
the camera sensor and then we create a

25
00:01:14,159 --> 00:01:23,200
JPEG file and run the visual AI on top

26
00:01:18,479 --> 00:01:25,680
of the JPEG via GPU or VPU. However,

27
00:01:23,200 --> 00:01:28,799
quantum mechanists tell us like by

28
00:01:25,680 --> 00:01:32,960
capturing the image, we have already

29
00:01:28,799 --> 00:01:36,400
lost up to 95% of the information that's

30
00:01:32,960 --> 00:01:39,360
contained in the photons. So, we draw

31
00:01:36,400 --> 00:01:42,079
the inspiration from the eye. So,

32
00:01:39,360 --> 00:01:45,280
contrary to uh what we usually believe

33
00:01:42,079 --> 00:01:47,680
like the eyes are not just like cameras.

34
00:01:45,280 --> 00:01:50,720
In fact, there are a lot of signal

35
00:01:47,680 --> 00:01:53,280
processing and intuitive thinking

36
00:01:50,720 --> 00:01:55,759
directly happening at the back of our

37
00:01:53,280 --> 00:02:00,560
eyes before the signals reach the

38
00:01:55,759 --> 00:02:04,479
brains. So when light hit the uh the

39
00:02:00,560 --> 00:02:07,360
retina, the RGC cells at the back of it

40
00:02:04,479 --> 00:02:10,080
actually fire up and that allows us to

41
00:02:07,360 --> 00:02:13,840
process information very fastly and

42
00:02:10,080 --> 00:02:17,040
react to fast change and movement

43
00:02:13,840 --> 00:02:19,200
and drawing from the inspiration we

44
00:02:17,040 --> 00:02:22,959
developed the visual sensing and

45
00:02:19,200 --> 00:02:26,560
processing unit Galileo. It replaces the

46
00:02:22,959 --> 00:02:30,400
conventional camera sensor plus GPU and

47
00:02:26,560 --> 00:02:34,239
VPU combination and it has a much better

48
00:02:30,400 --> 00:02:37,120
resolution up to 20 times better than

49
00:02:34,239 --> 00:02:40,319
conventional imaging systems and also

50
00:02:37,120 --> 00:02:43,360
about three orders of magnitude faster

51
00:02:40,319 --> 00:02:45,920
processing and much lower energy

52
00:02:43,360 --> 00:02:49,280
consumption.

53
00:02:45,920 --> 00:02:52,319
So the technology we are using is like

54
00:02:49,280 --> 00:02:55,440
we are not c directly capturing the

55
00:02:52,319 --> 00:02:58,800
photon by detector but instead we

56
00:02:55,440 --> 00:03:02,720
pre-process them with a series of face

57
00:02:58,800 --> 00:03:05,280
plates to maximally extract information

58
00:03:02,720 --> 00:03:09,200
and the resolution contained in those

59
00:03:05,280 --> 00:03:13,040
photons based on quantum mechanics.

60
00:03:09,200 --> 00:03:14,640
The uh this uh work has already been

61
00:03:13,040 --> 00:03:18,080
demonstrated

62
00:03:14,640 --> 00:03:20,959
experimentally showing that the say we

63
00:03:18,080 --> 00:03:24,959
want to distinguish two very closely

64
00:03:20,959 --> 00:03:27,680
spaced object and with a best

65
00:03:24,959 --> 00:03:30,159
conventional camera while they are so

66
00:03:27,680 --> 00:03:32,720
closely spaced together they are no

67
00:03:30,159 --> 00:03:37,200
longer distinguishable. But with our

68
00:03:32,720 --> 00:03:39,599
technology we can achieve about 25 times

69
00:03:37,200 --> 00:03:43,920
better resolution and clearly

70
00:03:39,599 --> 00:03:46,879
distinguish the two uh uh closely space

71
00:03:43,920 --> 00:03:49,760
points and estimate their separation.

72
00:03:46,879 --> 00:03:53,280
This uh work has been published in the

73
00:03:49,760 --> 00:03:57,040
journal Optica to this year and was uh

74
00:03:53,280 --> 00:04:00,239
funded by NASA and DARPA.

75
00:03:57,040 --> 00:04:03,519
So looking at the competition landscape

76
00:04:00,239 --> 00:04:06,640
um so our advantage in the resolution

77
00:04:03,519 --> 00:04:09,599
and processing speed is both are both

78
00:04:06,640 --> 00:04:12,400
like orders of magnitude uh better than

79
00:04:09,599 --> 00:04:16,400
the current state of the art com uh

80
00:04:12,400 --> 00:04:20,720
combination of camera sensors plus GPU

81
00:04:16,400 --> 00:04:26,080
or VPU say we want to distinguish say uh

82
00:04:20,720 --> 00:04:31,440
a small drone um then we can In fact,

83
00:04:26,080 --> 00:04:34,400
run the visual AI uh detected up to 20

84
00:04:31,440 --> 00:04:37,600
two kilometers away at a fraction of the

85
00:04:34,400 --> 00:04:41,360
time needed.

86
00:04:37,600 --> 00:04:44,880
Okay. So, um in terms of application

87
00:04:41,360 --> 00:04:48,080
cases, the technology can be used across

88
00:04:44,880 --> 00:04:51,919
many industries in both defense and

89
00:04:48,080 --> 00:04:55,120
commercial. And our go-to market starts

90
00:04:51,919 --> 00:04:58,479
from the uh defense side, the space

91
00:04:55,120 --> 00:05:01,440
domain awareness, earth observation and

92
00:04:58,479 --> 00:05:04,479
the air defense etc. And then while the

93
00:05:01,440 --> 00:05:06,720
technology matures will uh could be also

94
00:05:04,479 --> 00:05:09,520
applied to a lot of industrial

95
00:05:06,720 --> 00:05:12,960
inspection, robotics or autonomous

96
00:05:09,520 --> 00:05:15,199
vehicle. So our beach head market is

97
00:05:12,960 --> 00:05:17,520
space domain awareness and earth

98
00:05:15,199 --> 00:05:20,720
observation. So for example like

99
00:05:17,520 --> 00:05:24,639
observing very small satellites and scan

100
00:05:20,720 --> 00:05:27,440
for space debris uh etc. And for space

101
00:05:24,639 --> 00:05:31,360
domain awareness, we are part of the

102
00:05:27,440 --> 00:05:34,160
space force uh Apollo accelerator and we

103
00:05:31,360 --> 00:05:38,560
have been actively uh talking to space

104
00:05:34,160 --> 00:05:42,560
force for their use cases and for earth

105
00:05:38,560 --> 00:05:45,280
observation in addition to defense uh

106
00:05:42,560 --> 00:05:47,759
use cases there are also a lot of

107
00:05:45,280 --> 00:05:50,880
commercial use cases like financial

108
00:05:47,759 --> 00:05:53,120
services, agriculture or utility

109
00:05:50,880 --> 00:05:57,680
inspections.

110
00:05:53,120 --> 00:06:01,039
So for us um we for the partnership uh

111
00:05:57,680 --> 00:06:04,000
opportunity although we are uh starting

112
00:06:01,039 --> 00:06:06,880
in a more like defense and space domain

113
00:06:04,000 --> 00:06:09,600
partnering with the US government but we

114
00:06:06,880 --> 00:06:12,400
would like to hear from people like to

115
00:06:09,600 --> 00:06:16,560
partner with all sorts of possible pilot

116
00:06:12,400 --> 00:06:18,960
cases. uh for example in addition to uh

117
00:06:16,560 --> 00:06:21,199
space domain earth obsession the other

118
00:06:18,960 --> 00:06:26,000
commercial earth uh imaging

119
00:06:21,199 --> 00:06:29,440
opportunities the um food manufacturing

120
00:06:26,000 --> 00:06:35,080
inspections and eventually uh quality

121
00:06:29,440 --> 00:06:35,080
control etc. So yeah, thank you


1
00:00:01,267 --> 00:00:02,602
Good morning, everyone.

2
00:00:02,602 --> 00:00:05,438
And thank you, Sally, for
that nice introduction.

3
00:00:05,438 --> 00:00:09,042
Thank you all for inviting
me to speak with you today.

4
00:00:09,042 --> 00:00:13,580
It's a genuine honor to be here
to see some familiar faces,

5
00:00:13,580 --> 00:00:16,616
but also to meet
some new people.

6
00:00:16,616 --> 00:00:19,019
Today, what I'd like
to do is share with you

7
00:00:19,019 --> 00:00:23,156
some early reflections on the
future of management education.

8
00:00:23,156 --> 00:00:25,525
And what I'm going to do
is divide my brief remarks

9
00:00:25,525 --> 00:00:27,093
into three parts.

10
00:00:27,093 --> 00:00:30,230
First, what I'd like
to do is describe

11
00:00:30,230 --> 00:00:33,767
how this is a pivotal moment
for the world of business,

12
00:00:33,767 --> 00:00:37,070
and as a result, for
management education,

13
00:00:37,070 --> 00:00:40,273
given some significant
challenges under way.

14
00:00:40,273 --> 00:00:43,243
Second, as the still
relatively new Dean

15
00:00:43,243 --> 00:00:45,512
of the MIT Sloan
School of Management,

16
00:00:45,512 --> 00:00:50,550
I'd like to offer some thoughts
on how MIT Sloan, by becoming

17
00:00:50,550 --> 00:00:54,320
even more embedded
in the MIT ecosystem,

18
00:00:54,320 --> 00:00:57,791
can lead in addressing
some of these challenges

19
00:00:57,791 --> 00:01:00,960
and in reinventing
management education.

20
00:01:00,960 --> 00:01:04,431
And finally, I'd like to
provide an example of how

21
00:01:04,431 --> 00:01:08,601
we can collectively, all of
us, do this exciting work

22
00:01:08,601 --> 00:01:12,672
by discussing the challenges,
but also the opportunities posed

23
00:01:12,672 --> 00:01:15,241
by generative AI,
and how bringing back

24
00:01:15,241 --> 00:01:18,411
the human side of
enterprise is key to how

25
00:01:18,411 --> 00:01:20,613
we manage this moment.

26
00:01:20,613 --> 00:01:22,749
So let me begin with
the challenges, which

27
00:01:22,749 --> 00:01:25,285
are also opportunities.

28
00:01:25,285 --> 00:01:28,955
In recent years, the context
within which business

29
00:01:28,955 --> 00:01:33,560
has been operating for decades
has changed in significant ways.

30
00:01:33,560 --> 00:01:37,197
Now I'm going to present a
highly stylized description

31
00:01:37,197 --> 00:01:39,666
of that context and
the changes underway.

32
00:01:39,666 --> 00:01:44,170
The reality, of course, is
that's much, much more nuanced.

33
00:01:44,170 --> 00:01:49,342
But let me just give you the
less nuanced portrait of things.

34
00:01:49,342 --> 00:01:51,711
Over the last several
decades, business

35
00:01:51,711 --> 00:01:55,048
has operated in a
more or less flat

36
00:01:55,048 --> 00:01:58,685
world where geopolitical
and cultural differences

37
00:01:58,685 --> 00:02:01,955
across countries and
regions were eroding.

38
00:02:01,955 --> 00:02:06,826
A world in which innovations
and communications, logistics,

39
00:02:06,826 --> 00:02:10,330
design, and the spread
of global supply chains

40
00:02:10,330 --> 00:02:14,801
allowed firms to produce more or
less anything anywhere, usually

41
00:02:14,801 --> 00:02:17,570
driven by low input
and labor costs,

42
00:02:17,570 --> 00:02:19,806
and then sell their
products or services

43
00:02:19,806 --> 00:02:22,709
across the globe in
an array of markets

44
00:02:22,709 --> 00:02:26,679
with little concern for
trade restrictions, tariffs,

45
00:02:26,679 --> 00:02:30,517
cultural barriers, or even
the true cost of externalities

46
00:02:30,517 --> 00:02:32,285
like carbon emissions.

47
00:02:32,285 --> 00:02:37,357
Again, this is a very
highly stylized description

48
00:02:37,357 --> 00:02:38,558
of the context.

49
00:02:38,558 --> 00:02:42,595
The world was never as flat as
Thomas Friedman once argued.

50
00:02:42,595 --> 00:02:44,597
It was always much more lumpy.

51
00:02:44,597 --> 00:02:48,768
But the assumption that we were
living in a globalized world

52
00:02:48,768 --> 00:02:52,805
with a more or less
friction-less flow of capital,

53
00:02:52,805 --> 00:02:55,842
of products, of
people, of services,

54
00:02:55,842 --> 00:03:00,480
was one that was shared by many
business and political leaders.

55
00:03:00,480 --> 00:03:04,717
This model of business has
been challenged in recent years

56
00:03:04,717 --> 00:03:07,720
by a variety of
forces, including

57
00:03:07,720 --> 00:03:10,723
the rise of geopolitical
tensions between countries.

58
00:03:10,723 --> 00:03:12,492
And we can talk about
the US and China.

59
00:03:12,492 --> 00:03:13,893
But of course,
it's more than just

60
00:03:13,893 --> 00:03:15,428
those two countries
that have led

61
00:03:15,428 --> 00:03:19,065
to the rise of trade barriers
and the reconfiguration,

62
00:03:19,065 --> 00:03:22,468
or even diversification
of global supply chains.

63
00:03:22,468 --> 00:03:24,370
Now that reconfiguration
of supply chains

64
00:03:24,370 --> 00:03:26,005
happened before
the current moment.

65
00:03:26,005 --> 00:03:28,241
It happened during the
first Trump administration.

66
00:03:28,241 --> 00:03:29,676
It happened because
companies were

67
00:03:29,676 --> 00:03:33,846
thinking about their
global carbon footprint.

68
00:03:33,846 --> 00:03:36,249
It happened because of
the pandemic and the need

69
00:03:36,249 --> 00:03:38,785
to have more resilient
supply chains.

70
00:03:38,785 --> 00:03:43,923
But recent efforts have really
accelerated this process

71
00:03:43,923 --> 00:03:48,928
of trying to reconfigure
and change global trade

72
00:03:48,928 --> 00:03:50,163
and commerce.

73
00:03:50,163 --> 00:03:52,098
The second pressure,
and this is one

74
00:03:52,098 --> 00:03:53,900
that we don't talk
about as much but I

75
00:03:53,900 --> 00:03:57,704
think is equally important, is
the reemergence of regulation,

76
00:03:57,704 --> 00:04:01,107
not just in the EU but in
the US, in different states

77
00:04:01,107 --> 00:04:02,909
and in other countries, as well.

78
00:04:02,909 --> 00:04:06,746
Think about the Digital Services
Act or the Digital Markets Act

79
00:04:06,746 --> 00:04:11,651
and what that has done for
especially the digital economy.

80
00:04:11,651 --> 00:04:15,388
This is shaping how companies
make and sell their products

81
00:04:15,388 --> 00:04:18,024
and services around the globe.

82
00:04:18,024 --> 00:04:20,526
Third, there's a
growing awareness--

83
00:04:20,526 --> 00:04:23,463
and I think this is a good
thing-- and concern over climate

84
00:04:23,463 --> 00:04:26,099
change and its
impact on society,

85
00:04:26,099 --> 00:04:28,968
and thus the need to develop
low carbon products and business

86
00:04:28,968 --> 00:04:32,238
practices, business
models in the near future.

87
00:04:32,238 --> 00:04:36,409
Fourth, there are these
emergences of and maturity.

88
00:04:36,409 --> 00:04:38,678
Or maybe not maturity,
but evolution

89
00:04:38,678 --> 00:04:42,081
of disruptive new
technologies like AI

90
00:04:42,081 --> 00:04:43,883
that will impact
existing business

91
00:04:43,883 --> 00:04:47,020
models, work arrangements,
and employment patterns.

92
00:04:47,020 --> 00:04:51,591
And finally, there are changing
employee attitudes towards work,

93
00:04:51,591 --> 00:04:54,260
towards work life
balance, and expectations

94
00:04:54,260 --> 00:04:56,296
they have of their employers.

95
00:04:56,296 --> 00:04:58,631
These and other
challenges threaten

96
00:04:58,631 --> 00:05:02,769
to up-end existing business
models and management practices

97
00:05:02,769 --> 00:05:05,838
in the US and around the world.

98
00:05:05,838 --> 00:05:08,608
I believe that we are
in a pivotal moment

99
00:05:08,608 --> 00:05:12,245
when individual firms and
even entire industries

100
00:05:12,245 --> 00:05:17,350
need to rethink their business
models and ways of operating

101
00:05:17,350 --> 00:05:18,451
in the world.

102
00:05:18,451 --> 00:05:22,322
And there is no clear,
already established path

103
00:05:22,322 --> 00:05:24,057
for them to follow.

104
00:05:24,057 --> 00:05:27,193
In enterprises across
the world, leaders

105
00:05:27,193 --> 00:05:29,128
are trying to figure
out how to operate

106
00:05:29,128 --> 00:05:32,198
in a more regulated and
politicized environment.

107
00:05:32,198 --> 00:05:35,068
How to reduce carbon
emissions while still making

108
00:05:35,068 --> 00:05:38,404
innovative products and taking
advantage of their globally

109
00:05:38,404 --> 00:05:40,640
dispersed suppliers
and customers.

110
00:05:40,640 --> 00:05:43,743
How to manage a workforce
with new demands

111
00:05:43,743 --> 00:05:45,545
and new expectations.

112
00:05:45,545 --> 00:05:49,515
And how to integrate the promise
and potential of generative AI

113
00:05:49,515 --> 00:05:53,686
into existing and future product
services and business models

114
00:05:53,686 --> 00:05:57,490
in ways that will increase their
company's competitive value

115
00:05:57,490 --> 00:05:59,258
and not undermine it.

116
00:05:59,258 --> 00:06:03,563
And the sad truth is that
most management schools,

117
00:06:03,563 --> 00:06:07,767
business schools, cannot guide
these leaders since we, too,

118
00:06:07,767 --> 00:06:09,569
are stuck in the past.

119
00:06:09,569 --> 00:06:13,306
To be completely frank, most
management business schools

120
00:06:13,306 --> 00:06:15,608
have been teaching
the same material

121
00:06:15,608 --> 00:06:19,178
in the same way for
decades, not adapting

122
00:06:19,178 --> 00:06:23,282
our models, our frameworks,
and our theoretical approaches

123
00:06:23,282 --> 00:06:26,986
to the dramatic changes
underway in the world.

124
00:06:26,986 --> 00:06:28,654
And the students know it.

125
00:06:28,654 --> 00:06:30,656
And so do their
future employers.

126
00:06:30,656 --> 00:06:32,959
Now, I don't expect
this crowd to be

127
00:06:32,959 --> 00:06:36,629
a regular reader of a magazine
called Poets and Quants.

128
00:06:36,629 --> 00:06:40,199
This is a magazine that
talks about business schools.

129
00:06:40,199 --> 00:06:45,538
But last late July, an article
came out in Poets and Quants

130
00:06:45,538 --> 00:06:47,907
basically quoting all these
business school students

131
00:06:47,907 --> 00:06:49,909
at Graduate School of
Business at Stanford,

132
00:06:49,909 --> 00:06:51,644
where the students
were basically saying,

133
00:06:51,644 --> 00:06:53,312
we're not learning anything.

134
00:06:53,312 --> 00:06:55,114
We're not learning any skills.

135
00:06:55,114 --> 00:06:58,418
About a month ago, a similar
article in the same magazine

136
00:06:58,418 --> 00:07:00,753
came out about Wharton,
where they basically

137
00:07:00,753 --> 00:07:01,988
argued the same thing.

138
00:07:01,988 --> 00:07:03,856
These professors are
teaching the same things

139
00:07:03,856 --> 00:07:05,491
that they've been
teaching for decades.

140
00:07:05,491 --> 00:07:07,660
We're not learning
any new skills.

141
00:07:07,660 --> 00:07:11,030
Now I was, as the
new Dean of Sloan,

142
00:07:11,030 --> 00:07:13,933
greatly relieved that they were
writing about others and not

143
00:07:13,933 --> 00:07:15,334
about us.

144
00:07:15,334 --> 00:07:18,971
But the fact is, they could
have been writing about us.

145
00:07:18,971 --> 00:07:20,673
This is an industry problem.

146
00:07:20,673 --> 00:07:25,478
This is not a school or
particular university problem.

147
00:07:25,478 --> 00:07:28,815
And this is something that
we have to take on head-on.

148
00:07:28,815 --> 00:07:32,452
But I believe that these
and other broad challenges

149
00:07:32,452 --> 00:07:35,922
create exciting
opportunities for MIT Sloan

150
00:07:35,922 --> 00:07:39,592
to build on and expand
its unique assets,

151
00:07:39,592 --> 00:07:42,528
to play a leadership role in
addressing these challenges,

152
00:07:42,528 --> 00:07:47,133
and in the process, reinvigorate
management education, management

153
00:07:47,133 --> 00:07:49,435
research, and practice.

154
00:07:49,435 --> 00:07:51,170
Now, I know this sounds
like a sales job.

155
00:07:51,170 --> 00:07:53,806
But I really, actually,
really believe it.

156
00:07:53,806 --> 00:07:55,107
So why Sloan?

157
00:07:55,107 --> 00:07:59,245
Why do I think this is such a
great moment for MIT and MIT

158
00:07:59,245 --> 00:07:59,979
Sloan?

159
00:07:59,979 --> 00:08:03,749
And I believe it's because we
possess several amazing assets.

160
00:08:03,749 --> 00:08:05,818
The first is that
we have a world

161
00:08:05,818 --> 00:08:09,589
class, research-oriented
faculty, many of them already

162
00:08:09,589 --> 00:08:12,525
working on some of the
important issues of the day,

163
00:08:12,525 --> 00:08:15,761
whether it's health or climate
or advanced manufacturing,

164
00:08:15,761 --> 00:08:19,765
or the future of work or GenAI
or any of the other key issues.

165
00:08:19,765 --> 00:08:22,335
We have people already
working and collaborating

166
00:08:22,335 --> 00:08:24,737
across the university
on these issues.

167
00:08:24,737 --> 00:08:28,941
We have amazing faculty,
incredible students,

168
00:08:28,941 --> 00:08:31,978
and an incredibly dedicated
professional staff.

169
00:08:31,978 --> 00:08:35,581
And our curriculum
has traditionally

170
00:08:35,581 --> 00:08:38,985
blended theory and
practice, hand in mind,

171
00:08:38,985 --> 00:08:41,387
which is exactly
how adults learn.

172
00:08:41,387 --> 00:08:43,990
So we have these incredible
assets in our people

173
00:08:43,990 --> 00:08:46,526
and in the curriculum
that we have already.

174
00:08:46,526 --> 00:08:49,795
Secondly, and this is the most
important asset I think we have,

175
00:08:49,795 --> 00:08:54,133
is our embeddedness in MIT
and in the MIT ecosystem.

176
00:08:54,133 --> 00:08:56,736
Across this great
university, colleagues

177
00:08:56,736 --> 00:08:59,272
are conducting
cutting edge research

178
00:08:59,272 --> 00:09:02,308
on some of the key challenges I
described earlier, whether it's

179
00:09:02,308 --> 00:09:05,411
climate change, health care,
advanced manufacturing,

180
00:09:05,411 --> 00:09:10,249
generative AI, and so much more,
by becoming even more embedded

181
00:09:10,249 --> 00:09:11,651
in this ecosystem.

182
00:09:11,651 --> 00:09:12,752
And what does that mean?

183
00:09:12,752 --> 00:09:15,521
What it means is more
collaborative research,

184
00:09:15,521 --> 00:09:17,156
more collaborative teaching.

185
00:09:17,156 --> 00:09:19,792
Between Sloan and the
rest of the institute,

186
00:09:19,792 --> 00:09:24,030
I believe that MIT Sloan can
help translate innovations

187
00:09:24,030 --> 00:09:27,600
in these and other areas
into new enterprises,

188
00:09:27,600 --> 00:09:30,536
into new business models,
into new policies,

189
00:09:30,536 --> 00:09:34,507
into new ways of thinking about
the world and the economy.

190
00:09:34,507 --> 00:09:38,411
This is Sloan's role
in the MIT ecosystem,

191
00:09:38,411 --> 00:09:41,847
is to play that translational
management role.

192
00:09:41,847 --> 00:09:43,983
And let me just
elaborate on this.

193
00:09:43,983 --> 00:09:47,186
As I said, MIT's Sloan
faculty already very

194
00:09:47,186 --> 00:09:50,189
actively involved in many of
the presidential initiatives.

195
00:09:50,189 --> 00:09:53,759
When I think about the GenAI
or climate, even MITHIC,

196
00:09:53,759 --> 00:09:56,362
we have Sloan faculty who are
involved in either the steering

197
00:09:56,362 --> 00:09:59,065
committees or
co-leading these things.

198
00:09:59,065 --> 00:10:00,132
And this is great.

199
00:10:00,132 --> 00:10:03,803
This is a way that we're
bringing people together.

200
00:10:03,803 --> 00:10:06,105
But we can do so much more.

201
00:10:06,105 --> 00:10:09,909
And the way that I think about
this is, how can MIT Sloan lower

202
00:10:09,909 --> 00:10:14,313
the barriers so that students
from all over the institute

203
00:10:14,313 --> 00:10:17,183
can take our courses,
maybe even earn a degree?

204
00:10:17,183 --> 00:10:19,685
How can MIT Sloan
begin to develop

205
00:10:19,685 --> 00:10:22,822
with other parts of MIT
cutting-edge certificate

206
00:10:22,822 --> 00:10:25,424
programs or other
courses of study

207
00:10:25,424 --> 00:10:27,994
where we're bringing together
people from engineering

208
00:10:27,994 --> 00:10:30,396
and science and
humanities with Sloan

209
00:10:30,396 --> 00:10:32,932
to actually address some
of these big issues?

210
00:10:32,932 --> 00:10:35,301
I think there's so
much that we can do,

211
00:10:35,301 --> 00:10:37,503
which is not only
good for MIT, but it's

212
00:10:37,503 --> 00:10:40,640
a way of really reimagining
management education

213
00:10:40,640 --> 00:10:42,308
and management research.

214
00:10:42,308 --> 00:10:45,778
Now when I think
about this, I think

215
00:10:45,778 --> 00:10:49,615
about increasing MIT'S Sloan's
embeddedness within MIT means

216
00:10:49,615 --> 00:10:53,719
more than simply deepening the
ties between, say, the technical

217
00:10:53,719 --> 00:10:55,855
and the commercial
sides of campus.

218
00:10:55,855 --> 00:10:59,659
It also requires that MIT
Sloan work more closely

219
00:10:59,659 --> 00:11:03,729
with colleagues in SHASS and
reinvigorate its long standing

220
00:11:03,729 --> 00:11:08,234
tradition focused on the
human side of enterprise.

221
00:11:08,234 --> 00:11:11,737
As many in this room
may or may not know,

222
00:11:11,737 --> 00:11:15,541
MIT Sloan has a long and
distinguished history

223
00:11:15,541 --> 00:11:18,811
of focusing on the human
dimensions of business.

224
00:11:18,811 --> 00:11:22,014
In its early days during
the post-war boom,

225
00:11:22,014 --> 00:11:24,417
the US enterprise,
as US enterprises

226
00:11:24,417 --> 00:11:26,419
were growing and
trying to figure out

227
00:11:26,419 --> 00:11:29,522
how best to engage and
motivate their employees,

228
00:11:29,522 --> 00:11:32,191
Sloan Professor Douglas
McGregor published

229
00:11:32,191 --> 00:11:35,795
an important book called The
Human Side of Enterprise.

230
00:11:35,795 --> 00:11:37,663
It was published in 1959.

231
00:11:37,663 --> 00:11:42,334
And in that book, McGregor
outlined Theory X and Theory Y,

232
00:11:42,334 --> 00:11:45,905
opposing theories
describing why people work

233
00:11:45,905 --> 00:11:47,740
and how they should be managed.

234
00:11:47,740 --> 00:11:52,478
Theory X assumes that workers
are inherently unmotivated.

235
00:11:52,478 --> 00:11:57,049
And this leads to a
top-down style of management

236
00:11:57,049 --> 00:12:00,319
based on compliance
and a mix of carrots

237
00:12:00,319 --> 00:12:04,090
and sticks to reward
or to punish employees.

238
00:12:04,090 --> 00:12:06,659
Theory Y, on the
other hand, assumes

239
00:12:06,659 --> 00:12:11,163
that employees are intrinsically
motivated to do their best work

240
00:12:11,163 --> 00:12:15,000
and to contribute to the
organizations that employ them.

241
00:12:15,000 --> 00:12:17,870
This leads to a very
different management style,

242
00:12:17,870 --> 00:12:20,139
one that empowers
workers, that gives them

243
00:12:20,139 --> 00:12:22,341
greater discretion
over their jobs,

244
00:12:22,341 --> 00:12:25,811
and cultivates higher
levels of engagement.

245
00:12:25,811 --> 00:12:30,750
McGregor was only one of a
long list of MIT Sloan faculty

246
00:12:30,750 --> 00:12:33,152
who worked on this more
human-centric approach

247
00:12:33,152 --> 00:12:34,386
to management.

248
00:12:34,386 --> 00:12:36,522
And I think of the
work of Lotte Bailyn

249
00:12:36,522 --> 00:12:41,393
or Ed Schein on organizational
culture, or of Tom Kochan,

250
00:12:41,393 --> 00:12:44,230
Bob McKenzie, and Paul
Osterman on what they called

251
00:12:44,230 --> 00:12:46,198
high performance work systems.

252
00:12:46,198 --> 00:12:49,235
They fall clearly
in this tradition.

253
00:12:49,235 --> 00:12:53,005
I see my own research on labor
standards and global supply

254
00:12:53,005 --> 00:12:55,441
chains following this tradition.

255
00:12:55,441 --> 00:12:57,977
And faculty and students
in what Sloan now

256
00:12:57,977 --> 00:13:00,913
calls the Work in
Organizational Studies group,

257
00:13:00,913 --> 00:13:03,516
continue this important
line of research,

258
00:13:03,516 --> 00:13:07,086
as do our colleagues at the
MIT Leadership Center, which

259
00:13:07,086 --> 00:13:08,954
is also based on Sloan.

260
00:13:08,954 --> 00:13:13,025
And so for Sloan to deepen and
expand and expand this work,

261
00:13:13,025 --> 00:13:14,760
we need to increase
our collaboration

262
00:13:14,760 --> 00:13:18,130
with colleagues in SHASS
and across the institute.

263
00:13:18,130 --> 00:13:21,033
And this is why MITHIC
is so important for MIT,

264
00:13:21,033 --> 00:13:23,969
but also so important
for MIT Sloan.

265
00:13:23,969 --> 00:13:28,941
I believe that tapping into all,
every part of MIT, everything

266
00:13:28,941 --> 00:13:33,679
that has MIT to offer, would
help MIT Sloan chart the future

267
00:13:33,679 --> 00:13:36,515
to shape how new
technologies like AI

268
00:13:36,515 --> 00:13:39,285
will reconfigure
industries and careers,

269
00:13:39,285 --> 00:13:42,288
how new enterprises
will be created and run,

270
00:13:42,288 --> 00:13:44,657
how individuals
will work and live,

271
00:13:44,657 --> 00:13:47,827
how business practices will
become more sustainable,

272
00:13:47,827 --> 00:13:51,463
and how national economies
will develop and adapt.

273
00:13:51,463 --> 00:13:55,167
It's an incredibly exciting
time to be at MIT--

274
00:13:55,167 --> 00:13:57,036
to be back at MIT.

275
00:13:57,036 --> 00:13:58,337
So let me illustrate--

276
00:13:58,337 --> 00:13:59,705
And I'm almost done.

277
00:13:59,705 --> 00:14:03,309
Let me illustrate how we can
together do this important work

278
00:14:03,309 --> 00:14:06,712
by highlighting some important
research on GenAI that

279
00:14:06,712 --> 00:14:11,350
is already taking place at
both MIT and at MIT Sloan.

280
00:14:11,350 --> 00:14:14,086
Now as you all know,
Americans today

281
00:14:14,086 --> 00:14:17,590
are both ambivalent
and anxious about AI

282
00:14:17,590 --> 00:14:21,093
and its impact on their
jobs, on the economy,

283
00:14:21,093 --> 00:14:23,495
and on society as a whole.

284
00:14:23,495 --> 00:14:25,331
Many see opportunity.

285
00:14:25,331 --> 00:14:29,735
62% of respondents in
a recent Gallup survey

286
00:14:29,735 --> 00:14:32,137
believe that AI will
increase productivity.

287
00:14:32,137 --> 00:14:35,875
53% believe that it will
lead to economic growth.

288
00:14:35,875 --> 00:14:43,382
But still, 61% of respondents
in this Gallup survey

289
00:14:43,382 --> 00:14:47,019
think that AI will destroy
more jobs than it will create.

290
00:14:47,019 --> 00:14:50,556
And nearly half, 47%
of the respondents,

291
00:14:50,556 --> 00:14:52,958
think that it will
destroy more businesses

292
00:14:52,958 --> 00:14:54,793
than it will recreate.

293
00:14:54,793 --> 00:14:58,631
These are real concerns
from an anxious population

294
00:14:58,631 --> 00:15:02,001
voiced at a time of great
economic and political

295
00:15:02,001 --> 00:15:03,302
uncertainty.

296
00:15:03,302 --> 00:15:06,538
This is a critical moment,
with enormous consequences

297
00:15:06,538 --> 00:15:10,476
for the workforce, for
organizations, and for humanity.

298
00:15:10,476 --> 00:15:13,545
And as the latest generation
of artificial intelligence

299
00:15:13,545 --> 00:15:17,549
leaves its nascent phase, we
are confronted with a choice

300
00:15:17,549 --> 00:15:19,852
about which path to take.

301
00:15:19,852 --> 00:15:22,321
Will we deploy AI to
eliminate millions

302
00:15:22,321 --> 00:15:24,423
of jobs across the economy?

303
00:15:24,423 --> 00:15:27,626
Or will we use it to
empower the workforce

304
00:15:27,626 --> 00:15:30,930
and enhance our
human capabilities?

305
00:15:30,930 --> 00:15:34,800
Fortunately, colleagues
at MIT and MIT Sloan

306
00:15:34,800 --> 00:15:38,170
are already doing important
work to show the viability

307
00:15:38,170 --> 00:15:39,705
of the second path.

308
00:15:39,705 --> 00:15:43,909
For example, in their 2023
book, Power and Progress,

309
00:15:43,909 --> 00:15:46,612
Daron Acemoglu and
Simon Johnson argue

310
00:15:46,612 --> 00:15:49,815
for recharting the
course of this technology

311
00:15:49,815 --> 00:15:53,252
so that it promotes shared
prosperity and complements

312
00:15:53,252 --> 00:15:56,722
rather than substitutes
for the work of humans.

313
00:15:56,722 --> 00:16:00,993
Writing later with another
MIT colleague, David Autor,

314
00:16:00,993 --> 00:16:04,663
the pair argue that the
direction of AI development

315
00:16:04,663 --> 00:16:08,100
is a choice, and argue
that leaders and educators

316
00:16:08,100 --> 00:16:13,038
must choose a path of
machines in service of minds.

317
00:16:13,038 --> 00:16:16,709
But what does this mean in the
context of today's workforce

318
00:16:16,709 --> 00:16:17,843
and workplace?

319
00:16:17,843 --> 00:16:20,813
How do we create
organizations and paths

320
00:16:20,813 --> 00:16:25,484
that travel this human
centric, worker friendly path?

321
00:16:25,484 --> 00:16:27,553
Part of the answer
lies in research

322
00:16:27,553 --> 00:16:30,322
from MIT Sloan Professor
Roberto Rigobon

323
00:16:30,322 --> 00:16:33,993
and postdoctoral
researcher Isabella Loaiza.

324
00:16:33,993 --> 00:16:40,733
These scholars analyzed 19,000
tasks across 950 job types

325
00:16:40,733 --> 00:16:44,436
and found five human
capabilities that are increasing

326
00:16:44,436 --> 00:16:47,072
in value as AI advances.

327
00:16:47,072 --> 00:16:52,745
These are empathy, presence,
opinion, creativity, and hope.

328
00:16:52,745 --> 00:16:57,249
This Epic framework points us
on a path towards upskilling

329
00:16:57,249 --> 00:16:59,151
workers, with a
focus on what they

330
00:16:59,151 --> 00:17:02,788
call the fundamental
qualities of human nature.

331
00:17:02,788 --> 00:17:05,124
These are simply a
few of the examples

332
00:17:05,124 --> 00:17:08,427
of the exciting and important
work taking place across MIT.

333
00:17:08,427 --> 00:17:10,596
There's so much more
work taking place,

334
00:17:10,596 --> 00:17:12,998
but work that allows
us to see the choice

335
00:17:12,998 --> 00:17:16,001
and begin to imagine how we
take that second choice that

336
00:17:16,001 --> 00:17:19,872
enhances our humanity
and empowers people.

337
00:17:19,872 --> 00:17:24,076
This work suggests that job
loss and de-skilling are not

338
00:17:24,076 --> 00:17:27,079
inevitable outcomes
in this new era of AI.

339
00:17:27,079 --> 00:17:31,316
From Theory X and
Theory Y to Rigobon

340
00:17:31,316 --> 00:17:35,087
and Loaiza's important work--

341
00:17:35,087 --> 00:17:39,158
I've now lost my notes--

342
00:17:39,158 --> 00:17:41,026
I'll find them.

343
00:17:41,026 --> 00:17:41,960
Here it is.

344
00:17:41,960 --> 00:17:46,565
Insightful, epic framework to
the new educational paradigms

345
00:17:46,565 --> 00:17:49,201
made possible through
initiatives like universal AI

346
00:17:49,201 --> 00:17:53,639
that was recently released
by the MIT Open Learning

347
00:17:53,639 --> 00:17:54,640
Initiative.

348
00:17:54,640 --> 00:18:00,913
MIT and MIT Sloan have a history
of charting and paving pathways

349
00:18:00,913 --> 00:18:03,916
to an exciting and
productive future of work

350
00:18:03,916 --> 00:18:06,552
that not only includes
humans, but makes

351
00:18:06,552 --> 00:18:08,687
the most of our humanity.

352
00:18:08,687 --> 00:18:11,657
Together, we can
invent this future.

353
00:18:11,657 --> 00:18:12,491
Thank you very much.

354
00:18:12,491 --> 00:18:22,367
[APPLAUSE]

355
00:18:26,338 --> 00:18:28,941
So imagine that
you're Dean of SHASS,

356
00:18:28,941 --> 00:18:33,312
and you learn that
someone like Rick

357
00:18:33,312 --> 00:18:36,014
is going to be your
fellow dean, someone

358
00:18:36,014 --> 00:18:37,816
you're going to be able
to brainstorm with,

359
00:18:37,816 --> 00:18:39,952
someone who is going
to share insights.

360
00:18:39,952 --> 00:18:41,186
I mean, it's extraordinary.

361
00:18:41,186 --> 00:18:44,256
It's extraordinary to
have you as a fellow dean.

362
00:18:44,256 --> 00:18:45,023
Likewise.

363
00:18:45,023 --> 00:18:48,794

364
00:18:48,794 --> 00:18:52,798
So you talked a
little bit about ways

365
00:18:52,798 --> 00:18:57,336
in which the world has changed,
and business schools have

366
00:18:57,336 --> 00:18:58,670
been slow to adapt.

367
00:18:58,670 --> 00:19:02,608
I was hoping you could speak
about that more broadly.

368
00:19:02,608 --> 00:19:06,879
So, as you said, we're
at a pivotal time.

369
00:19:06,879 --> 00:19:11,016
How do you think higher
education more broadly

370
00:19:11,016 --> 00:19:12,584
should adapt to the time?

371
00:19:12,584 --> 00:19:16,522

372
00:19:16,522 --> 00:19:19,258
Big question.

373
00:19:19,258 --> 00:19:20,492
I don't have all the answers--

374
00:19:20,492 --> 00:19:25,030
I don't have a comprehensive
answer to that question.

375
00:19:25,030 --> 00:19:29,201
But I think we have fragments
of what could maybe be

376
00:19:29,201 --> 00:19:32,304
woven together into an answer.

377
00:19:32,304 --> 00:19:34,640
And that's why I think this
is such an important moment

378
00:19:34,640 --> 00:19:38,143
at MIT and for MIT Sloan,
because of the assets that we

379
00:19:38,143 --> 00:19:40,245
already have.

380
00:19:40,245 --> 00:19:41,947
A couple of things.

381
00:19:41,947 --> 00:19:46,985
One is for education, I don't
think the traditional model

382
00:19:46,985 --> 00:19:49,288
of education, of
just being in a room,

383
00:19:49,288 --> 00:19:51,823
passively sitting while
the professor, fountain

384
00:19:51,823 --> 00:19:54,660
of knowledge, is
spewing on and on works.

385
00:19:54,660 --> 00:19:56,428
I don't think it's
worked for a long time,

386
00:19:56,428 --> 00:19:59,198
but it certainly
doesn't work today.

387
00:19:59,198 --> 00:20:02,601
Instead, I think that we
should reimagine education

388
00:20:02,601 --> 00:20:05,337
using what we already
do well, which

389
00:20:05,337 --> 00:20:08,840
is we have great work that's
taking place in the classroom

390
00:20:08,840 --> 00:20:11,743
and the labs, et cetera.

391
00:20:11,743 --> 00:20:13,245
That should continue.

392
00:20:13,245 --> 00:20:16,715
We got really good
at using technology

393
00:20:16,715 --> 00:20:21,386
to do virtual learning, online
learning, whether it was

394
00:20:21,386 --> 00:20:22,921
synchronous or asynchronous.

395
00:20:22,921 --> 00:20:25,357
And again, we have Open
Learning and other assets

396
00:20:25,357 --> 00:20:27,326
at MIT that continue to do that.

397
00:20:27,326 --> 00:20:29,661
And we have this
tradition of what

398
00:20:29,661 --> 00:20:31,496
we call at Sloan
action learning, which

399
00:20:31,496 --> 00:20:35,167
is being in the world, whether
it's the MISTI programs that

400
00:20:35,167 --> 00:20:39,972
exist in SHASS, or some of
the other more clinical work

401
00:20:39,972 --> 00:20:43,375
that takes place
across the university,

402
00:20:43,375 --> 00:20:45,877
or what we call action
learning at Sloan,

403
00:20:45,877 --> 00:20:48,480
I think that's really important
because it's actually embedding

404
00:20:48,480 --> 00:20:52,251
students in real organizations
with real challenges

405
00:20:52,251 --> 00:20:54,519
and applying what
they learn in the lab,

406
00:20:54,519 --> 00:20:58,190
in the classroom, et cetera,
to try to solve those problems,

407
00:20:58,190 --> 00:20:59,958
which allows them to
actually-- as we know,

408
00:20:59,958 --> 00:21:02,461
because we're teachers, that's
when you actually figure out

409
00:21:02,461 --> 00:21:04,663
what you know, is when you
have to actually teach it.

410
00:21:04,663 --> 00:21:07,499
So it's going to
help them learn that.

411
00:21:07,499 --> 00:21:09,601
But also, even more
importantly, it's

412
00:21:09,601 --> 00:21:12,104
going to show them what they
still don't learn so that they

413
00:21:12,104 --> 00:21:13,672
come back hungry to learn more.

414
00:21:13,672 --> 00:21:17,075
And it's those cycles, repeated
cycles that are important.

415
00:21:17,075 --> 00:21:19,344
We have this, but
they're not connected.

416
00:21:19,344 --> 00:21:21,246
And I think we have
to connect the dots.

417
00:21:21,246 --> 00:21:22,781
And when I think
about this, I think

418
00:21:22,781 --> 00:21:25,350
that an education
at MIT Sloan, but I

419
00:21:25,350 --> 00:21:28,387
would say it should
be for MIT as a whole,

420
00:21:28,387 --> 00:21:30,322
should be a seamless experience.

421
00:21:30,322 --> 00:21:32,491
It should be something
that takes place on campus,

422
00:21:32,491 --> 00:21:35,961
off campus, in
person, virtually,

423
00:21:35,961 --> 00:21:38,563
synchronously,
asynchronously, et cetera.

424
00:21:38,563 --> 00:21:41,433
And if we can connect those
dots, then what we can do

425
00:21:41,433 --> 00:21:44,770
is have students learning and
really, really interesting ways.

426
00:21:44,770 --> 00:21:47,639
And that will, I think, allow us
to actually meet the challenges

427
00:21:47,639 --> 00:21:48,573
that I talked about.

428
00:21:48,573 --> 00:21:54,846
I mean, the dream that I have is
that we have a student from MIT

429
00:21:54,846 --> 00:21:56,515
who is maybe--

430
00:21:56,515 --> 00:21:59,885
since I was one of the founders
of the MIT Italy program,

431
00:21:59,885 --> 00:22:01,753
I'm going to use
that as an example.

432
00:22:01,753 --> 00:22:03,488
They're in Bologna.

433
00:22:03,488 --> 00:22:07,125
They're working for, doing
an internship at Ferrari,

434
00:22:07,125 --> 00:22:08,727
or something like that.

435
00:22:08,727 --> 00:22:12,364
They are taking an Italian
language or literature course

436
00:22:12,364 --> 00:22:14,733
at the University of
Bologna, but they're also

437
00:22:14,733 --> 00:22:17,769
online taking some classes
here so they can make progress

438
00:22:17,769 --> 00:22:18,870
towards their degree.

439
00:22:18,870 --> 00:22:21,373
So they don't have to
have the on/off switch.

440
00:22:21,373 --> 00:22:22,574
They're connected.

441
00:22:22,574 --> 00:22:24,810
We can do that because
we have the assets.

442
00:22:24,810 --> 00:22:27,679
And I think if we do
that, we can better

443
00:22:27,679 --> 00:22:29,648
meet the needs of our
students, better meet

444
00:22:29,648 --> 00:22:32,684
the needs of their
employers, future employers,

445
00:22:32,684 --> 00:22:34,386
and allow us to
actually have even

446
00:22:34,386 --> 00:22:35,987
greater impact in the world.

447
00:22:35,987 --> 00:22:37,389
Yes, I love that vision.

448
00:22:37,389 --> 00:22:39,291
And I mean, here's
one way of emphasizing

449
00:22:39,291 --> 00:22:41,560
why I think you're so right,
that the model can't just

450
00:22:41,560 --> 00:22:45,397
be a professor spewing
information on students.

451
00:22:45,397 --> 00:22:48,367
In the age of AI, to
a first approximation,

452
00:22:48,367 --> 00:22:50,602
all information is available
to everyone always.

453
00:22:50,602 --> 00:22:52,437
So of course, that
can't be the model.

454
00:22:52,437 --> 00:22:58,543
Now, here's a way of getting
deeper into this issue.

455
00:22:58,543 --> 00:23:05,617
So, as emerged in
your presentation,

456
00:23:05,617 --> 00:23:10,455
AI is changing the nature
of the labor market.

457
00:23:10,455 --> 00:23:14,860
It's changing what companies
expect of employees.

458
00:23:14,860 --> 00:23:17,162
And of course, that
affects higher ed

459
00:23:17,162 --> 00:23:21,233
because it affects the ways
in which we can bring value

460
00:23:21,233 --> 00:23:23,702
to students who are
hoping to get jobs,

461
00:23:23,702 --> 00:23:25,804
and really to students
who are hoping

462
00:23:25,804 --> 00:23:29,341
to find a path to financial
stability in their lives.

463
00:23:29,341 --> 00:23:33,845
So could you say a little
bit more first about

464
00:23:33,845 --> 00:23:37,883
how you expect the labor
market is going to change,

465
00:23:37,883 --> 00:23:41,319
and what the paths to financial
stability of the future

466
00:23:41,319 --> 00:23:42,387
are going to look like?

467
00:23:42,387 --> 00:23:45,757
And secondly, what MIT can
do to meet that challenge?

468
00:23:45,757 --> 00:23:48,660
Yeah, so the way
that I understand

469
00:23:48,660 --> 00:23:50,796
what might be happening
to the labor market

470
00:23:50,796 --> 00:23:53,064
is informed by our
wonderful colleagues,

471
00:23:53,064 --> 00:23:56,902
whether it's David Autor
and the work that he does,

472
00:23:56,902 --> 00:23:59,137
[? Daron, ?] Simon, et cetera.

473
00:23:59,137 --> 00:24:01,873
And it seems like
this is a version,

474
00:24:01,873 --> 00:24:06,178
maybe a more extreme version
of what we've seen before,

475
00:24:06,178 --> 00:24:11,049
where certain skills will
be automated or eliminated

476
00:24:11,049 --> 00:24:13,985
as a result of AI,
and others won't.

477
00:24:13,985 --> 00:24:19,691
And in the past, those have
been, more task-oriented

478
00:24:19,691 --> 00:24:21,393
routine jobs.

479
00:24:21,393 --> 00:24:23,929
Now people are thinking
about what they may be,

480
00:24:23,929 --> 00:24:30,669
whether it's a lower, more basic
analytical sort of analyst kinds

481
00:24:30,669 --> 00:24:32,904
of jobs, as opposed to others.

482
00:24:32,904 --> 00:24:35,440
We have to see where that goes.

483
00:24:35,440 --> 00:24:37,676
But if that's true, that
some of the things that you

484
00:24:37,676 --> 00:24:41,613
can do with generative AI, you
don't require the basic level

485
00:24:41,613 --> 00:24:43,048
of people who are
doing just a lot

486
00:24:43,048 --> 00:24:47,552
of grunt research and
easy analysis, then

487
00:24:47,552 --> 00:24:49,654
what can we do for them?

488
00:24:49,654 --> 00:24:51,122
And this is what
we've been doing

489
00:24:51,122 --> 00:24:53,625
at MIT Sloan in the
last several months

490
00:24:53,625 --> 00:24:57,329
is the genie is out of the
bottle in terms of gen AI.

491
00:24:57,329 --> 00:24:58,497
You can't put it back.

492
00:24:58,497 --> 00:25:00,899
It's not going to be
like, oh, you're cheating.

493
00:25:00,899 --> 00:25:03,268
You can't use it.

494
00:25:03,268 --> 00:25:05,470
I think that's not the
way to think about it.

495
00:25:05,470 --> 00:25:08,173
I think what we have to do is,
how do we use this incredibly

496
00:25:08,173 --> 00:25:12,677
powerful tool to enhance
our human capabilities,

497
00:25:12,677 --> 00:25:15,380
our reasoning, our analytical
skills, our decision making?

498
00:25:15,380 --> 00:25:17,415
And so what we're
doing at MIT Sloan

499
00:25:17,415 --> 00:25:21,086
is we're making sure that
everyone students, but also

500
00:25:21,086 --> 00:25:24,122
staff and faculty,
understand the basic-- are

501
00:25:24,122 --> 00:25:27,025
literate enough about the
basic models and tools.

502
00:25:27,025 --> 00:25:30,562
So we do already a boot
camp for orientation

503
00:25:30,562 --> 00:25:33,331
of our master's students.

504
00:25:33,331 --> 00:25:37,102
But we are now inviting
everyone in the community

505
00:25:37,102 --> 00:25:40,605
to use the universal AI
that was recently released

506
00:25:40,605 --> 00:25:42,741
as a way of being educated.

507
00:25:42,741 --> 00:25:46,444
Then what we're doing is we're
weaving AI into all our courses.

508
00:25:46,444 --> 00:25:48,380
So we already have a
whole bunch of electives

509
00:25:48,380 --> 00:25:49,681
that are really, really great.

510
00:25:49,681 --> 00:25:51,449
But rather than just
have those electives,

511
00:25:51,449 --> 00:25:54,119
how do we weave in
the basics of AI

512
00:25:54,119 --> 00:25:58,023
into finance, into marketing,
into strategy, into operations?

513
00:25:58,023 --> 00:26:00,525
And so it's not instead of.

514
00:26:00,525 --> 00:26:05,096
It's actually showing how you
use those tools to enhance

515
00:26:05,096 --> 00:26:06,998
your human decision
making, reasoning,

516
00:26:06,998 --> 00:26:09,768
analytics using this tool.

517
00:26:09,768 --> 00:26:13,238
And we're going to do it this
way, because I think that way,

518
00:26:13,238 --> 00:26:15,240
we lean into this technology.

519
00:26:15,240 --> 00:26:19,878
We equip our people for the
future of future developments

520
00:26:19,878 --> 00:26:21,546
of the labor market.

521
00:26:21,546 --> 00:26:23,281
We lean into the
MIT brand, which

522
00:26:23,281 --> 00:26:25,717
I think is very, very
important to distinguish

523
00:26:25,717 --> 00:26:28,620
our graduates from others.

524
00:26:28,620 --> 00:26:30,722
And it allows us
to actually design

525
00:26:30,722 --> 00:26:34,359
curriculum that can
quickly be adapted

526
00:26:34,359 --> 00:26:35,994
since AI is moving so quickly.

527
00:26:35,994 --> 00:26:38,196
So if we had the
module around AI,

528
00:26:38,196 --> 00:26:40,231
as opposed to the
12-week course,

529
00:26:40,231 --> 00:26:43,401
it's much easier to adapt
that, layering it on top

530
00:26:43,401 --> 00:26:45,537
of the finance,
strategy, ops, et cetera.

531
00:26:45,537 --> 00:26:47,105
So that's how we're
thinking about it.

532
00:26:47,105 --> 00:26:49,040
And I would say based
on conversations

533
00:26:49,040 --> 00:26:51,042
that we've all had
as faculty, that

534
00:26:51,042 --> 00:26:53,244
thinking about it
that way might be

535
00:26:53,244 --> 00:26:55,246
a good way across
the disciplines,

536
00:26:55,246 --> 00:26:55,747
I love it.

537
00:26:55,747 --> 00:27:00,318
I mean, you would think
that if you were a company

538
00:27:00,318 --> 00:27:02,854
and you're hiring, the
absolute first thing you

539
00:27:02,854 --> 00:27:08,460
want is for your people you hire
to be not just literate in AI,

540
00:27:08,460 --> 00:27:10,395
but they'd be the
kind of person who--

541
00:27:10,395 --> 00:27:15,867
absolutely the kind of person
whose work is empowered by AI.

542
00:27:15,867 --> 00:27:18,069
So I totally agree about that.

543
00:27:18,069 --> 00:27:23,441
Now, what about
expected disruptions

544
00:27:23,441 --> 00:27:26,745
and just what an entry-level
position might look like?

545
00:27:26,745 --> 00:27:31,683
So here's an example that I find
both illuminating and scary.

546
00:27:31,683 --> 00:27:34,519
So a law firm--

547
00:27:34,519 --> 00:27:37,522
entry-level people in
a law firm up to now

548
00:27:37,522 --> 00:27:41,793
have done tasks
that, in many cases,

549
00:27:41,793 --> 00:27:46,297
can be done better and certainly
more cheaply using ChatGPT.

550
00:27:46,297 --> 00:27:47,799
So that suggests
that we might move

551
00:27:47,799 --> 00:27:51,736
to a system in which a law
firm is just going to hire

552
00:27:51,736 --> 00:27:54,305
fewer entry-level people.

553
00:27:54,305 --> 00:27:58,376
But of course, the world still
is going to need top lawyers.

554
00:27:58,376 --> 00:28:01,346
So there still is a
path to getting there,

555
00:28:01,346 --> 00:28:03,682
but it just becomes
much more narrow.

556
00:28:03,682 --> 00:28:07,986
So how do we in higher
education prepare

557
00:28:07,986 --> 00:28:10,288
for a world in which
these paths are

558
00:28:10,288 --> 00:28:13,425
going to be much narrower
than they are today?

559
00:28:13,425 --> 00:28:15,627
It's a great question, and
we're already seeing that.

560
00:28:15,627 --> 00:28:16,928
We're already seeing it.

561
00:28:16,928 --> 00:28:19,464
Not just in the
legal profession,

562
00:28:19,464 --> 00:28:22,967
but even in the management area.

563
00:28:22,967 --> 00:28:26,271
It used to be that some of the
top consulting or investment

564
00:28:26,271 --> 00:28:30,675
banking companies would come,
and they would hire 20 or 30

565
00:28:30,675 --> 00:28:32,377
of Sloan graduates at a time.

566
00:28:32,377 --> 00:28:34,579
Every year, there was
these huge cohorts.

567
00:28:34,579 --> 00:28:38,717
They still come, and they're
hiring a number of our students,

568
00:28:38,717 --> 00:28:42,520
but in smaller numbers, because
they don't need as many of them

569
00:28:42,520 --> 00:28:45,523
as they used to because
of the, more or less,

570
00:28:45,523 --> 00:28:49,227
automation of some of
those tasks because of AI.

571
00:28:49,227 --> 00:28:53,431
And so let me talk about how I
think we should operate at MIT,

572
00:28:53,431 --> 00:28:55,467
and then whether or not
that's a model for higher

573
00:28:55,467 --> 00:28:56,668
education in general.

574
00:28:56,668 --> 00:28:58,002
It may or may not be.

575
00:28:58,002 --> 00:29:01,506
The way that I think
about this for MIT is,

576
00:29:01,506 --> 00:29:03,341
how do we really
produce students

577
00:29:03,341 --> 00:29:05,376
that understand the
technology, that

578
00:29:05,376 --> 00:29:08,546
have deep technical or
functional knowledge,

579
00:29:08,546 --> 00:29:12,217
and know something about
how to manage people,

580
00:29:12,217 --> 00:29:16,688
how to engage with people, how
to run organizations, et cetera?

581
00:29:16,688 --> 00:29:19,157
And if we do that,
that will be unmatched.

582
00:29:19,157 --> 00:29:23,561
And so when I think about MIT
Sloan being even more embedded

583
00:29:23,561 --> 00:29:28,600
in the rest of MIT, and thinking
about innovative new courses,

584
00:29:28,600 --> 00:29:31,703
or certificate programs,
maybe even degree programs.

585
00:29:31,703 --> 00:29:35,306
I think about how might we
bring together, I don't know,

586
00:29:35,306 --> 00:29:39,144
engineering students and
faculty working on fusion

587
00:29:39,144 --> 00:29:46,484
with Sloan students who
care about climate and less

588
00:29:46,484 --> 00:29:48,586
carbon-intensive energy?

589
00:29:48,586 --> 00:29:50,955
And can they come
together, learn enough

590
00:29:50,955 --> 00:29:53,291
about the technology,
learn enough

591
00:29:53,291 --> 00:29:54,893
about how do you
manage people and run

592
00:29:54,893 --> 00:29:56,427
organizations, et cetera?

593
00:29:56,427 --> 00:29:59,164
And together, working
together, creating

594
00:29:59,164 --> 00:30:03,301
a cohort of people who have
skills that would be unmatched.

595
00:30:03,301 --> 00:30:04,903
And you could do
it around health.

596
00:30:04,903 --> 00:30:07,605
You could do it around
advanced manufacturing.

597
00:30:07,605 --> 00:30:10,508
You could do it on so
many different areas.

598
00:30:10,508 --> 00:30:13,311
And again, and it's not just
the technical and commercial.

599
00:30:13,311 --> 00:30:16,447
It's the human side that we
were talking about earlier.

600
00:30:16,447 --> 00:30:22,720
I think if we do that, our
graduates will find that pathway

601
00:30:22,720 --> 00:30:25,089
not as narrow as others.

602
00:30:25,089 --> 00:30:29,427
I don't know if that's
possible for everyone

603
00:30:29,427 --> 00:30:32,330
just because of what's
going on in the world.

604
00:30:32,330 --> 00:30:34,232
But I know what's
possible for us,

605
00:30:34,232 --> 00:30:39,270
and I really believe in the
power of demonstration projects.

606
00:30:39,270 --> 00:30:41,406
So I think that if we can
show that it's happening--

607
00:30:41,406 --> 00:30:44,242
that's why I think the New
Educational Initiative is

608
00:30:44,242 --> 00:30:47,245
such a cool thing that's
going on here, as well.

609
00:30:47,245 --> 00:30:50,815
If we can demonstrate its
possibility, then maybe others,

610
00:30:50,815 --> 00:30:54,152
in their own ways, could
also learn and do something.

611
00:30:54,152 --> 00:30:54,986
That's what I think.

612
00:30:54,986 --> 00:30:56,054
No, I totally agree.

613
00:30:56,054 --> 00:30:59,757
Because surely one
thing that's happening

614
00:30:59,757 --> 00:31:03,828
is that narrow technical skills
are just going to-- they're

615
00:31:03,828 --> 00:31:05,997
going to become
obsolete so quickly

616
00:31:05,997 --> 00:31:08,366
that that's not the way
for higher education

617
00:31:08,366 --> 00:31:10,168
to bring value to students.

618
00:31:10,168 --> 00:31:12,136
And you mentioned
the EPIC framework,

619
00:31:12,136 --> 00:31:13,738
which I like in its own.

620
00:31:13,738 --> 00:31:16,207
But also I like having
MITHIC and EPIC.

621
00:31:16,207 --> 00:31:20,545

622
00:31:20,545 --> 00:31:25,049
I definitely think that
those are key skills.

623
00:31:25,049 --> 00:31:26,551
But I think leadership--

624
00:31:26,551 --> 00:31:28,620
I think leadership is
a key skill, as well.

625
00:31:28,620 --> 00:31:33,758
So the way I imagine
high performing-humans

626
00:31:33,758 --> 00:31:36,394
in the age of AI is, part
of what you need to do

627
00:31:36,394 --> 00:31:40,265
is lead a team, which is going
to include humans, but also AI.

628
00:31:40,265 --> 00:31:44,736
And because, more
broadly, AI is going

629
00:31:44,736 --> 00:31:48,439
to be very good at
accomplishing tasks.

630
00:31:48,439 --> 00:31:51,175
But humans are needed
to provide the judgment

631
00:31:51,175 --> 00:31:54,445
to decide what tasks
are worth executing on.

632
00:31:54,445 --> 00:31:58,182
And that is a human problem,
and it's a leadership problem.

633
00:31:58,182 --> 00:32:02,687
So I think there's no question
that we need to collaborate

634
00:32:02,687 --> 00:32:05,723
and that we need
to make it the case

635
00:32:05,723 --> 00:32:09,827
that you leave MIT with
this sort of skill.

636
00:32:09,827 --> 00:32:11,796
And I don't think
we need to abandon

637
00:32:11,796 --> 00:32:14,966
the idea that we're the world's
top technical institution.

638
00:32:14,966 --> 00:32:16,501
Because I think part
of what it means

639
00:32:16,501 --> 00:32:20,838
to be a top engineer in the age
of AI is to have these skills.

640
00:32:20,838 --> 00:32:22,740
I 100% agree with that.

641
00:32:22,740 --> 00:32:25,944
And I think this is actually
a really, really important

642
00:32:25,944 --> 00:32:32,617
message, is if MIT is
the institution that

643
00:32:32,617 --> 00:32:34,719
is saying it's not
just technology,

644
00:32:34,719 --> 00:32:38,790
it's also the human values,
it's the human reasoning,

645
00:32:38,790 --> 00:32:40,959
it's how do we interact
with one another,

646
00:32:40,959 --> 00:32:42,093
people will listen to that.

647
00:32:42,093 --> 00:32:43,995
Because they-- oh,
yeah, of course.

648
00:32:43,995 --> 00:32:48,032
They believe it, as opposed
to coming from elsewhere.

649
00:32:48,032 --> 00:32:50,568
And I believe it's actually
an incredible opportunity

650
00:32:50,568 --> 00:32:54,238
around leadership, but
also around values.

651
00:32:54,238 --> 00:32:57,442
When I think of
MIT Sloan's mission

652
00:32:57,442 --> 00:32:59,911
is to develop principle
innovative leaders who

653
00:32:59,911 --> 00:33:02,246
are going to improve the
world, that's what we're about.

654
00:33:02,246 --> 00:33:03,715
That's what we say we're about.

655
00:33:03,715 --> 00:33:05,817
And so if that's what we're
about, then, of course,

656
00:33:05,817 --> 00:33:07,552
we have to give a
cutting-edge education.

657
00:33:07,552 --> 00:33:10,555
So people can do
well by themselves,

658
00:33:10,555 --> 00:33:12,390
get good careers, et cetera.

659
00:33:12,390 --> 00:33:15,693
But also go and implement
that mission, make the world

660
00:33:15,693 --> 00:33:16,761
a better place.

661
00:33:16,761 --> 00:33:19,998
For them to do that, they
have to be good leaders.

662
00:33:19,998 --> 00:33:25,203
They have to really understand,
the complexity and the richness

663
00:33:25,203 --> 00:33:28,039
of humanity, et cetera.

664
00:33:28,039 --> 00:33:30,942
And they have to have not
only play a leadership, role,

665
00:33:30,942 --> 00:33:34,212
but actually have an
anchor around values.

666
00:33:34,212 --> 00:33:37,015
And one of the things that I
have loved about coming back--

667
00:33:37,015 --> 00:33:38,950
I mean, coming back--

668
00:33:38,950 --> 00:33:41,519
going away and
coming back, it's not

669
00:33:41,519 --> 00:33:43,955
like you don't see the
warts of the Institute.

670
00:33:43,955 --> 00:33:44,822
Of course you do.

671
00:33:44,822 --> 00:33:51,162
But you appreciate what
makes this place so special.

672
00:33:51,162 --> 00:33:55,500
And it's a community of smart
people doing important work,

673
00:33:55,500 --> 00:33:58,436
but who are anchored
with really great values.

674
00:33:58,436 --> 00:34:01,639
And I think that that's an asset
that we don't talk about enough,

675
00:34:01,639 --> 00:34:02,607
but we should.

676
00:34:02,607 --> 00:34:07,178
And so I think building on
the human side of enterprise,

677
00:34:07,178 --> 00:34:10,581
as I broadly described it,
is key not only for Sloan,

678
00:34:10,581 --> 00:34:12,817
but I think it's key for MIT.

679
00:34:12,817 --> 00:34:13,351
Yes.

680
00:34:13,351 --> 00:34:18,956
Now, here's something
that sometimes worries me.

681
00:34:18,956 --> 00:34:21,492
So I totally agree with
everything you said.

682
00:34:21,492 --> 00:34:25,496
I was once talking to someone
who thinks a lot about AI,

683
00:34:25,496 --> 00:34:27,832
and the future of the labor
market, and the age of AI.

684
00:34:27,832 --> 00:34:30,568
And I shared a version of
what you're talking about.

685
00:34:30,568 --> 00:34:32,537
And here's what he said.

686
00:34:32,537 --> 00:34:34,739
He said, yes, yes, yes.

687
00:34:34,739 --> 00:34:37,975
But I'm just worried that
when there's a career fair,

688
00:34:37,975 --> 00:34:43,915
and representative of Google
or some other big company

689
00:34:43,915 --> 00:34:48,686
is getting to know students,
the thing they're really

690
00:34:48,686 --> 00:34:50,988
going to care about is
whether they have the latest

691
00:34:50,988 --> 00:34:51,823
technical skills.

692
00:34:51,823 --> 00:34:55,927
And whether they seem like
just an interesting person,

693
00:34:55,927 --> 00:34:56,928
a good person.

694
00:34:56,928 --> 00:35:00,064
But at the end of
the day, companies

695
00:35:00,064 --> 00:35:02,800
aren't going to prioritize the
things we're talking about.

696
00:35:02,800 --> 00:35:04,802
And, of course, if that's
true, then students

697
00:35:04,802 --> 00:35:07,205
are going to notice, and
they're not going to value them.

698
00:35:07,205 --> 00:35:10,341
So do you think that what
this person said is right?

699
00:35:10,341 --> 00:35:12,844
Or do you think that
companies really, truly

700
00:35:12,844 --> 00:35:14,879
will value these
skills to the point

701
00:35:14,879 --> 00:35:17,381
that they're going to convey
that to prospective candidates?

702
00:35:17,381 --> 00:35:19,684
Yeah, so I can't speak
for all companies.

703
00:35:19,684 --> 00:35:24,822
But I think that your
interlocutor is wrong.

704
00:35:24,822 --> 00:35:28,226
And so some of you know this.

705
00:35:28,226 --> 00:35:31,329
Prior to coming back,
I worked at Apple.

706
00:35:31,329 --> 00:35:33,598
I ran their
corporate university,

707
00:35:33,598 --> 00:35:36,534
which is an interesting place
because it has recruits, faculty

708
00:35:36,534 --> 00:35:39,937
who are tenured faculty
at leading universities,

709
00:35:39,937 --> 00:35:41,739
as well as practitioners
who come up

710
00:35:41,739 --> 00:35:44,208
through the ranks of Apple,
and who are software engineers,

711
00:35:44,208 --> 00:35:46,344
or hardware engineers,
or marketing people who

712
00:35:46,344 --> 00:35:48,579
have a passion for education.

713
00:35:48,579 --> 00:35:53,217
And what I saw
there is, of course,

714
00:35:53,217 --> 00:35:58,089
the essential requirement is,
if you were going to be hired,

715
00:35:58,089 --> 00:35:59,390
you knew your stuff.

716
00:35:59,390 --> 00:35:59,891
Of course.

717
00:35:59,891 --> 00:36:03,227
You were good at technical,
or functional, et cetera.

718
00:36:03,227 --> 00:36:06,797
But what they also were
looking for is not--

719
00:36:06,797 --> 00:36:09,433
they just expect that if
you're hired, you're good.

720
00:36:09,433 --> 00:36:12,803
You're top of your game
at a technical level.

721
00:36:12,803 --> 00:36:14,705
But they were looking
for something else.

722
00:36:14,705 --> 00:36:17,909
And that something else is, can
you work well with other people,

723
00:36:17,909 --> 00:36:20,545
since work is cross-functional?

724
00:36:20,545 --> 00:36:23,247
You're working in teams all
the time, different teams

725
00:36:23,247 --> 00:36:24,382
to get things done.

726
00:36:24,382 --> 00:36:25,716
Do you know how to do that?

727
00:36:25,716 --> 00:36:27,351
Do you know how to
bring people along?

728
00:36:27,351 --> 00:36:29,053
Do you know when
to lead and when

729
00:36:29,053 --> 00:36:31,055
to sit back and let
other people lead?

730
00:36:31,055 --> 00:36:35,326
And are you guided by
a set of core values

731
00:36:35,326 --> 00:36:37,995
that, at Apple, are
really, really important?

732
00:36:37,995 --> 00:36:40,831
People were flushed out
not because they weren't

733
00:36:40,831 --> 00:36:44,368
good technically, but because
they didn't align with what

734
00:36:44,368 --> 00:36:46,037
the values were of the company.

735
00:36:46,037 --> 00:36:47,972
Now, I can only speak
about that one company.

736
00:36:47,972 --> 00:36:51,309
I don't know how it is exactly
in all the other companies.

737
00:36:51,309 --> 00:36:53,444
But I think it's
that combination

738
00:36:53,444 --> 00:36:55,146
is what people are looking for.

739
00:36:55,146 --> 00:36:58,082
And that's a combination
that MIT is very well

740
00:36:58,082 --> 00:36:59,350
positioned to deliver.

741
00:36:59,350 --> 00:36:59,951
I love that.

742
00:36:59,951 --> 00:37:02,153
I love that just as
an aspiration for MIT.

743
00:37:02,153 --> 00:37:04,689
So that it could just
be taken for granted

744
00:37:04,689 --> 00:37:06,891
that if you graduate
from MIT, of course,

745
00:37:06,891 --> 00:37:08,226
you're going to know your stuff.

746
00:37:08,226 --> 00:37:09,927
Of course, you're going to
have the top technical skills

747
00:37:09,927 --> 00:37:10,661
in the world.

748
00:37:10,661 --> 00:37:13,164
But you're also going to
have that extra element.

749
00:37:13,164 --> 00:37:15,266
Of course, you're going
to be an excellent leader.

750
00:37:15,266 --> 00:37:17,468
Of course, you're going
to have a moral compass.

751
00:37:17,468 --> 00:37:19,003
Of course, you're
going to understand

752
00:37:19,003 --> 00:37:22,240
the human side, the social,
ethical, political, economic

753
00:37:22,240 --> 00:37:22,773
context.

754
00:37:22,773 --> 00:37:23,641
I love that.

755
00:37:23,641 --> 00:37:25,710
Because of the education
that we can deliver as

756
00:37:25,710 --> 00:37:27,345
we're reinventing the education.

757
00:37:27,345 --> 00:37:27,845
Yes.

758
00:37:27,845 --> 00:37:28,980
Yes, yes, yes.

759
00:37:28,980 --> 00:37:32,016
We don't exactly deliver on it
yet, but we're getting there.

760
00:37:32,016 --> 00:37:33,884
But that is a vision.

761
00:37:33,884 --> 00:37:37,288
And I think that MITHIC
can be part of that vision.

762
00:37:37,288 --> 00:37:38,256
This is very exciting.

763
00:37:38,256 --> 00:37:43,060
OK, I like where we've
gotten to so far.

764
00:37:43,060 --> 00:37:45,997
Let me change tacks a
little bit and just ask you

765
00:37:45,997 --> 00:37:48,566
about how you got to this point.

766
00:37:48,566 --> 00:37:54,672
So, as Sally mentioned,
you actually got your PhD

767
00:37:54,672 --> 00:37:56,741
in political science at MIT.

768
00:37:56,741 --> 00:37:58,342
Can you tell us a
little bit about that

769
00:37:58,342 --> 00:38:01,245
and how that led to the
next steps in your career?

770
00:38:01,245 --> 00:38:02,446
Yeah.

771
00:38:02,446 --> 00:38:05,383
So one of the things, when we're
talking about labor markets

772
00:38:05,383 --> 00:38:07,952
and jobs, is I think
it's important for people

773
00:38:07,952 --> 00:38:09,887
to realize that it's not linear.

774
00:38:09,887 --> 00:38:12,990
It's actually really non-linear.

775
00:38:12,990 --> 00:38:15,526
And that's a good thing because
you pick up different skills.

776
00:38:15,526 --> 00:38:19,964
So I studied here in
MIT Political Science.

777
00:38:19,964 --> 00:38:21,632
Amazing department.

778
00:38:21,632 --> 00:38:23,267
I understand it's
a good department.

779
00:38:23,267 --> 00:38:24,068
That's what I hear.

780
00:38:24,068 --> 00:38:26,370
It's an excellent department.

781
00:38:26,370 --> 00:38:28,072
Did you hear that, Mr. Provost?

782
00:38:28,072 --> 00:38:33,010
It's an excellent
department, and I specialized

783
00:38:33,010 --> 00:38:34,278
in political economy.

784
00:38:34,278 --> 00:38:37,815
And the work that
I did was so MIT,

785
00:38:37,815 --> 00:38:43,621
which I was studying initially
how are industries adapting

786
00:38:43,621 --> 00:38:46,490
restructuring to
changes in technology

787
00:38:46,490 --> 00:38:48,893
and into market conditions.

788
00:38:48,893 --> 00:38:50,361
I did my dissertation in Italy.

789
00:38:50,361 --> 00:38:54,165
Later on, I did work in
Eastern Germany, et cetera.

790
00:38:54,165 --> 00:38:58,302
But as part of the work that I
did as a graduate student, which

791
00:38:58,302 --> 00:39:02,807
I loved, I was involved in
some of these institute-wide

792
00:39:02,807 --> 00:39:03,908
initiatives.

793
00:39:03,908 --> 00:39:06,744
The one that I was involved
in as a grad student was--

794
00:39:06,744 --> 00:39:08,479
later on, IT became
Made in America.

795
00:39:08,479 --> 00:39:09,246
It became this.

796
00:39:09,246 --> 00:39:11,349
It was called the
industrial performance,

797
00:39:11,349 --> 00:39:13,818
or the commission for industrial
productivity, or something

798
00:39:13,818 --> 00:39:17,221
like that, that had grad
students and faculty from all

799
00:39:17,221 --> 00:39:18,389
over the Institute.

800
00:39:18,389 --> 00:39:20,691
And we were trying to
understand the issue

801
00:39:20,691 --> 00:39:23,728
of American competitiveness
in a changing world market.

802
00:39:23,728 --> 00:39:25,896
And so there was a lot of
work being done in the US,

803
00:39:25,896 --> 00:39:28,265
but a lot of work that
was done comparatively.

804
00:39:28,265 --> 00:39:29,500
And I was involved in that.

805
00:39:29,500 --> 00:39:33,604
And I learned so much
by speaking and meeting

806
00:39:33,604 --> 00:39:36,841
colleagues in engineering,
and economics,

807
00:39:36,841 --> 00:39:39,477
and the different parts of MIT.

808
00:39:39,477 --> 00:39:41,545
And I think that
really imprinted itself

809
00:39:41,545 --> 00:39:46,283
on me, which was the importance
of interdisciplinary work,

810
00:39:46,283 --> 00:39:49,019
the importance of being out
in the world, in the field,

811
00:39:49,019 --> 00:39:50,721
and not just sitting
behind a desk

812
00:39:50,721 --> 00:39:55,559
and gathering and
analyzing data,

813
00:39:55,559 --> 00:39:59,997
and to be focused on the
big problems of the day.

814
00:39:59,997 --> 00:40:01,465
And so that really guided me.

815
00:40:01,465 --> 00:40:05,569
Now, I was hired, actually, by
Sloan, not by political science.

816
00:40:05,569 --> 00:40:07,471
Lester Thoreau was
the dean, and he

817
00:40:07,471 --> 00:40:11,475
was hiring a bunch of people who
didn't have traditional business

818
00:40:11,475 --> 00:40:11,976
backgrounds.

819
00:40:11,976 --> 00:40:14,311
Because he, too, at
that time, wanted

820
00:40:14,311 --> 00:40:17,047
to reimagine what
Sloan could be.

821
00:40:17,047 --> 00:40:21,552
And so a whole cohort of us came
in who were non-traditional,

822
00:40:21,552 --> 00:40:22,620
and that was great.

823
00:40:22,620 --> 00:40:24,288
And I had the great
fortune of teaching,

824
00:40:24,288 --> 00:40:26,223
both in political
science, and at Sloan,

825
00:40:26,223 --> 00:40:28,926
and eventually as serving as
the head of the Department

826
00:40:28,926 --> 00:40:31,996
of Political Science, which
continues to this day,

827
00:40:31,996 --> 00:40:35,199
to do this amazing work,
which is integrated

828
00:40:35,199 --> 00:40:36,767
with the rest of
the Institute that

829
00:40:36,767 --> 00:40:39,403
has real impact in the world.

830
00:40:39,403 --> 00:40:42,039
And I thought that
was super important.

831
00:40:42,039 --> 00:40:45,242
So that really shaped me.

832
00:40:45,242 --> 00:40:47,578
I mean, I'm excited about
the fact that you joined--

833
00:40:47,578 --> 00:40:49,380
that you came back to
MIT for many reasons.

834
00:40:49,380 --> 00:40:52,183
But I think one of them is
connected to that, the fact

835
00:40:52,183 --> 00:40:56,987
that you just have a perspective
that is much broader than what

836
00:40:56,987 --> 00:40:57,955
you would expect.

837
00:40:57,955 --> 00:41:00,825
Not just because your PhD
is in political science,

838
00:41:00,825 --> 00:41:05,429
but also because, as Sally
said, you served as provost.

839
00:41:05,429 --> 00:41:08,599
And you served as dean
at Apple University,

840
00:41:08,599 --> 00:41:11,602
which is a very different
kind of institution

841
00:41:11,602 --> 00:41:14,205
than Brown or MIT.

842
00:41:14,205 --> 00:41:19,543
So could you say a
little bit about how

843
00:41:19,543 --> 00:41:24,181
that broad perspective has
shaped your vision of Sloan?

844
00:41:24,181 --> 00:41:27,685
And also, what surprised you
now that you've been on the job

845
00:41:27,685 --> 00:41:28,686
for a little bit?

846
00:41:28,686 --> 00:41:31,055
What have you found
now that you're here

847
00:41:31,055 --> 00:41:32,923
that you didn't expect?

848
00:41:32,923 --> 00:41:34,325
Let me answer the
second question,

849
00:41:34,325 --> 00:41:36,093
and then go to the first one.

850
00:41:36,093 --> 00:41:39,930
What surprised me, the
pleasant surprise is

851
00:41:39,930 --> 00:41:45,569
just the incredible community,
coming back and being

852
00:41:45,569 --> 00:41:49,840
able to work every day
with a group of colleagues,

853
00:41:49,840 --> 00:41:53,477
whether they're faculty,
or staff, or students

854
00:41:53,477 --> 00:41:58,148
who are bright, doing good
work, have good values.

855
00:41:58,148 --> 00:42:01,352
I mean, I come to work every
day with a bounce in my step.

856
00:42:01,352 --> 00:42:04,388
I pinch myself that I get
to work here because it's

857
00:42:04,388 --> 00:42:06,090
such an amazing community.

858
00:42:06,090 --> 00:42:08,192
And I always knew it was great.

859
00:42:08,192 --> 00:42:10,227
I forgot how wonderful it was.

860
00:42:10,227 --> 00:42:12,663
And I think that's something
that we have to just remember.

861
00:42:12,663 --> 00:42:15,766
Sometimes we take it for
granted in today's world.

862
00:42:15,766 --> 00:42:20,704
That we have the luxury of doing
what we do here is amazing.

863
00:42:20,704 --> 00:42:22,973
So that's the
wonderful surprise.

864
00:42:22,973 --> 00:42:25,409
The less-than-wonderful
surprise is

865
00:42:25,409 --> 00:42:27,144
our systems are still terrible.

866
00:42:27,144 --> 00:42:29,780
And you can't-- like, how
many faculty do we have?

867
00:42:29,780 --> 00:42:32,516
And you have three different
sources of information on it.

868
00:42:32,516 --> 00:42:36,253
So I know we're working
on it, and it's just part

869
00:42:36,253 --> 00:42:40,324
of the beauty of MIT, of that.

870
00:42:40,324 --> 00:42:42,927
I think what I learned in
these other experiences, which

871
00:42:42,927 --> 00:42:47,565
I hope will shape how I
try to do the work as dean,

872
00:42:47,565 --> 00:42:52,169
at Brown, as provost, provost
is a really tough job.

873
00:42:52,169 --> 00:42:53,737
And because you
really are the CEO,

874
00:42:53,737 --> 00:42:56,974
and you're the front line
of so many of the challenges

875
00:42:56,974 --> 00:42:57,708
that happen.

876
00:42:57,708 --> 00:43:00,311
And you have to make
unpopular decisions.

877
00:43:00,311 --> 00:43:00,911
You have to.

878
00:43:00,911 --> 00:43:01,845
It's part of the job.

879
00:43:01,845 --> 00:43:06,250
You're not going to make
friends by being a provost--

880
00:43:06,250 --> 00:43:07,184
real friends.

881
00:43:07,184 --> 00:43:07,685
And--

882
00:43:07,685 --> 00:43:09,486
[LAUGHTER]

883
00:43:09,486 --> 00:43:12,323
Yeah, there's a lot
of transactional,

884
00:43:12,323 --> 00:43:18,295
like, hey, and forget
it, and stuff like that.

885
00:43:18,295 --> 00:43:23,033
And what I learned there was
the importance of really going

886
00:43:23,033 --> 00:43:27,571
out and listening to people in
the community, to the students,

887
00:43:27,571 --> 00:43:32,176
to the faculty, to the staff
when there were tough moments,

888
00:43:32,176 --> 00:43:34,578
and I was on the other side,
and they were yelling at me,

889
00:43:34,578 --> 00:43:37,147
or when there were
common issues, et cetera.

890
00:43:37,147 --> 00:43:39,149
And being able to tap
into the collective wisdom

891
00:43:39,149 --> 00:43:41,785
of the community is
really important.

892
00:43:41,785 --> 00:43:43,087
You can't do everything.

893
00:43:43,087 --> 00:43:45,255
You have to prioritize.

894
00:43:45,255 --> 00:43:48,759
We know a lot, but we just
don't know everything.

895
00:43:48,759 --> 00:43:52,162
And so how do we
actually embrace

896
00:43:52,162 --> 00:43:55,065
the richness and diversity
of our community and use

897
00:43:55,065 --> 00:43:56,100
that to inform us.

898
00:43:56,100 --> 00:43:59,803
That was the number one
lesson I learned at Brown.

899
00:43:59,803 --> 00:44:02,706
And I think that's
something that I really

900
00:44:02,706 --> 00:44:06,076
feel I need to
continue doing here now

901
00:44:06,076 --> 00:44:07,911
that I'm back at MIT Sloan.

902
00:44:07,911 --> 00:44:11,415
And at Apple, I learned
many, many things.

903
00:44:11,415 --> 00:44:12,583
And it's an amazing company.

904
00:44:12,583 --> 00:44:14,985
It reminds me a lot
of MIT, actually--

905
00:44:14,985 --> 00:44:18,922
filled with engineers doing
great work, et cetera.

906
00:44:18,922 --> 00:44:21,025
Many MIT people are there.

907
00:44:21,025 --> 00:44:24,294
But I lived in San Francisco,
and I would take often

908
00:44:24,294 --> 00:44:26,797
the Apple Bus from--

909
00:44:26,797 --> 00:44:31,502
an early in the morning bus from
San Francisco down to Cupertino.

910
00:44:31,502 --> 00:44:34,371
I was by far the oldest
person on the bus.

911
00:44:34,371 --> 00:44:38,609
And most of them were the
age of our MBA students.

912
00:44:38,609 --> 00:44:41,879
And while a couple of them
were napping, what I noticed

913
00:44:41,879 --> 00:44:44,648
is that most of them
were consuming content.

914
00:44:44,648 --> 00:44:46,350
They were listening
to a podcast.

915
00:44:46,350 --> 00:44:47,551
They were watching a video.

916
00:44:47,551 --> 00:44:49,019
They were reading
a short article.

917
00:44:49,019 --> 00:44:51,288
They were doing something.

918
00:44:51,288 --> 00:44:52,956
And I was sort of
watching this, and I'm

919
00:44:52,956 --> 00:44:55,759
like, we need to meet our
students where they are,

920
00:44:55,759 --> 00:44:57,628
not where we think [INAUDIBLE].

921
00:44:57,628 --> 00:45:01,165
We have to think about, what are
the different ways, and bits,

922
00:45:01,165 --> 00:45:05,903
and bytes that we can actually
get people on their commute,

923
00:45:05,903 --> 00:45:08,906
in their work, whatever,
to educate them?

924
00:45:08,906 --> 00:45:10,374
And so that's
something that I hope

925
00:45:10,374 --> 00:45:13,343
to be able to integrate
more in Sloan.

926
00:45:13,343 --> 00:45:14,845
I totally agree.

927
00:45:14,845 --> 00:45:17,548

928
00:45:17,548 --> 00:45:21,885
As you were talking,
you described

929
00:45:21,885 --> 00:45:26,323
a recent SHASS-Sloan
collaboration which earned us

930
00:45:26,323 --> 00:45:29,093
a couple of Nobel prizes.

931
00:45:29,093 --> 00:45:32,396
And to me, that's a
reminder that the potential

932
00:45:32,396 --> 00:45:38,368
for collaboration is not
just in terms of contributing

933
00:45:38,368 --> 00:45:40,237
to the MIT of the future.

934
00:45:40,237 --> 00:45:42,573
But it's also on
the research front.

935
00:45:42,573 --> 00:45:48,812
I mean, we, together, have not
all, but many of the institute's

936
00:45:48,812 --> 00:45:50,681
social scientists.

937
00:45:50,681 --> 00:45:55,185
And I think that there is so
much that we can do together,

938
00:45:55,185 --> 00:46:03,093
including understanding how
to adapt to the age of AI,

939
00:46:03,093 --> 00:46:09,867
understanding what the right
vision is to help shape

940
00:46:09,867 --> 00:46:12,069
the age of AI, as
you were saying,

941
00:46:12,069 --> 00:46:16,406
so that it's something
that is good for society

942
00:46:16,406 --> 00:46:19,777
and not something that
just costs us jobs.

943
00:46:19,777 --> 00:46:23,347
So could you speak a
little bit about how

944
00:46:23,347 --> 00:46:28,218
you see the potential of this
work in the social sciences?

945
00:46:28,218 --> 00:46:31,155
So I think we have an
incredible opportunity based

946
00:46:31,155 --> 00:46:34,224
on the strategic initiatives,
presidential initiatives

947
00:46:34,224 --> 00:46:39,096
that Sally and Anantha have
seeded in the last 18 months

948
00:46:39,096 --> 00:46:41,298
to two years,
which is important,

949
00:46:41,298 --> 00:46:44,034
which is all about
bringing people together

950
00:46:44,034 --> 00:46:46,069
around big issues.

951
00:46:46,069 --> 00:46:50,707
And I love that MIT Sloan
faculty are integrated

952
00:46:50,707 --> 00:46:52,342
in just about all of them.

953
00:46:52,342 --> 00:46:54,144
I think that that's
really important.

954
00:46:54,144 --> 00:46:57,915
So building on that,
what I would like to see

955
00:46:57,915 --> 00:47:00,984
is how do we encourage our
faculty and students to get

956
00:47:00,984 --> 00:47:04,755
engaged in projects, whether
it's around climate or energy,

957
00:47:04,755 --> 00:47:06,223
or whether around
health, whether

958
00:47:06,223 --> 00:47:09,259
around the human Insight,
collaborative, where

959
00:47:09,259 --> 00:47:10,527
we're doing work together.

960
00:47:10,527 --> 00:47:13,530
Because at universities,
I think you all know this.

961
00:47:13,530 --> 00:47:15,599
If you really want
people to get together,

962
00:47:15,599 --> 00:47:17,301
they get together
really for two reasons.

963
00:47:17,301 --> 00:47:18,869
It's not like by
serving on committees

964
00:47:18,869 --> 00:47:20,804
because they tolerate each
other when they're on committees

965
00:47:20,804 --> 00:47:21,738
and stuff like that.

966
00:47:21,738 --> 00:47:23,707
They get together when
they do work together,

967
00:47:23,707 --> 00:47:26,243
when they do research together,
or when they teach and mentor

968
00:47:26,243 --> 00:47:27,377
students together.

969
00:47:27,377 --> 00:47:28,846
That's the opportunity.

970
00:47:28,846 --> 00:47:32,115
And so now that we have this
structure that's bringing people

971
00:47:32,115 --> 00:47:35,919
together, how might we deepen
it by thinking about how we

972
00:47:35,919 --> 00:47:37,487
do more collaborative research?

973
00:47:37,487 --> 00:47:40,324
Which is exactly what I had when
I was a graduate student here.

974
00:47:40,324 --> 00:47:42,492
The experience I had as
a grad student was not

975
00:47:42,492 --> 00:47:44,695
like what my other
political science grad

976
00:47:44,695 --> 00:47:47,364
student colleagues at other
universities were having.

977
00:47:47,364 --> 00:47:49,433
That's part of the
MIT secret sauce.

978
00:47:49,433 --> 00:47:50,601
Let's do more of that.

979
00:47:50,601 --> 00:47:53,804
So I would like Sloan
to-- in any way it can,

980
00:47:53,804 --> 00:47:56,907
to deepen those
relationships and, again, do

981
00:47:56,907 --> 00:48:00,377
more collaborative research,
and even collaborative teaching,

982
00:48:00,377 --> 00:48:02,946
which I think is important.

983
00:48:02,946 --> 00:48:04,281
Rick, thank you.

984
00:48:04,281 --> 00:48:05,916
Thank you for your remarks.

985
00:48:05,916 --> 00:48:08,919
But more importantly,
thank you for your vision,

986
00:48:08,919 --> 00:48:10,487
and thank you for being back.

987
00:48:10,487 --> 00:48:12,656
Thank you for being back to MIT.

988
00:48:12,656 --> 00:48:13,790
Thank you.

989
00:48:13,790 --> 00:48:14,625
Thank you very much.

990
00:48:14,625 --> 00:48:17,461
[APPLAUSE]

991
00:48:17,461 --> 00:48:17,961

992
00:48:17,961 --> 00:48:18,662
Great.

993
00:48:18,662 --> 00:48:19,229
Thanks.

994
00:48:19,229 --> 00:48:21,031
That was good.


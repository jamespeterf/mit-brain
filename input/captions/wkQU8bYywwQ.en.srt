1
00:00:01,400 --> 00:00:08,000
okay so our next speaker is U Professor

2
00:00:04,920 --> 00:00:09,639
uh Antonia May and uh she's a

3
00:00:08,000 --> 00:00:11,840
Chancellor's fellow and the senior

4
00:00:09,639 --> 00:00:13,400
lecturer or um assist associate

5
00:00:11,840 --> 00:00:15,920
professor in the school of chemistry at

6
00:00:13,400 --> 00:00:18,039
the University of Edinburg and she will

7
00:00:15,920 --> 00:00:20,640
um okay let's wait a little bit for the

8
00:00:18,039 --> 00:00:23,320
slide to pull up um but she has done a

9
00:00:20,640 --> 00:00:27,279
lot of amazing work on drug drug design

10
00:00:23,320 --> 00:00:29,640
and um today um yeah we will hear a lot

11
00:00:27,279 --> 00:00:31,439
from her about her work good afternoon

12
00:00:29,640 --> 00:00:33,559
everyone uh first of all thank you very

13
00:00:31,439 --> 00:00:35,559
much to the organizers for inviting me

14
00:00:33,559 --> 00:00:38,680
and giving me the opportunity to speak

15
00:00:35,559 --> 00:00:42,520
here today um second of all maybe a bit

16
00:00:38,680 --> 00:00:44,360
of a controversial uh talk topic uh it

17
00:00:42,520 --> 00:00:46,320
wasn't quite what was in the program I

18
00:00:44,360 --> 00:00:50,320
think it never made it into the program

19
00:00:46,320 --> 00:00:51,760
so um basically hopefully in the next 15

20
00:00:50,320 --> 00:00:54,239
minutes 20 minutes I'm going to talk

21
00:00:51,760 --> 00:00:55,680
about what my group's been doing in in

22
00:00:54,239 --> 00:00:59,199
the space of both sort of generative

23
00:00:55,680 --> 00:01:01,239
modeling and um machine learning and how

24
00:00:59,199 --> 00:01:03,719
we've been using Lang anguage models um

25
00:01:01,239 --> 00:01:07,320
or how useful language models are in in

26
00:01:03,719 --> 00:01:08,960
this um area all right thankfully um

27
00:01:07,320 --> 00:01:11,799
we've already had a nice introduction in

28
00:01:08,960 --> 00:01:13,439
terms of um drug design so we can do

29
00:01:11,799 --> 00:01:16,479
high through pit screening we can do

30
00:01:13,439 --> 00:01:18,560
fragment based drug design um in the end

31
00:01:16,479 --> 00:01:21,560
what we want is some kind of compound

32
00:01:18,560 --> 00:01:23,759
that works well in our Target protein

33
00:01:21,560 --> 00:01:26,560
and of course we can optimize various

34
00:01:23,759 --> 00:01:28,400
different properties um adme properties

35
00:01:26,560 --> 00:01:30,680
but also binding Affinity so we kind of

36
00:01:28,400 --> 00:01:32,600
want some in silico scen screening way

37
00:01:30,680 --> 00:01:36,159
of being able to elaborate either a

38
00:01:32,600 --> 00:01:38,759
fragment or uh find a good hit molecule

39
00:01:36,159 --> 00:01:41,840
from our high throughput

40
00:01:38,759 --> 00:01:43,840
screening so what are the methods you

41
00:01:41,840 --> 00:01:46,240
can do this with so one of the things

42
00:01:43,840 --> 00:01:47,759
we've been looking at is active learning

43
00:01:46,240 --> 00:01:50,000
um Active Learning particularly looking

44
00:01:47,759 --> 00:01:52,280
at sort of compound libraries that are

45
00:01:50,000 --> 00:01:54,840
similar so you can use things like uh

46
00:01:52,280 --> 00:01:56,920
relative binding free energy predictions

47
00:01:54,840 --> 00:01:59,240
and you can iteratively label your

48
00:01:56,920 --> 00:02:01,520
library of lians you want want to score

49
00:01:59,240 --> 00:02:02,560
and then figure out which one might be

50
00:02:01,520 --> 00:02:04,759
the best

51
00:02:02,560 --> 00:02:06,240
compound another way of doing it is if

52
00:02:04,759 --> 00:02:08,280
you have a generative model you need to

53
00:02:06,240 --> 00:02:10,640
somehow figure out how good that

54
00:02:08,280 --> 00:02:12,599
molecule is binding into your binding

55
00:02:10,640 --> 00:02:14,120
pocket so typically what we've been

56
00:02:12,599 --> 00:02:16,720
doing there is just looking at docking

57
00:02:14,120 --> 00:02:18,400
scores um and as we've just learned from

58
00:02:16,720 --> 00:02:22,040
the previous talk they might be slightly

59
00:02:18,400 --> 00:02:25,120
dodgy and we'll see similar results in

60
00:02:22,040 --> 00:02:28,080
in in a few slides

61
00:02:25,120 --> 00:02:30,680
so because we're kind of looking at a

62
00:02:28,080 --> 00:02:32,200
different ways of uh model

63
00:02:30,680 --> 00:02:34,519
things looking at libraries but also at

64
00:02:32,200 --> 00:02:36,239
generative design I thought I'll give a

65
00:02:34,519 --> 00:02:38,519
brief highlight in terms of what we've

66
00:02:36,239 --> 00:02:40,480
been doing in terms of fragment uh based

67
00:02:38,519 --> 00:02:42,239
design for generative modeling so this

68
00:02:40,480 --> 00:02:44,840
is work done by Nicholas runi who is in

69
00:02:42,239 --> 00:02:46,720
my group um as a master student and

70
00:02:44,840 --> 00:02:49,560
things that are being picked up now by

71
00:02:46,720 --> 00:02:51,879
uh Oro patnik who's uh been working on

72
00:02:49,560 --> 00:02:54,640
this and the idea is that we're using a

73
00:02:51,879 --> 00:02:58,080
diffusion model um so typically in a

74
00:02:54,640 --> 00:02:59,879
diffusion model you train um on on a

75
00:02:58,080 --> 00:03:02,040
data set by adding noise and then you

76
00:02:59,879 --> 00:03:05,360
learn the reverse process to generate

77
00:03:02,040 --> 00:03:07,080
samples so we train a model and then we

78
00:03:05,360 --> 00:03:09,680
generate a bunch of samples

79
00:03:07,080 --> 00:03:11,680
unfortunately cats can't quite cure um

80
00:03:09,680 --> 00:03:16,200
diseases yet so we probably want to

81
00:03:11,680 --> 00:03:17,720
sample molecules instead of cats um but

82
00:03:16,200 --> 00:03:18,920
still we have a problem because now

83
00:03:17,720 --> 00:03:20,239
we've just generated a bunch of

84
00:03:18,920 --> 00:03:21,360
molecules most of them are probably

85
00:03:20,239 --> 00:03:24,319
going to be garbage cannot be

86
00:03:21,360 --> 00:03:27,080
synthesized as we've learned um so this

87
00:03:24,319 --> 00:03:30,040
might not be a super gen genius strategy

88
00:03:27,080 --> 00:03:32,400
to actually do things in in in this way

89
00:03:30,040 --> 00:03:35,080
so is there way in which we can actually

90
00:03:32,400 --> 00:03:36,400
refine our model such that we can

91
00:03:35,080 --> 00:03:40,879
generate something we're actually

92
00:03:36,400 --> 00:03:44,360
interested in and want so again uh image

93
00:03:40,879 --> 00:03:46,959
uh machine learning uh to the rescue we

94
00:03:44,360 --> 00:03:50,599
can use things like refinement so we can

95
00:03:46,959 --> 00:03:53,040
actually post um training refine our

96
00:03:50,599 --> 00:03:55,760
model to kind of guide it in the way we

97
00:03:53,040 --> 00:03:59,079
want it to go so here's an example of

98
00:03:55,760 --> 00:04:01,640
generating caffeine uh using a diffusion

99
00:03:59,079 --> 00:04:04,519
model so that is fueling uh the

100
00:04:01,640 --> 00:04:06,640
scientist but still not quite a drug uh

101
00:04:04,519 --> 00:04:09,120
but it means we have fairly stable

102
00:04:06,640 --> 00:04:10,280
control over how we are interacting with

103
00:04:09,120 --> 00:04:11,680
the diffusion model and what kind of

104
00:04:10,280 --> 00:04:16,199
molecules we can

105
00:04:11,680 --> 00:04:18,359
get so in terms of um fragment based

106
00:04:16,199 --> 00:04:21,799
design what can we do in this setting so

107
00:04:18,359 --> 00:04:24,759
here's an example of two fragments um

108
00:04:21,799 --> 00:04:27,080
bound to imbh and the question is how

109
00:04:24,759 --> 00:04:29,759
can we link these fragments so we're

110
00:04:27,080 --> 00:04:31,800
using this refinement approach for uh

111
00:04:29,759 --> 00:04:34,360
our pre-trained diffusion model and we

112
00:04:31,800 --> 00:04:36,919
can actually generate linkers quite

113
00:04:34,360 --> 00:04:39,560
easily uh you could also use a genetic

114
00:04:36,919 --> 00:04:41,360
algorithm to do that uh but I guess the

115
00:04:39,560 --> 00:04:42,960
whole fun part about machine learning is

116
00:04:41,360 --> 00:04:47,320
trying new tools and see if they do

117
00:04:42,960 --> 00:04:49,199
better than existing tools um so what we

118
00:04:47,320 --> 00:04:51,639
can do well in this case we actually

119
00:04:49,199 --> 00:04:53,400
took a very conservative sample of a

120
00:04:51,639 --> 00:04:55,560
th000 molecules that took about 22

121
00:04:53,400 --> 00:04:57,880
minutes so we're still not super fast

122
00:04:55,560 --> 00:05:00,880
with sampling uh then we can do a bunch

123
00:04:57,880 --> 00:05:04,440
of filtering um and we end up with 112

124
00:05:00,880 --> 00:05:06,160
molecules that are good in the sense of

125
00:05:04,440 --> 00:05:08,960
they fit The Binding site there's no

126
00:05:06,160 --> 00:05:13,720
weird strain they are sensible molecules

127
00:05:08,960 --> 00:05:15,840
based on a set of filtering criteria um

128
00:05:13,720 --> 00:05:17,800
now I don't have a massive wet lab where

129
00:05:15,840 --> 00:05:20,160
I can go and test things but the nice

130
00:05:17,800 --> 00:05:22,759
thing is we took this example from the

131
00:05:20,160 --> 00:05:24,280
literature and in these 112 molecules we

132
00:05:22,759 --> 00:05:27,880
actually recovered two compounds that

133
00:05:24,280 --> 00:05:31,120
were tested in the lab and they had nice

134
00:05:27,880 --> 00:05:32,919
um affinity so one of the things we're

135
00:05:31,120 --> 00:05:35,000
trying to do now is actually use this

136
00:05:32,919 --> 00:05:36,400
prospectively not just retrospectively

137
00:05:35,000 --> 00:05:38,080
but at least it's quite promising that

138
00:05:36,400 --> 00:05:40,319
in this particular case we managed to

139
00:05:38,080 --> 00:05:41,800
recover something that people medicinal

140
00:05:40,319 --> 00:05:44,199
chemists had come up with and tested in

141
00:05:41,800 --> 00:05:46,360
the lab and had good Affinity so that's

142
00:05:44,199 --> 00:05:49,319
kind of where we're there where we're at

143
00:05:46,360 --> 00:05:52,039
now so that leaves us with

144
00:05:49,319 --> 00:05:55,479
well if we can't afford to go in the lab

145
00:05:52,039 --> 00:05:57,919
can we actually use um a model that

146
00:05:55,479 --> 00:06:00,680
allows us to predict how well our

147
00:05:57,919 --> 00:06:03,680
generated compounds or compounds from a

148
00:06:00,680 --> 00:06:06,319
compound Library can bind and this is

149
00:06:03,680 --> 00:06:08,680
kind of where my my background comes in

150
00:06:06,319 --> 00:06:11,560
so I came into all of this from a

151
00:06:08,680 --> 00:06:13,400
molecular Dynamics angle so we've been

152
00:06:11,560 --> 00:06:15,240
looking a lot at these alchemical free

153
00:06:13,400 --> 00:06:17,800
energy types of calculations we're

154
00:06:15,240 --> 00:06:20,000
running MD simulations and then try and

155
00:06:17,800 --> 00:06:23,599
figure out from these MD simulations how

156
00:06:20,000 --> 00:06:26,599
well a protein and ligan binds so that

157
00:06:23,599 --> 00:06:29,560
is a fairly costly method it works well

158
00:06:26,599 --> 00:06:30,880
with uh con generic series if we have

159
00:06:29,560 --> 00:06:32,639
non- congeneric series we learned

160
00:06:30,880 --> 00:06:36,960
earlier today there are new methods that

161
00:06:32,639 --> 00:06:39,199
that are great but in general MD takes a

162
00:06:36,960 --> 00:06:42,000
bit of time and you might not be able to

163
00:06:39,199 --> 00:06:45,560
score I don't know a billion compounds

164
00:06:42,000 --> 00:06:47,960
so um you could do docking um as we've

165
00:06:45,560 --> 00:06:51,080
just learned docking isn't necessarily

166
00:06:47,960 --> 00:06:53,560
super reliable um or you can use machine

167
00:06:51,080 --> 00:06:54,800
learning and now there's the question

168
00:06:53,560 --> 00:06:56,759
are these machine learning models that

169
00:06:54,800 --> 00:06:59,840
have been coming out actually any useful

170
00:06:56,759 --> 00:07:01,720
and this is kind of um similar in the

171
00:06:59,840 --> 00:07:04,120
veins of what Pat Walters has been

172
00:07:01,720 --> 00:07:05,919
saying this morning we can test whether

173
00:07:04,120 --> 00:07:08,240
the way we think about it is the same

174
00:07:05,919 --> 00:07:10,400
way you think about it in terms of how

175
00:07:08,240 --> 00:07:12,400
we should be assessing these models

176
00:07:10,400 --> 00:07:15,039
because what is happening is we have a

177
00:07:12,400 --> 00:07:17,599
large set of data um we evaluate the

178
00:07:15,039 --> 00:07:19,680
model on the data and then we have a

179
00:07:17,599 --> 00:07:21,759
nice table and then go okay we have a

180
00:07:19,680 --> 00:07:23,280
great performing model but that doesn't

181
00:07:21,759 --> 00:07:27,199
really get us to the point where we're

182
00:07:23,280 --> 00:07:30,280
like hey I have a particular Target and

183
00:07:27,199 --> 00:07:32,479
I want to know how that works so so

184
00:07:30,280 --> 00:07:35,039
here's a non-n naming and shaming table

185
00:07:32,479 --> 00:07:36,879
you would typically find um and if we're

186
00:07:35,039 --> 00:07:39,560
just looking at some of the the data

187
00:07:36,879 --> 00:07:41,360
entry so all of these rows are different

188
00:07:39,560 --> 00:07:43,680
machine learning models for binding

189
00:07:41,360 --> 00:07:46,919
Affinity predictions and you've got uh

190
00:07:43,680 --> 00:07:49,840
High correlation low root means root

191
00:07:46,919 --> 00:07:51,560
means square error but how different are

192
00:07:49,840 --> 00:07:53,039
they really does the Bold number

193
00:07:51,560 --> 00:07:54,800
actually mean anything there's no error

194
00:07:53,039 --> 00:07:56,879
bars on this so we have no way of

195
00:07:54,800 --> 00:07:58,479
actually telling whether one model is

196
00:07:56,879 --> 00:08:02,599
better than another they're all

197
00:07:58,479 --> 00:08:05,400
evaluated on pdb coret well that's great

198
00:08:02,599 --> 00:08:07,800
but the test data has many different

199
00:08:05,400 --> 00:08:09,879
targets in there so is that really the

200
00:08:07,800 --> 00:08:11,759
kind of question we're trying to answer

201
00:08:09,879 --> 00:08:14,080
so if we're trying to answer I want to

202
00:08:11,759 --> 00:08:17,599
pick my favorite machine learning model

203
00:08:14,080 --> 00:08:19,199
I want to score my compound library and

204
00:08:17,599 --> 00:08:21,360
I want to score it against a particular

205
00:08:19,199 --> 00:08:22,720
Target am I going to get there with this

206
00:08:21,360 --> 00:08:24,440
because based on that I can probably

207
00:08:22,720 --> 00:08:27,120
pick any of them and they should all do

208
00:08:24,440 --> 00:08:30,520
really well right so how well do they

209
00:08:27,120 --> 00:08:33,800
actually do well here's an example of

210
00:08:30,520 --> 00:08:36,399
one we've looked at um this is just out

211
00:08:33,800 --> 00:08:39,039
of curiosity if we try and generate a

212
00:08:36,399 --> 00:08:42,120
model ourselves how how good does such a

213
00:08:39,039 --> 00:08:44,240
model work uh how well does it work so

214
00:08:42,120 --> 00:08:46,839
um these are three variants of the model

215
00:08:44,240 --> 00:08:49,160
we get high correlation uh that's all

216
00:08:46,839 --> 00:08:50,880
great now You observe here I say random

217
00:08:49,160 --> 00:08:52,120
here at the bottom so that's a random

218
00:08:50,880 --> 00:08:54,320
test training

219
00:08:52,120 --> 00:08:56,200
split that's fantastic but it doesn't

220
00:08:54,320 --> 00:08:57,640
help us with my particular Target

221
00:08:56,200 --> 00:08:59,680
example so if I've already seen the

222
00:08:57,640 --> 00:09:01,720
Target in the training data then

223
00:08:59,680 --> 00:09:03,399
probably I'm going to do quite well uh

224
00:09:01,720 --> 00:09:06,040
so if we do different splits like cold

225
00:09:03,399 --> 00:09:09,640
Target cold drug cold scaffold you end

226
00:09:06,040 --> 00:09:11,920
up losing your ability to actually be

227
00:09:09,640 --> 00:09:14,000
predictive um so you need to be careful

228
00:09:11,920 --> 00:09:17,640
in which way you actually work with a

229
00:09:14,000 --> 00:09:20,920
data um so and that is true for all the

230
00:09:17,640 --> 00:09:22,920
the metrics and also observe now because

231
00:09:20,920 --> 00:09:24,399
I've put some error bars on these I can

232
00:09:22,920 --> 00:09:26,120
actually distinguish my different model

233
00:09:24,399 --> 00:09:27,880
and go like there's a significant

234
00:09:26,120 --> 00:09:30,519
difference between them and whether they

235
00:09:27,880 --> 00:09:33,560
are useful or not is that the way to go

236
00:09:30,519 --> 00:09:37,160
probably still not quite so right now

237
00:09:33,560 --> 00:09:39,560
we've Amalgamated all of our protein and

238
00:09:37,160 --> 00:09:42,000
liand binding Affinity data and

239
00:09:39,560 --> 00:09:44,160
effectively what we've done is plotted

240
00:09:42,000 --> 00:09:45,399
this plot and worked out the pierc and

241
00:09:44,160 --> 00:09:48,839
correlation coefficient so we have

242
00:09:45,399 --> 00:09:52,360
experimental PKD versus predicted PKD

243
00:09:48,839 --> 00:09:55,600
and then based on that we can work out

244
00:09:52,360 --> 00:09:57,959
our spearm and correlation coefficient

245
00:09:55,600 --> 00:09:59,959
great so that's what we've done does

246
00:09:57,959 --> 00:10:02,800
that help us with the Target no

247
00:09:59,959 --> 00:10:04,079
um if we look at one target we can we

248
00:10:02,800 --> 00:10:05,800
can look at the scatter that's kind of

249
00:10:04,079 --> 00:10:07,480
similar so that's great but if we look

250
00:10:05,800 --> 00:10:09,440
at a different one we might actually

251
00:10:07,480 --> 00:10:12,160
have a negative correlation and it's not

252
00:10:09,440 --> 00:10:14,920
very uh predictive in terms of rank and

253
00:10:12,160 --> 00:10:17,160
we might have another one so really

254
00:10:14,920 --> 00:10:19,040
looking at just the scatter of this is

255
00:10:17,160 --> 00:10:21,040
not going to give us anything useful

256
00:10:19,040 --> 00:10:24,079
instead we should look at a different

257
00:10:21,040 --> 00:10:26,360
way of combining uh our individual

258
00:10:24,079 --> 00:10:29,000
Target predictions using a Fisher

259
00:10:26,360 --> 00:10:31,079
transform and that fisher transform

260
00:10:29,000 --> 00:10:33,600
basically basically allows us to get a

261
00:10:31,079 --> 00:10:36,680
much more reliable error estimate on how

262
00:10:33,600 --> 00:10:38,920
how good our spread is in the data

263
00:10:36,680 --> 00:10:42,440
versus just looking at the overall

264
00:10:38,920 --> 00:10:44,959
scatter this is nothing new in fact Pat

265
00:10:42,440 --> 00:10:47,920
has written a blog post about this in

266
00:10:44,959 --> 00:10:49,720
2019 uh particularly looking at the sort

267
00:10:47,920 --> 00:10:52,839
of free energy community at the time

268
00:10:49,720 --> 00:10:55,279
where people were compain comparing um

269
00:10:52,839 --> 00:10:57,920
Affinity predictions across many targets

270
00:10:55,279 --> 00:10:59,760
and benchmarks and um I think this is

271
00:10:57,920 --> 00:11:01,160
still true and we're not doing

272
00:10:59,760 --> 00:11:03,320
for for

273
00:11:01,160 --> 00:11:06,079
here so what is the model I've been

274
00:11:03,320 --> 00:11:08,680
showing you well this is now the uh

275
00:11:06,079 --> 00:11:10,760
language models uh so they're not large

276
00:11:08,680 --> 00:11:12,880
language models what we're looking at is

277
00:11:10,760 --> 00:11:16,480
uh protein language models so we have

278
00:11:12,880 --> 00:11:18,639
protein sequence uh and then a um

279
00:11:16,480 --> 00:11:20,800
embedding or protein encoding that that

280
00:11:18,639 --> 00:11:22,880
results from from from this embedding

281
00:11:20,800 --> 00:11:26,360
using a language model and we have smile

282
00:11:22,880 --> 00:11:28,480
strings and the same thing and then what

283
00:11:26,360 --> 00:11:32,600
the model is doing is we're basically

284
00:11:28,480 --> 00:11:35,120
projecting onto a a cosine uh space and

285
00:11:32,600 --> 00:11:40,000
looking at distances between protein and

286
00:11:35,120 --> 00:11:44,079
Lian space uh that means if a li uh has

287
00:11:40,000 --> 00:11:45,959
a good binding Affinity it kind of moves

288
00:11:44,079 --> 00:11:47,839
closer to the protein space if you think

289
00:11:45,959 --> 00:11:51,079
of it in that way whereas if it has a

290
00:11:47,839 --> 00:11:53,000
bad binding Affinity it moves away uh

291
00:11:51,079 --> 00:11:56,959
how does this work in practice so the

292
00:11:53,000 --> 00:11:59,320
architecture is using um an esm2 model

293
00:11:56,959 --> 00:12:02,399
and the Keta model and then we've

294
00:11:59,320 --> 00:12:04,399
actually put some um parameter efficient

295
00:12:02,399 --> 00:12:06,720
fine-tuning adapters on each of them so

296
00:12:04,399 --> 00:12:10,000
we actually can individually fine-tune

297
00:12:06,720 --> 00:12:12,839
our language models in order to be um

298
00:12:10,000 --> 00:12:16,920
getting better at actually capturing

299
00:12:12,839 --> 00:12:19,680
capturing this um so now what are the

300
00:12:16,920 --> 00:12:22,639
different bars I've shown earlier the

301
00:12:19,680 --> 00:12:26,000
the parameter efficient fine tune model

302
00:12:22,639 --> 00:12:28,680
plus this balm binding Affinity uh model

303
00:12:26,000 --> 00:12:30,600
is is the dark bar this is a baseline

304
00:12:28,680 --> 00:12:32,639
model the the Grays basically just

305
00:12:30,600 --> 00:12:35,000
concatenating our protein and ligin

306
00:12:32,639 --> 00:12:37,240
Coatings and using uh multi-layer

307
00:12:35,000 --> 00:12:39,399
perceptron in order to get your readout

308
00:12:37,240 --> 00:12:42,040
for the affinity and then the middle one

309
00:12:39,399 --> 00:12:45,040
is just the balm without the fine

310
00:12:42,040 --> 00:12:48,560
tuning Okay so we've generated a new

311
00:12:45,040 --> 00:12:52,000
model it's another black uh box uh no a

312
00:12:48,560 --> 00:12:54,240
black number in in in our table um well

313
00:12:52,000 --> 00:12:58,079
I want to know how good is this model in

314
00:12:54,240 --> 00:12:59,800
a sort of real scenario so uh we now

315
00:12:58,079 --> 00:13:02,399
look at a different

316
00:12:59,800 --> 00:13:06,199
uh set of splits so the the training was

317
00:13:02,399 --> 00:13:07,279
done on this leaky pdb bind um and now

318
00:13:06,199 --> 00:13:09,480
we're actually looking at different

319
00:13:07,279 --> 00:13:12,000
Target families so how good does it

320
00:13:09,480 --> 00:13:13,959
perform across different Target families

321
00:13:12,000 --> 00:13:16,160
and how good does it perform in

322
00:13:13,959 --> 00:13:19,120
comparison to docking so if we learned

323
00:13:16,160 --> 00:13:21,519
that docking is random uh well maybe

324
00:13:19,120 --> 00:13:24,440
this is also random we'll see but

325
00:13:21,519 --> 00:13:28,000
effectively um what we now see is the

326
00:13:24,440 --> 00:13:31,480
the blue dots are the the language model

327
00:13:28,000 --> 00:13:33,800
the trained language model the the um

328
00:13:31,480 --> 00:13:36,680
orange ones is the docking for this

329
00:13:33,800 --> 00:13:40,800
particular family of proteins then

330
00:13:36,680 --> 00:13:42,680
chapon targets again the the B model

331
00:13:40,800 --> 00:13:44,279
seems to be doing quite well but then

332
00:13:42,680 --> 00:13:45,680
there's also again examples where

333
00:13:44,279 --> 00:13:48,440
actually docking seems to be doing

334
00:13:45,680 --> 00:13:50,519
better so you really can't just put

335
00:13:48,440 --> 00:13:53,199
everything into one pot and get a

336
00:13:50,519 --> 00:13:55,680
guaranteed working model they will work

337
00:13:53,199 --> 00:13:57,959
differently across uh different targets

338
00:13:55,680 --> 00:14:00,680
so now um if I want to look at my

339
00:13:57,959 --> 00:14:03,320
overall correl coefficients and root me

340
00:14:00,680 --> 00:14:06,480
square error um I need to average over

341
00:14:03,320 --> 00:14:09,320
them not by just adding them but using

342
00:14:06,480 --> 00:14:14,639
my Fisher information so now I can look

343
00:14:09,320 --> 00:14:16,759
at my Spearman row or my person R versus

344
00:14:14,639 --> 00:14:19,759
the the different um tools we're using

345
00:14:16,759 --> 00:14:24,839
so we've got done docking with Vina and

346
00:14:19,759 --> 00:14:27,880
arock um and then uh the model we've got

347
00:14:24,839 --> 00:14:30,279
is this model better than these

348
00:14:27,880 --> 00:14:31,959
models I I don't know because we're not

349
00:14:30,279 --> 00:14:36,279
looking at the same things am I going to

350
00:14:31,959 --> 00:14:39,560
rerun all of this no probably not um but

351
00:14:36,279 --> 00:14:41,440
I think at least in this way I've now

352
00:14:39,560 --> 00:14:43,639
can convincingly say I know for

353
00:14:41,440 --> 00:14:45,920
particular T classes this model will

354
00:14:43,639 --> 00:14:48,480
probably do quite well for other ones it

355
00:14:45,920 --> 00:14:51,600
probably will not do well um is it

356
00:14:48,480 --> 00:14:54,079
learning the right thing maybe um

357
00:14:51,600 --> 00:14:56,279
something to look into so the last thing

358
00:14:54,079 --> 00:14:59,680
I want to mention is zero shot learning

359
00:14:56,279 --> 00:15:01,240
and few shot learning so um very briefly

360
00:14:59,680 --> 00:15:04,120
I talked about Active Learning so you

361
00:15:01,240 --> 00:15:05,720
can use active learning to score here uh

362
00:15:04,120 --> 00:15:07,360
we were thinking what if we could use

363
00:15:05,720 --> 00:15:10,639
something like this in in an active

364
00:15:07,360 --> 00:15:12,759
learning situation so here is a usp7

365
00:15:10,639 --> 00:15:15,000
target that was not in the training set

366
00:15:12,759 --> 00:15:17,000
at all and we actually get pretty

367
00:15:15,000 --> 00:15:20,639
reasonable statistics if we look at the

368
00:15:17,000 --> 00:15:22,680
the scatter but if we now take 10 or 20%

369
00:15:20,639 --> 00:15:24,920
of the data and do few shot learning we

370
00:15:22,680 --> 00:15:27,040
actually get a much better uh

371
00:15:24,920 --> 00:15:30,000
correlation the interesting thing is if

372
00:15:27,040 --> 00:15:33,680
we now take the same data and train a

373
00:15:30,000 --> 00:15:36,240
gan process um we get almost better

374
00:15:33,680 --> 00:15:38,920
correlation so what does that tell us

375
00:15:36,240 --> 00:15:40,880
well in some cases the Gan process is

376
00:15:38,920 --> 00:15:45,000
better in some cases it isn't because

377
00:15:40,880 --> 00:15:47,000
the gaan process requires you to make um

378
00:15:45,000 --> 00:15:48,759
a decision about the embeddings and

379
00:15:47,000 --> 00:15:51,440
depending on the embedding you choose

380
00:15:48,759 --> 00:15:54,480
you get similar performance to the model

381
00:15:51,440 --> 00:15:56,360
we've been training if you choose a bad

382
00:15:54,480 --> 00:15:58,360
embedding it actually is worse and you

383
00:15:56,360 --> 00:16:00,199
can't know this a priori so it depends

384
00:15:58,360 --> 00:16:02,040
it's not the same across all Targets

385
00:16:00,199 --> 00:16:04,519
it's going to be different across

386
00:16:02,040 --> 00:16:07,000
targets so yeah future toning can

387
00:16:04,519 --> 00:16:09,399
improve performance um but gausian

388
00:16:07,000 --> 00:16:11,880
process models perform similar in

389
00:16:09,399 --> 00:16:14,040
certain situations so this kind of gets

390
00:16:11,880 --> 00:16:16,360
me to the end if you're interested in

391
00:16:14,040 --> 00:16:19,399
how this works all of uh that model is

392
00:16:16,360 --> 00:16:21,959
online um and can be tried out it would

393
00:16:19,399 --> 00:16:25,360
be great to kind of hear what you think

394
00:16:21,959 --> 00:16:28,600
about it um I think in terms of what

395
00:16:25,360 --> 00:16:32,360
I've talked about so we can do fragment

396
00:16:28,600 --> 00:16:36,120
link in with diffusion models uh getting

397
00:16:32,360 --> 00:16:39,920
meaningful data splits is important um

398
00:16:36,120 --> 00:16:42,040
and language models can be used to uh

399
00:16:39,920 --> 00:16:44,399
predict affinities so kind of like a

400
00:16:42,040 --> 00:16:46,240
scoring function um the last thing I

401
00:16:44,399 --> 00:16:49,240
want to mention before acknowledgements

402
00:16:46,240 --> 00:16:52,160
is if you work in this field and you

403
00:16:49,240 --> 00:16:54,000
have interesting um best practices

404
00:16:52,160 --> 00:16:56,040
tutorials Lessons Learned please

405
00:16:54,000 --> 00:16:57,959
consider the living Journal of

406
00:16:56,040 --> 00:16:59,240
computational molecular science uh I'm

407
00:16:57,959 --> 00:17:01,160
an editor for it if you want to know

408
00:16:59,240 --> 00:17:03,439
more please come and talk to me about it

409
00:17:01,160 --> 00:17:06,959
if you do open source software consider

410
00:17:03,439 --> 00:17:08,559
Joss uh another nice uh Journal both of

411
00:17:06,959 --> 00:17:10,480
these are diamond open accents so

412
00:17:08,559 --> 00:17:13,199
nonprofit and ultra low cost for both

413
00:17:10,480 --> 00:17:16,039
reader and author with that I would like

414
00:17:13,199 --> 00:17:19,000
to acknowledge Rohan and AO who did most

415
00:17:16,039 --> 00:17:21,839
of the work and my group and you for

416
00:17:19,000 --> 00:17:21,839
your attention thank

417
00:17:24,199 --> 00:17:31,000
you great thanks for the awesome talk uh

418
00:17:27,640 --> 00:17:33,720
any questions uh you can come to the uh

419
00:17:31,000 --> 00:17:35,480
mics I have one we have um maybe two or

420
00:17:33,720 --> 00:17:38,120
three minutes uh but I have a question

421
00:17:35,480 --> 00:17:39,840
on have you tried uh with more like

422
00:17:38,120 --> 00:17:42,240
decoys because I feel like a lot of

423
00:17:39,840 --> 00:17:44,320
times we have um different scenarios

424
00:17:42,240 --> 00:17:46,320
right we um in the lead optimization

425
00:17:44,320 --> 00:17:48,120
stage we care more about correlation

426
00:17:46,320 --> 00:17:49,760
because we want to boost up the Affinity

427
00:17:48,120 --> 00:17:52,480
but in the kind of the virtual screening

428
00:17:49,760 --> 00:17:54,440
case when we have a lot of negatives um

429
00:17:52,480 --> 00:17:56,240
have you looked at more example for

430
00:17:54,440 --> 00:17:59,360
example like the top hit rate like

431
00:17:56,240 --> 00:18:02,000
enrichment type of thing um

432
00:17:59,360 --> 00:18:04,760
um so so I mean I mean the the the data

433
00:18:02,000 --> 00:18:07,520
set has both binders and non-binders in

434
00:18:04,760 --> 00:18:09,039
it right so in that sense um that

435
00:18:07,520 --> 00:18:12,120
information is there we've not

436
00:18:09,039 --> 00:18:15,280
specifically looked at this no um I know

437
00:18:12,120 --> 00:18:18,520
there's work out in that direction but

438
00:18:15,280 --> 00:18:20,640
no we have not okay okay there's there's

439
00:18:18,520 --> 00:18:23,200
please go ahead thanks it's a wonderful

440
00:18:20,640 --> 00:18:25,559
talk um you at one point differentiated

441
00:18:23,200 --> 00:18:29,159
between large language models

442
00:18:25,559 --> 00:18:30,640
and I guess just language models could

443
00:18:29,159 --> 00:18:31,880
you elaborate on that a little more it

444
00:18:30,640 --> 00:18:33,720
seems like that there's a lot of

445
00:18:31,880 --> 00:18:36,480
resources being poured into large

446
00:18:33,720 --> 00:18:39,200
language models as we know yeah okay so

447
00:18:36,480 --> 00:18:40,919
so I I think maybe my uh terminology was

448
00:18:39,200 --> 00:18:43,159
a bit wishy-washy so I guess large

449
00:18:40,919 --> 00:18:46,039
language models typically we think of

450
00:18:43,159 --> 00:18:48,600
chat jpt um those kind of type of models

451
00:18:46,039 --> 00:18:53,600
Lama whatever Gemini you name it so

452
00:18:48,600 --> 00:18:57,679
that's trained on um language um and

453
00:18:53,600 --> 00:18:59,240
text that is widely available uh here we

454
00:18:57,679 --> 00:19:01,799
look at um

455
00:18:59,240 --> 00:19:03,960
um language models that use similar

456
00:19:01,799 --> 00:19:07,240
architecture to these larger language

457
00:19:03,960 --> 00:19:11,600
models but are trained on sequence um

458
00:19:07,240 --> 00:19:14,280
and um smile strings so the idea there

459
00:19:11,600 --> 00:19:16,280
is that we we have much more information

460
00:19:14,280 --> 00:19:19,280
in sequence databases and smiles

461
00:19:16,280 --> 00:19:20,679
databases than 3D structural information

462
00:19:19,280 --> 00:19:24,480
so

463
00:19:20,679 --> 00:19:27,559
um we wanted to see what if we fine tune

464
00:19:24,480 --> 00:19:29,760
based on then um Affinity data can we

465
00:19:27,559 --> 00:19:32,200
get a signal out or is it all garbage

466
00:19:29,760 --> 00:19:34,240
effectively but yeah and and is there a

467
00:19:32,200 --> 00:19:36,559
difference then between say tuning a

468
00:19:34,240 --> 00:19:38,640
large language model on the exact data

469
00:19:36,559 --> 00:19:41,240
set you say in and starting yeah so so

470
00:19:38,640 --> 00:19:43,679
basically the the so we do two types of

471
00:19:41,240 --> 00:19:46,159
fine-tuning so we have these uh PFT

472
00:19:43,679 --> 00:19:49,960
adapters which are basically taking the

473
00:19:46,159 --> 00:19:52,400
pre-trained model and just um optimizing

474
00:19:49,960 --> 00:19:55,080
it a little bit in the training process

475
00:19:52,400 --> 00:19:58,919
and then we have this uh F shot training

476
00:19:55,080 --> 00:20:00,720
where basically we leave the most of it

477
00:19:58,919 --> 00:20:02,600
intact and just look at the projection

478
00:20:00,720 --> 00:20:04,559
layers and unfreeze some some weights

479
00:20:02,600 --> 00:20:06,280
there and retrain that bit so there's

480
00:20:04,559 --> 00:20:08,640
different parts where you can basically

481
00:20:06,280 --> 00:20:13,480
unfreeze and and and retrain depending

482
00:20:08,640 --> 00:20:13,480
on on your desires but yeah thank

483
00:20:14,679 --> 00:20:21,720
you nice talk with these language models

484
00:20:19,200 --> 00:20:25,320
and F shot techniques I think it's

485
00:20:21,720 --> 00:20:27,520
difficult to not fool yourself and just

486
00:20:25,320 --> 00:20:30,840
create a really elaborate similarity

487
00:20:27,520 --> 00:20:32,840
search so so did you do controls on this

488
00:20:30,840 --> 00:20:35,120
and did you say great instead of zero

489
00:20:32,840 --> 00:20:38,240
shot I'm just going to do KN andn with k

490
00:20:35,120 --> 00:20:39,039
equals 1 and do the lookups and just do

491
00:20:38,240 --> 00:20:41,760
the

492
00:20:39,039 --> 00:20:47,080
comparisons so so we looked at um

493
00:20:41,760 --> 00:20:47,080
molecular weight comparisons effectively

494
00:20:47,200 --> 00:20:52,640
um I don't think we have the the plots

495
00:20:50,960 --> 00:20:54,320
that really show this but I think we

496
00:20:52,640 --> 00:20:56,799
should do that yeah I mean I think just

497
00:20:54,320 --> 00:20:58,840
doing a a simple similarity search

498
00:20:56,799 --> 00:21:01,400
comparison and convincing yourself that

499
00:20:58,840 --> 00:21:04,320
you're not just creating a very fancy

500
00:21:01,400 --> 00:21:05,799
lookup table yeah no I think there's the

501
00:21:04,320 --> 00:21:07,679
I think this is why we looked at the

502
00:21:05,799 --> 00:21:10,320
gussian processes because to me that is

503
00:21:07,679 --> 00:21:12,960
already like a slightly fancier version

504
00:21:10,320 --> 00:21:17,279
of a lookup table Yeah and because they

505
00:21:12,960 --> 00:21:20,880
seem to work surprisingly well

506
00:21:17,279 --> 00:21:23,240
um yeah no that is a concern 100% okay

507
00:21:20,880 --> 00:21:25,440
thanks thank you yeah uh with that let's

508
00:21:23,240 --> 00:21:28,440
give our speaker one more round of

509
00:21:25,440 --> 00:21:28,440
applause


1
00:00:01,360 --> 00:00:06,359
um and also welcome to those of you who

2
00:00:03,320 --> 00:00:08,120
are online um this is a you know this is

3
00:00:06,359 --> 00:00:09,719
a busy time of the semester and we know

4
00:00:08,120 --> 00:00:12,599
that uh many people will appreciate the

5
00:00:09,719 --> 00:00:15,200
recording um as a chance to to uh return

6
00:00:12,599 --> 00:00:17,439
to this um I'm looking forward um to a

7
00:00:15,200 --> 00:00:19,199
very interesting conversation um in both

8
00:00:17,439 --> 00:00:21,279
this session and then right U following

9
00:00:19,199 --> 00:00:23,519
it after a brief Break um another

10
00:00:21,279 --> 00:00:26,400
session with our our other guest uh this

11
00:00:23,519 --> 00:00:30,000
afternoon around this the question uh

12
00:00:26,400 --> 00:00:32,960
that generative AI poses um for the uh

13
00:00:30,000 --> 00:00:35,840
for the legal structures um and and

14
00:00:32,960 --> 00:00:38,320
rights and practices of copyright in the

15
00:00:35,840 --> 00:00:41,039
United States and and in fact around the

16
00:00:38,320 --> 00:00:42,399
world um and I think this will this

17
00:00:41,039 --> 00:00:44,160
conversation is designed to be

18
00:00:42,399 --> 00:00:46,280
informative um so there will be a little

19
00:00:44,160 --> 00:00:48,000
bit of just basic uh kind of you know

20
00:00:46,280 --> 00:00:50,120
getting the community up to speed about

21
00:00:48,000 --> 00:00:52,160
the terms of the law uh it's also

22
00:00:50,120 --> 00:00:54,199
designed to be thought-provoking um and

23
00:00:52,160 --> 00:00:56,239
we've invited uh you know one of our

24
00:00:54,199 --> 00:00:58,160
speakers to kind of provoke us into some

25
00:00:56,239 --> 00:01:00,559
thinking about what's at stake um for

26
00:00:58,160 --> 00:01:03,719
authors and creatives um as generative

27
00:01:00,559 --> 00:01:05,720
AI emerges as a technology um and then

28
00:01:03,719 --> 00:01:08,600
it's also designed to be specifically

29
00:01:05,720 --> 00:01:10,799
reflective um for the MIT Community um

30
00:01:08,600 --> 00:01:12,640
and and others who are interested um in

31
00:01:10,799 --> 00:01:15,880
what's at stake at the interface of

32
00:01:12,640 --> 00:01:18,640
technology and Society um so I will

33
00:01:15,880 --> 00:01:21,600
introduce our our uh main speaker for

34
00:01:18,640 --> 00:01:23,479
this uh first session in a moment and uh

35
00:01:21,600 --> 00:01:25,920
before I turn it over to him I'm gonna

36
00:01:23,479 --> 00:01:27,560
to um Kazi who's the director of policy

37
00:01:25,920 --> 00:01:29,240
and advocacy at the author's Guild I'll

38
00:01:27,560 --> 00:01:31,280
give a longer introduction in a few

39
00:01:29,240 --> 00:01:34,479
minutes um I'll just say a little bit

40
00:01:31,280 --> 00:01:36,360
more about myself uh about about cir um

41
00:01:34,479 --> 00:01:40,640
and then give you kind of maybe about 5

42
00:01:36,360 --> 00:01:43,360
10 uh minute overview of uh the history

43
00:01:40,640 --> 00:01:47,600
um and current status of copyright um in

44
00:01:43,360 --> 00:01:49,920
20th in 21st century United States um so

45
00:01:47,600 --> 00:01:53,200
uh as Nico said I'm uh I'm a professor

46
00:01:49,920 --> 00:01:55,799
of History here at MIT um where I teach

47
00:01:53,200 --> 00:01:58,399
and publish in the field of 20th century

48
00:01:55,799 --> 00:02:00,520
US legal history one of the courses I

49
00:01:58,399 --> 00:02:03,560
teach at MIT um is called the history of

50
00:02:00,520 --> 00:02:06,799
the US Supreme Court um uh although I am

51
00:02:03,560 --> 00:02:08,679
not a lawyer um I am a legal historian

52
00:02:06,799 --> 00:02:12,040
um and also serve as one of the advisers

53
00:02:08,679 --> 00:02:14,640
for mit's has concentration in legal

54
00:02:12,040 --> 00:02:16,040
studies um and uh you know I should just

55
00:02:14,640 --> 00:02:17,599
sort of say given everything that's

56
00:02:16,040 --> 00:02:19,680
going on in the world um you know in my

57
00:02:17,599 --> 00:02:21,800
teaching I I do teach about the rule of

58
00:02:19,680 --> 00:02:23,440
law the separational powers the

59
00:02:21,800 --> 00:02:25,840
administrative procedures act the

60
00:02:23,440 --> 00:02:28,040
empowerment Control Act of 1974 other

61
00:02:25,840 --> 00:02:30,400
things that I hadn't had on my syllabus

62
00:02:28,040 --> 00:02:33,480
um last year but we'll be adding to them

63
00:02:30,400 --> 00:02:35,239
um very very quickly um you know and

64
00:02:33,480 --> 00:02:37,760
it's really designed to be a space for

65
00:02:35,239 --> 00:02:40,319
MIT students to to Grapple with issues

66
00:02:37,760 --> 00:02:43,480
um uh from the past as they as they uh

67
00:02:40,319 --> 00:02:44,959
connect with the present um and in the

68
00:02:43,480 --> 00:02:46,800
last year or so I've had a chance of

69
00:02:44,959 --> 00:02:48,800
doing this in conjunction sometimes with

70
00:02:46,800 --> 00:02:51,000
with c um with social ethical and

71
00:02:48,800 --> 00:02:53,720
responsibilities of computing initiative

72
00:02:51,000 --> 00:02:56,239
of the college which is as it described

73
00:02:53,720 --> 00:02:59,080
itself is facilitating the development

74
00:02:56,239 --> 00:03:00,519
of responsible habits of mind and action

75
00:02:59,080 --> 00:03:02,159
and I love that phrase

76
00:03:00,519 --> 00:03:04,599
for those who create and deploy

77
00:03:02,159 --> 00:03:06,680
Computing Technologies and fostering the

78
00:03:04,599 --> 00:03:09,159
creation of Technologies in the public

79
00:03:06,680 --> 00:03:11,480
interest and and so I think it it was a

80
00:03:09,159 --> 00:03:14,239
logical connection um for us to think

81
00:03:11,480 --> 00:03:17,560
about generative Ai and copyright as

82
00:03:14,239 --> 00:03:19,799
crucial issues um both for uh fostering

83
00:03:17,560 --> 00:03:22,080
the creation of Technologies um thinking

84
00:03:19,799 --> 00:03:24,080
about about the public interest and also

85
00:03:22,080 --> 00:03:27,360
developing responsible habits of mind

86
00:03:24,080 --> 00:03:29,799
and action for technologists at MIT and

87
00:03:27,360 --> 00:03:31,959
Beyond uh so let's get into the kind of

88
00:03:29,799 --> 00:03:33,360
you know the nitty-gritty of it um and

89
00:03:31,959 --> 00:03:35,319
uh I'm H I'm going to sort of run

90
00:03:33,360 --> 00:03:36,959
through some history for you here for a

91
00:03:35,319 --> 00:03:38,560
few minutes um I don't I don't have

92
00:03:36,959 --> 00:03:40,360
slides but I'm happy to provide

93
00:03:38,560 --> 00:03:43,000
citations or other information in the

94
00:03:40,360 --> 00:03:44,360
Q&A if people would like to know more um

95
00:03:43,000 --> 00:03:46,200
and you know we certainly know from our

96
00:03:44,360 --> 00:03:48,840
founding documents um some of the key

97
00:03:46,200 --> 00:03:51,080
phrases um that we know pretty well uh

98
00:03:48,840 --> 00:03:52,879
we know all about the pursuit of life

99
00:03:51,080 --> 00:03:54,840
liberty uh or we know about life liberty

100
00:03:52,879 --> 00:03:56,360
and the pursuit of happiness we know

101
00:03:54,840 --> 00:03:59,280
from the Constitution and the Bill of

102
00:03:56,360 --> 00:04:03,079
Rights uh that property uh is protected

103
00:03:59,280 --> 00:04:05,120
from without due process of law um but

104
00:04:03,079 --> 00:04:06,920
one of the phrases that does not appear

105
00:04:05,120 --> 00:04:09,000
in the constitution is the phrase

106
00:04:06,920 --> 00:04:10,640
intellectual property and the

107
00:04:09,000 --> 00:04:12,439
Constitution says that it uses this

108
00:04:10,640 --> 00:04:14,840
nowhere but nevertheless the

109
00:04:12,439 --> 00:04:18,120
Constitution is what protects

110
00:04:14,840 --> 00:04:20,639
intellectual property um as a form of

111
00:04:18,120 --> 00:04:22,919
property in general um and where we can

112
00:04:20,639 --> 00:04:26,000
find this most clearly is in Article 1

113
00:04:22,919 --> 00:04:27,759
Section 8 uh this is part article one

114
00:04:26,000 --> 00:04:30,479
gives Congress the power to do the

115
00:04:27,759 --> 00:04:34,039
following quote to promote promote the

116
00:04:30,479 --> 00:04:37,720
progress of Science and useful Arts by

117
00:04:34,039 --> 00:04:40,720
securing for limited times to authors

118
00:04:37,720 --> 00:04:42,800
and inventors the exclusive right to

119
00:04:40,720 --> 00:04:44,639
their respective writings and

120
00:04:42,800 --> 00:04:47,440
discoveries right so this is the kind of

121
00:04:44,639 --> 00:04:50,440
key phrase that in order to promote the

122
00:04:47,440 --> 00:04:52,720
progress of Science and useful Arts uh

123
00:04:50,440 --> 00:04:55,240
by that Congress gives us the power to

124
00:04:52,720 --> 00:04:57,960
secure for limited times to authors and

125
00:04:55,240 --> 00:05:00,320
inventors the exclusive right to their

126
00:04:57,960 --> 00:05:02,440
respective writings and discoveries

127
00:05:00,320 --> 00:05:04,080
that brief phrase structures all of

128
00:05:02,440 --> 00:05:06,000
intellectual property law in the United

129
00:05:04,080 --> 00:05:07,680
States it emerges from an anglo-american

130
00:05:06,000 --> 00:05:09,520
tradition there are of course versions

131
00:05:07,680 --> 00:05:11,360
in the EU and in other jurisdictions

132
00:05:09,520 --> 00:05:13,880
which I do not have the expertise to

133
00:05:11,360 --> 00:05:16,800
talk about today now this breaks down

134
00:05:13,880 --> 00:05:18,759
into two parts right so for inventors uh

135
00:05:16,800 --> 00:05:20,360
there are patents and again this is not

136
00:05:18,759 --> 00:05:22,080
something that we'll be addressing today

137
00:05:20,360 --> 00:05:23,880
but of course intellectual property

138
00:05:22,080 --> 00:05:27,840
certainly extends to patent law and

139
00:05:23,880 --> 00:05:30,319
other fields uh but for authors uh there

140
00:05:27,840 --> 00:05:32,800
is something called copyright

141
00:05:30,319 --> 00:05:35,280
and we'll focus on the latter here now

142
00:05:32,800 --> 00:05:36,840
copyright um to give a basic definition

143
00:05:35,280 --> 00:05:38,800
and I'm borrowing here from the US

144
00:05:36,840 --> 00:05:41,880
copyright office which is an entity of

145
00:05:38,800 --> 00:05:45,039
the Library of Congress um uh copyright

146
00:05:41,880 --> 00:05:48,680
protects original works of authorship as

147
00:05:45,039 --> 00:05:51,840
soon as a human author fixes the work in

148
00:05:48,680 --> 00:05:53,880
tangible form of expression so you can't

149
00:05:51,840 --> 00:05:57,280
just have the idea you have to fix the

150
00:05:53,880 --> 00:05:59,199
idea in a tangible form of expression

151
00:05:57,280 --> 00:06:01,280
now this could in this takes many forms

152
00:05:59,199 --> 00:06:03,720
this could include a book uh but it

153
00:06:01,280 --> 00:06:05,840
could also include computational code

154
00:06:03,720 --> 00:06:09,319
paintings and photographs musical

155
00:06:05,840 --> 00:06:11,360
compositions uh and the list goes on now

156
00:06:09,319 --> 00:06:14,520
as we think about the implications of

157
00:06:11,360 --> 00:06:17,160
generative AI um it's worth considering

158
00:06:14,520 --> 00:06:18,759
uh maybe three more terms that you might

159
00:06:17,160 --> 00:06:20,520
want to have at your fingertips or that

160
00:06:18,759 --> 00:06:21,880
you might come across as uh you're

161
00:06:20,520 --> 00:06:24,800
reading in this

162
00:06:21,880 --> 00:06:27,479
area but copyright law also spends a

163
00:06:24,800 --> 00:06:29,160
great deal of time uh considering the

164
00:06:27,479 --> 00:06:32,120
the definition and the boundaries of

165
00:06:29,160 --> 00:06:34,639
what is called called derivative Works

166
00:06:32,120 --> 00:06:37,960
um such as translations musical

167
00:06:34,639 --> 00:06:40,520
Arrangements movie adaptations right new

168
00:06:37,960 --> 00:06:43,479
things that come from old things right

169
00:06:40,520 --> 00:06:45,919
that are derived from existing things

170
00:06:43,479 --> 00:06:47,919
and derivative Works can be

171
00:06:45,919 --> 00:06:51,800
copyrighted but they can only be

172
00:06:47,919 --> 00:06:54,120
copyrighted if they are substantially

173
00:06:51,800 --> 00:06:56,879
transformed and if they bear the

174
00:06:54,120 --> 00:06:59,879
personality of the creator of that

175
00:06:56,879 --> 00:07:02,680
derivative work um so you know a

176
00:06:59,879 --> 00:07:05,360
translation of a of a book from from

177
00:07:02,680 --> 00:07:08,120
Japanese into English um can be

178
00:07:05,360 --> 00:07:10,240
copyrighted um if it is if it Bears the

179
00:07:08,120 --> 00:07:13,080
personality of the creator of that

180
00:07:10,240 --> 00:07:14,919
derivative work how I might uh translate

181
00:07:13,080 --> 00:07:16,879
a work is different from you or you or

182
00:07:14,919 --> 00:07:21,160
you right and that's in part what makes

183
00:07:16,879 --> 00:07:23,599
it uh derivative and also therefore uh

184
00:07:21,160 --> 00:07:25,639
copyrightable copyright also extends uh

185
00:07:23,599 --> 00:07:28,639
to the production of or the second term

186
00:07:25,639 --> 00:07:30,400
here transformative work right and to

187
00:07:28,639 --> 00:07:32,199
understand what that means uh courts

188
00:07:30,400 --> 00:07:35,800
have generally seen this as one that

189
00:07:32,199 --> 00:07:38,319
adds new expression meaning or message

190
00:07:35,800 --> 00:07:41,360
to the original work right so so it's

191
00:07:38,319 --> 00:07:43,599
not just a copy right but it is a

192
00:07:41,360 --> 00:07:46,319
transformation um transformative work

193
00:07:43,599 --> 00:07:48,960
also uh does not substitute for the

194
00:07:46,319 --> 00:07:51,080
original use of the work you can't use

195
00:07:48,960 --> 00:07:53,520
the one instead of the other as

196
00:07:51,080 --> 00:07:55,879
equivalence then it's not hasn't been

197
00:07:53,520 --> 00:07:58,560
transformed um and third that it does

198
00:07:55,879 --> 00:08:00,759
not harm the market for the original

199
00:07:58,560 --> 00:08:03,159
work right so if there's something that

200
00:08:00,759 --> 00:08:04,960
claims to be a transformative work but

201
00:08:03,159 --> 00:08:07,560
it essentially puts the the original out

202
00:08:04,960 --> 00:08:09,879
of business and then the the Creator

203
00:08:07,560 --> 00:08:11,560
author of that first work might have a

204
00:08:09,879 --> 00:08:14,560
copyright claim to

205
00:08:11,560 --> 00:08:16,879
make all right third time um and then we

206
00:08:14,560 --> 00:08:19,960
will uh dig into the specifics is the

207
00:08:16,879 --> 00:08:23,000
term fair use that the protections of

208
00:08:19,960 --> 00:08:25,280
copyright do allow for the fair use of

209
00:08:23,000 --> 00:08:29,080
copyrighted Works um and this happens at

210
00:08:25,280 --> 00:08:32,200
MIT every day as MIT faculty you may use

211
00:08:29,080 --> 00:08:35,159
copy wred images in class or share short

212
00:08:32,200 --> 00:08:37,360
readings for educational purposes to a

213
00:08:35,159 --> 00:08:39,760
limited group of students right and this

214
00:08:37,360 --> 00:08:42,159
is you know and there are General

215
00:08:39,760 --> 00:08:44,920
guidelines for fair use that courts have

216
00:08:42,159 --> 00:08:47,399
adjudicated when they do um they use

217
00:08:44,920 --> 00:08:49,920
four uh principles to figure out whether

218
00:08:47,399 --> 00:08:53,240
something is a fair or an unfair use of

219
00:08:49,920 --> 00:08:55,920
a copyrighted work first the purpose of

220
00:08:53,240 --> 00:08:58,480
the use right is there you know is there

221
00:08:55,920 --> 00:09:01,040
purpose to you know to transform or or

222
00:08:58,480 --> 00:09:02,519
duplicate something they would consider

223
00:09:01,040 --> 00:09:04,880
they would look at the nature of the

224
00:09:02,519 --> 00:09:06,959
copyrighted work uh the initial

225
00:09:04,880 --> 00:09:10,800
copyrighted work and whether it is

226
00:09:06,959 --> 00:09:13,040
highly creative or or not third and the

227
00:09:10,800 --> 00:09:15,680
amount of the taking right did you copy

228
00:09:13,040 --> 00:09:17,320
a portion of a book or photocopy the

229
00:09:15,680 --> 00:09:19,560
entire thing right the courts will

230
00:09:17,320 --> 00:09:21,760
consider that something like that and

231
00:09:19,560 --> 00:09:24,640
fourth what is the effect on the market

232
00:09:21,760 --> 00:09:26,600
for the original right does uh you know

233
00:09:24,640 --> 00:09:28,839
does a a fair use of copyrighted

234
00:09:26,600 --> 00:09:30,399
material put the original out of

235
00:09:28,839 --> 00:09:32,240
business

236
00:09:30,399 --> 00:09:34,560
so these are some terms um um is going

237
00:09:32,240 --> 00:09:36,680
to talk about in his presentation about

238
00:09:34,560 --> 00:09:38,680
how this uh affects authors that that he

239
00:09:36,680 --> 00:09:40,040
works with cl Schneider after this is

240
00:09:38,680 --> 00:09:41,640
going to talk about you know some of the

241
00:09:40,040 --> 00:09:43,839
implications of those for the MIT

242
00:09:41,640 --> 00:09:46,440
Community let me just say one more thing

243
00:09:43,839 --> 00:09:48,640
which is this question what is copyright

244
00:09:46,440 --> 00:09:51,720
for U you know what were the founders

245
00:09:48,640 --> 00:09:54,079
aiming to do um in the constitution in

246
00:09:51,720 --> 00:09:55,959
1787 and certainly they they said very

247
00:09:54,079 --> 00:09:57,519
explicitly what they wanted to do they

248
00:09:55,959 --> 00:10:00,640
wanted to promote the progress of

249
00:09:57,519 --> 00:10:03,959
Science and useful Arts right and that

250
00:10:00,640 --> 00:10:05,600
remains I think very important today um

251
00:10:03,959 --> 00:10:09,560
you know almost two Century or more than

252
00:10:05,600 --> 00:10:12,800
two centuries later um they the solution

253
00:10:09,560 --> 00:10:14,839
that they that they hit on in 1787 was

254
00:10:12,800 --> 00:10:16,800
the second part of that Clause right to

255
00:10:14,839 --> 00:10:18,959
secure for limited times to authors and

256
00:10:16,800 --> 00:10:21,399
inventors the exclusive right to their

257
00:10:18,959 --> 00:10:24,000
respective writings and discoveries and

258
00:10:21,399 --> 00:10:27,279
it is not uh immediately clear um that

259
00:10:24,000 --> 00:10:30,640
the solution that was offered in 1787

260
00:10:27,279 --> 00:10:32,200
still works in an age of generative AI

261
00:10:30,640 --> 00:10:33,920
right um and I think that the the

262
00:10:32,200 --> 00:10:36,680
founders would have you know really

263
00:10:33,920 --> 00:10:39,279
thought that fostering intervention inov

264
00:10:36,680 --> 00:10:42,279
sorry fostering Innovation and rewarding

265
00:10:39,279 --> 00:10:44,360
creators were two sides of the same coin

266
00:10:42,279 --> 00:10:47,000
right um and that that balancing test

267
00:10:44,360 --> 00:10:49,279
certainly remains uh important today

268
00:10:47,000 --> 00:10:52,040
some uh now feel that this that the

269
00:10:49,279 --> 00:10:54,279
claims of how that this is at stake have

270
00:10:52,040 --> 00:10:56,240
changed from two directions first from

271
00:10:54,279 --> 00:10:58,279
Publishers who see a threat to their

272
00:10:56,240 --> 00:11:01,240
business model um and who are asserting

273
00:10:58,279 --> 00:11:03,000
copyright claims against generative AI

274
00:11:01,240 --> 00:11:05,040
companies um you may have seen this line

275
00:11:03,000 --> 00:11:07,680
of argument in cases brought by for

276
00:11:05,040 --> 00:11:10,320
example the New York Times um and second

277
00:11:07,680 --> 00:11:12,279
from authors uh who object that large

278
00:11:10,320 --> 00:11:15,000
language models are profiting from their

279
00:11:12,279 --> 00:11:16,800
work and are concerned that llm outputs

280
00:11:15,000 --> 00:11:18,639
May threaten their professional

281
00:11:16,800 --> 00:11:20,320
livelihood now over the course of the

282
00:11:18,639 --> 00:11:23,560
day and of course in other programming

283
00:11:20,320 --> 00:11:25,360
we may do uh at at uh at the college

284
00:11:23,560 --> 00:11:27,200
over the course of the semester we'll

285
00:11:25,360 --> 00:11:29,839
explore these issues and some of the

286
00:11:27,200 --> 00:11:31,240
implications that are at stake but now

287
00:11:29,839 --> 00:11:35,399
what I'm going to do is turn things over

288
00:11:31,240 --> 00:11:37,279
to our guest um um Kazi as I said is the

289
00:11:35,399 --> 00:11:39,040
director of policy and advocacy at the

290
00:11:37,279 --> 00:11:42,440
author's Guild uh this is a professional

291
00:11:39,040 --> 00:11:44,519
organization of over 15,000 writers um

292
00:11:42,440 --> 00:11:46,480
and in his capacity he oversees the

293
00:11:44,519 --> 00:11:48,519
Guild's policy portfolio including

294
00:11:46,480 --> 00:11:50,480
positions on copyright collective

295
00:11:48,519 --> 00:11:52,279
bargaining antitrust and artificial

296
00:11:50,480 --> 00:11:54,560
intelligence so he's a great person to

297
00:11:52,279 --> 00:11:56,920
talk with us today uh he has previously

298
00:11:54,560 --> 00:11:58,760
served as the guild staff attorney uh

299
00:11:56,920 --> 00:12:01,120
and holds a JD from the University of

300
00:11:58,760 --> 00:12:02,680
Iowa col College of Law and also uh

301
00:12:01,120 --> 00:12:05,200
importantly for the author's Guild an

302
00:12:02,680 --> 00:12:07,639
MFA in creative writing from Columbia

303
00:12:05,200 --> 00:12:09,800
University uh and translates poetry from

304
00:12:07,639 --> 00:12:11,880
uru uh with work published in several

305
00:12:09,800 --> 00:12:14,839
literary journals um and has contributed

306
00:12:11,880 --> 00:12:16,440
a chapter on Digital Book piracy um in

307
00:12:14,839 --> 00:12:18,760
the first edition of the rutage

308
00:12:16,440 --> 00:12:22,279
companion to copyright and creativity in

309
00:12:18,760 --> 00:12:24,680
the 21st century um so um uh the the

310
00:12:22,279 --> 00:12:24,680
floor is

311
00:12:27,320 --> 00:12:33,519
yours um thanks thanks everybody thanks

312
00:12:30,760 --> 00:12:37,560
Chris for that wonderful um introduction

313
00:12:33,519 --> 00:12:41,920
and really really great um background on

314
00:12:37,560 --> 00:12:44,399
copyright law it's a I um I kind of fell

315
00:12:41,920 --> 00:12:46,040
into copyright sort of by happen stance

316
00:12:44,399 --> 00:12:47,720
I didn't study copyright when I was in

317
00:12:46,040 --> 00:12:49,920
law school I was going to go into

318
00:12:47,720 --> 00:12:51,760
Finance uh law and then the financial

319
00:12:49,920 --> 00:12:55,079
crisis happened but when I was doing my

320
00:12:51,760 --> 00:12:56,320
MFA I had the opportunity to um start

321
00:12:55,079 --> 00:12:59,320
working for the guild who were looking

322
00:12:56,320 --> 00:13:01,079
for a lawyer at the time and uh it's

323
00:12:59,320 --> 00:13:03,000
it's really one of the most fascinating

324
00:13:01,079 --> 00:13:05,560
areas of the law I think it gets closest

325
00:13:03,000 --> 00:13:07,519
to philosophy at times and um the

326
00:13:05,560 --> 00:13:10,920
questions that we grapple with are are

327
00:13:07,519 --> 00:13:15,360
are so rich and and just have deep

328
00:13:10,920 --> 00:13:17,639
implications for um for for for the way

329
00:13:15,360 --> 00:13:21,440
we you know interact the way we

330
00:13:17,639 --> 00:13:24,680
communicate uh what we read um how we

331
00:13:21,440 --> 00:13:26,920
browse the web uh Etc so um I'll just

332
00:13:24,680 --> 00:13:29,199
start by giving kind of a beef brief

333
00:13:26,920 --> 00:13:32,079
background of the guild and what it is

334
00:13:29,199 --> 00:13:34,480
is what it does and how um we got

335
00:13:32,079 --> 00:13:37,160
involved in generative Ai and in that

336
00:13:34,480 --> 00:13:39,120
process I will um touch on some of the

337
00:13:37,160 --> 00:13:41,480
uh Concepts that Chris introduced uh

338
00:13:39,120 --> 00:13:44,600
fair use uh transform transformative

339
00:13:41,480 --> 00:13:46,560
work uh drift Works Etc so um the

340
00:13:44,600 --> 00:13:49,120
author's Guild is uh the oldest and

341
00:13:46,560 --> 00:13:51,000
largest Professional Organization of uh

342
00:13:49,120 --> 00:13:54,959
writers in the US it has been around

343
00:13:51,000 --> 00:13:57,560
since 1912 um right now we have 15,000

344
00:13:54,959 --> 00:13:59,199
members uh all working authors and we

345
00:13:57,560 --> 00:14:01,440
really focus on this idea of the

346
00:13:59,199 --> 00:14:04,199
professional author which which goes to

347
00:14:01,440 --> 00:14:06,040
our mission of uh providing and creating

348
00:14:04,199 --> 00:14:08,120
fostering an environment where anyone

349
00:14:06,040 --> 00:14:10,160
who wants to write can earn a

350
00:14:08,120 --> 00:14:11,720
sustainable living from their writing

351
00:14:10,160 --> 00:14:15,320
and that's that's a big part of our

352
00:14:11,720 --> 00:14:17,759
mission um we're active um we we are

353
00:14:15,320 --> 00:14:20,839
active in DC as a lobbying group we

354
00:14:17,759 --> 00:14:22,800
Lobby in behalf of authors um a lot of

355
00:14:20,839 --> 00:14:26,839
our work has you know has been in

356
00:14:22,800 --> 00:14:28,720
copyright but we also um given the way

357
00:14:26,839 --> 00:14:32,880
uh the publishing industry has changed

358
00:14:28,720 --> 00:14:35,399
and and and and the the income um

359
00:14:32,880 --> 00:14:37,560
potential for authors has declined uh

360
00:14:35,399 --> 00:14:39,759
We've sort of uh moved into other areas

361
00:14:37,560 --> 00:14:42,600
of the law including antitrust uh one of

362
00:14:39,759 --> 00:14:44,800
the initiatives that we uh have been

363
00:14:42,600 --> 00:14:46,800
working on is to give authors collective

364
00:14:44,800 --> 00:14:49,600
bargaining rights Collective action

365
00:14:46,800 --> 00:14:51,720
rights um because they're independent

366
00:14:49,600 --> 00:14:53,440
contractors under current labor laws

367
00:14:51,720 --> 00:14:55,120
they can't work together which means

368
00:14:53,440 --> 00:14:56,959
that one author cannot talk to another

369
00:14:55,120 --> 00:14:59,160
author about what they're getting in

370
00:14:56,959 --> 00:15:01,600
their contracts and and they can't all

371
00:14:59,160 --> 00:15:03,399
go to the publisher together and say hey

372
00:15:01,600 --> 00:15:04,759
this is unfair these are these are the

373
00:15:03,399 --> 00:15:06,880
kind of terms that we want so that's one

374
00:15:04,759 --> 00:15:10,959
of the things that we've been working on

375
00:15:06,880 --> 00:15:14,800
but um uh pretty much since um late

376
00:15:10,959 --> 00:15:16,560
2022 um uh AI has kind of like been a

377
00:15:14,800 --> 00:15:19,399
daily presence in my

378
00:15:16,560 --> 00:15:21,959
life um not a day goes by I mean it's

379
00:15:19,399 --> 00:15:23,800
just uh you know endless calls on AI

380
00:15:21,959 --> 00:15:27,360
lots of we've done a lot of work on AI

381
00:15:23,800 --> 00:15:29,279
in the last uh now almost two years um

382
00:15:27,360 --> 00:15:34,040
and uh what happened in late ch late

383
00:15:29,279 --> 00:15:37,279
2022 was Chad GPT came online and um we

384
00:15:34,040 --> 00:15:39,639
very quickly just to pause there for a

385
00:15:37,279 --> 00:15:42,920
second and we we we actually were aware

386
00:15:39,639 --> 00:15:46,199
of uh implications of Co of um AI or

387
00:15:42,920 --> 00:15:49,040
copyright um for like a few years before

388
00:15:46,199 --> 00:15:50,839
that because um we had seen prototypes

389
00:15:49,040 --> 00:15:53,279
like I don't know if people have heard

390
00:15:50,839 --> 00:15:56,839
of the next rembrand it sounds like now

391
00:15:53,279 --> 00:16:00,920
it sounds like Atari but um you know I

392
00:15:56,839 --> 00:16:02,720
think in 20 20 18 or so it was uh kind

393
00:16:00,920 --> 00:16:06,319
of like the state-of-the-art AI model

394
00:16:02,720 --> 00:16:08,519
and it was a um AI that could developed

395
00:16:06,319 --> 00:16:13,199
by Microsoft that could uh generate

396
00:16:08,519 --> 00:16:16,199
images in the style of rbrand um and um

397
00:16:13,199 --> 00:16:19,959
so we were aware of the questions that

398
00:16:16,199 --> 00:16:21,759
AI raised for copyright um one of the

399
00:16:19,959 --> 00:16:24,759
questions I'm I'm glad you mentioned

400
00:16:21,759 --> 00:16:27,839
that in your um in in your definition of

401
00:16:24,759 --> 00:16:29,759
copyright you mentioned human author and

402
00:16:27,839 --> 00:16:33,000
um there that was actually a huge

403
00:16:29,759 --> 00:16:35,240
question uh at the time um it has to a a

404
00:16:33,000 --> 00:16:37,920
large degree been resolved but the

405
00:16:35,240 --> 00:16:41,680
question was what happens when uh a

406
00:16:37,920 --> 00:16:43,880
machine creates um uh a work of uh you

407
00:16:41,680 --> 00:16:46,319
know a work of art a work of literature

408
00:16:43,880 --> 00:16:48,480
writing do we does does the machine own

409
00:16:46,319 --> 00:16:51,319
copyright who owns copyright in that

410
00:16:48,480 --> 00:16:55,000
creation um and there is a long

411
00:16:51,319 --> 00:16:57,040
tradition in copyright law of of um

412
00:16:55,000 --> 00:16:59,720
recognizing that it is that copyright

413
00:16:57,040 --> 00:17:01,959
only belongs to the human author um

414
00:16:59,720 --> 00:17:06,319
there are there's a long line of cases

415
00:17:01,959 --> 00:17:09,400
um the the the the idea started really

416
00:17:06,319 --> 00:17:11,400
kind of becoming um um or or getting

417
00:17:09,400 --> 00:17:14,319
fleshed out in the early 20th century

418
00:17:11,400 --> 00:17:17,079
with the Advent of uh of

419
00:17:14,319 --> 00:17:19,160
Photography um where courts grappled

420
00:17:17,079 --> 00:17:22,319
with uh the question of whether or not

421
00:17:19,160 --> 00:17:26,400
there was any um um originality of

422
00:17:22,319 --> 00:17:27,919
expression in in the work and so the the

423
00:17:26,400 --> 00:17:29,280
the the question of what is human

424
00:17:27,919 --> 00:17:31,039
authorship is it the machine that's

425
00:17:29,280 --> 00:17:33,000
creating or is it the author that's or

426
00:17:31,039 --> 00:17:36,200
is it the human that's creating really

427
00:17:33,000 --> 00:17:39,880
became a focal point of uh of uh early

428
00:17:36,200 --> 00:17:44,160
sort of uh copyright um um uh

429
00:17:39,880 --> 00:17:48,440
discussions around AI um in

430
00:17:44,160 --> 00:17:52,120
2023 the copyright office uh came out

431
00:17:48,440 --> 00:17:55,280
with a guidance document that U

432
00:17:52,120 --> 00:17:57,200
essentially um uh talked about how it

433
00:17:55,280 --> 00:18:01,039
would register works that were created

434
00:17:57,200 --> 00:18:03,200
using Ai and and they following the long

435
00:18:01,039 --> 00:18:05,440
line of cases they said that they would

436
00:18:03,200 --> 00:18:06,679
not register works that or they would

437
00:18:05,440 --> 00:18:09,000
not not that they would not register

438
00:18:06,679 --> 00:18:11,640
works that they would that the author or

439
00:18:09,000 --> 00:18:15,720
anyone claiming registration in the work

440
00:18:11,640 --> 00:18:18,120
uh that had some AI um use would have to

441
00:18:15,720 --> 00:18:19,559
disclaim the parts that they did not

442
00:18:18,120 --> 00:18:20,600
themselves create that were not created

443
00:18:19,559 --> 00:18:23,159
by a human

444
00:18:20,600 --> 00:18:26,880
author um so that's where we're at right

445
00:18:23,159 --> 00:18:29,440
now if you use table diffusion or um any

446
00:18:26,880 --> 00:18:33,440
number of image generating AI to make an

447
00:18:29,440 --> 00:18:35,919
image um unless you modify it in a

448
00:18:33,440 --> 00:18:38,760
certain way that's not copyrightable and

449
00:18:35,919 --> 00:18:40,840
even then only the parts that are um

450
00:18:38,760 --> 00:18:43,240
that have uh human authorship and

451
00:18:40,840 --> 00:18:47,240
original expression only those parts are

452
00:18:43,240 --> 00:18:50,840
copyrightable so um for example you

453
00:18:47,240 --> 00:18:52,440
could have um um there was one

454
00:18:50,840 --> 00:18:54,720
interesting example that I heard

455
00:18:52,440 --> 00:18:57,559
recently where someone had created an

456
00:18:54,720 --> 00:18:59,320
artwork but only used like a dog that

457
00:18:57,559 --> 00:19:01,559
was generated by AI and they were

458
00:18:59,320 --> 00:19:02,840
thinking about copyrighting it and you

459
00:19:01,559 --> 00:19:05,480
know the answer is well yeah the

460
00:19:02,840 --> 00:19:09,000
copyright office will register the

461
00:19:05,480 --> 00:19:10,960
artwork but you have to disclaim the dog

462
00:19:09,000 --> 00:19:13,760
and the dog will not be so anything that

463
00:19:10,960 --> 00:19:15,960
is generated by a machine is actually uh

464
00:19:13,760 --> 00:19:20,720
is not protected so anyone else can use

465
00:19:15,960 --> 00:19:23,159
it um without any any need for any

466
00:19:20,720 --> 00:19:25,559
authorization so um that was one of the

467
00:19:23,159 --> 00:19:29,400
questions um that we were grappling with

468
00:19:25,559 --> 00:19:31,799
uh at the time we weren't really aware

469
00:19:29,400 --> 00:19:34,280
of there wasn't a whole lot that we were

470
00:19:31,799 --> 00:19:37,200
aware of as far as how training is done

471
00:19:34,280 --> 00:19:41,240
and since then the primary focus for us

472
00:19:37,200 --> 00:19:43,440
has been the ingestion of um books and

473
00:19:41,240 --> 00:19:45,799
other copyrighted materials when it

474
00:19:43,440 --> 00:19:49,880
comes to training um you know when you

475
00:19:45,799 --> 00:19:51,520
train in llm you um you you need all

476
00:19:49,880 --> 00:19:53,480
kinds of data right you know you know in

477
00:19:51,520 --> 00:19:55,799
computer science parland you just say

478
00:19:53,480 --> 00:19:57,240
data but like this data also includes in

479
00:19:55,799 --> 00:20:01,240
some cases hundreds of thousands of

480
00:19:57,240 --> 00:20:05,240
books and uh um we know in some cases we

481
00:20:01,240 --> 00:20:07,840
know the models and the books that they

482
00:20:05,240 --> 00:20:10,200
were trained on uh in other cases we

483
00:20:07,840 --> 00:20:11,559
don't um some of the models out there

484
00:20:10,200 --> 00:20:13,200
some of the large language models are

485
00:20:11,559 --> 00:20:17,320
blackbox models like

486
00:20:13,200 --> 00:20:20,480
anthropic um and uh the GPT models after

487
00:20:17,320 --> 00:20:22,200
3.5 so we don't really know the data

488
00:20:20,480 --> 00:20:25,000
composition the training data

489
00:20:22,200 --> 00:20:27,760
composition in those cases um but we do

490
00:20:25,000 --> 00:20:31,200
know by analogy from what developers

491
00:20:27,760 --> 00:20:35,159
have told us um for for instance uh

492
00:20:31,200 --> 00:20:38,320
llama um used a data set called um the

493
00:20:35,159 --> 00:20:40,600
pile which uh includes a subd DAT set

494
00:20:38,320 --> 00:20:42,480
called books three which which is

495
00:20:40,600 --> 00:20:45,919
comprised of 200,000 books that were

496
00:20:42,480 --> 00:20:50,440
downloaded from a pirate site so and um

497
00:20:45,919 --> 00:20:52,960
oddly enough This was um this was uh

498
00:20:50,440 --> 00:20:56,080
this was revealed by the the developers

499
00:20:52,960 --> 00:20:59,360
of meta in a paper they put out um where

500
00:20:56,080 --> 00:21:01,000
they got the data set and so for us that

501
00:20:59,360 --> 00:21:02,520
is a huge concern you know I mean if

502
00:21:01,000 --> 00:21:05,480
developers are going out there and

503
00:21:02,520 --> 00:21:07,280
instead of Licensing the books they are

504
00:21:05,480 --> 00:21:10,279
downloading pirated copies and then

505
00:21:07,280 --> 00:21:14,840
training large language models on them

506
00:21:10,279 --> 00:21:18,159
um that's that's ultimately uh one it's

507
00:21:14,840 --> 00:21:20,080
unethical because uh you know as in in

508
00:21:18,159 --> 00:21:22,440
the definition that that Chris mentioned

509
00:21:20,080 --> 00:21:25,840
of copyright there's a key term called

510
00:21:22,440 --> 00:21:29,520
exclusive so the exclusive right means

511
00:21:25,840 --> 00:21:33,000
that you as the in ventor you know in

512
00:21:29,520 --> 00:21:35,760
the patent um uh scenario or you as the

513
00:21:33,000 --> 00:21:38,880
author or the or the Artist as the

514
00:21:35,760 --> 00:21:40,799
creator of that work you uh you can

515
00:21:38,880 --> 00:21:43,480
exclude anyone else from using that work

516
00:21:40,799 --> 00:21:46,440
you decide who gets to use that work on

517
00:21:43,480 --> 00:21:48,760
what terms uh Etc and it's a limited

518
00:21:46,440 --> 00:21:53,440
Monopoly that that Congress created

519
00:21:48,760 --> 00:21:56,120
precisely to encourage Innovation um so

520
00:21:53,440 --> 00:21:58,360
um so so yes so uh you know when you

521
00:21:56,120 --> 00:22:00,600
download a book or download 200,000

522
00:21:58,360 --> 00:22:02,840
books books to train a model uh you are

523
00:22:00,600 --> 00:22:06,760
infringing on the exclusive rights of

524
00:22:02,840 --> 00:22:09,600
the author now um there are legal

525
00:22:06,760 --> 00:22:13,640
nuances that um I'll go into a little

526
00:22:09,600 --> 00:22:15,840
bit uh Chris also mentioned this uh this

527
00:22:13,640 --> 00:22:18,000
the the the the notion of fair use which

528
00:22:15,840 --> 00:22:20,720
is a very key Concept in copyright law

529
00:22:18,000 --> 00:22:23,120
and that basically allows um it's it's

530
00:22:20,720 --> 00:22:25,080
not um it's it's not a suspension of

531
00:22:23,120 --> 00:22:28,520
copyright but it's it's essentially an

532
00:22:25,080 --> 00:22:31,159
excuse um because uh courts understand

533
00:22:28,520 --> 00:22:33,360
and that the the copyright Clause begins

534
00:22:31,159 --> 00:22:36,000
with the preface for the advancement of

535
00:22:33,360 --> 00:22:38,840
Arts and Sciences so there is a public

536
00:22:36,000 --> 00:22:42,080
uh kind of good element in the copyright

537
00:22:38,840 --> 00:22:44,799
clause and fair use facilitates that

538
00:22:42,080 --> 00:22:47,400
fair use says if there is something that

539
00:22:44,799 --> 00:22:50,159
is being something being innovated then

540
00:22:47,400 --> 00:22:52,760
you can use a copyrighted work without

541
00:22:50,159 --> 00:22:56,039
permission now there are the four

542
00:22:52,760 --> 00:22:58,720
factors um the amount and substantiality

543
00:22:56,039 --> 00:23:02,880
of the use the nature of the copyrighted

544
00:22:58,720 --> 00:23:05,720
work um the um I always blank on the

545
00:23:02,880 --> 00:23:09,159
third Factor the the effect on the

546
00:23:05,720 --> 00:23:13,960
potential Market of the work

547
00:23:09,159 --> 00:23:17,159
um what is the third Factor R the yes

548
00:23:13,960 --> 00:23:19,200
yes so the amount of the taking so so

549
00:23:17,159 --> 00:23:21,320
it's it's like it's a it's it's

550
00:23:19,200 --> 00:23:23,120
essentially a balancing test and not and

551
00:23:21,320 --> 00:23:25,600
and courts when they look at these

552
00:23:23,120 --> 00:23:27,240
questions they can they can give they're

553
00:23:25,600 --> 00:23:29,360
not supposed to give equal weight to any

554
00:23:27,240 --> 00:23:32,679
of the factors so in some cases the

555
00:23:29,360 --> 00:23:36,000
court might say um you know because okay

556
00:23:32,679 --> 00:23:39,120
so one example the from a recent case uh

557
00:23:36,000 --> 00:23:43,200
Supreme Court case was um um uh Andy

558
00:23:39,120 --> 00:23:44,600
warhall did a screen print based on the

559
00:23:43,200 --> 00:23:46,400
photograph that was taken by a

560
00:23:44,600 --> 00:23:48,760
photographer now the LI the photo of

561
00:23:46,400 --> 00:23:52,000
Prince um the artist formerly known as

562
00:23:48,760 --> 00:23:55,240
Prince uh now the photographer licensed

563
00:23:52,000 --> 00:23:57,440
uh the prince images on her own and then

564
00:23:55,240 --> 00:24:00,520
Andy Warhol silk screen Prince were

565
00:23:57,440 --> 00:24:03,000
competing in the same Market as the um

566
00:24:00,520 --> 00:24:04,440
as as the photographers uh the Court

567
00:24:03,000 --> 00:24:07,360
Supreme Court when it looked at the four

568
00:24:04,440 --> 00:24:09,840
factors it it it it gave more weight

569
00:24:07,360 --> 00:24:11,640
even though it found that the work was

570
00:24:09,840 --> 00:24:14,720
what is called transformative that it

571
00:24:11,640 --> 00:24:18,000
added a new medium meaning or message to

572
00:24:14,720 --> 00:24:20,120
the original photo of Prince it did so

573
00:24:18,000 --> 00:24:22,440
in a way that had a profound impact on

574
00:24:20,120 --> 00:24:24,039
the market for the work so in that case

575
00:24:22,440 --> 00:24:26,039
the court weighed the fourth factor a

576
00:24:24,039 --> 00:24:28,720
little heavily and came out and said

577
00:24:26,039 --> 00:24:31,799
this is actually not fair use uh and

578
00:24:28,720 --> 00:24:33,440
this was actually infringement so it's

579
00:24:31,799 --> 00:24:35,200
it's you know fair use is interesting

580
00:24:33,440 --> 00:24:38,840
I'm not a litigator but I've been around

581
00:24:35,200 --> 00:24:41,960
litigators who litigate fair use and um

582
00:24:38,840 --> 00:24:43,720
it's it's you never know you never know

583
00:24:41,960 --> 00:24:46,159
how it's going to come out you can be

584
00:24:43,720 --> 00:24:47,640
sure of your arguments and when you get

585
00:24:46,159 --> 00:24:52,159
go in the courts looking at it in a

586
00:24:47,640 --> 00:24:54,679
certain way but um the the the what's

587
00:24:52,159 --> 00:24:57,559
and this in the ongoing litigations now

588
00:24:54,679 --> 00:25:00,679
there are several ongoing litigations um

589
00:24:57,559 --> 00:25:03,240
over AI generative AI there litigations

590
00:25:00,679 --> 00:25:05,080
in image um against able diffusion

591
00:25:03,240 --> 00:25:07,279
against meta pretty much any com any

592
00:25:05,080 --> 00:25:09,240
company that develops AI is facing a

593
00:25:07,279 --> 00:25:11,799
lawsuit right now uh there's also

594
00:25:09,240 --> 00:25:13,600
several um I believe by last count there

595
00:25:11,799 --> 00:25:16,200
were uh

596
00:25:13,600 --> 00:25:18,399
13 lawsuits against large language

597
00:25:16,200 --> 00:25:20,840
models that were just brought by authors

598
00:25:18,399 --> 00:25:22,320
and Publishers uh they're all class

599
00:25:20,840 --> 00:25:25,520
action most of them are class action

600
00:25:22,320 --> 00:25:27,799
lawsuits um so that means that if and

601
00:25:25,520 --> 00:25:28,840
when the lawsuits progress they could

602
00:25:27,799 --> 00:25:32,559
cover

603
00:25:28,840 --> 00:25:34,600
you know thousands of people but uh the

604
00:25:32,559 --> 00:25:36,880
the key question that will come up in

605
00:25:34,600 --> 00:25:38,679
this lawsuits and it hasn't come up yet

606
00:25:36,880 --> 00:25:41,600
because the defendants the AI companies

607
00:25:38,679 --> 00:25:43,440
hasn't haven't asserted a defense yet is

608
00:25:41,600 --> 00:25:46,480
that they will say

609
00:25:43,440 --> 00:25:49,799
that um I'm just trying to be mindful of

610
00:25:46,480 --> 00:25:51,960
time too so okay um they will they will

611
00:25:49,799 --> 00:25:53,679
say that our use is actually fair use

612
00:25:51,960 --> 00:25:55,520
because we are transforming the work we

613
00:25:53,679 --> 00:25:58,600
are transforming the work into something

614
00:25:55,520 --> 00:26:01,520
new a new technology now the problem

615
00:25:58,600 --> 00:26:03,279
with that uh argument that we see a big

616
00:26:01,520 --> 00:26:07,279
problem is that these Technologies are

617
00:26:03,279 --> 00:26:09,440
capable of uh in you know in many cases

618
00:26:07,279 --> 00:26:13,440
actually reproducing the work you know

619
00:26:09,440 --> 00:26:17,399
you can we have filters now in in in in

620
00:26:13,440 --> 00:26:19,600
in a lot of the public facing AIS but um

621
00:26:17,399 --> 00:26:22,760
you know we know from experimentation

622
00:26:19,600 --> 00:26:25,279
that um in many cases the AI can

623
00:26:22,760 --> 00:26:27,799
reproduce verbatim the the contents of

624
00:26:25,279 --> 00:26:29,159
what it has ingested um they've been

625
00:26:27,799 --> 00:26:32,000
experiments to show that people are

626
00:26:29,159 --> 00:26:36,120
working on on on on these Solutions all

627
00:26:32,000 --> 00:26:38,679
the time um there's also in other in in

628
00:26:36,120 --> 00:26:40,480
other situations the AI can be prompted

629
00:26:38,679 --> 00:26:42,760
to produce a derivative work for

630
00:26:40,480 --> 00:26:44,840
instance um Chris mentioned derivative

631
00:26:42,760 --> 00:26:46,679
Works uh one example of a derivative

632
00:26:44,840 --> 00:26:48,440
work is a very common example of a

633
00:26:46,679 --> 00:26:50,399
derivative work is a is a film

634
00:26:48,440 --> 00:26:53,039
adaptation or a screenplay based on a

635
00:26:50,399 --> 00:26:56,279
book and you can easily use an AI to do

636
00:26:53,039 --> 00:26:58,279
that so what I'm trying to get at is

637
00:26:56,279 --> 00:27:00,559
that the technology even though there is

638
00:26:58,279 --> 00:27:03,520
is something that's new happening to the

639
00:27:00,559 --> 00:27:06,880
work conceivably it is also a technology

640
00:27:03,520 --> 00:27:09,399
that is has um that that can

641
00:27:06,880 --> 00:27:11,640
completely EV eviscerate the market for

642
00:27:09,399 --> 00:27:13,440
The Works uh not not just the works but

643
00:27:11,640 --> 00:27:16,799
eviscerate the market for the rights in

644
00:27:13,440 --> 00:27:20,360
those works so uh you know uh if if you

645
00:27:16,799 --> 00:27:22,240
can use AI to uh create a screenplay

646
00:27:20,360 --> 00:27:25,679
that will diminish the value of the film

647
00:27:22,240 --> 00:27:27,480
rights in a book uh if you can use uh AI

648
00:27:25,679 --> 00:27:30,200
to in in some cases you know when we

649
00:27:27,480 --> 00:27:32,039
were in in when we were experimenting

650
00:27:30,200 --> 00:27:34,240
with GPT and trying to figure out what

651
00:27:32,039 --> 00:27:36,399
it could do from the perspective of um

652
00:27:34,240 --> 00:27:39,159
an author or a published work one of the

653
00:27:36,399 --> 00:27:43,159
things that it it can very easily do is

654
00:27:39,159 --> 00:27:45,480
uh or other AIS can do is create a um a

655
00:27:43,159 --> 00:27:48,679
hypothetical SQL to the work which again

656
00:27:45,480 --> 00:27:51,000
is a d d an exclusive derivative right

657
00:27:48,679 --> 00:27:54,080
that um every author has under copyright

658
00:27:51,000 --> 00:27:56,399
I'll just um I I I I don't think you

659
00:27:54,080 --> 00:27:58,600
mentioned this but basically copyright

660
00:27:56,399 --> 00:28:01,279
itself is a bundle of six exclusive

661
00:27:58,600 --> 00:28:03,360
rights um the right to reproduce the

662
00:28:01,279 --> 00:28:06,840
work the right to publicly perform the

663
00:28:03,360 --> 00:28:08,880
work the right to um uh uh create

664
00:28:06,840 --> 00:28:10,880
derivative works of the work which is

665
00:28:08,880 --> 00:28:12,720
you know you can you can use your work

666
00:28:10,880 --> 00:28:15,320
to create a new work or license it to

667
00:28:12,720 --> 00:28:17,519
somebody else uh the light the right to

668
00:28:15,320 --> 00:28:20,000
distribute copies of the work and there

669
00:28:17,519 --> 00:28:23,200
is one that's called that's a specific

670
00:28:20,000 --> 00:28:25,200
mechanical right uh for um media the

671
00:28:23,200 --> 00:28:27,039
right to publicly display the work and

672
00:28:25,200 --> 00:28:28,679
then the sixth right is a specific

673
00:28:27,039 --> 00:28:33,120
mechanical right

674
00:28:28,679 --> 00:28:37,919
um so so these six rights together are

675
00:28:33,120 --> 00:28:40,080
what enable any um publishing contract

676
00:28:37,919 --> 00:28:42,440
to come into existence they enable any

677
00:28:40,080 --> 00:28:44,720
film rights deal to come into existence

678
00:28:42,440 --> 00:28:46,799
the film rights deal is premised on the

679
00:28:44,720 --> 00:28:49,320
right to create a derivative work a

680
00:28:46,799 --> 00:28:51,399
translation contract is premised on the

681
00:28:49,320 --> 00:28:53,799
right to create a derivative work uh

682
00:28:51,399 --> 00:28:56,440
publishing contract incorporates the

683
00:28:53,799 --> 00:28:58,399
right to display the work the right to

684
00:28:56,440 --> 00:29:02,600
reproduce copies and distribute copies

685
00:28:58,399 --> 00:29:04,159
of the work so um so the value of all of

686
00:29:02,600 --> 00:29:06,159
those rights it's not just that the

687
00:29:04,159 --> 00:29:08,600
value of like a book will go down that

688
00:29:06,159 --> 00:29:11,120
people will stop buying a book but what

689
00:29:08,600 --> 00:29:12,799
will happen is that there will be the

690
00:29:11,120 --> 00:29:14,799
the transactions that happen right now

691
00:29:12,799 --> 00:29:17,159
for authors and Publishers the value of

692
00:29:14,799 --> 00:29:21,120
those rights will go down so that's a

693
00:29:17,159 --> 00:29:23,399
that's a big concern for us um let's see

694
00:29:21,120 --> 00:29:25,279
um there's so much that I can I can I

695
00:29:23,399 --> 00:29:26,799
can talk about I don't want to go over

696
00:29:25,279 --> 00:29:30,039
time

697
00:29:26,799 --> 00:29:30,039
um um

698
00:29:31,120 --> 00:29:38,360
um just looking at my notes um because I

699
00:29:35,120 --> 00:29:40,240
know that we will have things to talk

700
00:29:38,360 --> 00:29:43,240
about during the Q&A as

701
00:29:40,240 --> 00:29:43,240
well

702
00:29:43,600 --> 00:29:48,279
um yeah um the so maybe I can mention

703
00:29:47,039 --> 00:29:50,720
some of the other things that we're

704
00:29:48,279 --> 00:29:54,320
doing uh because we see this challenge

705
00:29:50,720 --> 00:29:58,399
the the the the uh and we really want to

706
00:29:54,320 --> 00:30:01,200
preserve this the human right writing

707
00:29:58,399 --> 00:30:03,880
profession because um there is no

708
00:30:01,200 --> 00:30:05,799
underestimating it AI is is is posing a

709
00:30:03,880 --> 00:30:07,840
pretty existential threat to this

710
00:30:05,799 --> 00:30:13,039
profession um and I'll talk a little bit

711
00:30:07,840 --> 00:30:15,440
more about in our Q&A um but um so we

712
00:30:13,039 --> 00:30:17,679
are active on several fronts we are

713
00:30:15,440 --> 00:30:20,840
working with um members of Congress to

714
00:30:17,679 --> 00:30:22,840
introduce uh legislation and uh

715
00:30:20,840 --> 00:30:24,559
regulations that will protect human

716
00:30:22,840 --> 00:30:28,440
authorship the way we're trying to do it

717
00:30:24,559 --> 00:30:30,679
is um one is that we need to know what

718
00:30:28,440 --> 00:30:33,360
is being ingested by the models I mean I

719
00:30:30,679 --> 00:30:36,360
think there's an interest in this this

720
00:30:33,360 --> 00:30:38,159
policy from a a lot of different uh

721
00:30:36,360 --> 00:30:40,519
groups you know privacy groups are

722
00:30:38,159 --> 00:30:42,120
interested in that you know we should be

723
00:30:40,519 --> 00:30:44,360
able to as consumers we should be able

724
00:30:42,120 --> 00:30:46,120
to know what's being what's being put

725
00:30:44,360 --> 00:30:49,320
into the large language models or like

726
00:30:46,120 --> 00:30:51,320
other other AI the the second thing that

727
00:30:49,320 --> 00:30:54,640
we are concerned about is the market

728
00:30:51,320 --> 00:30:57,080
harm to human created Works which is why

729
00:30:54,640 --> 00:30:59,919
we've been supportive of and pushing for

730
00:30:57,080 --> 00:31:03,320
um uh disclosure requirements on AI

731
00:30:59,919 --> 00:31:06,440
generated um images um text and other

732
00:31:03,320 --> 00:31:08,639
types of content and again you know like

733
00:31:06,440 --> 00:31:11,399
the we can come at it from copyright but

734
00:31:08,639 --> 00:31:14,519
the thing is the the the ramifications

735
00:31:11,399 --> 00:31:17,000
of AI you know they really radiate into

736
00:31:14,519 --> 00:31:19,080
other uh spheres of our life so for

737
00:31:17,000 --> 00:31:21,039
instance disclosure you know we are

738
00:31:19,080 --> 00:31:23,720
interested in it from the point of

739
00:31:21,039 --> 00:31:26,880
preserving a market but there are other

740
00:31:23,720 --> 00:31:29,080
um um policy reasons for for requiring

741
00:31:26,880 --> 00:31:31,240
disclosures uh non-consensual

742
00:31:29,080 --> 00:31:33,559
pornography is one of the ones that is

743
00:31:31,240 --> 00:31:36,200
often very often cited as the biggest

744
00:31:33,559 --> 00:31:37,919
reason for um you know there being a

745
00:31:36,200 --> 00:31:41,159
disclosure requirement so people know

746
00:31:37,919 --> 00:31:44,480
that something is AI generated versus um

747
00:31:41,159 --> 00:31:46,840
you know quote unquote real um we're

748
00:31:44,480 --> 00:31:50,519
also involved in a in a lawsuit right

749
00:31:46,840 --> 00:31:53,159
now against open Ai and Microsoft that

750
00:31:50,519 --> 00:31:55,639
that is a class action lawsuit uh with

751
00:31:53,159 --> 00:31:58,360
uh 13 bestselling authors as the class

752
00:31:55,639 --> 00:32:00,480
plaintiffs um and all of the lawsuits

753
00:31:58,360 --> 00:32:04,120
including ours are simply are premised

754
00:32:00,480 --> 00:32:06,039
on the the the the the the simple

755
00:32:04,120 --> 00:32:07,919
allegation that in the course of

756
00:32:06,039 --> 00:32:10,639
creating large language models

757
00:32:07,919 --> 00:32:13,880
developers uh made illegal copies of the

758
00:32:10,639 --> 00:32:16,399
works full copies because as we know um

759
00:32:13,880 --> 00:32:19,760
you know the the training data set it's

760
00:32:16,399 --> 00:32:22,600
um in in self-supervised training uh you

761
00:32:19,760 --> 00:32:24,159
you don't really break it down or or

762
00:32:22,600 --> 00:32:26,120
annotate or anything you just kind of

763
00:32:24,159 --> 00:32:28,679
throw all of the text that you can find

764
00:32:26,120 --> 00:32:32,480
in a large in a large f and run

765
00:32:28,679 --> 00:32:34,720
algorithms on it so and that actually is

766
00:32:32,480 --> 00:32:36,200
a violation of one of the exclusive

767
00:32:34,720 --> 00:32:38,039
rights which is the right to reprod the

768
00:32:36,200 --> 00:32:40,279
exclusive right to reproduce the work so

769
00:32:38,039 --> 00:32:42,000
by making a copy to train a large

770
00:32:40,279 --> 00:32:44,000
language model you're actually uh

771
00:32:42,000 --> 00:32:45,799
committing a copyright infringement

772
00:32:44,000 --> 00:32:48,519
violation against the author so that's

773
00:32:45,799 --> 00:32:50,760
that's what the lawsuit is premised on

774
00:32:48,519 --> 00:32:55,000
um it's it's it's still in its early

775
00:32:50,760 --> 00:32:57,559
stages um uh in fact like our CEO was in

776
00:32:55,000 --> 00:33:00,399
a deposition yesterday so we'll see

777
00:32:57,559 --> 00:33:03,519
we'll see how things uh things go from

778
00:33:00,399 --> 00:33:05,399
here um and but the likely scenario is

779
00:33:03,519 --> 00:33:09,080
that fair use is going to play a pretty

780
00:33:05,399 --> 00:33:11,679
big role um in the coming months uh

781
00:33:09,080 --> 00:33:12,960
especially in this landscape so I think

782
00:33:11,679 --> 00:33:15,120
I'll stop there and maybe we can

783
00:33:12,960 --> 00:33:17,279
continue to q&as because I'm sure the

784
00:33:15,120 --> 00:33:20,679
audience might have

785
00:33:17,279 --> 00:33:24,880
some thank you um

786
00:33:20,679 --> 00:33:26,760
so I think these are on yep they on um

787
00:33:24,880 --> 00:33:28,360
so before we get to the the public Q now

788
00:33:26,760 --> 00:33:31,080
I'm going to just kick off with one or

789
00:33:28,360 --> 00:33:33,919
two questions for um for some things

790
00:33:31,080 --> 00:33:35,840
that we had been emailing about in the

791
00:33:33,919 --> 00:33:39,880
last few days and and weeks and kind of

792
00:33:35,840 --> 00:33:41,559
leading up to this um and one is um I

793
00:33:39,880 --> 00:33:44,120
wanted to just talk a little bit about

794
00:33:41,559 --> 00:33:47,600
what it what it would mean to the

795
00:33:44,120 --> 00:33:49,080
author's Guild uh to win a case like

796
00:33:47,600 --> 00:33:52,120
this and let me say more about what you

797
00:33:49,080 --> 00:33:54,240
know what I mean that the legal system

798
00:33:52,120 --> 00:33:58,080
is designed to produce sort of winners

799
00:33:54,240 --> 00:34:01,440
and losers right um but uh is there is

800
00:33:58,080 --> 00:34:04,600
there a win-win scenario right one that

801
00:34:01,440 --> 00:34:07,800
both protects author's rights and

802
00:34:04,600 --> 00:34:11,119
fosters Innovation um at the kind of

803
00:34:07,800 --> 00:34:13,399
scale that that the the for-profit um

804
00:34:11,119 --> 00:34:15,079
and non-for-profit AI providers have

805
00:34:13,399 --> 00:34:17,480
been have been accomplishing in the last

806
00:34:15,079 --> 00:34:20,359
couple years y thanks that's actually a

807
00:34:17,480 --> 00:34:22,919
really good question um you know we are

808
00:34:20,359 --> 00:34:25,040
not uh winning for us does not mean

809
00:34:22,919 --> 00:34:29,040
destroying AI That's not something that

810
00:34:25,040 --> 00:34:30,879
we are interested in I think the the and

811
00:34:29,040 --> 00:34:32,280
and some in some days it seems hard to

812
00:34:30,879 --> 00:34:34,119
even imagine what winning looks like

813
00:34:32,280 --> 00:34:36,240
given the kind of insurmountable

814
00:34:34,119 --> 00:34:38,320
disruptions at times that we're seeing

815
00:34:36,240 --> 00:34:41,280
but we do have some very strong Notions

816
00:34:38,320 --> 00:34:44,320
as to as to how we can come out of this

817
00:34:41,280 --> 00:34:46,599
um while preserving you know um not just

818
00:34:44,320 --> 00:34:50,119
the writing profession but this uh

819
00:34:46,599 --> 00:34:54,280
really special kind of place for human

820
00:34:50,119 --> 00:34:56,280
creativity um and uh the the the it

821
00:34:54,280 --> 00:34:59,680
really does come down to licensing I

822
00:34:56,280 --> 00:35:03,680
think you know as long as AI companies

823
00:34:59,680 --> 00:35:07,240
and developers are um being ethical and

824
00:35:03,680 --> 00:35:09,480
legal really about their acquisition of

825
00:35:07,240 --> 00:35:11,599
the works that they're trained on then

826
00:35:09,480 --> 00:35:15,320
we can start sort of moving moving

827
00:35:11,599 --> 00:35:18,000
towards a um a responsible uh future for

828
00:35:15,320 --> 00:35:20,200
the development of generative AI but if

829
00:35:18,000 --> 00:35:22,720
you're uh you know if the developers are

830
00:35:20,200 --> 00:35:26,560
going out there and downloading uh

831
00:35:22,720 --> 00:35:28,440
caches of of books from Pirate sites um

832
00:35:26,560 --> 00:35:31,760
then we're already sort of starting off

833
00:35:28,440 --> 00:35:33,280
from a from a very wrong point of view

834
00:35:31,760 --> 00:35:36,280
in in one of the documents from the

835
00:35:33,280 --> 00:35:39,720
author's Guild um it has this sort of

836
00:35:36,280 --> 00:35:42,280
three-part principle of uh consent

837
00:35:39,720 --> 00:35:43,599
credit and compensation um so maybe just

838
00:35:42,280 --> 00:35:46,800
talk a little bit more about that yeah

839
00:35:43,599 --> 00:35:49,880
absolutely so um you know the consent is

840
00:35:46,800 --> 00:35:53,599
a way to sort of reinforce the idea that

841
00:35:49,880 --> 00:35:53,599
authors um and

842
00:35:53,920 --> 00:35:58,680
and uh can you guys hear me okay yeah uh

843
00:35:57,079 --> 00:36:00,560
consent is sorry consent just to

844
00:35:58,680 --> 00:36:03,280
reinforce the idea that authors and

845
00:36:00,560 --> 00:36:06,960
creators uh have the exclusive right you

846
00:36:03,280 --> 00:36:08,800
know they they they they deserve this um

847
00:36:06,960 --> 00:36:10,680
limited Monopoly that's in the

848
00:36:08,800 --> 00:36:14,599
Constitution because that's what they

849
00:36:10,680 --> 00:36:16,200
rely on to make a living and um you know

850
00:36:14,599 --> 00:36:18,359
their work should not be used without

851
00:36:16,200 --> 00:36:20,400
consent so and it's it's it's it's

852
00:36:18,359 --> 00:36:22,520
another way to say uh you know we need

853
00:36:20,400 --> 00:36:25,359
licensing because in a licensing what's

854
00:36:22,520 --> 00:36:28,440
going on is that the the the author is

855
00:36:25,359 --> 00:36:30,119
saying yes I I will allow you to use my

856
00:36:28,440 --> 00:36:33,480
work for AI training and I think there

857
00:36:30,119 --> 00:36:36,160
is a lot of interest um um you know

858
00:36:33,480 --> 00:36:39,520
among authors to sort of allow their

859
00:36:36,160 --> 00:36:41,720
Works to be used for training um and

860
00:36:39,520 --> 00:36:44,560
other authors who are you know uh

861
00:36:41,720 --> 00:36:47,119
principally against AI can say I do not

862
00:36:44,560 --> 00:36:48,680
consent to you using my Works uh for

863
00:36:47,119 --> 00:36:50,520
training I also want to make a quick

864
00:36:48,680 --> 00:36:53,839
distinction because you know uh

865
00:36:50,520 --> 00:36:56,880
especially early on in the um in the

866
00:36:53,839 --> 00:36:59,280
conversations around generative AI um

867
00:36:56,880 --> 00:37:01,000
you know when authors and other creators

868
00:36:59,280 --> 00:37:02,640
started talking about well where's our

869
00:37:01,000 --> 00:37:04,319
where's our right to consent you guys

870
00:37:02,640 --> 00:37:06,480
are just you know taking everything that

871
00:37:04,319 --> 00:37:09,400
we've created and putting it in uh some

872
00:37:06,480 --> 00:37:11,200
of the AI and and and proponents of AI

873
00:37:09,400 --> 00:37:13,400
and AI developers would come out and say

874
00:37:11,200 --> 00:37:15,960
hey we actually cannot like you know

875
00:37:13,400 --> 00:37:19,520
apportion consent because we're taking

876
00:37:15,960 --> 00:37:22,359
you know like this huge like like masses

877
00:37:19,520 --> 00:37:26,079
of data we're just scrapping you know we

878
00:37:22,359 --> 00:37:27,520
we we're using uh uh scrapes of U of

879
00:37:26,079 --> 00:37:30,280
several tens of millions of weap

880
00:37:27,520 --> 00:37:32,839
websites we cannot do that and there

881
00:37:30,280 --> 00:37:37,319
there needs to be a distinction made

882
00:37:32,839 --> 00:37:39,319
between professional human creators and

883
00:37:37,319 --> 00:37:41,599
their lives versus like anything that's

884
00:37:39,319 --> 00:37:42,800
on Reddit or a message board I think and

885
00:37:41,599 --> 00:37:44,760
and you can actually make that

886
00:37:42,800 --> 00:37:46,800
distinction also from a copyright frame

887
00:37:44,760 --> 00:37:49,560
because you know as we talked about fair

888
00:37:46,800 --> 00:37:51,520
use one of the factors is the the the

889
00:37:49,560 --> 00:37:54,760
impact on the market or the potential

890
00:37:51,520 --> 00:37:56,119
market for the work now as far as I

891
00:37:54,760 --> 00:37:58,640
understand there's not a there's not a

892
00:37:56,119 --> 00:38:02,000
big market for like you know Reddit post

893
00:37:58,640 --> 00:38:03,720
or I don't know there might be but uh

894
00:38:02,000 --> 00:38:05,280
that's how you that's one of the ways to

895
00:38:03,720 --> 00:38:07,240
differentiate professional creators

896
00:38:05,280 --> 00:38:10,240
professional creators rely on

897
00:38:07,240 --> 00:38:12,920
established copyright markets to earn a

898
00:38:10,240 --> 00:38:14,520
living you know to raise families to do

899
00:38:12,920 --> 00:38:17,480
you know all of the things that we do uh

900
00:38:14,520 --> 00:38:19,560
our members unfortunately they're not

901
00:38:17,480 --> 00:38:21,119
the earnings just every time we do an

902
00:38:19,560 --> 00:38:23,560
income survey the earnings just keep

903
00:38:21,119 --> 00:38:26,960
going down uh according to our last

904
00:38:23,560 --> 00:38:29,319
survey um um the median uh income for a

905
00:38:26,960 --> 00:38:31,800
full-time author which is someone that's

906
00:38:29,319 --> 00:38:34,079
devoted entirely to their writing career

907
00:38:31,800 --> 00:38:37,319
and not doing anything else was $220,000

908
00:38:34,079 --> 00:38:40,400
a year and only 10,000 of those dollars

909
00:38:37,319 --> 00:38:42,079
actually came from selling books so you

910
00:38:40,400 --> 00:38:44,680
know it was already a precarious

911
00:38:42,079 --> 00:38:46,119
situation that got even more precarious

912
00:38:44,680 --> 00:38:48,040
as we started dealing with AI I don't

913
00:38:46,119 --> 00:38:49,839
know if I answered that question yeah no

914
00:38:48,040 --> 00:38:51,960
ABS absolutely and I think you know part

915
00:38:49,839 --> 00:38:53,880
of what we're you know I think people

916
00:38:51,960 --> 00:38:57,280
think about these issues is is trying to

917
00:38:53,880 --> 00:38:59,960
find that path to to a win-win situation

918
00:38:57,280 --> 00:39:02,280
y right um that is that Fosters

919
00:38:59,960 --> 00:39:04,520
Innovation and creativity um and

920
00:39:02,280 --> 00:39:06,960
protects uh protects creators and I

921
00:39:04,520 --> 00:39:09,480
think that's that's you know an ultimate

922
00:39:06,960 --> 00:39:12,560
Challenge let me ask a second question

923
00:39:09,480 --> 00:39:14,440
um which is uh a broader one maybe uh

924
00:39:12,560 --> 00:39:18,359
maybe even a little bit autobiographical

925
00:39:14,440 --> 00:39:20,079
for you um uh you know you're you're not

926
00:39:18,359 --> 00:39:22,640
a large language model developer right

927
00:39:20,079 --> 00:39:25,160
you're not a computer scientist right um

928
00:39:22,640 --> 00:39:27,839
and so what's it like to to work at this

929
00:39:25,160 --> 00:39:30,400
intersection of technology and policy

930
00:39:27,839 --> 00:39:34,160
how do we ensure that policy makers

931
00:39:30,400 --> 00:39:36,880
policy Advocates like you have the best

932
00:39:34,160 --> 00:39:39,920
technological expertise like how do you

933
00:39:36,880 --> 00:39:41,520
you know how how do you uh sort of come

934
00:39:39,920 --> 00:39:43,359
upon the technological knowledge that

935
00:39:41,520 --> 00:39:46,000
you need to do your legal and policy

936
00:39:43,359 --> 00:39:48,800
advocacy work and vice versa you know

937
00:39:46,000 --> 00:39:51,520
how do how would you Advocate that

938
00:39:48,800 --> 00:39:52,960
technologist get their hands on on

939
00:39:51,520 --> 00:39:54,880
policy questions and the policy

940
00:39:52,960 --> 00:39:56,839
implications of their work again thanks

941
00:39:54,880 --> 00:39:59,000
that's that's also such a such a great

942
00:39:56,839 --> 00:40:00,560
question and I thought about this one

943
00:39:59,000 --> 00:40:02,240
quite a bit because you know when you

944
00:40:00,560 --> 00:40:04,079
when you just kind of dive into the work

945
00:40:02,240 --> 00:40:05,599
you kind of forget how you're working or

946
00:40:04,079 --> 00:40:08,160
why you're you're doing what you're

947
00:40:05,599 --> 00:40:10,040
doing and in in sort of thinking about

948
00:40:08,160 --> 00:40:11,160
this question I found it really

949
00:40:10,040 --> 00:40:14,359
thrilling

950
00:40:11,160 --> 00:40:16,280
because I remember like early early days

951
00:40:14,359 --> 00:40:18,000
when we were talking about like what it

952
00:40:16,280 --> 00:40:20,880
means for Law and what it means for

953
00:40:18,000 --> 00:40:22,400
policies that no one really had any you

954
00:40:20,880 --> 00:40:25,200
know everyone just had these kind of

955
00:40:22,400 --> 00:40:26,640
rough metaphors for what was going on at

956
00:40:25,200 --> 00:40:28,319
least on the law and policy side of

957
00:40:26,640 --> 00:40:30,920
things you know people might say the AI

958
00:40:28,319 --> 00:40:33,640
the machine is eating up stuff or you

959
00:40:30,920 --> 00:40:37,000
know uh it's like uh or like it's

960
00:40:33,640 --> 00:40:40,359
hoovering up stuff and regurgitating it

961
00:40:37,000 --> 00:40:42,200
and to me because no one really knew

962
00:40:40,359 --> 00:40:44,040
what was going on under the hood

963
00:40:42,200 --> 00:40:46,680
technologically I think the lawyers did

964
00:40:44,040 --> 00:40:49,880
not have that facility so even if you

965
00:40:46,680 --> 00:40:51,960
see the the the the initial complaints

966
00:40:49,880 --> 00:40:54,200
that were filed in some of the lawsuits

967
00:40:51,960 --> 00:40:56,240
not not in our lawsuit but in in uh in

968
00:40:54,200 --> 00:40:58,599
some of the other lawsuits against openi

969
00:40:56,240 --> 00:41:01,280
and meta um the complaints were very

970
00:40:58,599 --> 00:41:03,400
rough and it wasn't quite clear what the

971
00:41:01,280 --> 00:41:05,240
allegations were and that's partly

972
00:41:03,400 --> 00:41:08,640
because the translation hasn't hadn't

973
00:41:05,240 --> 00:41:11,400
happened you know um I I as as someone

974
00:41:08,640 --> 00:41:14,200
who you know in my copious uh spare time

975
00:41:11,400 --> 00:41:17,240
I I try to translate I I I think that a

976
00:41:14,200 --> 00:41:19,640
lot of it is is translating what the

977
00:41:17,240 --> 00:41:22,680
technologists are telling us about what

978
00:41:19,640 --> 00:41:26,560
they're doing into a language that you

979
00:41:22,680 --> 00:41:28,200
know is is is that that that lay people

980
00:41:26,560 --> 00:41:30,160
that are not Tech Tech ologist can

981
00:41:28,200 --> 00:41:32,400
understand and then being able to put it

982
00:41:30,160 --> 00:41:35,560
in a thoughtful uh kind of policy

983
00:41:32,400 --> 00:41:37,520
framework because as long as there's no

984
00:41:35,560 --> 00:41:39,599
you know no translation happening then

985
00:41:37,520 --> 00:41:42,119
you might have policy Frameworks that

986
00:41:39,599 --> 00:41:44,280
are anti-in Innovation or they might be

987
00:41:42,119 --> 00:41:45,920
too strict or they might be too LAX

988
00:41:44,280 --> 00:41:48,560
because there's a fundamental

989
00:41:45,920 --> 00:41:51,520
misunderstanding of of what is going on

990
00:41:48,560 --> 00:41:53,599
so for me it was uh really a you know

991
00:41:51,520 --> 00:41:56,760
vital that I I actually went and you

992
00:41:53,599 --> 00:41:59,960
know I mean I have I just I just have

993
00:41:56,760 --> 00:42:01,640
such a like congenital like non- stem

994
00:41:59,960 --> 00:42:04,880
brain you know I I can't remember the

995
00:42:01,640 --> 00:42:08,280
last time I took a math class but um I

996
00:42:04,880 --> 00:42:11,880
forced myself to learn to read the Cs

997
00:42:08,280 --> 00:42:13,920
papers about uh you know llm development

998
00:42:11,880 --> 00:42:17,720
and AI in general like going back to the

999
00:42:13,920 --> 00:42:20,520
first uh um it was uh I think it was

1000
00:42:17,720 --> 00:42:22,559
it's it's Kiros at all I don't remember

1001
00:42:20,520 --> 00:42:26,480
but it was the it was an experiment to

1002
00:42:22,559 --> 00:42:29,240
match um screen screen caps movie screen

1003
00:42:26,480 --> 00:42:31,680
caps with the descriptions and that was

1004
00:42:29,240 --> 00:42:33,960
one of the first uh I guess like um

1005
00:42:31,680 --> 00:42:37,480
large language model experiments that

1006
00:42:33,960 --> 00:42:39,640
was used uh it was it used about um a

1007
00:42:37,480 --> 00:42:42,040
cashier of 11,000 unpublished books and

1008
00:42:39,640 --> 00:42:44,839
to me that was fascinating to like see

1009
00:42:42,040 --> 00:42:46,680
how the technologists were approaching

1010
00:42:44,839 --> 00:42:49,599
um you know what they were doing you

1011
00:42:46,680 --> 00:42:51,359
know uh to to as a writer to see them

1012
00:42:49,599 --> 00:42:54,079
kind of hearing just to read them

1013
00:42:51,359 --> 00:42:58,000
talking about how important books were

1014
00:42:54,079 --> 00:43:02,040
or fictions in particular was and in in

1015
00:42:58,000 --> 00:43:05,960
in uh in in in reifying certain Concepts

1016
00:43:02,040 --> 00:43:07,319
um you know and and so I yeah and and so

1017
00:43:05,960 --> 00:43:09,359
that's that's how I really I think it's

1018
00:43:07,319 --> 00:43:13,800
really vital I think for my advice to

1019
00:43:09,359 --> 00:43:16,520
technologist would be um

1020
00:43:13,800 --> 00:43:18,640
I you know it's hard when you're in kind

1021
00:43:16,520 --> 00:43:20,079
of in your narrow channel of work like

1022
00:43:18,640 --> 00:43:22,640
it's the same in law right you know when

1023
00:43:20,079 --> 00:43:24,400
we're doing law we're just like there's

1024
00:43:22,640 --> 00:43:26,160
there's there's like an internal kind of

1025
00:43:24,400 --> 00:43:27,559
grammar that we use there's an internal

1026
00:43:26,160 --> 00:43:30,000
language we don't think about what's

1027
00:43:27,559 --> 00:43:32,319
going on outside of it so we but I think

1028
00:43:30,000 --> 00:43:34,800
what's important are these cross

1029
00:43:32,319 --> 00:43:36,520
functional dialogues so you know you

1030
00:43:34,800 --> 00:43:39,079
know what

1031
00:43:36,520 --> 00:43:41,920
people you know so you might not go out

1032
00:43:39,079 --> 00:43:43,640
and say uh download 11,000 books for

1033
00:43:41,920 --> 00:43:45,559
your experiment you might you know seek

1034
00:43:43,640 --> 00:43:47,800
out a license or you might like actually

1035
00:43:45,559 --> 00:43:50,880
seek out people who can help you seek

1036
00:43:47,800 --> 00:43:52,839
out those licenses um it's it's also

1037
00:43:50,880 --> 00:43:55,319
just a risk mitigation you know

1038
00:43:52,839 --> 00:43:59,160
especially now you know you might face

1039
00:43:55,319 --> 00:44:00,839
the risk of lawsuits ET but um it's just

1040
00:43:59,160 --> 00:44:03,040
it's just good to be mindful of like

1041
00:44:00,839 --> 00:44:05,440
what's going on outside of your box I

1042
00:44:03,040 --> 00:44:08,079
guess all right yeah and I think you're

1043
00:44:05,440 --> 00:44:10,880
right I think both that uh the

1044
00:44:08,079 --> 00:44:13,520
hesitation that technologist may have

1045
00:44:10,880 --> 00:44:15,720
about come about understanding copyright

1046
00:44:13,520 --> 00:44:17,880
law is as high as the as what copyright

1047
00:44:15,720 --> 00:44:19,680
lawyers have about how large language

1048
00:44:17,880 --> 00:44:22,160
aots work they're both they're both very

1049
00:44:19,680 --> 00:44:24,119
you know daunting learning absolutely

1050
00:44:22,160 --> 00:44:26,559
all right well let's um let's take a a

1051
00:44:24,119 --> 00:44:30,119
turn gears here and and open things up

1052
00:44:26,559 --> 00:44:32,359
for for Q&A um maybe Casper if you you

1053
00:44:30,119 --> 00:44:34,599
can kick it off if you speak loudly I

1054
00:44:32,359 --> 00:44:37,559
might repeat your question into the

1055
00:44:34,599 --> 00:44:40,760
microphone I have a question about what

1056
00:44:37,559 --> 00:44:43,800
the Practical threat

1057
00:44:40,760 --> 00:44:48,240
actually you if you don't mind I I guess

1058
00:44:43,800 --> 00:44:50,640
I have a question about what the um

1059
00:44:48,240 --> 00:44:54,839
additional threat the publishing

1060
00:44:50,640 --> 00:44:58,240
industry um posed by Ai and large

1061
00:44:54,839 --> 00:45:01,640
language models is um beyond the

1062
00:44:58,240 --> 00:45:04,400
existing the internet you know um so so

1063
00:45:01,640 --> 00:45:09,880
for example I can imagine a scenario in

1064
00:45:04,400 --> 00:45:15,680
which um uh you've written a novel and I

1065
00:45:09,880 --> 00:45:18,800
say um uh I asked chat GPT to give me um

1066
00:45:15,680 --> 00:45:21,480
a uh word forword quote of the whole

1067
00:45:18,800 --> 00:45:24,319
novel and it comes back with 150,000

1068
00:45:21,480 --> 00:45:27,000
word answer and then I read that instead

1069
00:45:24,319 --> 00:45:29,440
of buying the book and then imagine that

1070
00:45:27,000 --> 00:45:30,800
lots of lots of people do this so we

1071
00:45:29,440 --> 00:45:32,559
have uh all the people who would

1072
00:45:30,800 --> 00:45:35,880
otherwise have bought the book are in

1073
00:45:32,559 --> 00:45:38,800
fact just um getting chat GPT to

1074
00:45:35,880 --> 00:45:41,000
effectively give them the book but

1075
00:45:38,800 --> 00:45:44,160
that's not happening yet and presumably

1076
00:45:41,000 --> 00:45:45,880
it's a pretty remote possibility so is

1077
00:45:44,160 --> 00:45:47,920
it that you're worried that that may

1078
00:45:45,880 --> 00:45:49,599
happen or is it something else is it

1079
00:45:47,920 --> 00:45:54,359
something short of that that you feel

1080
00:45:49,599 --> 00:45:56,559
like poses a threat to the publishing

1081
00:45:54,359 --> 00:45:58,920
industry yeah that's a really that's a

1082
00:45:56,559 --> 00:46:01,200
really good question too I mean

1083
00:45:58,920 --> 00:46:05,119
um you're right that that's a remote

1084
00:46:01,200 --> 00:46:07,960
possibility it it could be there was uh

1085
00:46:05,119 --> 00:46:10,640
um computer scientist at the University

1086
00:46:07,960 --> 00:46:13,960
of Chicago benha I I I I think it's his

1087
00:46:10,640 --> 00:46:16,079
name but he was able to get uh chat GPT

1088
00:46:13,960 --> 00:46:18,040
to like give him each successive line

1089
00:46:16,079 --> 00:46:20,720
from Harry Potter and he kept going on

1090
00:46:18,040 --> 00:46:22,800
so but then open AI put in filters that

1091
00:46:20,720 --> 00:46:24,760
now you know now the response is due to

1092
00:46:22,800 --> 00:46:27,680
copyright restrictions we can't do that

1093
00:46:24,760 --> 00:46:30,559
so um so that's not actually the threat

1094
00:46:27,680 --> 00:46:33,800
I think that the the ultimate threat is

1095
00:46:30,559 --> 00:46:36,359
devaluing uh you know human authorship

1096
00:46:33,800 --> 00:46:40,160
uh when you have so I'll give you

1097
00:46:36,359 --> 00:46:43,079
examples of what what we see that we are

1098
00:46:40,160 --> 00:46:44,839
concerned about um one one thing is

1099
00:46:43,079 --> 00:46:47,119
especially with the internet a lot of

1100
00:46:44,839 --> 00:46:50,200
the publishing industry and how people

1101
00:46:47,119 --> 00:46:54,319
read has moved to uh you know it's it's

1102
00:46:50,200 --> 00:46:57,720
sort of controlled by a few big you

1103
00:46:54,319 --> 00:47:00,359
know olop any I'm I'm not going to say

1104
00:46:57,720 --> 00:47:03,280
that word but you know like uh like

1105
00:47:00,359 --> 00:47:05,599
Amazon um Amazon controls so much of

1106
00:47:03,280 --> 00:47:07,280
distribution and consumption of books

1107
00:47:05,599 --> 00:47:09,920
and they thrive on volume so

1108
00:47:07,280 --> 00:47:13,160
self-publishing is a huge thing now what

1109
00:47:09,920 --> 00:47:15,559
happens with AI is that it's so easy to

1110
00:47:13,160 --> 00:47:17,440
write a book write a book or like put a

1111
00:47:15,559 --> 00:47:19,720
book on Amazon and kind of game their

1112
00:47:17,440 --> 00:47:21,520
system to like earn Revenue so we we see

1113
00:47:19,720 --> 00:47:23,079
examples of this all the time one of the

1114
00:47:21,520 --> 00:47:25,640
one of the examples that we've we've

1115
00:47:23,079 --> 00:47:29,800
seen is uh someone will take someone

1116
00:47:25,640 --> 00:47:32,119
else's memoir and run it through Ai and

1117
00:47:29,800 --> 00:47:34,960
create an unauthorized biography based

1118
00:47:32,119 --> 00:47:38,240
on the Memoir and you know it's shorter

1119
00:47:34,960 --> 00:47:40,520
it's more consumable you know it might

1120
00:47:38,240 --> 00:47:42,359
it you might be like I don't really want

1121
00:47:40,520 --> 00:47:44,880
to read the Memoir I'm going to go for

1122
00:47:42,359 --> 00:47:46,960
this um that's that's one of the that's

1123
00:47:44,880 --> 00:47:50,119
one of the threats that we see but like

1124
00:47:46,960 --> 00:47:53,359
just on a much bigger scale where AI

1125
00:47:50,119 --> 00:47:55,760
generated books will just you know will

1126
00:47:53,359 --> 00:47:58,079
will essentially replace human authored

1127
00:47:55,760 --> 00:48:00,599
Works which take much longer ER to write

1128
00:47:58,079 --> 00:48:02,680
and then there's kind of this like

1129
00:48:00,599 --> 00:48:04,559
scenario where people get even more

1130
00:48:02,680 --> 00:48:06,200
acclimated to sort of like thinking of

1131
00:48:04,559 --> 00:48:07,760
books as it's like there's you know

1132
00:48:06,200 --> 00:48:10,119
there might not even be a human author

1133
00:48:07,760 --> 00:48:14,240
in question people are just consuming

1134
00:48:10,119 --> 00:48:16,000
text um and so for us like as a advocacy

1135
00:48:14,240 --> 00:48:18,280
Organization for authors it's very

1136
00:48:16,000 --> 00:48:21,559
important to make sure that those

1137
00:48:18,280 --> 00:48:25,040
economic channels remain viable for for

1138
00:48:21,559 --> 00:48:26,240
use by human authors um I don't know if

1139
00:48:25,040 --> 00:48:27,800
that's that was a very good question

1140
00:48:26,240 --> 00:48:30,000
that's I don't think if that's a good

1141
00:48:27,800 --> 00:48:33,040
good good enough answer but ultimately

1142
00:48:30,000 --> 00:48:36,160
like we are you know

1143
00:48:33,040 --> 00:48:37,720
um in infringement it's it's the the

1144
00:48:36,160 --> 00:48:39,559
second thing that I do want to mention

1145
00:48:37,720 --> 00:48:44,040
is that it's like it's it's not

1146
00:48:39,559 --> 00:48:46,720
necessarily about the the harm of uh a a

1147
00:48:44,040 --> 00:48:49,440
a a chatbot reproducing your entire

1148
00:48:46,720 --> 00:48:52,640
novel but the harm to the principle of

1149
00:48:49,440 --> 00:48:54,960
copyright um you know the idea of

1150
00:48:52,640 --> 00:48:56,359
consent uh that's that's ultimately what

1151
00:48:54,960 --> 00:48:58,880
we're trying to vindicate both through

1152
00:48:56,359 --> 00:49:01,720
the LW suits and through our

1153
00:48:58,880 --> 00:49:03,559
advocacy I might add another perspective

1154
00:49:01,720 --> 00:49:06,160
of this from you know many sort of

1155
00:49:03,559 --> 00:49:09,520
academic authors um for whom

1156
00:49:06,160 --> 00:49:11,440
compensation is minimal or of or

1157
00:49:09,520 --> 00:49:13,720
sometimes you know

1158
00:49:11,440 --> 00:49:16,920
non-existent um are those other two

1159
00:49:13,720 --> 00:49:18,599
letters the consent and credit right and

1160
00:49:16,920 --> 00:49:22,200
so there are you know there are many

1161
00:49:18,599 --> 00:49:24,960
academic authors who would who right now

1162
00:49:22,200 --> 00:49:27,480
would recognize you know yes people in

1163
00:49:24,960 --> 00:49:30,240
the world are turning to

1164
00:49:27,480 --> 00:49:33,240
um you know commercial generative AI

1165
00:49:30,240 --> 00:49:35,880
tools to ask and answer questions about

1166
00:49:33,240 --> 00:49:37,640
how the world works right and we have an

1167
00:49:35,880 --> 00:49:40,079
interest as scientists or others in

1168
00:49:37,640 --> 00:49:42,280
making sure that the outputs are you

1169
00:49:40,079 --> 00:49:44,960
know have good science in them in so

1170
00:49:42,280 --> 00:49:47,599
ways they want to be in the model right

1171
00:49:44,960 --> 00:49:49,599
um but um you know they they operated

1172
00:49:47,599 --> 00:49:52,839
under a previous sort of publishing

1173
00:49:49,599 --> 00:49:54,760
regime in which they put the articles in

1174
00:49:52,839 --> 00:49:56,359
you know PubMed or they put them in you

1175
00:49:54,760 --> 00:49:57,680
know publish them in under an open

1176
00:49:56,359 --> 00:49:59,520
license

1177
00:49:57,680 --> 00:50:02,839
um and you know suddenly that you know

1178
00:49:59,520 --> 00:50:05,359
lends itself to to ingestion without the

1179
00:50:02,839 --> 00:50:07,480
kind of consent and and credit issues

1180
00:50:05,359 --> 00:50:09,359
even if comp you know compensation may

1181
00:50:07,480 --> 00:50:11,680
be more of mine for professional authors

1182
00:50:09,359 --> 00:50:13,160
but for academic authors you know those

1183
00:50:11,680 --> 00:50:14,880
other two C's can can be really

1184
00:50:13,160 --> 00:50:16,680
important as well that's really good and

1185
00:50:14,880 --> 00:50:19,119
and maybe because you know you you're

1186
00:50:16,680 --> 00:50:21,640
involved in the open source um aspect of

1187
00:50:19,119 --> 00:50:23,799
things I I was really interested in the

1188
00:50:21,640 --> 00:50:26,799
the new preference signaling uh

1189
00:50:23,799 --> 00:50:29,160
methodology that that the uh the the

1190
00:50:26,799 --> 00:50:30,799
creative comments put out I mean I think

1191
00:50:29,160 --> 00:50:32,720
so for instance even if you publish

1192
00:50:30,799 --> 00:50:34,400
something under an open source license

1193
00:50:32,720 --> 00:50:36,799
you might not have given a license for

1194
00:50:34,400 --> 00:50:38,480
it to be ingested for AI in which case

1195
00:50:36,799 --> 00:50:41,400
you know the consent thing still comes

1196
00:50:38,480 --> 00:50:44,680
into place but um yeah now we're moving

1197
00:50:41,400 --> 00:50:47,040
towards a more robust sort of speak like

1198
00:50:44,680 --> 00:50:50,280
yeah I think though yeah that is a

1199
00:50:47,040 --> 00:50:52,720
that's where I think will the you know

1200
00:50:50,280 --> 00:50:53,880
authors and and and scientists inventors

1201
00:50:52,720 --> 00:50:56,400
other kinds of people will will

1202
00:50:53,880 --> 00:50:58,160
ultimately need need to be heading yeah

1203
00:50:56,400 --> 00:50:59,680
and again like going back to the the

1204
00:50:58,160 --> 00:51:01,480
market part right you know I mean the

1205
00:50:59,680 --> 00:51:03,520
market for academic work is very

1206
00:51:01,480 --> 00:51:06,160
different than the market for a trade

1207
00:51:03,520 --> 00:51:09,880
book or for a romance novel you know or

1208
00:51:06,160 --> 00:51:09,880
or um or a detective

1209
00:51:10,040 --> 00:51:13,040
story

1210
00:51:13,119 --> 00:51:19,119
yeah come on down I have a very basic

1211
00:51:17,000 --> 00:51:24,799
question so forgive me question it seems

1212
00:51:19,119 --> 00:51:27,480
to me that a lot of what makes copyright

1213
00:51:24,799 --> 00:51:30,440
enforcable is whether or not someone is

1214
00:51:27,480 --> 00:51:32,640
infringing on the market value the

1215
00:51:30,440 --> 00:51:37,359
ability to make money and people's

1216
00:51:32,640 --> 00:51:40,160
ability to fight being unfairly ingested

1217
00:51:37,359 --> 00:51:42,160
without their consent um seems to be

1218
00:51:40,160 --> 00:51:43,760
increased if there is an organization

1219
00:51:42,160 --> 00:51:46,040
that they work for like the New York

1220
00:51:43,760 --> 00:51:49,319
Times that can say Hey you are in ping

1221
00:51:46,040 --> 00:51:51,319
on my future profits um whereas

1222
00:51:49,319 --> 00:51:54,079
individuals like

1223
00:51:51,319 --> 00:51:56,119
screenwriters right if their um

1224
00:51:54,079 --> 00:51:58,839
subtitles are uploaded into an open

1225
00:51:56,119 --> 00:52:01,319
database and that gets ingested it's

1226
00:51:58,839 --> 00:52:03,280
harder to make that argument that a

1227
00:52:01,319 --> 00:52:04,760
screenwriter that you're hurting their

1228
00:52:03,280 --> 00:52:07,359
future proceeds because they're not part

1229
00:52:04,760 --> 00:52:10,319
of this larger organization so my bigger

1230
00:52:07,359 --> 00:52:13,720
question is what are the failings of the

1231
00:52:10,319 --> 00:52:16,359
copyright law as it is currently written

1232
00:52:13,720 --> 00:52:19,640
and because so much of it seems to be

1233
00:52:16,359 --> 00:52:20,839
framed in terms of making money what is

1234
00:52:19,640 --> 00:52:24,119
that leaving

1235
00:52:20,839 --> 00:52:26,040
out I mean just so many so many amazing

1236
00:52:24,119 --> 00:52:28,920
questions I I I should should have

1237
00:52:26,040 --> 00:52:32,440
should have I should have known I'm an

1238
00:52:28,920 --> 00:52:34,160
MIT um so a a couple of comments on on

1239
00:52:32,440 --> 00:52:35,319
that actually it is interesting you

1240
00:52:34,160 --> 00:52:37,680
would think that working for an

1241
00:52:35,319 --> 00:52:41,040
organization like the New York Times uh

1242
00:52:37,680 --> 00:52:44,400
as a writer would kind of give you a

1243
00:52:41,040 --> 00:52:46,119
little bit more you know uh well would

1244
00:52:44,400 --> 00:52:47,960
would give you leverage for enforcing

1245
00:52:46,119 --> 00:52:49,440
your rights but what happens is that you

1246
00:52:47,960 --> 00:52:50,960
know when you're a staff writer for the

1247
00:52:49,440 --> 00:52:53,319
New York Times the entire copyright

1248
00:52:50,960 --> 00:52:54,799
belongs to the New York Times so or even

1249
00:52:53,319 --> 00:52:56,720
if you're a contributor a lot of times

1250
00:52:54,799 --> 00:52:58,440
the New York Times will take all right

1251
00:52:56,720 --> 00:53:00,640
in the work which means that you

1252
00:52:58,440 --> 00:53:02,839
actually don't have any rights left to

1253
00:53:00,640 --> 00:53:04,480
enforce so all of the enforcement that

1254
00:53:02,839 --> 00:53:06,319
is going on from a copyright point of

1255
00:53:04,480 --> 00:53:09,359
view is New York Times kind of enforcing

1256
00:53:06,319 --> 00:53:11,680
its own property interest in in you know

1257
00:53:09,359 --> 00:53:13,839
things that like authors have written so

1258
00:53:11,680 --> 00:53:15,960
but it is a very good question because

1259
00:53:13,839 --> 00:53:18,520
uh with screenwriters for instance there

1260
00:53:15,960 --> 00:53:20,880
are unions now unions are playing a very

1261
00:53:18,520 --> 00:53:23,319
important and interesting role right now

1262
00:53:20,880 --> 00:53:26,200
because one of the threats to the

1263
00:53:23,319 --> 00:53:29,480
profession comes from say Studios not

1264
00:53:26,200 --> 00:53:32,520
high ing screenwriters uh but you know

1265
00:53:29,480 --> 00:53:34,680
using Ai and last year um there were

1266
00:53:32,520 --> 00:53:36,920
some very intense negotiations between

1267
00:53:34,680 --> 00:53:39,680
sag aftera cuz it's also affecting

1268
00:53:36,920 --> 00:53:41,480
actors you know I've heard like just

1269
00:53:39,680 --> 00:53:43,839
very strange stories of like if you have

1270
00:53:41,480 --> 00:53:46,400
a tiny role for like $50 a day you show

1271
00:53:43,839 --> 00:53:48,200
up on set someone takes you aside gets

1272
00:53:46,400 --> 00:53:50,760
you to step in like a booth and they

1273
00:53:48,200 --> 00:53:52,440
they do a 3D print scan of your body and

1274
00:53:50,760 --> 00:53:53,559
then that's used for like so so there

1275
00:53:52,440 --> 00:53:55,200
are things like that that are happening

1276
00:53:53,559 --> 00:53:57,440
so unions are playing a very important

1277
00:53:55,200 --> 00:54:00,920
role right now in enforcing rights you

1278
00:53:57,440 --> 00:54:04,680
the the the difference between us and a

1279
00:54:00,920 --> 00:54:06,480
union is that unions unions also like

1280
00:54:04,680 --> 00:54:07,680
the the the way entertainment unions

1281
00:54:06,480 --> 00:54:09,160
work and this is just by way of

1282
00:54:07,680 --> 00:54:10,520
background in case you're interested and

1283
00:54:09,160 --> 00:54:15,079
I'm I'm going to get to your ultimate

1284
00:54:10,520 --> 00:54:16,559
question um the the way the unions exist

1285
00:54:15,079 --> 00:54:19,040
in the entertainment industry we're not

1286
00:54:16,559 --> 00:54:21,240
a union but in in screenwriting and

1287
00:54:19,040 --> 00:54:23,400
acting they exist because there is an

1288
00:54:21,240 --> 00:54:26,920
arrangement between Studios and the

1289
00:54:23,400 --> 00:54:29,119
talent that um that that the Talent is

1290
00:54:26,920 --> 00:54:30,680
actually considered an employee of the

1291
00:54:29,119 --> 00:54:33,200
production which is why they're able to

1292
00:54:30,680 --> 00:54:35,520
get health insurance and residuals so it

1293
00:54:33,200 --> 00:54:36,559
it it fundamentally always comes down to

1294
00:54:35,520 --> 00:54:39,680
health

1295
00:54:36,559 --> 00:54:41,400
insurance unfortunately you know so even

1296
00:54:39,680 --> 00:54:43,520
in that case the screenwriters don't

1297
00:54:41,400 --> 00:54:45,640
actually have any copyright in the work

1298
00:54:43,520 --> 00:54:47,520
because they are considered employees of

1299
00:54:45,640 --> 00:54:49,319
the studio for that but because they

1300
00:54:47,520 --> 00:54:52,920
have the union they can they can they

1301
00:54:49,319 --> 00:54:54,599
can push back against the um but they

1302
00:54:52,920 --> 00:54:57,000
don't have the same rights Visa V AI

1303
00:54:54,599 --> 00:54:59,400
companies now copyright law a lot of it

1304
00:54:57,000 --> 00:55:01,319
is about making money because um

1305
00:54:59,400 --> 00:55:03,200
copyright but it's you know it's it's

1306
00:55:01,319 --> 00:55:04,760
about making money but there are other

1307
00:55:03,200 --> 00:55:08,559
parts to copyright law that I'll mention

1308
00:55:04,760 --> 00:55:12,359
it's a really good question actually um

1309
00:55:08,559 --> 00:55:14,119
it's uh for our members they pretty much

1310
00:55:12,359 --> 00:55:17,920
only rely on copyright because they're

1311
00:55:14,119 --> 00:55:20,079
tradebook authors you know the the their

1312
00:55:17,920 --> 00:55:21,680
books the way they're sold is that a

1313
00:55:20,079 --> 00:55:23,280
publisher is interested in a book

1314
00:55:21,680 --> 00:55:25,839
there's like you know there could be an

1315
00:55:23,280 --> 00:55:27,720
auction for the rights the publisher

1316
00:55:25,839 --> 00:55:29,920
then rep packages those rights and sells

1317
00:55:27,720 --> 00:55:33,520
it to a film company if it's a big book

1318
00:55:29,920 --> 00:55:36,079
so like it's it's the value is it every

1319
00:55:33,520 --> 00:55:38,200
every stage of the supply chain for

1320
00:55:36,079 --> 00:55:40,400
those rights like has a value to that so

1321
00:55:38,200 --> 00:55:43,119
it's all driven by copyright for our

1322
00:55:40,400 --> 00:55:44,920
members um what copyright the other

1323
00:55:43,119 --> 00:55:46,799
things that copyright really it's been

1324
00:55:44,920 --> 00:55:48,640
called the engine of free expression by

1325
00:55:46,799 --> 00:55:51,640
the Supreme Court and it's not something

1326
00:55:48,640 --> 00:55:55,559
that we really focused on today but um

1327
00:55:51,640 --> 00:55:57,920
you know I I think that with with how

1328
00:55:55,559 --> 00:56:01,200
easy it is to kind of generate

1329
00:55:57,920 --> 00:56:03,440
misinformation using Ai and uh if you

1330
00:56:01,200 --> 00:56:05,599
know it's that signal noise kind of

1331
00:56:03,440 --> 00:56:07,319
question that comes of like the signal

1332
00:56:05,599 --> 00:56:08,799
gets buried when there's too much noise

1333
00:56:07,319 --> 00:56:11,720
which is one of the reasons why we need

1334
00:56:08,799 --> 00:56:13,680
to sort of you know have regulations

1335
00:56:11,720 --> 00:56:15,440
around like what is AI generated you

1336
00:56:13,680 --> 00:56:16,799
know what what the customers are

1337
00:56:15,440 --> 00:56:18,440
consumers are

1338
00:56:16,799 --> 00:56:21,440
encountering

1339
00:56:18,440 --> 00:56:23,359
um the copyright also leaves out other

1340
00:56:21,440 --> 00:56:25,680
areas you know because copyright is

1341
00:56:23,359 --> 00:56:27,880
limited to the protection of uh

1342
00:56:25,680 --> 00:56:30,640
expression copyright does not protect

1343
00:56:27,880 --> 00:56:32,119
ideas so there's a very often times

1344
00:56:30,640 --> 00:56:34,039
authors will come to me and they'll say

1345
00:56:32,119 --> 00:56:36,039
someone plagiarized my work and I'm just

1346
00:56:34,039 --> 00:56:37,839
like well did they actually copy your

1347
00:56:36,039 --> 00:56:40,039
expression and they'll say no but they

1348
00:56:37,839 --> 00:56:42,839
take took my idea well that's not really

1349
00:56:40,039 --> 00:56:45,400
actionable copyright so but there are

1350
00:56:42,839 --> 00:56:47,520
these other attributes of the work like

1351
00:56:45,400 --> 00:56:49,760
an author's voice for instance you know

1352
00:56:47,520 --> 00:56:52,240
you can we're seeing this now in in in

1353
00:56:49,760 --> 00:56:53,799
in in analogous areas you know like

1354
00:56:52,240 --> 00:56:55,920
voice actors for instance have been able

1355
00:56:53,799 --> 00:56:58,480
to make a really good case for like the

1356
00:56:55,920 --> 00:57:01,319
the the they're having they call it like

1357
00:56:58,480 --> 00:57:03,559
biometric ownership of like their their

1358
00:57:01,319 --> 00:57:05,200
voice attributes but authors have an

1359
00:57:03,559 --> 00:57:07,039
authorial voice like Hemingway has a

1360
00:57:05,200 --> 00:57:09,839
very recognizable voice that's not

1361
00:57:07,039 --> 00:57:12,039
really protected by copyright you know

1362
00:57:09,839 --> 00:57:13,640
um so so there are things like that that

1363
00:57:12,039 --> 00:57:15,520
you know that that ideas are not

1364
00:57:13,640 --> 00:57:16,680
protected if you have a very unique idea

1365
00:57:15,520 --> 00:57:18,760
for something that's not really

1366
00:57:16,680 --> 00:57:21,520
protected by copyright so there's still

1367
00:57:18,760 --> 00:57:24,000
things that fall kind of outside of the

1368
00:57:21,520 --> 00:57:27,960
fall out of the copyright seve so to

1369
00:57:24,000 --> 00:57:30,160
speak yeah thank you

1370
00:57:27,960 --> 00:57:33,000
first of all thank you very much for the

1371
00:57:30,160 --> 00:57:35,359
talks and also the discussions L I feel

1372
00:57:33,000 --> 00:57:38,400
it's very insightful and meaningful to

1373
00:57:35,359 --> 00:57:40,720
all of us uh the question I have

1374
00:57:38,400 --> 00:57:43,640
actually we had a a chance to briefly

1375
00:57:40,720 --> 00:57:45,760
talk about this before the session but I

1376
00:57:43,640 --> 00:57:49,319
think probably will benefit everybody in

1377
00:57:45,760 --> 00:57:52,760
the audience is that in MIT you have

1378
00:57:49,319 --> 00:57:56,280
many many events like this and it's

1379
00:57:52,760 --> 00:57:59,240
usually recorded and uh usually when

1380
00:57:56,280 --> 00:58:04,160
recorded this and if if if you put this

1381
00:57:59,240 --> 00:58:05,559
on website we ask speak sign consent so

1382
00:58:04,160 --> 00:58:09,160
that's the

1383
00:58:05,559 --> 00:58:12,760
normal situation or process everybody is

1384
00:58:09,160 --> 00:58:17,440
familiar with but with generative AI you

1385
00:58:12,760 --> 00:58:20,400
can add some more generate more valuable

1386
00:58:17,440 --> 00:58:22,359
uh results from it B you can easily

1387
00:58:20,400 --> 00:58:23,359
summarize a person's presentation or

1388
00:58:22,359 --> 00:58:25,720
panel

1389
00:58:23,359 --> 00:58:27,720
discussion and generate that into a

1390
00:58:25,720 --> 00:58:31,440
summary

1391
00:58:27,720 --> 00:58:35,640
and uh I know you told me you need to a

1392
00:58:31,440 --> 00:58:39,720
separate resent recent form for that

1393
00:58:35,640 --> 00:58:42,440
report and signed by all the speakers or

1394
00:58:39,720 --> 00:58:46,319
participants I wonder if we can uh may

1395
00:58:42,440 --> 00:58:48,720
you can describe a little more detail uh

1396
00:58:46,319 --> 00:58:52,039
how we should approach this or can they

1397
00:58:48,720 --> 00:58:54,880
sign the same like yeah two items in the

1398
00:58:52,039 --> 00:58:56,799
same consent sure sure absolutely with

1399
00:58:54,880 --> 00:58:59,119
video recording

1400
00:58:56,799 --> 00:59:02,000
the rest yeah I know what kind of

1401
00:58:59,119 --> 00:59:04,400
potential risks could be if if we don't

1402
00:59:02,000 --> 00:59:06,400
do this properly thank you sure

1403
00:59:04,400 --> 00:59:07,880
absolutely absolutely so uh you're

1404
00:59:06,400 --> 00:59:11,319
you're looking at a few different things

1405
00:59:07,880 --> 00:59:13,559
one is the actual copyright right so um

1406
00:59:11,319 --> 00:59:15,079
if I come you know if for instance I

1407
00:59:13,559 --> 00:59:17,680
came here with a speech that I had

1408
00:59:15,079 --> 00:59:19,400
written and I go to the podium and I

1409
00:59:17,680 --> 00:59:21,920
read that speech and you recorded that

1410
00:59:19,400 --> 00:59:23,880
speech I Have a copyright interest in

1411
00:59:21,920 --> 00:59:26,920
that recording because that is a

1412
00:59:23,880 --> 00:59:29,119
recording of my you know Express

1413
00:59:26,920 --> 00:59:31,000
so when you do a release form a lot of

1414
00:59:29,119 --> 00:59:33,559
times like the release form will contain

1415
00:59:31,000 --> 00:59:35,559
an intellectual property release where

1416
00:59:33,559 --> 00:59:37,760
you say I actually like give you

1417
00:59:35,559 --> 00:59:39,680
permission to use any intellectual

1418
00:59:37,760 --> 00:59:42,559
property that might have come out of my

1419
00:59:39,680 --> 00:59:44,240
talk in a way that you you want to and

1420
00:59:42,559 --> 00:59:45,559
if you have that intellectual property

1421
00:59:44,240 --> 00:59:47,799
released then you're fine then you can

1422
00:59:45,559 --> 00:59:49,400
run it in a you know in an AI because

1423
00:59:47,799 --> 00:59:51,359
you have a broad release I guess like it

1424
00:59:49,400 --> 00:59:54,680
just it comes down to how broad or

1425
00:59:51,359 --> 00:59:56,079
narrow the language of your release is

1426
00:59:54,680 --> 00:59:57,680
um and then the second thing that you're

1427
00:59:56,079 --> 00:59:59,319
looking at is also rights of publicity

1428
00:59:57,680 --> 01:00:01,599
and personality especially if you have a

1429
00:59:59,319 --> 01:00:03,240
celebrity celebrities often times have

1430
01:00:01,599 --> 01:00:06,359
what are called rights of publicity

1431
01:00:03,240 --> 01:00:08,359
where they own um almost like a

1432
01:00:06,359 --> 01:00:10,400
trademark type interest in the way they

1433
01:00:08,359 --> 01:00:11,799
look or their particular style so you

1434
01:00:10,400 --> 01:00:14,920
want to make sure that your release

1435
01:00:11,799 --> 01:00:18,359
contains uh you know that you all that

1436
01:00:14,920 --> 01:00:18,359
they allow you to use it in that

1437
01:00:19,160 --> 01:00:27,760
wayk a follow as an audience I'm sit

1438
01:00:23,880 --> 01:00:30,440
here and listen to and I uh sub write a

1439
01:00:27,760 --> 01:00:33,400
kind of like a uh understanding or

1440
01:00:30,440 --> 01:00:35,960
summary about what I learn and do I need

1441
01:00:33,400 --> 01:00:38,520
to get permission from you no no no not

1442
01:00:35,960 --> 01:00:40,680
in that not as an audience okay got you

1443
01:00:38,520 --> 01:00:40,680
thank

1444
01:00:43,440 --> 01:00:49,400
you all right thank you uh my question

1445
01:00:46,799 --> 01:00:52,200
is about uh is there

1446
01:00:49,400 --> 01:00:55,480
a is there a difference between

1447
01:00:52,200 --> 01:00:58,599
potential infringement versus actual

1448
01:00:55,480 --> 01:01:00,880
instan it infringement because I I no

1449
01:00:58,599 --> 01:01:04,200
right you know having a model itself but

1450
01:01:00,880 --> 01:01:06,240
not using it to do X yeah versus the

1451
01:01:04,200 --> 01:01:07,440
actual X just wanted to get a better

1452
01:01:06,240 --> 01:01:09,960
understanding of that thank you

1453
01:01:07,440 --> 01:01:11,240
absolutely no there is no there is no

1454
01:01:09,960 --> 01:01:12,400
there is no such thing as like

1455
01:01:11,240 --> 01:01:14,000
infringement in the future the

1456
01:01:12,400 --> 01:01:16,079
infringement either occurs or not now

1457
01:01:14,000 --> 01:01:18,640
but you raise a very interesting point

1458
01:01:16,079 --> 01:01:22,079
because infringement when in the context

1459
01:01:18,640 --> 01:01:24,079
of AI happens the way I understand it

1460
01:01:22,079 --> 01:01:26,000
the way I explain it it happens at it

1461
01:01:24,079 --> 01:01:27,920
can happen at two different stages right

1462
01:01:26,000 --> 01:01:30,440
so you have a model but you're not

1463
01:01:27,920 --> 01:01:31,760
prompting it to do anything infringing

1464
01:01:30,440 --> 01:01:33,640
so you're not committing any

1465
01:01:31,760 --> 01:01:36,720
infringement however when the model was

1466
01:01:33,640 --> 01:01:38,039
trained there were copies made of works

1467
01:01:36,720 --> 01:01:40,160
during the training process and the

1468
01:01:38,039 --> 01:01:41,920
algorithm was run on so there is

1469
01:01:40,160 --> 01:01:43,920
infringement that has already occurred

1470
01:01:41,920 --> 01:01:45,839
at that point now as a user it doesn't

1471
01:01:43,920 --> 01:01:47,559
concern you but you know I just wanted

1472
01:01:45,839 --> 01:01:51,079
to be clear there's we say infringement

1473
01:01:47,559 --> 01:01:54,680
in the output versus infringement in the

1474
01:01:51,079 --> 01:01:56,240
input so let me take a you know kind of

1475
01:01:54,680 --> 01:01:58,079
Devil's Advocate position here here

1476
01:01:56,240 --> 01:01:59,640
right which um I think we have heard

1477
01:01:58,079 --> 01:02:01,640
from some of the large language model

1478
01:01:59,640 --> 01:02:05,000
developers but in the story goes

1479
01:02:01,640 --> 01:02:06,920
something like this um if I walk into a

1480
01:02:05,000 --> 01:02:09,359
li you know if I go into a library and I

1481
01:02:06,920 --> 01:02:11,720
read every book on the shelf and I walk

1482
01:02:09,359 --> 01:02:14,440
out and I write the Great American

1483
01:02:11,720 --> 01:02:19,079
novel I don't know anything to the

1484
01:02:14,440 --> 01:02:21,480
people in the library right um is that

1485
01:02:19,079 --> 01:02:24,200
what Lang large language models are or

1486
01:02:21,480 --> 01:02:26,119
what's different setting aside uh the

1487
01:02:24,200 --> 01:02:28,799
specific case of when we know that they

1488
01:02:26,119 --> 01:02:31,839
are trained on specifically pirated

1489
01:02:28,799 --> 01:02:34,119
information right but if uh but is is

1490
01:02:31,839 --> 01:02:36,640
that is that specifically the issue yeah

1491
01:02:34,119 --> 01:02:39,599
so that's you know I mean so my my kind

1492
01:02:36,640 --> 01:02:41,960
of I get asked this question a lot and

1493
01:02:39,599 --> 01:02:45,359
my my usual flippant answer is like are

1494
01:02:41,960 --> 01:02:47,200
you worth 1.3 million 1.3 trillion

1495
01:02:45,359 --> 01:02:49,480
dollar because that's what you know

1496
01:02:47,200 --> 01:02:51,000
that's what the the value of a sort of a

1497
01:02:49,480 --> 01:02:54,440
technology like that is but I mean it is

1498
01:02:51,000 --> 01:02:55,640
a very like good question because What's

1499
01:02:54,440 --> 01:02:58,119
um there are two things that I want to

1500
01:02:55,640 --> 01:03:00,119
say about that one is you know goes back

1501
01:02:58,119 --> 01:03:02,799
to your earlier question about

1502
01:03:00,119 --> 01:03:05,279
translating sort of between technology

1503
01:03:02,799 --> 01:03:07,720
and uh policy and language how important

1504
01:03:05,279 --> 01:03:10,680
language is so you know a lot of the

1505
01:03:07,720 --> 01:03:13,760
language that we use around AI has come

1506
01:03:10,680 --> 01:03:16,119
from people that have a very large

1507
01:03:13,760 --> 01:03:19,279
commercial interest in AI so you know

1508
01:03:16,119 --> 01:03:22,000
the the reading analogy is is is done

1509
01:03:19,279 --> 01:03:25,000
precisely in some ways it does obfuscate

1510
01:03:22,000 --> 01:03:26,880
what happens in a kind of on at the

1511
01:03:25,000 --> 01:03:29,359
technical level when you train a large

1512
01:03:26,880 --> 01:03:30,960
language model um which you know as I've

1513
01:03:29,359 --> 01:03:32,880
said a few times like it actually makes

1514
01:03:30,960 --> 01:03:35,319
a copy even the probabilistic

1515
01:03:32,880 --> 01:03:37,359
representation in the model is a

1516
01:03:35,319 --> 01:03:39,000
representation of that expression now

1517
01:03:37,359 --> 01:03:40,079
you know you can make that argument well

1518
01:03:39,000 --> 01:03:41,559
you know when you're reading something

1519
01:03:40,079 --> 01:03:43,279
or memorizing something your brain is

1520
01:03:41,559 --> 01:03:44,559
doing the same thing and is that like

1521
01:03:43,279 --> 01:03:47,480
copyright infringement because your

1522
01:03:44,559 --> 01:03:50,720
brain is doing that

1523
01:03:47,480 --> 01:03:53,200
um I mean this can get philosophical

1524
01:03:50,720 --> 01:03:56,319
like I guess my brain is a tangible

1525
01:03:53,200 --> 01:03:58,079
medium of expression you know to use uh

1526
01:03:56,319 --> 01:03:59,760
the definition but the the the the short

1527
01:03:58,079 --> 01:04:01,680
answer is that you know this the the

1528
01:03:59,760 --> 01:04:04,799
difference is between scale you know

1529
01:04:01,680 --> 01:04:06,760
it's like and and copyright Fosters like

1530
01:04:04,799 --> 01:04:09,400
it also goes back to this idea of human

1531
01:04:06,760 --> 01:04:12,160
authorship so copyright is in precisely

1532
01:04:09,400 --> 01:04:13,920
interested in humans innovating you know

1533
01:04:12,160 --> 01:04:16,720
based on the work of other humans but

1534
01:04:13,920 --> 01:04:20,000
copyright is not going to protect like a

1535
01:04:16,720 --> 01:04:22,880
mechanical or like an algorithmic like

1536
01:04:20,000 --> 01:04:25,359
process that can be um that can be used

1537
01:04:22,880 --> 01:04:29,279
on a very massive scale you know to do

1538
01:04:25,359 --> 01:04:32,839
the same thing okay um Let me let maybe

1539
01:04:29,279 --> 01:04:34,920
we'll have one more question um Casper I

1540
01:04:32,839 --> 01:04:38,440
would just be curious about what what

1541
01:04:34,920 --> 01:04:42,440
your idea about the long-term future

1542
01:04:38,440 --> 01:04:46,319
would would be in 15 years time yeah um

1543
01:04:42,440 --> 01:04:49,760
H how would you um how would you hope

1544
01:04:46,319 --> 01:04:52,880
that what sort of arrangement between

1545
01:04:49,760 --> 01:04:54,119
authors and AI companies would you like

1546
01:04:52,880 --> 01:04:57,480
to be in place can I just give a

1547
01:04:54,119 --> 01:05:01,920
tangible example um it suppose I I wrote

1548
01:04:57,480 --> 01:05:05,480
Harry Potter books um you suppose I I

1549
01:05:01,920 --> 01:05:08,359
allow I license I say it's okay for um

1550
01:05:05,480 --> 01:05:10,720
AI to be large language models to like

1551
01:05:08,359 --> 01:05:13,000
take my books and read my books is it

1552
01:05:10,720 --> 01:05:17,920
that I get paid a flat fee for that or

1553
01:05:13,000 --> 01:05:22,839
is it that when um when the AI is then

1554
01:05:17,920 --> 01:05:25,920
used to generate a um fantasy children's

1555
01:05:22,839 --> 01:05:28,359
book I get some portion yeah but would

1556
01:05:25,920 --> 01:05:31,119
that work because um how would you be

1557
01:05:28,359 --> 01:05:34,200
able to trace like how how big an

1558
01:05:31,119 --> 01:05:37,240
influence my books were on the output

1559
01:05:34,200 --> 01:05:39,760
versus other books that it may have read

1560
01:05:37,240 --> 01:05:41,799
like so how are you thinking I mean I've

1561
01:05:39,760 --> 01:05:43,799
I've got a clear sense of like you don't

1562
01:05:41,799 --> 01:05:46,079
want them to be trained on pired

1563
01:05:43,799 --> 01:05:48,799
versions of my books now but what is the

1564
01:05:46,079 --> 01:05:50,559
15-year like IDE good solution that we

1565
01:05:48,799 --> 01:05:53,079
could find to this that's uh you know

1566
01:05:50,559 --> 01:05:56,039
we've spent months talking about this it

1567
01:05:53,079 --> 01:05:59,039
is like it believe it or not like uh it

1568
01:05:56,039 --> 01:06:01,520
is the as they say the million-dollar

1569
01:05:59,039 --> 01:06:03,400
question in all of the specialized

1570
01:06:01,520 --> 01:06:05,559
copyright law panels that I have

1571
01:06:03,400 --> 01:06:08,119
attended in the last like few months

1572
01:06:05,559 --> 01:06:10,920
licensing um so one thing that I will

1573
01:06:08,119 --> 01:06:15,000
say is that uh licensing is already kind

1574
01:06:10,920 --> 01:06:16,640
of mushrooming because I think the the

1575
01:06:15,000 --> 01:06:18,400
the the presence of large language

1576
01:06:16,640 --> 01:06:20,359
models created a need and then there

1577
01:06:18,400 --> 01:06:23,079
were tons and tons of startups that are

1578
01:06:20,359 --> 01:06:25,920
like filling that need right now so um

1579
01:06:23,079 --> 01:06:28,279
you know almost on like a semi weekly

1580
01:06:25,920 --> 01:06:29,480
basis I get uh an email from a startup

1581
01:06:28,279 --> 01:06:32,200
saying hey we're building like a

1582
01:06:29,480 --> 01:06:34,880
licensing model for like content are you

1583
01:06:32,200 --> 01:06:36,720
guys interested in talking to us uh we

1584
01:06:34,880 --> 01:06:38,160
uh the author's Guild actually has one

1585
01:06:36,720 --> 01:06:40,079
partnership right now and we will have

1586
01:06:38,160 --> 01:06:42,240
other Partnerships uh non-exclusive

1587
01:06:40,079 --> 01:06:45,720
partnership with a uh company called

1588
01:06:42,240 --> 01:06:48,880
created by humans which um facilitates

1589
01:06:45,720 --> 01:06:50,680
uh licensing to AI companies so uh 15

1590
01:06:48,880 --> 01:06:53,559
years down the line it might happen like

1591
01:06:50,680 --> 01:06:56,760
in the next year that like we have all

1592
01:06:53,559 --> 01:06:57,920
AI uses are are are s of license now the

1593
01:06:56,760 --> 01:07:00,279
question that you ask is a very

1594
01:06:57,920 --> 01:07:02,760
interesting one because the value of the

1595
01:07:00,279 --> 01:07:05,000
market has not been established yet so

1596
01:07:02,760 --> 01:07:07,000
you know the few examples that we have

1597
01:07:05,000 --> 01:07:09,559
seen so for instance Harper Collins the

1598
01:07:07,000 --> 01:07:12,640
big publisher they entered into a AI

1599
01:07:09,559 --> 01:07:15,079
licensing deal and they set the value of

1600
01:07:12,640 --> 01:07:18,680
each work at

1601
01:07:15,079 --> 01:07:21,160
$5,000 um for a three-year license uh

1602
01:07:18,680 --> 01:07:23,039
lump sum you know the work can be

1603
01:07:21,160 --> 01:07:26,039
prompted as many times used as many

1604
01:07:23,039 --> 01:07:27,480
times so so that's one that that's one

1605
01:07:26,039 --> 01:07:29,960
way people are looking at it do we go

1606
01:07:27,480 --> 01:07:32,119
for a lumpsum there are technological

1607
01:07:29,960 --> 01:07:34,559
ways that I understand are you know I'm

1608
01:07:32,119 --> 01:07:36,680
at MIT so I I someone here should should

1609
01:07:34,559 --> 01:07:38,599
tell me if this is true or not but uh

1610
01:07:36,680 --> 01:07:41,319
there are the technological means that

1611
01:07:38,599 --> 01:07:44,359
are coming around where you can kind of

1612
01:07:41,319 --> 01:07:47,119
calculate a base value for how many

1613
01:07:44,359 --> 01:07:49,839
tokens were used you know and and and

1614
01:07:47,119 --> 01:07:51,599
and align it to the particular work so

1615
01:07:49,839 --> 01:07:53,760
it's not even that like you know someone

1616
01:07:51,599 --> 01:07:55,640
generating a fantasy novel it's like

1617
01:07:53,760 --> 01:07:57,920
whether or not Harry Potter that the

1618
01:07:55,640 --> 01:08:01,079
token attributed to Harry Potter in the

1619
01:07:57,920 --> 01:08:03,319
large language model were were used in

1620
01:08:01,079 --> 01:08:05,720
generating a response about Wizardry for

1621
01:08:03,319 --> 01:08:07,880
instance so those things are coming but

1622
01:08:05,720 --> 01:08:09,640
but I I imagine that the income from

1623
01:08:07,880 --> 01:08:12,319
that is going to be minimal now we're

1624
01:08:09,640 --> 01:08:14,640
also seeing all kinds of interesting

1625
01:08:12,319 --> 01:08:17,480
Downstream uses starting to come online

1626
01:08:14,640 --> 01:08:19,480
like chat Bots based on authors uh one

1627
01:08:17,480 --> 01:08:20,920
of the things that uh early on came

1628
01:08:19,480 --> 01:08:23,000
online was something called The Dan

1629
01:08:20,920 --> 01:08:24,839
Brown chat bot where you can kind of

1630
01:08:23,000 --> 01:08:26,679
talk to Dan Brown about his books and it

1631
01:08:24,839 --> 01:08:30,640
was basically they had ingested the

1632
01:08:26,679 --> 01:08:32,359
books um so but the licensing question

1633
01:08:30,640 --> 01:08:35,920
is a very interesting one for me because

1634
01:08:32,359 --> 01:08:38,239
I'm I'm in like in in in in discussions

1635
01:08:35,920 --> 01:08:40,279
around that a lot uh right now people

1636
01:08:38,239 --> 01:08:42,359
are starting with lumpsum but I think

1637
01:08:40,279 --> 01:08:44,719
there's going to be a more a finer

1638
01:08:42,359 --> 01:08:47,040
economic value that we will eventually

1639
01:08:44,719 --> 01:08:49,279
ascertain for these

1640
01:08:47,040 --> 01:08:51,359
rights all right uh and I'll just say

1641
01:08:49,279 --> 01:08:53,960
one final thing that longterm in the

1642
01:08:51,359 --> 01:08:55,799
field of generative AI is 15 months

1643
01:08:53,960 --> 01:08:58,560
months but we do need to be thinking

1644
01:08:55,799 --> 01:09:03,120
about about 15 years deep seek came

1645
01:08:58,560 --> 01:09:04,759
online so now we don't um yeah so uh

1646
01:09:03,120 --> 01:09:07,080
right now we're going to take a brief

1647
01:09:04,759 --> 01:09:08,679
Break um and there there may still be

1648
01:09:07,080 --> 01:09:11,719
some snacks outside restrooms down the

1649
01:09:08,679 --> 01:09:13,560
hall um and our um will be uh in

1650
01:09:11,719 --> 01:09:15,640
attendance at the next panel our next

1651
01:09:13,560 --> 01:09:17,880
speaker will come a few minutes after

1652
01:09:15,640 --> 01:09:19,680
that and we'll start up again soon so

1653
01:09:17,880 --> 01:09:23,659
thank thanks very much

1654
01:09:19,680 --> 01:09:23,659
[Applause]


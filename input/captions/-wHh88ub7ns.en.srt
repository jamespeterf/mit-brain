1
00:00:00,000 --> 00:00:03,520
All right, thanks D. Yeah, it's it's

2
00:00:02,000 --> 00:00:04,720
really great to be back. It's been a

3
00:00:03,520 --> 00:00:06,960
long time since I've had a chance to

4
00:00:04,720 --> 00:00:08,320
give a talk at MIT and um one thing I

5
00:00:06,960 --> 00:00:10,480
remembered from organizing the Lids

6
00:00:08,320 --> 00:00:12,800
collopium was that we strategically put

7
00:00:10,480 --> 00:00:14,320
the seminar at the end of the day and

8
00:00:12,800 --> 00:00:15,920
you know that was like it's like you're

9
00:00:14,320 --> 00:00:17,760
running the seminar speaker through the

10
00:00:15,920 --> 00:00:20,080
gauntlet during the day. This is the

11
00:00:17,760 --> 00:00:22,240
most like the most endurance testing

12
00:00:20,080 --> 00:00:24,000
approach to seminar design, right? Like

13
00:00:22,240 --> 00:00:25,119
you know I really appreciated that. It

14
00:00:24,000 --> 00:00:27,519
was great meeting a bunch of people

15
00:00:25,119 --> 00:00:30,080
during the day. I had a lot of fun. Um I

16
00:00:27,519 --> 00:00:32,079
I do think it's um RIDs is just in an

17
00:00:30,080 --> 00:00:33,680
incredibly exciting place. So it's like

18
00:00:32,079 --> 00:00:35,440
really fun to see all the stuff that's

19
00:00:33,680 --> 00:00:36,640
going on here. So yeah, I'm very excited

20
00:00:35,440 --> 00:00:37,600
to tell you about this work. Since we're

21
00:00:36,640 --> 00:00:40,000
starting a little bit late, I'm just

22
00:00:37,600 --> 00:00:41,920
going to jump right in. Um the talk is

23
00:00:40,000 --> 00:00:43,600
about experimentation in marketplaces.

24
00:00:41,920 --> 00:00:45,680
Uh one thing I should say though uh is

25
00:00:43,600 --> 00:00:47,840
it's joint work with Hannah Lee who was

26
00:00:45,680 --> 00:00:50,000
a postoc here some of you may have met u

27
00:00:47,840 --> 00:00:52,239
a current PhD student Anushka Morti

28
00:00:50,000 --> 00:00:54,800
who's in MSN in my department and then

29
00:00:52,239 --> 00:00:57,120
Gabriel Winrob who's at the GSB although

30
00:00:54,800 --> 00:00:59,680
uh as of Thursday uh has just left

31
00:00:57,120 --> 00:01:02,239
Stanford and is moving to Chile. Um so

32
00:00:59,680 --> 00:01:04,920
he's a longtime collaborator of mine.

33
00:01:02,239 --> 00:01:07,080
Okay. So um the talk is about

34
00:01:04,920 --> 00:01:09,760
experimentation really under inventory

35
00:01:07,080 --> 00:01:11,360
constraints and the specific example

36
00:01:09,760 --> 00:01:12,880
I'll keep referring to just in terms of

37
00:01:11,360 --> 00:01:15,040
the language I use when I deliver the

38
00:01:12,880 --> 00:01:17,280
talk is inventory constraints in the

39
00:01:15,040 --> 00:01:19,600
context of marketplaces where guests for

40
00:01:17,280 --> 00:01:21,280
example may arrive to a site like Airbnb

41
00:01:19,600 --> 00:01:23,360
and be looking to put listings but

42
00:01:21,280 --> 00:01:25,360
there's a limited inventory of listings.

43
00:01:23,360 --> 00:01:27,439
Um but I just want to point out a couple

44
00:01:25,360 --> 00:01:29,280
of other sort of types of things I've

45
00:01:27,439 --> 00:01:30,640
worked on where I think similar issues

46
00:01:29,280 --> 00:01:32,799
arise. One is in the context of

47
00:01:30,640 --> 00:01:34,960
healthcare clinics where you have many

48
00:01:32,799 --> 00:01:38,880
patients few providers. So those

49
00:01:34,960 --> 00:01:41,200
patients uh uh interact with sort of a

50
00:01:38,880 --> 00:01:42,720
capacity constrained system that's you

51
00:01:41,200 --> 00:01:44,960
know where care is mediated through a

52
00:01:42,720 --> 00:01:47,360
small number of providers. Another one

53
00:01:44,960 --> 00:01:49,600
uh ongoing collaboration with Netflix

54
00:01:47,360 --> 00:01:51,680
that's related to uh congestion that

55
00:01:49,600 --> 00:01:53,200
occurs at exit from their data centers.

56
00:01:51,680 --> 00:01:54,640
Netflix serves like depending on what

57
00:01:53,200 --> 00:01:56,320
part of the country you're the world

58
00:01:54,640 --> 00:01:58,159
you're in somewhere on the order of like

59
00:01:56,320 --> 00:02:00,399
a quarter of the bits on the internet at

60
00:01:58,159 --> 00:02:02,320
various times. And so like there

61
00:02:00,399 --> 00:02:04,240
actually is real congestion in the exits

62
00:02:02,320 --> 00:02:05,520
from their data centers um where you

63
00:02:04,240 --> 00:02:07,520
have competition between the same

64
00:02:05,520 --> 00:02:08,560
streams. So if you randomize viewers in

65
00:02:07,520 --> 00:02:10,520
an experiment, they're actually

66
00:02:08,560 --> 00:02:12,959
competing with each other for scarce

67
00:02:10,520 --> 00:02:14,879
resources. Um so again, like I said,

68
00:02:12,959 --> 00:02:16,720
I'll use the language of marketplaces to

69
00:02:14,879 --> 00:02:18,319
talk about capacity constraints, but I

70
00:02:16,720 --> 00:02:19,680
don't want you to sort of overindex on

71
00:02:18,319 --> 00:02:22,319
marketplaces. I think I'm going to try

72
00:02:19,680 --> 00:02:24,400
to abstract from that a little bit. Um

73
00:02:22,319 --> 00:02:26,160
okay, so what is the talk about? So talk

74
00:02:24,400 --> 00:02:28,160
is about the fact that marketplaces will

75
00:02:26,160 --> 00:02:30,560
commonly use experiments to assess the

76
00:02:28,160 --> 00:02:31,920
value of interventions and so uh you

77
00:02:30,560 --> 00:02:33,920
know typically referred to these things

78
00:02:31,920 --> 00:02:36,400
as AB tests because the tech industry

79
00:02:33,920 --> 00:02:37,879
has a new name for everything. So AB

80
00:02:36,400 --> 00:02:40,800
tests are just randomized controlled

81
00:02:37,879 --> 00:02:42,640
experiments. Um in two-sided marketplace

82
00:02:40,800 --> 00:02:44,560
platforms you know you might ask

83
00:02:42,640 --> 00:02:46,080
questions like what's the impact of

84
00:02:44,560 --> 00:02:47,599
changing the checkout flow? What's the

85
00:02:46,080 --> 00:02:49,360
impact of changing you know the amount

86
00:02:47,599 --> 00:02:50,879
of information I provide? What's the

87
00:02:49,360 --> 00:02:53,280
impact of changing other aspects of the

88
00:02:50,879 --> 00:02:54,959
market design? In all of these cases,

89
00:02:53,280 --> 00:02:56,720
what you're typically asking yourself

90
00:02:54,959 --> 00:02:58,080
is, what do you think would happen if

91
00:02:56,720 --> 00:03:00,480
you rolled the intervention out to the

92
00:02:58,080 --> 00:03:01,760
whole market versus, you know, you

93
00:03:00,480 --> 00:03:03,840
didn't roll the intervention out to the

94
00:03:01,760 --> 00:03:05,920
whole market. So that difference, the

95
00:03:03,840 --> 00:03:07,360
difference between the entire system in

96
00:03:05,920 --> 00:03:08,720
treatment versus the entire system in

97
00:03:07,360 --> 00:03:10,800
control is what's called the global

98
00:03:08,720 --> 00:03:13,200
treatment effect or the global average

99
00:03:10,800 --> 00:03:14,800
treatment effect. And that's what's

100
00:03:13,200 --> 00:03:16,560
called the est demand of interest, the

101
00:03:14,800 --> 00:03:18,319
the target quantity of interest. And so

102
00:03:16,560 --> 00:03:19,760
we're running experiments to try to

103
00:03:18,319 --> 00:03:21,360
estimate this quantity when we have a

104
00:03:19,760 --> 00:03:23,519
new intervention.

105
00:03:21,360 --> 00:03:24,879
Um, so something that's been well

106
00:03:23,519 --> 00:03:26,239
studied at this point, I've got like a

107
00:03:24,879 --> 00:03:27,200
small caricature you may have seen

108
00:03:26,239 --> 00:03:29,440
before actually because these are

109
00:03:27,200 --> 00:03:32,319
Hannah's slides, uh, that these first

110
00:03:29,440 --> 00:03:34,720
few slides uh, date back to Hannah's job

111
00:03:32,319 --> 00:03:36,799
talk. Um, something that's been well

112
00:03:34,720 --> 00:03:39,680
studied up to this point is the fact

113
00:03:36,799 --> 00:03:42,400
that because there's a common inventory

114
00:03:39,680 --> 00:03:44,480
of listings, uh, you have statistical

115
00:03:42,400 --> 00:03:46,480
interference that's created if you

116
00:03:44,480 --> 00:03:47,920
pursue standard estimation techniques in

117
00:03:46,480 --> 00:03:49,120
this setting. So, let me just make that

118
00:03:47,920 --> 00:03:51,200
more concrete because it's a bit of a

119
00:03:49,120 --> 00:03:53,760
vague statement. So imagine a world in

120
00:03:51,200 --> 00:03:55,360
which I have a set of listings and just

121
00:03:53,760 --> 00:03:58,879
two customers in the world. Highly

122
00:03:55,360 --> 00:04:00,799
caricatured world um and I'm testing a

123
00:03:58,879 --> 00:04:04,400
new feature that makes treatment

124
00:04:00,799 --> 00:04:06,400
listings more attractive. Okay. So um

125
00:04:04,400 --> 00:04:08,000
I'll represent that sort of by the idea

126
00:04:06,400 --> 00:04:10,080
that you know these are more attractive

127
00:04:08,000 --> 00:04:11,200
less attractive in global treatment. I

128
00:04:10,080 --> 00:04:13,760
want to estimate what would have

129
00:04:11,200 --> 00:04:15,680
happened if everybody was seeing more

130
00:04:13,760 --> 00:04:17,199
attractive listings. Global control

131
00:04:15,680 --> 00:04:18,639
everybody is seeing like the vanilla

132
00:04:17,199 --> 00:04:20,400
plain listings. Okay, this might be

133
00:04:18,639 --> 00:04:21,680
something like more attractive profile

134
00:04:20,400 --> 00:04:24,479
pictures for the listings or something

135
00:04:21,680 --> 00:04:25,759
like that. So if I randomize customers

136
00:04:24,479 --> 00:04:27,520
to treatment and control, just to keep

137
00:04:25,759 --> 00:04:28,960
it simple, imagine this customer is in

138
00:04:27,520 --> 00:04:30,000
treatment, this one's in control.

139
00:04:28,960 --> 00:04:32,720
There's only two customers.

140
00:04:30,000 --> 00:04:35,280
Randomization is pretty simple here. So

141
00:04:32,720 --> 00:04:37,600
um let's imagine this customer, they'll

142
00:04:35,280 --> 00:04:38,880
see the world as if it's in control. The

143
00:04:37,600 --> 00:04:40,160
two listings they're considering are

144
00:04:38,880 --> 00:04:41,840
these two. They see them as if they're

145
00:04:40,160 --> 00:04:42,960
in control. This customer is in

146
00:04:41,840 --> 00:04:44,880
treatment. They'll see these two

147
00:04:42,960 --> 00:04:47,919
listings as if they're in treatment.

148
00:04:44,880 --> 00:04:50,720
Okay, that's what randomization means.

149
00:04:47,919 --> 00:04:52,320
Now you can you can see kind of that in

150
00:04:50,720 --> 00:04:54,080
a world in which the treatment customer

151
00:04:52,320 --> 00:04:56,639
arrives before the control customer for

152
00:04:54,080 --> 00:04:58,400
example um the booking outcome of the

153
00:04:56,639 --> 00:04:59,759
treatment customer has a direct impact

154
00:04:58,400 --> 00:05:01,440
now on what happens to the control

155
00:04:59,759 --> 00:05:02,639
customer. So for example if the

156
00:05:01,440 --> 00:05:04,800
treatment customer is more likely to

157
00:05:02,639 --> 00:05:06,400
book maybe they book this middle listing

158
00:05:04,800 --> 00:05:08,080
but then that reduces supply to the

159
00:05:06,400 --> 00:05:10,000
control customer which is the textbook

160
00:05:08,080 --> 00:05:11,759
definition of interference because now

161
00:05:10,000 --> 00:05:13,039
the treatment status of one customer is

162
00:05:11,759 --> 00:05:15,680
impacting the outcome of another

163
00:05:13,039 --> 00:05:17,520
customer. Okay. Um, in this case in

164
00:05:15,680 --> 00:05:19,280
particular, you can actually go a bit

165
00:05:17,520 --> 00:05:21,520
further than that. And one thing you can

166
00:05:19,280 --> 00:05:23,520
see is that the treatment customers are

167
00:05:21,520 --> 00:05:26,080
seeing a relatively less competitive

168
00:05:23,520 --> 00:05:28,479
market in the experiment than they would

169
00:05:26,080 --> 00:05:30,000
see in global treatment because they're

170
00:05:28,479 --> 00:05:32,080
seeing fewer customers that are more

171
00:05:30,000 --> 00:05:34,000
likely to book than they would in global

172
00:05:32,080 --> 00:05:36,560
treatment. And the converse is true for

173
00:05:34,000 --> 00:05:40,080
the global control folks. Uh, in global

174
00:05:36,560 --> 00:05:41,600
control, the market is is um is more

175
00:05:40,080 --> 00:05:43,280
Sorry, I think I said this backwards.

176
00:05:41,600 --> 00:05:45,600
This is a more competitive market than

177
00:05:43,280 --> 00:05:48,000
this one for the treatment customers.

178
00:05:45,600 --> 00:05:50,240
This is a less competitive market than

179
00:05:48,000 --> 00:05:52,000
this one for the control customers. And

180
00:05:50,240 --> 00:05:54,320
because of those effects, you actually

181
00:05:52,000 --> 00:05:56,080
overestimate the treatment effect. Okay?

182
00:05:54,320 --> 00:05:57,680
You overestimate the rate at which uh

183
00:05:56,080 --> 00:05:58,960
the treatment customers book. You

184
00:05:57,680 --> 00:06:00,479
underestimate the rate at which they

185
00:05:58,960 --> 00:06:03,280
would book relative to the respective

186
00:06:00,479 --> 00:06:05,080
globals. Would you run this uh like AB

187
00:06:03,280 --> 00:06:07,680
testing on a very small subset of

188
00:06:05,080 --> 00:06:09,280
population? It shouldn't matter. Like

189
00:06:07,680 --> 00:06:10,560
basically this interference effect is

190
00:06:09,280 --> 00:06:12,880
very small. Yeah, that's a good

191
00:06:10,560 --> 00:06:14,560
question. um you know for the purposes

192
00:06:12,880 --> 00:06:15,520
of what I'm talking about here you

193
00:06:14,560 --> 00:06:17,039
should certainly be thinking about

194
00:06:15,520 --> 00:06:19,039
situations where AB tests are being run

195
00:06:17,039 --> 00:06:21,440
at scale even when they're run in small

196
00:06:19,039 --> 00:06:22,880
populations usually they're run in small

197
00:06:21,440 --> 00:06:24,720
populations that are subsets where

198
00:06:22,880 --> 00:06:26,960
interference is a problem so it's for

199
00:06:24,720 --> 00:06:29,120
example uh there are some tests that are

200
00:06:26,960 --> 00:06:30,400
run at 10% at global scale for example

201
00:06:29,120 --> 00:06:32,240
so maybe that's a place where yeah

202
00:06:30,400 --> 00:06:33,759
that's that's legitimate the kinds of

203
00:06:32,240 --> 00:06:35,919
things I'm imagining are something where

204
00:06:33,759 --> 00:06:37,759
yeah I'm running at 10% but 10% is

205
00:06:35,919 --> 00:06:40,880
within a cluster like New Zealand is

206
00:06:37,759 --> 00:06:42,960
often highlighted as like a like a you a

207
00:06:40,880 --> 00:06:44,400
a textbook country that we experiment on

208
00:06:42,960 --> 00:06:46,080
before we roll thing out to the entire

209
00:06:44,400 --> 00:06:47,360
world. There's like old old articles

210
00:06:46,080 --> 00:06:48,639
written about new, you know, Facebook

211
00:06:47,360 --> 00:06:50,080
experiments in New Zealand for this

212
00:06:48,639 --> 00:06:51,440
reason. I think this is a legitimate

213
00:06:50,080 --> 00:06:54,000
point though. I mean, one thing I like

214
00:06:51,440 --> 00:06:55,680
about this space is that uh there's lots

215
00:06:54,000 --> 00:06:57,120
of degrees of freedom. And so pretty

216
00:06:55,680 --> 00:06:59,360
much everything that you guys will ask

217
00:06:57,120 --> 00:07:00,560
me is going to be something that I don't

218
00:06:59,360 --> 00:07:01,880
have a great answer to. I haven't

219
00:07:00,560 --> 00:07:06,240
thought about, you know, thoroughly.

220
00:07:01,880 --> 00:07:08,720
Yeah. Um Okay. So, um I'm not going to

221
00:07:06,240 --> 00:07:10,960
spend a lot of time uh rehashing related

222
00:07:08,720 --> 00:07:13,360
work on on bias. The main thing I'll say

223
00:07:10,960 --> 00:07:17,280
is that most of the emphasis of of

224
00:07:13,360 --> 00:07:20,479
existing work on this topic has been on

225
00:07:17,280 --> 00:07:23,120
um on sort of focusing on either

226
00:07:20,479 --> 00:07:25,599
quantifying the bias that's created or

227
00:07:23,120 --> 00:07:27,440
doing something about it. Okay. Um so

228
00:07:25,599 --> 00:07:29,199
that would range like you know sort of

229
00:07:27,440 --> 00:07:30,800
how large is that bias but also what are

230
00:07:29,199 --> 00:07:33,039
alternative experiment designs I could

231
00:07:30,800 --> 00:07:34,800
use alternative estimators or both

232
00:07:33,039 --> 00:07:37,199
together that I could use to do

233
00:07:34,800 --> 00:07:38,960
something about this bias. Maybe the

234
00:07:37,199 --> 00:07:40,880
point of this talk is actually somewhat

235
00:07:38,960 --> 00:07:43,120
different and it came from a very

236
00:07:40,880 --> 00:07:44,880
concrete issue that arose when I tried

237
00:07:43,120 --> 00:07:47,199
talking about this work with this work

238
00:07:44,880 --> 00:07:49,120
was uh the initial work that Hannah and

239
00:07:47,199 --> 00:07:51,680
I and Gabriel did was together with the

240
00:07:49,120 --> 00:07:53,120
data scientists at Airbnb. And one of

241
00:07:51,680 --> 00:07:54,560
the things that came up when we were

242
00:07:53,120 --> 00:07:57,440
then sort of presenting these results

243
00:07:54,560 --> 00:07:59,759
more broadly um there and elsewhere is

244
00:07:57,440 --> 00:08:01,280
that people were asking the following

245
00:07:59,759 --> 00:08:02,479
question. Well, you're you're showing me

246
00:08:01,280 --> 00:08:05,520
this caricature where the treatment

247
00:08:02,479 --> 00:08:06,639
effect is overestimated. Is that bad?

248
00:08:05,520 --> 00:08:07,919
because if the treatment effect is

249
00:08:06,639 --> 00:08:09,840
overestimated, I'm not getting the sign

250
00:08:07,919 --> 00:08:11,120
wrong. And if I'm not getting the sign

251
00:08:09,840 --> 00:08:12,560
wrong and I kind of care about launching

252
00:08:11,120 --> 00:08:14,000
this thing, is that really that big of a

253
00:08:12,560 --> 00:08:16,080
deal? And I thought that was a really

254
00:08:14,000 --> 00:08:18,160
good question. Like it's a very simple

255
00:08:16,080 --> 00:08:19,599
but compelling question. And I should

256
00:08:18,160 --> 00:08:21,599
have a good answer to that question. Um,

257
00:08:19,599 --> 00:08:23,039
which we didn't at the time. And that

258
00:08:21,599 --> 00:08:24,240
was really the departure point for this

259
00:08:23,039 --> 00:08:26,240
work. I mean, one of the things that

260
00:08:24,240 --> 00:08:28,479
prompted me to think about was just how

261
00:08:26,240 --> 00:08:30,319
would I answer the question, you know,

262
00:08:28,479 --> 00:08:32,080
does interference matter if I want to

263
00:08:30,319 --> 00:08:35,120
make a decision? So that's the title of

264
00:08:32,080 --> 00:08:36,959
the paper and the talk and that's really

265
00:08:35,120 --> 00:08:39,120
what we'll focus on today. The main

266
00:08:36,959 --> 00:08:40,399
takeaway and I want to I want to qualify

267
00:08:39,120 --> 00:08:41,919
this a little bit I'll try to tell you

268
00:08:40,399 --> 00:08:44,320
where the qualifications around this

269
00:08:41,919 --> 00:08:46,080
claim are. But one takeaway is that for

270
00:08:44,320 --> 00:08:48,160
a wide range of treatments interference

271
00:08:46,080 --> 00:08:50,560
can actually be beneficial and you want

272
00:08:48,160 --> 00:08:53,360
to like I think if you hear that type of

273
00:08:50,560 --> 00:08:55,839
comment on a slide you want to take that

274
00:08:53,360 --> 00:08:58,240
in with the right grain of salt. So I'm

275
00:08:55,839 --> 00:08:59,600
not claiming that this first of all I

276
00:08:58,240 --> 00:09:01,040
mean just as a basic thing I'm not

277
00:08:59,600 --> 00:09:02,959
necessarily claiming this undermines my

278
00:09:01,040 --> 00:09:05,360
own research in the area. Okay so that's

279
00:09:02,959 --> 00:09:06,800
important. Um and I'm also just not I I

280
00:09:05,360 --> 00:09:08,560
don't think I'm claiming that work that

281
00:09:06,800 --> 00:09:10,480
we do on interference and debiasing and

282
00:09:08,560 --> 00:09:12,480
alternative designs is a dead end as a

283
00:09:10,480 --> 00:09:13,440
result. That's not really the point. I

284
00:09:12,480 --> 00:09:15,440
think for me actually the more

285
00:09:13,440 --> 00:09:17,040
compelling takeaway is that this this

286
00:09:15,440 --> 00:09:18,880
kind of work makes it pretty clear to me

287
00:09:17,040 --> 00:09:20,959
that you want to be pretty thoughtful

288
00:09:18,880 --> 00:09:23,360
about exactly when you invest the effort

289
00:09:20,959 --> 00:09:25,680
into a debiasing designer estimator. and

290
00:09:23,360 --> 00:09:28,160
I hadn't really appreciated that sort of

291
00:09:25,680 --> 00:09:29,600
distinction before. Um, and so that that

292
00:09:28,160 --> 00:09:31,120
I think is where I'm hoping there's

293
00:09:29,600 --> 00:09:32,480
something compelling. Besides that, I

294
00:09:31,120 --> 00:09:33,760
just found sort of the methological

295
00:09:32,480 --> 00:09:35,040
aspects of some of this work kind of

296
00:09:33,760 --> 00:09:38,399
interesting to do. So hopefully that

297
00:09:35,040 --> 00:09:40,399
that'll come through. Okay. So um brief

298
00:09:38,399 --> 00:09:41,600
outline, the rough way we're going to

299
00:09:40,399 --> 00:09:43,519
follow this is we're going to build a

300
00:09:41,600 --> 00:09:45,600
queuing model that represents a

301
00:09:43,519 --> 00:09:47,360
caricature of the platform and we'll use

302
00:09:45,600 --> 00:09:48,800
the queueing model and instantiate three

303
00:09:47,360 --> 00:09:50,640
different ways for treatment, for

304
00:09:48,800 --> 00:09:52,240
control, and for an experiment. And then

305
00:09:50,640 --> 00:09:53,360
we'll do everything else in that world.

306
00:09:52,240 --> 00:09:54,880
Okay. Okay. So I'll tell you kind of

307
00:09:53,360 --> 00:09:56,959
decision-m we'll follow frequentist

308
00:09:54,880 --> 00:09:58,519
hypothesis testing and then I'll talk to

309
00:09:56,959 --> 00:10:00,399
you about sort of the

310
00:09:58,519 --> 00:10:03,360
implications. All right. So what's the

311
00:10:00,399 --> 00:10:04,560
model? Um essentially as I just said uh

312
00:10:03,360 --> 00:10:07,040
we'll think about two different

313
00:10:04,560 --> 00:10:08,399
inventory constrained systems as

314
00:10:07,040 --> 00:10:09,920
treatment and control and

315
00:10:08,399 --> 00:10:11,600
experimentation is going to be a mixture

316
00:10:09,920 --> 00:10:13,680
of these two in a way that I'll make

317
00:10:11,600 --> 00:10:15,040
precise in a second. Similar models

318
00:10:13,680 --> 00:10:16,959
studied in a in a range of different

319
00:10:15,040 --> 00:10:18,399
papers. I put H and S here because these

320
00:10:16,959 --> 00:10:19,760
are two different lees. So this is

321
00:10:18,399 --> 00:10:22,560
Hannah Lee who I already mentioned and

322
00:10:19,760 --> 00:10:24,160
then this is Schwanging Lee. Um so you

323
00:10:22,560 --> 00:10:26,720
know all of these papers in different

324
00:10:24,160 --> 00:10:28,240
ways use uh use sort of these kind of

325
00:10:26,720 --> 00:10:30,560
stateful queuing models underneath

326
00:10:28,240 --> 00:10:32,079
models of experimentation. I hope people

327
00:10:30,560 --> 00:10:35,120
here are familiar with this pair of

328
00:10:32,079 --> 00:10:37,120
papers by Vivc Fryas Tani Pang Andy Jang

329
00:10:35,120 --> 00:10:38,720
and few others. Really really nice work

330
00:10:37,120 --> 00:10:40,640
that I think starts connecting the dots

331
00:10:38,720 --> 00:10:42,880
over to reinforcement learning. And I

332
00:10:40,640 --> 00:10:44,320
think that's a very good sort of toolbox

333
00:10:42,880 --> 00:10:47,040
for us to be thinking about with with

334
00:10:44,320 --> 00:10:49,279
these kinds of problems. Okay, inventory

335
00:10:47,040 --> 00:10:51,120
dynamics. I'll I'll summarize quickly by

336
00:10:49,279 --> 00:10:52,959
saying that the inventory dynamics are

337
00:10:51,120 --> 00:10:54,399
birth death chain. And the only reason

338
00:10:52,959 --> 00:10:55,839
these slides exist is to give a little

339
00:10:54,399 --> 00:10:58,160
bit of notation to that birth death

340
00:10:55,839 --> 00:11:00,480
chain. Okay. So what's the birth death

341
00:10:58,160 --> 00:11:02,560
queuing model? Um customers arrive over

342
00:11:00,480 --> 00:11:04,800
time. They can book listings if one is

343
00:11:02,560 --> 00:11:07,720
available. So crucially it's a birth

344
00:11:04,800 --> 00:11:10,640
death chain with a finite buffer finite

345
00:11:07,720 --> 00:11:12,240
inventory of listings available. The

346
00:11:10,640 --> 00:11:14,880
state over time will be the number of

347
00:11:12,240 --> 00:11:16,800
booked listings of this chain. uh

348
00:11:14,880 --> 00:11:18,800
customers can they they arrive as a

349
00:11:16,800 --> 00:11:20,640
pluson process. Now one thing we do

350
00:11:18,800 --> 00:11:22,959
allow in the base model is that

351
00:11:20,640 --> 00:11:24,240
customers can be heterogeneous and I

352
00:11:22,959 --> 00:11:25,760
want to point out here this is

353
00:11:24,240 --> 00:11:27,839
heterogeneity that's sort of irrelevant

354
00:11:25,760 --> 00:11:29,839
from a math standpoint because I can

355
00:11:27,839 --> 00:11:31,760
that better not do that uh that I can I

356
00:11:29,839 --> 00:11:32,880
can aggregate poson processes I still

357
00:11:31,760 --> 00:11:34,880
have a plus on process that's not

358
00:11:32,880 --> 00:11:36,640
interesting the the reason to include

359
00:11:34,880 --> 00:11:39,200
the heterogeneity explicitly is just as

360
00:11:36,640 --> 00:11:40,959
a modeling point that heterogeneity

361
00:11:39,200 --> 00:11:43,760
among customers that's unobservable to

362
00:11:40,959 --> 00:11:46,079
the platform is allowed as a matter of

363
00:11:43,760 --> 00:11:48,160
like the conclusion that I'm drawing one

364
00:11:46,079 --> 00:11:50,480
thing that's not part of the model

365
00:11:48,160 --> 00:11:52,079
priori is listing heterogeneity and I'll

366
00:11:50,480 --> 00:11:53,680
return to that hopefully I'll have a

367
00:11:52,079 --> 00:11:55,600
minute to spend on that at the end of

368
00:11:53,680 --> 00:11:58,640
the talk before I before I wrap up.

369
00:11:55,600 --> 00:12:00,480
Okay. Um now the overall arrival rate is

370
00:11:58,640 --> 00:12:01,880
denoted lambda which is just a sum over

371
00:12:00,480 --> 00:12:04,160
these different

372
00:12:01,880 --> 00:12:07,519
types and then like I said I have a

373
00:12:04,160 --> 00:12:10,480
fixed capacity of listings K listings

374
00:12:07,519 --> 00:12:12,000
and that's the total inventory. And so

375
00:12:10,480 --> 00:12:14,079
what's happening over time is customers

376
00:12:12,000 --> 00:12:15,760
book listings which means the available

377
00:12:14,079 --> 00:12:17,360
inventory at any given time is less than

378
00:12:15,760 --> 00:12:21,440
K. It fluctuates over time. That's the

379
00:12:17,360 --> 00:12:22,959
birth death chain, right? Um I make kind

380
00:12:21,440 --> 00:12:25,519
of a few other primitives that I need

381
00:12:22,959 --> 00:12:27,120
are just how do I book and how do

382
00:12:25,519 --> 00:12:28,800
listings become available? Because of a

383
00:12:27,120 --> 00:12:30,320
birth death chain, I need birth rates

384
00:12:28,800 --> 00:12:32,800
and death rates. So where do those come

385
00:12:30,320 --> 00:12:34,240
from? So the birth rate comes from a

386
00:12:32,800 --> 00:12:35,760
booking probability of arriving

387
00:12:34,240 --> 00:12:38,000
customers. So this is the probability

388
00:12:35,760 --> 00:12:40,240
that an arriving customer is books when

389
00:12:38,000 --> 00:12:41,839
there's k minus k listings available or

390
00:12:40,240 --> 00:12:43,519
equivalently little k listings already

391
00:12:41,839 --> 00:12:45,120
booked. And I'd expect that to be

392
00:12:43,519 --> 00:12:48,480
decreasing in the number of available

393
00:12:45,120 --> 00:12:50,240
listings. Okay. Um that's kind of admits

394
00:12:48,480 --> 00:12:51,600
almost every model of interest to us

395
00:12:50,240 --> 00:12:54,160
probably is going to look something like

396
00:12:51,600 --> 00:12:57,279
that. And lambda of K is just the

397
00:12:54,160 --> 00:13:02,079
aggregation of that uh net booking rate

398
00:12:57,279 --> 00:13:05,360
over over um over customers right um so

399
00:13:02,079 --> 00:13:07,920
customers arrive they book and then you

400
00:13:05,360 --> 00:13:09,040
know as you can see like if you think

401
00:13:07,920 --> 00:13:11,600
about the thing I said at the beginning

402
00:13:09,040 --> 00:13:12,880
of the talk because customers arrive and

403
00:13:11,600 --> 00:13:14,880
book that changes the state of the

404
00:13:12,880 --> 00:13:16,720
system as seen by subsequent customers.

405
00:13:14,880 --> 00:13:18,240
So this is in some sense like the

406
00:13:16,720 --> 00:13:19,680
simplest model in which you can easily

407
00:13:18,240 --> 00:13:21,040
see the inter temporal interference

408
00:13:19,680 --> 00:13:23,200
effect that was outlined at the

409
00:13:21,040 --> 00:13:27,360
beginning in that in that like toy model

410
00:13:23,200 --> 00:13:28,800
right simplest stoastic model. Um, okay.

411
00:13:27,360 --> 00:13:31,920
And then the other thing I need is like

412
00:13:28,800 --> 00:13:34,320
a a a rate at which listings become

413
00:13:31,920 --> 00:13:35,680
available again. So that for when K

414
00:13:34,320 --> 00:13:37,279
listings are booked, that'll be tow of

415
00:13:35,680 --> 00:13:38,800
K. And the only thing I assume about

416
00:13:37,279 --> 00:13:41,120
this is that this is also not decreasing

417
00:13:38,800 --> 00:13:43,839
in K. Like one simple example would

418
00:13:41,120 --> 00:13:45,760
would be if every listing is held for an

419
00:13:43,839 --> 00:13:48,240
independent exponential time before

420
00:13:45,760 --> 00:13:49,920
becoming available, then the the tow

421
00:13:48,240 --> 00:13:51,920
rate would just be constant times the

422
00:13:49,920 --> 00:13:54,399
number of booked listings. Okay, but you

423
00:13:51,920 --> 00:13:56,880
know you could have an MM mm1 type model

424
00:13:54,399 --> 00:13:57,880
where it's a constant uh death rate over

425
00:13:56,880 --> 00:14:01,279
time as

426
00:13:57,880 --> 00:14:03,440
well. Okay. Um so number of booked

427
00:14:01,279 --> 00:14:04,959
listings with this kind of definition

428
00:14:03,440 --> 00:14:06,639
then becomes a continuous time birth

429
00:14:04,959 --> 00:14:09,120
desk chain. Okay. Up to this point I'm

430
00:14:06,639 --> 00:14:11,040
not saying anything very deep. I hope uh

431
00:14:09,120 --> 00:14:12,720
if if LID's education today looks

432
00:14:11,040 --> 00:14:14,639
anything like it did when I was here

433
00:14:12,720 --> 00:14:16,800
that should all be standard for for

434
00:14:14,639 --> 00:14:18,800
folks that that are in the room. I hope

435
00:14:16,800 --> 00:14:21,120
um like the simplest Marov chain that

436
00:14:18,800 --> 00:14:23,920
you would see. Okay.

437
00:14:21,120 --> 00:14:25,199
What's that? Dangerous. Oh, no. Don't

438
00:14:23,920 --> 00:14:27,680
tell me that. Don't tell me that. All

439
00:14:25,199 --> 00:14:29,199
right, let me pause for a second. So,

440
00:14:27,680 --> 00:14:30,560
uh, have I said anything that anyone

441
00:14:29,199 --> 00:14:31,760
wants to ask questions about, especially

442
00:14:30,560 --> 00:14:33,920
after saying that, nobody's going to

443
00:14:31,760 --> 00:14:35,440
raise their hand. So, let me summarize

444
00:14:33,920 --> 00:14:37,600
the model so I don't put anyone on the

445
00:14:35,440 --> 00:14:39,120
spot, right? So, the model is I have a

446
00:14:37,600 --> 00:14:41,839
markoff chain whose state is the number

447
00:14:39,120 --> 00:14:44,720
of booked listings. This state moves up

448
00:14:41,839 --> 00:14:46,240
when a customer arrives and books. Okay.

449
00:14:44,720 --> 00:14:47,680
So the one subtlety you have to keep in

450
00:14:46,240 --> 00:14:50,880
mind I think that'll be important when

451
00:14:47,680 --> 00:14:53,920
we define the data is that um I get to

452
00:14:50,880 --> 00:14:55,519
observe all arrivals and the data will

453
00:14:53,920 --> 00:14:58,079
be the booking outcome of customers

454
00:14:55,519 --> 00:14:59,279
which is zero or one. So that's one

455
00:14:58,079 --> 00:15:01,519
sense in which it's different than a

456
00:14:59,279 --> 00:15:03,040
classical birth death you know data

457
00:15:01,519 --> 00:15:04,399
model because I'm also getting data from

458
00:15:03,040 --> 00:15:06,639
customers that don't book that don't

459
00:15:04,399 --> 00:15:08,320
change the state of the system. Okay. Um

460
00:15:06,639 --> 00:15:10,399
but other than that the the state

461
00:15:08,320 --> 00:15:12,079
changes if customers arrive in book uh

462
00:15:10,399 --> 00:15:13,680
that that reduces the number of booked

463
00:15:12,079 --> 00:15:15,680
listings sorry increases the number of

464
00:15:13,680 --> 00:15:17,279
booked listings and then the number of

465
00:15:15,680 --> 00:15:19,120
book listings goes down by one every

466
00:15:17,279 --> 00:15:21,040
time a listing becomes available again.

467
00:15:19,120 --> 00:15:23,839
The rates of that happening are lambda

468
00:15:21,040 --> 00:15:25,920
of K and toao of K. That's the model.

469
00:15:23,839 --> 00:15:26,959
And what is the treatment? Okay, good.

470
00:15:25,920 --> 00:15:28,240
So, I'm getting there. Haven't gotten

471
00:15:26,959 --> 00:15:29,839
there yet. So, right now, this would be

472
00:15:28,240 --> 00:15:32,079
like two instantiations for treatment

473
00:15:29,839 --> 00:15:34,199
and control. Um, the treatment is going

474
00:15:32,079 --> 00:15:37,199
to be on the booking probabilities,

475
00:15:34,199 --> 00:15:40,079
right? So, uh what I'm imagining is that

476
00:15:37,199 --> 00:15:42,160
I have two different systems that change

477
00:15:40,079 --> 00:15:43,760
the booking probabilities. And I'm going

478
00:15:42,160 --> 00:15:46,639
to use subscript one and zero to denote

479
00:15:43,760 --> 00:15:49,360
treatment and control. Lambda 1 of K is

480
00:15:46,639 --> 00:15:51,440
the booking rate in state K in the

481
00:15:49,360 --> 00:15:54,240
treatment system. Lambda zero of K is

482
00:15:51,440 --> 00:15:56,560
the booking rate in the is the arrival

483
00:15:54,240 --> 00:15:58,240
rate in the control system. So if I

484
00:15:56,560 --> 00:15:59,560
normalize by lambda then these are the

485
00:15:58,240 --> 00:16:01,440
steady state average booking

486
00:15:59,560 --> 00:16:02,720
probabilities. And kind of the

487
00:16:01,440 --> 00:16:05,360
interesting thing from an interference

488
00:16:02,720 --> 00:16:08,000
standpoint to see sort of uh as a matter

489
00:16:05,360 --> 00:16:09,759
of algebra is that treatment changes two

490
00:16:08,000 --> 00:16:11,360
things. There's the direct effect of

491
00:16:09,759 --> 00:16:12,720
changing the rate and the indirect

492
00:16:11,360 --> 00:16:14,800
effect of changing the steady state

493
00:16:12,720 --> 00:16:16,560
distribution. And so the question really

494
00:16:14,800 --> 00:16:17,920
from an inference perspective is can I

495
00:16:16,560 --> 00:16:20,079
estimate both of those two things

496
00:16:17,920 --> 00:16:21,759
together. Estimating the direct effect

497
00:16:20,079 --> 00:16:23,880
is usually the easy thing. The hard

498
00:16:21,759 --> 00:16:27,440
thing is estimating the indirect

499
00:16:23,880 --> 00:16:29,759
effect. Okay. All right. So uh two

500
00:16:27,440 --> 00:16:32,160
slides of of data randomization and

501
00:16:29,759 --> 00:16:33,680
estimation um that are I I think you'll

502
00:16:32,160 --> 00:16:36,720
only need to track the notation on these

503
00:16:33,680 --> 00:16:39,040
these couple of slides. Uh so we run an

504
00:16:36,720 --> 00:16:41,360
experiment with n arriving customers

505
00:16:39,040 --> 00:16:43,920
that I newly randomized to treatment of

506
00:16:41,360 --> 00:16:47,440
control. So y is the booking outcome of

507
00:16:43,920 --> 00:16:49,600
the i customer and um uh the treatment

508
00:16:47,440 --> 00:16:52,160
assignment of a customer you know berni

509
00:16:49,600 --> 00:16:53,360
randomized n1 n0 are used to denote the

510
00:16:52,160 --> 00:16:54,920
number of customers in treatment or

511
00:16:53,360 --> 00:16:58,079
control

512
00:16:54,920 --> 00:17:00,079
okay all right any questions on any of

513
00:16:58,079 --> 00:17:03,279
that notation does that make sense so

514
00:17:00,079 --> 00:17:04,880
first n customers that show up um I'm

515
00:17:03,279 --> 00:17:06,720
going to just you know bully randomize

516
00:17:04,880 --> 00:17:09,679
them over time and then allocate them

517
00:17:06,720 --> 00:17:11,600
now notice that what's happening here is

518
00:17:09,679 --> 00:17:13,120
that means that the effective system

519
00:17:11,600 --> 00:17:15,439
created in the experiment is a mixture

520
00:17:13,120 --> 00:17:17,039
of the two birth dust chains because the

521
00:17:15,439 --> 00:17:18,480
booking rates will be dependent on

522
00:17:17,039 --> 00:17:21,199
whether I got randomized into treatment

523
00:17:18,480 --> 00:17:25,360
or control. Hopefully that's clear. All

524
00:17:21,199 --> 00:17:27,120
right. Um so estimators the estimator of

525
00:17:25,360 --> 00:17:28,960
interest to us in this talk is going to

526
00:17:27,120 --> 00:17:31,440
be not an interesting estimator. It's

527
00:17:28,960 --> 00:17:33,919
the difference in means estimator. So we

528
00:17:31,440 --> 00:17:35,679
just literally take the average booking

529
00:17:33,919 --> 00:17:38,160
in treatment, average booking in control

530
00:17:35,679 --> 00:17:40,080
and the difference of the two. Um the

531
00:17:38,160 --> 00:17:42,880
associated variance estimator that's the

532
00:17:40,080 --> 00:17:45,520
typical thing you learn in stats 101 is

533
00:17:42,880 --> 00:17:47,039
just this like pulled variance uh here

534
00:17:45,520 --> 00:17:48,320
where you know I've got the sample

535
00:17:47,039 --> 00:17:50,240
variance in the treatment group sample

536
00:17:48,320 --> 00:17:53,600
variance in the control group normalized

537
00:17:50,240 --> 00:17:54,960
by the by the sample sizes. And I think

538
00:17:53,600 --> 00:17:56,559
one I want to point a couple things out

539
00:17:54,960 --> 00:17:59,120
on this slide. First of all like why

540
00:17:56,559 --> 00:18:01,440
focus on this? This is by far the most

541
00:17:59,120 --> 00:18:05,280
common way that people form estimates in

542
00:18:01,440 --> 00:18:06,720
industry. Okay. And second, um, it's

543
00:18:05,280 --> 00:18:08,240
interesting to us because there's been a

544
00:18:06,720 --> 00:18:10,000
lot of emphasis on what goes on with

545
00:18:08,240 --> 00:18:11,120
this estimator under interference.

546
00:18:10,000 --> 00:18:12,640
There's actually been not very much

547
00:18:11,120 --> 00:18:14,559
attention paid to what happens to this

548
00:18:12,640 --> 00:18:16,080
estimator. And one interesting thing to

549
00:18:14,559 --> 00:18:17,840
see is that this estimator also has

550
00:18:16,080 --> 00:18:19,760
problems with interference because it

551
00:18:17,840 --> 00:18:21,360
ignores all correlations and obviously

552
00:18:19,760 --> 00:18:23,520
like outcomes are correlated between

553
00:18:21,360 --> 00:18:25,200
customers. So one of our things that

554
00:18:23,520 --> 00:18:28,880
kind of mini problem that arose here was

555
00:18:25,200 --> 00:18:30,720
to understand does interference cause

556
00:18:28,880 --> 00:18:32,960
you know problems for us because this

557
00:18:30,720 --> 00:18:34,559
estimator is also biased and we you know

558
00:18:32,960 --> 00:18:36,720
what's the impact of that. So that was

559
00:18:34,559 --> 00:18:38,640
like a thing that as far as I could tell

560
00:18:36,720 --> 00:18:40,360
hadn't really received much attention um

561
00:18:38,640 --> 00:18:42,960
in the

562
00:18:40,360 --> 00:18:46,400
literature. Um okay and then the last

563
00:18:42,960 --> 00:18:48,240
step is decision- making. So we use in

564
00:18:46,400 --> 00:18:49,840
the same way that these are by far the

565
00:18:48,240 --> 00:18:51,440
most common things that are done in

566
00:18:49,840 --> 00:18:53,360
industry. When I say most common, by the

567
00:18:51,440 --> 00:18:55,200
way, like obviously you may control for

568
00:18:53,360 --> 00:18:56,400
coariantss, right? So there may be like

569
00:18:55,200 --> 00:18:59,039
pre-treatment coariants, things like

570
00:18:56,400 --> 00:19:00,799
that. I'm I'm obviously leaving all of

571
00:18:59,039 --> 00:19:02,240
that complexity out of here. I I think

572
00:19:00,799 --> 00:19:04,320
one could easily start thinking about

573
00:19:02,240 --> 00:19:06,400
models that are more complicated from a

574
00:19:04,320 --> 00:19:08,000
like regression controls perspective,

575
00:19:06,400 --> 00:19:09,440
but it's not changing the fundamental

576
00:19:08,000 --> 00:19:10,799
property that modeling the interference

577
00:19:09,440 --> 00:19:12,440
is not a thing that's usually done with

578
00:19:10,799 --> 00:19:15,120
the naive

579
00:19:12,440 --> 00:19:16,640
estimators. Um, so what do the what does

580
00:19:15,120 --> 00:19:18,880
the decision maker do? They form a t

581
00:19:16,640 --> 00:19:21,120
test. That's the again the most typical

582
00:19:18,880 --> 00:19:23,200
thing or t test statistic. They'll look

583
00:19:21,120 --> 00:19:24,559
at the DM estimator, difference in means

584
00:19:23,200 --> 00:19:27,039
estimator divided by square of the

585
00:19:24,559 --> 00:19:28,480
variance. And then the decision rule is

586
00:19:27,039 --> 00:19:30,640
something like look at your test

587
00:19:28,480 --> 00:19:32,480
statistic and reject it if the magnitude

588
00:19:30,640 --> 00:19:34,080
is large enough. I mean all of these

589
00:19:32,480 --> 00:19:36,320
pages could be taken out of like you

590
00:19:34,080 --> 00:19:38,400
know the first three pages of a a stats

591
00:19:36,320 --> 00:19:41,600
book or something. Yeah. Is there any

592
00:19:38,400 --> 00:19:44,720
general relation between like bias in

593
00:19:41,600 --> 00:19:46,720
the difference in means estimate and any

594
00:19:44,720 --> 00:19:48,400
bias that's in the variance estimate?

595
00:19:46,720 --> 00:19:49,840
That's a great honestly I was wondering

596
00:19:48,400 --> 00:19:50,799
that I don't have an answer to that

597
00:19:49,840 --> 00:19:52,320
question. I think it's a super

598
00:19:50,799 --> 00:19:56,080
interesting question. I'm going to try

599
00:19:52,320 --> 00:19:58,880
to show you at least what we found in in

600
00:19:56,080 --> 00:20:00,559
and um part of that I think one has to

601
00:19:58,880 --> 00:20:01,840
be a little bit careful there because

602
00:20:00,559 --> 00:20:03,280
I'm going to I'm going to split the

603
00:20:01,840 --> 00:20:04,559
problem unsurprisingly because I'm

604
00:20:03,280 --> 00:20:07,039
looking at hypothesis testing. I'll

605
00:20:04,559 --> 00:20:10,480
split it into false positive probability

606
00:20:07,039 --> 00:20:11,840
and power. Um so I'm going to sort of

607
00:20:10,480 --> 00:20:14,640
tell you different things in those two

608
00:20:11,840 --> 00:20:19,320
regimes. uh I don't know if there's sort

609
00:20:14,640 --> 00:20:23,679
of general results on um bias in the

610
00:20:19,320 --> 00:20:26,000
non-null setting and the variance. um we

611
00:20:23,679 --> 00:20:27,679
obtained some interesting there there's

612
00:20:26,000 --> 00:20:29,760
one thing that's not in the talk or the

613
00:20:27,679 --> 00:20:31,039
paper which again I don't think this

614
00:20:29,760 --> 00:20:33,120
should be surprising but I couldn't find

615
00:20:31,039 --> 00:20:35,120
it anywhere which is that intuitively

616
00:20:33,120 --> 00:20:37,840
one should expect the coariance between

617
00:20:35,120 --> 00:20:40,559
successive customers is negative because

618
00:20:37,840 --> 00:20:42,480
if I book then I've reduced inventory so

619
00:20:40,559 --> 00:20:44,240
I should make you less likely to book

620
00:20:42,480 --> 00:20:46,240
and it takes a little bit of work to

621
00:20:44,240 --> 00:20:47,760
show that but that's in fact correct

622
00:20:46,240 --> 00:20:49,280
intuition

623
00:20:47,760 --> 00:20:50,880
um and then because the coariance is

624
00:20:49,280 --> 00:20:52,480
negative one would think that maybe that

625
00:20:50,880 --> 00:20:53,919
would push forward into being able to

626
00:20:52,480 --> 00:20:56,720
say something about the way in which the

627
00:20:53,919 --> 00:20:58,919
variance estimator um the the variance

628
00:20:56,720 --> 00:21:01,039
estimator is biased by missing

629
00:20:58,919 --> 00:21:04,159
correlations. The the issue that we ran

630
00:21:01,039 --> 00:21:05,280
into is that uh that would be true in a

631
00:21:04,159 --> 00:21:06,799
world in which both systems are

632
00:21:05,280 --> 00:21:08,880
identical. So we leverage that for

633
00:21:06,799 --> 00:21:10,400
analyzing false positive probability.

634
00:21:08,880 --> 00:21:12,320
But if the two systems are different

635
00:21:10,400 --> 00:21:14,320
that that effect interacts with the

636
00:21:12,320 --> 00:21:15,919
treatment effect and that we weren't

637
00:21:14,320 --> 00:21:17,760
able to come come up with any nice

638
00:21:15,919 --> 00:21:18,520
expressions. So yeah, I don't have a

639
00:21:17,760 --> 00:21:20,720
good

640
00:21:18,520 --> 00:21:22,159
answer. But that coariance business that

641
00:21:20,720 --> 00:21:26,159
I just mentioned, none of that is in the

642
00:21:22,159 --> 00:21:27,440
talk or the paper. Um, okay. So

643
00:21:26,159 --> 00:21:29,200
returning to the decision rule, the

644
00:21:27,440 --> 00:21:31,360
decision rule is always like reject if

645
00:21:29,200 --> 00:21:32,720
the test statistic is big. Now what does

646
00:21:31,360 --> 00:21:36,000
big mean? The usually the way we think

647
00:21:32,720 --> 00:21:37,840
about big is we fix a desired size,

648
00:21:36,000 --> 00:21:40,799
which is our false positive probability

649
00:21:37,840 --> 00:21:43,120
target that might be like 5%. that then

650
00:21:40,799 --> 00:21:45,919
we do a look up against a normal or a t

651
00:21:43,120 --> 00:21:48,320
table and we end up with a number 1.96

652
00:21:45,919 --> 00:21:50,799
and we reject if it's bigger than 1.96.

653
00:21:48,320 --> 00:21:52,400
Okay. So what's the net output of all of

654
00:21:50,799 --> 00:21:54,320
this? Like what is the decision maker

655
00:21:52,400 --> 00:21:55,679
looking for when we do these kinds of

656
00:21:54,320 --> 00:21:57,360
things? What we're what the decision

657
00:21:55,679 --> 00:21:59,840
maker if if they really believe what's

658
00:21:57,360 --> 00:22:03,679
in a stats book then what they what they

659
00:21:59,840 --> 00:22:07,840
think is happening is if the truth is

660
00:22:03,679 --> 00:22:10,080
that the gte is zero then I should not

661
00:22:07,840 --> 00:22:13,679
reject the null. Right? the the null

662
00:22:10,080 --> 00:22:15,760
being the GTE is zero. And so if the

663
00:22:13,679 --> 00:22:18,080
truth is that the GT is zero, then I

664
00:22:15,760 --> 00:22:19,600
want my the chance that I reject to be

665
00:22:18,080 --> 00:22:21,760
controlled at alpha, which should be no

666
00:22:19,600 --> 00:22:24,640
more than alpha. If the truth is that

667
00:22:21,760 --> 00:22:26,640
the GT is not zero, then I want that to

668
00:22:24,640 --> 00:22:28,880
be as high as possible. Okay? And that's

669
00:22:26,640 --> 00:22:31,039
these two statements. So basically the

670
00:22:28,880 --> 00:22:33,120
two informal goals, and I'll clarify why

671
00:22:31,039 --> 00:22:34,960
they're informal in a second. The two

672
00:22:33,120 --> 00:22:37,039
informal goals are that false positive

673
00:22:34,960 --> 00:22:38,640
probability is controlled at level alpha

674
00:22:37,039 --> 00:22:39,760
and that your statistical power is as

675
00:22:38,640 --> 00:22:41,120
high as possible. It's basically

676
00:22:39,760 --> 00:22:42,799
hypothesis testing is binary

677
00:22:41,120 --> 00:22:44,200
classification and these are the two

678
00:22:42,799 --> 00:22:47,840
goals that I have in binary

679
00:22:44,200 --> 00:22:50,400
classification. Um why is it informal?

680
00:22:47,840 --> 00:22:52,080
It's informal actually because H0 not

681
00:22:50,400 --> 00:22:54,559
true and H0 true are not well-

682
00:22:52,080 --> 00:22:57,280
definfined things to condition on. When

683
00:22:54,559 --> 00:23:01,120
H0 is true, right, what does that mean?

684
00:22:57,280 --> 00:23:03,200
The gte is zero. In my setting, there's

685
00:23:01,120 --> 00:23:04,559
many systems that can give rise to the

686
00:23:03,200 --> 00:23:06,159
same booking rates, booking

687
00:23:04,559 --> 00:23:08,400
probabilities that are different from

688
00:23:06,159 --> 00:23:11,039
each other. And without a distribution

689
00:23:08,400 --> 00:23:12,480
over those systems, like putting this to

690
00:23:11,039 --> 00:23:13,360
the right of the slash doesn't mean

691
00:23:12,480 --> 00:23:16,159
anything. So that's not a well-

692
00:23:13,360 --> 00:23:17,919
definfined event. And more commonly,

693
00:23:16,159 --> 00:23:20,320
this is the case certainly when looking

694
00:23:17,919 --> 00:23:22,559
at alternatives. This is standard,

695
00:23:20,320 --> 00:23:24,000
right? That if I look at power, I have

696
00:23:22,559 --> 00:23:25,360
to talk about power at a specific

697
00:23:24,000 --> 00:23:27,600
alternative, which I did not make

698
00:23:25,360 --> 00:23:29,200
precise here, right? So one of the

699
00:23:27,600 --> 00:23:31,200
things I'm going to first focus on false

700
00:23:29,200 --> 00:23:32,880
positive probability and getting like

701
00:23:31,200 --> 00:23:34,880
ask like try to tell you a little bit

702
00:23:32,880 --> 00:23:36,400
how do we tackle this composite null

703
00:23:34,880 --> 00:23:39,640
problem. So the composite null is the

704
00:23:36,400 --> 00:23:42,559
fact that h0 is this composite of many

705
00:23:39,640 --> 00:23:45,919
possible system pairs that give rise to

706
00:23:42,559 --> 00:23:47,360
a a difference that's zero. Um now

707
00:23:45,919 --> 00:23:48,720
before I do that I just want to say one

708
00:23:47,360 --> 00:23:49,480
thing and then and then pause a second

709
00:23:48,720 --> 00:23:51,280
for

710
00:23:49,480 --> 00:23:52,880
questions. This is a weird

711
00:23:51,280 --> 00:23:54,320
decision-making framework. I think we

712
00:23:52,880 --> 00:23:57,280
should all agree on that. It's like

713
00:23:54,320 --> 00:23:59,840
weird and like very commonplace at the

714
00:23:57,280 --> 00:24:01,520
same time, right? And this is a a thing

715
00:23:59,840 --> 00:24:03,600
I was wondering working on this too.

716
00:24:01,520 --> 00:24:05,840
Like I think there are two motivations

717
00:24:03,600 --> 00:24:07,280
for this kind of work. You know, either

718
00:24:05,840 --> 00:24:09,120
where you want to end up is you want to

719
00:24:07,280 --> 00:24:11,679
come up with a decision-m procedure

720
00:24:09,120 --> 00:24:13,520
that's so unambiguously better that

721
00:24:11,679 --> 00:24:16,000
everyone should stop what they're doing,

722
00:24:13,520 --> 00:24:17,200
like run and trash everything, all the

723
00:24:16,000 --> 00:24:20,080
code on their systems and start over

724
00:24:17,200 --> 00:24:21,760
with what you just came up with. or

725
00:24:20,080 --> 00:24:24,000
you're seeing something that everybody

726
00:24:21,760 --> 00:24:25,679
is doing and the only question, the

727
00:24:24,000 --> 00:24:27,679
scientific question is what is the

728
00:24:25,679 --> 00:24:29,679
implication of what you're doing? In

729
00:24:27,679 --> 00:24:31,200
that world, I'm not spending a lot of

730
00:24:29,679 --> 00:24:33,279
time asking myself whether what they're

731
00:24:31,200 --> 00:24:34,799
doing makes sense. I'm really just

732
00:24:33,279 --> 00:24:36,159
trying to understand the implications of

733
00:24:34,799 --> 00:24:38,039
what they're doing because I got to be

734
00:24:36,159 --> 00:24:40,559
honest with you, I have a lot of trouble

735
00:24:38,039 --> 00:24:42,720
with sort of accepting, you know, null

736
00:24:40,559 --> 00:24:44,559
hypothesis, significance testing as the

737
00:24:42,720 --> 00:24:46,240
right way to make business decisions.

738
00:24:44,559 --> 00:24:48,799
But that's not my call. Like a lot of

739
00:24:46,240 --> 00:24:49,919
people do this every day. So because a

740
00:24:48,799 --> 00:24:51,360
lot of people do it every day as a

741
00:24:49,919 --> 00:24:52,960
matter of science at least understanding

742
00:24:51,360 --> 00:24:54,400
why what the implications are what

743
00:24:52,960 --> 00:24:55,520
they're doing is worth it. I just want

744
00:24:54,400 --> 00:24:56,960
to make that clear to everybody because

745
00:24:55,520 --> 00:24:58,960
I think a common reaction at this point

746
00:24:56,960 --> 00:25:00,559
would be I just don't think that's the

747
00:24:58,960 --> 00:25:02,080
right way to do things. That's fine but

748
00:25:00,559 --> 00:25:04,080
then we should run out and develop this

749
00:25:02,080 --> 00:25:05,279
like alternative world killing strategy

750
00:25:04,080 --> 00:25:06,400
that's way better than what they're

751
00:25:05,279 --> 00:25:07,840
doing right now. And we haven't been

752
00:25:06,400 --> 00:25:10,000
successful at that over 100 years of

753
00:25:07,840 --> 00:25:12,559
trying. So I think that's part of the

754
00:25:10,000 --> 00:25:14,640
problem in industry I feel is getting

755
00:25:12,559 --> 00:25:16,559
people to a place where they understand

756
00:25:14,640 --> 00:25:17,919
the consequences of the decision proc

757
00:25:16,559 --> 00:25:20,080
decision-making procedures they're

758
00:25:17,919 --> 00:25:21,360
using. Um so this something I think I

759
00:25:20,080 --> 00:25:23,600
find very interesting. That's one of the

760
00:25:21,360 --> 00:25:25,600
reasons I got into this work was that I

761
00:25:23,600 --> 00:25:28,320
think there's a lot there um to be able

762
00:25:25,600 --> 00:25:30,720
to take you know for example one thing I

763
00:25:28,320 --> 00:25:33,039
would love to see more of is uh a more

764
00:25:30,720 --> 00:25:36,080
basian perspective to decision-m where

765
00:25:33,039 --> 00:25:37,919
past experiments inform uh you know

766
00:25:36,080 --> 00:25:39,679
allow you to form a prior before you run

767
00:25:37,919 --> 00:25:41,520
your next experiment. That would be a

768
00:25:39,679 --> 00:25:43,520
much more sensible way in my view of

769
00:25:41,520 --> 00:25:45,520
thinking about decision-m but that's not

770
00:25:43,520 --> 00:25:47,039
typical. It's not that doesn't happen

771
00:25:45,520 --> 00:25:48,559
and there's certainly large companies in

772
00:25:47,039 --> 00:25:51,720
particular I think that have done that

773
00:25:48,559 --> 00:25:55,720
but this is still extremely common place

774
00:25:51,720 --> 00:26:00,480
right okay let me pause there for a

775
00:25:55,720 --> 00:26:00,480
second questions on any of the setups so

776
00:26:00,919 --> 00:26:05,919
far okay so birth death chains for

777
00:26:03,679 --> 00:26:08,240
treatment and control experiment is a

778
00:26:05,919 --> 00:26:09,600
mixture of the two I get some data out

779
00:26:08,240 --> 00:26:10,799
and then I use the data form the

780
00:26:09,600 --> 00:26:13,440
difference in means estimator the

781
00:26:10,799 --> 00:26:17,200
variance estimator run a t test and and

782
00:26:13,440 --> 00:26:19,360
then use that to reject the null.

783
00:26:17,200 --> 00:26:21,360
Why do you run a t test? I mean, what

784
00:26:19,360 --> 00:26:23,440
guarantees of

785
00:26:21,360 --> 00:26:24,720
nothing guarante?

786
00:26:23,440 --> 00:26:26,320
Yeah, nothing. That's the whole point of

787
00:26:24,720 --> 00:26:28,159
the talk, right? Is like they don't they

788
00:26:26,320 --> 00:26:30,880
don't have that, but they do other

789
00:26:28,159 --> 00:26:32,240
things. I mean, there's like bootstrap.

790
00:26:30,880 --> 00:26:33,760
There's a million other things that one

791
00:26:32,240 --> 00:26:35,200
can do. Yeah, it's interesting actually.

792
00:26:33,760 --> 00:26:37,840
So, bootstrap is one that I was really

793
00:26:35,200 --> 00:26:39,600
surprised wasn't more commonly used. Um,

794
00:26:37,840 --> 00:26:41,120
I think there's a couple reasons. Most

795
00:26:39,600 --> 00:26:43,520
of them stupid honestly, but they're

796
00:26:41,120 --> 00:26:45,679
important to highlight. Um, so one of

797
00:26:43,520 --> 00:26:47,360
them is that these test results are

798
00:26:45,679 --> 00:26:50,320
typically populated into dashboards that

799
00:26:47,360 --> 00:26:51,520
are continuously accessible. And like

800
00:26:50,320 --> 00:26:52,799
does it need to be that way? I don't

801
00:26:51,520 --> 00:26:55,039
know. That's a different question. But

802
00:26:52,799 --> 00:26:56,559
rerunning Bootstrap at scale for all the

803
00:26:55,039 --> 00:26:58,559
experiments that a company has running

804
00:26:56,559 --> 00:27:00,080
is like something that experimentation

805
00:26:58,559 --> 00:27:03,039
platform teams typically aren't

806
00:27:00,080 --> 00:27:04,960
prioritizing against like you know other

807
00:27:03,039 --> 00:27:06,559
sort of needs. So that's one reason that

808
00:27:04,960 --> 00:27:07,760
I bring up is like the fact that they're

809
00:27:06,559 --> 00:27:08,960
running these and then that raises a

810
00:27:07,760 --> 00:27:10,720
whole host of other issues because now

811
00:27:08,960 --> 00:27:13,039
you've got effectively like sequential

812
00:27:10,720 --> 00:27:14,400
testing happening, right? Another one

813
00:27:13,039 --> 00:27:15,520
that I found somewhat surprising, I

814
00:27:14,400 --> 00:27:17,440
think maybe interesting to some people

815
00:27:15,520 --> 00:27:19,440
in the room, but it isn't certainly not

816
00:27:17,440 --> 00:27:21,320
part of this talk is just the fact that

817
00:27:19,440 --> 00:27:23,919
there's um

818
00:27:21,320 --> 00:27:25,360
um like every team that I've talked

819
00:27:23,919 --> 00:27:26,559
virtually every team I guess not all but

820
00:27:25,360 --> 00:27:28,320
virtually every team I've talked to that

821
00:27:26,559 --> 00:27:31,039
builds experimentation platforms in

822
00:27:28,320 --> 00:27:32,720
companies is a cost center. They really

823
00:27:31,039 --> 00:27:34,400
only exist to serve other business

824
00:27:32,720 --> 00:27:36,480
units. they're not generating any

825
00:27:34,400 --> 00:27:37,840
revenue on their own. And that actually

826
00:27:36,480 --> 00:27:39,120
turns out to have some really important

827
00:27:37,840 --> 00:27:40,559
implications. I think the thing it's

828
00:27:39,120 --> 00:27:42,480
closest to is sort of like the stuff

829
00:27:40,559 --> 00:27:44,080
that Stephen has thought about a little

830
00:27:42,480 --> 00:27:46,159
bit with like principal agent hypothesis

831
00:27:44,080 --> 00:27:47,840
testing where what ends up happening is

832
00:27:46,159 --> 00:27:49,520
that a lot of the statistical

833
00:27:47,840 --> 00:27:52,400
infrastructure they're building is in

834
00:27:49,520 --> 00:27:53,520
response to the demands of data

835
00:27:52,400 --> 00:27:54,880
scientists that have very strong

836
00:27:53,520 --> 00:27:58,240
incentives in play for what they're

837
00:27:54,880 --> 00:28:00,880
asking for. And that creates like an odd

838
00:27:58,240 --> 00:28:03,039
an odd sort of environment in which what

839
00:28:00,880 --> 00:28:05,440
gets built actually is the outcome of a

840
00:28:03,039 --> 00:28:07,760
game that we don't understand very well.

841
00:28:05,440 --> 00:28:09,120
And and uh and so I'm not going to say

842
00:28:07,760 --> 00:28:10,960
any more about that, right? Like to make

843
00:28:09,120 --> 00:28:13,279
sure I finish on time, but I do think

844
00:28:10,960 --> 00:28:14,399
that there there's like deserata maybe

845
00:28:13,279 --> 00:28:16,960
is the best way to say it. There's

846
00:28:14,399 --> 00:28:19,840
deserata in the construction of the

847
00:28:16,960 --> 00:28:21,919
environment that go well beyond what

848
00:28:19,840 --> 00:28:23,559
what we would do as methods people. But

849
00:28:21,919 --> 00:28:26,000
that said, as narrowly as a methods

850
00:28:23,559 --> 00:28:28,960
researcher, that question of like what

851
00:28:26,000 --> 00:28:32,640
what is going on with this choice is

852
00:28:28,960 --> 00:28:34,720
what motivated the talk. Yeah. Okay. So,

853
00:28:32,640 --> 00:28:36,000
let me talk briefly about maybe the one

854
00:28:34,720 --> 00:28:37,919
big assumption that I'm going to make

855
00:28:36,000 --> 00:28:40,480
and then what that gets me and we'll see

856
00:28:37,919 --> 00:28:43,039
how I do on time. Um, hopefully I can

857
00:28:40,480 --> 00:28:44,240
get through most of this. Okay. So, I

858
00:28:43,039 --> 00:28:46,080
already said this that there's many

859
00:28:44,240 --> 00:28:49,279
potential treatments that can yield a

860
00:28:46,080 --> 00:28:52,640
gte of zero. Um, and so one thing that

861
00:28:49,279 --> 00:28:54,480
we do, I think this is maybe I'm going

862
00:28:52,640 --> 00:28:56,080
to try to convince you that this class

863
00:28:54,480 --> 00:28:59,520
of treatments is interesting in its own

864
00:28:56,080 --> 00:29:01,279
right and it has the property that if I

865
00:28:59,520 --> 00:29:04,080
if I know in advance that the treatment

866
00:29:01,279 --> 00:29:06,480
lies in this class and I tell you the GT

867
00:29:04,080 --> 00:29:08,320
is zero, then it collapses the null to

868
00:29:06,480 --> 00:29:12,480
being a point null instead of a

869
00:29:08,320 --> 00:29:14,159
composite null. Now monotinicity, the

870
00:29:12,480 --> 00:29:15,919
the phrase we use is monotonicity. I've

871
00:29:14,159 --> 00:29:17,520
actually in another talk I got feedback

872
00:29:15,919 --> 00:29:19,120
that maybe that's not the right phrase

873
00:29:17,520 --> 00:29:21,760
to use. So I'm open to workshopping

874
00:29:19,120 --> 00:29:23,520
this. But what does monotonicity mean?

875
00:29:21,760 --> 00:29:27,360
Um it basically means that the treatment

876
00:29:23,520 --> 00:29:30,240
is monotone if uh the the sign of the

877
00:29:27,360 --> 00:29:33,200
change of the booking rate is the same

878
00:29:30,240 --> 00:29:34,880
in every state. So roughly speaking in

879
00:29:33,200 --> 00:29:36,960
words what does this mean? That the sign

880
00:29:34,880 --> 00:29:39,200
of the change is is not state dependent

881
00:29:36,960 --> 00:29:40,480
averaged over customer types. So here's

882
00:29:39,200 --> 00:29:42,399
a case where like for example some

883
00:29:40,480 --> 00:29:43,919
customer types may go up some go down.

884
00:29:42,399 --> 00:29:46,799
I'm just saying that on average across

885
00:29:43,919 --> 00:29:49,120
customer types um in each state the sign

886
00:29:46,799 --> 00:29:50,640
of that change is is the same. Uh there

887
00:29:49,120 --> 00:29:52,559
were similar things that were studied

888
00:29:50,640 --> 00:29:54,480
some in an empirical context by Dave

889
00:29:52,559 --> 00:29:57,200
Holtz and then others in sort of more

890
00:29:54,480 --> 00:29:58,799
methods papers here. One of we had uh an

891
00:29:57,200 --> 00:30:01,039
early definition like this in our paper

892
00:29:58,799 --> 00:30:03,279
from 22. Um one I'll call out here is

893
00:30:01,039 --> 00:30:04,559
this paper by folks from Lyft uh where

894
00:30:03,279 --> 00:30:06,159
they were looking at shadow price

895
00:30:04,559 --> 00:30:07,600
adjustments to deal with interference.

896
00:30:06,159 --> 00:30:09,559
They do their analysis under an

897
00:30:07,600 --> 00:30:13,279
assumption like this one about the

898
00:30:09,559 --> 00:30:14,640
treatment. Okay. Um now there's many

899
00:30:13,279 --> 00:30:16,799
examples of treatments that could be

900
00:30:14,640 --> 00:30:18,000
modeled this way. It was funny because

901
00:30:16,799 --> 00:30:19,919
initially like when we started working

902
00:30:18,000 --> 00:30:22,000
on this it was just like a methological

903
00:30:19,919 --> 00:30:23,360
of methological interest to us like what

904
00:30:22,000 --> 00:30:25,840
what is an interesting assumption that

905
00:30:23,360 --> 00:30:27,120
gets that gets to a point null but then

906
00:30:25,840 --> 00:30:29,679
I realized actually you know most things

907
00:30:27,120 --> 00:30:30,960
that you do fall in that class. There's

908
00:30:29,679 --> 00:30:32,320
like some things we do that are

909
00:30:30,960 --> 00:30:34,240
genuinely state dependent but many

910
00:30:32,320 --> 00:30:36,559
things are not. Um so you know

911
00:30:34,240 --> 00:30:38,799
increasing information in introducing

912
00:30:36,559 --> 00:30:40,480
new payment flows changes to the user

913
00:30:38,799 --> 00:30:42,240
interface the vast majority of these are

914
00:30:40,480 --> 00:30:43,520
really like state independent if I think

915
00:30:42,240 --> 00:30:44,640
the sign of that is something and

916
00:30:43,520 --> 00:30:45,919
there's no particular reason to think

917
00:30:44,640 --> 00:30:47,760
that depends on how many things I have

918
00:30:45,919 --> 00:30:50,240
available or certainly not in a first

919
00:30:47,760 --> 00:30:52,000
order way. One of my favorite ones here

920
00:30:50,240 --> 00:30:53,600
a key thing about all of these is that I

921
00:30:52,000 --> 00:30:56,240
also may not know in advance the sign of

922
00:30:53,600 --> 00:30:58,000
the effect. Okay that's important. Um

923
00:30:56,240 --> 00:31:00,320
and so like one of my favorite ones

924
00:30:58,000 --> 00:31:02,000
about this is this Etsy one. Etsy

925
00:31:00,320 --> 00:31:04,080
offsets carbon emissions from shipping

926
00:31:02,000 --> 00:31:05,679
and packaging on this purpose on this

927
00:31:04,080 --> 00:31:07,039
purchase. And that's one where certainly

928
00:31:05,679 --> 00:31:09,279
I think like depending on where you live

929
00:31:07,039 --> 00:31:10,880
in the country. That is like a pro or a

930
00:31:09,279 --> 00:31:13,279
con, you know, that uh that that's

931
00:31:10,880 --> 00:31:15,200
that's what they're doing. So um so I

932
00:31:13,279 --> 00:31:17,039
think I think you know for us it was

933
00:31:15,200 --> 00:31:18,320
interesting to then see that there's a

934
00:31:17,039 --> 00:31:20,559
wide range of interventions that

935
00:31:18,320 --> 00:31:22,240
potentially could fall in this class.

936
00:31:20,559 --> 00:31:23,760
That said, I do want to say for the

937
00:31:22,240 --> 00:31:26,399
purposes of this talk and it's a lids

938
00:31:23,760 --> 00:31:28,399
colloquium that like you know I think

939
00:31:26,399 --> 00:31:31,200
the interesting thing about that is that

940
00:31:28,399 --> 00:31:34,640
kind of what it gives us um from the

941
00:31:31,200 --> 00:31:36,600
perspective of our model is a class of

942
00:31:34,640 --> 00:31:39,919
treatments that's plausible and

943
00:31:36,600 --> 00:31:42,480
interesting and that has a property that

944
00:31:39,919 --> 00:31:44,000
really then makes analysis tractable and

945
00:31:42,480 --> 00:31:45,679
lets us say some interesting stuff.

946
00:31:44,000 --> 00:31:46,880
Okay. So I think it wouldn't be

947
00:31:45,679 --> 00:31:49,120
interesting to say what I'm about to

948
00:31:46,880 --> 00:31:50,399
tell you if it wasn't plausible and it

949
00:31:49,120 --> 00:31:51,960
wouldn't be enough if it was plausible

950
00:31:50,399 --> 00:31:54,000
without any technical

951
00:31:51,960 --> 00:31:55,760
consequence. Um and of course there's

952
00:31:54,000 --> 00:31:59,440
the classic box quote that's mandatory

953
00:31:55,760 --> 00:32:01,440
on any slide like this. All right. So uh

954
00:31:59,440 --> 00:32:03,200
what is a monot what do we get out of

955
00:32:01,440 --> 00:32:06,640
monotonicity? We get that if the

956
00:32:03,200 --> 00:32:09,120
treatment is monotone then the if the

957
00:32:06,640 --> 00:32:12,559
gte is zero. So if you have monotone

958
00:32:09,120 --> 00:32:13,919
treatment and the GT is zero then the

959
00:32:12,559 --> 00:32:16,799
booking rates have to be identical in

960
00:32:13,919 --> 00:32:19,200
the two systems. Um so this is what's uh

961
00:32:16,799 --> 00:32:21,200
sometimes known as the Fiser null or the

962
00:32:19,200 --> 00:32:22,799
Fisher sharp null that the data

963
00:32:21,200 --> 00:32:27,679
generation process under treatment and

964
00:32:22,799 --> 00:32:29,200
control is identical. Okay. Um and one

965
00:32:27,679 --> 00:32:31,840
one thing I just want to point out for

966
00:32:29,200 --> 00:32:33,919
those of you that care about this sort

967
00:32:31,840 --> 00:32:35,360
of thing. One one reason I found this

968
00:32:33,919 --> 00:32:36,880
project fun is that I learned something

969
00:32:35,360 --> 00:32:38,720
about birth death chains that I didn't

970
00:32:36,880 --> 00:32:41,039
know before which is really cool because

971
00:32:38,720 --> 00:32:42,480
they're like again like I said the first

972
00:32:41,039 --> 00:32:44,159
you know one of the first Morov chain

973
00:32:42,480 --> 00:32:45,519
models you learn. So birth death chains

974
00:32:44,159 --> 00:32:47,679
actually have a very nice property which

975
00:32:45,519 --> 00:32:50,080
is called stochastic monotonicity which

976
00:32:47,679 --> 00:32:52,240
is that uh if you if you initialize the

977
00:32:50,080 --> 00:32:54,080
chain in two distributions one of which

978
00:32:52,240 --> 00:32:56,880
stoastically dominates the other that

979
00:32:54,080 --> 00:32:58,559
property is preserved for all time and

980
00:32:56,880 --> 00:33:00,559
you know continuous time analoges of

981
00:32:58,559 --> 00:33:02,399
birth test chains exhibit the same

982
00:33:00,559 --> 00:33:03,919
behavior. This is a very nice very

983
00:33:02,399 --> 00:33:05,360
interesting property and it turns out

984
00:33:03,919 --> 00:33:06,799
for us that's ideal because if you

985
00:33:05,360 --> 00:33:08,960
combine that with monotonicity of

986
00:33:06,799 --> 00:33:10,559
booking probabilities it it sort of

987
00:33:08,960 --> 00:33:13,039
gives you exactly the machinery you need

988
00:33:10,559 --> 00:33:15,679
to get this type of result right so that

989
00:33:13,039 --> 00:33:16,880
was that was kind of nice okay so the

990
00:33:15,679 --> 00:33:18,559
first thing that I want to tell you is

991
00:33:16,880 --> 00:33:19,840
then what do we get as a consequence and

992
00:33:18,559 --> 00:33:21,360
now I can look at false positive

993
00:33:19,840 --> 00:33:25,360
probability but under this restriction

994
00:33:21,360 --> 00:33:26,360
of monotone treatment yeah so um the

995
00:33:25,360 --> 00:33:31,519
assumption

996
00:33:26,360 --> 00:33:33,120
that the time it takes for the uh the

997
00:33:31,519 --> 00:33:34,559
book looking to become reavailable. Ah

998
00:33:33,120 --> 00:33:36,240
that that doesn't change with treatment

999
00:33:34,559 --> 00:33:38,559
doesn't change with the treatment. Yeah.

1000
00:33:36,240 --> 00:33:40,559
So one of the reasons that that's the

1001
00:33:38,559 --> 00:33:43,600
case in this paper is that we're looking

1002
00:33:40,559 --> 00:33:47,519
at randomization on the customer side.

1003
00:33:43,600 --> 00:33:50,799
And so it's hard to imagine sort of like

1004
00:33:47,519 --> 00:33:53,039
how treatment on the customer side can

1005
00:33:50,799 --> 00:33:54,640
then get fed through to changes in just

1006
00:33:53,039 --> 00:33:56,399
those rates. it feels like I would need

1007
00:33:54,640 --> 00:33:58,240
a much higher state much higher

1008
00:33:56,399 --> 00:34:00,000
dimensional state representation where

1009
00:33:58,240 --> 00:34:02,480
I'm tracking what type of customer

1010
00:34:00,000 --> 00:34:05,279
booked me and that's having an impact on

1011
00:34:02,480 --> 00:34:07,760
my and so yeah that's I think one thing

1012
00:34:05,279 --> 00:34:09,599
is that I believe that most of what I'm

1013
00:34:07,760 --> 00:34:11,679
about to talk about is true even if you

1014
00:34:09,599 --> 00:34:13,359
focus on listing randomization where the

1015
00:34:11,679 --> 00:34:15,679
listings are what's treated and allow

1016
00:34:13,359 --> 00:34:17,280
that type of thing but you would need a

1017
00:34:15,679 --> 00:34:18,879
a very different model like so

1018
00:34:17,280 --> 00:34:21,119
qualitatively I believe it but it's just

1019
00:34:18,879 --> 00:34:23,520
a conjecture I don't I don't have theory

1020
00:34:21,119 --> 00:34:26,240
that fills that

1021
00:34:23,520 --> 00:34:27,520
Okay. So, uh I'm going to keep one eye

1022
00:34:26,240 --> 00:34:28,560
on the time here and I just want to make

1023
00:34:27,520 --> 00:34:30,320
sure I'm able to get through the

1024
00:34:28,560 --> 00:34:31,919
results. Um but now that we've got all

1025
00:34:30,320 --> 00:34:35,040
the setup, the results are a little bit

1026
00:34:31,919 --> 00:34:37,720
quicker to present. So, I think a simple

1027
00:34:35,040 --> 00:34:40,879
way to think about what I want to tell

1028
00:34:37,720 --> 00:34:42,560
you is um I want to talk about false

1029
00:34:40,879 --> 00:34:43,760
positive probability and power and I'm

1030
00:34:42,560 --> 00:34:45,200
looking at a test statistic that

1031
00:34:43,760 --> 00:34:48,079
involves a difference in means estimator

1032
00:34:45,200 --> 00:34:49,599
and a variance estimator. And so one way

1033
00:34:48,079 --> 00:34:51,599
to think about that is there's I care

1034
00:34:49,599 --> 00:34:53,919
about these two quantities under the

1035
00:34:51,599 --> 00:34:55,119
null and in a non-null setting. So

1036
00:34:53,919 --> 00:34:57,520
that's kind of what I'm going to try to

1037
00:34:55,119 --> 00:34:59,040
tell you. Okay. Now under the null, it's

1038
00:34:57,520 --> 00:35:00,560
pretty obvious to see that the

1039
00:34:59,040 --> 00:35:02,240
difference in means estimator has mean

1040
00:35:00,560 --> 00:35:05,200
zero. So that's not that comp. The two

1041
00:35:02,240 --> 00:35:06,880
systems are identical. So that's easy.

1042
00:35:05,200 --> 00:35:08,880
What surprised us is actually the

1043
00:35:06,880 --> 00:35:10,800
variance estimator is unbiased for the

1044
00:35:08,880 --> 00:35:12,480
true variance of the difference in means

1045
00:35:10,800 --> 00:35:14,000
estimator. And remember that should be

1046
00:35:12,480 --> 00:35:15,599
surprising even under the null where the

1047
00:35:14,000 --> 00:35:17,839
two systems are identical. At least to

1048
00:35:15,599 --> 00:35:19,200
us it was because there's no correlation

1049
00:35:17,839 --> 00:35:21,000
included in the difference in means

1050
00:35:19,200 --> 00:35:24,160
estimator, sorry, in the variance

1051
00:35:21,000 --> 00:35:26,960
estimator. And the proof of it also is a

1052
00:35:24,160 --> 00:35:28,800
little fun and cute because it combines

1053
00:35:26,960 --> 00:35:30,000
ideas from Fischer and Neon which like

1054
00:35:28,800 --> 00:35:32,880
for those of you that know didn't get

1055
00:35:30,000 --> 00:35:34,480
along and so it was nice to it was nice

1056
00:35:32,880 --> 00:35:36,320
to actually like figure out a way to

1057
00:35:34,480 --> 00:35:38,320
like combine sort of some of the

1058
00:35:36,320 --> 00:35:40,079
statistical ideas from each of them. And

1059
00:35:38,320 --> 00:35:41,200
the rough idea is that we prove this

1060
00:35:40,079 --> 00:35:42,880
result actually in a great deal of

1061
00:35:41,200 --> 00:35:45,280
generality. it it's sort of for

1062
00:35:42,880 --> 00:35:48,320
arbitrary dependent observations. This

1063
00:35:45,280 --> 00:35:50,200
is true and the the trick involves first

1064
00:35:48,320 --> 00:35:52,480
applying a random permutation to the

1065
00:35:50,200 --> 00:35:54,839
data which converts your arbitrary

1066
00:35:52,480 --> 00:35:57,200
dependent observations into exchangeable

1067
00:35:54,839 --> 00:35:59,839
observations. And what's key is that if

1068
00:35:57,200 --> 00:36:02,160
if the you're under the fiser null, the

1069
00:35:59,839 --> 00:36:04,280
fisher null can be restated as treatment

1070
00:36:02,160 --> 00:36:06,640
is independent of the data

1071
00:36:04,280 --> 00:36:08,320
generation. And so if that's the case

1072
00:36:06,640 --> 00:36:10,079
and you apply this random permutation,

1073
00:36:08,320 --> 00:36:11,000
you haven't changed the distribution of

1074
00:36:10,079 --> 00:36:13,280
the test

1075
00:36:11,000 --> 00:36:14,880
statistics. So effectively I can assume

1076
00:36:13,280 --> 00:36:17,119
without loss of generality that my data

1077
00:36:14,880 --> 00:36:19,680
is exchangeable. And once I do that,

1078
00:36:17,119 --> 00:36:22,079
Namon has this paper from 1923 where he

1079
00:36:19,680 --> 00:36:24,560
proves a variance decomposition under an

1080
00:36:22,079 --> 00:36:26,480
assumption of constant causal effect or

1081
00:36:24,560 --> 00:36:29,040
constant treatment effect uh at the unit

1082
00:36:26,480 --> 00:36:31,520
level. And we can use kind of a variant

1083
00:36:29,040 --> 00:36:33,599
of that algebra, elementary algebra to

1084
00:36:31,520 --> 00:36:36,400
basically get this unbiasedness of the

1085
00:36:33,599 --> 00:36:38,079
variance estimator. So it's like is it

1086
00:36:36,400 --> 00:36:39,680
we looked for a while to see if this

1087
00:36:38,079 --> 00:36:41,119
exact result was in the literature and

1088
00:36:39,680 --> 00:36:42,880
the best of what we could tell it's not

1089
00:36:41,119 --> 00:36:45,920
there yet because it again it combines

1090
00:36:42,880 --> 00:36:47,839
kind of two odd sets of ideas together.

1091
00:36:45,920 --> 00:36:50,400
Usually this exchangeability arises in

1092
00:36:47,839 --> 00:36:52,880
the context of permutation testing or

1093
00:36:50,400 --> 00:36:54,560
randomization inference and you know

1094
00:36:52,880 --> 00:36:56,880
non's sort of variance decomposition

1095
00:36:54,560 --> 00:36:58,720
shows up in sort of different places. Um

1096
00:36:56,880 --> 00:37:00,640
so anyway, I'd love to hear from anyone

1097
00:36:58,720 --> 00:37:02,240
if you've got references to sort of

1098
00:37:00,640 --> 00:37:03,680
related things that we should look at.

1099
00:37:02,240 --> 00:37:05,200
Um but that that's kind of the key

1100
00:37:03,680 --> 00:37:06,800
output is the variance estimator is

1101
00:37:05,200 --> 00:37:08,079
unbiased. Now variance estimator is

1102
00:37:06,800 --> 00:37:10,160
unbiased. The difference in means

1103
00:37:08,079 --> 00:37:11,599
estimator is unbiased. One should expect

1104
00:37:10,160 --> 00:37:13,200
that in fact like false positive

1105
00:37:11,599 --> 00:37:15,200
probability behaves well and indeed

1106
00:37:13,200 --> 00:37:17,280
that's exactly what happens. This I

1107
00:37:15,200 --> 00:37:19,599
won't belabor but basically we show that

1108
00:37:17,280 --> 00:37:21,599
asmtoically um the test statistic is

1109
00:37:19,599 --> 00:37:22,720
normal under the null. And this is

1110
00:37:21,599 --> 00:37:25,040
really nice because one of the things

1111
00:37:22,720 --> 00:37:27,200
it's telling you is that you you you

1112
00:37:25,040 --> 00:37:29,280
don't have to worry about the inflation

1113
00:37:27,200 --> 00:37:31,040
of false positive probability. So the

1114
00:37:29,280 --> 00:37:32,480
intuition we got from the toy example at

1115
00:37:31,040 --> 00:37:34,400
the beginning now we should be leaning

1116
00:37:32,480 --> 00:37:35,440
into more because if false positive

1117
00:37:34,400 --> 00:37:36,760
probability is controlled and I'm

1118
00:37:35,440 --> 00:37:38,640
telling you the treatment effect is

1119
00:37:36,760 --> 00:37:40,079
overestimated. I'm feeling pretty good

1120
00:37:38,640 --> 00:37:41,440
about myself and the only thing that

1121
00:37:40,079 --> 00:37:44,000
could break things now is if the

1122
00:37:41,440 --> 00:37:47,119
variance is poor and so we'll talk about

1123
00:37:44,000 --> 00:37:48,320
that. Um just one note here. One thing

1124
00:37:47,119 --> 00:37:52,960
again that I couldn't find in the

1125
00:37:48,320 --> 00:37:54,240
literature is that um there's sort of an

1126
00:37:52,960 --> 00:37:56,320
interesting thing going on here is that

1127
00:37:54,240 --> 00:37:57,839
we have marovian data and we're

1128
00:37:56,320 --> 00:37:59,599
analyzing a central limit theorem for

1129
00:37:57,839 --> 00:38:02,160
the difference in means estimator and I

1130
00:37:59,599 --> 00:38:03,440
couldn't find that result either because

1131
00:38:02,160 --> 00:38:05,200
central limit theorem for the difference

1132
00:38:03,440 --> 00:38:06,640
in means estimator. It was interesting

1133
00:38:05,200 --> 00:38:08,160
talking to Stefan actually. He just

1134
00:38:06,640 --> 00:38:10,800
finished a very nice causal inference

1135
00:38:08,160 --> 00:38:12,560
book, Stfan Wagger. And in the beginning

1136
00:38:10,800 --> 00:38:13,839
of that book, there's a proof of the CLT

1137
00:38:12,560 --> 00:38:16,640
for the difference in means estimator

1138
00:38:13,839 --> 00:38:18,880
under IID data. But even he had trouble

1139
00:38:16,640 --> 00:38:20,800
finding that proof, you know, in it's

1140
00:38:18,880 --> 00:38:22,880
not the proof isn't hard. It uses

1141
00:38:20,800 --> 00:38:24,160
elementary techniques, but it's just

1142
00:38:22,880 --> 00:38:25,680
surprising. I think some of these like

1143
00:38:24,160 --> 00:38:27,520
basic instruments are things that are

1144
00:38:25,680 --> 00:38:29,119
not available in textbook form, which is

1145
00:38:27,520 --> 00:38:30,640
mostly an ad that Stfan's causal

1146
00:38:29,119 --> 00:38:32,000
inference book is amazing. So you should

1147
00:38:30,640 --> 00:38:34,720
definitely look at that if you haven't

1148
00:38:32,000 --> 00:38:36,079
already. All right. So okay so that's

1149
00:38:34,720 --> 00:38:37,920
false positive probability we talk about

1150
00:38:36,079 --> 00:38:39,599
power. Now I've kind of already given

1151
00:38:37,920 --> 00:38:41,200
you a hint of this type of result that

1152
00:38:39,599 --> 00:38:43,040
the treatment effect is overestimated

1153
00:38:41,200 --> 00:38:44,880
when we have and and the generalization

1154
00:38:43,040 --> 00:38:46,800
of the toy example at the beginning is

1155
00:38:44,880 --> 00:38:48,240
under monotone treatment. So if the

1156
00:38:46,800 --> 00:38:50,640
treatment's monotone in this way I

1157
00:38:48,240 --> 00:38:52,960
described then you you indeed get this

1158
00:38:50,640 --> 00:38:55,119
result that the that the uh treatment

1159
00:38:52,960 --> 00:38:59,280
effect is upward biased the estimate is

1160
00:38:55,119 --> 00:39:00,800
upward biased. Um uh one thing I guess

1161
00:38:59,280 --> 00:39:03,200
that I'll just say here is that that

1162
00:39:00,800 --> 00:39:05,200
type of result there's some similar

1163
00:39:03,200 --> 00:39:06,880
things in meanfield settings. What's

1164
00:39:05,200 --> 00:39:08,560
nice for us is that we can use that same

1165
00:39:06,880 --> 00:39:11,599
stocastic monotonicity to prove this in

1166
00:39:08,560 --> 00:39:14,079
finite samples that finite sample bias.

1167
00:39:11,599 --> 00:39:15,599
Um and exactly for the intuitive reason

1168
00:39:14,079 --> 00:39:16,800
that I described treatment is

1169
00:39:15,599 --> 00:39:18,960
overestimated and control is

1170
00:39:16,800 --> 00:39:20,160
underestimated. I'm glossing over some

1171
00:39:18,960 --> 00:39:22,160
things that I think are important

1172
00:39:20,160 --> 00:39:23,760
technically but not in the talk which is

1173
00:39:22,160 --> 00:39:25,680
it matters what the initial distribution

1174
00:39:23,760 --> 00:39:26,880
is for example. So you have to

1175
00:39:25,680 --> 00:39:29,280
initialize if you think about the

1176
00:39:26,880 --> 00:39:31,040
distributions as living in this lattice

1177
00:39:29,280 --> 00:39:32,960
of determined by first order stochcastic

1178
00:39:31,040 --> 00:39:34,400
dominance you have to initialize it a

1179
00:39:32,960 --> 00:39:35,960
distribution that's between the

1180
00:39:34,400 --> 00:39:38,240
treatment and control steadyst state

1181
00:39:35,960 --> 00:39:40,240
distributions. Uh so you can't you can't

1182
00:39:38,240 --> 00:39:42,480
sort of arbitrarily uh prove such a

1183
00:39:40,240 --> 00:39:44,000
thing but you know we thought for the

1184
00:39:42,480 --> 00:39:45,839
paper I think what we put in is an

1185
00:39:44,000 --> 00:39:48,000
assumption that the initial distribution

1186
00:39:45,839 --> 00:39:49,520
is the control steady state distribution

1187
00:39:48,000 --> 00:39:50,960
sort of imagining you you know start

1188
00:39:49,520 --> 00:39:54,160
from control and run the experiment or

1189
00:39:50,960 --> 00:39:56,640
something. Okay, so that leaves just the

1190
00:39:54,160 --> 00:39:59,359
variance. And so what I've shown you so

1191
00:39:56,640 --> 00:40:01,280
far is that the treatment effect is

1192
00:39:59,359 --> 00:40:03,359
being overestimated. Now, overestimated

1193
00:40:01,280 --> 00:40:04,880
relative to what? Relative to the truth.

1194
00:40:03,359 --> 00:40:07,760
So one way to think about that is if I

1195
00:40:04,880 --> 00:40:09,920
had an unbiased estimator, then the

1196
00:40:07,760 --> 00:40:11,839
numerator of a test statistic using the

1197
00:40:09,920 --> 00:40:13,839
difference in means estimator is larger

1198
00:40:11,839 --> 00:40:16,640
on average than the numerator of an

1199
00:40:13,839 --> 00:40:19,119
unbiased estimator. Okay, so that's sort

1200
00:40:16,640 --> 00:40:21,280
of that first statement. Now I've got

1201
00:40:19,119 --> 00:40:23,599
the variance is this naive variance

1202
00:40:21,280 --> 00:40:25,440
estimator that I wrote down. What

1203
00:40:23,599 --> 00:40:27,359
variance do I want to compare against if

1204
00:40:25,440 --> 00:40:29,040
I want to look at an unbiased estimation

1205
00:40:27,359 --> 00:40:30,280
strategy? Well, one thing we imagine is

1206
00:40:29,040 --> 00:40:32,720
like suppose the decision maker

1207
00:40:30,280 --> 00:40:35,280
alternatively had access to an unbiased

1208
00:40:32,720 --> 00:40:37,920
estimator and had access to the correct

1209
00:40:35,280 --> 00:40:40,720
variance for that unbiased estimator.

1210
00:40:37,920 --> 00:40:42,160
Okay. So then you know what what we

1211
00:40:40,720 --> 00:40:45,160
imagine then is they could form a

1212
00:40:42,160 --> 00:40:48,320
different test statistic and use that

1213
00:40:45,160 --> 00:40:50,960
instead. And you know I think for us

1214
00:40:48,320 --> 00:40:52,320
sort of like all signs were pointing in

1215
00:40:50,960 --> 00:40:54,400
the direction this has to be terrible

1216
00:40:52,320 --> 00:40:57,119
and indeed it is. And the question was

1217
00:40:54,400 --> 00:40:59,280
just how do you get there and that was

1218
00:40:57,119 --> 00:41:01,839
when um we came across this paper by

1219
00:40:59,280 --> 00:41:03,200
Vive uh the first paper and in that

1220
00:41:01,839 --> 00:41:05,680
paper one of the things they do is they

1221
00:41:03,200 --> 00:41:08,000
prove a chrome lower bound which is

1222
00:41:05,680 --> 00:41:11,040
actually interesting to me. Um I had a

1223
00:41:08,000 --> 00:41:14,079
paper from from uh Nerfs a couple years

1224
00:41:11,040 --> 00:41:15,920
before that that had a nonparametric

1225
00:41:14,079 --> 00:41:19,760
maximum likelihood estimator for Marov

1226
00:41:15,920 --> 00:41:21,839
chain um experiments that actually

1227
00:41:19,760 --> 00:41:23,440
exactly matches the career lower bound

1228
00:41:21,839 --> 00:41:26,800
which makes sense like that we you know

1229
00:41:23,440 --> 00:41:29,640
that that should have been the career uh

1230
00:41:26,800 --> 00:41:32,079
sort of variance um achieving

1231
00:41:29,640 --> 00:41:34,640
estimator. Um so what they do is they

1232
00:41:32,079 --> 00:41:37,680
basically say okay you know in the worst

1233
00:41:34,640 --> 00:41:40,040
case like we can construct an example of

1234
00:41:37,680 --> 00:41:42,160
a birth death chain where unbiased

1235
00:41:40,040 --> 00:41:44,640
estimation has the property that the

1236
00:41:42,160 --> 00:41:46,400
variance will blow up exponentially in

1237
00:41:44,640 --> 00:41:47,839
the size of the state space. So if you

1238
00:41:46,400 --> 00:41:50,079
look they essentially construct a

1239
00:41:47,839 --> 00:41:51,359
sequence of birth death chains which

1240
00:41:50,079 --> 00:41:53,599
have the property that if you had an

1241
00:41:51,359 --> 00:41:55,119
unbiased estimator then the variance of

1242
00:41:53,599 --> 00:41:56,560
that estimator is going to blow up

1243
00:41:55,119 --> 00:41:59,200
exponentially in the size of the state

1244
00:41:56,560 --> 00:42:02,160
space. But their system is sort of

1245
00:41:59,200 --> 00:42:04,160
tailorade to get that behavior. And

1246
00:42:02,160 --> 00:42:05,920
unfortunately, one of the things that

1247
00:42:04,160 --> 00:42:08,560
one needs to note is that there also

1248
00:42:05,920 --> 00:42:09,839
exist examples of systems with larger

1249
00:42:08,560 --> 00:42:12,560
and larger state space where that

1250
00:42:09,839 --> 00:42:13,920
doesn't happen. And so for us, like what

1251
00:42:12,560 --> 00:42:17,200
we wanted to show is that that's a

1252
00:42:13,920 --> 00:42:19,119
generic phenomenon. And so what we do in

1253
00:42:17,200 --> 00:42:21,760
the paper is that we consider any

1254
00:42:19,119 --> 00:42:23,599
sequence of moni of you know systems

1255
00:42:21,760 --> 00:42:27,760
essentially pairs of control and

1256
00:42:23,599 --> 00:42:30,079
treatment systems with um the the sort

1257
00:42:27,760 --> 00:42:31,760
of systems approaching a mean-filled

1258
00:42:30,079 --> 00:42:34,240
limit as the size of the state space

1259
00:42:31,760 --> 00:42:35,520
goes to infinity. What do I mean by mean

1260
00:42:34,240 --> 00:42:37,599
limit? Informally, the way you could

1261
00:42:35,520 --> 00:42:38,800
think about this is that if I have the

1262
00:42:37,599 --> 00:42:41,280
size of the state space going to

1263
00:42:38,800 --> 00:42:44,240
infinity, then what I'm asking is that

1264
00:42:41,280 --> 00:42:46,960
the booking probability curves and the

1265
00:42:44,240 --> 00:42:48,640
the the death rate curves approach an

1266
00:42:46,960 --> 00:42:51,000
appropriate limit approach functional

1267
00:42:48,640 --> 00:42:53,040
limits as as the state space grows to

1268
00:42:51,000 --> 00:42:54,800
infinity. So that seemed like a pretty

1269
00:42:53,040 --> 00:42:56,000
benign assumption and and from our

1270
00:42:54,800 --> 00:42:58,400
perspective that feels like a pretty

1271
00:42:56,000 --> 00:43:00,800
generic result that the exponential

1272
00:42:58,400 --> 00:43:02,800
growth of the variance is unavoidable. I

1273
00:43:00,800 --> 00:43:05,119
also want to say like that exponential

1274
00:43:02,800 --> 00:43:07,119
growth and and by the way by as it's not

1275
00:43:05,119 --> 00:43:09,119
hard to see this but because the booking

1276
00:43:07,119 --> 00:43:10,480
outcomes are binary the naive variance

1277
00:43:09,119 --> 00:43:12,960
estimator is clearly bounded by a

1278
00:43:10,480 --> 00:43:14,800
constant and so you have this like

1279
00:43:12,960 --> 00:43:17,200
exponential gap in the variance and the

1280
00:43:14,800 --> 00:43:19,040
numerator is overestimated so one would

1281
00:43:17,200 --> 00:43:20,880
expect yes that like your power is much

1282
00:43:19,040 --> 00:43:23,680
better using the naive strategy over any

1283
00:43:20,880 --> 00:43:25,119
unbiased strategy. Um so let me just

1284
00:43:23,680 --> 00:43:26,640
first show you this is like one curve

1285
00:43:25,119 --> 00:43:28,240
I'm actually not going to spend a lot of

1286
00:43:26,640 --> 00:43:30,560
time on this graph. This is one example

1287
00:43:28,240 --> 00:43:32,560
of like particular parameters where the

1288
00:43:30,560 --> 00:43:34,400
power the power this is the log of the

1289
00:43:32,560 --> 00:43:36,319
false negative probability. So false

1290
00:43:34,400 --> 00:43:38,640
negative probability is one minus power.

1291
00:43:36,319 --> 00:43:40,160
So you want this to be small and you can

1292
00:43:38,640 --> 00:43:41,839
see like the gap is enormous already

1293
00:43:40,160 --> 00:43:44,079
even in this example at like k equals

1294
00:43:41,839 --> 00:43:46,880
70. Now our treatment effect here was

1295
00:43:44,079 --> 00:43:49,520
like 0.02 in the booking probability. I

1296
00:43:46,880 --> 00:43:51,760
I think putting all that aside, it it's

1297
00:43:49,520 --> 00:43:53,119
an extreme result like this exponential

1298
00:43:51,760 --> 00:43:57,040
growth with the size of the state space

1299
00:43:53,119 --> 00:43:58,400
says it's just sort of so good it almost

1300
00:43:57,040 --> 00:43:59,680
wouldn't have mattered actually if you

1301
00:43:58,400 --> 00:44:01,839
were overestimating the treatment

1302
00:43:59,680 --> 00:44:03,760
effect. So I want to be clear what the

1303
00:44:01,839 --> 00:44:05,839
main takeaway is here. The main thing

1304
00:44:03,760 --> 00:44:07,760
we're trying to say is that relative to

1305
00:44:05,839 --> 00:44:09,680
being unbiased, you're overestimating

1306
00:44:07,760 --> 00:44:10,599
the numerator and you have a massive gap

1307
00:44:09,680 --> 00:44:13,839
in the

1308
00:44:10,599 --> 00:44:15,440
denominator in your favor. That's

1309
00:44:13,839 --> 00:44:17,839
probably not what you would do if you

1310
00:44:15,440 --> 00:44:20,119
were debiasing. If you were debiasing,

1311
00:44:17,839 --> 00:44:23,200
what you would try to do is remove some

1312
00:44:20,119 --> 00:44:24,920
bias, but like most things you would do

1313
00:44:23,200 --> 00:44:27,040
that do that will introduce some

1314
00:44:24,920 --> 00:44:29,119
variance. And so like one example of

1315
00:44:27,040 --> 00:44:30,560
this is the DQ estimator from Vake.

1316
00:44:29,119 --> 00:44:33,200
That's a much more plausible thing to do

1317
00:44:30,560 --> 00:44:34,720
than to be fully unbiased. And that has

1318
00:44:33,200 --> 00:44:36,319
a pretty favorable bias variance

1319
00:44:34,720 --> 00:44:38,480
behavior relatively speaking if your

1320
00:44:36,319 --> 00:44:41,280
interest really was in debiasing. But

1321
00:44:38,480 --> 00:44:43,839
even that has the property that you know

1322
00:44:41,280 --> 00:44:46,480
the naive variance estim the naive uh uh

1323
00:44:43,839 --> 00:44:48,960
treatment effect estimate will be larger

1324
00:44:46,480 --> 00:44:51,280
and the variance will be smaller. Right?

1325
00:44:48,960 --> 00:44:52,880
So sort of like I think what I'm trying

1326
00:44:51,280 --> 00:44:54,960
to say is this is the most extreme case

1327
00:44:52,880 --> 00:44:56,319
of the bias variance trade-off and both

1328
00:44:54,960 --> 00:44:58,240
the numerator and denominator are

1329
00:44:56,319 --> 00:45:00,319
working in your favor if you're using

1330
00:44:58,240 --> 00:45:03,040
the naive sort of test statistic in

1331
00:45:00,319 --> 00:45:04,400
increasing your power. Right? So what

1332
00:45:03,040 --> 00:45:06,720
are the takeaways? Like if the

1333
00:45:04,400 --> 00:45:08,800
treatments are monotone and the decision

1334
00:45:06,720 --> 00:45:10,640
maker uses a naive test, your false

1335
00:45:08,800 --> 00:45:12,640
positive pro probability is controlled

1336
00:45:10,640 --> 00:45:14,160
correctly and your statistical power is

1337
00:45:12,640 --> 00:45:16,400
like much higher than it would be with

1338
00:45:14,160 --> 00:45:17,599
any unbiased approach. So this is what I

1339
00:45:16,400 --> 00:45:19,040
meant at the beginning of the talk when

1340
00:45:17,599 --> 00:45:21,760
I said you're strictly better off not

1341
00:45:19,040 --> 00:45:23,280
debiasing. Just to drive home again,

1342
00:45:21,760 --> 00:45:25,040
reducing bias tends to increase

1343
00:45:23,280 --> 00:45:27,040
variance. Not always. It's a bias

1344
00:45:25,040 --> 00:45:29,680
variance decomposition, not a trade-off.

1345
00:45:27,040 --> 00:45:31,280
So you know, maybe you do something that

1346
00:45:29,680 --> 00:45:33,119
actually gets you both. But in general,

1347
00:45:31,280 --> 00:45:35,359
this would be the case for most of the

1348
00:45:33,119 --> 00:45:37,119
proposals in the literature. And so most

1349
00:45:35,359 --> 00:45:38,480
lowbias estimators probably still are

1350
00:45:37,119 --> 00:45:40,240
going to fall on the wrong side of this

1351
00:45:38,480 --> 00:45:41,920
boundary. So I don't think that my point

1352
00:45:40,240 --> 00:45:43,520
is I don't think that's the right way to

1353
00:45:41,920 --> 00:45:45,119
think about how am I going to do better.

1354
00:45:43,520 --> 00:45:47,359
Like somehow I'm going to evade this by

1355
00:45:45,119 --> 00:45:49,280
coming up with a slightly lower bias

1356
00:45:47,359 --> 00:45:50,720
estimator that actually gives me good

1357
00:45:49,280 --> 00:45:51,760
enough variance and I'm better off. I

1358
00:45:50,720 --> 00:45:53,079
don't think that's the right way. I

1359
00:45:51,760 --> 00:45:55,000
think the right way is to focus on

1360
00:45:53,079 --> 00:45:57,839
monotonicity. Like what's the role of

1361
00:45:55,000 --> 00:45:59,760
monotonicity? Okay. And here it's

1362
00:45:57,839 --> 00:46:01,520
important to know that if you get

1363
00:45:59,760 --> 00:46:02,760
outside the monotone world things can be

1364
00:46:01,520 --> 00:46:06,000
arbitrarily

1365
00:46:02,760 --> 00:46:07,440
bad. Okay. So in particular think and

1366
00:46:06,000 --> 00:46:09,599
and getting outside the monotone world

1367
00:46:07,440 --> 00:46:12,319
is also not that hard because you could

1368
00:46:09,599 --> 00:46:14,480
imagine something like I choose to do

1369
00:46:12,319 --> 00:46:16,319
this like price intervention where

1370
00:46:14,480 --> 00:46:18,880
whether I raise or lower prices depends

1371
00:46:16,319 --> 00:46:20,079
on how much inventory is available. So

1372
00:46:18,880 --> 00:46:21,440
maybe when there's not a lot of

1373
00:46:20,079 --> 00:46:23,040
inventory available I'm going to raise

1374
00:46:21,440 --> 00:46:24,960
prices. When there's a lot available

1375
00:46:23,040 --> 00:46:27,760
I'll lower prices. Now that's clearly

1376
00:46:24,960 --> 00:46:29,200
state dependent. And using interventions

1377
00:46:27,760 --> 00:46:31,520
like that in the paper, we show that the

1378
00:46:29,200 --> 00:46:34,480
absolute worst case. In fact, there are

1379
00:46:31,520 --> 00:46:36,000
treatments where the true GTE is zero,

1380
00:46:34,480 --> 00:46:38,560
but your false positive probability

1381
00:46:36,000 --> 00:46:40,079
approach is one. And that's basically

1382
00:46:38,560 --> 00:46:42,319
because of the bias and the difference

1383
00:46:40,079 --> 00:46:44,640
in means estimator. There's also

1384
00:46:42,319 --> 00:46:46,960
treatments where the true GT is non

1385
00:46:44,640 --> 00:46:49,119
zero, but your false positive your

1386
00:46:46,960 --> 00:46:51,280
power, sorry, stays very low. And that's

1387
00:46:49,119 --> 00:46:53,839
because essentially because your naive

1388
00:46:51,280 --> 00:46:55,760
estimator maintains a GTE that's an

1389
00:46:53,839 --> 00:46:58,079
estimate that's around zero. So your

1390
00:46:55,760 --> 00:47:00,160
power never really grows. Okay. So

1391
00:46:58,079 --> 00:47:02,319
things can be arbitrarily bad which

1392
00:47:00,160 --> 00:47:04,160
obviously prompts the question sort of

1393
00:47:02,319 --> 00:47:05,440
how state dependent is my treatment. And

1394
00:47:04,160 --> 00:47:07,599
that's the sense in which I was saying

1395
00:47:05,440 --> 00:47:09,680
earlier. I think a key takeaway from the

1396
00:47:07,599 --> 00:47:11,359
work for me is you know as you're

1397
00:47:09,680 --> 00:47:13,119
thinking as as a platform thinks about

1398
00:47:11,359 --> 00:47:14,560
the value of debiasing. A lot of that

1399
00:47:13,119 --> 00:47:17,040
comes down to the extent to which you

1400
00:47:14,560 --> 00:47:18,720
think this type of state dependence is

1401
00:47:17,040 --> 00:47:20,480
really a primary driver of of the

1402
00:47:18,720 --> 00:47:22,640
treatment effect. and that that's sort

1403
00:47:20,480 --> 00:47:24,480
of that would be at least one reason

1404
00:47:22,640 --> 00:47:27,119
that the takeaways in this talk are not

1405
00:47:24,480 --> 00:47:28,440
the right ones for for a platform. A

1406
00:47:27,119 --> 00:47:30,480
couple of quick comments on

1407
00:47:28,440 --> 00:47:32,040
modifications. Um I won't say a lot

1408
00:47:30,480 --> 00:47:33,760
about this. If listings are

1409
00:47:32,040 --> 00:47:35,359
heterogeneous, the stochcastic

1410
00:47:33,760 --> 00:47:38,079
monotonicity properties of birth death

1411
00:47:35,359 --> 00:47:39,599
chains no longer apply. So you need and

1412
00:47:38,079 --> 00:47:41,040
and basically the issue there is that

1413
00:47:39,599 --> 00:47:42,720
you need some substitution pattern

1414
00:47:41,040 --> 00:47:44,240
across different types of listings. In

1415
00:47:42,720 --> 00:47:46,640
that case you have a multi-dimensional

1416
00:47:44,240 --> 00:47:54,480
queuing system. And so for that you know

1417
00:47:46,640 --> 00:47:56,640
we um we uh um um sort of rely on a

1418
00:47:54,480 --> 00:47:59,280
multinnomial loit choice model that we

1419
00:47:56,640 --> 00:48:00,960
introduced in an earlier paper in 22 and

1420
00:47:59,280 --> 00:48:03,440
look at appropriate def definition of

1421
00:48:00,960 --> 00:48:05,200
monotonicity and the meanfield limit um

1422
00:48:03,440 --> 00:48:06,640
then sort of we're able to get some

1423
00:48:05,200 --> 00:48:08,319
related results to what I've already

1424
00:48:06,640 --> 00:48:09,760
shown you in the talk in that setting.

1425
00:48:08,319 --> 00:48:12,480
And so our conjecture is that we end up

1426
00:48:09,760 --> 00:48:13,920
with sort of a similar power result and

1427
00:48:12,480 --> 00:48:15,200
we're able to show that one does

1428
00:48:13,920 --> 00:48:18,000
actually have correct control of false

1429
00:48:15,200 --> 00:48:19,599
positive probability in that setting. Um

1430
00:48:18,000 --> 00:48:21,040
this is a simulation that kind of

1431
00:48:19,599 --> 00:48:23,760
demonstrates similar behavior in that

1432
00:48:21,040 --> 00:48:26,440
setting. Um another interesting thing is

1433
00:48:23,760 --> 00:48:29,280
that uh we can accommodate some types of

1434
00:48:26,440 --> 00:48:31,839
non-stationerity and that's because the

1435
00:48:29,280 --> 00:48:34,640
stoastic monity of a birth death chain

1436
00:48:31,839 --> 00:48:36,480
holds at every time point. So the birth

1437
00:48:34,640 --> 00:48:39,599
death chain itself could have some

1438
00:48:36,480 --> 00:48:40,920
variation in the parameters over time

1439
00:48:39,599 --> 00:48:43,520
but you still have stochastic

1440
00:48:40,920 --> 00:48:44,800
monotonicity. So there's like an easy

1441
00:48:43,520 --> 00:48:47,839
ability to incorporate some

1442
00:48:44,800 --> 00:48:49,040
non-stationerity into the result. Um but

1443
00:48:47,839 --> 00:48:51,760
you have to be careful about what the

1444
00:48:49,040 --> 00:48:53,680
estim is there. So the estim of interest

1445
00:48:51,760 --> 00:48:55,920
or of that that you can say something

1446
00:48:53,680 --> 00:48:58,280
about there is the insample estimate the

1447
00:48:55,920 --> 00:49:00,640
estimated during the time horizon of the

1448
00:48:58,280 --> 00:49:03,200
experiment. All right. And then finally

1449
00:49:00,640 --> 00:49:07,119
um what about other goals? So, you know,

1450
00:49:03,200 --> 00:49:09,599
I think it's clear that this isn't sort

1451
00:49:07,119 --> 00:49:11,319
of all that goes on in decision- making.

1452
00:49:09,599 --> 00:49:13,920
And I think like the two big things I'll

1453
00:49:11,319 --> 00:49:15,440
highlight. One of them is that often

1454
00:49:13,920 --> 00:49:16,720
when we're making a choice to launch or

1455
00:49:15,440 --> 00:49:18,160
not launch something, we're also

1456
00:49:16,720 --> 00:49:20,000
thinking implicitly about the cost of

1457
00:49:18,160 --> 00:49:21,359
that thing or maybe even explicitly,

1458
00:49:20,000 --> 00:49:23,280
which means then we really care about

1459
00:49:21,359 --> 00:49:24,400
the treatment effect estimate. then then

1460
00:49:23,280 --> 00:49:26,480
it's not the case that you're just

1461
00:49:24,400 --> 00:49:28,240
seeing is it different from zero because

1462
00:49:26,480 --> 00:49:29,359
if you're looking is it above C then you

1463
00:49:28,240 --> 00:49:31,119
know you've got to think about what

1464
00:49:29,359 --> 00:49:33,440
what's the cost what's the treatment

1465
00:49:31,119 --> 00:49:36,880
effect relative to the cost and then the

1466
00:49:33,440 --> 00:49:38,640
other one I think is that um uh you know

1467
00:49:36,880 --> 00:49:41,680
there are other metrics of interest

1468
00:49:38,640 --> 00:49:44,000
which don't obey this inflation effect

1469
00:49:41,680 --> 00:49:45,599
the one one that's I think primary in a

1470
00:49:44,000 --> 00:49:48,000
lot of work that we've done is thinking

1471
00:49:45,599 --> 00:49:51,520
about profit or revenue when you change

1472
00:49:48,000 --> 00:49:53,839
prices up demand moves down and uh

1473
00:49:51,520 --> 00:49:55,680
because of that effect. Um, it's

1474
00:49:53,839 --> 00:49:57,119
possible that you get the sign wrong

1475
00:49:55,680 --> 00:49:59,599
because of of the same kind of

1476
00:49:57,119 --> 00:50:01,119
interference phenomenon. And so when

1477
00:49:59,599 --> 00:50:03,680
you're getting the sign wrong now, you

1478
00:50:01,119 --> 00:50:05,359
can't rely on the same types of claims

1479
00:50:03,680 --> 00:50:07,040
I'm making in this talk. So I think

1480
00:50:05,359 --> 00:50:09,599
that's another case where the decision-m

1481
00:50:07,040 --> 00:50:10,880
framework has other issues, but it won't

1482
00:50:09,599 --> 00:50:12,119
fall in the class of what I've talked

1483
00:50:10,880 --> 00:50:14,880
about.

1484
00:50:12,119 --> 00:50:17,960
Um, so you know, I think to summarize

1485
00:50:14,880 --> 00:50:20,559
sort of our our takeaway is one that to

1486
00:50:17,960 --> 00:50:22,240
anyone who like takes the whole pipeline

1487
00:50:20,559 --> 00:50:24,880
view or the statistical decision theory

1488
00:50:22,240 --> 00:50:26,319
view of statistics isn't surprising,

1489
00:50:24,880 --> 00:50:28,160
which is that you should start by being

1490
00:50:26,319 --> 00:50:29,839
clear about what your goals are and then

1491
00:50:28,160 --> 00:50:31,200
use the goals and like the intervent

1492
00:50:29,839 --> 00:50:34,800
your knowledge of the intervention to

1493
00:50:31,200 --> 00:50:36,800
inform exactly what you do. And I I

1494
00:50:34,800 --> 00:50:38,720
think it is sort of useful at least to

1495
00:50:36,800 --> 00:50:40,960
sit back. Maybe one of the things for me

1496
00:50:38,720 --> 00:50:42,160
that came out of this was that blindly

1497
00:50:40,960 --> 00:50:44,000
thinking about correcting interference

1498
00:50:42,160 --> 00:50:45,440
is not the right thing. Like you really

1499
00:50:44,000 --> 00:50:48,240
want interference correction to be a

1500
00:50:45,440 --> 00:50:51,520
targeted methodological goal that

1501
00:50:48,240 --> 00:50:54,400
focuses on the the sort of nature of the

1502
00:50:51,520 --> 00:50:56,720
intervention and the desired sort of

1503
00:50:54,400 --> 00:50:58,079
decision-making goal to motivate why

1504
00:50:56,720 --> 00:50:59,520
you're doing that, right? And that

1505
00:50:58,079 --> 00:51:02,400
hasn't been something that I certainly

1506
00:50:59,520 --> 00:51:04,480
prioritized up until uh doing this work.

1507
00:51:02,400 --> 00:51:05,520
Um so hopefully kind of the takeaways

1508
00:51:04,480 --> 00:51:06,640
make sense. If there's any questions,

1509
00:51:05,520 --> 00:51:11,160
I'm happy to take them. I know it's

1510
00:51:06,640 --> 00:51:15,410
already five. Um, so let me stop there.

1511
00:51:11,160 --> 00:51:15,410
[Applause]


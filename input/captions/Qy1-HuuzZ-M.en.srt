1
00:00:00,399 --> 00:00:08,679
our next speaker Professor Rafael gas

2
00:00:05,600 --> 00:00:11,080
Bomar I hope the pronounce is right uh

3
00:00:08,679 --> 00:00:12,920
who is a associate professor in MIT

4
00:00:11,080 --> 00:00:16,080
Department of Material Science and

5
00:00:12,920 --> 00:00:20,400
Engineering he's interested in fing

6
00:00:16,080 --> 00:00:23,119
machine learning and atom atomistic

7
00:00:20,400 --> 00:00:26,039
simulations for Designing materials and

8
00:00:23,119 --> 00:00:28,679
their transformation now let's welcome

9
00:00:26,039 --> 00:00:31,960
Rafael thank

10
00:00:28,679 --> 00:00:31,960
you yes

11
00:00:34,760 --> 00:00:39,200
yeah5 they're running this like

12
00:00:36,480 --> 00:00:42,360
clockwork and thanks so much for for

13
00:00:39,200 --> 00:00:46,480
coming uh I go by Rafa like the like a

14
00:00:42,360 --> 00:00:48,680
tennis player and um uh like like it was

15
00:00:46,480 --> 00:00:50,600
said at the at the introduction uh my

16
00:00:48,680 --> 00:00:53,520
work groups at the sort of interface of

17
00:00:50,600 --> 00:00:56,760
AI and and first principles um and the

18
00:00:53,520 --> 00:00:59,320
reason why this is important is because

19
00:00:56,760 --> 00:01:01,399
it takes about 20 years for a material

20
00:00:59,320 --> 00:01:02,920
to make it to Market from the time

21
00:01:01,399 --> 00:01:05,439
somebody has an idea at the lab it's

22
00:01:02,920 --> 00:01:09,240
like oh this gooey substance could be

23
00:01:05,439 --> 00:01:11,280
good for um uh for posted notes until

24
00:01:09,240 --> 00:01:13,840
something is actually produced at scale

25
00:01:11,280 --> 00:01:16,840
in the market it the typical number that

26
00:01:13,840 --> 00:01:21,360
people use is 20 years um and for our

27
00:01:16,840 --> 00:01:23,640
net Z objectives in 2050 we pretty much

28
00:01:21,360 --> 00:01:26,560
have five six more years to invent the

29
00:01:23,640 --> 00:01:28,439
technologies that will scale up by the

30
00:01:26,560 --> 00:01:30,720
time we need a net zero we've determined

31
00:01:28,439 --> 00:01:34,000
that we will be at a net zero economy

32
00:01:30,720 --> 00:01:36,920
um and a lot of the problems and the

33
00:01:34,000 --> 00:01:39,040
solutions around the energy and

34
00:01:36,920 --> 00:01:40,840
sustainability go around materials

35
00:01:39,040 --> 00:01:44,799
Innovations there is obviously going to

36
00:01:40,840 --> 00:01:46,280
be you know Arbitrage about uh buying

37
00:01:44,799 --> 00:01:47,600
electricity today and selling it

38
00:01:46,280 --> 00:01:49,439
tomorrow there there are Technical

39
00:01:47,600 --> 00:01:51,560
Solutions that are not just about

40
00:01:49,439 --> 00:01:53,880
materials but materials are going to be

41
00:01:51,560 --> 00:01:55,479
critical obviously for energy storage

42
00:01:53,880 --> 00:01:58,799
and batteries right lithium ion

43
00:01:55,479 --> 00:02:00,799
batteries do not really scale to a great

44
00:01:58,799 --> 00:02:02,600
scale or it's going to be challenging to

45
00:02:00,799 --> 00:02:04,200
store all the electricity that we need

46
00:02:02,600 --> 00:02:07,159
in lithium ion batteries the way they

47
00:02:04,200 --> 00:02:08,959
look right now energy energy conversion

48
00:02:07,159 --> 00:02:10,800
right we want more solar can we make

49
00:02:08,959 --> 00:02:14,080
solar that is not as expensive as

50
00:02:10,800 --> 00:02:15,720
silicon um can we make better polymers

51
00:02:14,080 --> 00:02:18,440
for windmill blades so I don't know if

52
00:02:15,720 --> 00:02:20,879
you follow this but the offshore

53
00:02:18,440 --> 00:02:22,519
windmills have been complicated because

54
00:02:20,879 --> 00:02:25,319
the materials are not as tough as they

55
00:02:22,519 --> 00:02:26,879
could be can we make cheaper magnets for

56
00:02:25,319 --> 00:02:30,080
these windmills right so it's all these

57
00:02:26,879 --> 00:02:32,360
questions that are intimately tied uh TI

58
00:02:30,080 --> 00:02:33,959
to to materials Innovations Plastics

59
00:02:32,360 --> 00:02:36,560
what do we do with with plastics right

60
00:02:33,959 --> 00:02:39,200
we make a 100 million tons of

61
00:02:36,560 --> 00:02:40,800
polyethylene every year um well the

62
00:02:39,200 --> 00:02:42,120
solution through that has to go through

63
00:02:40,800 --> 00:02:45,120
materials

64
00:02:42,120 --> 00:02:49,000
Innovations in parallel to the sort of

65
00:02:45,120 --> 00:02:51,640
urgent needs we've seen a class of

66
00:02:49,000 --> 00:02:53,920
Technology explode over the last decade

67
00:02:51,640 --> 00:02:55,480
or over the last five years right things

68
00:02:53,920 --> 00:02:58,680
that used to

69
00:02:55,480 --> 00:03:00,680
be exclusive to humans and really really

70
00:02:58,680 --> 00:03:02,440
hard turn out to be not that hard

71
00:03:00,680 --> 00:03:05,599
anymore right it's been over almost a

72
00:03:02,440 --> 00:03:07,200
decade since Alpha ago when you know

73
00:03:05,599 --> 00:03:09,640
this game that was supposed to be

74
00:03:07,200 --> 00:03:11,720
combinatorially much harder than chess

75
00:03:09,640 --> 00:03:14,480
and and intractable for computers for a

76
00:03:11,720 --> 00:03:16,120
100 years turned out to be solvable with

77
00:03:14,480 --> 00:03:17,760
a new class of Technology right with

78
00:03:16,120 --> 00:03:20,000
deep learning or machine learning in

79
00:03:17,760 --> 00:03:22,760
general and we've seen this apply to a

80
00:03:20,000 --> 00:03:26,720
number of of places right we've seen um

81
00:03:22,760 --> 00:03:29,040
like I said the sort of rule based games

82
00:03:26,720 --> 00:03:31,200
solved with reinforcement learning maybe

83
00:03:29,040 --> 00:03:32,959
7 years ago we've obviously seen all the

84
00:03:31,200 --> 00:03:35,560
Winds of Machine Vision if you got a

85
00:03:32,959 --> 00:03:37,640
nest camera right tells you the postman

86
00:03:35,560 --> 00:03:39,159
the post person showed up with a package

87
00:03:37,640 --> 00:03:41,360
that's all Machine Vision and that

88
00:03:39,159 --> 00:03:43,959
technology has been sort of part of our

89
00:03:41,360 --> 00:03:46,239
lives for now maybe five years and then

90
00:03:43,959 --> 00:03:50,120
over the last two or three llms right

91
00:03:46,239 --> 00:03:51,879
we've all seen and the success of uh

92
00:03:50,120 --> 00:03:54,000
obviously chat GPT and similar

93
00:03:51,879 --> 00:03:57,640
Technologies in producing sort of

94
00:03:54,000 --> 00:04:00,760
humanlike text and and then in the

95
00:03:57,640 --> 00:04:03,239
Sciences there's been sort of one big

96
00:04:00,760 --> 00:04:05,480
wind has been Alpha right you remember

97
00:04:03,239 --> 00:04:07,959
maybe four or five years ago this

98
00:04:05,480 --> 00:04:10,239
problem of protein structure prediction

99
00:04:07,959 --> 00:04:13,439
figuring out what geometry a protein is

100
00:04:10,239 --> 00:04:15,239
going to have just based on its sequence

101
00:04:13,439 --> 00:04:17,919
on the physics based side it's like a

102
00:04:15,239 --> 00:04:19,560
really interactable problem it requires

103
00:04:17,919 --> 00:04:20,720
computation at a scale that we we

104
00:04:19,560 --> 00:04:24,080
couldn't sort of

105
00:04:20,720 --> 00:04:26,160
really aspire to to deploy and it turns

106
00:04:24,080 --> 00:04:27,919
out it was a very learnable problem that

107
00:04:26,160 --> 00:04:30,520
it wasn't really that hard and with a

108
00:04:27,919 --> 00:04:32,960
100,000 instances of training examples

109
00:04:30,520 --> 00:04:34,080
it was actually learnable so all of

110
00:04:32,960 --> 00:04:36,880
these have something in common right

111
00:04:34,080 --> 00:04:38,919
they been a combination of gpus that's

112
00:04:36,880 --> 00:04:42,759
what you know Nvidia is one of the most

113
00:04:38,919 --> 00:04:45,080
valuable companies in the world um uh

114
00:04:42,759 --> 00:04:47,000
just data right although we've kind of

115
00:04:45,080 --> 00:04:48,639
run out of data for llms because they've

116
00:04:47,000 --> 00:04:50,639
already read every word that has ever

117
00:04:48,639 --> 00:04:52,759
been written so maybe some of those are

118
00:04:50,639 --> 00:04:55,840
already CT and then algorithms right

119
00:04:52,759 --> 00:04:57,880
just algorithmic Innovation and I for

120
00:04:55,840 --> 00:04:59,919
instance I am never going to write a

121
00:04:57,880 --> 00:05:02,039
cover letter again in my life right got

122
00:04:59,919 --> 00:05:03,680
this cover letter prepared in case we

123
00:05:02,039 --> 00:05:06,600
ever discover a high temperature

124
00:05:03,680 --> 00:05:09,919
superconductor I already have GPT right

125
00:05:06,600 --> 00:05:12,600
to me the the cover letter now can I ask

126
00:05:09,919 --> 00:05:14,840
GPT to find me the super conductor

127
00:05:12,600 --> 00:05:17,000
that's that's the harder part that's the

128
00:05:14,840 --> 00:05:19,759
thing that's very different about our

129
00:05:17,000 --> 00:05:22,240
world right like how do we deploy these

130
00:05:19,759 --> 00:05:24,680
Technologies for chemistry and and

131
00:05:22,240 --> 00:05:26,160
materials Innovations could that could

132
00:05:24,680 --> 00:05:28,120
be any of these things right it could be

133
00:05:26,160 --> 00:05:30,039
carbon capture right we need to sack

134
00:05:28,120 --> 00:05:31,759
carbon out of the air we need need

135
00:05:30,039 --> 00:05:34,919
batteries like I said we need more

136
00:05:31,759 --> 00:05:37,479
sustainable Plastics um and this has

137
00:05:34,919 --> 00:05:39,880
some qualitative differences from some

138
00:05:37,479 --> 00:05:43,000
of the other victories um the first one

139
00:05:39,880 --> 00:05:44,840
is that typically we only want a match

140
00:05:43,000 --> 00:05:47,639
to Human Performance for most of the

141
00:05:44,840 --> 00:05:49,720
other tasks right we want images as good

142
00:05:47,639 --> 00:05:51,720
as as an artist would draw you know we

143
00:05:49,720 --> 00:05:54,400
want contracts as good as a lawyer would

144
00:05:51,720 --> 00:05:57,080
would write uh but here we kind of want

145
00:05:54,400 --> 00:05:58,600
to do better than the best human has

146
00:05:57,080 --> 00:06:00,039
ever done in history right because

147
00:05:58,600 --> 00:06:02,840
otherwise we you know you know you'll

148
00:06:00,039 --> 00:06:04,800
invent things once um so we want to do

149
00:06:02,840 --> 00:06:07,720
better than the best scientist has ever

150
00:06:04,800 --> 00:06:10,000
done which is kind of a shift um and it

151
00:06:07,720 --> 00:06:12,599
has sort of this outof

152
00:06:10,000 --> 00:06:14,120
distribution extrapolation challenge

153
00:06:12,599 --> 00:06:15,240
that is really hard for machine learning

154
00:06:14,120 --> 00:06:17,160
right we're asking the machine learning

155
00:06:15,240 --> 00:06:20,440
model to do something that is by

156
00:06:17,160 --> 00:06:22,360
definition outside of the training data

157
00:06:20,440 --> 00:06:24,479
outside of the way we trained it because

158
00:06:22,360 --> 00:06:28,000
we're asking it to invent completely

159
00:06:24,479 --> 00:06:30,560
Noble things um and we postulate and

160
00:06:28,000 --> 00:06:32,880
this is not necessarily A a proven

161
00:06:30,560 --> 00:06:36,560
hypothesis that the fact that in the

162
00:06:32,880 --> 00:06:38,680
Sciences we have rules should help right

163
00:06:36,560 --> 00:06:40,680
the fact that you know maybe your

164
00:06:38,680 --> 00:06:43,280
companies do physics based simulations

165
00:06:40,680 --> 00:06:45,520
maybe you do you know finite elements

166
00:06:43,280 --> 00:06:47,880
maybe you do fluid dynamics right in

167
00:06:45,520 --> 00:06:50,560
many places we know the laws of physics

168
00:06:47,880 --> 00:06:52,160
in a way that should help our models and

169
00:06:50,560 --> 00:06:53,560
a big example of this would be climate

170
00:06:52,160 --> 00:06:55,360
modeling right we don't do any climate

171
00:06:53,560 --> 00:06:57,280
modeling but climate modeling is

172
00:06:55,360 --> 00:07:00,360
something that has really succeeded over

173
00:06:57,280 --> 00:07:02,479
the last three two three years um

174
00:07:00,360 --> 00:07:05,039
through a combination of understanding

175
00:07:02,479 --> 00:07:08,240
the way the physics works and utilizing

176
00:07:05,039 --> 00:07:10,440
lots of experimental data um to drive

177
00:07:08,240 --> 00:07:13,639
things forward so in the chemistry and

178
00:07:10,440 --> 00:07:16,960
Material Science space we we only get to

179
00:07:13,639 --> 00:07:18,919
deploy um machine learning or to utilize

180
00:07:16,960 --> 00:07:20,840
machine learning if we live sort of in a

181
00:07:18,919 --> 00:07:24,319
more data intensive Paradigm right at

182
00:07:20,840 --> 00:07:26,000
the end of the day um the traditional

183
00:07:24,319 --> 00:07:28,759
scientific

184
00:07:26,000 --> 00:07:32,400
approach So-Cal edisonian approach would

185
00:07:28,759 --> 00:07:36,080
be this on the left here

186
00:07:32,400 --> 00:07:38,400
where the framework is a human decides

187
00:07:36,080 --> 00:07:39,759
what the space of options would be right

188
00:07:38,400 --> 00:07:41,720
and that's typically in the hundreds of

189
00:07:39,759 --> 00:07:43,960
thousands right when when experimental

190
00:07:41,720 --> 00:07:45,840
scientists show up in their Labs today

191
00:07:43,960 --> 00:07:47,599
they you know the thing the set of

192
00:07:45,840 --> 00:07:49,120
things they could be doing that day it's

193
00:07:47,599 --> 00:07:50,960
typically in the hundreds or thousands

194
00:07:49,120 --> 00:07:53,080
of ideas it's not in the millions or

195
00:07:50,960 --> 00:07:54,759
billions of ideas um and then they

196
00:07:53,080 --> 00:07:56,759
select based on their understanding of

197
00:07:54,759 --> 00:07:59,599
the world the literature they've read

198
00:07:56,759 --> 00:08:01,280
their internal model of the world

199
00:07:59,599 --> 00:08:03,879
handful of experiments which take a

200
00:08:01,280 --> 00:08:06,360
couple of days to run so this cycle

201
00:08:03,879 --> 00:08:08,440
these data pipes are kind of narrow

202
00:08:06,360 --> 00:08:10,800
right and then the outcomes are sort of

203
00:08:08,440 --> 00:08:13,639
two three new data points a day which

204
00:08:10,800 --> 00:08:15,919
are just very well digested by a human

205
00:08:13,639 --> 00:08:18,000
being right we're very good at operating

206
00:08:15,919 --> 00:08:19,479
in low modes in low data modes right

207
00:08:18,000 --> 00:08:21,720
that's something we've done cognitively

208
00:08:19,479 --> 00:08:24,039
very well so AI is not really going to

209
00:08:21,720 --> 00:08:26,720
change this part of the world if if you

210
00:08:24,039 --> 00:08:28,520
really produce new data at sort of a

211
00:08:26,720 --> 00:08:30,400
throughput of a couple a day you don't

212
00:08:28,520 --> 00:08:32,719
need a deep Lear anymore right or our

213
00:08:30,400 --> 00:08:34,399
deep learning model won't be a

214
00:08:32,719 --> 00:08:37,279
Difference Maker right because our human

215
00:08:34,399 --> 00:08:38,800
intuition is very good on the other side

216
00:08:37,279 --> 00:08:40,279
of the pipe and this is of this new

217
00:08:38,800 --> 00:08:44,440
paradigm that has emerged over the last

218
00:08:40,279 --> 00:08:47,000
few years is ways to generate more data

219
00:08:44,440 --> 00:08:49,399
over larger design spaces like well a

220
00:08:47,000 --> 00:08:51,360
computer a million options 100 million

221
00:08:49,399 --> 00:08:53,839
options that's really not that difficult

222
00:08:51,360 --> 00:08:55,160
problem for a computer today Pharma

223
00:08:53,839 --> 00:08:59,120
companies and again I don't know if

224
00:08:55,160 --> 00:09:01,200
there are any here um they purchase new

225
00:08:59,120 --> 00:09:03,360
comp compounds from virtual catalogs

226
00:09:01,200 --> 00:09:05,959
from a company called enamine or others

227
00:09:03,360 --> 00:09:07,959
like them which have a list of 1.5

228
00:09:05,959 --> 00:09:10,000
billion compounds you could buy for them

229
00:09:07,959 --> 00:09:12,200
from them and you put your lit machine

230
00:09:10,000 --> 00:09:14,040
learning model running over the list of

231
00:09:12,200 --> 00:09:16,880
compounds these folks make and order the

232
00:09:14,040 --> 00:09:19,399
ones that could work for you um so in

233
00:09:16,880 --> 00:09:22,079
this new paradigm we have broader search

234
00:09:19,399 --> 00:09:26,120
spaces we try to create data in bigger

235
00:09:22,079 --> 00:09:28,320
chunks at a given time and the loop gets

236
00:09:26,120 --> 00:09:29,760
closed not through human intuition but

237
00:09:28,320 --> 00:09:34,320
through a computer right through Active

238
00:09:29,760 --> 00:09:36,959
Learning um uh and in general um in

239
00:09:34,320 --> 00:09:40,399
chemistry and materials there is a

240
00:09:36,959 --> 00:09:43,160
hierarchy of how much data we can make

241
00:09:40,399 --> 00:09:46,440
at every instance right so typically um

242
00:09:43,160 --> 00:09:48,680
at the base of the pyramid we can deploy

243
00:09:46,440 --> 00:09:50,440
statistical machine learning models over

244
00:09:48,680 --> 00:09:52,680
millions and billions of options right

245
00:09:50,440 --> 00:09:54,839
this people call this virtual screening

246
00:09:52,680 --> 00:09:57,040
we can totally screen Millions hundreds

247
00:09:54,839 --> 00:09:58,680
of millions of compounds with a neural

248
00:09:57,040 --> 00:10:02,120
network or with a machine learning model

249
00:09:58,680 --> 00:10:06,279
so this ual space we can screen you know

250
00:10:02,120 --> 00:10:08,160
at gigantic scales um maybe we can use

251
00:10:06,279 --> 00:10:09,560
sort of more trust worthy simulations

252
00:10:08,160 --> 00:10:11,279
right depending on your field you could

253
00:10:09,560 --> 00:10:13,000
sort of screen with a neural network in

254
00:10:11,279 --> 00:10:15,079
climate modeling and then run a few

255
00:10:13,000 --> 00:10:17,880
models forward with

256
00:10:15,079 --> 00:10:20,760
actual physics based simulations or

257
00:10:17,880 --> 00:10:22,880
finite element simulations um and then

258
00:10:20,760 --> 00:10:25,079
we need to make stuff and depending

259
00:10:22,880 --> 00:10:28,120
where in the world you see this is this

260
00:10:25,079 --> 00:10:30,120
is the where the materials world is very

261
00:10:28,120 --> 00:10:32,959
different from other places

262
00:10:30,120 --> 00:10:35,399
because if you want chat GPT to write

263
00:10:32,959 --> 00:10:37,680
contracts you only need to worry that

264
00:10:35,399 --> 00:10:43,639
the contracts are good but there is

265
00:10:37,680 --> 00:10:45,360
no change of um uh platform you know the

266
00:10:43,639 --> 00:10:48,680
contract is a digital object that gets

267
00:10:45,360 --> 00:10:51,360
sent over email as a PDF file so CH GPT

268
00:10:48,680 --> 00:10:53,920
can actuate in the real world directly

269
00:10:51,360 --> 00:10:56,440
right in materials we kind of need to

270
00:10:53,920 --> 00:10:58,800
make stuff right and then we need to

271
00:10:56,440 --> 00:11:01,200
make it to see if it works and then we

272
00:10:58,800 --> 00:11:02,880
need to scale it up to deploy it into

273
00:11:01,200 --> 00:11:04,839
into the market right and these two

274
00:11:02,880 --> 00:11:07,959
things we will talk more about this but

275
00:11:04,839 --> 00:11:11,880
this is critical um so there is making

276
00:11:07,959 --> 00:11:13,440
which is kind of harder than simulating

277
00:11:11,880 --> 00:11:15,040
and then there is characterizing and

278
00:11:13,440 --> 00:11:17,639
measuring the quality of what you've

279
00:11:15,040 --> 00:11:19,240
made for the performance metrics that

280
00:11:17,639 --> 00:11:21,399
you want to hit for your Target product

281
00:11:19,240 --> 00:11:23,320
profiles like is this thing good enough

282
00:11:21,399 --> 00:11:25,680
and and that typically is the most time

283
00:11:23,320 --> 00:11:28,720
consuming part right so different places

284
00:11:25,680 --> 00:11:31,000
different Industries and different um

285
00:11:28,720 --> 00:11:34,160
products have sort of different widths

286
00:11:31,000 --> 00:11:36,800
but in general this cycle um of of how

287
00:11:34,160 --> 00:11:38,600
much data we produce is hierarchical

288
00:11:36,800 --> 00:11:40,959
like this and in my group we've done a

289
00:11:38,600 --> 00:11:43,200
number of these um I won't I won't spend

290
00:11:40,959 --> 00:11:44,920
too much time describing sort of our own

291
00:11:43,200 --> 00:11:47,399
detailed research but we've deployed

292
00:11:44,920 --> 00:11:48,800
these types of things for polymers for

293
00:11:47,399 --> 00:11:50,680
for lithium batteries for organic

294
00:11:48,800 --> 00:11:53,040
Electronics we've done organic light

295
00:11:50,680 --> 00:11:55,000
emitting diodes uh we've done nanoporous

296
00:11:53,040 --> 00:11:56,519
Catal I have some slides on on those you

297
00:11:55,000 --> 00:11:58,720
have time we're doing recyclable

298
00:11:56,519 --> 00:12:01,120
polymers for windmill blades so in

299
00:11:58,720 --> 00:12:03,560
general this hierarchy of running some

300
00:12:01,120 --> 00:12:06,079
some Physics based simulations over some

301
00:12:03,560 --> 00:12:08,000
design space making them work together

302
00:12:06,079 --> 00:12:10,399
with machine learning models such that

303
00:12:08,000 --> 00:12:14,000
we can save ourselves simulation time

304
00:12:10,399 --> 00:12:17,160
even and then bring in domain experts as

305
00:12:14,000 --> 00:12:19,959
the translation entity right that that

306
00:12:17,160 --> 00:12:22,519
will translate computational designs

307
00:12:19,959 --> 00:12:24,760
into actual sort of materials that that

308
00:12:22,519 --> 00:12:27,360
will be tested right and and every time

309
00:12:24,760 --> 00:12:30,000
we narrow down the face space of things

310
00:12:27,360 --> 00:12:31,320
we could do and have this communicate

311
00:12:30,000 --> 00:12:34,360
with one another this this should look

312
00:12:31,320 --> 00:12:36,440
tiny on your screens um the data

313
00:12:34,360 --> 00:12:38,360
infrastructure that we built is like

314
00:12:36,440 --> 00:12:40,320
tens of thousands of lines of code in

315
00:12:38,360 --> 00:12:43,399
order to store all of these to automate

316
00:12:40,320 --> 00:12:44,920
to have these Digital Data pipes there's

317
00:12:43,399 --> 00:12:47,440
a lot of infrastructure that needs to be

318
00:12:44,920 --> 00:12:50,360
built um maybe there will be questions

319
00:12:47,440 --> 00:12:52,560
later about sort of what is the balance

320
00:12:50,360 --> 00:12:56,720
between digitizing old data and

321
00:12:52,560 --> 00:13:00,160
digitizing new data um I've typically

322
00:12:56,720 --> 00:13:03,920
been on the camp of digitizing new data

323
00:13:00,160 --> 00:13:06,800
digitizing old data until llms was a

324
00:13:03,920 --> 00:13:09,360
nightmare with llms maybe there is there

325
00:13:06,800 --> 00:13:11,920
is a a low overhead way of going back

326
00:13:09,360 --> 00:13:16,760
and and salvaging all data and research

327
00:13:11,920 --> 00:13:19,440
in augmented generation in rag but until

328
00:13:16,760 --> 00:13:21,360
today leverage in all data was was just

329
00:13:19,440 --> 00:13:24,440
too expensive

330
00:13:21,360 --> 00:13:27,639
um so more concretely right what are

331
00:13:24,440 --> 00:13:30,480
places where AI is being deployed today

332
00:13:27,639 --> 00:13:34,680
sort of at the interface of research or

333
00:13:30,480 --> 00:13:37,680
or um very aggressive early adopters in

334
00:13:34,680 --> 00:13:39,079
the in Industry well deep learning

335
00:13:37,680 --> 00:13:41,760
models machine learning models can

336
00:13:39,079 --> 00:13:44,360
definitely predict what a material what

337
00:13:41,760 --> 00:13:46,079
a molecule will do from its structure

338
00:13:44,360 --> 00:13:48,000
this I I just mention this when I talked

339
00:13:46,079 --> 00:13:51,000
about this enamine company for drag

340
00:13:48,000 --> 00:13:52,600
Discovery right so going back for you

341
00:13:51,000 --> 00:13:56,519
know

342
00:13:52,600 --> 00:13:58,720
2015 for the first instances 20 for

343
00:13:56,519 --> 00:13:59,759
molecules 2018 for the first instances

344
00:13:58,720 --> 00:14:02,240
for

345
00:13:59,759 --> 00:14:05,079
for crystals maybe a little bit later in

346
00:14:02,240 --> 00:14:07,360
the early 2020s for proteins uh and this

347
00:14:05,079 --> 00:14:10,199
is a generative example over the last

348
00:14:07,360 --> 00:14:12,240
sort of five to 10 years the community

349
00:14:10,199 --> 00:14:15,399
has made deep learning models that are

350
00:14:12,240 --> 00:14:17,639
just very good at looking at matter so

351
00:14:15,399 --> 00:14:19,759
for whatever arrangement of atoms if I

352
00:14:17,639 --> 00:14:21,560
have enough training data in the right

353
00:14:19,759 --> 00:14:24,120
space I can make a machine learning

354
00:14:21,560 --> 00:14:26,959
model that would tell me this is good

355
00:14:24,120 --> 00:14:28,759
this is bad and and that's Pharma

356
00:14:26,959 --> 00:14:32,000
companies do this all the time today

357
00:14:28,759 --> 00:14:34,759
right so you you train a model on your

358
00:14:32,000 --> 00:14:36,480
you know binding examples from a highr

359
00:14:34,759 --> 00:14:38,040
puras and now you have a binding

360
00:14:36,480 --> 00:14:39,839
predictor that would apply to new

361
00:14:38,040 --> 00:14:43,000
compounds that you want to buy or make

362
00:14:39,839 --> 00:14:45,600
right and or to admit um or this would

363
00:14:43,000 --> 00:14:47,560
apply to polymers for lithium ion

364
00:14:45,600 --> 00:14:50,680
batteries or to crystals for

365
00:14:47,560 --> 00:14:53,320
ferroelectric material so in general um

366
00:14:50,680 --> 00:14:54,880
over the last sort of 5 to 10 years the

367
00:14:53,320 --> 00:14:57,160
community has made good deep learning

368
00:14:54,880 --> 00:14:59,560
models that given a structure will

369
00:14:57,160 --> 00:15:01,199
assign the label

370
00:14:59,560 --> 00:15:06,040
of what it's going to do as long as

371
00:15:01,199 --> 00:15:09,560
there is enough data um AI can predict

372
00:15:06,040 --> 00:15:11,800
how to make stuff okay um we call in

373
00:15:09,560 --> 00:15:14,560
chemistry we call this retrosynthesis

374
00:15:11,800 --> 00:15:16,120
which is if you wanted this compound

375
00:15:14,560 --> 00:15:17,839
these are the precursors you were going

376
00:15:16,120 --> 00:15:21,360
to have to buy and these are the ways

377
00:15:17,839 --> 00:15:23,199
you would put them together um this goes

378
00:15:21,360 --> 00:15:26,800
back the idea of trying to do this with

379
00:15:23,199 --> 00:15:28,040
computers goes back to the 60s to Cory

380
00:15:26,800 --> 00:15:31,079
who worked you know at a school that

381
00:15:28,040 --> 00:15:35,440
shall not be named over right over there

382
00:15:31,079 --> 00:15:38,240
um uh and and this has been a a dream of

383
00:15:35,440 --> 00:15:40,680
the organic chemistry community and

384
00:15:38,240 --> 00:15:44,120
again it's been commoditized now many

385
00:15:40,680 --> 00:15:46,759
companies will provide retrosynthesis

386
00:15:44,120 --> 00:15:48,880
software as a service where you say well

387
00:15:46,759 --> 00:15:52,360
I want to make this compound you call

388
00:15:48,880 --> 00:15:53,639
their their their API you call their web

389
00:15:52,360 --> 00:15:55,600
and then they send you back well then

390
00:15:53,639 --> 00:15:57,360
you should buy these precursors and make

391
00:15:55,600 --> 00:15:59,920
these chemistries in this way right so

392
00:15:57,360 --> 00:16:02,000
this is this is something is not perfect

393
00:15:59,920 --> 00:16:04,199
nothing everything could be perfected

394
00:16:02,000 --> 00:16:05,639
but it works and has been around for

395
00:16:04,199 --> 00:16:08,240
this this example for instance from

396
00:16:05,639 --> 00:16:10,560
Marvin segler who's now at Microsoft is

397
00:16:08,240 --> 00:16:13,720
six years old now so this is like I said

398
00:16:10,560 --> 00:16:15,800
this been productized um and this is the

399
00:16:13,720 --> 00:16:18,040
case also for for

400
00:16:15,800 --> 00:16:21,680
materials materials are a little bit

401
00:16:18,040 --> 00:16:24,319
behind because the chemists have all

402
00:16:21,680 --> 00:16:26,519
agreed about how to report the way they

403
00:16:24,319 --> 00:16:29,440
make stuff all chemical reactions are

404
00:16:26,519 --> 00:16:31,959
WRAT in the same way m materials

405
00:16:29,440 --> 00:16:33,440
chemistry material synthesis procedures

406
00:16:31,959 --> 00:16:34,920
are written in a completely different

407
00:16:33,440 --> 00:16:37,720
way right like so if you know if you

408
00:16:34,920 --> 00:16:39,920
shake and Cal sign or you do Soul gel

409
00:16:37,720 --> 00:16:41,519
right there is infinite combinations

410
00:16:39,920 --> 00:16:45,120
that don't have a standard onology

411
00:16:41,519 --> 00:16:48,440
meaning that the only way of

412
00:16:45,120 --> 00:16:50,240
processing syn material synthesis data

413
00:16:48,440 --> 00:16:52,360
has been going to the literature and

414
00:16:50,240 --> 00:16:55,079
reading papers because the data is

415
00:16:52,360 --> 00:16:57,319
unstructured and again llms have really

416
00:16:55,079 --> 00:16:59,160
changed this over the last three years

417
00:16:57,319 --> 00:17:01,959
it's been possible to go to the

418
00:16:59,160 --> 00:17:04,720
literature and ask an llm to read the

419
00:17:01,959 --> 00:17:07,319
papers and organize the material

420
00:17:04,720 --> 00:17:10,000
synthesis data such that then you can

421
00:17:07,319 --> 00:17:12,319
predict how to make new materials based

422
00:17:10,000 --> 00:17:15,520
on the recipes of existing materials

423
00:17:12,319 --> 00:17:17,520
right so again llms have have power the

424
00:17:15,520 --> 00:17:20,600
extraction and then other classes of

425
00:17:17,520 --> 00:17:23,240
models can predict how to make M you

426
00:17:20,600 --> 00:17:25,559
know an oxide or how to make a a

427
00:17:23,240 --> 00:17:28,199
catalyst based or a metal organic

428
00:17:25,559 --> 00:17:29,559
framework based on on the on the

429
00:17:28,199 --> 00:17:30,720
literature

430
00:17:29,559 --> 00:17:33,880
and then just in the last couple of

431
00:17:30,720 --> 00:17:36,320
years uh LMS have sort of taken a bigger

432
00:17:33,880 --> 00:17:40,200
role in what we can say sort of

433
00:17:36,320 --> 00:17:43,240
orchestrating or or agentic workflows

434
00:17:40,200 --> 00:17:45,280
where you know in addition to sort of

435
00:17:43,240 --> 00:17:47,360
doing this individual task that I said

436
00:17:45,280 --> 00:17:49,000
you know you can go read the literature

437
00:17:47,360 --> 00:17:52,039
or we can predict what a material will

438
00:17:49,000 --> 00:17:55,200
do um the orchestration of what to do

439
00:17:52,039 --> 00:17:57,240
when can also be run by a by an NM right

440
00:17:55,200 --> 00:17:59,200
so these are a couple of examples I

441
00:17:57,240 --> 00:18:01,120
apologize here to to my Budd Gabe gz

442
00:17:59,200 --> 00:18:02,720
this is in nature now but I'm citing the

443
00:18:01,120 --> 00:18:06,360
the preprint but this disc go in nature

444
00:18:02,720 --> 00:18:10,159
at the end of 2023 um and this is a a

445
00:18:06,360 --> 00:18:11,919
particular paper for a for a llm that

446
00:18:10,159 --> 00:18:13,880
again reads the

447
00:18:11,919 --> 00:18:16,679
literature decides whether you need to

448
00:18:13,880 --> 00:18:19,080
change your reagents um and produces

449
00:18:16,679 --> 00:18:21,440
synthesis recipes sort of autonomously

450
00:18:19,080 --> 00:18:24,360
right the the orchestration of which

451
00:18:21,440 --> 00:18:28,080
model to call when is something that is

452
00:18:24,360 --> 00:18:30,360
is happening right now and then you know

453
00:18:28,080 --> 00:18:32,600
there it says gener ative AI right there

454
00:18:30,360 --> 00:18:35,039
what does what does sort of material

455
00:18:32,600 --> 00:18:36,480
Discovery have to do with generative AI

456
00:18:35,039 --> 00:18:38,240
well they're kind of one and the same

457
00:18:36,480 --> 00:18:41,559
thing from our perspective if if you

458
00:18:38,240 --> 00:18:44,760
notice I mention machine learning models

459
00:18:41,559 --> 00:18:47,600
that go from structure to property or

460
00:18:44,760 --> 00:18:49,960
from material to synthesis but really

461
00:18:47,600 --> 00:18:53,200
what we want to do is go from the

462
00:18:49,960 --> 00:18:54,840
property I want to maybe the structure

463
00:18:53,200 --> 00:18:57,480
that will produce it or from the

464
00:18:54,840 --> 00:18:59,360
material that I want to the synthesis

465
00:18:57,480 --> 00:19:01,039
from the properties that I want to the

466
00:18:59,360 --> 00:19:03,440
synthesis that would make a material

467
00:19:01,039 --> 00:19:07,120
with those properties right what I want

468
00:19:03,440 --> 00:19:08,640
is to inverse the sign ideally the

469
00:19:07,120 --> 00:19:10,679
product people will come to me with a

470
00:19:08,640 --> 00:19:12,880
Target product profile and say well we

471
00:19:10,679 --> 00:19:14,840
want some nanoporous material that would

472
00:19:12,880 --> 00:19:16,520
absorb CO2 in this pressure and

473
00:19:14,840 --> 00:19:18,320
temperature and it costs less than a

474
00:19:16,520 --> 00:19:20,360
dollar a kilogram right and then I just

475
00:19:18,320 --> 00:19:21,360
put that into the LM and it tells me

476
00:19:20,360 --> 00:19:23,080
well then you need to buy these

477
00:19:21,360 --> 00:19:26,120
precursors and put them in the oven for

478
00:19:23,080 --> 00:19:28,080
two days um that's a generative task

479
00:19:26,120 --> 00:19:30,159
right instead of going from a known

480
00:19:28,080 --> 00:19:34,120
structure to the properties we expect it

481
00:19:30,159 --> 00:19:37,000
will have we go from the properties we

482
00:19:34,120 --> 00:19:40,000
want to a material that could have them

483
00:19:37,000 --> 00:19:42,360
and that's a it's a much harder task

484
00:19:40,000 --> 00:19:43,960
because there may be many answers if you

485
00:19:42,360 --> 00:19:46,080
want something trivial there might be

486
00:19:43,960 --> 00:19:47,640
many answers and if you want something

487
00:19:46,080 --> 00:19:49,320
impossible like my high temperature

488
00:19:47,640 --> 00:19:51,280
superconductor there might be no answer

489
00:19:49,320 --> 00:19:55,400
whatsoever also and the model needs to

490
00:19:51,280 --> 00:19:57,600
know how to do this um U the idea of

491
00:19:55,400 --> 00:19:59,159
trying to do this in chemistry goes back

492
00:19:57,600 --> 00:20:01,440
about eight years from the first

493
00:19:59,159 --> 00:20:04,000
examples and people have kept going at

494
00:20:01,440 --> 00:20:07,840
it and there is a gilon improvements

495
00:20:04,000 --> 00:20:11,840
over that original work um and there is

496
00:20:07,840 --> 00:20:15,039
a big ecosystem of AI for chemistry

497
00:20:11,840 --> 00:20:17,200
companies that have utilized or or

498
00:20:15,039 --> 00:20:21,320
productize generative AI for small

499
00:20:17,200 --> 00:20:22,880
molecules interestingly um AI for small

500
00:20:21,320 --> 00:20:24,400
molecules even though it got very

501
00:20:22,880 --> 00:20:26,799
exciting there's a lot of small

502
00:20:24,400 --> 00:20:28,360
molecules you could make and and people

503
00:20:26,799 --> 00:20:29,960
have been thinking about sort of AI for

504
00:20:28,360 --> 00:20:33,360
chemistry for a long time so it seem

505
00:20:29,960 --> 00:20:36,840
like a natural match um proteins which

506
00:20:33,360 --> 00:20:39,240
seemed harder originally have overtaking

507
00:20:36,840 --> 00:20:42,240
small molecules and they turn out to be

508
00:20:39,240 --> 00:20:45,960
easier for you know based on and the

509
00:20:42,240 --> 00:20:49,039
reason I believe is because

510
00:20:45,960 --> 00:20:50,360
proteins all form a family they all come

511
00:20:49,039 --> 00:20:52,760
from the same

512
00:20:50,360 --> 00:20:55,480
distribution biology and life and

513
00:20:52,760 --> 00:20:57,720
evolution have created a common language

514
00:20:55,480 --> 00:21:00,440
that covers all of proteins so it turns

515
00:20:57,720 --> 00:21:03,360
out those were were easier functions to

516
00:21:00,440 --> 00:21:06,120
learn just like go was easier to learn

517
00:21:03,360 --> 00:21:08,320
than self-driving cars um proteins

518
00:21:06,120 --> 00:21:10,480
turned out to be learnable in a way that

519
00:21:08,320 --> 00:21:13,240
has exploded over the last you know

520
00:21:10,480 --> 00:21:15,679
three four years um so generative models

521
00:21:13,240 --> 00:21:18,640
for proteins really work and they say if

522
00:21:15,679 --> 00:21:20,840
you want a protein that binds this other

523
00:21:18,640 --> 00:21:22,679
Target like that then you need to you

524
00:21:20,840 --> 00:21:26,400
know arrange this amino acids in a

525
00:21:22,679 --> 00:21:29,440
sequence and you can make those in a um

526
00:21:26,400 --> 00:21:31,720
uh Express those uh

527
00:21:29,440 --> 00:21:33,400
as a nucleic acid and then translate

528
00:21:31,720 --> 00:21:34,720
them and you know these companies I have

529
00:21:33,400 --> 00:21:37,720
a list later I don't know if you've

530
00:21:34,720 --> 00:21:41,039
heard during this space cidra raised a

531
00:21:37,720 --> 00:21:43,400
billion dollars a series no this is not

532
00:21:41,039 --> 00:21:48,200
an MIT startup um it raised a billion

533
00:21:43,400 --> 00:21:50,000
dollars a series recently to do that um

534
00:21:48,200 --> 00:21:52,159
so like I said the inverse design maybe

535
00:21:50,000 --> 00:21:55,720
a little bit technical but in general

536
00:21:52,159 --> 00:21:58,080
the same tools that produce you know

537
00:21:55,720 --> 00:22:00,559
pictures of an astronaut riding a horse

538
00:21:58,080 --> 00:22:04,559
on the surface of the Moon from a prpt

539
00:22:00,559 --> 00:22:07,880
from a prompt could produce a blue low

540
00:22:04,559 --> 00:22:10,279
cost stable molecule to put in the LED

541
00:22:07,880 --> 00:22:12,240
display on my phone we just need to you

542
00:22:10,279 --> 00:22:13,679
know train them on different data and

543
00:22:12,240 --> 00:22:15,559
structure them in a different way

544
00:22:13,679 --> 00:22:17,640
because the thing we're producing here

545
00:22:15,559 --> 00:22:19,799
are pixels and the thing we're producing

546
00:22:17,640 --> 00:22:22,760
in this model is ideally atomic

547
00:22:19,799 --> 00:22:24,279
structure or even better just the

548
00:22:22,760 --> 00:22:25,600
synthesis recipe just tell me what to

549
00:22:24,279 --> 00:22:26,880
buy right like don't even tell me what

550
00:22:25,600 --> 00:22:30,159
the molecule looks like just tell me

551
00:22:26,880 --> 00:22:32,000
what I need to make um um so that sounds

552
00:22:30,159 --> 00:22:34,640
amazing you know

553
00:22:32,000 --> 00:22:36,760
and what's what's not working right like

554
00:22:34,640 --> 00:22:38,400
what's what what is it really sort of

555
00:22:36,760 --> 00:22:40,240
what what are the boundaries right now

556
00:22:38,400 --> 00:22:43,480
well there's a lot of things AI cannot

557
00:22:40,240 --> 00:22:44,960
do in chemistry and materials um I have

558
00:22:43,480 --> 00:22:47,440
them listed there I can sort of give a

559
00:22:44,960 --> 00:22:49,720
little color but deciding what's

560
00:22:47,440 --> 00:22:51,520
important it's all about context right

561
00:22:49,720 --> 00:22:53,159
at the end of the day a lot of this have

562
00:22:51,520 --> 00:22:57,240
to do with sort of the rest of the

563
00:22:53,159 --> 00:23:01,679
context and AI cannot decide whether

564
00:22:57,240 --> 00:23:04,799
it's better to to make a sustainable

565
00:23:01,679 --> 00:23:07,480
plastic or a recycling system for

566
00:23:04,799 --> 00:23:10,440
existing Plastics that's that's you know

567
00:23:07,480 --> 00:23:12,320
there is technoeconomic there is a moral

568
00:23:10,440 --> 00:23:14,279
there is a market opportunity there is

569
00:23:12,320 --> 00:23:16,640
time to pass like all these things live

570
00:23:14,279 --> 00:23:18,640
outside the training data and the way

571
00:23:16,640 --> 00:23:20,320
machine learning models think so that's

572
00:23:18,640 --> 00:23:22,559
our responsibility right like we we are

573
00:23:20,320 --> 00:23:25,400
the ones that need to Define very clear

574
00:23:22,559 --> 00:23:27,559
objective function so what is the Target

575
00:23:25,400 --> 00:23:29,600
in the most structured well defined

576
00:23:27,559 --> 00:23:30,919
possible way that I want to pursue

577
00:23:29,600 --> 00:23:32,600
otherwise the models will cheat they

578
00:23:30,919 --> 00:23:34,760
will cheat all the time and just give

579
00:23:32,600 --> 00:23:37,520
you the most obvious solution or or the

580
00:23:34,760 --> 00:23:40,600
easiest solution um if if the question

581
00:23:37,520 --> 00:23:43,360
is unspecified um I don't know what your

582
00:23:40,600 --> 00:23:47,120
companies exactly have encountered here

583
00:23:43,360 --> 00:23:49,039
but in general creative humans don't

584
00:23:47,120 --> 00:23:52,159
like to be told what to do by a

585
00:23:49,039 --> 00:23:55,559
computer um and this is a big impedance

586
00:23:52,159 --> 00:23:57,279
matching when things need to be realized

587
00:23:55,559 --> 00:23:59,640
in the real world right in the physical

588
00:23:57,279 --> 00:24:02,880
World objects need to made be made

589
00:23:59,640 --> 00:24:05,880
chemistry needs to happen in a lab um so

590
00:24:02,880 --> 00:24:08,159
the conduit for this AI creativity is

591
00:24:05,880 --> 00:24:10,360
human beings that are extremely skilled

592
00:24:08,159 --> 00:24:11,919
and deep thinkers who would rather

593
00:24:10,360 --> 00:24:14,200
explore their own hypothesis than a

594
00:24:11,919 --> 00:24:17,159
computer's hypothesis and this seems

595
00:24:14,200 --> 00:24:21,320
trivial but it's held back the field

596
00:24:17,159 --> 00:24:23,320
because well the AI has high tolerance

597
00:24:21,320 --> 00:24:25,320
for false positives right something you

598
00:24:23,320 --> 00:24:27,559
thought was a great idea turns out to be

599
00:24:25,320 --> 00:24:29,600
a bad idea the computer doesn't care

600
00:24:27,559 --> 00:24:31,559
right like well will it learns it's good

601
00:24:29,600 --> 00:24:33,120
data it keep going it's kind of Soul

602
00:24:31,559 --> 00:24:35,679
crashing to have false negatives all the

603
00:24:33,120 --> 00:24:38,720
time in the lab right so in general the

604
00:24:35,679 --> 00:24:40,679
the computer human interface around AI

605
00:24:38,720 --> 00:24:42,880
for for materials and science is not a

606
00:24:40,679 --> 00:24:44,279
solved problem uh and then this this

607
00:24:42,880 --> 00:24:46,279
goes back to a point that I keep

608
00:24:44,279 --> 00:24:48,559
referring to like the AI doesn't make

609
00:24:46,279 --> 00:24:51,480
anything right and there is two layers

610
00:24:48,559 --> 00:24:53,600
of making in materials and chemistry

611
00:24:51,480 --> 00:24:56,320
there's the first layer of just making a

612
00:24:53,600 --> 00:24:59,039
tiny amount so we can see if the thing

613
00:24:56,320 --> 00:25:01,399
works which is one barrier

614
00:24:59,039 --> 00:25:04,480
and an in Pharma too and then there's a

615
00:25:01,399 --> 00:25:06,640
second of making a ton of it or many

616
00:25:04,480 --> 00:25:08,520
many tons of it to put it in in whatever

617
00:25:06,640 --> 00:25:10,880
your Market is right you're making

618
00:25:08,520 --> 00:25:13,480
Catalyst you know some of these big

619
00:25:10,880 --> 00:25:15,600
catalysts in in petrochemistry they load

620
00:25:13,480 --> 00:25:18,559
20 tons or 50 tons of catalyst in a

621
00:25:15,600 --> 00:25:21,600
single time the scaling is completely

622
00:25:18,559 --> 00:25:24,120
outside of of what AI can think about

623
00:25:21,600 --> 00:25:26,760
and then and you've seen this with with

624
00:25:24,120 --> 00:25:28,600
GPT these models don't really know when

625
00:25:26,760 --> 00:25:30,679
they're really really wrong right like

626
00:25:28,600 --> 00:25:32,960
there's you can go out of domain you

627
00:25:30,679 --> 00:25:34,720
train your model on on oxides and you

628
00:25:32,960 --> 00:25:36,880
ask it about Alloys about metallic

629
00:25:34,720 --> 00:25:38,520
Alloys instead of ceramic oxides and

630
00:25:36,880 --> 00:25:39,960
it's catastrophic but the model won't

631
00:25:38,520 --> 00:25:42,679
tell you it's catastrophic we just give

632
00:25:39,960 --> 00:25:45,240
you random numbers um so what's what's

633
00:25:42,679 --> 00:25:48,080
the happening today at the research

634
00:25:45,240 --> 00:25:50,240
level what is sort of the the solution

635
00:25:48,080 --> 00:25:53,440
to some of these things well what we

636
00:25:50,240 --> 00:25:56,600
call this the execution Gap uh and how

637
00:25:53,440 --> 00:25:58,799
are folks taking this on with autonomous

638
00:25:56,600 --> 00:26:01,960
Labs or programmable labs right that's

639
00:25:58,799 --> 00:26:05,880
how the AI the scientific intelligence

640
00:26:01,960 --> 00:26:07,720
gets hooked into enacting science not

641
00:26:05,880 --> 00:26:10,600
just thinking about science but doing

642
00:26:07,720 --> 00:26:12,840
science and that's with a lab that can

643
00:26:10,600 --> 00:26:14,679
be accessed through code and there's

644
00:26:12,840 --> 00:26:16,840
been examples for a few years this is

645
00:26:14,679 --> 00:26:20,559
sort of growing and growing these are

646
00:26:16,840 --> 00:26:22,360
two examples from last year um this is

647
00:26:20,559 --> 00:26:25,080
from from the other camp this a west

648
00:26:22,360 --> 00:26:28,600
coast exampler of Berkeley and this is

649
00:26:25,080 --> 00:26:31,559
from my my dear collaborator um uh Claus

650
00:26:28,600 --> 00:26:34,159
Jensen here at MIT chemical engineering

651
00:26:31,559 --> 00:26:36,840
we contributed AI to this but we didn't

652
00:26:34,159 --> 00:26:39,559
contribute the robot right making this

653
00:26:36,840 --> 00:26:42,240
requires mechanical engineers it

654
00:26:39,559 --> 00:26:44,840
requires you know Machining pieces it

655
00:26:42,240 --> 00:26:49,200
requires control people

656
00:26:44,840 --> 00:26:51,480
so making the AI actuate the real world

657
00:26:49,200 --> 00:26:56,279
turns out to be not really an AI problem

658
00:26:51,480 --> 00:26:58,440
at all and a automation um and sort of

659
00:26:56,279 --> 00:27:01,360
chemistry or materials or synthesis or

660
00:26:58,440 --> 00:27:03,480
processing problem altoe now in this

661
00:27:01,360 --> 00:27:06,880
particular example we were able to hook

662
00:27:03,480 --> 00:27:08,640
all the pieces in the space of dice

663
00:27:06,880 --> 00:27:10,960
molecules of a certain color so this

664
00:27:08,640 --> 00:27:13,360
wasn't phal compounds but it was

665
00:27:10,960 --> 00:27:15,399
chemical compounds uh with a desired

666
00:27:13,360 --> 00:27:19,520
color we were able

667
00:27:15,399 --> 00:27:21,120
to create a programmable lab that has

668
00:27:19,520 --> 00:27:25,159
moving pieces and can make chemistry

669
00:27:21,120 --> 00:27:27,720
happen on its own and the AI tools to

670
00:27:25,159 --> 00:27:30,760
design molecules with generative AI

671
00:27:27,720 --> 00:27:32,559
predict how to make them with

672
00:27:30,760 --> 00:27:34,640
retrosynthesis and access to the

673
00:27:32,559 --> 00:27:36,840
literature to recover literature

674
00:27:34,640 --> 00:27:38,760
information predict their properties

675
00:27:36,840 --> 00:27:40,159
with property prediction models like the

676
00:27:38,760 --> 00:27:42,799
graph neural networks I mentioned

677
00:27:40,159 --> 00:27:44,480
earlier quantify uncertainty to know how

678
00:27:42,799 --> 00:27:46,799
to make the itself

679
00:27:44,480 --> 00:27:50,000
better with rounds of

680
00:27:46,799 --> 00:27:52,279
learning uh and drive the whole cycle

681
00:27:50,000 --> 00:27:54,519
through and through three or four times

682
00:27:52,279 --> 00:27:56,159
autonomously I mean it's autonomous in

683
00:27:54,519 --> 00:28:00,120
the sense that most of the when it works

684
00:27:56,159 --> 00:28:01,640
it runs on its own if run out of solvent

685
00:28:00,120 --> 00:28:03,320
somebody gets a text message that they

686
00:28:01,640 --> 00:28:06,279
need to go replace the solvent so it's

687
00:28:03,320 --> 00:28:10,279
autonomous in its normal operation but

688
00:28:06,279 --> 00:28:12,600
obviously requires a human supervisor

689
00:28:10,279 --> 00:28:14,919
but not necessarily a co-pilot so here

690
00:28:12,600 --> 00:28:17,880
we are we're we're in a place where more

691
00:28:14,919 --> 00:28:19,600
data is better right llms worked because

692
00:28:17,880 --> 00:28:21,960
they could read of all the internet and

693
00:28:19,600 --> 00:28:25,679
all the copyrighted information out

694
00:28:21,960 --> 00:28:28,120
there uh scientific journals are are on

695
00:28:25,679 --> 00:28:29,600
to us uh and on to this practice

696
00:28:28,120 --> 00:28:31,640
practices and they're not letting people

697
00:28:29,600 --> 00:28:35,320
read papers right they know they hold a

698
00:28:31,640 --> 00:28:37,559
lot of value uh but somehow we need to

699
00:28:35,320 --> 00:28:40,240
integrate all of these data sets and all

700
00:28:37,559 --> 00:28:42,240
these modalities and try to achieve as

701
00:28:40,240 --> 00:28:45,600
much sort of scientific

702
00:28:42,240 --> 00:28:47,880
reasoning um as we can I I was making

703
00:28:45,600 --> 00:28:51,440
some changes here

704
00:28:47,880 --> 00:28:53,080
um uh at the last minute this is the

705
00:28:51,440 --> 00:28:55,240
slide that I brought over so sorry it's

706
00:28:53,080 --> 00:28:57,480
misformed but I I suspected you folks

707
00:28:55,240 --> 00:28:59,120
were going to uh to care about this this

708
00:28:57,480 --> 00:29:01,720
is what I was mention is sort of about

709
00:28:59,120 --> 00:29:04,080
this time these waves of things we've

710
00:29:01,720 --> 00:29:06,080
seen we saw small molecule drugs almost

711
00:29:04,080 --> 00:29:07,799
hit a peak there's some clinical trial

712
00:29:06,080 --> 00:29:09,960
results coming back I don't know if

713
00:29:07,799 --> 00:29:11,640
you're following the field but recursion

714
00:29:09,960 --> 00:29:13,799
has three or four clinical outcomes

715
00:29:11,640 --> 00:29:15,000
coming out this year so it's kind of

716
00:29:13,799 --> 00:29:16,559
it's

717
00:29:15,000 --> 00:29:19,720
uh

718
00:29:16,559 --> 00:29:21,120
H we're going to get our grades back in

719
00:29:19,720 --> 00:29:22,760
in the small molecule drugs but we

720
00:29:21,120 --> 00:29:23,840
already took the exam right like the ex

721
00:29:22,760 --> 00:29:26,320
Britain we're just waiting for the

722
00:29:23,840 --> 00:29:29,159
greates uh protein drugs happening right

723
00:29:26,320 --> 00:29:32,039
now and the material

724
00:29:29,159 --> 00:29:36,480
is is sort of you know a lot of

725
00:29:32,039 --> 00:29:38,880
big AI names have attached their names

726
00:29:36,480 --> 00:29:41,640
or their their activities to material

727
00:29:38,880 --> 00:29:43,960
design and sustainability work over the

728
00:29:41,640 --> 00:29:46,080
last you know three to six months so it

729
00:29:43,960 --> 00:29:48,559
has sort of a Time urgency and and an

730
00:29:46,080 --> 00:29:50,720
excitement to it um so with this I think

731
00:29:48,559 --> 00:29:53,320
I have 52 seconds left so I'll just

732
00:29:50,720 --> 00:29:55,600
thank the team thanks our sponsors and

733
00:29:53,320 --> 00:30:02,640
thank you so much for your time Fox

734
00:29:55,600 --> 00:30:04,600
[Applause]

735
00:30:02,640 --> 00:30:06,440
yes so there's a number of written

736
00:30:04,600 --> 00:30:08,440
questions it seems like what all the

737
00:30:06,440 --> 00:30:12,320
questions will be written

738
00:30:08,440 --> 00:30:14,760
yes yeah so the first question says uh

739
00:30:12,320 --> 00:30:19,880
the whether we can go from model to

740
00:30:14,760 --> 00:30:21,760
Theory um being that being uh analyzing

741
00:30:19,880 --> 00:30:24,159
models using other models extracting

742
00:30:21,760 --> 00:30:26,960
knowledge or are machine learning and

743
00:30:24,159 --> 00:30:29,320
Theory just too different um I didn't

744
00:30:26,960 --> 00:30:32,480
want to bore this community with details

745
00:30:29,320 --> 00:30:35,760
I believe machine learning and Theory

746
00:30:32,480 --> 00:30:38,120
simulations are kind of the same thing

747
00:30:35,760 --> 00:30:40,159
um so sorry if this is this is what you

748
00:30:38,120 --> 00:30:41,679
wanted to spend some time on I'm sorry

749
00:30:40,159 --> 00:30:44,360
we we I'm sure we get more chances to

750
00:30:41,679 --> 00:30:46,799
talk in our lives uh my personal belief

751
00:30:44,360 --> 00:30:48,679
on my group's whole research area is

752
00:30:46,799 --> 00:30:52,440
that there is a

753
00:30:48,679 --> 00:30:54,559
Continuum of computation that goes from

754
00:30:52,440 --> 00:30:56,880
places where you know all the physics

755
00:30:54,559 --> 00:30:59,039
and all the theory if you're making you

756
00:30:56,880 --> 00:31:00,320
know planes uh you pretty much don't

757
00:30:59,039 --> 00:31:01,840
need machine learning right we know the

758
00:31:00,320 --> 00:31:06,200
equations that govern the way planes

759
00:31:01,840 --> 00:31:08,440
work um to Alpha which is completely

760
00:31:06,200 --> 00:31:10,600
black box it doesn't really use any of

761
00:31:08,440 --> 00:31:12,360
the physics that we know and anything in

762
00:31:10,600 --> 00:31:14,519
between so there's a whole spectrum of

763
00:31:12,360 --> 00:31:16,519
places and you know Microsoft is doing

764
00:31:14,519 --> 00:31:18,679
this Google is doing this where you

765
00:31:16,519 --> 00:31:20,200
inject machine learning into simulations

766
00:31:18,679 --> 00:31:21,600
that you like but you make them faster

767
00:31:20,200 --> 00:31:24,919
or you make them more efficient or more

768
00:31:21,600 --> 00:31:27,159
accurate or you inject more physics

769
00:31:24,919 --> 00:31:29,720
understanding into machine learning to

770
00:31:27,159 --> 00:31:32,360
make the models more efficient or learn

771
00:31:29,720 --> 00:31:34,240
with less data there is something called

772
00:31:32,360 --> 00:31:37,039
equivariance which is having machine

773
00:31:34,240 --> 00:31:39,159
learning models obey the same symmetry

774
00:31:37,039 --> 00:31:41,679
as the real world so you know if you've

775
00:31:39,159 --> 00:31:45,279
got an arrow and you rotate your own

776
00:31:41,679 --> 00:31:47,679
position the arrow will rotate with you

777
00:31:45,279 --> 00:31:50,000
and machine models don't do that by

778
00:31:47,679 --> 00:31:51,639
default if you rotate the reference

779
00:31:50,000 --> 00:31:53,760
point the arrow still points in the old

780
00:31:51,639 --> 00:31:56,480
in the old Direction unless the models

781
00:31:53,760 --> 00:31:59,039
are equivariant and well that turns out

782
00:31:56,480 --> 00:32:01,600
to help a lot to learn so tasks but not

783
00:31:59,039 --> 00:32:02,559
others so yes I I do believe in that

784
00:32:01,600 --> 00:32:05,880
very big

785
00:32:02,559 --> 00:32:07,960
time uh yeah are we so the first one

786
00:32:05,880 --> 00:32:09,720
I'll just go by votes and try to be fast

787
00:32:07,960 --> 00:32:11,639
are we going to be able to generate

788
00:32:09,720 --> 00:32:14,159
enzymes that can catalyze reaction that

789
00:32:11,639 --> 00:32:17,320
will help remediation and detoxification

790
00:32:14,159 --> 00:32:20,480
at scale um I think the qu the answer is

791
00:32:17,320 --> 00:32:24,399
Big Time yes on the technical part so I

792
00:32:20,480 --> 00:32:27,360
think enzyme design is a subset of

793
00:32:24,399 --> 00:32:29,880
protein design um and that's just going

794
00:32:27,360 --> 00:32:31,600
to work you know we have we can we can

795
00:32:29,880 --> 00:32:34,080
express enzymes we can measure the

796
00:32:31,600 --> 00:32:35,919
activity in a Clos Loop we can fine-tune

797
00:32:34,080 --> 00:32:38,960
models that we train on General protein

798
00:32:35,919 --> 00:32:42,360
task so I think this Loop of enzyme

799
00:32:38,960 --> 00:32:45,240
Discovery is most likely to work whether

800
00:32:42,360 --> 00:32:48,159
this would be economical to actually do

801
00:32:45,240 --> 00:32:50,799
remediation out there is a much harder

802
00:32:48,159 --> 00:32:52,519
question and today AI won't help us

803
00:32:50,799 --> 00:32:56,559
answer that question technoeconomic

804
00:32:52,519 --> 00:32:59,919
analysis and and sort of market analysis

805
00:32:56,559 --> 00:33:02,880
um AI won't do that for us but enzymes

806
00:32:59,919 --> 00:33:04,320
are very expensive so most likely the

807
00:33:02,880 --> 00:33:06,279
the first answer the answer to that

808
00:33:04,320 --> 00:33:09,159
question was yes whether that will

809
00:33:06,279 --> 00:33:10,000
actually be useful in the real world is

810
00:33:09,159 --> 00:33:12,440
maybe

811
00:33:10,000 --> 00:33:14,120
not would you have examples where

812
00:33:12,440 --> 00:33:16,519
visualization and computation help

813
00:33:14,120 --> 00:33:18,360
people explore complex tradeoffs using

814
00:33:16,519 --> 00:33:21,919
these methods yes this a very good one

815
00:33:18,360 --> 00:33:24,679
thank you uh

816
00:33:21,919 --> 00:33:26,519
so actually we're used to very good

817
00:33:24,679 --> 00:33:29,760
human computer

818
00:33:26,519 --> 00:33:32,440
interfaces in general you know when you

819
00:33:29,760 --> 00:33:34,799
log in into your bank app or you go

820
00:33:32,440 --> 00:33:36,720
shopping in Amazon The Experience the

821
00:33:34,799 --> 00:33:39,600
way you interact with data has been

822
00:33:36,720 --> 00:33:42,600
curated by being really experts for many

823
00:33:39,600 --> 00:33:44,200
many years um so in that sense there's a

824
00:33:42,600 --> 00:33:47,760
lot to learn from the way people

825
00:33:44,200 --> 00:33:50,799
interact with data uh from those fields

826
00:33:47,760 --> 00:33:54,200
um in general this is a place where we

827
00:33:50,799 --> 00:33:58,639
my group have invested many cycles which

828
00:33:54,200 --> 00:34:01,720
is distilling and Mining

829
00:33:58,639 --> 00:34:05,080
AI outputs such that they can be handed

830
00:34:01,720 --> 00:34:07,679
off to a or passed on to a human being

831
00:34:05,080 --> 00:34:10,320
that can get you know excited about what

832
00:34:07,679 --> 00:34:12,280
thei is producing not overwhelmed about

833
00:34:10,320 --> 00:34:14,280
sort of the stream of of nonsense right

834
00:34:12,280 --> 00:34:15,599
if you let an AI model on its own it

835
00:34:14,280 --> 00:34:19,359
most likely going to produce a stream of

836
00:34:15,599 --> 00:34:21,839
nonsense so distill down compress apply

837
00:34:19,359 --> 00:34:24,520
all the filters whether AI or or rule

838
00:34:21,839 --> 00:34:26,679
base but in general yes that's a place

839
00:34:24,520 --> 00:34:28,520
where we've we've done I think we've

840
00:34:26,679 --> 00:34:30,760
spent a lot of work

841
00:34:28,520 --> 00:34:32,359
and all the projects that end up making

842
00:34:30,760 --> 00:34:34,760
something and you know we we file a

843
00:34:32,359 --> 00:34:36,800
pattern on a catalyst or we make a cool

844
00:34:34,760 --> 00:34:40,200
polymer that maybe can you know be a

845
00:34:36,800 --> 00:34:42,800
product all go through distilling data

846
00:34:40,200 --> 00:34:46,119
mining visualizing such that a human

847
00:34:42,800 --> 00:34:47,679
being can pick up the the the Baton and

848
00:34:46,119 --> 00:34:49,839
actually make something and tell us

849
00:34:47,679 --> 00:34:51,480
things back because then it's like well

850
00:34:49,839 --> 00:34:54,200
somebody presented this at a conference

851
00:34:51,480 --> 00:34:57,079
last year it's not a new IP right wasn't

852
00:34:54,200 --> 00:34:59,079
a so or this molecule you know it's too

853
00:34:57,079 --> 00:35:00,599
expensive why because this

854
00:34:59,079 --> 00:35:02,880
retrosynthesis recipe this thing is

855
00:35:00,599 --> 00:35:04,520
proposing uses platinum and we cannot

856
00:35:02,880 --> 00:35:07,839
afford the platinum in this material

857
00:35:04,520 --> 00:35:10,920
right so it's not only as showing uh

858
00:35:07,839 --> 00:35:13,119
data mining AI predictions for human

859
00:35:10,920 --> 00:35:16,680
beings but human beings being able to

860
00:35:13,119 --> 00:35:19,599
give actionable feedback back into the

861
00:35:16,680 --> 00:35:22,359
models let's see if we can do a couple

862
00:35:19,599 --> 00:35:24,320
more uh what is the best practice or

863
00:35:22,359 --> 00:35:26,040
state-of-the-art to apply AI for

864
00:35:24,320 --> 00:35:28,119
starting a new project on materials

865
00:35:26,040 --> 00:35:31,760
design

866
00:35:28,119 --> 00:35:34,119
so I would say I have a slide here of

867
00:35:31,760 --> 00:35:37,119
this this might be I skipped it because

868
00:35:34,119 --> 00:35:39,599
I was running a little bit fast

869
00:35:37,119 --> 00:35:41,520
and this is my experience when things

870
00:35:39,599 --> 00:35:44,280
have worked so maybe it would be sort of

871
00:35:41,520 --> 00:35:46,320
the answer to this is like that in our

872
00:35:44,280 --> 00:35:48,920
experience it needs to be something that

873
00:35:46,320 --> 00:35:51,560
you've measured before it seems hard to

874
00:35:48,920 --> 00:35:53,560
deploy AI on making something you've

875
00:35:51,560 --> 00:35:56,599
never made or thought about before so

876
00:35:53,560 --> 00:35:59,040
typically the B being able to measure

877
00:35:56,599 --> 00:36:02,480
knowing what the space looks like having

878
00:35:59,040 --> 00:36:04,119
some uh literature data to pre-train on

879
00:36:02,480 --> 00:36:06,440
that really helps actually in our

880
00:36:04,119 --> 00:36:08,160
experience having the model read all the

881
00:36:06,440 --> 00:36:10,599
literature before we start doing

882
00:36:08,160 --> 00:36:12,280
anything that seems really useful and

883
00:36:10,599 --> 00:36:15,240
then there needs to be some mechanism to

884
00:36:12,280 --> 00:36:16,839
create new data these cycles of learning

885
00:36:15,240 --> 00:36:20,240
they are a huge bottom leg because the

886
00:36:16,839 --> 00:36:22,040
model will obviously have gaps and you

887
00:36:20,240 --> 00:36:24,520
know especially in the context of this

888
00:36:22,040 --> 00:36:27,440
big data Paradigm I was talking about we

889
00:36:24,520 --> 00:36:29,560
need a lot of data to patch those gaps

890
00:36:27,440 --> 00:36:31,760
um so typically we need some mechanism

891
00:36:29,560 --> 00:36:33,680
for active learning and cycling so I

892
00:36:31,760 --> 00:36:38,240
would say I don't know if it's exactly

893
00:36:33,680 --> 00:36:38,240
best practices as a as a

894
00:36:38,880 --> 00:36:45,800
uh rule that I propose to you but it's

895
00:36:41,480 --> 00:36:48,119
definitely a experience that we've had

896
00:36:45,800 --> 00:36:51,839
um that sort of this this is the common

897
00:36:48,119 --> 00:36:51,839
denominator of of success

898
00:36:52,079 --> 00:36:56,640
here is large scale automated synthesis

899
00:36:54,760 --> 00:36:58,760
and testing really needed Oram more

900
00:36:56,640 --> 00:37:02,520
simulation and AI leverage to converse

901
00:36:58,760 --> 00:37:03,240
design finite element static Dynamics um

902
00:37:02,520 --> 00:37:08,480
I

903
00:37:03,240 --> 00:37:12,280
think yes it's like inclusive or H so

904
00:37:08,480 --> 00:37:14,160
both are true the handoff of one to

905
00:37:12,280 --> 00:37:18,079
another

906
00:37:14,160 --> 00:37:20,640
is a again a place where humans can make

907
00:37:18,079 --> 00:37:22,560
decisions typically when when I give a

908
00:37:20,640 --> 00:37:24,920
slightly more technical talk I have

909
00:37:22,560 --> 00:37:26,680
three examples of work we've done that

910
00:37:24,920 --> 00:37:30,160
has the bullets that you know the common

911
00:37:26,680 --> 00:37:32,800
denominators that showed before and one

912
00:37:30,160 --> 00:37:35,520
of them there were no robots whatsoever

913
00:37:32,800 --> 00:37:37,880
the AI predictions were filtered down

914
00:37:35,520 --> 00:37:40,240
passed on to human beings who then use

915
00:37:37,880 --> 00:37:42,319
their expertise could be convinced that

916
00:37:40,240 --> 00:37:44,000
this was a a good idea that it was worth

917
00:37:42,319 --> 00:37:46,200
their time that it align with their

918
00:37:44,000 --> 00:37:49,480
creativity that they have enough agency

919
00:37:46,200 --> 00:37:51,480
to so it use a lot of AI a lot of

920
00:37:49,480 --> 00:37:52,800
physics that we trusted we could be very

921
00:37:51,480 --> 00:37:54,560
predictive because we really know the

922
00:37:52,800 --> 00:37:56,520
lose of the game we could be very

923
00:37:54,560 --> 00:37:58,480
quantitative and very predictive the

924
00:37:56,520 --> 00:38:00,800
models would extrap at well right

925
00:37:58,480 --> 00:38:02,560
physics extrapolates much better than AI

926
00:38:00,800 --> 00:38:05,599
right the physics based models by

927
00:38:02,560 --> 00:38:07,920
definition are are made to generalize

928
00:38:05,599 --> 00:38:10,200
machinary models struggle to generalize

929
00:38:07,920 --> 00:38:12,839
so typically in our experience the more

930
00:38:10,200 --> 00:38:14,920
physics we have the less it needs to be

931
00:38:12,839 --> 00:38:17,160
a robot doing experiments because we

932
00:38:14,920 --> 00:38:19,960
kind of automate all the simulations and

933
00:38:17,160 --> 00:38:22,480
distill down really good ideas if things

934
00:38:19,960 --> 00:38:24,079
are more black box and we don't have a

935
00:38:22,480 --> 00:38:27,599
lot

936
00:38:24,079 --> 00:38:30,359
of physics base or scientific support

937
00:38:27,599 --> 00:38:31,960
and we're just trying things um that's

938
00:38:30,359 --> 00:38:33,520
kind of hard for for human beings you

939
00:38:31,960 --> 00:38:34,880
know there's not that many cycles of

940
00:38:33,520 --> 00:38:38,079
just trying things that you can do with

941
00:38:34,880 --> 00:38:40,119
human beings so typically the less we

942
00:38:38,079 --> 00:38:42,599
know about the nature of the problem the

943
00:38:40,119 --> 00:38:44,920
more we rely on large scale experimental

944
00:38:42,599 --> 00:38:47,240
efforts that could be done by humans

945
00:38:44,920 --> 00:38:49,040
right like if you have a grad student

946
00:38:47,240 --> 00:38:51,960
technicians that can do five experiments

947
00:38:49,040 --> 00:38:54,359
a day for you know 300 days a year

948
00:38:51,960 --> 00:38:56,359
that's enough data right so the question

949
00:38:54,359 --> 00:39:00,000
is what's the sort of you know what are

950
00:38:56,359 --> 00:39:03,040
the reproducibility motivation cost

951
00:39:00,000 --> 00:39:04,800
tradeoffs between human and robotized

952
00:39:03,040 --> 00:39:05,920
experimentation so maybe we have time

953
00:39:04,800 --> 00:39:09,079
for one

954
00:39:05,920 --> 00:39:10,920
more um oh yeah what's the state of

955
00:39:09,079 --> 00:39:13,839
multimodal understanding in chemistry

956
00:39:10,920 --> 00:39:15,359
and materials and what do we foresee as

957
00:39:13,839 --> 00:39:19,160
initiatives in this

958
00:39:15,359 --> 00:39:21,240
regard so it's about to happen so it's

959
00:39:19,160 --> 00:39:23,240
going to happen hasn't happened yet we

960
00:39:21,240 --> 00:39:27,680
really haven't seen a lot of multimodal

961
00:39:23,240 --> 00:39:30,920
training and typically in chemistry the

962
00:39:27,680 --> 00:39:33,119
typical modality is a lot of chemical

963
00:39:30,920 --> 00:39:35,760
structures and the properties so it's

964
00:39:33,119 --> 00:39:37,640
just one modality um and then all the

965
00:39:35,760 --> 00:39:38,920
synthesis story we were just describing

966
00:39:37,640 --> 00:39:41,000
right where you can have sort of how to

967
00:39:38,920 --> 00:39:43,480
make stuff so I think these haven't

968
00:39:41,000 --> 00:39:47,599
really been orchestrated yet I think

969
00:39:43,480 --> 00:39:50,480
will likely happen structure to property

970
00:39:47,599 --> 00:39:51,960
synthesis to structure I think those two

971
00:39:50,480 --> 00:39:53,040
you know if you know I don't know if

972
00:39:51,960 --> 00:39:54,480
it's going to be berley I don't know if

973
00:39:53,040 --> 00:39:58,240
it's going to be us I don't know if it's

974
00:39:54,480 --> 00:40:00,720
going to be a company um but these two

975
00:39:58,240 --> 00:40:03,040
things will get orchestrated

976
00:40:00,720 --> 00:40:05,400
alongside large language models reading

977
00:40:03,040 --> 00:40:06,920
the literature right the only blocking

978
00:40:05,400 --> 00:40:09,760
element for large language models really

979
00:40:06,920 --> 00:40:11,839
in the literature is licenses from the

980
00:40:09,760 --> 00:40:14,319
from the Publishers right everything

981
00:40:11,839 --> 00:40:18,960
else is sort of technically trivial so I

982
00:40:14,319 --> 00:40:21,079
think it's coming um I think the lab

983
00:40:18,960 --> 00:40:23,440
part of this will be a couple more years

984
00:40:21,079 --> 00:40:25,720
I think coordinating this with Machine

985
00:40:23,440 --> 00:40:27,960
Vision to know how to you know pour a

986
00:40:25,720 --> 00:40:29,200
liquid so you can shake it

987
00:40:27,960 --> 00:40:33,319
that's going to be a little bit longer

988
00:40:29,200 --> 00:40:35,599
so I would say digital multimodal yes

989
00:40:33,319 --> 00:40:38,640
physical

990
00:40:35,599 --> 00:40:40,480
actionable lab multimodal will take a

991
00:40:38,640 --> 00:40:41,920
little bit longer and I think we're up

992
00:40:40,480 --> 00:40:46,119
to time so thank you very much folks for

993
00:40:41,920 --> 00:40:46,119
your time thank you thank you


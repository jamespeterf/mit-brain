1
00:00:00,000 --> 00:00:08,160
Our final speaker today is Brian Leu, a

2
00:00:04,720 --> 00:00:11,679
PhD candidate at MIT's Operations

3
00:00:08,160 --> 00:00:15,040
Research Center. Before MIT, Brian was a

4
00:00:11,679 --> 00:00:18,160
data and applied scientists at Microsoft

5
00:00:15,040 --> 00:00:20,720
and he brings a strong technical lens to

6
00:00:18,160 --> 00:00:23,439
today's conversation. Brian will discuss

7
00:00:20,720 --> 00:00:26,400
a research collaboration between HSI and

8
00:00:23,439 --> 00:00:28,560
Amwell Silvercloud utilizing health

9
00:00:26,400 --> 00:00:32,960
analytics to enhance engagement and

10
00:00:28,560 --> 00:00:33,760
effectiveness. Take it away, Brian.

11
00:00:32,960 --> 00:00:36,160
>> Uh, cool.

12
00:00:33,760 --> 00:00:37,920
>> So, yeah, thanks everyone. And then, um,

13
00:00:36,160 --> 00:00:39,760
I'll just be quickly talking about kind

14
00:00:37,920 --> 00:00:41,360
of some of the more in detailed research

15
00:00:39,760 --> 00:00:43,680
that we're doing in this collaboration.

16
00:00:41,360 --> 00:00:45,920
And this is joint work with, uh, Petro,

17
00:00:43,680 --> 00:00:47,680
who's also a PhD student in the OC, and

18
00:00:45,920 --> 00:00:50,640
with our adviser, uh, Professor Rupul

19
00:00:47,680 --> 00:00:52,480
Munder, who's associate professor at the

20
00:00:50,640 --> 00:00:55,640
operations research and statistics group

21
00:00:52,480 --> 00:00:55,640
at Sloan.

22
00:00:55,840 --> 00:00:59,440
So um what we're kind of interested in

23
00:00:57,600 --> 00:01:01,199
our collaboration is kind of developing

24
00:00:59,440 --> 00:01:03,280
models to better explore patient

25
00:01:01,199 --> 00:01:05,119
behavior on the silvercloud platform.

26
00:01:03,280 --> 00:01:06,560
And one thing kind of from the start we

27
00:01:05,119 --> 00:01:08,320
noticed with silvercloud is that we they

28
00:01:06,560 --> 00:01:10,479
gave us uh very rich data. So we have

29
00:01:08,320 --> 00:01:12,960
patient demographics we have information

30
00:01:10,479 --> 00:01:15,040
about the supporters even usage logs

31
00:01:12,960 --> 00:01:17,040
kind of timestamp data points every time

32
00:01:15,040 --> 00:01:19,200
a uh patient even interacts with their

33
00:01:17,040 --> 00:01:20,560
platform as well as feedback. So we're

34
00:01:19,200 --> 00:01:22,479
actually very excited to receive this

35
00:01:20,560 --> 00:01:24,320
kind of like large uh amount of real

36
00:01:22,479 --> 00:01:25,520
world data that we can kind of apply to

37
00:01:24,320 --> 00:01:28,320
several methods that we have been

38
00:01:25,520 --> 00:01:30,159
developing uh to analyze.

39
00:01:28,320 --> 00:01:31,920
So kind of uh at the high level what

40
00:01:30,159 --> 00:01:35,119
we're interested in uh modeling or

41
00:01:31,920 --> 00:01:37,040
predicting is first patient outcomes. So

42
00:01:35,119 --> 00:01:38,880
uh a patient enters the platform, they

43
00:01:37,040 --> 00:01:40,240
complete uh modules and they leave the

44
00:01:38,880 --> 00:01:43,759
platform and then we kind of have a

45
00:01:40,240 --> 00:01:45,280
start and an end score. And um from this

46
00:01:43,759 --> 00:01:46,560
we can kind of determine how much the

47
00:01:45,280 --> 00:01:48,799
patient improves, whether there's

48
00:01:46,560 --> 00:01:50,720
reliable improvement uh both for their

49
00:01:48,799 --> 00:01:52,720
uh silvercloud programs for anxiety and

50
00:01:50,720 --> 00:01:54,479
for depression.

51
00:01:52,720 --> 00:01:55,840
And we're also also interested in

52
00:01:54,479 --> 00:01:57,119
looking at patient engagement. So this

53
00:01:55,840 --> 00:01:58,640
is kind of whether or not they complete

54
00:01:57,119 --> 00:02:01,119
the program. Some patients they start

55
00:01:58,640 --> 00:02:03,040
the program, they abandon. And also kind

56
00:02:01,119 --> 00:02:06,000
of how often do they use the program? So

57
00:02:03,040 --> 00:02:08,239
like the duration that they spend per

58
00:02:06,000 --> 00:02:11,360
session and how that progresses through

59
00:02:08,239 --> 00:02:13,680
uh through their time with SilverCloud.

60
00:02:11,360 --> 00:02:15,360
And one kind of goal we have uh like

61
00:02:13,680 --> 00:02:18,400
overarching goal is we're not interested

62
00:02:15,360 --> 00:02:20,319
in just making models to predict these

63
00:02:18,400 --> 00:02:22,319
outcomes or engagement metrics. Well,

64
00:02:20,319 --> 00:02:24,400
we're also interested in understanding

65
00:02:22,319 --> 00:02:26,239
what various factors whether it's on the

66
00:02:24,400 --> 00:02:27,760
silvercloud side, the patient side

67
00:02:26,239 --> 00:02:29,599
contribute towards these types of

68
00:02:27,760 --> 00:02:32,000
patient behaviors such as uh successful

69
00:02:29,599 --> 00:02:33,760
treatment outcomes.

70
00:02:32,000 --> 00:02:35,440
So this is actually what we found kind

71
00:02:33,760 --> 00:02:38,080
of very early on in our collaboration is

72
00:02:35,440 --> 00:02:40,560
that it's it's a very difficult uh like

73
00:02:38,080 --> 00:02:42,319
process right um you have a lot of data

74
00:02:40,560 --> 00:02:45,599
uh for patient outcomes the kind of

75
00:02:42,319 --> 00:02:47,280
signal is very noisy and what we ended

76
00:02:45,599 --> 00:02:49,040
up doing is we actually determined that

77
00:02:47,280 --> 00:02:50,400
we need really like uh complex like

78
00:02:49,040 --> 00:02:52,560
state-of-the-art machine learning models

79
00:02:50,400 --> 00:02:56,319
such as like boosted tree ensembles to

80
00:02:52,560 --> 00:02:58,239
get models that perform well. Now while

81
00:02:56,319 --> 00:03:00,319
these models perform well they're

82
00:02:58,239 --> 00:03:02,239
actually very complicated and difficult

83
00:03:00,319 --> 00:03:05,040
to interpret.

84
00:03:02,239 --> 00:03:06,480
So kind of uh the models we use just

85
00:03:05,040 --> 00:03:08,000
like uh for example like one of our

86
00:03:06,480 --> 00:03:10,319
favorite models are like uh gradient

87
00:03:08,000 --> 00:03:12,239
boosted decision trees and these

88
00:03:10,319 --> 00:03:14,400
basically just generate a bunch of

89
00:03:12,239 --> 00:03:17,120
decision trees to form a complex model

90
00:03:14,400 --> 00:03:19,680
that predicts um predicts a prediction

91
00:03:17,120 --> 00:03:21,599
target. And just kind of a sample of

92
00:03:19,680 --> 00:03:23,200
what we're looking at here is uh on this

93
00:03:21,599 --> 00:03:26,080
picture this is just like a sample of

94
00:03:23,200 --> 00:03:27,760
500 500 tree boosting ensemble. And this

95
00:03:26,080 --> 00:03:30,000
is actually kind of a small smallest

96
00:03:27,760 --> 00:03:32,159
model by like most uh modern machine

97
00:03:30,000 --> 00:03:34,239
learning standards. And even from this

98
00:03:32,159 --> 00:03:36,239
it's like almost impossible to determine

99
00:03:34,239 --> 00:03:38,239
looking at this model what's going on.

100
00:03:36,239 --> 00:03:39,920
So this model is very useful for making

101
00:03:38,239 --> 00:03:42,000
predictions. However, for actually

102
00:03:39,920 --> 00:03:44,239
understanding what's in the data, this

103
00:03:42,000 --> 00:03:46,400
model is not so great.

104
00:03:44,239 --> 00:03:47,760
And in kind of the field of like

105
00:03:46,400 --> 00:03:49,440
interpretability in machine learning,

106
00:03:47,760 --> 00:03:51,040
this is a pretty well-known trade-off.

107
00:03:49,440 --> 00:03:52,720
You have like your modern ML methods

108
00:03:51,040 --> 00:03:54,879
like random forests, gradient boosted

109
00:03:52,720 --> 00:03:56,640
trees, your like modern foundation

110
00:03:54,879 --> 00:03:58,159
models, language models, they're

111
00:03:56,640 --> 00:04:00,640
excellent at making predictions.

112
00:03:58,159 --> 00:04:02,720
However, they're actually very poor at

113
00:04:00,640 --> 00:04:04,400
kind of revealing patterns in the data.

114
00:04:02,720 --> 00:04:06,080
Versus a lot of the classical methods

115
00:04:04,400 --> 00:04:07,920
such as like decision trees, linear

116
00:04:06,080 --> 00:04:09,599
regression, these models are a lot

117
00:04:07,920 --> 00:04:11,120
simpler. They're easier to understand.

118
00:04:09,599 --> 00:04:13,040
You can kind of determine what's going

119
00:04:11,120 --> 00:04:14,959
on. However, in terms of prediction

120
00:04:13,040 --> 00:04:17,919
prediction accuracy, they perform very

121
00:04:14,959 --> 00:04:19,600
poorly. So, what we kind of do for our

122
00:04:17,919 --> 00:04:22,240
research is we develop methods that kind

123
00:04:19,600 --> 00:04:24,560
of explore this trade-off. We try to get

124
00:04:22,240 --> 00:04:26,080
uh like we kind of start with high

125
00:04:24,560 --> 00:04:27,680
performing models like random forests

126
00:04:26,080 --> 00:04:29,120
and trees and we see we can extract

127
00:04:27,680 --> 00:04:33,520
models that are simpler but still

128
00:04:29,120 --> 00:04:35,440
perform well and still however um you

129
00:04:33,520 --> 00:04:37,840
can look at these simple models and

130
00:04:35,440 --> 00:04:40,320
determine more useful insights about the

131
00:04:37,840 --> 00:04:41,520
data. So this is kind of a sample of

132
00:04:40,320 --> 00:04:43,280
like the relevant research we've been

133
00:04:41,520 --> 00:04:45,680
doing in the past few years on this

134
00:04:43,280 --> 00:04:47,520
field.

135
00:04:45,680 --> 00:04:49,360
So um I'll just kind of conclude with a

136
00:04:47,520 --> 00:04:51,840
quick demonstration on kind of what we

137
00:04:49,360 --> 00:04:53,759
did with the silvercloud data is we are

138
00:04:51,840 --> 00:04:56,160
interested in for example in predicting

139
00:04:53,759 --> 00:04:59,120
uh whether or not patients exhibit

140
00:04:56,160 --> 00:05:01,040
reliable improvement for uh anxiety

141
00:04:59,120 --> 00:05:03,199
treatment. And we start with this model

142
00:05:01,040 --> 00:05:04,960
large model. This is the large tree that

143
00:05:03,199 --> 00:05:07,120
performs well. And we compress this

144
00:05:04,960 --> 00:05:08,960
model into a much smaller distilled

145
00:05:07,120 --> 00:05:10,479
model. And from this model we can

146
00:05:08,960 --> 00:05:14,880
actually get interesting insights about

147
00:05:10,479 --> 00:05:16,800
the data. So one key point is going from

148
00:05:14,880 --> 00:05:18,080
the full model to the compact model we

149
00:05:16,800 --> 00:05:19,360
actually get very very similar

150
00:05:18,080 --> 00:05:20,479
performance. And this is actually a new

151
00:05:19,360 --> 00:05:23,680
method that we developed that's

152
00:05:20,479 --> 00:05:25,759
currently under review. And the

153
00:05:23,680 --> 00:05:27,759
extracted model is small enough to be uh

154
00:05:25,759 --> 00:05:30,000
examined by hand. So in this extracted

155
00:05:27,759 --> 00:05:31,680
model every single uh kind of structure

156
00:05:30,000 --> 00:05:33,039
here is a rule. It's like a single

157
00:05:31,680 --> 00:05:35,360
sentence that describes what's going on

158
00:05:33,039 --> 00:05:37,440
in the data. And you can look at and

159
00:05:35,360 --> 00:05:40,800
examine each of these rules to get an

160
00:05:37,440 --> 00:05:43,840
idea of what factors in um impact

161
00:05:40,800 --> 00:05:46,160
successful treatment outcomes.

162
00:05:43,840 --> 00:05:47,759
Cool. So I think uh that's uh coming up

163
00:05:46,160 --> 00:05:50,759
about time. So yeah, happy to take any

164
00:05:47,759 --> 00:05:50,759
questions.

165
00:05:51,360 --> 00:05:57,039
>> Um thank thanks Brian. Um, I suspect

166
00:05:54,720 --> 00:05:59,759
that some folks may be really interested

167
00:05:57,039 --> 00:06:02,000
in this and some folks may have not ever

168
00:05:59,759 --> 00:06:04,479
seen this before, but um, this is the

169
00:06:02,000 --> 00:06:07,199
kind of work we do here at MIT and it's

170
00:06:04,479 --> 00:06:08,479
very exciting. So can you talk a little

171
00:06:07,199 --> 00:06:12,160
bit when you're when you're doing this

172
00:06:08,479 --> 00:06:14,560
and you ended up with your 12 rules um

173
00:06:12,160 --> 00:06:16,560
or in any other part of this can you

174
00:06:14,560 --> 00:06:18,960
share a little bit of a of something of

175
00:06:16,560 --> 00:06:20,800
a s what surprised you about the

176
00:06:18,960 --> 00:06:22,720
research you were doing here and and

177
00:06:20,800 --> 00:06:25,280
what did you do next when you you know

178
00:06:22,720 --> 00:06:26,960
ran into such a surprise?

179
00:06:25,280 --> 00:06:28,800
Uh one one thing that I think was uh

180
00:06:26,960 --> 00:06:30,639
pretty interesting was I think at first

181
00:06:28,800 --> 00:06:32,720
uh when we just like started uh fitting

182
00:06:30,639 --> 00:06:34,960
models it actually even with kind of

183
00:06:32,720 --> 00:06:36,000
like the modern ML methods we had

184
00:06:34,960 --> 00:06:37,440
trouble getting good predictive

185
00:06:36,000 --> 00:06:40,479
performance and it required a lot of

186
00:06:37,440 --> 00:06:42,240
like kind of um almost like manually

187
00:06:40,479 --> 00:06:43,759
like engineering features from the data.

188
00:06:42,240 --> 00:06:45,440
So we looked at a lot of things like for

189
00:06:43,759 --> 00:06:47,840
every single like patient who's assigned

190
00:06:45,440 --> 00:06:49,360
a supporter, how many other patients the

191
00:06:47,840 --> 00:06:50,560
supporter has like supporter workload

192
00:06:49,360 --> 00:06:51,919
experience and it was actually quite a

193
00:06:50,560 --> 00:06:55,680
surprise to see that those actually had

194
00:06:51,919 --> 00:06:57,039
a influence on like um patient outcomes.

195
00:06:55,680 --> 00:07:00,000
So like how how experienced the

196
00:06:57,039 --> 00:07:01,919
supporters were and things like that.

197
00:07:00,000 --> 00:07:04,240
>> So that actually has a lot of practical

198
00:07:01,919 --> 00:07:07,599
potentially practical implications and

199
00:07:04,240 --> 00:07:10,319
that um that you can work on with with

200
00:07:07,599 --> 00:07:11,199
Anel and and the uh ML Silver Cloud

201
00:07:10,319 --> 00:07:12,560
team.

202
00:07:11,199 --> 00:07:14,720
>> Yeah. Yeah, definitely.

203
00:07:12,560 --> 00:07:17,360
>> All right. Well, I am looking at the

204
00:07:14,720 --> 00:07:20,479
time and we seem to have filled an hour.

205
00:07:17,360 --> 00:07:23,520
So, I'm going to turn it back over to um

206
00:07:20,479 --> 00:07:23,520
to Jim.


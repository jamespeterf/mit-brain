1
00:00:04,020 --> 00:00:05,190
- My name is Daniela Rus.

2
00:00:05,190 --> 00:00:07,080
I'm the director of the Computer Science

3
00:00:07,080 --> 00:00:10,110
and Artificial Intelligence
Laboratory at MIT,

4
00:00:10,110 --> 00:00:13,140
the place where the future
of computing takes flight.

5
00:00:13,140 --> 00:00:17,100
Our laboratory has deep
roots in two powerhouses,

6
00:00:17,100 --> 00:00:20,370
the AI lab and the laboratory
for computer science.

7
00:00:20,370 --> 00:00:22,680
Now we have a lot of projects at CSAIL

8
00:00:22,680 --> 00:00:25,110
in a lot of different areas, but today

9
00:00:25,110 --> 00:00:27,810
we are going to focus
on our machine friends.

10
00:00:27,810 --> 00:00:29,073
Let's go take a look.

11
00:00:31,380 --> 00:00:32,490
Hello Joseph.

12
00:00:32,490 --> 00:00:33,750
What are you working on today?

13
00:00:33,750 --> 00:00:34,583
- Hi Daniela.

14
00:00:34,583 --> 00:00:36,270
I've been working on some of our wearables

15
00:00:36,270 --> 00:00:39,130
for interacting with robots
and with other animals.

16
00:00:39,130 --> 00:00:41,049
- Why do we want wearables to interact

17
00:00:41,049 --> 00:00:42,690
with robots and animals?

18
00:00:42,690 --> 00:00:45,030
- So we wanna make it easier for anyone

19
00:00:45,030 --> 00:00:46,410
to interact with robots.

20
00:00:46,410 --> 00:00:47,910
And you know, right now
it can be a little hard

21
00:00:47,910 --> 00:00:49,590
to learn the robot's language,

22
00:00:49,590 --> 00:00:52,440
but if we could just use
someone's natural muscle signals

23
00:00:52,440 --> 00:00:54,690
or even their motion or brain signals,

24
00:00:54,690 --> 00:00:56,340
then it could be a lot more intuitive.

25
00:00:56,340 --> 00:00:58,590
- So what does Stretch do today?

26
00:00:58,590 --> 00:01:01,830
- So Stretch is responding
to a lot of the gestures

27
00:01:01,830 --> 00:01:03,720
that I'm making, based on a neural network

28
00:01:03,720 --> 00:01:05,670
processing my muscle signals.

29
00:01:05,670 --> 00:01:07,950
- So can you make Stretch
shake hands with me?

30
00:01:07,950 --> 00:01:09,870
- So if I squeeze my fist,

31
00:01:09,870 --> 00:01:12,000
then Stretch will close its gripper.

32
00:01:12,000 --> 00:01:15,360
- What are we going to use
these intuitive motions for?

33
00:01:15,360 --> 00:01:16,980
- I always wanted a robot to help me

34
00:01:16,980 --> 00:01:17,920
around the kitchen actually. So.

35
00:01:17,920 --> 00:01:19,140
- Like a sous chef?

36
00:01:19,140 --> 00:01:21,990
- Exactly. So we've been
using a lot of wearables

37
00:01:21,990 --> 00:01:24,150
to record how people do kitchen tasks,

38
00:01:24,150 --> 00:01:27,060
like peeling cucumbers, slicing potatoes,

39
00:01:27,060 --> 00:01:29,340
or setting the table, and
then hopefully the robot

40
00:01:29,340 --> 00:01:32,160
can learn from those demonstrations
and those interactions.

41
00:01:32,160 --> 00:01:33,840
- So what else are we working on?

42
00:01:33,840 --> 00:01:36,570
- This is actually a device
that we've been developing

43
00:01:36,570 --> 00:01:38,700
along with Rob Woods' lab at Harvard

44
00:01:38,700 --> 00:01:41,580
and it allows us to probe the mysteries

45
00:01:41,580 --> 00:01:43,410
of how whales actually communicate

46
00:01:43,410 --> 00:01:45,240
and learn more about their culture.

47
00:01:45,240 --> 00:01:49,200
This is placed on a whale and
holds on using suction cups

48
00:01:49,200 --> 00:01:51,240
and then it has a lot
of different sensors.

49
00:01:51,240 --> 00:01:54,330
It has underwater microphones,
it has depth sensors,

50
00:01:54,330 --> 00:01:56,550
temperature sensors, motion sensors,

51
00:01:56,550 --> 00:01:58,170
and maybe even biosignal sensors

52
00:01:58,170 --> 00:01:59,760
that we've been looking at adding.

53
00:01:59,760 --> 00:02:03,266
And this allows us to get
a great multimodal view

54
00:02:03,266 --> 00:02:05,640
of how the whale is behaving and hopefully

55
00:02:05,640 --> 00:02:08,400
we can build up a data set
that lets us understand

56
00:02:08,400 --> 00:02:12,060
more about their language
and their culture.

57
00:02:12,060 --> 00:02:13,200
- How do you collect this data?

58
00:02:13,200 --> 00:02:15,930
How do you attach the tag onto the whale?

59
00:02:15,930 --> 00:02:18,390
- Yeah, so we go out and
we listen for the whales,

60
00:02:18,390 --> 00:02:20,940
using microphones to
find them and then we go

61
00:02:20,940 --> 00:02:24,840
and attach the tag to the
whale, either using a long pole

62
00:02:24,840 --> 00:02:27,690
or using drones, and
we try to be as gentle

63
00:02:27,690 --> 00:02:29,520
and as minimally invasive as possible

64
00:02:29,520 --> 00:02:31,530
so the whales don't really notice it.

65
00:02:31,530 --> 00:02:33,660
We actually had a recent expedition

66
00:02:33,660 --> 00:02:35,490
where we got to be really
close to the whales

67
00:02:35,490 --> 00:02:37,890
and we were lucky enough to
even see a whale giving birth.

68
00:02:37,890 --> 00:02:39,870
- That's amazing. Can you show it?

69
00:02:39,870 --> 00:02:43,350
- Yeah, we actually had a
lot of drones in the air.

70
00:02:43,350 --> 00:02:46,440
We had microphones underwater
and people on the boat.

71
00:02:46,440 --> 00:02:49,560
We were all recording this amazing event

72
00:02:49,560 --> 00:02:51,870
and this is an example
of where I synchronized

73
00:02:51,870 --> 00:02:53,430
all the different
devices so you can see it

74
00:02:53,430 --> 00:02:54,600
from many different angles

75
00:02:54,600 --> 00:02:56,760
and get all of the
different data we recorded.

76
00:02:56,760 --> 00:02:59,580
So we have drone footage
showing it from up above.

77
00:02:59,580 --> 00:03:01,800
We have all our cameras from the boat,

78
00:03:01,800 --> 00:03:05,880
we have the audio recordings
as well as the GPS positions.

79
00:03:05,880 --> 00:03:08,460
So this will hopefully
allow us to learn more

80
00:03:08,460 --> 00:03:12,930
about how they approach
this multi-species event

81
00:03:12,930 --> 00:03:14,070
and celebration.

82
00:03:14,070 --> 00:03:17,580
- Studying artificial
intelligence and robotics

83
00:03:17,580 --> 00:03:21,240
is teaching us a lot, not
just about the technology,

84
00:03:21,240 --> 00:03:24,720
but also about ourselves, about life

85
00:03:24,720 --> 00:03:28,620
and about this wonderful
place we get to live on,

86
00:03:28,620 --> 00:03:32,913
the place Carl Sagan used
to call the pale blue dot.

87
00:03:33,780 --> 00:03:36,930
Let's go check out some
modular robotic cubes.

88
00:03:36,930 --> 00:03:39,390
This way. Hi John.

89
00:03:39,390 --> 00:03:40,223
- Hi Daniela.

90
00:03:40,223 --> 00:03:41,158
- How are you today?

91
00:03:41,158 --> 00:03:41,991
- I'm doing pretty well.

92
00:03:41,991 --> 00:03:42,824
- And how is Belty doing today?

93
00:03:42,824 --> 00:03:44,520
- So Belty is doing pretty good.

94
00:03:44,520 --> 00:03:46,080
He wants to show you a
demo where he picks up

95
00:03:46,080 --> 00:03:48,630
and relocates a block, and
you can sort of imagine this

96
00:03:48,630 --> 00:03:51,690
as like industrial Legos so
that you could have factories

97
00:03:51,690 --> 00:03:54,190
and buildings that sort
of reconfigure themselves.

98
00:03:56,430 --> 00:03:57,963
- Wow, that was amazing.

99
00:03:59,760 --> 00:04:01,650
- So now he's trying to
interface with a different robot

100
00:04:01,650 --> 00:04:02,823
to drop off this block.

101
00:04:06,060 --> 00:04:07,680
- John, that's really very cool.

102
00:04:07,680 --> 00:04:09,450
But why would we want to do this?

103
00:04:09,450 --> 00:04:12,360
- Our current industrial
system is not very flexible,

104
00:04:12,360 --> 00:04:16,320
scalable, and when we have
disruptions like the pandemic

105
00:04:16,320 --> 00:04:19,080
or other disruptions,
basically we can't respond

106
00:04:19,080 --> 00:04:19,913
fast enough to them.

107
00:04:19,913 --> 00:04:22,050
And having factories modular should help

108
00:04:22,050 --> 00:04:23,760
make that more effective.

109
00:04:23,760 --> 00:04:26,730
- So response basically
means making all the products

110
00:04:26,730 --> 00:04:30,210
that we need at the time we need them.

111
00:04:30,210 --> 00:04:33,960
And with a system, we can
begin to imagine factories

112
00:04:33,960 --> 00:04:36,420
that have cell reconfiguring gantries,

113
00:04:36,420 --> 00:04:39,213
where the gantries will
automatically adapt

114
00:04:39,213 --> 00:04:41,910
to the production need.

115
00:04:41,910 --> 00:04:45,900
Right now it takes a
long time to reconfigure

116
00:04:45,900 --> 00:04:47,940
and redesign gantry systems.

117
00:04:47,940 --> 00:04:51,510
With this approach, we will
have much more agile factories.

118
00:04:51,510 --> 00:04:53,100
John, and where do we go from here?

119
00:04:53,100 --> 00:04:55,620
- I think my next step after graduating

120
00:04:55,620 --> 00:04:58,440
is to try to figure out a way
to potentially open source

121
00:04:58,440 --> 00:05:01,140
this idea and get multiple
researchers working together

122
00:05:01,140 --> 00:05:03,750
to create sort of the the specifications

123
00:05:03,750 --> 00:05:05,430
for modular factories.

124
00:05:05,430 --> 00:05:07,290
- Graduation is soon, right?

125
00:05:07,290 --> 00:05:08,970
- Graduation is about a month.

126
00:05:08,970 --> 00:05:10,860
I have a lot of hard work ahead of me.

127
00:05:10,860 --> 00:05:13,526
- Well I look forward
to seeing Belty's feet

128
00:05:13,526 --> 00:05:15,180
in a month's time.

129
00:05:15,180 --> 00:05:16,013
- Thank you.

130
00:05:16,013 --> 00:05:18,870
- Let's go see what's happening
at the robot locomotion lab.

131
00:05:18,870 --> 00:05:20,610
Come on over. Hi Russ.

132
00:05:20,610 --> 00:05:23,370
- Hi Daniela. Welcome to
the robot locomotion group.

133
00:05:23,370 --> 00:05:25,050
- What are you working on today?

134
00:05:25,050 --> 00:05:26,940
- Well we've got robots all around you.

135
00:05:26,940 --> 00:05:28,620
We've been doing a lot
of things over the years.

136
00:05:28,620 --> 00:05:30,420
We do flying robots, as you know.

137
00:05:30,420 --> 00:05:32,820
We do humanoid robots, but these days

138
00:05:32,820 --> 00:05:34,470
we're making robots play with their hands.

139
00:05:34,470 --> 00:05:35,730
- Amazing. Tell me more.

140
00:05:35,730 --> 00:05:36,870
- The world's changing.

141
00:05:36,870 --> 00:05:39,750
We have big generative
AI, and now we're trying

142
00:05:39,750 --> 00:05:41,820
to make sure we understand
how to make generative AI

143
00:05:41,820 --> 00:05:43,410
work for robots with hands,

144
00:05:43,410 --> 00:05:45,480
- You mean you're studying the interaction

145
00:05:45,480 --> 00:05:46,720
aspect of intelligence?

146
00:05:46,720 --> 00:05:48,120
- Yeah, and there's big questions.

147
00:05:48,120 --> 00:05:49,560
We don't really know how much data

148
00:05:49,560 --> 00:05:50,970
is gonna be required to feed this.

149
00:05:50,970 --> 00:05:52,590
We don't know where
we're gonna get the data.

150
00:05:52,590 --> 00:05:54,210
So we already have a couple bets.

151
00:05:54,210 --> 00:05:56,520
One of them is to bet on simulation

152
00:05:56,520 --> 00:05:59,760
plus some really good control
design and simulation.

153
00:05:59,760 --> 00:06:01,560
- Amazing. Can we see some demos?

154
00:06:01,560 --> 00:06:04,560
- We have a bi-manual
robot, which means two arms,

155
00:06:04,560 --> 00:06:05,730
working with two hands,

156
00:06:05,730 --> 00:06:07,710
and doing some complicated
motion planning.

157
00:06:07,710 --> 00:06:09,900
And then I'll show you
something else on a quadruped.

158
00:06:09,900 --> 00:06:13,170
And these are examples
of of really good plans

159
00:06:13,170 --> 00:06:17,130
that we can make slowly,
but generate a lot of data

160
00:06:17,130 --> 00:06:19,260
and feed a data pipeline.

161
00:06:19,260 --> 00:06:23,160
- I'm so excited to see this
integration of language,

162
00:06:23,160 --> 00:06:24,870
perception and control,

163
00:06:24,870 --> 00:06:26,940
which are the hallmarks of intelligence.

164
00:06:26,940 --> 00:06:30,300
- I agree. This here is a bi-manual setup

165
00:06:30,300 --> 00:06:32,790
I was telling you about,
having two robots work

166
00:06:32,790 --> 00:06:35,640
in perfect harmony and
doing complex motions

167
00:06:35,640 --> 00:06:38,430
in and out of obstacles
is still a hard problem.

168
00:06:38,430 --> 00:06:41,220
Tommy here has been really
making a lot of progress

169
00:06:41,220 --> 00:06:42,420
on that and he's gonna
tell you a little bit

170
00:06:42,420 --> 00:06:43,980
about our new experiment.

171
00:06:43,980 --> 00:06:45,510
- If you're holding an object, you sort

172
00:06:45,510 --> 00:06:47,340
of fix your hands together.

173
00:06:47,340 --> 00:06:49,140
So anytime you move one
of the arms, the other

174
00:06:49,140 --> 00:06:50,810
has to move perfectly to stay in sync

175
00:06:50,810 --> 00:06:53,070
or you'll drop the
object, or if it's fragile

176
00:06:53,070 --> 00:06:54,840
you might break it.

177
00:06:54,840 --> 00:06:58,020
So we've been working on some
code that allows us to control

178
00:06:58,020 --> 00:07:00,210
and plan for the robot
arms in a very precise way

179
00:07:00,210 --> 00:07:01,500
so as to accomplish that.

180
00:07:01,500 --> 00:07:03,450
So as you can see here,
we're gonna move each

181
00:07:03,450 --> 00:07:06,060
of the joints individually
in that left arm

182
00:07:06,060 --> 00:07:08,490
and then the right arm has to
take very complicated motions

183
00:07:08,490 --> 00:07:10,830
in order to maintain that constraint.

184
00:07:10,830 --> 00:07:13,440
- So this part isn't the end
goal, this is just showing you

185
00:07:13,440 --> 00:07:16,050
that we've got the map right
and understand how to work

186
00:07:16,050 --> 00:07:18,420
with the hands perfectly in sync.

187
00:07:18,420 --> 00:07:20,130
- And the last bit here,
we can even move one

188
00:07:20,130 --> 00:07:22,280
of the arms without
moving its hand at all.

189
00:07:25,050 --> 00:07:28,230
- Okay, now we wanna show
you the real demo here,

190
00:07:28,230 --> 00:07:30,900
where we put some shelves
up in front of the robot

191
00:07:30,900 --> 00:07:32,850
and make it a little bit more crowded,

192
00:07:32,850 --> 00:07:34,200
so the robot has to figure it out.

193
00:07:34,200 --> 00:07:36,000
- The new planning framework we're using

194
00:07:36,000 --> 00:07:38,490
is something called graph of convex sets.

195
00:07:38,490 --> 00:07:41,400
One of the benefits it gives
us is we can get very strong

196
00:07:41,400 --> 00:07:43,410
collision-free guarantees.

197
00:07:43,410 --> 00:07:45,870
So we know the robot's not
gonna bump into anything.

198
00:07:45,870 --> 00:07:47,280
Normally we're a little uneasy

199
00:07:47,280 --> 00:07:49,440
to bring the robots
this close to obstacles,

200
00:07:49,440 --> 00:07:52,620
but we're so confident in the
methodology we're using here

201
00:07:52,620 --> 00:07:54,690
that we're willing to cut it really close.

202
00:07:54,690 --> 00:07:55,980
And as it's doing this you can see

203
00:07:55,980 --> 00:07:58,380
that it's really maintaining the distance

204
00:07:58,380 --> 00:08:00,280
and the orientation between its hands.

205
00:08:01,740 --> 00:08:05,490
- This is our spot robot
from Boston Dynamics here.

206
00:08:05,490 --> 00:08:06,600
We showed you a little bit about

207
00:08:06,600 --> 00:08:08,910
how we're doing advanced motion planning

208
00:08:08,910 --> 00:08:11,430
with two arms attached to a table.

209
00:08:11,430 --> 00:08:13,290
But we've been working
hard now on trying to get

210
00:08:13,290 --> 00:08:15,810
a mobile manipulator, a legged robot here,

211
00:08:15,810 --> 00:08:18,900
to do the same kind of
beautiful motion plans

212
00:08:18,900 --> 00:08:20,400
but use its entire body.

213
00:08:20,400 --> 00:08:22,680
So let me put this down here on the robot

214
00:08:22,680 --> 00:08:24,540
and see if you can get
Spot to pick it up, David.

215
00:08:24,540 --> 00:08:25,800
- In the following motion, we will have

216
00:08:25,800 --> 00:08:30,800
GCS plan in 25 dimensions
to move back, grab

217
00:08:31,050 --> 00:08:35,340
the little robot and try to
place it between its legs.

218
00:08:35,340 --> 00:08:36,450
- Sounds great.

219
00:08:36,450 --> 00:08:37,283
- Let's do it.

220
00:08:49,080 --> 00:08:51,450
- Why do we care so much
about doing whole body motion

221
00:08:51,450 --> 00:08:53,190
planning on a quadruped here?

222
00:08:53,190 --> 00:08:57,270
- Previously, many
quadrupeds came without arms,

223
00:08:57,270 --> 00:08:59,940
so they do purely locomotion

224
00:08:59,940 --> 00:09:02,460
and don't do much manipulation
in the real world.

225
00:09:02,460 --> 00:09:04,950
On stationary robots, we do
care about collision-free

226
00:09:04,950 --> 00:09:07,200
motion planning and generating fast

227
00:09:07,200 --> 00:09:10,590
and good-looking trajectories
and think it is time

228
00:09:10,590 --> 00:09:15,590
to combine both of that so
we can do mobile manipulation

229
00:09:16,080 --> 00:09:19,890
and have a useful robot, not
only someone mounted on a desk,

230
00:09:19,890 --> 00:09:23,340
but traverse through
(indistinct) environment

231
00:09:23,340 --> 00:09:25,890
and help in other places.

232
00:09:25,890 --> 00:09:26,850
- Yeah, this robot is great.

233
00:09:26,850 --> 00:09:30,480
This can walk all over campus
and now we're gonna make it

234
00:09:30,480 --> 00:09:33,600
so it can manipulate
objects wherever it goes.

235
00:09:33,600 --> 00:09:35,430
- Let's see it move a little bit.

236
00:09:35,430 --> 00:09:36,730
- Looks good. Let's do it.

237
00:09:46,759 --> 00:09:47,592
- Hi Gabe.

238
00:09:48,540 --> 00:09:49,530
- Hi Daniela.

239
00:09:49,530 --> 00:09:51,930
- What are you working on
and who's your new friend?

240
00:09:51,930 --> 00:09:53,190
- In the improbable AI lab here,

241
00:09:53,190 --> 00:09:55,680
we've been working on
different combinations

242
00:09:55,680 --> 00:09:57,690
of locomotion and manipulation.

243
00:09:57,690 --> 00:09:59,820
Previously we were working on Dribble bot,

244
00:09:59,820 --> 00:10:01,140
which is a soccer playing robot.

245
00:10:01,140 --> 00:10:03,570
And now we're really interested
in sort of what happens

246
00:10:03,570 --> 00:10:06,540
if we take this quadruped and
we mount an arm on the top.

247
00:10:06,540 --> 00:10:10,050
- So what's the difference
between this one and Dribble bot?

248
00:10:10,050 --> 00:10:11,409
- This robot is a lot
bigger, and the reason

249
00:10:11,409 --> 00:10:14,250
for its large size is so
it can support the arm,

250
00:10:14,250 --> 00:10:17,430
which is heavier, but the
advantage that we'll have

251
00:10:17,430 --> 00:10:19,770
from using the arm is that we can

252
00:10:19,770 --> 00:10:22,320
actually do some interesting manipulation.

253
00:10:22,320 --> 00:10:24,690
So instead of just kicking
objects with its feet,

254
00:10:24,690 --> 00:10:27,270
the robot can walk
around and touch objects,

255
00:10:27,270 --> 00:10:28,830
which will be useful
in lots of environments

256
00:10:28,830 --> 00:10:30,570
like a kitchen, where
we need to accomplish

257
00:10:30,570 --> 00:10:31,933
some manipulation tasks.

258
00:10:31,933 --> 00:10:33,538
- Can it move the objects around?

259
00:10:33,538 --> 00:10:37,890
Can it plan for how to
organize your kitchen?

260
00:10:37,890 --> 00:10:39,240
- Right now we're really focusing

261
00:10:39,240 --> 00:10:41,550
on the low level controls of the robot.

262
00:10:41,550 --> 00:10:44,520
So how can the walking and
grasping be coordinated?

263
00:10:44,520 --> 00:10:46,500
For example, if the
robot needs to reach up

264
00:10:46,500 --> 00:10:48,960
to a really high cabinet,
it might actually have

265
00:10:48,960 --> 00:10:52,350
to stretch its legs or
even move a small object

266
00:10:52,350 --> 00:10:54,960
to step up on top of
it in order to reach up

267
00:10:54,960 --> 00:10:56,100
to that cabinet.

268
00:10:56,100 --> 00:10:58,230
- So it's learning some gymnastics.

269
00:10:58,230 --> 00:11:00,180
- Yeah, yeah. In a sense.

270
00:11:00,180 --> 00:11:01,200
- Can we see?

271
00:11:01,200 --> 00:11:02,820
- Yeah, we can do a little motion around,

272
00:11:02,820 --> 00:11:07,080
it's actually operated by
a virtual reality headset

273
00:11:07,080 --> 00:11:10,650
and so our operator will move
that arm around a little bit.

274
00:11:10,650 --> 00:11:13,623
- Oh, it's wanting to dance
or stretch or something.

275
00:11:15,270 --> 00:11:17,280
- You can see that if it wants
to reach low to the ground,

276
00:11:17,280 --> 00:11:19,740
it kind of needs to bend its legs down.

277
00:11:19,740 --> 00:11:21,090
- Yeah, it's very interesting.

278
00:11:21,090 --> 00:11:22,950
The control is very smooth.

279
00:11:22,950 --> 00:11:24,810
- Because of the learning-based
approach that we use.

280
00:11:24,810 --> 00:11:26,790
It can avoid some of
the like singularities

281
00:11:26,790 --> 00:11:27,810
that you might get when the arm

282
00:11:27,810 --> 00:11:29,940
is outstretched all that way.

283
00:11:29,940 --> 00:11:31,080
What we're really building I think,

284
00:11:31,080 --> 00:11:34,530
is a teleoperation interface
for providing demonstrations.

285
00:11:34,530 --> 00:11:38,250
And the challenge of course is
that with such a large robot

286
00:11:38,250 --> 00:11:39,510
with high degrees of freedom,

287
00:11:39,510 --> 00:11:41,820
the human operator might have a hard time

288
00:11:41,820 --> 00:11:43,380
telling the robot
exactly what it should do

289
00:11:43,380 --> 00:11:44,310
in every scenario.

290
00:11:44,310 --> 00:11:47,430
- Well, Gabe, you know that
upstairs we have a kitchen

291
00:11:47,430 --> 00:11:50,220
where we're studying how humans perform

292
00:11:50,220 --> 00:11:53,730
the kind of prep tasks
that are needed in cooking.

293
00:11:53,730 --> 00:11:57,030
And perhaps we can get the
robots to be a sous chef

294
00:11:57,030 --> 00:11:58,920
for our human chefs.

295
00:11:58,920 --> 00:12:00,786
- Definitely. I think in
a few months we should

296
00:12:00,786 --> 00:12:01,950
bring 'em up and and give it a try.

297
00:12:01,950 --> 00:12:03,300
- Gabe, that was so awesome.

298
00:12:03,300 --> 00:12:06,030
Thank you so much for
showing us your new friend

299
00:12:06,030 --> 00:12:07,440
and I really look forward

300
00:12:07,440 --> 00:12:10,830
to seeing it in the kitchen helping us.

301
00:12:10,830 --> 00:12:12,660
- Thank you. Looking forward to it too.

302
00:12:12,660 --> 00:12:14,560
- All right, have a nice day. Bye-Bye.

303
00:12:15,690 --> 00:12:17,310
Thank you for joining us

304
00:12:17,310 --> 00:12:19,680
to meet our machine friends at C Cell.

305
00:12:19,680 --> 00:12:21,393
See you on the next tour.


1
00:00:11,120 --> 00:00:17,039
So um today we're going to cover an

2
00:00:14,080 --> 00:00:20,240
introduction to time series analysis and

3
00:00:17,039 --> 00:00:23,199
time series analysis is really a very

4
00:00:20,240 --> 00:00:24,720
sort of powerful meth methodology in

5
00:00:23,199 --> 00:00:27,279
statistics

6
00:00:24,720 --> 00:00:29,920
um and especially uh powerful when it

7
00:00:27,279 --> 00:00:33,760
comes to modeling uh financial markets.

8
00:00:29,920 --> 00:00:38,079
So I hope you'll find this introduction

9
00:00:33,760 --> 00:00:42,160
engaging and motivating. Um so let's

10
00:00:38,079 --> 00:00:45,680
talk about time series. Uh we basically

11
00:00:42,160 --> 00:00:50,160
have notation indicating a stochcastic

12
00:00:45,680 --> 00:00:53,760
process where x corresponds to the value

13
00:00:50,160 --> 00:00:59,760
of the process at time t

14
00:00:53,760 --> 00:01:01,840
and the time periods t can be discrete.

15
00:00:59,760 --> 00:01:06,400
This is most commonly what we'll work

16
00:01:01,840 --> 00:01:11,520
with. Uh but it can also correspond to a

17
00:01:06,400 --> 00:01:15,600
continuous time interval. And so uh we

18
00:01:11,520 --> 00:01:18,799
can imagine basically time periods u uh

19
00:01:15,600 --> 00:01:24,560
time indexed by uh positive numbers from

20
00:01:18,799 --> 00:01:29,600
zero. And in terms of modeling such a

21
00:01:24,560 --> 00:01:33,920
time series um we want to be able to

22
00:01:29,600 --> 00:01:39,040
specify the probability model for any

23
00:01:33,920 --> 00:01:41,840
collection of time point values. So when

24
00:01:39,040 --> 00:01:46,079
we say let's specify a probability model

25
00:01:41,840 --> 00:01:48,399
for a time series then that corresponds

26
00:01:46,079 --> 00:01:49,920
to being able to specify the joint

27
00:01:48,399 --> 00:01:53,600
density

28
00:01:49,920 --> 00:01:55,759
of any set of points. Here we have m

29
00:01:53,600 --> 00:01:59,920
different time points.

30
00:01:55,759 --> 00:02:04,159
This generalizes to all cases of m and

31
00:01:59,920 --> 00:02:08,959
uh such a subset of the values of the

32
00:02:04,159 --> 00:02:12,239
process are uh a finite dimensional uh

33
00:02:08,959 --> 00:02:16,879
set of values and so we'll have finite

34
00:02:12,239 --> 00:02:21,680
dimensional distributions for xt.

35
00:02:16,879 --> 00:02:25,040
Now, uh, importantly, we'll want to

36
00:02:21,680 --> 00:02:27,200
consider time series that are strictly

37
00:02:25,040 --> 00:02:30,400
stationary.

38
00:02:27,200 --> 00:02:34,720
And a strictly stationary time series is

39
00:02:30,400 --> 00:02:37,920
one for which the distribution of any

40
00:02:34,720 --> 00:02:42,720
set of time points

41
00:02:37,920 --> 00:02:46,319
um is equal to the distribution of the

42
00:02:42,720 --> 00:02:50,400
same time points shifted by a constant.

43
00:02:46,319 --> 00:02:54,879
So if we're looking at

44
00:02:50,400 --> 00:02:58,400
the index of time and we have xt um if

45
00:02:54,879 --> 00:03:05,920
we look at say four points here

46
00:02:58,400 --> 00:03:09,519
t1 t2 t3 t4 then the distribution of the

47
00:03:05,920 --> 00:03:13,200
values at these time points will be the

48
00:03:09,519 --> 00:03:15,280
same as the distribution if we shift

49
00:03:13,200 --> 00:03:19,599
these time points all by the same

50
00:03:15,280 --> 00:03:24,400
amount. toao. So t2 plus toao and so

51
00:03:19,599 --> 00:03:26,159
forth. So we basically have that in this

52
00:03:24,400 --> 00:03:28,480
window

53
00:03:26,159 --> 00:03:30,799
and in this window

54
00:03:28,480 --> 00:03:35,200
the distribution of outcomes is the

55
00:03:30,799 --> 00:03:39,519
same. So what does that mean? Well, that

56
00:03:35,200 --> 00:03:42,799
means that if there's a mean value

57
00:03:39,519 --> 00:03:45,920
in this period, then it's the same mean

58
00:03:42,799 --> 00:03:48,480
value in this other period as well as

59
00:03:45,920 --> 00:03:50,400
all possible periods. So we basically

60
00:03:48,480 --> 00:03:53,280
have

61
00:03:50,400 --> 00:03:57,439
a probability model

62
00:03:53,280 --> 00:04:00,959
that is constrained in terms of the

63
00:03:57,439 --> 00:04:03,360
level being horizontal

64
00:04:00,959 --> 00:04:06,400
and the amount of spread about that

65
00:04:03,360 --> 00:04:12,319
level is constant.

66
00:04:06,400 --> 00:04:14,239
Now with statistics we like to estimate

67
00:04:12,319 --> 00:04:16,479
parameters.

68
00:04:14,239 --> 00:04:18,880
Parameters like a sample mean are very

69
00:04:16,479 --> 00:04:22,720
easy to estimate. We get a sample of

70
00:04:18,880 --> 00:04:26,800
values and estimate the population mean

71
00:04:22,720 --> 00:04:30,320
with the sample mean. And so we're may

72
00:04:26,800 --> 00:04:33,199
be familiar with estimating constants

73
00:04:30,320 --> 00:04:36,320
and estimating means of populations is

74
00:04:33,199 --> 00:04:40,800
is a you know trivial example example of

75
00:04:36,320 --> 00:04:44,240
that. With stationary time series, we

76
00:04:40,800 --> 00:04:46,800
want to consider

77
00:04:44,240 --> 00:04:50,320
perhaps a transform of our time series

78
00:04:46,800 --> 00:04:53,840
to a stationary scale and then there

79
00:04:50,320 --> 00:04:56,880
will be parameters of that distribution

80
00:04:53,840 --> 00:04:59,600
that we can estimate and we can estimate

81
00:04:56,880 --> 00:05:02,800
them because

82
00:04:59,600 --> 00:05:04,639
the distribution is the same basically

83
00:05:02,800 --> 00:05:07,600
across the whole range. So there's some

84
00:05:04,639 --> 00:05:09,440
hope that we'll be able to uh specify

85
00:05:07,600 --> 00:05:13,919
parameters

86
00:05:09,440 --> 00:05:17,759
uh consistently and with high precision.

87
00:05:13,919 --> 00:05:21,120
Now um

88
00:05:17,759 --> 00:05:24,880
uh a less strict

89
00:05:21,120 --> 00:05:27,280
um stationerity condition is called

90
00:05:24,880 --> 00:05:30,320
covariant stationerity.

91
00:05:27,280 --> 00:05:33,360
And with covariant stationerity,

92
00:05:30,320 --> 00:05:36,320
we're looking just at the first and

93
00:05:33,360 --> 00:05:40,240
second order sort of expectations

94
00:05:36,320 --> 00:05:42,560
of the time series values. So the mean

95
00:05:40,240 --> 00:05:47,600
value of xt

96
00:05:42,560 --> 00:05:51,440
will be a constant mu for all t

97
00:05:47,600 --> 00:05:55,520
and the variance of xt

98
00:05:51,440 --> 00:05:58,320
will also not depend on the time t. it

99
00:05:55,520 --> 00:06:01,919
will be stationary or constant over the

100
00:05:58,320 --> 00:06:09,039
time range and the co-variance

101
00:06:01,919 --> 00:06:12,720
of values that are tow units apart will

102
00:06:09,039 --> 00:06:15,360
have a co-variance that simply is a

103
00:06:12,720 --> 00:06:18,319
function of how far apart the time

104
00:06:15,360 --> 00:06:21,039
points are. So

105
00:06:18,319 --> 00:06:24,560
here um you know we're looking basically

106
00:06:21,039 --> 00:06:27,280
at sort of a mean level mu and maybe

107
00:06:24,560 --> 00:06:30,000
plus or minus the square root of the

108
00:06:27,280 --> 00:06:31,919
variance of xt

109
00:06:30,000 --> 00:06:35,520
uh being

110
00:06:31,919 --> 00:06:37,680
the lower and upper

111
00:06:35,520 --> 00:06:41,440
levels here. And then if we're

112
00:06:37,680 --> 00:06:45,840
interested in looking at how correlated

113
00:06:41,440 --> 00:06:48,000
different time values are then if we

114
00:06:45,840 --> 00:06:55,800
consider

115
00:06:48,000 --> 00:06:55,800
say t and t plus toao I guess

116
00:06:57,680 --> 00:07:03,919
and we also consider another t prime and

117
00:07:00,880 --> 00:07:06,800
t prime plus toao

118
00:07:03,919 --> 00:07:09,520
over here. Then when we have

119
00:07:06,800 --> 00:07:12,000
realizations of the process, they're

120
00:07:09,520 --> 00:07:14,960
going to be staying within

121
00:07:12,000 --> 00:07:19,520
a few standard deviations of the mean

122
00:07:14,960 --> 00:07:23,440
and the correlation between values at

123
00:07:19,520 --> 00:07:26,800
different time points will be the same

124
00:07:23,440 --> 00:07:29,599
if the distance the the time period

125
00:07:26,800 --> 00:07:31,280
between those time points are the same.

126
00:07:29,599 --> 00:07:34,639
So

127
00:07:31,280 --> 00:07:38,800
so those that's covariant stationerity.

128
00:07:34,639 --> 00:07:42,400
Now with such uh time series that are

129
00:07:38,800 --> 00:07:46,400
co-variance stationary then we can look

130
00:07:42,400 --> 00:07:50,880
at the autocorrelation function

131
00:07:46,400 --> 00:07:53,919
and the correlation between xt and xt

132
00:07:50,880 --> 00:07:55,520
plus toao is the covariance between the

133
00:07:53,919 --> 00:07:58,240
two

134
00:07:55,520 --> 00:07:59,919
divided by the square root of the

135
00:07:58,240 --> 00:08:02,160
product of the variances. So these are

136
00:07:59,919 --> 00:08:04,800
familiar formulas generally for

137
00:08:02,160 --> 00:08:06,720
correlations and we call them

138
00:08:04,800 --> 00:08:09,520
autocorrelations because we're looking

139
00:08:06,720 --> 00:08:11,680
at the correlation of a time series with

140
00:08:09,520 --> 00:08:14,960
itself

141
00:08:11,680 --> 00:08:17,960
and so we have row of t is the

142
00:08:14,960 --> 00:08:17,960
autocorrelation.

143
00:08:18,560 --> 00:08:25,360
Now let's take a look at some uh

144
00:08:21,520 --> 00:08:29,520
financial time series. Uh let's begin

145
00:08:25,360 --> 00:08:32,240
with just looking at the S&P 500 index.

146
00:08:29,520 --> 00:08:37,760
So this is the

147
00:08:32,240 --> 00:08:42,000
uh value of the 500 major stocks in the

148
00:08:37,760 --> 00:08:46,240
US equity market. And this is from I

149
00:08:42,000 --> 00:08:48,880
think 2011 to 2020 plus. And you can see

150
00:08:46,240 --> 00:08:52,480
how this over that period of time

151
00:08:48,880 --> 00:08:54,800
trended up with some dramatic uh drops

152
00:08:52,480 --> 00:08:59,360
due to co

153
00:08:54,800 --> 00:09:03,440
and with such a time series

154
00:08:59,360 --> 00:09:06,080
um it's clearly not stationary

155
00:09:03,440 --> 00:09:08,800
because it's trending over time. If we

156
00:09:06,080 --> 00:09:11,920
looked at different bands of years, they

157
00:09:08,800 --> 00:09:15,600
have different means. And so we really

158
00:09:11,920 --> 00:09:18,720
cannot uh consider this scaling of the

159
00:09:15,600 --> 00:09:20,320
index to be uh stationary or coariant

160
00:09:18,720 --> 00:09:23,440
stationary.

161
00:09:20,320 --> 00:09:27,920
And what ends up happening with many

162
00:09:23,440 --> 00:09:29,760
many financial time series is that we

163
00:09:27,920 --> 00:09:36,160
consider

164
00:09:29,760 --> 00:09:41,360
the time series YT say to correspond to

165
00:09:36,160 --> 00:09:46,959
a random walk model on the log scale.

166
00:09:41,360 --> 00:09:50,640
So if we were to look at

167
00:09:46,959 --> 00:09:53,640
taking the log of the series

168
00:09:50,640 --> 00:09:53,640
and

169
00:10:02,160 --> 00:10:06,440
look at the increments of that

170
00:10:09,200 --> 00:10:13,800
this is the log return

171
00:10:16,959 --> 00:10:21,040
of yt.

172
00:10:19,200 --> 00:10:24,480
Then

173
00:10:21,040 --> 00:10:28,000
the value of yt

174
00:10:24,480 --> 00:10:30,240
is going to be an initial value y knot

175
00:10:28,000 --> 00:10:33,680
times the exponential of the sum of

176
00:10:30,240 --> 00:10:38,480
these log returns.

177
00:10:33,680 --> 00:10:42,240
And we can relate these log returns

178
00:10:38,480 --> 00:10:45,440
to the uh percent returns on a

179
00:10:42,240 --> 00:10:49,279
fractional scale.

180
00:10:45,440 --> 00:10:55,760
This is log of 1 + rt

181
00:10:49,279 --> 00:11:01,360
where rt is equal to yt minus ytus one

182
00:10:55,760 --> 00:11:04,160
over uh yt minus one.

183
00:11:01,360 --> 00:11:08,320
Um

184
00:11:04,160 --> 00:11:13,440
so what will commonly be the case is

185
00:11:08,320 --> 00:11:15,920
that this sequence of log returns is

186
00:11:13,440 --> 00:11:18,959
coariant stationary.

187
00:11:15,920 --> 00:11:21,600
And so what I'd like to do next is to

188
00:11:18,959 --> 00:11:26,399
look at some time series plots of

189
00:11:21,600 --> 00:11:29,839
different financial time series and see

190
00:11:26,399 --> 00:11:34,000
whether this transformation

191
00:11:29,839 --> 00:11:36,320
uh to log returns seems to make the

192
00:11:34,000 --> 00:11:42,399
series appear stationary.

193
00:11:36,320 --> 00:11:44,880
So here's the S&P 500 index. Um these

194
00:11:42,399 --> 00:11:48,079
graphs here actually update the graph

195
00:11:44,880 --> 00:11:50,320
from before to uh the end of uh

196
00:11:48,079 --> 00:11:51,839
September.

197
00:11:50,320 --> 00:11:57,040
And

198
00:11:51,839 --> 00:12:00,880
if we change initially the

199
00:11:57,040 --> 00:12:03,680
absolute price to the log of the price,

200
00:12:00,880 --> 00:12:08,480
um you'll notice that sort of an

201
00:12:03,680 --> 00:12:12,560
exponential growth tends to transform to

202
00:12:08,480 --> 00:12:14,639
a linear growth on the log scale.

203
00:12:12,560 --> 00:12:18,079
And

204
00:12:14,639 --> 00:12:21,120
that comment is uh representing the fact

205
00:12:18,079 --> 00:12:23,600
that the lower panel follows more of a

206
00:12:21,120 --> 00:12:26,000
straight line path than the upper panel

207
00:12:23,600 --> 00:12:30,000
which has perhaps some exponential

208
00:12:26,000 --> 00:12:34,560
curvature to it. Now if we look at the

209
00:12:30,000 --> 00:12:37,680
uh monthly log returns,

210
00:12:34,560 --> 00:12:40,639
we can see that

211
00:12:37,680 --> 00:12:44,160
those monthly

212
00:12:40,639 --> 00:12:47,200
increments on the log scale

213
00:12:44,160 --> 00:12:50,320
have basically a flat time series

214
00:12:47,200 --> 00:12:55,040
process. And so it's rather consistent

215
00:12:50,320 --> 00:12:57,600
with this, you know, movement across

216
00:12:55,040 --> 00:13:04,320
a level that in this case is close to

217
00:12:57,600 --> 00:13:09,200
zero um with constant variance. Now with

218
00:13:04,320 --> 00:13:14,320
this data, we might consider looking at

219
00:13:09,200 --> 00:13:17,440
the distribution of these log returns

220
00:13:14,320 --> 00:13:20,160
and see whether they're consistent with

221
00:13:17,440 --> 00:13:23,920
a normal model just as a benchmark

222
00:13:20,160 --> 00:13:27,760
example that we might use. And here's

223
00:13:23,920 --> 00:13:30,000
the uh uh fitted normal curve to the

224
00:13:27,760 --> 00:13:31,440
data. And

225
00:13:30,000 --> 00:13:35,240
you know, would you say that this is a

226
00:13:31,440 --> 00:13:35,240
good fit to the data?

227
00:13:35,600 --> 00:13:41,440
Do I see any nods or shakes? I think you

228
00:13:39,920 --> 00:13:45,040
had a shake.

229
00:13:41,440 --> 00:13:48,440
>> Um it looks like relative weight like it

230
00:13:45,040 --> 00:13:48,440
falls like

231
00:13:48,800 --> 00:13:57,760
>> right. Yeah. And so um the true height

232
00:13:53,360 --> 00:14:01,519
is basically uh the realized values that

233
00:13:57,760 --> 00:14:03,839
are close to the mean and the normal fit

234
00:14:01,519 --> 00:14:08,320
is sort of underestimating those values

235
00:14:03,839 --> 00:14:10,880
that are close and complementing that

236
00:14:08,320 --> 00:14:12,720
the tails of the distribution maybe are

237
00:14:10,880 --> 00:14:16,800
underestimating the magnitude of the

238
00:14:12,720 --> 00:14:21,040
tails as well. And so this property is a

239
00:14:16,800 --> 00:14:24,160
property that is called lepto kurtosis

240
00:14:21,040 --> 00:14:28,720
and which means sort of slender. Uh

241
00:14:24,160 --> 00:14:30,560
lepto is Greek for slender. Um and then

242
00:14:28,720 --> 00:14:33,839
so let's take a look at what happens if

243
00:14:30,560 --> 00:14:36,880
we look at weekly returns.

244
00:14:33,839 --> 00:14:39,279
Okay, with weekly returns

245
00:14:36,880 --> 00:14:41,440
we get an again a series that appears to

246
00:14:39,279 --> 00:14:43,519
be fairly flat.

247
00:14:41,440 --> 00:14:48,000
The volatility though looks like it

248
00:14:43,519 --> 00:14:51,279
maybe isn't stable. So the variation of

249
00:14:48,000 --> 00:14:56,480
the uh time series at different time

250
00:14:51,279 --> 00:14:59,839
points may not be constant. It certainly

251
00:14:56,480 --> 00:15:02,639
was extreme during the COVID crisis

252
00:14:59,839 --> 00:15:05,279
um as evident here. And here's again the

253
00:15:02,639 --> 00:15:08,240
normal curve which has the s the same

254
00:15:05,279 --> 00:15:11,199
properties noted before. And then here's

255
00:15:08,240 --> 00:15:13,120
the daily log returns.

256
00:15:11,199 --> 00:15:17,120
So looking at a higher frequency

257
00:15:13,120 --> 00:15:20,720
measurements, we again get this property

258
00:15:17,120 --> 00:15:24,079
of sort of a stability in the mean, but

259
00:15:20,720 --> 00:15:26,000
maybe not a stability or stationerity in

260
00:15:24,079 --> 00:15:29,760
the variance.

261
00:15:26,000 --> 00:15:32,560
And again, the normal model doesn't look

262
00:15:29,760 --> 00:15:36,480
like it's uh appropriate. and it

263
00:15:32,560 --> 00:15:39,680
captures a a center and a spread, but

264
00:15:36,480 --> 00:15:43,199
uh seems to be far off near the mean and

265
00:15:39,680 --> 00:15:46,560
far away. Okay, let's take a look at

266
00:15:43,199 --> 00:15:50,720
Amazon stock. So, we're just going to

267
00:15:46,560 --> 00:15:54,320
look at the same plots here. Uh you'll

268
00:15:50,720 --> 00:15:58,399
notice that the absolute price has a

269
00:15:54,320 --> 00:16:02,560
rather um notable exponential growth in

270
00:15:58,399 --> 00:16:06,720
it. Um when we take the log scale we

271
00:16:02,560 --> 00:16:10,480
have this plot and what's really

272
00:16:06,720 --> 00:16:14,800
important to see is whether the sort of

273
00:16:10,480 --> 00:16:16,880
variability in the time series is

274
00:16:14,800 --> 00:16:20,560
constant

275
00:16:16,880 --> 00:16:24,560
or not. And when before taking the logs

276
00:16:20,560 --> 00:16:26,800
we have a really narrow variation of the

277
00:16:24,560 --> 00:16:29,920
price series com at the beginning

278
00:16:26,800 --> 00:16:33,199
compared with the end. But on the log

279
00:16:29,920 --> 00:16:36,560
scale, the variation is is more

280
00:16:33,199 --> 00:16:40,560
comparable. So that's actually a good

281
00:16:36,560 --> 00:16:46,240
thing to have. We still have a trend in

282
00:16:40,560 --> 00:16:50,160
the series. And taking the

283
00:16:46,240 --> 00:16:53,120
differences in the log values

284
00:16:50,160 --> 00:16:55,759
makes this series

285
00:16:53,120 --> 00:16:59,120
stationary or at least appear

286
00:16:55,759 --> 00:17:02,880
stationary. And here's the uh log

287
00:16:59,120 --> 00:17:08,400
returns on a monthly frequency.

288
00:17:02,880 --> 00:17:13,039
And uh here's the uh histogram of those

289
00:17:08,400 --> 00:17:16,079
log returns and the normal fit. It's

290
00:17:13,039 --> 00:17:20,799
perhaps doing a slightly better job uh

291
00:17:16,079 --> 00:17:23,039
than for the S&P 500. It's not clear. Um

292
00:17:20,799 --> 00:17:27,679
here is the weekly frequency time

293
00:17:23,039 --> 00:17:29,840
series. Again, um the top panel does

294
00:17:27,679 --> 00:17:32,080
look like it's consistent with a

295
00:17:29,840 --> 00:17:35,760
stationary series in terms of the

296
00:17:32,080 --> 00:17:38,559
properties we've highlighted so far and

297
00:17:35,760 --> 00:17:40,880
the Gaussian distribution seems to be

298
00:17:38,559 --> 00:17:43,280
fitting a bit better.

299
00:17:40,880 --> 00:17:48,320
Um if we look at the daily log returns

300
00:17:43,280 --> 00:17:50,160
then uh we have um this sort of

301
00:17:48,320 --> 00:17:53,600
leptoccurtosis

302
00:17:50,160 --> 00:17:57,360
appearing in this uh histogram of daily

303
00:17:53,600 --> 00:18:00,000
returns. And in looking at the time

304
00:17:57,360 --> 00:18:02,320
series of the daily returns

305
00:18:00,000 --> 00:18:04,640
um it looks like there are some

306
00:18:02,320 --> 00:18:07,520
significant spikes

307
00:18:04,640 --> 00:18:12,080
that are not really sort of consistent

308
00:18:07,520 --> 00:18:14,559
with the rest of the series. So maybe uh

309
00:18:12,080 --> 00:18:16,720
you know that feature is something that

310
00:18:14,559 --> 00:18:18,400
we would want to incorporate into our

311
00:18:16,720 --> 00:18:20,480
models.

312
00:18:18,400 --> 00:18:23,600
Well, here's

313
00:18:20,480 --> 00:18:26,400
getting away from the uh equity markets.

314
00:18:23,600 --> 00:18:28,400
This is looking at the crude oil futures

315
00:18:26,400 --> 00:18:33,200
contract.

316
00:18:28,400 --> 00:18:34,720
And with the crude oil futures contract

317
00:18:33,200 --> 00:18:36,480
um

318
00:18:34,720 --> 00:18:39,760
this

319
00:18:36,480 --> 00:18:43,760
future um it trades I think at the

320
00:18:39,760 --> 00:18:46,559
Chicago Merkantile Exchange. Um it

321
00:18:43,760 --> 00:18:49,679
actually has a

322
00:18:46,559 --> 00:18:54,640
dramatic feature that the value of the

323
00:18:49,679 --> 00:18:58,240
contract went negative in 2020

324
00:18:54,640 --> 00:19:02,240
which was a shock to financial markets

325
00:18:58,240 --> 00:19:04,880
especially uh brokers and traders in

326
00:19:02,240 --> 00:19:10,080
those contracts. You can imagine if you

327
00:19:04,880 --> 00:19:12,320
had a hundred contracts of crude oil

328
00:19:10,080 --> 00:19:15,440
on the day you woke up and the price was

329
00:19:12,320 --> 00:19:19,039
negative, you basically owed your broker

330
00:19:15,440 --> 00:19:22,080
a hundred times that negative value. And

331
00:19:19,039 --> 00:19:24,400
uh brokers actually sometimes were

332
00:19:22,080 --> 00:19:26,320
unable to tell you what your position

333
00:19:24,400 --> 00:19:29,919
was because their systems didn't allow

334
00:19:26,320 --> 00:19:33,600
for negative prices. um if we try to

335
00:19:29,919 --> 00:19:35,919
take the log of the series and look at

336
00:19:33,600 --> 00:19:39,840
the differences with these negative

337
00:19:35,919 --> 00:19:44,160
values that's actually a huge problem

338
00:19:39,840 --> 00:19:48,559
but nonetheless uh let's see I did graph

339
00:19:44,160 --> 00:19:50,480
these um which essentially will sort of

340
00:19:48,559 --> 00:19:53,760
exclude those days when there were

341
00:19:50,480 --> 00:19:57,360
negative values for the contract and

342
00:19:53,760 --> 00:20:00,559
looking at this here's the monthly log

343
00:19:57,360 --> 00:20:04,240
returns. So this is excluding the

344
00:20:00,559 --> 00:20:08,320
negative uh price periods

345
00:20:04,240 --> 00:20:10,000
um on a monthly basis, on a weekly

346
00:20:08,320 --> 00:20:13,440
basis,

347
00:20:10,000 --> 00:20:16,880
and on a daily basis. And so what's

348
00:20:13,440 --> 00:20:20,000
really important here is just how

349
00:20:16,880 --> 00:20:25,039
looking at different financial time

350
00:20:20,000 --> 00:20:28,559
series with the same framework

351
00:20:25,039 --> 00:20:30,960
of log logging the series if it's

352
00:20:28,559 --> 00:20:34,000
positive and looking at increments on

353
00:20:30,960 --> 00:20:38,640
the log scale which correspond to

354
00:20:34,000 --> 00:20:41,360
percentage changes. um the data

355
00:20:38,640 --> 00:20:46,880
generally is transformed or often is

356
00:20:41,360 --> 00:20:49,919
transformed to a stationary scale. Um

357
00:20:46,880 --> 00:20:51,760
yet another example is looking at the

358
00:20:49,919 --> 00:20:57,600
yields

359
00:20:51,760 --> 00:21:02,799
of the uh 10-year uh US Treasury.

360
00:20:57,600 --> 00:21:06,080
Um, and so the top panel shows

361
00:21:02,799 --> 00:21:11,120
it's called price, but it's really the

362
00:21:06,080 --> 00:21:14,320
yield uh in percentage terms of 10-year

363
00:21:11,120 --> 00:21:18,640
government bonds. And so you can see it

364
00:21:14,320 --> 00:21:21,919
started above 3% dropped down to less

365
00:21:18,640 --> 00:21:25,120
than 1% following the COVID crisis and

366
00:21:21,919 --> 00:21:29,600
then was rising ever since.

367
00:21:25,120 --> 00:21:32,559
And if we look at the uh

368
00:21:29,600 --> 00:21:35,280
price or the yield changes on the log

369
00:21:32,559 --> 00:21:40,000
scale, we get this plot which isn't too

370
00:21:35,280 --> 00:21:44,720
different um and in its appearance. But

371
00:21:40,000 --> 00:21:50,559
then if we look at the uh changes in log

372
00:21:44,720 --> 00:21:54,159
on uh u changes in log uh the increments

373
00:21:50,559 --> 00:21:56,880
in log which are log returns in sort of

374
00:21:54,159 --> 00:22:00,880
mathematical definition. Log returns are

375
00:21:56,880 --> 00:22:03,919
not really the right terminology for the

376
00:22:00,880 --> 00:22:05,840
percentage changes in yield but we'll

377
00:22:03,919 --> 00:22:09,200
basically be using the same terminology

378
00:22:05,840 --> 00:22:13,520
as before. One can see that we basically

379
00:22:09,200 --> 00:22:15,760
get a distribution of increments

380
00:22:13,520 --> 00:22:17,840
steps in the random walk on the log

381
00:22:15,760 --> 00:22:21,919
scale that

382
00:22:17,840 --> 00:22:24,960
are unimodal and symmetric.

383
00:22:21,919 --> 00:22:27,039
And as we consider

384
00:22:24,960 --> 00:22:30,000
higher frequency, here's weekly and

385
00:22:27,039 --> 00:22:32,720
here's daily, it's actually doing a

386
00:22:30,000 --> 00:22:36,159
better job perhaps using a normal model

387
00:22:32,720 --> 00:22:40,799
for this uh transformed series than for

388
00:22:36,159 --> 00:22:45,120
the uh equity market series. So, so with

389
00:22:40,799 --> 00:22:48,559
these cases, uh the same

390
00:22:45,120 --> 00:22:52,400
manipulations of the data, taking logs,

391
00:22:48,559 --> 00:22:55,280
looking at log returns corresponds to

392
00:22:52,400 --> 00:22:58,320
transforming the series to

393
00:22:55,280 --> 00:23:01,840
a random walk process.

394
00:22:58,320 --> 00:23:06,559
And with random walk processes

395
00:23:01,840 --> 00:23:12,640
um we can think of the sum from zero to

396
00:23:06,559 --> 00:23:16,480
t of or it's capital t say of x subt

397
00:23:12,640 --> 00:23:18,080
and call this maybe s subt.

398
00:23:16,480 --> 00:23:20,720
Um

399
00:23:18,080 --> 00:23:24,960
in modeling

400
00:23:20,720 --> 00:23:28,000
the random walk by this sum um there

401
00:23:24,960 --> 00:23:32,000
will be many different models we can

402
00:23:28,000 --> 00:23:36,640
consider for this. The simplest model

403
00:23:32,000 --> 00:23:38,880
would be one where these x's the steps

404
00:23:36,640 --> 00:23:41,919
are

405
00:23:38,880 --> 00:23:45,520
identically distributed and independent.

406
00:23:41,919 --> 00:23:51,039
So it's like a pure random walk.

407
00:23:45,520 --> 00:23:52,640
um and uh more complicated models uh

408
00:23:51,039 --> 00:23:56,400
will

409
00:23:52,640 --> 00:24:00,559
consider ST um or the XTS to be

410
00:23:56,400 --> 00:24:07,799
dependent upon each other. So what we'd

411
00:24:00,559 --> 00:24:07,799
like to do then is let's see as we um

412
00:24:08,400 --> 00:24:13,840
let's see here

413
00:24:10,720 --> 00:24:17,200
if we think of this autocorrelation

414
00:24:13,840 --> 00:24:19,600
function the correlation

415
00:24:17,200 --> 00:24:21,279
between

416
00:24:19,600 --> 00:24:25,360
x's

417
00:24:21,279 --> 00:24:28,559
that are toao units of time apart

418
00:24:25,360 --> 00:24:30,799
um we can actually calculate

419
00:24:28,559 --> 00:24:32,400
autocorrelations

420
00:24:30,799 --> 00:24:34,559
for

421
00:24:32,400 --> 00:24:37,679
each of the series we just looked at.

422
00:24:34,559 --> 00:24:41,840
And so here is the autocorrelation

423
00:24:37,679 --> 00:24:44,799
function of the monthly log returns on

424
00:24:41,840 --> 00:24:50,640
the S&P 500.

425
00:24:44,799 --> 00:24:55,279
And one can see that there actually was

426
00:24:50,640 --> 00:24:57,120
a large negative autocorrelation for one

427
00:24:55,279 --> 00:25:00,720
month apart.

428
00:24:57,120 --> 00:25:03,760
and the other autocorrelations varied

429
00:25:00,720 --> 00:25:07,440
around this blue range.

430
00:25:03,760 --> 00:25:09,120
And what's important with

431
00:25:07,440 --> 00:25:13,760
autocorrelations

432
00:25:09,120 --> 00:25:16,320
um if we have a time series

433
00:25:13,760 --> 00:25:21,679
uh xt

434
00:25:16,320 --> 00:25:26,159
t equaling 1 2 up to capital t and then

435
00:25:21,679 --> 00:25:29,159
we consider the uh sample

436
00:25:26,159 --> 00:25:29,159
autocorrelation

437
00:25:31,760 --> 00:25:38,000
at lag K.

438
00:25:35,679 --> 00:25:44,480
Then this is an estimate of the

439
00:25:38,000 --> 00:25:47,200
correlation between XT and XT + K.

440
00:25:44,480 --> 00:25:49,120
And we call this RK.

441
00:25:47,200 --> 00:25:51,200
And I'll maybe put a hat on it to

442
00:25:49,120 --> 00:25:52,799
indicate that this is estimated from the

443
00:25:51,200 --> 00:25:58,400
sample.

444
00:25:52,799 --> 00:26:00,720
It turns out that this is

445
00:25:58,400 --> 00:26:03,360
approximately

446
00:26:00,720 --> 00:26:06,000
distributed

447
00:26:03,360 --> 00:26:07,919
as a normal

448
00:26:06,000 --> 00:26:13,039
with

449
00:26:07,919 --> 00:26:18,000
a mean or I guess okay a normal with the

450
00:26:13,039 --> 00:26:22,000
row k the true autocorrelation

451
00:26:18,000 --> 00:26:25,000
and a variance that's one over t minus

452
00:26:22,000 --> 00:26:25,000
k.

453
00:26:26,240 --> 00:26:32,080
So if we

454
00:26:30,240 --> 00:26:35,840
look at

455
00:26:32,080 --> 00:26:38,640
these bands, these bands correspond to

456
00:26:35,840 --> 00:26:40,400
sort of the region of sample

457
00:26:38,640 --> 00:26:44,919
autocorrelations

458
00:26:40,400 --> 00:26:44,919
that are consistent with a zero

459
00:26:45,120 --> 00:26:51,679
true autocorrelation.

460
00:26:47,120 --> 00:26:55,919
So if we want to if we want to test a

461
00:26:51,679 --> 00:26:57,919
null hypothesis that row k is equal to

462
00:26:55,919 --> 00:27:01,200
zero,

463
00:26:57,919 --> 00:27:02,720
we can say reject

464
00:27:01,200 --> 00:27:04,880
if

465
00:27:02,720 --> 00:27:08,880
r hat k

466
00:27:04,880 --> 00:27:13,200
is greater than 1.96

467
00:27:08,880 --> 00:27:17,039
times the square<unk> of 1 / t minus k.

468
00:27:13,200 --> 00:27:20,960
applying a normal model for that return

469
00:27:17,039 --> 00:27:24,880
distribution. So we basically have um

470
00:27:20,960 --> 00:27:28,720
for the r hat k where we have a row k

471
00:27:24,880 --> 00:27:30,640
here we have a bell-shaped curve with a

472
00:27:28,720 --> 00:27:35,200
standard deviation

473
00:27:30,640 --> 00:27:38,960
square root of 1 over t minus k and if

474
00:27:35,200 --> 00:27:41,760
we consider row k equal to zero then we

475
00:27:38,960 --> 00:27:46,159
do the rejection if it's outside these

476
00:27:41,760 --> 00:27:49,440
bands. Now um

477
00:27:46,159 --> 00:27:52,240
the uh let's take a look at how these

478
00:27:49,440 --> 00:27:56,640
autocorrelations vary as we vary the

479
00:27:52,240 --> 00:27:58,480
frequency. Here's the uh weekly

480
00:27:56,640 --> 00:28:03,520
frequency

481
00:27:58,480 --> 00:28:07,279
for the computation of log returns. And

482
00:28:03,520 --> 00:28:09,039
we have this pattern where perhaps there

483
00:28:07,279 --> 00:28:12,559
are some

484
00:28:09,039 --> 00:28:17,520
significant negative autocorrelations

485
00:28:12,559 --> 00:28:20,880
at say uh five weeks apart.

486
00:28:17,520 --> 00:28:26,000
Um, and

487
00:28:20,880 --> 00:28:28,240
what would you say is a property of

488
00:28:26,000 --> 00:28:30,960
a time series that has negative

489
00:28:28,240 --> 00:28:35,520
autocorrelations

490
00:28:30,960 --> 00:28:37,200
say of order at lag five. What does that

491
00:28:35,520 --> 00:28:39,039
really

492
00:28:37,200 --> 00:28:39,919
mean in terms of what you would expect?

493
00:28:39,039 --> 00:28:41,039
Yes. Sort

494
00:28:39,919 --> 00:28:45,120
>> of mean reversion.

495
00:28:41,039 --> 00:28:48,000
>> Mean rever. Yes. Exactly. So the

496
00:28:45,120 --> 00:28:49,840
negative autocorrelations

497
00:28:48,000 --> 00:28:53,279
are consistent perhaps with mean

498
00:28:49,840 --> 00:28:57,760
reversion. So that means that

499
00:28:53,279 --> 00:29:00,159
if you know the price changes are too

500
00:28:57,760 --> 00:29:04,640
high they'll revert back or if they're

501
00:29:00,159 --> 00:29:07,919
too low they'll revert back. And um

502
00:29:04,640 --> 00:29:11,200
let's see also on these graphs are

503
00:29:07,919 --> 00:29:13,840
partial autocorrelations which we'll

504
00:29:11,200 --> 00:29:17,039
discuss later.

505
00:29:13,840 --> 00:29:20,880
Um but uh partial

506
00:29:17,039 --> 00:29:24,480
autocorrelations are correlations at a

507
00:29:20,880 --> 00:29:28,880
given lag after accommodating

508
00:29:24,480 --> 00:29:31,440
the dependence on lower order lags.

509
00:29:28,880 --> 00:29:34,159
We'll see that what how that works out

510
00:29:31,440 --> 00:29:36,720
uh in the case study later. But let's

511
00:29:34,159 --> 00:29:40,880
take a look at just these other series.

512
00:29:36,720 --> 00:29:44,320
Um, so here's the daily series uh with

513
00:29:40,880 --> 00:29:47,360
the S&P 500. And so you can see, oh,

514
00:29:44,320 --> 00:29:50,360
there's actually some reasonable strong

515
00:29:47,360 --> 00:29:50,360
autocorrelations.

516
00:29:50,480 --> 00:29:55,200
Here's Amazon stock.

517
00:29:53,200 --> 00:29:58,960
I'm not sure why it doesn't have the

518
00:29:55,200 --> 00:30:01,440
band on the lower side. Uh

519
00:29:58,960 --> 00:30:04,880
but it um it basically is symmetrical

520
00:30:01,440 --> 00:30:09,200
with that blue band where the

521
00:30:04,880 --> 00:30:10,880
correlation is consistent with zero

522
00:30:09,200 --> 00:30:14,799
autocorrelation.

523
00:30:10,880 --> 00:30:17,440
Um here's the weekly, here's the daily.

524
00:30:14,799 --> 00:30:20,080
So, so interestingly, Amazon stock

525
00:30:17,440 --> 00:30:22,080
doesn't seem to have any significant

526
00:30:20,080 --> 00:30:26,320
autocorrelations regardless of the

527
00:30:22,080 --> 00:30:27,840
frequency. Here's the um crude oil

528
00:30:26,320 --> 00:30:29,679
future.

529
00:30:27,840 --> 00:30:33,279
You can see that with the crude oil

530
00:30:29,679 --> 00:30:37,200
future in on a weekly basis, we have a

531
00:30:33,279 --> 00:30:39,200
negative autocorrelation at uh two weeks

532
00:30:37,200 --> 00:30:43,039
and then a positive autocorrelation at

533
00:30:39,200 --> 00:30:45,600
three weeks. So there's some interesting

534
00:30:43,039 --> 00:30:47,840
uh patterns that perhaps can be

535
00:30:45,600 --> 00:30:51,279
exploited.

536
00:30:47,840 --> 00:30:54,559
And here's daily. Uh again, one can see

537
00:30:51,279 --> 00:30:59,039
the rather significant autocorrelations

538
00:30:54,559 --> 00:31:03,200
at the low lag values.

539
00:30:59,039 --> 00:31:06,080
And let's see with the treasury

540
00:31:03,200 --> 00:31:10,559
yields looking at the autocorrelations

541
00:31:06,080 --> 00:31:12,960
and how the log yield changes one can

542
00:31:10,559 --> 00:31:16,880
see that there is some strong time

543
00:31:12,960 --> 00:31:19,440
dependence at the weekly basis as well

544
00:31:16,880 --> 00:31:21,360
as that the daily basis.

545
00:31:19,440 --> 00:31:23,760
Now

546
00:31:21,360 --> 00:31:25,440
let's see the this discussion of

547
00:31:23,760 --> 00:31:27,039
autocorrelations

548
00:31:25,440 --> 00:31:32,080
is

549
00:31:27,039 --> 00:31:33,840
a very important one in uh time series

550
00:31:32,080 --> 00:31:37,279
modeling

551
00:31:33,840 --> 00:31:41,279
and I just want to

552
00:31:37,279 --> 00:31:43,840
um highlight how if we have a time

553
00:31:41,279 --> 00:31:47,919
series

554
00:31:43,840 --> 00:31:50,919
and we have a we fit a time series

555
00:31:47,919 --> 00:31:50,919
model.

556
00:31:52,480 --> 00:32:03,919
And so we compute say y t t = 1 to t.

557
00:31:59,120 --> 00:32:06,159
Then um the residual

558
00:32:03,919 --> 00:32:07,679
series

559
00:32:06,159 --> 00:32:11,919
from

560
00:32:07,679 --> 00:32:14,000
this fit of the time series model is the

561
00:32:11,919 --> 00:32:20,679
set of errors

562
00:32:14,000 --> 00:32:20,679
which are yt minus y t

563
00:32:23,600 --> 00:32:28,480
and

564
00:32:26,000 --> 00:32:34,080
you know we can just write yt is equal

565
00:32:28,480 --> 00:32:38,799
to y t plus epsilon or error t.

566
00:32:34,080 --> 00:32:42,720
Um a good model.

567
00:32:38,799 --> 00:32:45,919
So the model

568
00:32:42,720 --> 00:32:47,760
is good

569
00:32:45,919 --> 00:32:50,080
if

570
00:32:47,760 --> 00:32:52,159
the ETSs

571
00:32:50,080 --> 00:32:55,120
basically

572
00:32:52,159 --> 00:32:58,519
have

573
00:32:55,120 --> 00:32:58,519
mean zero

574
00:32:58,880 --> 00:33:02,440
constant variance

575
00:33:03,760 --> 00:33:06,880
are uncorrelated.

576
00:33:10,000 --> 00:33:17,840
with each other. And so the these

577
00:33:14,240 --> 00:33:22,360
assumptions um are basically assumptions

578
00:33:17,840 --> 00:33:22,360
of a white noise process.

579
00:33:24,880 --> 00:33:30,880
So if our model

580
00:33:28,880 --> 00:33:35,120
basically

581
00:33:30,880 --> 00:33:40,080
predicts up to this

582
00:33:35,120 --> 00:33:42,240
residual process which is unpredictable

583
00:33:40,080 --> 00:33:44,080
has mean zero constant variance is

584
00:33:42,240 --> 00:33:48,000
uncorrelated. There's no information

585
00:33:44,080 --> 00:33:51,519
left in the residual series and so we

586
00:33:48,000 --> 00:33:53,760
can use the autocorrelation

587
00:33:51,519 --> 00:33:55,919
of the

588
00:33:53,760 --> 00:34:00,000
residual series.

589
00:33:55,919 --> 00:34:06,000
We can use the autocorrelation function

590
00:34:00,000 --> 00:34:07,519
of the error series to test

591
00:34:06,000 --> 00:34:09,599
if

592
00:34:07,519 --> 00:34:13,119
the uh

593
00:34:09,599 --> 00:34:15,839
model is good basically.

594
00:34:13,119 --> 00:34:20,000
And a good model

595
00:34:15,839 --> 00:34:23,040
will be a model that has captured all of

596
00:34:20,000 --> 00:34:24,639
the time dependent information in it.

597
00:34:23,040 --> 00:34:26,800
And

598
00:34:24,639 --> 00:34:30,240
the uh

599
00:34:26,800 --> 00:34:33,839
predictions from these or forecasts from

600
00:34:30,240 --> 00:34:36,960
this model are ones we have confidence

601
00:34:33,839 --> 00:34:42,399
in. And so there's actually another

602
00:34:36,960 --> 00:34:45,760
assumption here which is that um

603
00:34:42,399 --> 00:34:50,040
let's see it's um if the epsilon t are

604
00:34:45,760 --> 00:34:50,040
normal or gaussian

605
00:34:52,480 --> 00:34:57,399
then this gives uh good predictions

606
00:34:58,240 --> 00:35:05,280
and by predictions I'm thinking of not

607
00:35:01,920 --> 00:35:07,359
point forecasts of a series but a

608
00:35:05,280 --> 00:35:09,119
prediction interval and how wide should

609
00:35:07,359 --> 00:35:11,839
that prediction interval be depending

610
00:35:09,119 --> 00:35:15,520
upon the variability.

611
00:35:11,839 --> 00:35:18,560
Um so so if when we work with time

612
00:35:15,520 --> 00:35:20,720
series we're actually are

613
00:35:18,560 --> 00:35:22,480
going to work often with

614
00:35:20,720 --> 00:35:27,520
autocorrelations

615
00:35:22,480 --> 00:35:32,480
of residuals to see um whether there's

616
00:35:27,520 --> 00:35:35,520
any time dependence in the series. And

617
00:35:32,480 --> 00:35:37,760
if we um

618
00:35:35,520 --> 00:35:39,760
what what's rather interesting to note

619
00:35:37,760 --> 00:35:44,520
is that

620
00:35:39,760 --> 00:35:44,520
one can fix a single correlation

621
00:35:46,000 --> 00:35:52,960
lag and use that to test whether the

622
00:35:50,880 --> 00:35:56,079
data are consistent with a zero

623
00:35:52,960 --> 00:35:57,760
autocorrelation of a fixed lag. We can

624
00:35:56,079 --> 00:36:02,560
also

625
00:35:57,760 --> 00:36:07,040
use sets of lags and test whether the

626
00:36:02,560 --> 00:36:10,320
whole set is equal to zero or not. And

627
00:36:07,040 --> 00:36:13,359
so um

628
00:36:10,320 --> 00:36:20,720
let's see let me just write it over

629
00:36:13,359 --> 00:36:22,480
here. So um if say row one equals row 2

630
00:36:20,720 --> 00:36:25,119
equals

631
00:36:22,480 --> 00:36:27,680
row k

632
00:36:25,119 --> 00:36:29,280
is equal to zero

633
00:36:27,680 --> 00:36:32,400
then

634
00:36:29,280 --> 00:36:34,880
r hat j

635
00:36:32,400 --> 00:36:37,680
which is distributed as normal zero

636
00:36:34,880 --> 00:36:45,200
roughly 1 / t

637
00:36:37,680 --> 00:36:49,920
um for j equaling one to to uh A

638
00:36:45,200 --> 00:36:51,920
r hat j 2 * t

639
00:36:49,920 --> 00:36:55,920
is approximately

640
00:36:51,920 --> 00:36:58,000
the square of a normal 01 which is a kai

641
00:36:55,920 --> 00:37:00,240
squared 1

642
00:36:58,000 --> 00:37:06,000
random variable.

643
00:37:00,240 --> 00:37:10,720
And if we look at the sum of t r hat j^

644
00:37:06,000 --> 00:37:13,839
2 from 1 to k this will be approximately

645
00:37:10,720 --> 00:37:18,800
a ki squared distribution with k degrees

646
00:37:13,839 --> 00:37:21,119
of freedom. And so we can then we can

647
00:37:18,800 --> 00:37:26,119
reject

648
00:37:21,119 --> 00:37:26,119
the uh null hypothesis.

649
00:37:27,440 --> 00:37:33,040
If

650
00:37:29,280 --> 00:37:35,920
this test statistic I'll call it well

651
00:37:33,040 --> 00:37:38,800
actually I'll call it BP because it's

652
00:37:35,920 --> 00:37:40,320
actually called the box pierce test if

653
00:37:38,800 --> 00:37:43,640
BP

654
00:37:40,320 --> 00:37:43,640
is large

655
00:37:44,000 --> 00:37:51,520
say larger than

656
00:37:46,960 --> 00:37:54,240
a critical value C star which where this

657
00:37:51,520 --> 00:37:56,560
is determined by the ki squared

658
00:37:54,240 --> 00:37:56,560
distribution.

659
00:37:58,880 --> 00:38:04,920
And so this is actually called the box

660
00:38:01,520 --> 00:38:04,920
pierce test.

661
00:38:07,599 --> 00:38:14,800
And um so

662
00:38:11,200 --> 00:38:16,880
we'll actually uh be very interested in

663
00:38:14,800 --> 00:38:18,800
autocorrelations of the original series

664
00:38:16,880 --> 00:38:21,599
but then autocorrelations of the

665
00:38:18,800 --> 00:38:24,320
residual series. And whenever we have a

666
00:38:21,599 --> 00:38:27,119
model where the residual series still

667
00:38:24,320 --> 00:38:29,359
has significant autocorrelations in it,

668
00:38:27,119 --> 00:38:33,240
then we're really not done yet. We

669
00:38:29,359 --> 00:38:33,240
really need to continue.

670
00:38:36,480 --> 00:38:40,960
Okay.

671
00:38:38,640 --> 00:38:45,599
So we have

672
00:38:40,960 --> 00:38:48,000
now the next topic is a really sort of

673
00:38:45,599 --> 00:38:51,760
extraordinary theorem.

674
00:38:48,000 --> 00:38:53,280
um the W representation theorem

675
00:38:51,760 --> 00:38:56,280
and

676
00:38:53,280 --> 00:38:56,280
with

677
00:38:56,320 --> 00:39:02,240
stationary processes that are

678
00:38:59,200 --> 00:39:05,680
co-variance stationary

679
00:39:02,240 --> 00:39:09,440
then it turns out that any covariant

680
00:39:05,680 --> 00:39:11,280
stationary process can be decomposed

681
00:39:09,440 --> 00:39:13,680
into

682
00:39:11,280 --> 00:39:16,560
a VT process which is linearly

683
00:39:13,680 --> 00:39:20,240
deterministic.

684
00:39:16,560 --> 00:39:24,320
So it's that means that

685
00:39:20,240 --> 00:39:27,680
basically the current value is a linear

686
00:39:24,320 --> 00:39:33,520
combination of past values

687
00:39:27,680 --> 00:39:39,359
and ST is a moving average process

688
00:39:33,520 --> 00:39:42,680
where we have these ADA T's which are

689
00:39:39,359 --> 00:39:42,680
white noise

690
00:39:43,200 --> 00:39:53,240
and our ST process is just a weighted

691
00:39:47,599 --> 00:39:53,240
sum of those white noise terms.

692
00:39:53,359 --> 00:39:57,280
And

693
00:39:55,520 --> 00:40:01,040
the white noise terms are also

694
00:39:57,280 --> 00:40:03,680
uncorrelated with the linearly

695
00:40:01,040 --> 00:40:06,079
deterministic process.

696
00:40:03,680 --> 00:40:09,599
So

697
00:40:06,079 --> 00:40:14,560
let's see when I first learned of this

698
00:40:09,599 --> 00:40:16,320
theorem I was um

699
00:40:14,560 --> 00:40:19,839
had an issue with well what is a

700
00:40:16,320 --> 00:40:22,160
linearly deterministic process? So, can

701
00:40:19,839 --> 00:40:26,760
anyone suggest what a linearly

702
00:40:22,160 --> 00:40:26,760
deterministic process is

703
00:40:27,839 --> 00:40:33,400
or or could be or an example of one.

704
00:40:43,920 --> 00:40:49,280
So we have VT

705
00:40:46,880 --> 00:40:52,920
is linear

706
00:40:49,280 --> 00:40:52,920
the deterministic.

707
00:41:01,359 --> 00:41:12,640
So we have VT. So if we observe VT over

708
00:41:07,839 --> 00:41:17,920
a sequence of time points,

709
00:41:12,640 --> 00:41:19,599
will for what patterns of VT will that

710
00:41:17,920 --> 00:41:24,440
determine

711
00:41:19,599 --> 00:41:24,440
the VT process into the future?

712
00:41:24,720 --> 00:41:28,440
Can you think of any?

713
00:41:32,640 --> 00:41:37,040
So if vt

714
00:41:34,560 --> 00:41:40,319
is equal to mu

715
00:41:37,040 --> 00:41:45,040
plus say cosine

716
00:41:40,319 --> 00:41:47,760
of theta t

717
00:41:45,040 --> 00:41:51,680
then this thing will just move up and

718
00:41:47,760 --> 00:41:55,520
down and we can actually determine

719
00:41:51,680 --> 00:41:58,640
that cosine function from enough values

720
00:41:55,520 --> 00:42:02,160
of vt. Yes. So does that mean like any

721
00:41:58,640 --> 00:42:02,800
any periodic process would be linearly

722
00:42:02,160 --> 00:42:08,880
determined?

723
00:42:02,800 --> 00:42:10,720
>> Yes. Any Yeah. And um it's interesting

724
00:42:08,880 --> 00:42:13,280
uh

725
00:42:10,720 --> 00:42:16,720
to know that I th those of you who may

726
00:42:13,280 --> 00:42:18,880
have studied harmonic analysis

727
00:42:16,720 --> 00:42:23,040
um

728
00:42:18,880 --> 00:42:29,000
could come across the u

729
00:42:23,040 --> 00:42:29,000
result that if we have say different

730
00:42:29,040 --> 00:42:35,119
period different cosine or s functions

731
00:42:32,240 --> 00:42:37,839
and take sums of those

732
00:42:35,119 --> 00:42:40,079
then that will also be a linearly

733
00:42:37,839 --> 00:42:45,200
predictable process.

734
00:42:40,079 --> 00:42:47,839
And so if you look at summing signs of

735
00:42:45,200 --> 00:42:50,720
different frequencies which basically

736
00:42:47,839 --> 00:42:55,200
corresponds to forier series that are

737
00:42:50,720 --> 00:42:56,720
flat um then uh those are linearly

738
00:42:55,200 --> 00:42:58,720
predictable.

739
00:42:56,720 --> 00:43:01,119
Um

740
00:42:58,720 --> 00:43:04,240
so so that's

741
00:43:01,119 --> 00:43:07,119
the VT process that we

742
00:43:04,240 --> 00:43:09,359
should be aware of. Um but what's really

743
00:43:07,119 --> 00:43:12,560
interesting is that the variation about

744
00:43:09,359 --> 00:43:16,640
that deterministic process the ST

745
00:43:12,560 --> 00:43:21,119
process um can be

746
00:43:16,640 --> 00:43:23,599
expressed as a moving average process

747
00:43:21,119 --> 00:43:27,599
and this

748
00:43:23,599 --> 00:43:30,319
u representation holds for any covariant

749
00:43:27,599 --> 00:43:34,240
stationary time series. Now for any

750
00:43:30,319 --> 00:43:38,640
coariant stationary time series

751
00:43:34,240 --> 00:43:41,359
um let's see

752
00:43:38,640 --> 00:43:44,160
with the covariance

753
00:43:41,359 --> 00:43:46,319
stationary

754
00:43:44,160 --> 00:43:48,160
process

755
00:43:46,319 --> 00:43:51,359
st

756
00:43:48,160 --> 00:43:54,720
um we have basically that mu is equal to

757
00:43:51,359 --> 00:43:59,119
the expected value of st sort of sigma

758
00:43:54,720 --> 00:44:01,839
squar which is the variance of st.

759
00:43:59,119 --> 00:44:05,119
This is constant over time. This is

760
00:44:01,839 --> 00:44:11,640
constant over time. And the co-variance

761
00:44:05,119 --> 00:44:11,640
of xt xt plus toao

762
00:44:11,760 --> 00:44:18,319
is equal to gamma of toao

763
00:44:15,040 --> 00:44:20,880
uh for all t.

764
00:44:18,319 --> 00:44:25,200
So

765
00:44:20,880 --> 00:44:28,319
any coariant stationary process

766
00:44:25,200 --> 00:44:29,920
can be represented as this moving

767
00:44:28,319 --> 00:44:34,359
average

768
00:44:29,920 --> 00:44:34,359
of white noise process.

769
00:44:35,280 --> 00:44:42,640
And so well how would we

770
00:44:39,200 --> 00:44:46,319
use this Wolves representation theorem?

771
00:44:42,640 --> 00:44:50,560
Well, if we have a time series XT that

772
00:44:46,319 --> 00:44:53,440
we want to specify a coariant stationary

773
00:44:50,560 --> 00:44:56,240
time series model to it, well, the first

774
00:44:53,440 --> 00:44:57,760
thing we would do perhaps is sort of

775
00:44:56,240 --> 00:45:02,800
drend

776
00:44:57,760 --> 00:45:06,800
the series XT so that it has a constant

777
00:45:02,800 --> 00:45:10,400
mean level. So if we had a

778
00:45:06,800 --> 00:45:13,839
linear trend or a quadratic trend, we

779
00:45:10,400 --> 00:45:18,400
would subtract that out. So xt is a

780
00:45:13,839 --> 00:45:22,240
series that uh looks like it has a flat

781
00:45:18,400 --> 00:45:26,560
path. And then we could initialize

782
00:45:22,240 --> 00:45:28,960
a parameter P indicating the past

783
00:45:26,560 --> 00:45:32,560
number of observations

784
00:45:28,960 --> 00:45:34,800
that explain the linearly deterministic

785
00:45:32,560 --> 00:45:38,160
term.

786
00:45:34,800 --> 00:45:42,160
And we can then

787
00:45:38,160 --> 00:45:45,440
project our time series XT onto the

788
00:45:42,160 --> 00:45:47,520
space spanned by the lags,

789
00:45:45,440 --> 00:45:53,920
the P lags.

790
00:45:47,520 --> 00:45:55,599
and then look at the errors about that

791
00:45:53,920 --> 00:46:01,359
projection.

792
00:45:55,599 --> 00:46:04,400
So here we can think of having the time

793
00:46:01,359 --> 00:46:08,960
series values y1 to yn

794
00:46:04,400 --> 00:46:13,359
and we can project those onto the lags

795
00:46:08,960 --> 00:46:15,839
of the y values. So for the first sort

796
00:46:13,359 --> 00:46:19,599
of p rows we actually need to go back in

797
00:46:15,839 --> 00:46:21,119
time. So that means we have to start not

798
00:46:19,599 --> 00:46:24,319
from the beginning of our time series

799
00:46:21,119 --> 00:46:27,760
but maybe p units ahead and then we can

800
00:46:24,319 --> 00:46:29,680
apply ordinary le squares to define the

801
00:46:27,760 --> 00:46:34,319
projection

802
00:46:29,680 --> 00:46:38,720
matrix onto those lagged values. And

803
00:46:34,319 --> 00:46:41,040
then we have this projected residual.

804
00:46:38,720 --> 00:46:43,440
And what we would want is that this

805
00:46:41,040 --> 00:46:48,240
projected residual

806
00:46:43,440 --> 00:46:51,280
um would if it's a stationary time

807
00:46:48,240 --> 00:46:54,079
series, we could use time series

808
00:46:51,280 --> 00:46:57,599
methods. We'll learn about how to

809
00:46:54,079 --> 00:47:01,680
specify a moving average model to these

810
00:46:57,599 --> 00:47:04,640
uh series and get estimates of the size

811
00:47:01,680 --> 00:47:06,800
and also estimates of the white noise

812
00:47:04,640 --> 00:47:10,560
terms.

813
00:47:06,800 --> 00:47:13,760
And with this

814
00:47:10,560 --> 00:47:18,160
step, we then

815
00:47:13,760 --> 00:47:23,119
can evaluate whether our residuals

816
00:47:18,160 --> 00:47:26,160
um are orthogonal to lagged values for

817
00:47:23,119 --> 00:47:29,119
lags greater than pback.

818
00:47:26,160 --> 00:47:33,599
So these residuals

819
00:47:29,119 --> 00:47:39,200
should not have any dependence on

820
00:47:33,599 --> 00:47:43,119
lags of y that are further back than p.

821
00:47:39,200 --> 00:47:44,960
If if not if if there is if those are

822
00:47:43,119 --> 00:47:49,359
not orthogonal then we should increase

823
00:47:44,960 --> 00:47:52,319
p. Um, and then we want to look at

824
00:47:49,359 --> 00:47:54,560
whether the ADAT's in our moving average

825
00:47:52,319 --> 00:47:57,440
model, whether those are consistent with

826
00:47:54,560 --> 00:48:00,640
white noise or not.

827
00:47:57,440 --> 00:48:04,560
And so if they are, we're good. But if

828
00:48:00,640 --> 00:48:06,560
if not then we need to consider sort of

829
00:48:04,560 --> 00:48:10,880
changing the specification of the moving

830
00:48:06,560 --> 00:48:12,800
average model and perhaps adding other

831
00:48:10,880 --> 00:48:15,040
variables such as deterministic

832
00:48:12,800 --> 00:48:18,480
variables that could be useful in the

833
00:48:15,040 --> 00:48:22,240
projections. But what this demonstrates

834
00:48:18,480 --> 00:48:26,640
is how this theory can

835
00:48:22,240 --> 00:48:32,079
in sort of the abstract be applied to

836
00:48:26,640 --> 00:48:37,440
real world data. And um

837
00:48:32,079 --> 00:48:42,000
so uh you know as we increase P the

838
00:48:37,440 --> 00:48:47,280
number of lags we use for the projection

839
00:48:42,000 --> 00:48:50,960
um we end up getting a limiting value

840
00:48:47,280 --> 00:48:54,640
as P gets large. Um that this sort of is

841
00:48:50,960 --> 00:48:57,839
capturing the uh

842
00:48:54,640 --> 00:49:02,800
linearly predictable uh part of the

843
00:48:57,839 --> 00:49:05,040
series. the VTS. Um, but this assumption

844
00:49:02,800 --> 00:49:09,200
basically requires

845
00:49:05,040 --> 00:49:15,280
if we let P grow arbitrarily large, we

846
00:49:09,200 --> 00:49:17,920
probably want to make sure that P over N

847
00:49:15,280 --> 00:49:21,359
uh goes to zero. so that we're

848
00:49:17,920 --> 00:49:22,880
estimating P parameters

849
00:49:21,359 --> 00:49:26,559
with

850
00:49:22,880 --> 00:49:30,319
a number of points that

851
00:49:26,559 --> 00:49:32,160
is large relative to P.

852
00:49:30,319 --> 00:49:35,040
Um

853
00:49:32,160 --> 00:49:37,760
so this is just a way of thinking about

854
00:49:35,040 --> 00:49:40,559
how uh

855
00:49:37,760 --> 00:49:44,079
we might approach our modeling effort

856
00:49:40,559 --> 00:49:46,960
exploiting the wool decomposition.

857
00:49:44,079 --> 00:49:49,440
But um what's what's really important

858
00:49:46,960 --> 00:49:53,359
here is that

859
00:49:49,440 --> 00:49:56,160
any covariant stationary model

860
00:49:53,359 --> 00:49:59,839
has a representation as this moving

861
00:49:56,160 --> 00:50:03,680
average process of white noise.

862
00:49:59,839 --> 00:50:06,720
So that's a fairly powerful result. It

863
00:50:03,680 --> 00:50:09,040
says that once we have transformed our

864
00:50:06,720 --> 00:50:14,800
data to a scale that where coariant

865
00:50:09,040 --> 00:50:17,280
stationerity is appropriate then we can

866
00:50:14,800 --> 00:50:20,240
restrict ourselves to the class of

867
00:50:17,280 --> 00:50:23,680
moving average processes. And what we'll

868
00:50:20,240 --> 00:50:26,000
see is that there are alternatives to

869
00:50:23,680 --> 00:50:28,240
moving average processes called auto

870
00:50:26,000 --> 00:50:33,920
reggressions that are very closely

871
00:50:28,240 --> 00:50:34,800
related to uh moving average processes.

872
00:50:33,920 --> 00:50:39,200
Yes.

873
00:50:34,800 --> 00:50:43,040
>> Um so I guess my question is why do you

874
00:50:39,200 --> 00:50:47,280
need to specify covarian stationerity

875
00:50:43,040 --> 00:50:48,000
for um the the uh the representation

876
00:50:47,280 --> 00:50:51,680
theorem?

877
00:50:48,000 --> 00:50:55,640
>> Okay. Um the uh well with the

878
00:50:51,680 --> 00:50:55,640
representation. Okay.

879
00:50:56,880 --> 00:51:03,359
Okay. Um let's see where is it? Here you

880
00:51:00,319 --> 00:51:07,280
know it's fine. Here here it is. Okay,

881
00:51:03,359 --> 00:51:12,079
basically if if we consider this process

882
00:51:07,280 --> 00:51:16,800
ST which has some set of weights SI

883
00:51:12,079 --> 00:51:21,200
times white noise ADA T's then if these

884
00:51:16,800 --> 00:51:25,680
conditions are satisfied for the size so

885
00:51:21,200 --> 00:51:31,680
the sum they're squares summable

886
00:51:25,680 --> 00:51:35,119
you know finite then this process ST t

887
00:51:31,680 --> 00:51:37,839
is going to be covariant stationary.

888
00:51:35,119 --> 00:51:40,480
It'll have finite mean and variance

889
00:51:37,839 --> 00:51:44,160
that's constant and the covariances will

890
00:51:40,480 --> 00:51:48,800
also be constant over increments of know

891
00:51:44,160 --> 00:51:51,839
any lag. What's what's powerful is that

892
00:51:48,800 --> 00:51:55,280
this representation

893
00:51:51,839 --> 00:51:57,040
can be used for any coariant stationary

894
00:51:55,280 --> 00:52:00,000
model.

895
00:51:57,040 --> 00:52:03,119
So this is coariant stationary

896
00:52:00,000 --> 00:52:06,400
but any coariant stationary model has

897
00:52:03,119 --> 00:52:09,440
this kind of representation.

898
00:52:06,400 --> 00:52:13,839
Yeah sure.

899
00:52:09,440 --> 00:52:15,599
And of course you know um

900
00:52:13,839 --> 00:52:18,480
coariant stationerity is a nice

901
00:52:15,599 --> 00:52:20,720
assumption. It may not be satisfied. So

902
00:52:18,480 --> 00:52:23,040
you need to you know have more complex

903
00:52:20,720 --> 00:52:25,839
models. But it's good to know when you

904
00:52:23,040 --> 00:52:28,400
have these uh assumptions satisfied that

905
00:52:25,839 --> 00:52:30,240
this is the representation.

906
00:52:28,400 --> 00:52:33,680
All right. So we next want to introduce

907
00:52:30,240 --> 00:52:37,680
you to this operator called a lag

908
00:52:33,680 --> 00:52:41,200
operator or a backshift operator.

909
00:52:37,680 --> 00:52:46,000
And uh because I call it a lag operator,

910
00:52:41,200 --> 00:52:49,200
I label it L. And so L

911
00:52:46,000 --> 00:52:53,680
operates on a time series XT and just

912
00:52:49,200 --> 00:52:56,079
shifts the time index back one period.

913
00:52:53,680 --> 00:53:02,240
So we're thinking of discrete time

914
00:52:56,079 --> 00:53:04,400
series with integer values of t and um

915
00:53:02,240 --> 00:53:08,960
the lag

916
00:53:04,400 --> 00:53:14,079
operating on xt shifts the time units

917
00:53:08,960 --> 00:53:16,720
back one period. And we can think of L

918
00:53:14,079 --> 00:53:19,839
to the zero power

919
00:53:16,720 --> 00:53:21,920
doing the identity.

920
00:53:19,839 --> 00:53:24,559
L1

921
00:53:21,920 --> 00:53:28,400
one power of L shifts back once. If we

922
00:53:24,559 --> 00:53:31,119
apply L twice or L squ this shifts back

923
00:53:28,400 --> 00:53:36,079
two periods and of course if we apply it

924
00:53:31,119 --> 00:53:40,559
N times then we shift back N periods.

925
00:53:36,079 --> 00:53:43,200
And so with these lag operators, we can

926
00:53:40,559 --> 00:53:46,079
think of inverses of those operators as

927
00:53:43,200 --> 00:53:49,200
well and sort of consider sort of

928
00:53:46,079 --> 00:53:54,079
shifting the time series forward if that

929
00:53:49,200 --> 00:53:57,359
were useful. And so when we think of the

930
00:53:54,079 --> 00:54:02,319
w representation

931
00:53:57,359 --> 00:54:05,440
um we can express it as the sum of the

932
00:54:02,319 --> 00:54:08,000
moving average process

933
00:54:05,440 --> 00:54:14,400
and the linearly deterministic process

934
00:54:08,000 --> 00:54:18,640
vt. And we can represent the uh moving

935
00:54:14,400 --> 00:54:20,960
average process as a polomial

936
00:54:18,640 --> 00:54:25,520
of the lag operators possibly of

937
00:54:20,960 --> 00:54:29,720
infinite order that is multiplying the

938
00:54:25,520 --> 00:54:29,720
um ad t's.

939
00:54:30,640 --> 00:54:36,079
Now

940
00:54:32,319 --> 00:54:40,319
a a useful um sort of application of

941
00:54:36,079 --> 00:54:47,520
this uh moving average representation is

942
00:54:40,319 --> 00:54:52,640
that if we think about how was

943
00:54:47,520 --> 00:54:57,280
the value of the process at time t

944
00:54:52,640 --> 00:55:00,079
affected by the white noise process ada

945
00:54:57,280 --> 00:55:02,480
j lags ago.

946
00:55:00,079 --> 00:55:05,920
Then

947
00:55:02,480 --> 00:55:10,000
the partial derivative of XT with

948
00:55:05,920 --> 00:55:14,559
respect to that J lag back white noise

949
00:55:10,000 --> 00:55:18,000
term is given by SI J. So when pi j is

950
00:55:14,559 --> 00:55:22,079
large in magnitude that means that the

951
00:55:18,000 --> 00:55:24,960
current value of x is dependent on the j

952
00:55:22,079 --> 00:55:26,720
lag of the white noise

953
00:55:24,960 --> 00:55:30,000
and

954
00:55:26,720 --> 00:55:35,359
with a representation of the xt series

955
00:55:30,000 --> 00:55:41,480
by uh this uh pi function if one sort of

956
00:55:35,359 --> 00:55:41,480
graphs the pi function over lags.

957
00:55:42,079 --> 00:55:50,480
So let me do it over here. So if we look

958
00:55:45,440 --> 00:55:53,799
at SI J as a function of J

959
00:55:50,480 --> 00:55:53,799
and have

960
00:55:54,640 --> 00:56:03,200
we might have weights J that vary

961
00:55:59,520 --> 00:56:05,520
positive and negative. And so if this

962
00:56:03,200 --> 00:56:10,079
were the case,

963
00:56:05,520 --> 00:56:13,440
it would indicate in this graph that the

964
00:56:10,079 --> 00:56:15,680
impact of

965
00:56:13,440 --> 00:56:21,440
the white noise sort of three periods

966
00:56:15,680 --> 00:56:25,280
ago has a significant impact on X now.

967
00:56:21,440 --> 00:56:30,160
So it can capture sort of delayed

968
00:56:25,280 --> 00:56:34,400
responses of the time series XT to the

969
00:56:30,160 --> 00:56:37,520
white noise terms. And if we look at the

970
00:56:34,400 --> 00:56:43,119
long range

971
00:56:37,520 --> 00:56:47,520
impact of A to J or sorry the long range

972
00:56:43,119 --> 00:56:49,760
yeah impact of uh

973
00:56:47,520 --> 00:56:52,160
the uh

974
00:56:49,760 --> 00:56:56,480
or the cumulative response of XT

975
00:56:52,160 --> 00:57:00,960
basically corresponds um

976
00:56:56,480 --> 00:57:03,440
to the uh sum

977
00:57:00,960 --> 00:57:05,520
of the size

978
00:57:03,440 --> 00:57:10,799
and so there's basically a long run

979
00:57:05,520 --> 00:57:12,880
cumulative response of XT to the uh to a

980
00:57:10,799 --> 00:57:16,799
given

981
00:57:12,880 --> 00:57:20,160
a T. Um so this is the long run

982
00:57:16,799 --> 00:57:24,079
cumulative response to uh the white

983
00:57:20,160 --> 00:57:25,920
noise terms. Now what's interesting

984
00:57:24,079 --> 00:57:32,000
about

985
00:57:25,920 --> 00:57:37,200
the uh s of l process

986
00:57:32,000 --> 00:57:43,599
so if we have s of l is equal to the sum

987
00:57:37,200 --> 00:57:45,520
u from zero to infinity of s j l to the

988
00:57:43,599 --> 00:57:47,920
j

989
00:57:45,520 --> 00:57:50,960
um

990
00:57:47,920 --> 00:57:54,160
it's possible that this operator is

991
00:57:50,960 --> 00:57:55,920
invertible able

992
00:57:54,160 --> 00:58:00,400
and

993
00:57:55,920 --> 00:58:03,440
if it's invertible there exists

994
00:58:00,400 --> 00:58:07,760
an inverse operator

995
00:58:03,440 --> 00:58:10,880
with coefficients pi star and the

996
00:58:07,760 --> 00:58:14,960
product of these two polomials is simply

997
00:58:10,880 --> 00:58:17,520
equal to the identity

998
00:58:14,960 --> 00:58:19,920
and

999
00:58:17,520 --> 00:58:24,480
if that's the case

1000
00:58:19,920 --> 00:58:30,079
that an inverse of the PI of L operator

1001
00:58:24,480 --> 00:58:33,200
exists. Then we can

1002
00:58:30,079 --> 00:58:35,440
write our model for the stationary

1003
00:58:33,200 --> 00:58:38,480
process

1004
00:58:35,440 --> 00:58:40,559
as being equivalent to

1005
00:58:38,480 --> 00:58:45,920
applying the inverse operator to both

1006
00:58:40,559 --> 00:58:50,160
sides. And so we get an inverse operator

1007
00:58:45,920 --> 00:58:52,720
which is a polomial lags operating on xt

1008
00:58:50,160 --> 00:58:54,240
is equal to the a to t. So this

1009
00:58:52,720 --> 00:58:57,760
corresponds

1010
00:58:54,240 --> 00:59:01,920
to actually an auto reggression model

1011
00:58:57,760 --> 00:59:04,160
that um has white noise terms.

1012
00:59:01,920 --> 00:59:06,640
And so

1013
00:59:04,160 --> 00:59:11,200
when this exists this is the format of

1014
00:59:06,640 --> 00:59:13,920
that. And what we'd like to do is

1015
00:59:11,200 --> 00:59:16,160
um show you how this works with some

1016
00:59:13,920 --> 00:59:18,640
different examples. Right now it's

1017
00:59:16,160 --> 00:59:21,200
perhaps a bit abstract but when we look

1018
00:59:18,640 --> 00:59:24,400
at the special cases of an auto

1019
00:59:21,200 --> 00:59:30,680
reggressive order one model um many of

1020
00:59:24,400 --> 00:59:30,680
these terms will become clear. Now um

1021
00:59:31,040 --> 00:59:38,960
we can introduce with this notation of

1022
00:59:33,440 --> 00:59:44,079
lags and polomial lag operators the um

1023
00:59:38,960 --> 00:59:46,000
ARMA PQ models where ARMA stands for

1024
00:59:44,079 --> 00:59:49,680
auto reggressive

1025
00:59:46,000 --> 00:59:53,040
and MA stands for moving average models

1026
00:59:49,680 --> 00:59:55,200
and the P corresponds to the order of

1027
00:59:53,040 --> 00:59:57,599
the auto reggressive and the Q

1028
00:59:55,200 --> 01:00:01,040
corresponds to the order of the moving

1029
00:59:57,599 --> 01:00:04,079
average. We can think of our time series

1030
01:00:01,040 --> 01:00:07,680
XT being a sum of terms, auto

1031
01:00:04,079 --> 01:00:10,880
reggressive terms on the top row and

1032
01:00:07,680 --> 01:00:15,680
then the second row corresponds to

1033
01:00:10,880 --> 01:00:22,280
moving average terms of the white noise.

1034
01:00:15,680 --> 01:00:22,280
So notice in the top row we have xt

1035
01:00:23,040 --> 01:00:30,799
and actually if you look at that

1036
01:00:25,680 --> 01:00:34,000
equation if we sort of take xt minus mu

1037
01:00:30,799 --> 01:00:39,119
this turns out to be equal to v1

1038
01:00:34,000 --> 01:00:41,920
xt -1 minus mu plus v2

1039
01:00:39,119 --> 01:00:46,240
and so forth. So these are lag terms of

1040
01:00:41,920 --> 01:00:49,520
the mean adjusted x's and then we have

1041
01:00:46,240 --> 01:00:52,000
the next row is the sum of the white

1042
01:00:49,520 --> 01:00:52,079
noise terms at time t t t t t t t t t t

1043
01:00:52,000 --> 01:00:53,440
t t t t t t t t t t t t t t t t t t t t

1044
01:00:52,079 --> 01:00:58,960
t t t t t t t t t t t minus one up to t

1045
01:00:53,440 --> 01:01:03,119
minus q. So, ARMA PQ models are a

1046
01:00:58,960 --> 01:01:06,960
parsimmonious case of time series models

1047
01:01:03,119 --> 01:01:11,520
where we just have P auto reggressive

1048
01:01:06,960 --> 01:01:16,839
parameters F1 to FP and Q moving average

1049
01:01:11,520 --> 01:01:16,839
parameters theta 1 to theta Q.

1050
01:01:17,440 --> 01:01:25,359
And if we write

1051
01:01:20,480 --> 01:01:27,520
the if we group all the terms with x's

1052
01:01:25,359 --> 01:01:30,720
on the left hand side and all the terms

1053
01:01:27,520 --> 01:01:35,040
with the adas on the right hand side we

1054
01:01:30,720 --> 01:01:39,119
then get this f of l operator* xt minus

1055
01:01:35,040 --> 01:01:40,640
f is equal to theta of l a t

1056
01:01:39,119 --> 01:01:43,280
and

1057
01:01:40,640 --> 01:01:45,680
the w decomposition

1058
01:01:43,280 --> 01:01:52,000
of this

1059
01:01:45,680 --> 01:01:55,760
arma model is to multiply this arma

1060
01:01:52,000 --> 01:01:58,160
equation on both sides by the inverse of

1061
01:01:55,760 --> 01:02:04,319
f of l.

1062
01:01:58,160 --> 01:02:05,920
And so mu plus s of l a t is the w uh

1063
01:02:04,319 --> 01:02:11,359
decomposition

1064
01:02:05,920 --> 01:02:14,640
representation of the of the process.

1065
01:02:11,359 --> 01:02:17,200
So let's look at

1066
01:02:14,640 --> 01:02:19,040
um auto reggressive

1067
01:02:17,200 --> 01:02:21,440
models.

1068
01:02:19,040 --> 01:02:25,920
So we'll assume that there's no moving

1069
01:02:21,440 --> 01:02:28,240
average term. So we have the f of l

1070
01:02:25,920 --> 01:02:31,520
operator

1071
01:02:28,240 --> 01:02:34,319
operating on xt minus mu is equal to the

1072
01:02:31,520 --> 01:02:40,640
white noise.

1073
01:02:34,319 --> 01:02:46,160
And so that model basically says that XT

1074
01:02:40,640 --> 01:02:49,440
is a linear combination of the P lags of

1075
01:02:46,160 --> 01:02:54,079
XT plus white noise.

1076
01:02:49,440 --> 01:02:58,240
So this is a regression model for our

1077
01:02:54,079 --> 01:03:03,760
time series XT using predictor variables

1078
01:02:58,240 --> 01:03:08,319
the lags of this time series. And if we

1079
01:03:03,760 --> 01:03:12,480
take expectations of both sides,

1080
01:03:08,319 --> 01:03:14,799
we basically get mu

1081
01:03:12,480 --> 01:03:17,440
the constant

1082
01:03:14,799 --> 01:03:21,359
expectation of the coariant stationary

1083
01:03:17,440 --> 01:03:25,039
process is equal to C plus the sum of FJ

1084
01:03:21,359 --> 01:03:26,559
times mu, the expectation of each of the

1085
01:03:25,039 --> 01:03:30,559
lags

1086
01:03:26,559 --> 01:03:33,599
plus zero. And so C turns out to equal

1087
01:03:30,559 --> 01:03:36,160
mu * V of 1.

1088
01:03:33,599 --> 01:03:40,160
So u

1089
01:03:36,160 --> 01:03:43,640
we have that uh representation of the

1090
01:03:40,160 --> 01:03:43,640
constant term.

1091
01:03:44,480 --> 01:03:48,240
Now

1092
01:03:46,000 --> 01:03:53,359
what's

1093
01:03:48,240 --> 01:03:56,559
important with time series models is

1094
01:03:53,359 --> 01:04:00,240
whether the time series model

1095
01:03:56,559 --> 01:04:02,960
is stationary or not.

1096
01:04:00,240 --> 01:04:05,119
And

1097
01:04:02,960 --> 01:04:08,559
it turns out that for an auto

1098
01:04:05,119 --> 01:04:10,559
reggressive model with parameters f1 to

1099
01:04:08,559 --> 01:04:15,359
fp

1100
01:04:10,559 --> 01:04:19,240
that if we look at what's called this

1101
01:04:15,359 --> 01:04:19,240
characteristic equation

1102
01:04:19,520 --> 01:04:26,240
1 minus v1 z

1103
01:04:22,799 --> 01:04:28,160
minus v2 z ^ 2 up to pp z to the p

1104
01:04:26,240 --> 01:04:32,480
power.

1105
01:04:28,160 --> 01:04:35,480
If we consider the roots of that

1106
01:04:32,480 --> 01:04:35,480
polomial

1107
01:04:35,599 --> 01:04:42,240
then well if we have roots lambda 1 to

1108
01:04:39,760 --> 01:04:44,240
lambda p

1109
01:04:42,240 --> 01:04:48,079
then

1110
01:04:44,240 --> 01:04:51,359
f of l has to be the product of these

1111
01:04:48,079 --> 01:04:54,319
terms. each of these terms,

1112
01:04:51,359 --> 01:04:59,119
each of these factors are equal to zero

1113
01:04:54,319 --> 01:05:03,000
when sort of z equals

1114
01:04:59,119 --> 01:05:03,000
uh lambda 1.

1115
01:05:03,119 --> 01:05:10,640
So if z equals lambda 1 then the first

1116
01:05:07,119 --> 01:05:14,240
term is zero. If z equals the p

1117
01:05:10,640 --> 01:05:17,200
root lambda p then this last factor is

1118
01:05:14,240 --> 01:05:20,000
zero. So this is a representation of

1119
01:05:17,200 --> 01:05:23,960
this peace order polomial

1120
01:05:20,000 --> 01:05:23,960
in terms of its roots

1121
01:05:24,720 --> 01:05:30,640
and the condition for stationerity is

1122
01:05:27,680 --> 01:05:33,280
that all of these roots have to lie

1123
01:05:30,640 --> 01:05:36,880
outside the unit circle

1124
01:05:33,280 --> 01:05:40,400
in the complex plane.

1125
01:05:36,880 --> 01:05:45,119
And so um

1126
01:05:40,400 --> 01:05:50,480
if we look at one of these roots

1127
01:05:45,119 --> 01:05:56,079
fix just lambda as a root then if we

1128
01:05:50,480 --> 01:05:58,400
take the inverse of this factor

1129
01:05:56,079 --> 01:06:01,599
it has this geometric

1130
01:05:58,400 --> 01:06:04,960
sum expression

1131
01:06:01,599 --> 01:06:07,599
of 1 + 1 over lambda l + 1 over lambda^

1132
01:06:04,960 --> 01:06:11,200
2 l^2 and so forth.

1133
01:06:07,599 --> 01:06:13,440
And so it's basically an infinite order

1134
01:06:11,200 --> 01:06:16,480
polomial

1135
01:06:13,440 --> 01:06:19,200
in lags.

1136
01:06:16,480 --> 01:06:22,799
Um and the coefficients are one over

1137
01:06:19,200 --> 01:06:27,839
lambda to the i power.

1138
01:06:22,799 --> 01:06:30,160
So if these lambdas are bigger than one

1139
01:06:27,839 --> 01:06:34,240
in magnitude

1140
01:06:30,160 --> 01:06:38,160
then the inverse of those

1141
01:06:34,240 --> 01:06:41,520
the reciprocal of those is uh smaller

1142
01:06:38,160 --> 01:06:43,920
than one in magnitude. So these terms

1143
01:06:41,520 --> 01:06:47,599
will die down

1144
01:06:43,920 --> 01:06:50,880
with a limiting value of zero

1145
01:06:47,599 --> 01:06:52,559
and that's necessary for this

1146
01:06:50,880 --> 01:06:54,160
representation

1147
01:06:52,559 --> 01:06:56,559
to

1148
01:06:54,160 --> 01:07:00,480
be appropriate.

1149
01:06:56,559 --> 01:07:03,920
So we get a co-variance stationary

1150
01:07:00,480 --> 01:07:08,720
sum of lagged errors

1151
01:07:03,920 --> 01:07:12,400
uh lagged white noise terms um with this

1152
01:07:08,720 --> 01:07:14,880
uh representation. So the f inverse of L

1153
01:07:12,400 --> 01:07:18,400
is actually the product

1154
01:07:14,880 --> 01:07:21,280
of P of these

1155
01:07:18,400 --> 01:07:24,480
reciprocals.

1156
01:07:21,280 --> 01:07:28,720
And so the condition that each of those

1157
01:07:24,480 --> 01:07:32,799
reciprocals or or each of those terms is

1158
01:07:28,720 --> 01:07:35,520
defined by lambda js that are bigger

1159
01:07:32,799 --> 01:07:39,599
than one in magnitude

1160
01:07:35,520 --> 01:07:43,039
makes their geometric series expression

1161
01:07:39,599 --> 01:07:45,599
converge. If the lambdas

1162
01:07:43,039 --> 01:07:49,039
were inside the unit circle the

1163
01:07:45,599 --> 01:07:51,520
magnitude then when we multiply them

1164
01:07:49,039 --> 01:07:53,760
together square them they get bigger and

1165
01:07:51,520 --> 01:07:56,319
bigger.

1166
01:07:53,760 --> 01:07:59,599
Okay. Um

1167
01:07:56,319 --> 01:08:01,440
so let's take a look at what this

1168
01:07:59,599 --> 01:08:05,200
works out to be just for an auto

1169
01:08:01,440 --> 01:08:08,079
reggressive process with p equal to 1.

1170
01:08:05,200 --> 01:08:12,880
with P equal to 1, our characteristic

1171
01:08:08,079 --> 01:08:16,640
equation is simply 1 minus V Z = Z. And

1172
01:08:12,880 --> 01:08:19,520
so the root of that is clearly 1 over

1173
01:08:16,640 --> 01:08:24,239
FE.

1174
01:08:19,520 --> 01:08:26,080
And so the a the p= 1 auto reggressive

1175
01:08:24,239 --> 01:08:29,359
model is going to be coariant stationary

1176
01:08:26,080 --> 01:08:32,640
if and only if the magnitude of fee is

1177
01:08:29,359 --> 01:08:34,880
smaller than one or equivalently

1178
01:08:32,640 --> 01:08:36,400
its inverse magnitude is greater than

1179
01:08:34,880 --> 01:08:41,679
one.

1180
01:08:36,400 --> 01:08:45,279
And so we end up having these first and

1181
01:08:41,679 --> 01:08:49,359
second moments and these co-variances

1182
01:08:45,279 --> 01:08:52,560
which are very easy to compute.

1183
01:08:49,359 --> 01:08:55,199
And you know this will probably be an

1184
01:08:52,560 --> 01:08:57,839
homework exercise problem. But with the

1185
01:08:55,199 --> 01:08:59,679
first order auto reggression model, we

1186
01:08:57,839 --> 01:09:02,480
have a constant mean, a constant

1187
01:08:59,679 --> 01:09:05,199
variance, which is sigma squar over 1

1188
01:09:02,480 --> 01:09:08,319
minus v

1189
01:09:05,199 --> 01:09:10,000
time sigma squared. And uh the

1190
01:09:08,319 --> 01:09:14,080
co-variances

1191
01:09:10,000 --> 01:09:18,080
basically are the variance

1192
01:09:14,080 --> 01:09:19,600
times f to the j power. So with an

1193
01:09:18,080 --> 01:09:24,719
autocorrelation

1194
01:09:19,600 --> 01:09:27,679
uh the fee is the first

1195
01:09:24,719 --> 01:09:31,679
order autocorrelation and fee to the J

1196
01:09:27,679 --> 01:09:37,520
is the J order autocorrelation.

1197
01:09:31,679 --> 01:09:39,199
Okay. Now if f is

1198
01:09:37,520 --> 01:09:43,279
um

1199
01:09:39,199 --> 01:09:46,799
between or minus one and one or for fee

1200
01:09:43,279 --> 01:09:50,640
between zero and one the process

1201
01:09:46,799 --> 01:09:55,040
uh exhibits exponential mean reversion

1202
01:09:50,640 --> 01:09:57,600
and when fee is negative

1203
01:09:55,040 --> 01:10:00,400
but no larger than negative one in

1204
01:09:57,600 --> 01:10:04,159
magnitude then it exhibits some

1205
01:10:00,400 --> 01:10:08,000
oscillating exponential mean reversion.

1206
01:10:04,159 --> 01:10:11,120
But when f equals 1, then the wool

1207
01:10:08,000 --> 01:10:12,719
decomposition does not exist and the

1208
01:10:11,120 --> 01:10:16,560
process

1209
01:10:12,719 --> 01:10:18,800
is a simple random walk which is

1210
01:10:16,560 --> 01:10:21,840
non-stationary

1211
01:10:18,800 --> 01:10:26,640
and when fee is greater than one then

1212
01:10:21,840 --> 01:10:30,640
the process is explosive.

1213
01:10:26,640 --> 01:10:33,120
So uh in financial markets there these

1214
01:10:30,640 --> 01:10:37,600
first order auto reggressive models

1215
01:10:33,120 --> 01:10:40,480
actually are used quite frequently with

1216
01:10:37,600 --> 01:10:43,360
interest rates where there's maybe a

1217
01:10:40,480 --> 01:10:46,800
constant long-term interest rate level

1218
01:10:43,360 --> 01:10:49,440
and there's variation about that. This

1219
01:10:46,800 --> 01:10:52,640
olbeck process corresponds to the first

1220
01:10:49,440 --> 01:10:54,480
order auto reggressive process.

1221
01:10:52,640 --> 01:10:59,760
um

1222
01:10:54,480 --> 01:11:02,000
with these other series um these are

1223
01:10:59,760 --> 01:11:04,320
financial

1224
01:11:02,000 --> 01:11:08,800
or time series and financial markets

1225
01:11:04,320 --> 01:11:12,080
where the level of the series is

1226
01:11:08,800 --> 01:11:15,760
expected to be stable over time. So

1227
01:11:12,080 --> 01:11:19,600
perhaps interest rate spreads would be

1228
01:11:15,760 --> 01:11:24,159
modeled as being stable or stationary.

1229
01:11:19,600 --> 01:11:29,120
real exchange rates perhaps or valuation

1230
01:11:24,159 --> 01:11:33,679
ratios. Um so so these models arise in

1231
01:11:29,120 --> 01:11:38,000
these uh application areas. Now to fit

1232
01:11:33,679 --> 01:11:40,560
um an auto reggressive process

1233
01:11:38,000 --> 01:11:43,520
um

1234
01:11:40,560 --> 01:11:45,040
and we could simply just fit a linear

1235
01:11:43,520 --> 01:11:49,679
regression

1236
01:11:45,040 --> 01:11:53,280
model with p lags of the series as uh

1237
01:11:49,679 --> 01:11:58,719
explanatory variables. But what's rather

1238
01:11:53,280 --> 01:12:02,400
interesting to know is this approach

1239
01:11:58,719 --> 01:12:06,800
called ule uh solving ule walker

1240
01:12:02,400 --> 01:12:08,719
equations. If we take our model

1241
01:12:06,800 --> 01:12:12,000
equation,

1242
01:12:08,719 --> 01:12:14,560
that first equation line, we have the

1243
01:12:12,000 --> 01:12:18,239
mean deviation

1244
01:12:14,560 --> 01:12:24,640
of XT is equal to a linear combination

1245
01:12:18,239 --> 01:12:27,520
of FJ times the J lag deviation from U.

1246
01:12:24,640 --> 01:12:32,800
There's a typo there. That second

1247
01:12:27,520 --> 01:12:36,960
uh F2 should have an XT minus 2. Um then

1248
01:12:32,800 --> 01:12:41,360
if we multiply both sides of this model

1249
01:12:36,960 --> 01:12:44,400
equation by Xt minus J minus mu

1250
01:12:41,360 --> 01:12:49,120
then we basically for each term we're

1251
01:12:44,400 --> 01:12:52,400
adding XT minus J minus mu as a factor

1252
01:12:49,120 --> 01:12:55,280
and then take expectations of that we

1253
01:12:52,400 --> 01:12:59,280
have our J

1254
01:12:55,280 --> 01:13:01,840
lag auto covariance

1255
01:12:59,280 --> 01:13:05,600
and it's equal to

1256
01:13:01,840 --> 01:13:07,760
the F1 * the J minus1

1257
01:13:05,600 --> 01:13:12,960
lag autocariance

1258
01:13:07,760 --> 01:13:15,679
plus F2 * the J minus 2 lag and so forth

1259
01:13:12,960 --> 01:13:21,040
and if

1260
01:13:15,679 --> 01:13:25,040
the J is equal to zero then we also have

1261
01:13:21,040 --> 01:13:29,760
a sigma squared term where we're looking

1262
01:13:25,040 --> 01:13:34,000
at um basically that that well that term

1263
01:13:29,760 --> 01:13:36,960
comes comes in. So um so we basically

1264
01:13:34,000 --> 01:13:40,719
have equations

1265
01:13:36,960 --> 01:13:43,280
a system of equations

1266
01:13:40,719 --> 01:13:45,760
if we vary J

1267
01:13:43,280 --> 01:13:48,719
and so if we consider J equal to one to

1268
01:13:45,760 --> 01:13:50,960
P we get a system of P linear equations

1269
01:13:48,719 --> 01:13:56,480
in the FJS

1270
01:13:50,960 --> 01:13:59,360
and this is our U walker equations gamma

1271
01:13:56,480 --> 01:14:02,880
one is equal to the first row of the

1272
01:13:59,360 --> 01:14:04,400
matrix times the vector of fees and so

1273
01:14:02,880 --> 01:14:06,800
forth.

1274
01:14:04,400 --> 01:14:08,800
And with the properties of the

1275
01:14:06,800 --> 01:14:11,120
autocovariances,

1276
01:14:08,800 --> 01:14:16,159
they are symmetrical.

1277
01:14:11,120 --> 01:14:18,560
So we can actually use these to uh

1278
01:14:16,159 --> 01:14:23,440
make the computations of of the

1279
01:14:18,560 --> 01:14:25,440
matrices. And when we use this Ule

1280
01:14:23,440 --> 01:14:26,960
Walker approach to estimate the

1281
01:14:25,440 --> 01:14:30,400
parameters,

1282
01:14:26,960 --> 01:14:36,159
we're actually using a sort of method of

1283
01:14:30,400 --> 01:14:39,199
moments principle for estimating the

1284
01:14:36,159 --> 01:14:42,320
auto reggressive model parameters.

1285
01:14:39,199 --> 01:14:45,440
Method of moments is a principle in

1286
01:14:42,320 --> 01:14:49,440
statistical estimation where we

1287
01:14:45,440 --> 01:14:52,640
basically equate sample moments and the

1288
01:14:49,440 --> 01:14:55,600
population moments and solve for what

1289
01:14:52,640 --> 01:14:58,400
population parameter values match the

1290
01:14:55,600 --> 01:15:02,400
sample moments.

1291
01:14:58,400 --> 01:15:06,320
Now uh we can do a similar analysis of

1292
01:15:02,400 --> 01:15:08,320
moving average models. So here we have a

1293
01:15:06,320 --> 01:15:13,199
Qth order moving average model

1294
01:15:08,320 --> 01:15:19,120
represented by a polomial theta of L of

1295
01:15:13,199 --> 01:15:22,320
order Q in terms of powers of L. And um

1296
01:15:19,120 --> 01:15:26,560
the properties of this process

1297
01:15:22,320 --> 01:15:32,719
can be studied. And one thing we might

1298
01:15:26,560 --> 01:15:38,960
want to do is invert this moving average

1299
01:15:32,719 --> 01:15:42,480
model into an auto reggressive model

1300
01:15:38,960 --> 01:15:44,719
by basically modeling multiplying the

1301
01:15:42,480 --> 01:15:49,920
model equation on both sides by the

1302
01:15:44,719 --> 01:15:53,760
inverse of the theta of L operator.

1303
01:15:49,920 --> 01:15:56,880
And so if we do that um then we

1304
01:15:53,760 --> 01:15:58,480
basically have an auto reggressive

1305
01:15:56,880 --> 01:16:02,480
representation

1306
01:15:58,480 --> 01:16:04,800
of the moving average order Q model.

1307
01:16:02,480 --> 01:16:06,320
And if you calculate

1308
01:16:04,800 --> 01:16:08,320
simple

1309
01:16:06,320 --> 01:16:11,760
second order properties of this moving

1310
01:16:08,320 --> 01:16:13,600
average process, well the mean is simply

1311
01:16:11,760 --> 01:16:16,320
mu.

1312
01:16:13,600 --> 01:16:17,920
The right hand side of the equation is

1313
01:16:16,320 --> 01:16:20,560
just

1314
01:16:17,920 --> 01:16:24,640
weighted sums of adas which have mean

1315
01:16:20,560 --> 01:16:27,199
zero. And so the expectation of the left

1316
01:16:24,640 --> 01:16:30,400
hand side is simply equal to mu. And if

1317
01:16:27,199 --> 01:16:33,520
we look at the variance of xt

1318
01:16:30,400 --> 01:16:36,719
um it basically is the variance of the

1319
01:16:33,520 --> 01:16:39,600
weighted sum of the adas.

1320
01:16:36,719 --> 01:16:41,120
And it turns out to have this simple

1321
01:16:39,600 --> 01:16:45,520
form

1322
01:16:41,120 --> 01:16:48,719
with co-variances of the series

1323
01:16:45,520 --> 01:16:54,000
with moving average processes. If we

1324
01:16:48,719 --> 01:16:59,280
look at time increments J that are

1325
01:16:54,000 --> 01:17:03,760
longer than the Q order, then there's no

1326
01:16:59,280 --> 01:17:06,480
overlap of white noise terms

1327
01:17:03,760 --> 01:17:09,199
in XT and XT plus J. And so their

1328
01:17:06,480 --> 01:17:10,960
co-variance is going to be zero. When

1329
01:17:09,199 --> 01:17:13,199
there is overlap then we get this

1330
01:17:10,960 --> 01:17:16,880
formula.

1331
01:17:13,199 --> 01:17:24,880
Okay. Uh so next

1332
01:17:16,880 --> 01:17:27,280
um we want to uh deal with how we can

1333
01:17:24,880 --> 01:17:30,239
accommodate non-stationerity and time

1334
01:17:27,280 --> 01:17:32,640
series. So far we've just assumed

1335
01:17:30,239 --> 01:17:34,480
examples and models like auto

1336
01:17:32,640 --> 01:17:38,800
reggressive and moving average models

1337
01:17:34,480 --> 01:17:41,280
where this series is stationary.

1338
01:17:38,800 --> 01:17:43,679
There will be cases when our time series

1339
01:17:41,280 --> 01:17:45,440
is not stationary

1340
01:17:43,679 --> 01:17:48,320
and

1341
01:17:45,440 --> 01:17:51,600
differencing the series

1342
01:17:48,320 --> 01:17:54,719
will generally render a series to a

1343
01:17:51,600 --> 01:17:56,800
stationary uh transformation.

1344
01:17:54,719 --> 01:17:58,880
And so

1345
01:17:56,800 --> 01:18:02,760
if we consider

1346
01:17:58,880 --> 01:18:02,760
first order differencing

1347
01:18:03,360 --> 01:18:06,679
we have

1348
01:18:06,719 --> 01:18:14,159
let's see here if we do deltayt

1349
01:18:10,400 --> 01:18:16,000
equaling 1 - l yt

1350
01:18:14,159 --> 01:18:18,560
= yt

1351
01:18:16,000 --> 01:18:22,560
minus l yt

1352
01:18:18,560 --> 01:18:25,120
which is yt minus yt minus one. Okay,

1353
01:18:22,560 --> 01:18:27,199
this is first order differences.

1354
01:18:25,120 --> 01:18:29,440
If we

1355
01:18:27,199 --> 01:18:31,360
apply the

1356
01:18:29,440 --> 01:18:35,520
first difference of this, we end up

1357
01:18:31,360 --> 01:18:41,120
getting yt - yt -1

1358
01:18:35,520 --> 01:18:44,960
- yt -1 - ytus 2.

1359
01:18:41,120 --> 01:18:46,880
And this turns out to be equal to yt - 2

1360
01:18:44,960 --> 01:18:51,280
ytus1

1361
01:18:46,880 --> 01:18:53,280
+ ytus 2.

1362
01:18:51,280 --> 01:18:56,239
And there could be kith order

1363
01:18:53,280 --> 01:18:58,560
differencing, but in practice we'll only

1364
01:18:56,239 --> 01:19:01,920
generally use first or second order

1365
01:18:58,560 --> 01:19:05,199
differencing. And what's really neat

1366
01:19:01,920 --> 01:19:07,040
about differencing is that first order

1367
01:19:05,199 --> 01:19:10,640
differencing

1368
01:19:07,040 --> 01:19:12,320
will eliminate a linear trend in the

1369
01:19:10,640 --> 01:19:14,400
series.

1370
01:19:12,320 --> 01:19:17,280
Basically, if we have a linear trend,

1371
01:19:14,400 --> 01:19:20,320
then the difference will just be a

1372
01:19:17,280 --> 01:19:23,040
constant difference.

1373
01:19:20,320 --> 01:19:24,640
And the second order difference is

1374
01:19:23,040 --> 01:19:29,920
appropriate

1375
01:19:24,640 --> 01:19:33,440
if there is a sort of quadratic

1376
01:19:29,920 --> 01:19:35,040
um trend in the series and second order

1377
01:19:33,440 --> 01:19:38,560
differencing will eliminate that

1378
01:19:35,040 --> 01:19:42,960
quadratic trend. So we'll finish there

1379
01:19:38,560 --> 01:19:45,520
for today. But this issue of modeling

1380
01:19:42,960 --> 01:19:48,480
differences of the series

1381
01:19:45,520 --> 01:19:52,080
or second differences of the series as

1382
01:19:48,480 --> 01:19:54,880
stationary corresponds to having time

1383
01:19:52,080 --> 01:19:59,679
series models that are looking at the

1384
01:19:54,880 --> 01:20:01,360
dynamics of the slope of the time series

1385
01:19:59,679 --> 01:20:03,600
or

1386
01:20:01,360 --> 01:20:06,080
which is like the first derivative or

1387
01:20:03,600 --> 01:20:09,600
the second derivative

1388
01:20:06,080 --> 01:20:14,080
and assuming that those are perhaps

1389
01:20:09,600 --> 01:20:16,719
constant level and constant variability.

1390
01:20:14,080 --> 01:20:20,800
So, so those mathematical features end

1391
01:20:16,719 --> 01:20:23,120
up now being very intuitive uhly applied

1392
01:20:20,800 --> 01:20:27,960
actually with with different cases.

1393
01:20:23,120 --> 01:20:27,960
Okay, we'll finish there for today.


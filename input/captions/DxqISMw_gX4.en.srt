1
00:00:00,320 --> 00:00:04,240
Thank you so much for for inviting me.

2
00:00:02,320 --> 00:00:06,720
It's really pleasure to be here and I'm

3
00:00:04,240 --> 00:00:09,360
excited to tell you what we're working

4
00:00:06,720 --> 00:00:12,719
on except you know especially because I

5
00:00:09,360 --> 00:00:14,480
do feel that the work I do and my lab is

6
00:00:12,719 --> 00:00:16,560
highly complimementaryary of the work

7
00:00:14,480 --> 00:00:18,960
that you do and I think that there will

8
00:00:16,560 --> 00:00:21,439
be so many opportunity to do some great

9
00:00:18,960 --> 00:00:25,199
work together. So so this is a little

10
00:00:21,439 --> 00:00:30,800
bit of kind of a journey of my research

11
00:00:25,199 --> 00:00:33,680
and and my my lab. I really like to

12
00:00:30,800 --> 00:00:35,680
do work that is highly motivated by

13
00:00:33,680 --> 00:00:37,840
really important scientific question and

14
00:00:35,680 --> 00:00:39,600
so I'll tell you what what is the kind

15
00:00:37,840 --> 00:00:42,800
of trillion dollar question that I've

16
00:00:39,600 --> 00:00:45,840
been chasing for a very long time and

17
00:00:42,800 --> 00:00:48,399
what I'm doing right now in terms of joi

18
00:00:45,840 --> 00:00:50,160
for our pollution exposure and the work

19
00:00:48,399 --> 00:00:52,719
we are doing on the first foundation

20
00:00:50,160 --> 00:00:54,719
model for climate adaptation and then I

21
00:00:52,719 --> 00:00:56,239
switch on the responsible AI in terms of

22
00:00:54,719 --> 00:00:59,760
thinking about the environmental impact

23
00:00:56,239 --> 00:01:02,800
of AI and I think that where I am right

24
00:00:59,760 --> 00:01:06,799
now in my research journey is that in

25
00:01:02,800 --> 00:01:10,159
one hand I very excited about developing

26
00:01:06,799 --> 00:01:13,280
this foundation model to prevent deaths

27
00:01:10,159 --> 00:01:14,960
from extreme weather event and climate

28
00:01:13,280 --> 00:01:16,960
and on the other side I'm also

29
00:01:14,960 --> 00:01:19,680
quantifying the environmental impact of

30
00:01:16,960 --> 00:01:21,680
AI and so which of the two is going to

31
00:01:19,680 --> 00:01:23,840
win uh I still don't know but it's

32
00:01:21,680 --> 00:01:26,240
actually is an interesting space and I

33
00:01:23,840 --> 00:01:28,479
feel that's where research is is a being

34
00:01:26,240 --> 00:01:30,560
on this space of always feeling

35
00:01:28,479 --> 00:01:32,479
ambivalent of what is the right thing to

36
00:01:30,560 --> 00:01:35,920
do. So I think that's where I'm going to

37
00:01:32,479 --> 00:01:37,360
start. It's really you know are we if

38
00:01:35,920 --> 00:01:40,720
you're thinking I'm going to give you an

39
00:01:37,360 --> 00:01:44,159
answer in an hour. No. uh but at least I

40
00:01:40,720 --> 00:01:47,680
can tell you where I am at in with in my

41
00:01:44,159 --> 00:01:49,520
my research lab where literally we have

42
00:01:47,680 --> 00:01:51,280
two post-docctoral fellows that they're

43
00:01:49,520 --> 00:01:54,399
best friends with each other where one

44
00:01:51,280 --> 00:01:56,159
is trying to you know use as many GPUs

45
00:01:54,399 --> 00:01:58,479
as possible and the other one is trying

46
00:01:56,159 --> 00:02:00,000
to use as less as GPUs as possible and

47
00:01:58,479 --> 00:02:02,000
they're still talking to each other and

48
00:02:00,000 --> 00:02:05,200
they're playing music together. So

49
00:02:02,000 --> 00:02:07,280
anyway, so um here is a date kind of

50
00:02:05,200 --> 00:02:09,520
trillion dollar question I'm asking uh

51
00:02:07,280 --> 00:02:11,440
and you know basically does exposure to

52
00:02:09,520 --> 00:02:13,200
find particular matters even a level

53
00:02:11,440 --> 00:02:16,239
below the national ambient air quality

54
00:02:13,200 --> 00:02:18,400
standard are still safe to human health

55
00:02:16,239 --> 00:02:20,879
and is there pollution from coal fire

56
00:02:18,400 --> 00:02:22,959
powered plants more toxic than air

57
00:02:20,879 --> 00:02:25,440
pollution from other sources you know

58
00:02:22,959 --> 00:02:28,160
how do we quantify the environmental

59
00:02:25,440 --> 00:02:30,080
impact of wildfires you know this is the

60
00:02:28,160 --> 00:02:31,760
type of policy relevant question which

61
00:02:30,080 --> 00:02:35,040
right now actually thanks to be even

62
00:02:31,760 --> 00:02:36,560
more uh more more more contentious more

63
00:02:35,040 --> 00:02:38,319
contentious.

64
00:02:36,560 --> 00:02:40,879
So that's are the scientific question

65
00:02:38,319 --> 00:02:43,040
and then on the other side I am really

66
00:02:40,879 --> 00:02:45,200
interested in causal inference and try

67
00:02:43,040 --> 00:02:48,239
to go from causal inference from analyst

68
00:02:45,200 --> 00:02:50,400
observational data to causal inference

69
00:02:48,239 --> 00:02:53,200
and thinking about AI that can think

70
00:02:50,400 --> 00:02:57,599
about causal cause and effect. I want to

71
00:02:53,200 --> 00:02:58,959
mention this book and Elias Baron um I

72
00:02:57,599 --> 00:03:02,239
don't know how many of you are familiar

73
00:02:58,959 --> 00:03:04,480
of him. was a student of Judia Pearl. He

74
00:03:02,239 --> 00:03:06,720
has published this book called causal

75
00:03:04,480 --> 00:03:09,920
artificial intelligence

76
00:03:06,720 --> 00:03:12,720
and I found the introduction very

77
00:03:09,920 --> 00:03:15,440
helpful in terms of framing where we are

78
00:03:12,720 --> 00:03:16,800
in the world of causal inference and so

79
00:03:15,440 --> 00:03:20,159
uh and that's something I've been

80
00:03:16,800 --> 00:03:22,800
thinking about uh very long time but I

81
00:03:20,159 --> 00:03:25,760
do think it's important to frame my talk

82
00:03:22,800 --> 00:03:29,519
within this framework. So first of all I

83
00:03:25,760 --> 00:03:31,680
think you know uh the Judea Pearl

84
00:03:29,519 --> 00:03:33,360
introduced this causal hierarchy. So

85
00:03:31,680 --> 00:03:35,840
actually this is not even Elizabeth Bar

86
00:03:33,360 --> 00:03:39,519
it's really Judia Pearl which he has in

87
00:03:35,840 --> 00:03:42,239
included this he has introduced this um

88
00:03:39,519 --> 00:03:45,440
causal hierarchy that is basically the

89
00:03:42,239 --> 00:03:48,480
first level which is the red level is

90
00:03:45,440 --> 00:03:51,280
just seeing right you have observational

91
00:03:48,480 --> 00:03:53,360
data and you're trying to run a model to

92
00:03:51,280 --> 00:03:56,480
figure out an association between X and

93
00:03:53,360 --> 00:03:59,519
Y right analysis observational data then

94
00:03:56,480 --> 00:04:01,280
the second layer for causal inference is

95
00:03:59,519 --> 00:04:04,480
what would they call it the intervention

96
00:04:01,280 --> 00:04:07,599
ional which is if I change something

97
00:04:04,480 --> 00:04:10,640
right so if I which is called doing

98
00:04:07,599 --> 00:04:13,280
right what if what if I do X then what's

99
00:04:10,640 --> 00:04:15,040
going to be the causal effect on Y right

100
00:04:13,280 --> 00:04:18,079
and then there is the third part which

101
00:04:15,040 --> 00:04:21,199
is a counterfactual imaging which is

102
00:04:18,079 --> 00:04:23,840
what will be the effect of acting on

103
00:04:21,199 --> 00:04:26,880
something that will never see that

104
00:04:23,840 --> 00:04:28,880
actually has never happened right and so

105
00:04:26,880 --> 00:04:30,960
I I thought that this was a good frame

106
00:04:28,880 --> 00:04:32,560
because that's how my research evolution

107
00:04:30,960 --> 00:04:34,560
has been going in the context of

108
00:04:32,560 --> 00:04:37,840
environmental impact from and I'm going

109
00:04:34,560 --> 00:04:40,880
to show you from associational to causal

110
00:04:37,840 --> 00:04:44,560
inference to now foundation model which

111
00:04:40,880 --> 00:04:47,520
is counterfactual um imaging. So the

112
00:04:44,560 --> 00:04:52,000
actually this is something that I wrote

113
00:04:47,520 --> 00:04:53,759
before I bomb and before um Judia Pearl

114
00:04:52,000 --> 00:04:56,400
framework although I really recognize

115
00:04:53,759 --> 00:04:59,600
the jud framework is is really useful

116
00:04:56,400 --> 00:05:01,600
and so basically just to get a narrow

117
00:04:59,600 --> 00:05:03,919
down to the scientific question

118
00:05:01,600 --> 00:05:06,560
basically with Cory Ziger who's a

119
00:05:03,919 --> 00:05:09,199
professor at Brown we wrote this paper

120
00:05:06,560 --> 00:05:12,080
where basically you know try to really

121
00:05:09,199 --> 00:05:14,080
think about the question about seeing

122
00:05:12,080 --> 00:05:15,520
which is basically is exposure ure to

123
00:05:14,080 --> 00:05:17,199
find particular matter which are

124
00:05:15,520 --> 00:05:19,520
pollutant in the air below the national

125
00:05:17,199 --> 00:05:21,440
ambient air quality standard associated

126
00:05:19,520 --> 00:05:23,199
with increase in mortality right that's

127
00:05:21,440 --> 00:05:26,800
an associational question second

128
00:05:23,199 --> 00:05:28,479
question is what if I intervene by

129
00:05:26,800 --> 00:05:30,000
implementing strict international

130
00:05:28,479 --> 00:05:32,080
ambient air quality standard what's

131
00:05:30,000 --> 00:05:34,720
going to be the number of lives saved

132
00:05:32,080 --> 00:05:36,880
and then what is imaging which is like

133
00:05:34,720 --> 00:05:38,479
let's imagine an alternative world where

134
00:05:36,880 --> 00:05:40,880
we have implemented the series of

135
00:05:38,479 --> 00:05:43,919
strategy to cut their pollution or to

136
00:05:40,880 --> 00:05:45,680
cut greenhouse gases then what will be

137
00:05:43,919 --> 00:05:48,080
the positive consequence on society,

138
00:05:45,680 --> 00:05:50,400
right? And so my mental framework in

139
00:05:48,080 --> 00:05:52,400
terms of thinking about methodological

140
00:05:50,400 --> 00:05:55,759
innovation in statistics and computer

141
00:05:52,400 --> 00:05:58,720
science and AI has been following this

142
00:05:55,759 --> 00:06:00,479
type of framework in in the last 15

143
00:05:58,720 --> 00:06:03,199
years.

144
00:06:00,479 --> 00:06:05,360
Now I you know I always say that

145
00:06:03,199 --> 00:06:08,000
everything you need to start I mean one

146
00:06:05,360 --> 00:06:09,680
of the premise I always work on is data.

147
00:06:08,000 --> 00:06:10,880
you know without data especially if

148
00:06:09,680 --> 00:06:13,120
you're trying to address an important

149
00:06:10,880 --> 00:06:15,840
question you know there is there is

150
00:06:13,120 --> 00:06:18,560
nothing else so I've been really

151
00:06:15,840 --> 00:06:20,720
spending part of my career into

152
00:06:18,560 --> 00:06:22,880
assembling a data science team that

153
00:06:20,720 --> 00:06:25,840
pretty much harnessed data from the

154
00:06:22,880 --> 00:06:27,759
entire US healthcare system and so and

155
00:06:25,840 --> 00:06:29,600
that's where you see now the excitement

156
00:06:27,759 --> 00:06:32,639
about potentially surrounding foundation

157
00:06:29,600 --> 00:06:36,000
model on uh claims data from entire US

158
00:06:32,639 --> 00:06:39,120
healthcare system so we we um harmonize

159
00:06:36,000 --> 00:06:43,039
we buy harmonize integ great huge amount

160
00:06:39,120 --> 00:06:45,840
of data engineering uh data set from

161
00:06:43,039 --> 00:06:48,080
over 20 government data sources that

162
00:06:45,840 --> 00:06:51,120
pretty much measure everything about

163
00:06:48,080 --> 00:06:53,120
environment everything about society and

164
00:06:51,120 --> 00:06:56,160
then health outcomes and so the health

165
00:06:53,120 --> 00:06:58,639
outcomes come comes from the Medicare

166
00:06:56,160 --> 00:07:00,720
and Medicaid claims and so basically in

167
00:06:58,639 --> 00:07:02,639
the United States there is you know

168
00:07:00,720 --> 00:07:05,360
there are two type of of national health

169
00:07:02,639 --> 00:07:07,840
insurance Medicaid all ages for people

170
00:07:05,360 --> 00:07:09,919
they have within certain lower bucket of

171
00:07:07,840 --> 00:07:12,880
soio economic status and Medicaid for

172
00:07:09,919 --> 00:07:14,880
everybody when you turn 65. And so for

173
00:07:12,880 --> 00:07:18,319
everybody, so this is our 60 million

174
00:07:14,880 --> 00:07:20,240
Americans, we know when they come into

175
00:07:18,319 --> 00:07:21,919
the system, we know their zip code of

176
00:07:20,240 --> 00:07:24,560
residence, we know age, gender, all

177
00:07:21,919 --> 00:07:26,720
kinds of basic demographic and then we

178
00:07:24,560 --> 00:07:28,960
can follow them over time for every

179
00:07:26,720 --> 00:07:32,319
single hospitalization for that cause up

180
00:07:28,960 --> 00:07:34,160
to that. So it's it's extremely rich.

181
00:07:32,319 --> 00:07:36,560
And so the same thing for Medicaid data.

182
00:07:34,160 --> 00:07:38,880
Medicaid as I mentioned is all ages but

183
00:07:36,560 --> 00:07:40,720
it's not representative in terms that

184
00:07:38,880 --> 00:07:42,479
you know you have to qualify to be

185
00:07:40,720 --> 00:07:45,120
enrolled in Medicaid that there are

186
00:07:42,479 --> 00:07:49,280
certain bucket of soio economic status.

187
00:07:45,120 --> 00:07:52,160
So basically the the research of my lab

188
00:07:49,280 --> 00:07:53,680
is literally seeing doing and now

189
00:07:52,160 --> 00:07:55,680
imagining

190
00:07:53,680 --> 00:07:57,520
in this massive amount of data right

191
00:07:55,680 --> 00:08:00,720
there are three buckets. There is as I

192
00:07:57,520 --> 00:08:02,800
mentioned exposure and the intervention.

193
00:08:00,720 --> 00:08:05,280
So basically everything about exposure

194
00:08:02,800 --> 00:08:08,240
to our pollution, wildfire exposure,

195
00:08:05,280 --> 00:08:10,400
flooding, extreme weather event, right?

196
00:08:08,240 --> 00:08:12,560
Chemical contaminants, right? That's one

197
00:08:10,400 --> 00:08:13,840
bucket. The second bucket, as I

198
00:08:12,560 --> 00:08:16,080
mentioned, all of the Medicare and

199
00:08:13,840 --> 00:08:18,319
Medicaid data. And then the third

200
00:08:16,080 --> 00:08:20,560
bucket, what we call confounders because

201
00:08:18,319 --> 00:08:24,319
these are all other variables that can

202
00:08:20,560 --> 00:08:26,400
covary with, you know, exposure to to to

203
00:08:24,319 --> 00:08:28,960
environmental contaminant and health,

204
00:08:26,400 --> 00:08:30,720
but that you need to to uh to account

205
00:08:28,960 --> 00:08:34,000
for it, you know. And one of the major

206
00:08:30,720 --> 00:08:36,399
sources of data is basically the uh the

207
00:08:34,000 --> 00:08:39,360
uh census data.

208
00:08:36,399 --> 00:08:41,120
So I mean what type of work we are doing

209
00:08:39,360 --> 00:08:43,599
with all of this right? So just you

210
00:08:41,120 --> 00:08:45,600
think about in in one hand a data

211
00:08:43,599 --> 00:08:50,880
science team a massive amount of data

212
00:08:45,600 --> 00:08:54,640
and the other is trying to see like do

213
00:08:50,880 --> 00:08:59,519
and and imagine right and so these are

214
00:08:54,640 --> 00:09:03,360
all types of challenges that we are

215
00:08:59,519 --> 00:09:06,160
working on on a daily daily daily basis

216
00:09:03,360 --> 00:09:08,880
one thing that in the work I do because

217
00:09:06,160 --> 00:09:10,399
it's impact directory policy there are

218
00:09:08,880 --> 00:09:13,360
elements that are absolutely

219
00:09:10,399 --> 00:09:15,760
nonnegotiable, right? Interpretability.

220
00:09:13,360 --> 00:09:18,000
We need to interpret our model. We need

221
00:09:15,760 --> 00:09:20,880
to reproduce that because we're trying

222
00:09:18,000 --> 00:09:23,360
to influence trillion dollar question.

223
00:09:20,880 --> 00:09:26,000
And so there's going to be audits from

224
00:09:23,360 --> 00:09:28,720
the industry that wanted to reproduce

225
00:09:26,000 --> 00:09:31,279
our our funding. We have to act

226
00:09:28,720 --> 00:09:33,760
responsibly and then we have to quantify

227
00:09:31,279 --> 00:09:36,480
uncertainty across all of the different

228
00:09:33,760 --> 00:09:38,240
stages in the most comprehensive way.

229
00:09:36,480 --> 00:09:41,040
One thing where there is a lot of work

230
00:09:38,240 --> 00:09:43,200
and probably many of you are familiar or

231
00:09:41,040 --> 00:09:47,760
have done even better work than than we

232
00:09:43,200 --> 00:09:50,399
did is actually on ensemble learning or

233
00:09:47,760 --> 00:09:52,880
prediction to estimate exposure to our

234
00:09:50,399 --> 00:09:54,880
pollution. That's is very kind of easy

235
00:09:52,880 --> 00:09:57,680
and lowanging fruit. This is not about

236
00:09:54,880 --> 00:10:00,560
causation. I just want to know this is

237
00:09:57,680 --> 00:10:02,880
the map in the United States where there

238
00:10:00,560 --> 00:10:04,320
are monitors of air pollution and you

239
00:10:02,880 --> 00:10:06,160
see that there are part of the United

240
00:10:04,320 --> 00:10:08,640
States where pollution is not monitored

241
00:10:06,160 --> 00:10:10,399
very well right where the healthc care

242
00:10:08,640 --> 00:10:12,320
data that I have is for everybody it's

243
00:10:10,399 --> 00:10:15,680
for every single zip code in the United

244
00:10:12,320 --> 00:10:18,079
States and so now there is this huge

245
00:10:15,680 --> 00:10:20,079
literature very powerful literature

246
00:10:18,079 --> 00:10:24,959
where what we try to do is we're going

247
00:10:20,079 --> 00:10:28,800
to use satellite images and many other

248
00:10:24,959 --> 00:10:31,279
variables that can allow to predict

249
00:10:28,800 --> 00:10:34,079
localized exposure to our pollution in

250
00:10:31,279 --> 00:10:35,680
in in in a very good way. So this is

251
00:10:34,079 --> 00:10:37,920
something that probably is your bread

252
00:10:35,680 --> 00:10:39,920
and butter right that that now has been

253
00:10:37,920 --> 00:10:42,000
done and it's there is a full area of

254
00:10:39,920 --> 00:10:44,079
research. So basically that could be

255
00:10:42,000 --> 00:10:47,279
threebased model, narrow network model,

256
00:10:44,079 --> 00:10:50,079
ensemble and hybrid models and the idea

257
00:10:47,279 --> 00:10:52,959
is basically take take satellite

258
00:10:50,079 --> 00:10:56,079
information which are aerosol aerosol

259
00:10:52,959 --> 00:10:58,079
optical dots which is depth which is a

260
00:10:56,079 --> 00:11:01,760
surrogate of our pollution. There are

261
00:10:58,079 --> 00:11:04,079
many other variables and then you train

262
00:11:01,760 --> 00:11:06,480
uh this model and you can you know you

263
00:11:04,079 --> 00:11:09,440
can do downscaling whatever you like and

264
00:11:06,480 --> 00:11:12,480
then you can estimate then 1 kilometer 1

265
00:11:09,440 --> 00:11:14,800
kilometer grid the daily level of

266
00:11:12,480 --> 00:11:16,640
pollution than your breed and the same

267
00:11:14,800 --> 00:11:19,279
thing you can do with exposure to

268
00:11:16,640 --> 00:11:22,000
wildfires the same thing you you can do

269
00:11:19,279 --> 00:11:24,720
with exposure to heat right I mean this

270
00:11:22,000 --> 00:11:26,800
is a very uh very simple this has been

271
00:11:24,720 --> 00:11:28,560
going around for some time but I'm

272
00:11:26,800 --> 00:11:31,360
telling you all this because that's has

273
00:11:28,560 --> 00:11:33,279
been very helpful to us because you know

274
00:11:31,360 --> 00:11:35,680
and this is actually not work I directly

275
00:11:33,279 --> 00:11:38,000
do. I just you know leverage that work

276
00:11:35,680 --> 00:11:40,880
because then with if I have a daily

277
00:11:38,000 --> 00:11:43,360
levels of pollution a 1 kilometer to 1

278
00:11:40,880 --> 00:11:46,000
kilometer grid for the last 20 years

279
00:11:43,360 --> 00:11:48,000
then I can link to health data right and

280
00:11:46,000 --> 00:11:49,839
so I can do an analysis for all the

281
00:11:48,000 --> 00:11:53,200
continental United States and not only

282
00:11:49,839 --> 00:11:57,440
for people for which air pollution data

283
00:11:53,200 --> 00:12:00,079
um is is monitored. One thing though

284
00:11:57,440 --> 00:12:02,800
that we need so all of these I told you

285
00:12:00,079 --> 00:12:06,160
there's nothing about causality right

286
00:12:02,800 --> 00:12:09,040
it's just a piece of our data science

287
00:12:06,160 --> 00:12:10,959
pipe pip pi p p p p p p p p p p p p p p

288
00:12:09,040 --> 00:12:13,440
p p p p p p pipeline that it's done very

289
00:12:10,959 --> 00:12:17,279
well and just before I go to causal

290
00:12:13,440 --> 00:12:21,200
inference allow us to really measure

291
00:12:17,279 --> 00:12:24,399
exposure for everyone right in um in in

292
00:12:21,200 --> 00:12:26,160
in a very good way by the way now there

293
00:12:24,399 --> 00:12:28,480
are things are done even better I don't

294
00:12:26,160 --> 00:12:31,680
know if you have read like the new

295
00:12:28,480 --> 00:12:33,920
foundation model called Aurora I think

296
00:12:31,680 --> 00:12:35,680
comes from Microsoft there are now all

297
00:12:33,920 --> 00:12:38,560
of these foundation model they're

298
00:12:35,680 --> 00:12:40,880
predicting hurt systems right and then

299
00:12:38,560 --> 00:12:44,399
allow to estimate exposure to pollution

300
00:12:40,880 --> 00:12:47,920
or to other phenomenal um extremely well

301
00:12:44,399 --> 00:12:50,480
that's that's a key necessary step but

302
00:12:47,920 --> 00:12:52,240
it's another part where I'm really

303
00:12:50,480 --> 00:12:56,160
focusing remember what I'm really

304
00:12:52,240 --> 00:12:58,399
focusing is seeing doing an imaging

305
00:12:56,160 --> 00:13:01,279
because I want to look at the most

306
00:12:58,399 --> 00:13:04,399
effective intervention to save life from

307
00:13:01,279 --> 00:13:06,480
exposure to our pollution or from um

308
00:13:04,399 --> 00:13:09,360
stressors.

309
00:13:06,480 --> 00:13:11,440
So that's where I started to think about

310
00:13:09,360 --> 00:13:15,279
and I want to give you the journey over

311
00:13:11,440 --> 00:13:17,519
time about how you start to combine

312
00:13:15,279 --> 00:13:19,839
causal inference in artificial

313
00:13:17,519 --> 00:13:22,720
intelligence. And even though Elias

314
00:13:19,839 --> 00:13:26,399
Bernbomb wrote an entire book about it,

315
00:13:22,720 --> 00:13:29,040
I found very hard to take some of the

316
00:13:26,399 --> 00:13:30,880
after chapter one [laughter] which is

317
00:13:29,040 --> 00:13:34,399
the introduction and the framework which

318
00:13:30,880 --> 00:13:36,800
I really like. Then after that thinking

319
00:13:34,399 --> 00:13:38,480
about policym and thinking about

320
00:13:36,800 --> 00:13:41,120
interpretability that's where he

321
00:13:38,480 --> 00:13:45,600
completely got lost, right? I mean well

322
00:13:41,120 --> 00:13:47,279
I I you know he he he lost me. maybe you

323
00:13:45,600 --> 00:13:48,560
know may maybe you will be able to stick

324
00:13:47,279 --> 00:13:52,160
with that and so that's what I'm

325
00:13:48,560 --> 00:13:54,959
thinking in a in a much more I would say

326
00:13:52,160 --> 00:13:57,040
uh practical manner of how you could

327
00:13:54,959 --> 00:13:59,839
take this artificial intelligence model

328
00:13:57,040 --> 00:14:03,360
and start to think about reasoning about

329
00:13:59,839 --> 00:14:06,639
cause um cause and effect and so you

330
00:14:03,360 --> 00:14:09,839
know remember like I come from the field

331
00:14:06,639 --> 00:14:13,680
of statistics and I've been thinking

332
00:14:09,839 --> 00:14:15,519
about causal inference from all my life

333
00:14:13,680 --> 00:14:17,680
you know even though I know I look very

334
00:14:15,519 --> 00:14:19,279
young to you, but I've been around for

335
00:14:17,680 --> 00:14:21,279
quite some time, right? So, it's

336
00:14:19,279 --> 00:14:24,560
actually starting to be Oh, I didn't put

337
00:14:21,279 --> 00:14:26,480
the Oh, no. I put the the dates there,

338
00:14:24,560 --> 00:14:29,519
right? So, some of you, you know, were

339
00:14:26,480 --> 00:14:32,000
pretty young. So, first of all, I

340
00:14:29,519 --> 00:14:34,160
started by thinking about, you know,

341
00:14:32,000 --> 00:14:38,480
even before coausal inference, right?

342
00:14:34,160 --> 00:14:41,839
When we were in the late 90s, one way of

343
00:14:38,480 --> 00:14:44,320
thinking about and you see I had in red

344
00:14:41,839 --> 00:14:47,040
when is about association. So like

345
00:14:44,320 --> 00:14:49,680
seeing I have in orange where is about

346
00:14:47,040 --> 00:14:53,040
doing which is a causal inference and

347
00:14:49,680 --> 00:14:55,120
then I have in red in in green like the

348
00:14:53,040 --> 00:14:57,040
new artificial intelligence framework

349
00:14:55,120 --> 00:14:59,760
right and I want to show you the

350
00:14:57,040 --> 00:15:02,720
trajectory of evolution of actually my

351
00:14:59,760 --> 00:15:04,720
own thinking around this field so first

352
00:15:02,720 --> 00:15:06,959
of all in the late 90s so when we're

353
00:15:04,720 --> 00:15:09,519
thinking about association that will

354
00:15:06,959 --> 00:15:11,360
think about uncertainty right and many

355
00:15:09,519 --> 00:15:13,839
of you are probably very familiar was it

356
00:15:11,360 --> 00:15:16,240
basically doing a Beijian

357
00:15:13,839 --> 00:15:18,160
regression models and then that that's

358
00:15:16,240 --> 00:15:20,079
evolved in actual invasion model

359
00:15:18,160 --> 00:15:22,800
averaging. Beta vision model averaging

360
00:15:20,079 --> 00:15:25,760
was a very powerful tools because will

361
00:15:22,800 --> 00:15:27,920
allow you to predict what will happen in

362
00:15:25,760 --> 00:15:29,600
the future averaging across the

363
00:15:27,920 --> 00:15:33,120
different models which is basically now

364
00:15:29,600 --> 00:15:34,959
what you call ensemble learning right so

365
00:15:33,120 --> 00:15:38,160
there was nothing really about causal

366
00:15:34,959 --> 00:15:42,560
inference at that point then I think in

367
00:15:38,160 --> 00:15:46,560
the in the early in in the point two in

368
00:15:42,560 --> 00:15:50,079
2000 then where I started to really

369
00:15:46,560 --> 00:15:52,320
advance the work of the potential

370
00:15:50,079 --> 00:15:54,560
outcome framework and so that is really

371
00:15:52,320 --> 00:15:58,880
the causal inference under the Don the

372
00:15:54,560 --> 00:16:00,399
Don Rubin work merge with Beijian

373
00:15:58,880 --> 00:16:02,560
inference and I'm going to tell you a

374
00:16:00,399 --> 00:16:05,519
little bit more about that and the

375
00:16:02,560 --> 00:16:09,120
uncertainty piece comes what what you

376
00:16:05,519 --> 00:16:13,040
call about so you call about feature

377
00:16:09,120 --> 00:16:15,519
selection in machine learning in Beijian

378
00:16:13,040 --> 00:16:19,759
we think about more about variable

379
00:16:15,519 --> 00:16:21,920
selection under a model but also is also

380
00:16:19,759 --> 00:16:24,079
called about averaging across the

381
00:16:21,920 --> 00:16:26,399
different models accounting for the

382
00:16:24,079 --> 00:16:28,320
uncertainty about which variable enter

383
00:16:26,399 --> 00:16:31,600
in into the model. So that's the point

384
00:16:28,320 --> 00:16:34,160
two and then the point three around the

385
00:16:31,600 --> 00:16:36,880
2010 was about basically taking

386
00:16:34,160 --> 00:16:40,240
everything that we do in the 2000 but

387
00:16:36,880 --> 00:16:42,639
then making it less parametric

388
00:16:40,240 --> 00:16:45,279
and that's where it gets closer to to

389
00:16:42,639 --> 00:16:48,240
machine learning right because Beijian

390
00:16:45,279 --> 00:16:50,480
inference originally was heavily relying

391
00:16:48,240 --> 00:16:53,360
on parametric structure but now we can

392
00:16:50,480 --> 00:16:55,839
do Beijian non nonparametrics and you

393
00:16:53,360 --> 00:16:57,680
can do in fact Beijian machine learning

394
00:16:55,839 --> 00:17:00,000
and that's a finally I'm going I'm going

395
00:16:57,680 --> 00:17:02,480
to go quickly through what we're doing

396
00:17:00,000 --> 00:17:05,600
right now which is AI foundation model

397
00:17:02,480 --> 00:17:07,280
that can reason on cause on on cause and

398
00:17:05,600 --> 00:17:09,600
effect which is start to think about

399
00:17:07,280 --> 00:17:12,400
what will be the consequence on human

400
00:17:09,600 --> 00:17:14,799
health if we do multiple intervention

401
00:17:12,400 --> 00:17:16,640
even though we never get to observe this

402
00:17:14,799 --> 00:17:20,079
multiple intervention all at the same

403
00:17:16,640 --> 00:17:23,039
time and so I I just have a couple of

404
00:17:20,079 --> 00:17:25,679
technical slide and this one was I think

405
00:17:23,039 --> 00:17:28,240
it's important because

406
00:17:25,679 --> 00:17:30,160
you know you often And um and maybe you

407
00:17:28,240 --> 00:17:32,480
do and correct me if I'm wrong, but when

408
00:17:30,160 --> 00:17:33,760
you're thinking about I'm sure you you

409
00:17:32,480 --> 00:17:35,440
know when you're thinking about your

410
00:17:33,760 --> 00:17:37,120
machine learning model or even when

411
00:17:35,440 --> 00:17:39,039
you're thinking about inter

412
00:17:37,120 --> 00:17:41,600
interpretability and you're thinking

413
00:17:39,039 --> 00:17:44,080
about feature selection, you're always

414
00:17:41,600 --> 00:17:46,480
having like one model, right? There is

415
00:17:44,080 --> 00:17:50,160
an outcome model and then there is a

416
00:17:46,480 --> 00:17:51,520
var, you know, series of p predictor and

417
00:17:50,160 --> 00:17:53,840
what you're trying to do is to figure

418
00:17:51,520 --> 00:17:56,640
out which variable is important, right?

419
00:17:53,840 --> 00:17:59,360
For the prediction. But now if what you

420
00:17:56,640 --> 00:18:04,400
want to do is not to predict but to

421
00:17:59,360 --> 00:18:07,840
estimate a a causal effect then your

422
00:18:04,400 --> 00:18:10,720
variable selection algorithm must be

423
00:18:07,840 --> 00:18:12,960
different and that's where we introduce

424
00:18:10,720 --> 00:18:14,640
for the first time and you know now we

425
00:18:12,960 --> 00:18:16,400
are doing in the context of a linear

426
00:18:14,640 --> 00:18:18,720
model but doesn't matter you can do it

427
00:18:16,400 --> 00:18:20,799
in any model and I want to just give you

428
00:18:18,720 --> 00:18:24,320
this idea that you should think about

429
00:18:20,799 --> 00:18:26,799
and and and and and look at it where the

430
00:18:24,320 --> 00:18:29,679
idea is really how you do variable

431
00:18:26,799 --> 00:18:31,760
importance of feature selection

432
00:18:29,679 --> 00:18:33,919
when what you want to do you want to

433
00:18:31,760 --> 00:18:35,760
preserve the estimates of the causal

434
00:18:33,919 --> 00:18:37,360
effect. Let me give you an example. So

435
00:18:35,760 --> 00:18:39,919
basically you have to think about two

436
00:18:37,360 --> 00:18:41,679
models. Generally you only think

437
00:18:39,919 --> 00:18:43,360
equation two right if you're doing

438
00:18:41,679 --> 00:18:45,280
prediction you only think about your

439
00:18:43,360 --> 00:18:47,760
your your equation two where you want to

440
00:18:45,280 --> 00:18:51,440
estimate the fact of x on y and that's

441
00:18:47,760 --> 00:18:54,000
there is a a model right you have uh the

442
00:18:51,440 --> 00:18:56,559
effect of x and then you you adjust for

443
00:18:54,000 --> 00:18:59,039
you that is a series of coariant. Let's

444
00:18:56,559 --> 00:19:01,760
assume for a moment that the the thing

445
00:18:59,039 --> 00:19:05,919
you really care about is estimating the

446
00:19:01,760 --> 00:19:07,520
fat of x on y. Okay, simple as that. And

447
00:19:05,919 --> 00:19:10,400
what you need to figure out, you want to

448
00:19:07,520 --> 00:19:13,520
know which variable u you you want to

449
00:19:10,400 --> 00:19:17,200
include in the equation too, not to

450
00:19:13,520 --> 00:19:20,160
predict y well, but to get an unbiased

451
00:19:17,200 --> 00:19:22,480
estimate of of beta. Okay, that's the

452
00:19:20,160 --> 00:19:24,320
goal. And so if you want to do that,

453
00:19:22,480 --> 00:19:27,360
then you need a second equation, which

454
00:19:24,320 --> 00:19:30,720
is the one on top where let me tell you

455
00:19:27,360 --> 00:19:33,440
what these parameters are. Alphas are 01

456
00:19:30,720 --> 00:19:35,120
variables that are unknown. that tells

457
00:19:33,440 --> 00:19:37,360
you whether or not that particular

458
00:19:35,120 --> 00:19:40,320
variable should be in the exposure model

459
00:19:37,360 --> 00:19:42,720
which is in the first equation or alpha

460
00:19:40,320 --> 00:19:44,320
y are whether or not that variable you

461
00:19:42,720 --> 00:19:45,840
should be in the outcome model right so

462
00:19:44,320 --> 00:19:49,120
you need to figure out which of these

463
00:19:45,840 --> 00:19:51,679
variable should be turned one and zero

464
00:19:49,120 --> 00:19:55,520
if you just think about pre prediction

465
00:19:51,679 --> 00:19:58,320
you're going to select the use that will

466
00:19:55,520 --> 00:20:01,039
best best pre predict y but if you want

467
00:19:58,320 --> 00:20:04,240
to estimate the beta and the unbiased

468
00:20:01,039 --> 00:20:06,880
estimates you have to take account of

469
00:20:04,240 --> 00:20:09,440
that odds ratio there

470
00:20:06,880 --> 00:20:11,760
which is you know let's say it's it's

471
00:20:09,440 --> 00:20:13,919
omega and the omega has to be really

472
00:20:11,760 --> 00:20:16,160
really large and so the criteria that

473
00:20:13,919 --> 00:20:19,840
you have to show is that you want to

474
00:20:16,160 --> 00:20:21,600
include a variable in your outcome model

475
00:20:19,840 --> 00:20:24,480
too

476
00:20:21,600 --> 00:20:28,000
only if that variable is highly

477
00:20:24,480 --> 00:20:31,280
predictable of x and what does this do

478
00:20:28,000 --> 00:20:34,000
is make sure that in your outcome model

479
00:20:31,280 --> 00:20:37,440
you're including variables that are

480
00:20:34,000 --> 00:20:39,760
strongly predicted of X and weakly

481
00:20:37,440 --> 00:20:43,520
predicted of Y.

482
00:20:39,760 --> 00:20:46,240
Why? Because if you omit that variable,

483
00:20:43,520 --> 00:20:49,200
the estimates of beta will be biased.

484
00:20:46,240 --> 00:20:50,240
Okay, so this is just a trick and you

485
00:20:49,200 --> 00:20:52,000
know it's been published there are

486
00:20:50,240 --> 00:20:54,000
multiple paper about but the idea would

487
00:20:52,000 --> 00:20:56,559
be that if you want to select variables

488
00:20:54,000 --> 00:20:59,200
in your machine learning model that get

489
00:20:56,559 --> 00:21:00,640
an estimates of a causal effect you

490
00:20:59,200 --> 00:21:02,320
really have to account of the

491
00:21:00,640 --> 00:21:03,840
relationship between these confounders

492
00:21:02,320 --> 00:21:05,919
and exposure what you're trying to

493
00:21:03,840 --> 00:21:09,200
account for it to make sure that you get

494
00:21:05,919 --> 00:21:11,120
unbiased um unbiased inference and then

495
00:21:09,200 --> 00:21:12,640
this idea has been generalized and there

496
00:21:11,120 --> 00:21:14,640
are you know multiple paper in the

497
00:21:12,640 --> 00:21:17,200
context of causal inference more general

498
00:21:14,640 --> 00:21:18,720
where you have to you know more general

499
00:21:17,200 --> 00:21:20,000
models you know I show you the idea in

500
00:21:18,720 --> 00:21:21,600
the linear model but you can have

501
00:21:20,000 --> 00:21:24,080
multiple model you can have bijan on

502
00:21:21,600 --> 00:21:26,159
parametric model and also in the context

503
00:21:24,080 --> 00:21:27,679
of causal inference but the idea I

504
00:21:26,159 --> 00:21:30,559
wanted to tell you is that when you're

505
00:21:27,679 --> 00:21:32,640
doing both the seeing part and the

506
00:21:30,559 --> 00:21:35,200
imaging part and when the goal is to

507
00:21:32,640 --> 00:21:39,600
estimating a causal effect you cannot

508
00:21:35,200 --> 00:21:43,760
rely on algorithm that are based on

509
00:21:39,600 --> 00:21:46,400
principle of optimizing your

510
00:21:43,760 --> 00:21:48,080
prediction but you need another model

511
00:21:46,400 --> 00:21:49,760
that account the relationship between

512
00:21:48,080 --> 00:21:51,679
the potential confounders and the

513
00:21:49,760 --> 00:21:53,600
treatment that you're interested. Yes.

514
00:21:51,679 --> 00:21:55,280
>> Um, one question I have is when you're

515
00:21:53,600 --> 00:21:56,720
kind of doing this exercise and trying

516
00:21:55,280 --> 00:21:58,640
to think about like what confounders

517
00:21:56,720 --> 00:22:00,080
should I include in my model? Obviously,

518
00:21:58,640 --> 00:22:01,600
you do your best to think about like

519
00:22:00,080 --> 00:22:03,600
what are literally all the factors I

520
00:22:01,600 --> 00:22:05,760
could think about that I could include.

521
00:22:03,600 --> 00:22:08,240
After you construct the model, is there

522
00:22:05,760 --> 00:22:09,919
like ways that you look at it to say,

523
00:22:08,240 --> 00:22:12,320
okay, now I've constructed the model. I

524
00:22:09,919 --> 00:22:14,480
have an estimate of my parameters. post

525
00:22:12,320 --> 00:22:17,679
talk, can I maybe assess if there are

526
00:22:14,480 --> 00:22:19,280
biases that I that I didn't account for?

527
00:22:17,679 --> 00:22:22,960
>> Yeah, great question. So, there are

528
00:22:19,280 --> 00:22:24,960
there are two two things to to think

529
00:22:22,960 --> 00:22:28,159
about. Number one is that you can still

530
00:22:24,960 --> 00:22:30,880
have bias if number one, you haven't

531
00:22:28,159 --> 00:22:32,880
included coariant that you want to. And

532
00:22:30,880 --> 00:22:36,000
so the goal here is that if you have a

533
00:22:32,880 --> 00:22:38,159
good enough sample size so that will

534
00:22:36,000 --> 00:22:40,960
protect you for that because you know

535
00:22:38,159 --> 00:22:43,679
it's it's just engineering so that you

536
00:22:40,960 --> 00:22:46,080
are going to force into your model any

537
00:22:43,679 --> 00:22:47,520
variable that are related to the

538
00:22:46,080 --> 00:22:49,120
exposure that you want to estimate

539
00:22:47,520 --> 00:22:50,799
effect.

540
00:22:49,120 --> 00:22:52,880
The other bigger one which is the

541
00:22:50,799 --> 00:22:54,480
elephant in the room is that if there

542
00:22:52,880 --> 00:22:56,799
are confounders that you haven't

543
00:22:54,480 --> 00:22:58,640
measured right then this is not going to

544
00:22:56,799 --> 00:23:01,679
save you because if you haven't measured

545
00:22:58,640 --> 00:23:03,600
so now one thing that you can do there

546
00:23:01,679 --> 00:23:06,720
are a lot of way of doing sensitivity

547
00:23:03,600 --> 00:23:07,919
analysis for unmeasured confounding and

548
00:23:06,720 --> 00:23:09,600
so there are two things you have to

549
00:23:07,919 --> 00:23:12,559
think about first of all you have to

550
00:23:09,600 --> 00:23:14,799
think that your unmeasured confounder to

551
00:23:12,559 --> 00:23:15,919
create bias will have to be uncorrelated

552
00:23:14,799 --> 00:23:18,080
with everything that you already

553
00:23:15,919 --> 00:23:20,320
accounted for and second of all there

554
00:23:18,080 --> 00:23:24,159
are sensitivity analysis. And basically

555
00:23:20,320 --> 00:23:27,360
what they do, they allow you to estimate

556
00:23:24,159 --> 00:23:30,240
how strong the relationship between this

557
00:23:27,360 --> 00:23:33,440
unmeasured confounder and the exposure

558
00:23:30,240 --> 00:23:35,360
will need to be to completely change

559
00:23:33,440 --> 00:23:37,120
your conclusion, right? And so there are

560
00:23:35,360 --> 00:23:39,520
measures that you can do about that. And

561
00:23:37,120 --> 00:23:41,600
then of course the other way to overcome

562
00:23:39,520 --> 00:23:43,600
a measure confounding will be not rely

563
00:23:41,600 --> 00:23:45,440
on observational study, but you can do a

564
00:23:43,600 --> 00:23:48,000
quas experimental you know quas

565
00:23:45,440 --> 00:23:50,240
experimental studies.

566
00:23:48,000 --> 00:23:52,640
So yeah and this is just to say there

567
00:23:50,240 --> 00:23:54,480
has been work in my in my lab in my

568
00:23:52,640 --> 00:23:58,000
group that then have been generalized

569
00:23:54,480 --> 00:24:00,320
this model you know on the contest of no

570
00:23:58,000 --> 00:24:04,000
no

571
00:24:00,320 --> 00:24:08,080
parametric a basian um estimation and

572
00:24:04,000 --> 00:24:11,360
I'll I'll skip this now all of this it's

573
00:24:08,080 --> 00:24:13,919
not just like don't just like writing a

574
00:24:11,360 --> 00:24:16,960
papers and getting presenting a narrow

575
00:24:13,919 --> 00:24:20,559
IPS or in jazza in our statistics

576
00:24:16,960 --> 00:24:22,880
community this matter right so so we

577
00:24:20,559 --> 00:24:27,520
applied actually

578
00:24:22,880 --> 00:24:29,200
um this work of thinking uh Beijian

579
00:24:27,520 --> 00:24:32,320
causal inference in the context of

580
00:24:29,200 --> 00:24:35,279
nonparametric estimation so this was a

581
00:24:32,320 --> 00:24:37,440
study in 2023 where we apply to the

582
00:24:35,279 --> 00:24:39,200
entire Medicare database link to

583
00:24:37,440 --> 00:24:42,799
environmental exposure and societal

584
00:24:39,200 --> 00:24:44,960
factor so this was a study uh where we

585
00:24:42,799 --> 00:24:47,360
have 62

586
00:24:44,960 --> 00:24:50,080
23 million observations

587
00:24:47,360 --> 00:24:51,600
uh this was the largest uh sample size

588
00:24:50,080 --> 00:24:54,400
that New England Journal of Medicine

589
00:24:51,600 --> 00:24:56,480
paper published where we were able to

590
00:24:54,400 --> 00:24:59,200
estimate for the first time using the

591
00:24:56,480 --> 00:25:04,000
whole US healthcare system what would be

592
00:24:59,200 --> 00:25:06,159
the impact of PM 2.5 on mortality and

593
00:25:04,000 --> 00:25:09,679
not only for everybody but also

594
00:25:06,159 --> 00:25:12,159
stratifying by people of color and and

595
00:25:09,679 --> 00:25:15,440
so economic status but the most

596
00:25:12,159 --> 00:25:16,640
important plot which this led to the

597
00:25:15,440 --> 00:25:18,480
change of the national ambient

598
00:25:16,640 --> 00:25:21,120
interquality standard under the Biden

599
00:25:18,480 --> 00:25:22,720
administration. Now Trump has tried to

600
00:25:21,120 --> 00:25:25,679
repeal it but has not been able to do

601
00:25:22,720 --> 00:25:27,600
that yet. So it's really the doing

602
00:25:25,679 --> 00:25:29,360
question. Okay, going back to causal

603
00:25:27,600 --> 00:25:31,679
inference and the doing question. What

604
00:25:29,360 --> 00:25:34,720
this plot shows and this was basically

605
00:25:31,679 --> 00:25:39,360
what led to the change in the law. What

606
00:25:34,720 --> 00:25:44,320
this plot shows is how what will be the

607
00:25:39,360 --> 00:25:47,520
risk reduction in mortality rate if

608
00:25:44,320 --> 00:25:50,799
instead of taking the current standard

609
00:25:47,520 --> 00:25:52,799
safety standard for PM 2.5 or 12 because

610
00:25:50,799 --> 00:25:55,760
originally we're at 12 and I'm going to

611
00:25:52,799 --> 00:25:57,919
lower to 11 or if I take the current

612
00:25:55,760 --> 00:26:00,400
standard from 12 and I'm going to lower

613
00:25:57,919 --> 00:26:02,080
to 10 or I'm going to lower to nine or

614
00:26:00,400 --> 00:26:04,240
I'm going to lower to eight. Right? That

615
00:26:02,080 --> 00:26:06,880
is really the doing question from a

616
00:26:04,240 --> 00:26:09,840
causal inference perspective and you see

617
00:26:06,880 --> 00:26:13,200
that of course low you know more

618
00:26:09,840 --> 00:26:15,840
stringent are the safety standard more

619
00:26:13,200 --> 00:26:18,240
life you're going to save right

620
00:26:15,840 --> 00:26:20,320
importantly during the Biden

621
00:26:18,240 --> 00:26:23,360
administration was also the really

622
00:26:20,320 --> 00:26:24,720
important element of thinking

623
00:26:23,360 --> 00:26:26,080
differentially of the number you're

624
00:26:24,720 --> 00:26:27,760
going to the number of life you're going

625
00:26:26,080 --> 00:26:30,240
to save for the different social

626
00:26:27,760 --> 00:26:33,919
economic group and it's interesting that

627
00:26:30,240 --> 00:26:36,880
you see when you go from 12 to 9. You

628
00:26:33,919 --> 00:26:40,480
see that actually the people of color

629
00:26:36,880 --> 00:26:43,919
which are the blue bar and the white a

630
00:26:40,480 --> 00:26:46,559
lower soio economic status have the much

631
00:26:43,919 --> 00:26:49,520
larger reduction the number of deaths

632
00:26:46,559 --> 00:26:52,159
than people of you know white of high

633
00:26:49,520 --> 00:26:55,679
high soio economic status and so that

634
00:26:52,159 --> 00:26:56,880
particular um paper and that figure led

635
00:26:55,679 --> 00:26:59,039
to the revision of the national

636
00:26:56,880 --> 00:27:01,600
amalander from 12 microgram per

637
00:26:59,039 --> 00:27:03,039
kilometer to 9 microgram per kilometer

638
00:27:01,600 --> 00:27:04,799
and so I show you that because it's

639
00:27:03,039 --> 00:27:07,279
important when you think about even at

640
00:27:04,799 --> 00:27:11,440
the most sophisticated

641
00:27:07,279 --> 00:27:14,159
coal basian nonparametric ensemble AI

642
00:27:11,440 --> 00:27:17,039
put whatever you want right but you it's

643
00:27:14,159 --> 00:27:19,679
important then with the sophistication

644
00:27:17,039 --> 00:27:22,559
of the algorithmic sophistication you

645
00:27:19,679 --> 00:27:25,120
need to translate the result in a way

646
00:27:22,559 --> 00:27:26,480
that policy maker wanted to to see and

647
00:27:25,120 --> 00:27:29,120
you know that all the uncertainty

648
00:27:26,480 --> 00:27:32,000
measure and blah blah blah so that has

649
00:27:29,120 --> 00:27:33,600
been really one of the journey where we

650
00:27:32,000 --> 00:27:37,200
had the disp paper, New Union Journal of

651
00:27:33,600 --> 00:27:40,080
Medicine in April 2023. Then there was

652
00:27:37,200 --> 00:27:41,679
um a a science article that was also

653
00:27:40,080 --> 00:27:43,279
really important paper. I'm not going to

654
00:27:41,679 --> 00:27:46,159
be able to tell you everything right

655
00:27:43,279 --> 00:27:48,080
now, but basically the goal was to look

656
00:27:46,159 --> 00:27:50,799
specifically of air pollution that comes

657
00:27:48,080 --> 00:27:52,159
from coal fire power plants. And that's

658
00:27:50,799 --> 00:27:53,679
so important now as I'm going to tell

659
00:27:52,159 --> 00:27:55,679
you in a second with the new explosion

660
00:27:53,679 --> 00:27:59,200
of AI because a lot of the AI

661
00:27:55,679 --> 00:28:02,000
infrastructure is powered by coal. And

662
00:27:59,200 --> 00:28:05,440
so that's where we presented the work

663
00:28:02,000 --> 00:28:07,120
where uh cold fire power plants lead to

664
00:28:05,440 --> 00:28:10,240
a level of pollution that is even more

665
00:28:07,120 --> 00:28:15,039
toxic. And then that paper got picked up

666
00:28:10,240 --> 00:28:17,120
by Senator Kerry, a COP um a COP 2028 in

667
00:28:15,039 --> 00:28:19,440
Dubai where was the first time they

668
00:28:17,120 --> 00:28:22,000
actually they started to really switch

669
00:28:19,440 --> 00:28:25,520
from climate crisis and recognize that

670
00:28:22,000 --> 00:28:28,720
is also an a health crisis and there was

671
00:28:25,520 --> 00:28:30,559
a lot of seeing and doing right behind

672
00:28:28,720 --> 00:28:33,360
uh behind all of this paper and then as

673
00:28:30,559 --> 00:28:36,000
I mentioned uh the Biden administration

674
00:28:33,360 --> 00:28:39,039
in February 2024 lowered the national

675
00:28:36,000 --> 00:28:40,880
quality standard from 12 to 9. And so

676
00:28:39,039 --> 00:28:43,520
cleaner hair, life saved. And the other

677
00:28:40,880 --> 00:28:46,559
thing that we are doing right now using

678
00:28:43,520 --> 00:28:48,880
actually um machine learning is showing

679
00:28:46,559 --> 00:28:51,840
how many also less greenhouse gases you

680
00:28:48,880 --> 00:28:54,159
have from implementing uh air quality

681
00:28:51,840 --> 00:28:56,799
policy which actually is pretty you know

682
00:28:54,159 --> 00:29:01,120
what we are finding that if you pass a

683
00:28:56,799 --> 00:29:04,159
law that clean the air you actually

684
00:29:01,120 --> 00:29:07,440
reducing green as gas emission more than

685
00:29:04,159 --> 00:29:09,520
if you pass climate rules because the

686
00:29:07,440 --> 00:29:11,760
national quality standard is a federal

687
00:29:09,520 --> 00:29:14,960
law And so if you have to comply with

688
00:29:11,760 --> 00:29:16,720
that law, ultimately if you try to cut

689
00:29:14,960 --> 00:29:19,919
unmet exposure to our pollution, you're

690
00:29:16,720 --> 00:29:23,919
gonna attack similar sources of um of

691
00:29:19,919 --> 00:29:25,679
greenhouse gases. So So and then the

692
00:29:23,919 --> 00:29:27,520
last piece of all of this journey, I

693
00:29:25,679 --> 00:29:29,520
promise you, is that now we are getting

694
00:29:27,520 --> 00:29:31,520
to have to uh building the first

695
00:29:29,520 --> 00:29:33,760
foundation model for climate resilience

696
00:29:31,520 --> 00:29:35,919
and climate adaptation that is strained

697
00:29:33,760 --> 00:29:38,799
on the entire US healthcare system. Uh

698
00:29:35,919 --> 00:29:41,039
and so basically, you know, we don't

699
00:29:38,799 --> 00:29:44,720
want to do one exposure, one health

700
00:29:41,039 --> 00:29:47,039
outcome at a time, but building on now

701
00:29:44,720 --> 00:29:49,200
the most recent

702
00:29:47,039 --> 00:29:51,840
development of foundation model to be

703
00:29:49,200 --> 00:29:54,480
able to uh analyze it together. And so

704
00:29:51,840 --> 00:29:57,120
the idea is that we can uh analyze

705
00:29:54,480 --> 00:30:00,159
unprecedentedly massive multimodel data

706
00:29:57,120 --> 00:30:02,960
to find generalizable pattern to make a

707
00:30:00,159 --> 00:30:06,720
prediction more accurate than um than

708
00:30:02,960 --> 00:30:09,120
traditional methods. So uh this was a

709
00:30:06,720 --> 00:30:11,120
recent work that is not foundation model

710
00:30:09,120 --> 00:30:13,520
yet but just to give you a sense that we

711
00:30:11,120 --> 00:30:17,279
now have the ability to estimate

712
00:30:13,520 --> 00:30:19,520
exposure to wildfires, burns on extreme

713
00:30:17,279 --> 00:30:23,440
heat, right? All of these climate

714
00:30:19,520 --> 00:30:25,520
variable are in a very like precise

715
00:30:23,440 --> 00:30:27,679
matter and so that will allow to

716
00:30:25,520 --> 00:30:30,320
together with health data to to train

717
00:30:27,679 --> 00:30:32,960
this foundation model. So Clauddio

718
00:30:30,320 --> 00:30:35,600
Clauddio but Batillaro is a

719
00:30:32,960 --> 00:30:37,600
post-docctoral fellow in my lab and uh

720
00:30:35,600 --> 00:30:41,360
little advertiser is on the job market

721
00:30:37,600 --> 00:30:43,440
this year and he's leading this work on

722
00:30:41,360 --> 00:30:46,000
uh the foundation model for healthy

723
00:30:43,440 --> 00:30:47,760
climate adaptation and the idea is

724
00:30:46,000 --> 00:30:50,399
basically to have a pre-train on the

725
00:30:47,760 --> 00:30:52,000
entire US system plus all of the

726
00:30:50,399 --> 00:30:54,640
environmental data plus all of the

727
00:30:52,000 --> 00:30:57,360
societal data and basically produce

728
00:30:54,640 --> 00:30:59,200
these unified embeddings that capture

729
00:30:57,360 --> 00:31:00,880
the complex spatial temporary

730
00:30:59,200 --> 00:31:02,399
relationship between climate stressors,

731
00:31:00,880 --> 00:31:05,039
social economic variables and LTA

732
00:31:02,399 --> 00:31:07,200
outcome. And so that's where you can

733
00:31:05,039 --> 00:31:10,159
basically start evaluating you know

734
00:31:07,200 --> 00:31:11,760
downstream benchmark task and then

735
00:31:10,159 --> 00:31:13,919
that's where you start getting these

736
00:31:11,760 --> 00:31:17,520
imaging where you can start thinking

737
00:31:13,919 --> 00:31:20,159
about what if scenarios of forecasting

738
00:31:17,520 --> 00:31:22,880
for climate

739
00:31:20,159 --> 00:31:24,399
adaptation using you know synthetic

740
00:31:22,880 --> 00:31:26,960
ground through data to validate

741
00:31:24,399 --> 00:31:29,600
counterfactual uh counterfactual

742
00:31:26,960 --> 00:31:33,080
prediction. And so uh so just to give

743
00:31:29,600 --> 00:31:33,080
you some example

744
00:31:33,600 --> 00:31:38,720
you know there is a lot of stuff here in

745
00:31:36,720 --> 00:31:42,960
terms of

746
00:31:38,720 --> 00:31:46,000
using this this model to realign

747
00:31:42,960 --> 00:31:48,159
uh misalign data and then thinking about

748
00:31:46,000 --> 00:31:51,200
individual level health longitudinal

749
00:31:48,159 --> 00:31:54,720
trajectory because the Medicare data is

750
00:31:51,200 --> 00:31:58,159
um long longitudinal and so this is

751
00:31:54,720 --> 00:32:00,000
really a massive undertaking where you

752
00:31:58,159 --> 00:32:01,840
know we are thinking it where the

753
00:32:00,000 --> 00:32:03,120
ultimate downstream task will be to

754
00:32:01,840 --> 00:32:04,399
estimate the delta effect of our

755
00:32:03,120 --> 00:32:07,279
pollution and getting an exposure

756
00:32:04,399 --> 00:32:11,360
response function to do downscaling to

757
00:32:07,279 --> 00:32:14,559
think about what if scenarios of um uh

758
00:32:11,360 --> 00:32:16,880
high uh high complex

759
00:32:14,559 --> 00:32:18,559
okay so that's that's the first part and

760
00:32:16,880 --> 00:32:20,480
so I you know I show you this all of

761
00:32:18,559 --> 00:32:23,200
this journey and now we're saying okay

762
00:32:20,480 --> 00:32:27,039
we are launching this first foundation

763
00:32:23,200 --> 00:32:29,760
model a lot of GPU train all the US

764
00:32:27,039 --> 00:32:34,480
healthcare system. And so then let's

765
00:32:29,760 --> 00:32:36,399
look on the other side which is um you

766
00:32:34,480 --> 00:32:39,440
know let's now we have solved the

767
00:32:36,399 --> 00:32:41,919
problem right we have these agents that

768
00:32:39,440 --> 00:32:43,919
can tell us what you should be doing to

769
00:32:41,919 --> 00:32:46,240
be able to prevent deaths from extreme

770
00:32:43,919 --> 00:32:49,360
weather event and is there a better

771
00:32:46,240 --> 00:32:52,720
future right and so I wanted to mention

772
00:32:49,360 --> 00:32:55,519
some work that we are doing on exploring

773
00:32:52,720 --> 00:32:57,919
and and evaluating the environmental

774
00:32:55,519 --> 00:33:01,919
impact of hyperscaler data center and

775
00:32:57,919 --> 00:33:04,720
also to thinking about the health impact

776
00:33:01,919 --> 00:33:06,880
um as well. So as I said you know one

777
00:33:04,720 --> 00:33:09,120
part I have a team developing foundation

778
00:33:06,880 --> 00:33:12,960
model another part developing a team

779
00:33:09,120 --> 00:33:16,559
that quantify the harmful effect of of

780
00:33:12,960 --> 00:33:18,240
this uh of this foundation model. So

781
00:33:16,559 --> 00:33:20,480
this is all you know this is on the New

782
00:33:18,240 --> 00:33:22,320
York Times every day right you all know

783
00:33:20,480 --> 00:33:24,559
about this. So there are new data

784
00:33:22,320 --> 00:33:28,240
centers you know popping up as

785
00:33:24,559 --> 00:33:30,880
mushrooms. uh we're using AI you know

786
00:33:28,240 --> 00:33:34,320
and I am using AI I'm developing more

787
00:33:30,880 --> 00:33:37,519
powerful AI and so I think the question

788
00:33:34,320 --> 00:33:40,399
is now can we start so I wanted to start

789
00:33:37,519 --> 00:33:43,919
from a very data science perspective

790
00:33:40,399 --> 00:33:47,679
which is I wanted to start by building

791
00:33:43,919 --> 00:33:50,240
the data science pipe pipeline that

792
00:33:47,679 --> 00:33:52,880
tells me in correspondence of each data

793
00:33:50,240 --> 00:33:55,120
center how much carbon footprint how

794
00:33:52,880 --> 00:33:57,120
much pollution what are the healthy

795
00:33:55,120 --> 00:33:59,440
impact what what is the water

796
00:33:57,120 --> 00:34:01,919
consumption and then if I start at least

797
00:33:59,440 --> 00:34:03,600
starting with the foundation of data

798
00:34:01,919 --> 00:34:05,200
then we can start reasoning and I know

799
00:34:03,600 --> 00:34:07,279
that many of you thinking about decision

800
00:34:05,200 --> 00:34:08,879
you're making and optimization but we

801
00:34:07,279 --> 00:34:12,079
can't go there until you have the

802
00:34:08,879 --> 00:34:14,480
foundation of what the data is right so

803
00:34:12,079 --> 00:34:16,639
um so we have done a massive amount of

804
00:34:14,480 --> 00:34:19,760
work because of course these are all

805
00:34:16,639 --> 00:34:20,960
proprietary data right and the big tech

806
00:34:19,760 --> 00:34:22,639
don't want to tell you really what's

807
00:34:20,960 --> 00:34:24,240
going on so it's not going to be perfect

808
00:34:22,639 --> 00:34:26,480
but we have done we're doing a lot of

809
00:34:24,240 --> 00:34:28,320
work so there's has been we have buying

810
00:34:26,480 --> 00:34:30,639
some proprietary data. There is massive

811
00:34:28,320 --> 00:34:33,440
amount of web scraping. There is a lot

812
00:34:30,639 --> 00:34:36,960
of remote sensing information

813
00:34:33,440 --> 00:34:40,560
and so basically we have in this paper

814
00:34:36,960 --> 00:34:42,560
we are focusing on the hyperscaler right

815
00:34:40,560 --> 00:34:44,800
there there are many many many more data

816
00:34:42,560 --> 00:34:46,960
center than 43 and actually this is

817
00:34:44,800 --> 00:34:49,679
already old because this is up to April

818
00:34:46,960 --> 00:34:51,280
2025th but we focus on the hyperscaler

819
00:34:49,679 --> 00:34:54,480
which are the biggest one which we know

820
00:34:51,280 --> 00:34:56,000
they tend to run AI uh application and

821
00:34:54,480 --> 00:34:57,920
so

822
00:34:56,000 --> 00:34:59,599
what you see in that map actually you

823
00:34:57,920 --> 00:35:02,720
don't cannot see it very well but you

824
00:34:59,599 --> 00:35:06,000
later. So the the black dots so there

825
00:35:02,720 --> 00:35:08,480
are there are 403 black dots and these

826
00:35:06,000 --> 00:35:10,800
are where the data center are located

827
00:35:08,480 --> 00:35:13,599
and then the smaller dots of different

828
00:35:10,800 --> 00:35:16,720
colors are the power plants that are

829
00:35:13,599 --> 00:35:20,560
providing energy to this data center and

830
00:35:16,720 --> 00:35:23,359
these low smaller dots are colorcoded

831
00:35:20,560 --> 00:35:27,440
based on whether or not there are coal

832
00:35:23,359 --> 00:35:30,000
or re you know or renewable sources. So

833
00:35:27,440 --> 00:35:34,079
if you think about for a moment the red

834
00:35:30,000 --> 00:35:37,280
one the red dots are all fossil fuel

835
00:35:34,079 --> 00:35:40,240
right coal gas and oil. So you see most

836
00:35:37,280 --> 00:35:44,480
of the map is red and orange right and

837
00:35:40,240 --> 00:35:47,680
then the blue are um the blue are wind

838
00:35:44,480 --> 00:35:50,079
or other renewable source yellow nuclear

839
00:35:47,680 --> 00:35:52,000
which are very few the pink are

840
00:35:50,079 --> 00:35:54,160
geothermal which are very few and so on.

841
00:35:52,000 --> 00:35:57,280
Right? So you you already get a sense

842
00:35:54,160 --> 00:36:00,960
that most of the AI infrastructure is

843
00:35:57,280 --> 00:36:03,359
powered by uh fossil fuel uh com

844
00:36:00,960 --> 00:36:06,000
combustion the majority is natural gas

845
00:36:03,359 --> 00:36:08,400
but big big chunk is also on coil on

846
00:36:06,000 --> 00:36:10,640
oil. So these are the the question that

847
00:36:08,400 --> 00:36:12,560
we're addressing is basically what what

848
00:36:10,640 --> 00:36:14,480
is electricity consumption sources and

849
00:36:12,560 --> 00:36:16,960
tributable CO2 emission from these data

850
00:36:14,480 --> 00:36:18,640
centers what is the full mix of the

851
00:36:16,960 --> 00:36:21,680
power plants and that's where I think

852
00:36:18,640 --> 00:36:24,400
your optimization expertise can help. We

853
00:36:21,680 --> 00:36:25,839
have not done that yet. Uh there, you

854
00:36:24,400 --> 00:36:28,880
know, right now we're just documenting

855
00:36:25,839 --> 00:36:31,760
it. what is the full mix which state

856
00:36:28,880 --> 00:36:33,760
have the I2 the CO2 emission and then

857
00:36:31,760 --> 00:36:35,200
here I'm just going to show you the CO2

858
00:36:33,760 --> 00:36:38,400
emission but we have now already

859
00:36:35,200 --> 00:36:40,320
extended the pipeline that from the when

860
00:36:38,400 --> 00:36:42,079
when you know the power plants that are

861
00:36:40,320 --> 00:36:44,000
giving energy we know what comes out of

862
00:36:42,079 --> 00:36:46,320
the smoke stack and then we have

863
00:36:44,000 --> 00:36:48,960
atmospheric chemistry model that tell us

864
00:36:46,320 --> 00:36:51,359
pollution where it goes and then we link

865
00:36:48,960 --> 00:36:53,520
to Medicare data so we know the health

866
00:36:51,359 --> 00:36:56,320
impact and we know the healthare the

867
00:36:53,520 --> 00:36:57,920
healthcare cost and so then you So this

868
00:36:56,320 --> 00:37:00,640
is the question ultimately we want to

869
00:36:57,920 --> 00:37:03,440
get like you know uh where should I

870
00:37:00,640 --> 00:37:06,000
place a data center right or where

871
00:37:03,440 --> 00:37:08,240
should I intervene on the power grid or

872
00:37:06,000 --> 00:37:09,599
how we can decarbonize the sector as

873
00:37:08,240 --> 00:37:11,280
much as possible this are really very

874
00:37:09,599 --> 00:37:13,680
hard question we are not there yet but

875
00:37:11,280 --> 00:37:16,240
this is at the first step toward getting

876
00:37:13,680 --> 00:37:18,400
that so just to give you a little idea

877
00:37:16,240 --> 00:37:22,320
of how we are doing it and so as I

878
00:37:18,400 --> 00:37:25,359
mentioned is we have validated the set

879
00:37:22,320 --> 00:37:27,280
of 403 hyperscaler we actually know

880
00:37:25,359 --> 00:37:29,119
whether I don't know is Amazon, Google,

881
00:37:27,280 --> 00:37:32,320
we're not publishing the information but

882
00:37:29,119 --> 00:37:36,160
we know where coming from so private

883
00:37:32,320 --> 00:37:40,480
data web scraping satellite imaging then

884
00:37:36,160 --> 00:37:42,960
we know we take the power capac you know

885
00:37:40,480 --> 00:37:44,400
we we know which which power plants are

886
00:37:42,960 --> 00:37:46,160
giving the electricity there are some

887
00:37:44,400 --> 00:37:49,119
missing data but that actually is easy

888
00:37:46,160 --> 00:37:51,119
to to deal not very much and then we

889
00:37:49,119 --> 00:37:53,920
basically have make some assumption

890
00:37:51,119 --> 00:37:56,160
where the annual electricity consumption

891
00:37:53,920 --> 00:37:58,480
was calculated by multiplying the power

892
00:37:56,160 --> 00:38:00,480
capacity hours per year and utilization

893
00:37:58,480 --> 00:38:02,400
rate of 63%.

894
00:38:00,480 --> 00:38:03,839
And so that utilization rate is a kind

895
00:38:02,400 --> 00:38:07,359
of an average it was determined

896
00:38:03,839 --> 00:38:09,359
empirically and then uh every upper

897
00:38:07,359 --> 00:38:11,119
scale was assigned to is a balancing

898
00:38:09,359 --> 00:38:13,040
authority and a corresponding power

899
00:38:11,119 --> 00:38:15,359
plants and then the emission were

900
00:38:13,040 --> 00:38:17,839
estimated using an energy generated

901
00:38:15,359 --> 00:38:19,760
weighted model and APA emission factors.

902
00:38:17,839 --> 00:38:21,760
If you're working on energy system, you

903
00:38:19,760 --> 00:38:23,599
probably know about this 10 times more

904
00:38:21,760 --> 00:38:25,599
than I do and so I'm sure there is a way

905
00:38:23,599 --> 00:38:27,440
to do it better. And then we also

906
00:38:25,599 --> 00:38:31,040
calculate the carbon intensity right. So

907
00:38:27,440 --> 00:38:34,800
what how much CO2 emission for um

908
00:38:31,040 --> 00:38:38,160
kilowatt for um for for hour. And again

909
00:38:34,800 --> 00:38:40,560
the idea here is a the first data

910
00:38:38,160 --> 00:38:43,119
science pipeline to do descriptive

911
00:38:40,560 --> 00:38:45,359
statistics. So not even like [laughter]

912
00:38:43,119 --> 00:38:47,440
um causal inference. And so but it's

913
00:38:45,359 --> 00:38:49,119
it's it's actually pretty fascinating.

914
00:38:47,440 --> 00:38:51,359
And so you know I'm just showing you the

915
00:38:49,119 --> 00:38:52,960
data aggregate state level because we

916
00:38:51,359 --> 00:38:55,920
don't want to show actually data at the

917
00:38:52,960 --> 00:38:58,640
single hyperscaler but basically you see

918
00:38:55,920 --> 00:39:00,560
that these are we show the data both in

919
00:38:58,640 --> 00:39:02,960
terms of the balancing authority and

920
00:39:00,560 --> 00:39:07,760
based on on the states at the state

921
00:39:02,960 --> 00:39:10,000
level on top are the CO2 emissions and

922
00:39:07,760 --> 00:39:12,240
on the bottom is the electricity

923
00:39:10,000 --> 00:39:16,400
consumption. I mean, I think we all know

924
00:39:12,240 --> 00:39:20,560
that Virginia is the the capital of the

925
00:39:16,400 --> 00:39:23,920
data centers and um and consequentially

926
00:39:20,560 --> 00:39:25,359
where you have more uh CO2 emission. But

927
00:39:23,920 --> 00:39:27,520
what think is interesting and the

928
00:39:25,359 --> 00:39:29,920
picture changed a little bit and I found

929
00:39:27,520 --> 00:39:32,000
this picture pretty interesting is that

930
00:39:29,920 --> 00:39:35,680
we also quantify the full mix, right?

931
00:39:32,000 --> 00:39:38,960
what's the combination and so um for

932
00:39:35,680 --> 00:39:42,240
each balancing authority so on top is on

933
00:39:38,960 --> 00:39:47,760
average for the US and so you see that

934
00:39:42,240 --> 00:39:51,280
the um electricity that um the um

935
00:39:47,760 --> 00:39:54,960
electricity demand of these uh

936
00:39:51,280 --> 00:40:01,280
hyperscalar data center is 42% natural

937
00:39:54,960 --> 00:40:04,079
gas 19% coal which is a lot and 3 uh 2%

938
00:40:01,280 --> 00:40:06,497
on average of nuclear and then you know

939
00:40:04,079 --> 00:40:07,040
all of the rest is renewable.

940
00:40:06,497 --> 00:40:08,960
[clears throat]

941
00:40:07,040 --> 00:40:10,640
There are some part of the United States

942
00:40:08,960 --> 00:40:13,200
I'm going to show you in a second which

943
00:40:10,640 --> 00:40:16,480
of course is the one in the center where

944
00:40:13,200 --> 00:40:21,040
is the coal capital where actually the

945
00:40:16,480 --> 00:40:23,839
uh electricity the coal um

946
00:40:21,040 --> 00:40:28,079
the sorry the fall coming from coal is

947
00:40:23,839 --> 00:40:31,599
as higher as a 38 um 38% and so I think

948
00:40:28,079 --> 00:40:34,400
you see you now start resonating about

949
00:40:31,599 --> 00:40:37,119
if you need to you know you could

950
00:40:34,400 --> 00:40:39,839
potentially transfer electricity from

951
00:40:37,119 --> 00:40:42,079
one authority to other even if you don't

952
00:40:39,839 --> 00:40:44,640
want to change the location of the data

953
00:40:42,079 --> 00:40:47,359
center. So then you can at least try to

954
00:40:44,640 --> 00:40:49,599
maximize how much is available on

955
00:40:47,359 --> 00:40:53,359
renewal by the way or renewable energy.

956
00:40:49,599 --> 00:40:55,760
Right now I'm in the middle of of um

957
00:40:53,359 --> 00:40:58,800
actually um

958
00:40:55,760 --> 00:41:00,800
doing some sort of consultation and pro

959
00:40:58,800 --> 00:41:05,839
proono

960
00:41:00,800 --> 00:41:10,960
analysis that will prevent for a meta

961
00:41:05,839 --> 00:41:13,440
data center opening in Nebraska where in

962
00:41:10,960 --> 00:41:15,680
order to do that they're going to reopen

963
00:41:13,440 --> 00:41:18,400
a series of cold fire power plants that

964
00:41:15,680 --> 00:41:21,760
were previously uh were previously shut

965
00:41:18,400 --> 00:41:25,040
down And so basically uh right now I

966
00:41:21,760 --> 00:41:30,240
mean right now already you know since

967
00:41:25,040 --> 00:41:33,040
April 2025th we are dealing with 52 um

968
00:41:30,240 --> 00:41:35,920
69 metaton

969
00:41:33,040 --> 00:41:38,880
uh carbon emission uh which is basically

970
00:41:35,920 --> 00:41:42,000
the equivalent of a major US city or or

971
00:41:38,880 --> 00:41:43,599
a sizable portion of the US aviation. So

972
00:41:42,000 --> 00:41:46,960
it's you know it's becoming like a

973
00:41:43,599 --> 00:41:50,160
sector. Um then there has been an

974
00:41:46,960 --> 00:41:52,800
increase of five times since 2018. Um

975
00:41:50,160 --> 00:41:54,560
and then you know clearly Virginia is

976
00:41:52,800 --> 00:41:56,880
the one that has the largest CO2

977
00:41:54,560 --> 00:41:59,280
emission. This is interesting because

978
00:41:56,880 --> 00:42:02,079
that show the the carbon intensity. So

979
00:41:59,280 --> 00:42:04,319
how much comes from CO2 from energy

980
00:42:02,079 --> 00:42:07,359
electricity and so that's really the I

981
00:42:04,319 --> 00:42:09,200
would call it the coal capital of of uh

982
00:42:07,359 --> 00:42:11,200
of the United States. And so you see for

983
00:42:09,200 --> 00:42:15,119
example that makes no sense to build

984
00:42:11,200 --> 00:42:18,000
another data center um in that um in

985
00:42:15,119 --> 00:42:22,000
that particular region. So I'm going to

986
00:42:18,000 --> 00:42:24,880
um end with one uh one slide which you

987
00:42:22,000 --> 00:42:27,440
know doesn't give you the the answer but

988
00:42:24,880 --> 00:42:30,400
I thought it was an interesting

989
00:42:27,440 --> 00:42:34,800
comparison let's say and so I told you

990
00:42:30,400 --> 00:42:38,319
that the total CO2 emission attributable

991
00:42:34,800 --> 00:42:42,240
to the 43 hypers scale data center is

992
00:42:38,319 --> 00:42:44,480
now 52 million metric tons right and so

993
00:42:42,240 --> 00:42:47,520
then for curiosity

994
00:42:44,480 --> 00:42:51,920
I started to think about

995
00:42:47,520 --> 00:42:54,834
how much g how much CO2 emission will be

996
00:42:51,920 --> 00:42:56,560
cut from the new environmental

997
00:42:54,834 --> 00:42:58,240
[clears throat] reg regulation which is

998
00:42:56,560 --> 00:43:00,319
all the work I'm trying to do and

999
00:42:58,240 --> 00:43:02,480
actually by chance I mean this is a

1000
00:43:00,319 --> 00:43:07,200
little bit of a joke but if you look at

1001
00:43:02,480 --> 00:43:09,680
the APA 2024 regulatory analysis project

1002
00:43:07,200 --> 00:43:11,839
of which I've contributed for the new

1003
00:43:09,680 --> 00:43:15,280
standard for call they said that will

1004
00:43:11,839 --> 00:43:17,599
cut about 55 million metric ton per year

1005
00:43:15,280 --> 00:43:19,760
So we are literally at the point where

1006
00:43:17,599 --> 00:43:23,280
in one hand the new environmental

1007
00:43:19,760 --> 00:43:25,440
regulation are hoping to cut 55 million

1008
00:43:23,280 --> 00:43:29,119
ton and then the new data center will

1009
00:43:25,440 --> 00:43:30,640
generate new 55 million ton. I mean of

1010
00:43:29,119 --> 00:43:32,319
course the story is much more

1011
00:43:30,640 --> 00:43:35,040
complicated than this but I thought it

1012
00:43:32,319 --> 00:43:36,400
was an interesting fun fact to end.

1013
00:43:35,040 --> 00:43:38,079
Thank you so much for your attention.

1014
00:43:36,400 --> 00:43:40,030
Please don't be shy ask question and

1015
00:43:38,079 --> 00:43:42,050
anything. Thank you.

1016
00:43:40,030 --> 00:43:42,050
>> [applause]


1
00:00:04,319 --> 00:00:10,320
I'm happy to introduce our next two

2
00:00:06,799 --> 00:00:13,519
speakers. It'll be a duet. Uh the first

3
00:00:10,320 --> 00:00:17,279
uh will be uh Michael Casey who is a

4
00:00:13,519 --> 00:00:19,359
longtime adviser at the MIT Media Lab.

5
00:00:17,279 --> 00:00:22,480
Um although you wear a lot of hats, I

6
00:00:19,359 --> 00:00:25,119
would add to it author, speaker,

7
00:00:22,480 --> 00:00:26,160
journalist, and actually I would say and

8
00:00:25,119 --> 00:00:28,480
probably a lot of people would say

9
00:00:26,160 --> 00:00:30,800
visionary as well. So uh let's hear it

10
00:00:28,480 --> 00:00:32,399
from Michael. Thanks, Jim. Thanks a lot.

11
00:00:30,800 --> 00:00:33,440
You take that. I've got my own. I'm

12
00:00:32,399 --> 00:00:36,320
good. Yeah.

13
00:00:33,440 --> 00:00:37,840
>> All right. Uh, so, um, thanks. We are

14
00:00:36,320 --> 00:00:39,520
the last act before lunch. So, I

15
00:00:37,840 --> 00:00:40,879
appreciate you sticking around for this.

16
00:00:39,520 --> 00:00:42,079
Um, we're going to take a slightly

17
00:00:40,879 --> 00:00:43,440
different tack, I think, from what the

18
00:00:42,079 --> 00:00:45,040
others have been talking about. Very

19
00:00:43,440 --> 00:00:47,280
integrated, very related to it all.

20
00:00:45,040 --> 00:00:49,360
Hopefully, though. Um, basically, yeah,

21
00:00:47,280 --> 00:00:50,960
I am a senior adviser of the MIT Media

22
00:00:49,360 --> 00:00:52,320
Labs digital currency initiative, but

23
00:00:50,960 --> 00:00:55,199
I'm also the chairman of this thing

24
00:00:52,320 --> 00:00:57,120
called the AI, the advanced AI society.

25
00:00:55,199 --> 00:00:58,800
And what we do is we represent entities

26
00:00:57,120 --> 00:01:01,840
who are building a decentralized

27
00:00:58,800 --> 00:01:03,760
alternative to AI. Now the word

28
00:01:01,840 --> 00:01:05,760
decentralization can conjure up some

29
00:01:03,760 --> 00:01:08,000
scary ideas, right? There's no control.

30
00:01:05,760 --> 00:01:10,080
It's like this idea of nobody being in

31
00:01:08,000 --> 00:01:11,360
charge. Uh actually we're going to be

32
00:01:10,080 --> 00:01:13,680
here to tell you a little bit about the

33
00:01:11,360 --> 00:01:15,600
problem under current centralized AI in

34
00:01:13,680 --> 00:01:17,119
which you are not in charge and that

35
00:01:15,600 --> 00:01:18,640
this is the problem, right? And that

36
00:01:17,119 --> 00:01:20,880
there's a way out of this and we call it

37
00:01:18,640 --> 00:01:23,520
proof of control and it's about taking

38
00:01:20,880 --> 00:01:25,280
an AI portfolio approach to how you do

39
00:01:23,520 --> 00:01:27,040
this. So basically a little bit about me

40
00:01:25,280 --> 00:01:29,759
as I said I associated with the digital

41
00:01:27,040 --> 00:01:33,040
currency initiative at the media lab. Uh

42
00:01:29,759 --> 00:01:34,960
I also taught classes at Sloan with Gary

43
00:01:33,040 --> 00:01:36,240
Gensel and and Simon Johnson being a

44
00:01:34,960 --> 00:01:38,159
couple of them. Obviously Simon being

45
00:01:36,240 --> 00:01:40,799
our latest Noble laureate very proud of

46
00:01:38,159 --> 00:01:42,799
that for him. Um and I done a bunch of

47
00:01:40,799 --> 00:01:44,320
things with IP over the years. But right

48
00:01:42,799 --> 00:01:45,840
now what we at the society are doing

49
00:01:44,320 --> 00:01:46,960
which we think is quite telling in this

50
00:01:45,840 --> 00:01:48,560
space is we're working with Romesh

51
00:01:46,960 --> 00:01:52,560
Rashar at the media lab on his

52
00:01:48,560 --> 00:01:54,240
decentralized AI lab. Um and basically

53
00:01:52,560 --> 00:01:56,000
what Romesh is doing I think is really

54
00:01:54,240 --> 00:01:57,920
quite visionary and I think of it as

55
00:01:56,000 --> 00:02:00,320
something that brings us back to the

56
00:01:57,920 --> 00:02:02,479
roots of the spirit of an open

57
00:02:00,320 --> 00:02:04,320
decentralized internet and this actually

58
00:02:02,479 --> 00:02:06,159
draws in my mind on some of the great

59
00:02:04,320 --> 00:02:07,920
traditions of MIT the network the

60
00:02:06,159 --> 00:02:09,759
computer networking work you know the

61
00:02:07,920 --> 00:02:11,599
likes of Tim Berners Lee perhaps and

62
00:02:09,759 --> 00:02:12,959
sort of you know AI like Marvin Minsky

63
00:02:11,599 --> 00:02:15,599
right these two things coming together

64
00:02:12,959 --> 00:02:17,280
because with AI we have this opportunity

65
00:02:15,599 --> 00:02:19,360
it's a small window we have an

66
00:02:17,280 --> 00:02:21,760
opportunity to to sort of break down the

67
00:02:19,360 --> 00:02:24,640
paradigm of the web 2.0 era with this

68
00:02:21,760 --> 00:02:26,800
very powerful concentration of of

69
00:02:24,640 --> 00:02:28,720
economic and I would say political power

70
00:02:26,800 --> 00:02:30,720
that resides in the hands of a number of

71
00:02:28,720 --> 00:02:32,160
platforms. So the idea that now with

72
00:02:30,720 --> 00:02:34,720
billions of agents all representing

73
00:02:32,160 --> 00:02:36,879
ourselves opening in an open autonomous

74
00:02:34,720 --> 00:02:38,080
independent way we might be able to

75
00:02:36,879 --> 00:02:39,920
actually get back to something that

76
00:02:38,080 --> 00:02:42,160
looks more like this open access system

77
00:02:39,920 --> 00:02:43,680
that we were all dreaming of right uh

78
00:02:42,160 --> 00:02:44,800
the problem is right now under the

79
00:02:43,680 --> 00:02:47,120
current paradigm we're actually

80
00:02:44,800 --> 00:02:50,080
barreling even more heavily into a

81
00:02:47,120 --> 00:02:51,519
concentrated situation right so I as I

82
00:02:50,080 --> 00:02:52,879
said I think this is not only an

83
00:02:51,519 --> 00:02:55,519
economic problem it's a political

84
00:02:52,879 --> 00:02:57,519
problem in my mind this is a fasttrack

85
00:02:55,519 --> 00:02:59,760
way towards totalitarianism this is not

86
00:02:57,519 --> 00:03:02,239
to call out the companies themselves But

87
00:02:59,760 --> 00:03:04,959
the very idea that you would control

88
00:03:02,239 --> 00:03:06,959
this much economic might over the most

89
00:03:04,959 --> 00:03:08,560
important technology of our time that

90
00:03:06,959 --> 00:03:10,159
you know an information technology of

91
00:03:08,560 --> 00:03:11,760
this kind is really quite scary. So we

92
00:03:10,159 --> 00:03:13,840
have a we kind of have a moral and

93
00:03:11,760 --> 00:03:15,120
social imperative to fix this. But today

94
00:03:13,840 --> 00:03:16,400
we're actually going to talk to you I

95
00:03:15,120 --> 00:03:18,560
think in language that is more

96
00:03:16,400 --> 00:03:20,480
persistent and consistent with the idea

97
00:03:18,560 --> 00:03:21,920
of the corporate imperatives that come

98
00:03:20,480 --> 00:03:25,120
with how you deal with this. And that is

99
00:03:21,920 --> 00:03:27,840
to say that in fact using this blackbox

100
00:03:25,120 --> 00:03:29,440
hyperscala model uh certainly if it's

101
00:03:27,840 --> 00:03:30,799
concentrated only in that we're not

102
00:03:29,440 --> 00:03:32,640
dismissing the idea that you work with

103
00:03:30,799 --> 00:03:35,120
LLMs and and so forth but the idea that

104
00:03:32,640 --> 00:03:37,519
it's concentrated in that ends up being

105
00:03:35,120 --> 00:03:38,720
too expensive slower and and your

106
00:03:37,519 --> 00:03:41,920
outcomes aren't aren't what you want

107
00:03:38,720 --> 00:03:43,599
them to be either. I any of you saw the

108
00:03:41,920 --> 00:03:45,760
um Harvard Business Review report

109
00:03:43,599 --> 00:03:47,840
recently about work slop. Well, I see

110
00:03:45,760 --> 00:03:49,680
that as being a function of the lack of

111
00:03:47,840 --> 00:03:51,440
transparency in the system because

112
00:03:49,680 --> 00:03:52,879
ultimately these models are

113
00:03:51,440 --> 00:03:54,159
hallucinating and they are doing things

114
00:03:52,879 --> 00:03:56,239
that we can't control. If we don't know

115
00:03:54,159 --> 00:03:57,519
what's going on under the hood, then

116
00:03:56,239 --> 00:03:58,799
human beings are going to have to go

117
00:03:57,519 --> 00:04:00,640
back and open them up and do it again.

118
00:03:58,799 --> 00:04:02,640
So, we're doing a lot of wasted work and

119
00:04:00,640 --> 00:04:05,120
that amounts to cost and inefficiency

120
00:04:02,640 --> 00:04:06,879
for all of you guys. But it's more than

121
00:04:05,120 --> 00:04:09,599
just money, right? This is actually an

122
00:04:06,879 --> 00:04:11,200
existential issue. Uh it's almost like,

123
00:04:09,599 --> 00:04:13,439
you know, you're not the driver in the

124
00:04:11,200 --> 00:04:15,519
car. You're not really a passenger in a

125
00:04:13,439 --> 00:04:17,120
car. you're actually in a bus that's out

126
00:04:15,519 --> 00:04:18,560
of control. I don't know how many of you

127
00:04:17,120 --> 00:04:20,799
have seen that that classic Sandra

128
00:04:18,560 --> 00:04:22,320
Bulock and Kanu Reeves movie, but you

129
00:04:20,799 --> 00:04:23,919
know, there's there's something quite

130
00:04:22,320 --> 00:04:26,160
threatening about the idea of of having

131
00:04:23,919 --> 00:04:28,800
this all fall apart on our on our watch

132
00:04:26,160 --> 00:04:31,440
here. So, this is going to get real

133
00:04:28,800 --> 00:04:33,600
pretty quickly. We believe that, you

134
00:04:31,440 --> 00:04:36,720
know, there's going to be a demand that

135
00:04:33,600 --> 00:04:39,360
we have to have proofs of control over

136
00:04:36,720 --> 00:04:41,040
our AI, over our data, over our compute,

137
00:04:39,360 --> 00:04:42,880
over the models. And this will come from

138
00:04:41,040 --> 00:04:44,320
boards. It will come from regulators. It

139
00:04:42,880 --> 00:04:45,919
will come through economics because the

140
00:04:44,320 --> 00:04:47,199
scarcity of power is going to create

141
00:04:45,919 --> 00:04:49,840
create a fight. We've been just talking

142
00:04:47,199 --> 00:04:51,680
about all this over those resources. And

143
00:04:49,840 --> 00:04:54,240
and to get there, you need to know that

144
00:04:51,680 --> 00:04:55,840
you've got control. So, you know, and

145
00:04:54,240 --> 00:04:58,160
the other one is the internet itself. It

146
00:04:55,840 --> 00:05:00,000
won't be able to handle billions of

147
00:04:58,160 --> 00:05:02,000
trillions of different endpoints all

148
00:05:00,000 --> 00:05:04,800
acting together through these

149
00:05:02,000 --> 00:05:06,880
centralized systems. So, let's put it in

150
00:05:04,800 --> 00:05:08,240
the context of the $1.3 trillion that

151
00:05:06,880 --> 00:05:10,080
you we're hearing lots of forecasts

152
00:05:08,240 --> 00:05:12,320
obviously where these are going, but IDC

153
00:05:10,080 --> 00:05:15,520
saying that's what the spend is going to

154
00:05:12,320 --> 00:05:18,479
be by 2029 on you know AI solutions and

155
00:05:15,520 --> 00:05:21,360
services. But if we don't have those

156
00:05:18,479 --> 00:05:22,240
proofs in place, it's it's just not

157
00:05:21,360 --> 00:05:23,680
going to happen. there's going to be

158
00:05:22,240 --> 00:05:26,320
these blockages, these constraints that

159
00:05:23,680 --> 00:05:28,240
we just talked about will come up andor

160
00:05:26,320 --> 00:05:30,240
it will mean that the distribution of

161
00:05:28,240 --> 00:05:32,800
that spend is going to be a lot more

162
00:05:30,240 --> 00:05:34,880
uneven, unfair and ultimately AI will

163
00:05:32,800 --> 00:05:36,880
not be able to unlock all of these

164
00:05:34,880 --> 00:05:38,400
solutions that we're looking to solve

165
00:05:36,880 --> 00:05:41,360
and it will fall short of its promise

166
00:05:38,400 --> 00:05:44,000
for humanity. So how do we do so right?

167
00:05:41,360 --> 00:05:47,120
Our thesis that we have to move from

168
00:05:44,000 --> 00:05:49,360
this sort of blackbox sort of this

169
00:05:47,120 --> 00:05:50,800
opaque system to one in which there is a

170
00:05:49,360 --> 00:05:53,680
lot more information about who is

171
00:05:50,800 --> 00:05:55,039
control and that blockchain technologies

172
00:05:53,680 --> 00:05:57,680
along with cryptography you heard a

173
00:05:55,039 --> 00:06:00,000
little bit about you know um zero trust

174
00:05:57,680 --> 00:06:01,120
kind of environments uh TE all these

175
00:06:00,000 --> 00:06:03,280
things some of which are being developed

176
00:06:01,120 --> 00:06:04,960
in the hypers scale world can actually

177
00:06:03,280 --> 00:06:06,800
be deployed in these more localized

178
00:06:04,960 --> 00:06:08,720
settings and all of that is going to

179
00:06:06,800 --> 00:06:11,919
help to build this proofof control

180
00:06:08,720 --> 00:06:13,520
system. The problem is even though these

181
00:06:11,919 --> 00:06:15,759
technologies already exist, right, there

182
00:06:13,520 --> 00:06:17,919
are people building a range of different

183
00:06:15,759 --> 00:06:21,039
mechanisms up and down the stack of all

184
00:06:17,919 --> 00:06:22,800
these different AI providers to give

185
00:06:21,039 --> 00:06:24,319
you, you know, verification of your

186
00:06:22,800 --> 00:06:27,280
model to give you control over the

187
00:06:24,319 --> 00:06:29,600
compute and so forth. There's really not

188
00:06:27,280 --> 00:06:31,360
a lot happening between those vendors

189
00:06:29,600 --> 00:06:32,319
and the buyers, the enterprises who are

190
00:06:31,360 --> 00:06:34,880
using them. This is sort of an

191
00:06:32,319 --> 00:06:37,199
automatic, you know, click the buy

192
00:06:34,880 --> 00:06:38,800
button through the centralized model. So

193
00:06:37,199 --> 00:06:40,240
there's a lack of visibility about

194
00:06:38,800 --> 00:06:42,479
what's going on here. And that's really

195
00:06:40,240 --> 00:06:44,800
what the advanced AI society is all

196
00:06:42,479 --> 00:06:48,240
about. We are here to, you know,

197
00:06:44,800 --> 00:06:50,240
basically enable this connection between

198
00:06:48,240 --> 00:06:51,280
enterprises and the providers of these

199
00:06:50,240 --> 00:06:53,680
solutions that are going to give those

200
00:06:51,280 --> 00:06:55,680
enterprises the proof of control over

201
00:06:53,680 --> 00:06:57,600
their AI systems and get us out of this

202
00:06:55,680 --> 00:06:59,360
this problem. And to tell you more about

203
00:06:57,600 --> 00:07:02,479
that, I'm going to get Trisha to come

204
00:06:59,360 --> 00:07:04,960
out and uh dig you deeper into it. This

205
00:07:02,479 --> 00:07:07,840
is Trisha Wong who is uh she's the CEO

206
00:07:04,960 --> 00:07:11,360
of the advanced AI society and um

207
00:07:07,840 --> 00:07:13,680
>> I work with Trisha on a uh on her prior

208
00:07:11,360 --> 00:07:16,080
blockchain research lab and Trish has a

209
00:07:13,680 --> 00:07:17,919
a deep experience in sort of resolving

210
00:07:16,080 --> 00:07:20,160
enterprise challenges for Fortune 500

211
00:07:17,919 --> 00:07:22,800
and so you know go for it Trisha.

212
00:07:20,160 --> 00:07:25,280
>> Thanks Michael. So as Michael has

213
00:07:22,800 --> 00:07:26,880
outlined is that we have a big proof of

214
00:07:25,280 --> 00:07:28,000
control bottleneck coming but there's

215
00:07:26,880 --> 00:07:29,440
all these solutions that already in

216
00:07:28,000 --> 00:07:32,560
place and that's why we started advanced

217
00:07:29,440 --> 00:07:34,720
AI society and we are on one end the

218
00:07:32,560 --> 00:07:36,160
industry association of all the leading

219
00:07:34,720 --> 00:07:38,080
providers that are actually developing

220
00:07:36,160 --> 00:07:39,520
these solutions for proof of control but

221
00:07:38,080 --> 00:07:41,039
they're specialist vendors so they're

222
00:07:39,520 --> 00:07:42,479
not very well known right now and on the

223
00:07:41,039 --> 00:07:44,479
other end we're building out a

224
00:07:42,479 --> 00:07:46,639
marketplace called portfolio works that

225
00:07:44,479 --> 00:07:48,479
really bundles their solutions but the

226
00:07:46,639 --> 00:07:49,599
thing is is that you know we do a lot of

227
00:07:48,479 --> 00:07:51,840
research here at the industry

228
00:07:49,599 --> 00:07:54,400
association so we have an evidence lab

229
00:07:51,840 --> 00:07:56,560
and compute is as we all know one of the

230
00:07:54,400 --> 00:07:58,160
biggest costs for AI. So we have a

231
00:07:56,560 --> 00:07:59,199
report coming out on that topic and I

232
00:07:58,160 --> 00:08:01,440
just want to tell you what the big

233
00:07:59,199 --> 00:08:03,919
takeaway is. Now early on um as we get

234
00:08:01,440 --> 00:08:06,319
to preview that here at data center day

235
00:08:03,919 --> 00:08:07,680
is that um you know our big takeaway and

236
00:08:06,319 --> 00:08:10,160
if there's just anything for you to

237
00:08:07,680 --> 00:08:12,240
remember after today is that it is you

238
00:08:10,160 --> 00:08:14,319
know to build a missionritical high

239
00:08:12,240 --> 00:08:16,800
resilience and compliant AI compute

240
00:08:14,319 --> 00:08:18,960
infrastructure now requires you to

241
00:08:16,800 --> 00:08:21,199
really figure out what your customized

242
00:08:18,960 --> 00:08:23,280
approach is with both hyperscalers and

243
00:08:21,199 --> 00:08:25,360
proof of control vendors. you know a lot

244
00:08:23,280 --> 00:08:26,800
about the hyperscalers but you don't

245
00:08:25,360 --> 00:08:28,080
know a lot about the proof of control

246
00:08:26,800 --> 00:08:30,400
vendors which is what we're here to tell

247
00:08:28,080 --> 00:08:32,240
you a bit more about and you know the

248
00:08:30,400 --> 00:08:33,680
thing is is that if you're you know we

249
00:08:32,240 --> 00:08:35,760
want to make very clear is that if your

250
00:08:33,680 --> 00:08:37,279
stack only looks like this especially

251
00:08:35,760 --> 00:08:39,039
after today's you know talk is we want

252
00:08:37,279 --> 00:08:41,680
to help communicate is that anyone's

253
00:08:39,039 --> 00:08:43,440
stack who only looks like this you are

254
00:08:41,680 --> 00:08:45,680
vulnerable you actually have greater

255
00:08:43,440 --> 00:08:47,360
risk of business continuity and so our

256
00:08:45,680 --> 00:08:49,440
goal is not to say oh only do

257
00:08:47,360 --> 00:08:50,800
hyperscalers or only do proof of control

258
00:08:49,440 --> 00:08:52,880
we're saying you want to take an

259
00:08:50,800 --> 00:08:54,560
integrated approach that takes the best

260
00:08:52,880 --> 00:08:57,040
of both worlds customized to your

261
00:08:54,560 --> 00:08:59,519
solution and we call this the portfolio

262
00:08:57,040 --> 00:09:02,080
AI approach which means diversifying

263
00:08:59,519 --> 00:09:04,320
your AI stack and mixing you know these

264
00:09:02,080 --> 00:09:06,320
decentralized AI options that also comes

265
00:09:04,320 --> 00:09:08,640
along with you know open and federated

266
00:09:06,320 --> 00:09:10,800
options and really adopting these proof

267
00:09:08,640 --> 00:09:12,160
of control solutions in the places that

268
00:09:10,800 --> 00:09:13,760
are appropriate in your stack. So we

269
00:09:12,160 --> 00:09:15,040
think you know the modern business

270
00:09:13,760 --> 00:09:16,720
infrastructure for business when you

271
00:09:15,040 --> 00:09:18,240
talk between company AB or government

272
00:09:16,720 --> 00:09:20,240
ABC it's all going to look different

273
00:09:18,240 --> 00:09:22,880
what their portfolio is going to be

274
00:09:20,240 --> 00:09:24,959
shaped by what their needs are and so I

275
00:09:22,880 --> 00:09:27,360
just want to you know provide a few

276
00:09:24,959 --> 00:09:29,360
insights from our research we've been

277
00:09:27,360 --> 00:09:31,120
talking to you know the buyers who are

278
00:09:29,360 --> 00:09:32,959
dealing with the struggles of pushing

279
00:09:31,120 --> 00:09:34,800
the limits of only their hyperscaler

280
00:09:32,959 --> 00:09:36,880
stack and then we're talk we've been

281
00:09:34,800 --> 00:09:38,240
talking a lot to the vendors these

282
00:09:36,880 --> 00:09:40,560
specialist vendors who have these

283
00:09:38,240 --> 00:09:43,440
solutions. So the first big trend to

284
00:09:40,560 --> 00:09:45,519
know is that there's a shift that's just

285
00:09:43,440 --> 00:09:47,360
overall overall it's all going to be if

286
00:09:45,519 --> 00:09:49,120
you start to adopt these controls there

287
00:09:47,360 --> 00:09:51,680
are ways that will make your entire

288
00:09:49,120 --> 00:09:53,440
operations cheaper faster and better and

289
00:09:51,680 --> 00:09:55,200
one of those first things way it becomes

290
00:09:53,440 --> 00:09:57,120
cheaper is that right now there's

291
00:09:55,200 --> 00:09:58,720
usually a massive upfront capex you just

292
00:09:57,120 --> 00:10:00,480
heard about that from Morgan how it

293
00:09:58,720 --> 00:10:02,240
takes you know all this money to even

294
00:10:00,480 --> 00:10:04,399
build just a 10 megawatt center so now

295
00:10:02,240 --> 00:10:06,560
we're moving into a more dynamic opex

296
00:10:04,399 --> 00:10:08,880
utility model that allows for

297
00:10:06,560 --> 00:10:10,959
verifiability and flexible usage message

298
00:10:08,880 --> 00:10:12,720
so you don't get distracted access. So

299
00:10:10,959 --> 00:10:14,640
some of um you know the names to look

300
00:10:12,720 --> 00:10:16,959
out for in this space you know Across

301
00:10:14,640 --> 00:10:19,839
they're actually building down to you

302
00:10:16,959 --> 00:10:22,000
know using your phone using cell phones

303
00:10:19,839 --> 00:10:23,680
as a way to uh build it into this

304
00:10:22,000 --> 00:10:25,360
infrastructure and then you have a

305
00:10:23,680 --> 00:10:27,200
company called Tesak stakes you know

306
00:10:25,360 --> 00:10:29,519
they actually allow you to figure out

307
00:10:27,200 --> 00:10:31,839
how to own a part of the data center and

308
00:10:29,519 --> 00:10:33,440
they build a governance into it and you

309
00:10:31,839 --> 00:10:36,640
can actually prove that ownership and

310
00:10:33,440 --> 00:10:39,040
usage. A cave cloud is storage, but you

311
00:10:36,640 --> 00:10:41,839
get zero egress fees. And then spiron

312
00:10:39,040 --> 00:10:43,920
allows you to do remote LLMs. So bring

313
00:10:41,839 --> 00:10:47,519
down the cost from let's say like

314
00:10:43,920 --> 00:10:49,760
$500,000 to even$10 to $20,000. So these

315
00:10:47,519 --> 00:10:52,399
are massive cost differences and savings

316
00:10:49,760 --> 00:10:54,240
for companies. And along with that is

317
00:10:52,399 --> 00:10:56,399
that there's also, you know, the move

318
00:10:54,240 --> 00:10:58,560
from these long infrastructural build

319
00:10:56,399 --> 00:10:59,920
timelines to these rapid flexible

320
00:10:58,560 --> 00:11:01,440
deployment. And you heard that before

321
00:10:59,920 --> 00:11:03,200
from Morgan where it takes like

322
00:11:01,440 --> 00:11:05,200
oftentimes, you know, three, six, 10

323
00:11:03,200 --> 00:11:06,480
years depending on what kind of, you

324
00:11:05,200 --> 00:11:09,040
know, data center you want to build.

325
00:11:06,480 --> 00:11:10,959
It's faster for Elon to ship a power,

326
00:11:09,040 --> 00:11:13,279
you know, center from a data center from

327
00:11:10,959 --> 00:11:14,959
Europe over to here. Um, you know, you

328
00:11:13,279 --> 00:11:17,279
see Google investing in all these

329
00:11:14,959 --> 00:11:19,279
nuclear reactors. Well, there's this new

330
00:11:17,279 --> 00:11:21,440
world where it's you can actually build

331
00:11:19,279 --> 00:11:23,920
rapid and flexible deployment of compute

332
00:11:21,440 --> 00:11:25,600
functionality. And so you have Holland

333
00:11:23,920 --> 00:11:27,440
here where they're really building

334
00:11:25,600 --> 00:11:28,720
building out these micro data centers.

335
00:11:27,440 --> 00:11:30,720
You have Athier who's really like the

336
00:11:28,720 --> 00:11:33,519
Airbnb of GPUs around the world there.

337
00:11:30,720 --> 00:11:35,760
They build enterprisegrade distributed

338
00:11:33,519 --> 00:11:37,839
uh you know GPUs and you have Across

339
00:11:35,760 --> 00:11:40,800
again who also leverages the storage on

340
00:11:37,839 --> 00:11:43,519
your phone. And then we're seeing this

341
00:11:40,800 --> 00:11:45,600
move from opaque residency to

342
00:11:43,519 --> 00:11:48,079
cryptographically verifiable

343
00:11:45,600 --> 00:11:49,839
sovereignty. Now hyperscalers are

344
00:11:48,079 --> 00:11:52,240
already you know you have Google, you

345
00:11:49,839 --> 00:11:53,920
have um them they're they're offering

346
00:11:52,240 --> 00:11:55,680
options for residency. This is not to

347
00:11:53,920 --> 00:11:58,079
say you can't get it with your current

348
00:11:55,680 --> 00:11:59,760
cloud providers, but what you see a move

349
00:11:58,079 --> 00:12:02,160
to is actually, you know, you're going

350
00:11:59,760 --> 00:12:04,240
to have regulators say we want you to

351
00:12:02,160 --> 00:12:06,880
actually prove and we want you to get

352
00:12:04,240 --> 00:12:08,959
very granular in where the data was

353
00:12:06,880 --> 00:12:10,959
residents and processed. So you see this

354
00:12:08,959 --> 00:12:12,959
with a coffee cloud that's an option.

355
00:12:10,959 --> 00:12:16,000
You have equity labs which is does you

356
00:12:12,959 --> 00:12:18,880
know down to the new Nvidia chips H100s

357
00:12:16,000 --> 00:12:21,200
where it's provable compliance onto the

358
00:12:18,880 --> 00:12:22,880
very chip itself. And then you have a

359
00:12:21,200 --> 00:12:24,800
here who also offers that down to the

360
00:12:22,880 --> 00:12:27,279
sovereignty. So you get really granular

361
00:12:24,800 --> 00:12:29,360
not just a region but you can say I want

362
00:12:27,279 --> 00:12:31,600
this type of data in this you know

363
00:12:29,360 --> 00:12:34,399
country or even in this city on this

364
00:12:31,600 --> 00:12:36,639
block and then overall all of these

365
00:12:34,399 --> 00:12:38,399
technologies the big difference is that

366
00:12:36,639 --> 00:12:39,839
it's moving from this kind of trust us

367
00:12:38,399 --> 00:12:41,760
relationship because you can trust these

368
00:12:39,839 --> 00:12:43,120
hyperscalers. You know it's all spelled

369
00:12:41,760 --> 00:12:44,720
out in the contract. You just have to go

370
00:12:43,120 --> 00:12:46,800
into their portal. You're going to get

371
00:12:44,720 --> 00:12:48,320
those reports. But as we've said with

372
00:12:46,800 --> 00:12:49,680
the proof of control bottleneck that's

373
00:12:48,320 --> 00:12:51,680
coming is that you're going to have

374
00:12:49,680 --> 00:12:54,399
regulators and boards saying we want

375
00:12:51,680 --> 00:12:56,399
more publicly provable verifiable

376
00:12:54,399 --> 00:12:58,240
immutable control. Do you need that for

377
00:12:56,399 --> 00:13:00,480
all of your data? No. But you want to

378
00:12:58,240 --> 00:13:01,839
figure out what parts of your compute

379
00:13:00,480 --> 00:13:03,920
infrastructure you're going to need that

380
00:13:01,839 --> 00:13:05,760
for. And so you scan you see that coming

381
00:13:03,920 --> 00:13:07,920
from services like equity labs. We have

382
00:13:05,760 --> 00:13:09,680
secret network where they offer TE. And

383
00:13:07,920 --> 00:13:10,720
we know that you know TE is being

384
00:13:09,680 --> 00:13:12,480
offered already already by the

385
00:13:10,720 --> 00:13:14,720
hyperscalers. But what secret does is

386
00:13:12,480 --> 00:13:16,160
that they do it via smart contracts. So

387
00:13:14,720 --> 00:13:18,399
it's very much tamperproof. You have

388
00:13:16,160 --> 00:13:21,120
filecoin that does you know tamperproof

389
00:13:18,399 --> 00:13:22,880
archival storage and actually MIT's

390
00:13:21,120 --> 00:13:24,720
courseware is many of their courses are

391
00:13:22,880 --> 00:13:26,560
uploaded to filecoin. And then you have

392
00:13:24,720 --> 00:13:29,200
quip which offers the world's first

393
00:13:26,560 --> 00:13:30,800
shared quantum computing with also

394
00:13:29,200 --> 00:13:32,959
verification.

395
00:13:30,800 --> 00:13:35,120
And lastly, the insight is you know the

396
00:13:32,959 --> 00:13:37,360
big change this all represents is that

397
00:13:35,120 --> 00:13:39,360
we're moving from a single vendor

398
00:13:37,360 --> 00:13:41,120
dependency you know so even if you do

399
00:13:39,360 --> 00:13:42,639
multilouds which is the reality we know

400
00:13:41,120 --> 00:13:45,200
not you know you're not literally with

401
00:13:42,639 --> 00:13:47,600
one single vendor vendor but these

402
00:13:45,200 --> 00:13:49,519
vendors are all about propri proprietary

403
00:13:47,600 --> 00:13:51,519
controls once you're in their system

404
00:13:49,519 --> 00:13:53,360
it's very costly to leave you know it's

405
00:13:51,519 --> 00:13:56,639
very costly to you know you can't just

406
00:13:53,360 --> 00:13:58,079
change SDKs out so this move is to this

407
00:13:56,639 --> 00:14:00,639
AI portfolio approach of the

408
00:13:58,079 --> 00:14:02,959
best-in-class products from hyperscalers

409
00:14:00,639 --> 00:14:04,880
and the proof of control vendors. So the

410
00:14:02,959 --> 00:14:06,720
modern computing infrastructure stack

411
00:14:04,880 --> 00:14:08,320
should really start to look like a mix.

412
00:14:06,720 --> 00:14:09,760
You're going to want to figure out well

413
00:14:08,320 --> 00:14:11,440
what of the vendors from proof of

414
00:14:09,760 --> 00:14:13,360
control are going to make sense and what

415
00:14:11,440 --> 00:14:15,360
of the vendors from my hyperscalers are

416
00:14:13,360 --> 00:14:16,880
going to make sense. And the best thing

417
00:14:15,360 --> 00:14:18,800
about all of these proof of control

418
00:14:16,880 --> 00:14:21,199
technology is that they're composable.

419
00:14:18,800 --> 00:14:23,040
They're integrable. They it's not about

420
00:14:21,199 --> 00:14:24,880
forcing you to make a choice of either

421
00:14:23,040 --> 00:14:27,519
or. They all integrate into your

422
00:14:24,880 --> 00:14:29,519
existing systems. And so before we take

423
00:14:27,519 --> 00:14:31,600
questions, I want to end on, you know,

424
00:14:29,519 --> 00:14:33,120
we prepared just to get a sense of like,

425
00:14:31,600 --> 00:14:35,040
well, how do you figure out where in

426
00:14:33,120 --> 00:14:36,639
your AI portfolio would you want to

427
00:14:35,040 --> 00:14:37,839
prioritize proof of control? I'm not

428
00:14:36,639 --> 00:14:39,440
going to go through all these questions

429
00:14:37,839 --> 00:14:41,680
here, but just to go give you an

430
00:14:39,440 --> 00:14:44,160
example. The first one is that you know

431
00:14:41,680 --> 00:14:45,920
this is a very this is the very I would

432
00:14:44,160 --> 00:14:48,079
say most popular use cases that we see

433
00:14:45,920 --> 00:14:49,279
emerging for a real case for why you

434
00:14:48,079 --> 00:14:51,600
would have want to adopt and where you

435
00:14:49,279 --> 00:14:53,120
would adopt proof of control is you want

436
00:14:51,600 --> 00:14:54,480
to start asking your teams and you may

437
00:14:53,120 --> 00:14:55,760
not be able to answer this question

438
00:14:54,480 --> 00:14:57,760
yourselves but certainly you want to

439
00:14:55,760 --> 00:14:59,040
take this sheet back and talk to you

440
00:14:57,760 --> 00:15:00,399
with your team about and by the way

441
00:14:59,040 --> 00:15:03,120
we're going to provide a QR code where

442
00:15:00,399 --> 00:15:04,480
you can um download the report um is the

443
00:15:03,120 --> 00:15:06,639
first question is well you might want to

444
00:15:04,480 --> 00:15:08,560
ask your your team is where do we have

445
00:15:06,639 --> 00:15:11,839
product offerings where it's actually

446
00:15:08,560 --> 00:15:14,480
very zero to even you know low to zero

447
00:15:11,839 --> 00:15:16,160
tolerance for latency. So emerging

448
00:15:14,480 --> 00:15:18,160
conversations we're having with buyers

449
00:15:16,160 --> 00:15:20,320
or potential buyers is really around

450
00:15:18,160 --> 00:15:22,560
autonomous vehicles, anything around

451
00:15:20,320 --> 00:15:24,079
healthcare or even gaming where you can

452
00:15:22,560 --> 00:15:26,160
see that like you don't want to you

453
00:15:24,079 --> 00:15:28,480
can't afford that round trip to the

454
00:15:26,160 --> 00:15:29,839
cloud and back. And so we have a bunch

455
00:15:28,480 --> 00:15:31,920
of questions we'd love to talk to you

456
00:15:29,839 --> 00:15:33,519
about. Um and this is all really linked

457
00:15:31,920 --> 00:15:35,600
back to the innovations that are

458
00:15:33,519 --> 00:15:37,519
happening out of you know project Nando

459
00:15:35,600 --> 00:15:39,440
where Romesh Rescar really provides this

460
00:15:37,519 --> 00:15:41,199
kind of vision for what happens when

461
00:15:39,440 --> 00:15:43,440
that stress point of not billions but

462
00:15:41,199 --> 00:15:45,360
trillions of agents and endpoints come

463
00:15:43,440 --> 00:15:47,519
online and start to stress the current

464
00:15:45,360 --> 00:15:48,880
system that we have. And so with these

465
00:15:47,519 --> 00:15:50,079
questions and insights we hope you can

466
00:15:48,880 --> 00:15:52,079
see that you don't have to be on this

467
00:15:50,079 --> 00:15:53,839
bus you know you don't even have to be a

468
00:15:52,079 --> 00:15:56,160
passenger on this in a seat. you can

469
00:15:53,839 --> 00:15:57,759
actually be control and you can figure

470
00:15:56,160 --> 00:15:59,440
out at what points would you want to

471
00:15:57,759 --> 00:16:00,959
take more of a backseat role or at what

472
00:15:59,440 --> 00:16:03,279
points do you really want to make sure

473
00:16:00,959 --> 00:16:04,480
you are in control of that car. So,

474
00:16:03,279 --> 00:16:10,279
thank you so much and do we have time

475
00:16:04,480 --> 00:16:10,279
for questions or should we go to lunch?

476
00:16:11,199 --> 00:16:14,519
>> Any questions?

477
00:16:16,240 --> 00:16:20,320
>> Thank you. That was fantastic. Um you

478
00:16:18,079 --> 00:16:22,240
mentioned a point about uh composability

479
00:16:20,320 --> 00:16:25,199
and and being able to integrate a lot of

480
00:16:22,240 --> 00:16:26,560
these proof of control vendors. Um could

481
00:16:25,199 --> 00:16:29,199
you go a little bit more into detail

482
00:16:26,560 --> 00:16:31,040
about like the difference of uh

483
00:16:29,199 --> 00:16:33,040
hyperscalers where you sort of have to

484
00:16:31,040 --> 00:16:35,199
go to where their facilities are and

485
00:16:33,040 --> 00:16:36,560
where their infrastructure is versus

486
00:16:35,199 --> 00:16:37,920
some of the more flexibility you might

487
00:16:36,560 --> 00:16:41,040
get from these proof of control vendors

488
00:16:37,920 --> 00:16:42,639
in terms of being deployed deployable to

489
00:16:41,040 --> 00:16:44,160
cl

490
00:16:42,639 --> 00:16:45,680
within your overall kind of network

491
00:16:44,160 --> 00:16:48,000
stack within your CDN providers like

492
00:16:45,680 --> 00:16:49,759
Akami and other kind of places that they

493
00:16:48,000 --> 00:16:51,600
might be able to be more flexible.

494
00:16:49,759 --> 00:16:53,519
>> Yeah. So the current hyperscalers when

495
00:16:51,600 --> 00:16:55,360
you're working in their ecosystem that's

496
00:16:53,519 --> 00:16:56,320
that's really convenient right that's

497
00:16:55,360 --> 00:16:58,079
the thing about going with the

498
00:16:56,320 --> 00:16:59,440
hyperscape the ecosystem and there are

499
00:16:58,079 --> 00:17:01,120
times where it makes sense especially if

500
00:16:59,440 --> 00:17:03,199
you're just getting started you want to

501
00:17:01,120 --> 00:17:04,720
just get started you want to go and once

502
00:17:03,199 --> 00:17:06,959
you're in their system it's very easy to

503
00:17:04,720 --> 00:17:09,280
deploy and that's the convenience the

504
00:17:06,959 --> 00:17:11,600
upside of it one of the reasons why it's

505
00:17:09,280 --> 00:17:13,280
been hard you know this is no fault of

506
00:17:11,600 --> 00:17:15,600
the buyers and the industry why it's

507
00:17:13,280 --> 00:17:17,760
hard to find these specialist vendors is

508
00:17:15,600 --> 00:17:20,160
that they're developing at different

509
00:17:17,760 --> 00:17:22,000
layers of the stack they're Not it's

510
00:17:20,160 --> 00:17:23,839
hard to find one ecosystem that's going

511
00:17:22,000 --> 00:17:26,400
to encompass it all. But the great thing

512
00:17:23,839 --> 00:17:28,240
about composability um which really that

513
00:17:26,400 --> 00:17:30,559
word is just means like portability,

514
00:17:28,240 --> 00:17:32,320
flexibility. It's like Lego blocks that

515
00:17:30,559 --> 00:17:34,400
all just actually fit together because

516
00:17:32,320 --> 00:17:35,919
of the underlying code and the

517
00:17:34,400 --> 00:17:37,760
underlying language and underlying

518
00:17:35,919 --> 00:17:40,080
agreements in the space of using

519
00:17:37,760 --> 00:17:41,760
blockchain is that it all we can

520
00:17:40,080 --> 00:17:43,600
actually bundle that techn those

521
00:17:41,760 --> 00:17:45,840
technologies together. So it actually in

522
00:17:43,600 --> 00:17:47,679
the end gives a buyer much more choice

523
00:17:45,840 --> 00:17:49,520
and freedom because you're not forced to

524
00:17:47,679 --> 00:17:52,080
only buy this one type of bundle. You

525
00:17:49,520 --> 00:17:53,840
can actually swap out pieces of a layer.

526
00:17:52,080 --> 00:17:55,760
You can say well I don't want that kind

527
00:17:53,840 --> 00:17:57,840
of residency because I don't need that

528
00:17:55,760 --> 00:17:59,840
those options. I want to go with this

529
00:17:57,840 --> 00:18:01,360
provider. Well gives that's what allows.

530
00:17:59,840 --> 00:18:02,960
So this is hope that answers your

531
00:18:01,360 --> 00:18:04,000
question. You want to add anything? No,

532
00:18:02,960 --> 00:18:06,000
I think that's it. I mean, there's a lot

533
00:18:04,000 --> 00:18:07,520
of sort of smart contract solutions that

534
00:18:06,000 --> 00:18:09,919
essentially are sort of just keying off

535
00:18:07,520 --> 00:18:12,240
the multiple different uh pieces that

536
00:18:09,919 --> 00:18:14,000
then give you this sort of uniform

537
00:18:12,240 --> 00:18:15,520
uniform bundle essentially is the way I

538
00:18:14,000 --> 00:18:17,760
like to think about it.

539
00:18:15,520 --> 00:18:18,960
>> Um, and you spoke to portability. So I

540
00:18:17,760 --> 00:18:20,960
think a lot of the purpose that you're

541
00:18:18,960 --> 00:18:22,960
trying to do especially with like

542
00:18:20,960 --> 00:18:24,240
creating these bundled portfolios is to

543
00:18:22,960 --> 00:18:25,679
if I want to switch out an

544
00:18:24,240 --> 00:18:28,400
infrastructure provider with one of

545
00:18:25,679 --> 00:18:31,440
these um proof of control uh vendors to

546
00:18:28,400 --> 00:18:34,000
another one that the overall burden of

547
00:18:31,440 --> 00:18:36,160
me like switching costs or changing out

548
00:18:34,000 --> 00:18:38,000
my compute infrastructure or deciding

549
00:18:36,160 --> 00:18:39,840
maybe I want to test out some of the

550
00:18:38,000 --> 00:18:41,840
infrastructure rather than shifting my

551
00:18:39,840 --> 00:18:43,039
entire workload. That's kind of what you

552
00:18:41,840 --> 00:18:45,200
guys are going to be focused on trying

553
00:18:43,039 --> 00:18:45,919
to ensure that that's that's a an easy

554
00:18:45,200 --> 00:18:47,440
process.

555
00:18:45,919 --> 00:18:48,960
>> Yeah. Yeah. And we have a tech sandbox

556
00:18:47,440 --> 00:18:50,880
because it's composable. It just so

557
00:18:48,960 --> 00:18:52,960
happens it's very easy to host a tech

558
00:18:50,880 --> 00:18:54,000
sandbox for all of our members where you

559
00:18:52,960 --> 00:18:56,080
can come in and play with the

560
00:18:54,000 --> 00:18:57,760
technology. And one of the highest costs

561
00:18:56,080 --> 00:19:00,080
you see for startups right now, which is

562
00:18:57,760 --> 00:19:02,640
really crazy and a blocker to innovation

563
00:19:00,080 --> 00:19:04,160
is in fees for, you know, getting access

564
00:19:02,640 --> 00:19:06,240
to these models, getting access to

565
00:19:04,160 --> 00:19:07,760
storage, getting access to compute. It's

566
00:19:06,240 --> 00:19:09,120
exorbitant and it's actually holding

567
00:19:07,760 --> 00:19:11,679
startups behind that they have to

568
00:19:09,120 --> 00:19:13,520
dedicate more of their costs to just the

569
00:19:11,679 --> 00:19:15,360
infrastructure. Well, what you see in

570
00:19:13,520 --> 00:19:18,320
these more portable with these options

571
00:19:15,360 --> 00:19:20,480
that we see amongst our members is that

572
00:19:18,320 --> 00:19:22,799
you get zero across fees. It's very

573
00:19:20,480 --> 00:19:25,039
predictable. You can build that in to

574
00:19:22,799 --> 00:19:26,640
your budget. So, you can anticipate what

575
00:19:25,039 --> 00:19:28,480
those costs are. You also know you're

576
00:19:26,640 --> 00:19:30,000
not going to get vendor lock in that

577
00:19:28,480 --> 00:19:31,360
they're not going to all sudden jack up

578
00:19:30,000 --> 00:19:32,320
the fees later on.

579
00:19:31,360 --> 00:19:34,240
>> I'll just say this as well about

580
00:19:32,320 --> 00:19:36,320
portability of course, right? One of the

581
00:19:34,240 --> 00:19:38,799
most important, you know, costs you will

582
00:19:36,320 --> 00:19:40,320
face is a loss of data or is is the

583
00:19:38,799 --> 00:19:41,600
capacity to control that data, right?

584
00:19:40,320 --> 00:19:43,280
It's the most important thing that you

585
00:19:41,600 --> 00:19:44,559
have. In fact, I like to say that one of

586
00:19:43,280 --> 00:19:45,919
the great things about a proof of

587
00:19:44,559 --> 00:19:48,000
control approach is that this is how

588
00:19:45,919 --> 00:19:49,919
we're going to give all of this really

589
00:19:48,000 --> 00:19:52,400
sensitive data that is currently under

590
00:19:49,919 --> 00:19:54,480
lock and keen is not being applied to AI

591
00:19:52,400 --> 00:19:56,160
a chance to actually safely be applied

592
00:19:54,480 --> 00:19:57,360
to it and we can start to address some

593
00:19:56,160 --> 00:19:59,840
of the problems we've been talking about

594
00:19:57,360 --> 00:20:02,400
climate change you know energy solutions

595
00:19:59,840 --> 00:20:04,320
etc etc with data that is actually

596
00:20:02,400 --> 00:20:06,320
really really sensitive. So the idea

597
00:20:04,320 --> 00:20:08,480
that rather than just entering into a

598
00:20:06,320 --> 00:20:10,400
privacy agreement with a hyperscaler,

599
00:20:08,480 --> 00:20:11,840
you literally have ownership and control

600
00:20:10,400 --> 00:20:13,440
over under a provably private

601
00:20:11,840 --> 00:20:15,440
environment and then you can port it

602
00:20:13,440 --> 00:20:17,600
somewhere else. That's the key point,

603
00:20:15,440 --> 00:20:19,120
right? It's it's that level of control

604
00:20:17,600 --> 00:20:20,880
that protects you from the risks

605
00:20:19,120 --> 00:20:23,039
associated with it and then you know

606
00:20:20,880 --> 00:20:24,880
really makes that that switching and

607
00:20:23,039 --> 00:20:26,799
that transition cost so much so much

608
00:20:24,880 --> 00:20:27,360
lighter. So, I think it's a really

609
00:20:26,799 --> 00:20:28,960
important point

610
00:20:27,360 --> 00:20:30,960
>> and I think it's going to be I mean a

611
00:20:28,960 --> 00:20:32,960
thing that brands are going to want to

612
00:20:30,960 --> 00:20:34,799
promote for parts of the data where

613
00:20:32,960 --> 00:20:37,280
their customers are going to want to see

614
00:20:34,799 --> 00:20:38,799
that public verifiability because it's

615
00:20:37,280 --> 00:20:40,640
actually going to make them trust you

616
00:20:38,799 --> 00:20:42,480
more on what you're doing with their

617
00:20:40,640 --> 00:20:46,679
data and that they can actually see and

618
00:20:42,480 --> 00:20:46,679
have access to it as they get smarter.

619
00:20:48,400 --> 00:20:53,679
>> Thank you. Okay, one more. I'm an active

620
00:20:51,760 --> 00:20:55,600
questioner I guess but um from a

621
00:20:53,679 --> 00:20:57,600
mechanical engineer's point of view so

622
00:20:55,600 --> 00:20:59,039
explain it why I'm five I guess but is

623
00:20:57,600 --> 00:21:00,960
there any inherent friction with the

624
00:20:59,039 --> 00:21:02,960
scaling laws on performance especially

625
00:21:00,960 --> 00:21:04,880
as you get to the efficiencies of of

626
00:21:02,960 --> 00:21:07,280
scale from a a compute cluster

627
00:21:04,880 --> 00:21:09,840
perspective but also um if you look at

628
00:21:07,280 --> 00:21:11,919
like the Nvidia GPU generations and the

629
00:21:09,840 --> 00:21:14,400
the NVL link domains that they're

630
00:21:11,919 --> 00:21:16,320
expanding um is just are there any

631
00:21:14,400 --> 00:21:18,240
frictions with the the scaling laws

632
00:21:16,320 --> 00:21:20,000
especially like test time as even on the

633
00:21:18,240 --> 00:21:21,520
inference side you need more more and

634
00:21:20,000 --> 00:21:22,240
more compute to to hit some of the

635
00:21:21,520 --> 00:21:23,440
performances.

636
00:21:22,240 --> 00:21:25,200
>> It's a question we get all the time,

637
00:21:23,440 --> 00:21:26,720
right? Because it is clearly the idea of

638
00:21:25,200 --> 00:21:28,000
latency and challenge that comes from

639
00:21:26,720 --> 00:21:29,440
sort of colllocating in these

640
00:21:28,000 --> 00:21:32,159
environments. But there's an enormous

641
00:21:29,440 --> 00:21:33,840
amount of work being done right now. Um

642
00:21:32,159 --> 00:21:36,159
um just blanking on the names, but um

643
00:21:33,840 --> 00:21:37,760
you know, NAS research for example, uh

644
00:21:36,159 --> 00:21:39,360
prime intellect, these guys are really

645
00:21:37,760 --> 00:21:41,280
proving out machine learning models that

646
00:21:39,360 --> 00:21:43,200
are based on distributed compute.

647
00:21:41,280 --> 00:21:44,720
There's federated models. I think the

648
00:21:43,200 --> 00:21:47,280
point we're going to make here is that

649
00:21:44,720 --> 00:21:48,960
this is all about this portfolio hybrid

650
00:21:47,280 --> 00:21:50,480
approach, right? So there are certain

651
00:21:48,960 --> 00:21:52,480
things that obviously are just going to

652
00:21:50,480 --> 00:21:54,400
have to be done in a highly concentrated

653
00:21:52,480 --> 00:21:56,240
hyperscaler environment, but there's so

654
00:21:54,400 --> 00:21:58,000
many other aspects to the model. There's

655
00:21:56,240 --> 00:21:59,760
so many aspects to the implementation

656
00:21:58,000 --> 00:22:01,039
and execution of that model that we

657
00:21:59,760 --> 00:22:03,120
think can just reside in different

658
00:22:01,039 --> 00:22:04,960
environments. And so this composability,

659
00:22:03,120 --> 00:22:06,400
this portfolio approach is the way we're

660
00:22:04,960 --> 00:22:07,840
going to approach that. The other thing,

661
00:22:06,400 --> 00:22:09,280
of course, is like there's a lot of

662
00:22:07,840 --> 00:22:10,960
people looking at, okay, how do we just

663
00:22:09,280 --> 00:22:12,480
break the paradigm? Right now, Nvidia

664
00:22:10,960 --> 00:22:14,000
has a lock on it, not just because its

665
00:22:12,480 --> 00:22:16,880
chips are so good, but we're all using

666
00:22:14,000 --> 00:22:19,600
the same, you know, software uh you

667
00:22:16,880 --> 00:22:21,120
know, algorithms to run those chips.

668
00:22:19,600 --> 00:22:22,880
People looking at completely different

669
00:22:21,120 --> 00:22:24,720
mechanisms for how you would actually,

670
00:22:22,880 --> 00:22:27,039
you know, run that compute across

671
00:22:24,720 --> 00:22:28,880
different much more decentralized uh

672
00:22:27,039 --> 00:22:30,159
chip arrangements is is really what what

673
00:22:28,880 --> 00:22:31,919
this is also going to be about. There's

674
00:22:30,159 --> 00:22:33,760
a lot of innovation happening around how

675
00:22:31,919 --> 00:22:35,360
do you break the I mean, the incentives

676
00:22:33,760 --> 00:22:37,520
for anybody to build an alternative to

677
00:22:35,360 --> 00:22:39,280
Nvidia are huge, right? That's a what is

678
00:22:37,520 --> 00:22:41,120
it $3 trillion market cap that you can

679
00:22:39,280 --> 00:22:42,880
go up. It's a big bounty. So there's a

680
00:22:41,120 --> 00:22:44,320
lot of people working on how do you how

681
00:22:42,880 --> 00:22:46,080
you break that down. But I still as I

682
00:22:44,320 --> 00:22:47,600
said I think that it's really a hybrid

683
00:22:46,080 --> 00:22:49,520
approach that we're looking at here.

684
00:22:47,600 --> 00:22:51,039
>> Yeah, that's why Equity Labs one of you

685
00:22:49,520 --> 00:22:52,720
know members in our community is

686
00:22:51,039 --> 00:22:54,799
building on the latest Nvidia chips

687
00:22:52,720 --> 00:22:56,799
where no one else is doing that provable

688
00:22:54,799 --> 00:22:58,080
compliance. So very soon regulators

689
00:22:56,799 --> 00:22:59,919
especially I think it's going to start

690
00:22:58,080 --> 00:23:02,960
in Europe. They're going to ask for that

691
00:22:59,919 --> 00:23:04,400
and they're going to be able to show it.

692
00:23:02,960 --> 00:23:06,080
>> Good questions too. Yeah.

693
00:23:04,400 --> 00:23:09,799
>> Okay. Let's uh hear it from Michael and

694
00:23:06,080 --> 00:23:09,799
Trisha. Thank you.


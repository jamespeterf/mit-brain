1
00:00:11,920 --> 00:00:16,960
Today I'll be talking about uh immersive

2
00:00:14,080 --> 00:00:19,920
real-time 3D ultrasound visualization in

3
00:00:16,960 --> 00:00:21,199
augmented reality. Um so I'm in the

4
00:00:19,920 --> 00:00:23,600
media lab in a group called the

5
00:00:21,199 --> 00:00:26,960
conformal decoders. We make kind of

6
00:00:23,600 --> 00:00:29,439
ultrasound uh devices uh both for

7
00:00:26,960 --> 00:00:31,039
sensing and transduction. So we do

8
00:00:29,439 --> 00:00:34,160
things like imaging and neurom

9
00:00:31,039 --> 00:00:38,440
modulation and drug delivery.

10
00:00:34,160 --> 00:00:38,440
Um but to start off

11
00:00:38,719 --> 00:00:44,719
see I'd like to back up and kind of give

12
00:00:41,120 --> 00:00:46,320
a picture of a vision um which is you

13
00:00:44,719 --> 00:00:49,039
know superheroes. We've all seen these

14
00:00:46,320 --> 00:00:52,079
comics. We know that Superman has X-ray

15
00:00:49,039 --> 00:00:54,960
vision um meaning that he can see you

16
00:00:52,079 --> 00:00:57,280
know kind of the bones of people. So, he

17
00:00:54,960 --> 00:00:59,520
uses this power not that often, but

18
00:00:57,280 --> 00:01:01,440
maybe to see bad guys through walls.

19
00:00:59,520 --> 00:01:04,559
Doesn't really make sense cuz you really

20
00:01:01,440 --> 00:01:05,680
need kind of a a sensor on the other

21
00:01:04,559 --> 00:01:08,240
side. It's kind of more of a

22
00:01:05,680 --> 00:01:12,159
transmission imaging. Um, but it's a

23
00:01:08,240 --> 00:01:14,560
cool vision. Um, in real life, what this

24
00:01:12,159 --> 00:01:17,280
kind of looks like is, you know, we have

25
00:01:14,560 --> 00:01:18,880
in many military applications low light

26
00:01:17,280 --> 00:01:22,240
or infrared cameras where you can see

27
00:01:18,880 --> 00:01:25,280
body heat um in darkness. Um there's

28
00:01:22,240 --> 00:01:27,439
also airport scanners u millimeter wave

29
00:01:25,280 --> 00:01:30,320
scanners that you know cycle around your

30
00:01:27,439 --> 00:01:32,400
body and give um a view of your tissue.

31
00:01:30,320 --> 00:01:37,640
It passes through clothes um and can

32
00:01:32,400 --> 00:01:37,640
show objects like weapons on your body.

33
00:01:37,759 --> 00:01:42,799
There's also

34
00:01:40,479 --> 00:01:45,520
Oh, come in. There's a little bit of a

35
00:01:42,799 --> 00:01:48,000
lag. Sorry. Um there's also X-ray

36
00:01:45,520 --> 00:01:49,920
transmission through through trucks. So,

37
00:01:48,000 --> 00:01:52,159
you know, often they scan trucks passing

38
00:01:49,920 --> 00:01:54,799
through the border to look for drugs and

39
00:01:52,159 --> 00:01:57,600
other uh contraband. Um, but that also

40
00:01:54,799 --> 00:01:59,920
creates an image um from one side of the

41
00:01:57,600 --> 00:02:02,079
truck to the other.

42
00:01:59,920 --> 00:02:03,759
Uh, what I was really more interested in

43
00:02:02,079 --> 00:02:07,119
actually is I saw a different comic

44
00:02:03,759 --> 00:02:09,520
where Superman is is using um his X-ray

45
00:02:07,119 --> 00:02:11,280
vision for health to to look inside

46
00:02:09,520 --> 00:02:13,360
people's bodies and to examine the

47
00:02:11,280 --> 00:02:16,720
health of people's lungs. So this was in

48
00:02:13,360 --> 00:02:19,920
1979 the health education con council in

49
00:02:16,720 --> 00:02:22,480
in DC comics. Um but this is really more

50
00:02:19,920 --> 00:02:26,319
of a cool vision for you know how this

51
00:02:22,480 --> 00:02:28,160
superpower can be used. Um so we ask

52
00:02:26,319 --> 00:02:30,800
ourselves you know in the medical

53
00:02:28,160 --> 00:02:34,000
imaging modalities like what can we do

54
00:02:30,800 --> 00:02:37,040
to look inside the human body? Um MRI is

55
00:02:34,000 --> 00:02:40,720
a common form. It's nonionizing safe.

56
00:02:37,040 --> 00:02:42,959
There's 150 million scans a year. Um,

57
00:02:40,720 --> 00:02:44,879
and an image kind of looks like this

58
00:02:42,959 --> 00:02:48,160
where you get soft tissue contrast. You

59
00:02:44,879 --> 00:02:50,080
can see the bone uh brain.

60
00:02:48,160 --> 00:02:52,879
There's also X-ray, which is far more

61
00:02:50,080 --> 00:02:54,080
common, 3.6 billion scans a year. Um,

62
00:02:52,879 --> 00:02:56,720
however, you don't really get soft

63
00:02:54,080 --> 00:02:59,920
tissue contrast, and you can kind of see

64
00:02:56,720 --> 00:03:02,879
uh bones very well, though. Um so um

65
00:02:59,920 --> 00:03:04,959
however X-rays are ionizing meaning you

66
00:03:02,879 --> 00:03:07,280
can only get a certain number of X-rays

67
00:03:04,959 --> 00:03:09,599
every year um before you have a

68
00:03:07,280 --> 00:03:11,519
potential developing tumors and genetic

69
00:03:09,599 --> 00:03:14,000
mutation.

70
00:03:11,519 --> 00:03:16,159
Um and then there's ultrasound uh which

71
00:03:14,000 --> 00:03:19,280
is often used in fetal imaging where you

72
00:03:16,159 --> 00:03:22,720
see images of babies uh in in their

73
00:03:19,280 --> 00:03:24,879
mother's um wombs. Um but it's also used

74
00:03:22,720 --> 00:03:28,800
in cardiac imaging um and it's

75
00:03:24,879 --> 00:03:30,799
nonionizing portable um and 180 million

76
00:03:28,800 --> 00:03:33,440
scans per year. So quite uh largely

77
00:03:30,799 --> 00:03:35,599
deployed in volume. Um but if we look at

78
00:03:33,440 --> 00:03:37,440
all these technologies on a scale of

79
00:03:35,599 --> 00:03:39,680
kind of safety and portability and look

80
00:03:37,440 --> 00:03:42,640
at what is the state-of-the-art

81
00:03:39,680 --> 00:03:45,040
um here we see an X-ray system. So kind

82
00:03:42,640 --> 00:03:49,760
of low on safety because it's radiative

83
00:03:45,040 --> 00:03:52,480
but you know somewhat handheld. Um,

84
00:03:49,760 --> 00:03:53,920
and there's also portable MRI now. So,

85
00:03:52,480 --> 00:03:56,400
you know, they can wheel this around

86
00:03:53,920 --> 00:03:59,040
into the patient room and fit it around

87
00:03:56,400 --> 00:04:01,280
their head. Um, but it's it's very safe,

88
00:03:59,040 --> 00:04:03,920
but it's still kind of cart bearing.

89
00:04:01,280 --> 00:04:06,319
Needs to uh connect to a wall in a DC

90
00:04:03,920 --> 00:04:08,480
power supply. Um, and then there's

91
00:04:06,319 --> 00:04:10,480
ultrasound. So, a butterfly handheld

92
00:04:08,480 --> 00:04:12,959
probe is very common now. It can connect

93
00:04:10,480 --> 00:04:15,680
to the iPhone and stream real time

94
00:04:12,959 --> 00:04:17,680
images directly there. Um, and they're

95
00:04:15,680 --> 00:04:20,639
very cheap. they've become commercially

96
00:04:17,680 --> 00:04:22,720
mass-produced and it's about $100 a

97
00:04:20,639 --> 00:04:25,600
scan. So, in terms of safety and

98
00:04:22,720 --> 00:04:27,440
portability, um you know, ultrasound is

99
00:04:25,600 --> 00:04:30,080
really a great modality for

100
00:04:27,440 --> 00:04:32,880
accomplishing this vision of of having

101
00:04:30,080 --> 00:04:36,680
electronics that are um native and

102
00:04:32,880 --> 00:04:36,680
wearable by the user.

103
00:04:36,880 --> 00:04:42,720
So, if we also look at um kind of the

104
00:04:40,160 --> 00:04:44,400
pipeline of of imaging today, you know,

105
00:04:42,720 --> 00:04:48,080
it starts with the physician. The

106
00:04:44,400 --> 00:04:50,639
physician orders a radiologist uh to

107
00:04:48,080 --> 00:04:52,320
prepare you know a a scan and the

108
00:04:50,639 --> 00:04:55,040
radiologist contacts an imaging

109
00:04:52,320 --> 00:04:57,840
technician to perform the scan in

110
00:04:55,040 --> 00:05:00,560
ultrasound case a synographer

111
00:04:57,840 --> 00:05:01,759
um the technician scans the patient

112
00:05:00,560 --> 00:05:03,759
delivers the report back to the

113
00:05:01,759 --> 00:05:05,919
radiologist and that passes back to the

114
00:05:03,759 --> 00:05:08,720
physician. So it passes through many

115
00:05:05,919 --> 00:05:10,960
hands um just to often get a single view

116
00:05:08,720 --> 00:05:14,000
of you know what's going on inside the

117
00:05:10,960 --> 00:05:15,680
body. Physicians are also allowed to,

118
00:05:14,000 --> 00:05:17,440
you know, do live examinations where

119
00:05:15,680 --> 00:05:20,479
they can just use the probe directly on

120
00:05:17,440 --> 00:05:23,520
the patient because it's safe and get a

121
00:05:20,479 --> 00:05:25,199
feedback for surgical planning um or to

122
00:05:23,520 --> 00:05:29,039
determine something about the patient.

123
00:05:25,199 --> 00:05:31,039
So, uh there is a very long process, but

124
00:05:29,039 --> 00:05:32,880
there's no reason why the physician

125
00:05:31,039 --> 00:05:35,280
can't um examine the patient directly

126
00:05:32,880 --> 00:05:38,240
and gain more information.

127
00:05:35,280 --> 00:05:40,560
Um if we look at how this affects things

128
00:05:38,240 --> 00:05:42,880
um we can see that you know 51% of

129
00:05:40,560 --> 00:05:45,199
medical trainees report no formal

130
00:05:42,880 --> 00:05:47,919
ultrasound training at their institution

131
00:05:45,199 --> 00:05:51,600
and after they get trained they begin to

132
00:05:47,919 --> 00:05:55,759
use ultrasound way more so around 64%.

133
00:05:51,600 --> 00:05:58,639
Um and in uh synographer

134
00:05:55,759 --> 00:06:00,880
went too far ahead uh in synographer

135
00:05:58,639 --> 00:06:03,360
reviewed reports uh they found that

136
00:06:00,880 --> 00:06:06,479
around 18% of the errors were due to

137
00:06:03,360 --> 00:06:08,160
underreading or misfindings um 11% due

138
00:06:06,479 --> 00:06:11,520
to lack of knowledge. So there there is

139
00:06:08,160 --> 00:06:15,639
quite a gap in the training and use um

140
00:06:11,520 --> 00:06:15,639
even among trained physicians.

141
00:06:16,000 --> 00:06:20,720
Um and finally um ultrasound isn't used

142
00:06:18,400 --> 00:06:24,400
to diagnose too many diseases but in

143
00:06:20,720 --> 00:06:26,800
some liver diseases uh carcinomomas um

144
00:06:24,400 --> 00:06:29,919
you know suboptimal liver ultrasound had

145
00:06:26,800 --> 00:06:32,960
a five times higher risk um and a high

146
00:06:29,919 --> 00:06:35,759
false negative rate. So um there are

147
00:06:32,960 --> 00:06:38,759
real consequences to to using ultrasound

148
00:06:35,759 --> 00:06:38,759
incorrectly.

149
00:06:39,600 --> 00:06:44,880
Um but if we kind of just Google

150
00:06:42,080 --> 00:06:48,160
ultrasound user um we can see that you

151
00:06:44,880 --> 00:06:50,160
know every user kind of has is craning

152
00:06:48,160 --> 00:06:52,639
their neck looking at a display and then

153
00:06:50,160 --> 00:06:54,800
operating the ultrasound probe uh to the

154
00:06:52,639 --> 00:06:56,400
side and it's a real pain in the neck

155
00:06:54,800 --> 00:07:01,039
and something kind of we've just

156
00:06:56,400 --> 00:07:04,160
accepted for the past 40 years. Um

157
00:07:01,039 --> 00:07:06,319
so I think you know a better view of of

158
00:07:04,160 --> 00:07:08,319
imaging modalities are that they should

159
00:07:06,319 --> 00:07:11,680
be these immersive interfaces that are

160
00:07:08,319 --> 00:07:13,680
dynamic, intuitive and augmentative. Um

161
00:07:11,680 --> 00:07:16,160
we can see like in Iron Man he's got the

162
00:07:13,680 --> 00:07:19,120
Jarvis display and it's an augmented

163
00:07:16,160 --> 00:07:21,120
view um that you know overlays data

164
00:07:19,120 --> 00:07:23,360
relevant information about about the

165
00:07:21,120 --> 00:07:25,280
real world. So this is the type of

166
00:07:23,360 --> 00:07:28,960
intuitive interface that we want to move

167
00:07:25,280 --> 00:07:30,800
towards. Um and so the question is like

168
00:07:28,960 --> 00:07:33,840
what should not X-ray vision but

169
00:07:30,800 --> 00:07:36,160
ultrasound vision feel like? Um and you

170
00:07:33,840 --> 00:07:38,560
know this is an image that you know

171
00:07:36,160 --> 00:07:41,280
makes sense because underwater

172
00:07:38,560 --> 00:07:43,919
ultrasound waves you know travel um

173
00:07:41,280 --> 00:07:47,120
pretty much unencumbered and so if you

174
00:07:43,919 --> 00:07:48,800
were a sea superhero with ultrasound

175
00:07:47,120 --> 00:07:55,080
vision you would be able to you know

176
00:07:48,800 --> 00:07:55,080
look inside of animals and treat them.

177
00:07:56,560 --> 00:08:04,319
Oh, so uh this leads me to talk about

178
00:08:00,160 --> 00:08:08,400
our work. Let's see. Scroll.

179
00:08:04,319 --> 00:08:10,000
There we go. Okay. Um which is uh the

180
00:08:08,400 --> 00:08:14,560
real-time ultrasound system for

181
00:08:10,000 --> 00:08:16,560
visualizing um 3D ultrasound. Uh so this

182
00:08:14,560 --> 00:08:18,800
is for my team at the conformable

183
00:08:16,560 --> 00:08:21,360
decoders. Um I just want to mention my

184
00:08:18,800 --> 00:08:24,560
co-authors uh Hari, Chennai, Tanisha,

185
00:08:21,360 --> 00:08:27,840
and Bowen. Um um Hari and Bowen are

186
00:08:24,560 --> 00:08:30,840
students at MIT. Um so thank you to

187
00:08:27,840 --> 00:08:30,840
them.

188
00:08:32,080 --> 00:08:36,959
Uh

189
00:08:34,000 --> 00:08:38,560
okay, thank you. Um so yeah, in terms of

190
00:08:36,959 --> 00:08:41,519
previous work, people have definitely

191
00:08:38,560 --> 00:08:44,320
worked on overlaying ultrasound images

192
00:08:41,519 --> 00:08:46,800
on top of real life objects using um

193
00:08:44,320 --> 00:08:48,640
platforms like the hollow lens. Um, but

194
00:08:46,800 --> 00:08:50,720
they often will take a bunch of plain

195
00:08:48,640 --> 00:08:55,640
images and try to reconstruct them into

196
00:08:50,720 --> 00:08:55,640
a 3D overlay that's not dynamic.

197
00:08:58,240 --> 00:09:02,000
Um, there have been other works that,

198
00:09:00,080 --> 00:09:04,880
you know, mix other imaging modalities

199
00:09:02,000 --> 00:09:07,200
like CT scans and kind of use these

200
00:09:04,880 --> 00:09:09,120
sorts of markers to overlay everything

201
00:09:07,200 --> 00:09:12,080
including the ultrasound so that you can

202
00:09:09,120 --> 00:09:14,160
provide cross context. Um, but again,

203
00:09:12,080 --> 00:09:17,160
these are not kind of live images. these

204
00:09:14,160 --> 00:09:17,160
reconstructions.

205
00:09:18,640 --> 00:09:25,040
Um so we worked on a different work um

206
00:09:22,720 --> 00:09:27,279
from a previous grad student Colin. Um

207
00:09:25,040 --> 00:09:29,920
we worked on an a low power 3D

208
00:09:27,279 --> 00:09:33,360
ultrasound imaging system. So this uh

209
00:09:29,920 --> 00:09:36,480
system captures real-time volutric point

210
00:09:33,360 --> 00:09:39,279
clouds with a synthetic aperture sensing

211
00:09:36,480 --> 00:09:42,399
um and has a huge uh field of view 57

212
00:09:39,279 --> 00:09:46,080
degrees and can um image objects up to

213
00:09:42,399 --> 00:09:49,440
11 cm deep. Um because of this image

214
00:09:46,080 --> 00:09:51,680
capture scheme, we can essentially use a

215
00:09:49,440 --> 00:09:55,920
GPU and reduce the data rates and

216
00:09:51,680 --> 00:09:59,440
perform all the 3D uh beam forming um at

217
00:09:55,920 --> 00:10:01,920
two frames per second. Um, so here's a

218
00:09:59,440 --> 00:10:04,000
picture of the system um with

219
00:10:01,920 --> 00:10:09,440
customdesigned electronics. You can see

220
00:10:04,000 --> 00:10:11,680
the transducer at the end. Um, oops. And

221
00:10:09,440 --> 00:10:15,200
essentially we we have this stack that

222
00:10:11,680 --> 00:10:17,680
allows us to produce uh 3D point clouds.

223
00:10:15,200 --> 00:10:20,000
So you can see in this box um these are

224
00:10:17,680 --> 00:10:22,000
different metal objects like springs.

225
00:10:20,000 --> 00:10:25,120
Um, and this is kind of the live image

226
00:10:22,000 --> 00:10:27,440
as it changes. So instead of a 2D fan,

227
00:10:25,120 --> 00:10:31,079
we're producing kind of a box that

228
00:10:27,440 --> 00:10:31,079
represents the volume.

229
00:10:31,600 --> 00:10:36,880
Um, and so the question is now that we

230
00:10:34,079 --> 00:10:39,120
have this system built, how can we port

231
00:10:36,880 --> 00:10:41,360
this into the VR space and how can we

232
00:10:39,120 --> 00:10:43,360
overlay this on top of real life view

233
00:10:41,360 --> 00:10:47,680
and do this in a way where, you know,

234
00:10:43,360 --> 00:10:50,480
there's minimal uh latency. Um so to do

235
00:10:47,680 --> 00:10:53,360
to basically compress a million points

236
00:10:50,480 --> 00:10:55,760
um and stream them across the wire we

237
00:10:53,360 --> 00:10:59,519
had to come up with some special packets

238
00:10:55,760 --> 00:11:01,680
and data frames um to utilize UDP

239
00:10:59,519 --> 00:11:04,480
streaming um to the fullest extent. So

240
00:11:01,680 --> 00:11:07,600
the UDP is a real time asynchronous

241
00:11:04,480 --> 00:11:10,480
system. Um so as soon as you know we

242
00:11:07,600 --> 00:11:12,959
have our beam formed images ready to go,

243
00:11:10,480 --> 00:11:15,920
they're streamed into the gamer engine

244
00:11:12,959 --> 00:11:18,240
and um there's two point clouds that are

245
00:11:15,920 --> 00:11:20,959
overlaid. Uh one point cloud that is

246
00:11:18,240 --> 00:11:23,040
kind of hand manipulatable and another

247
00:11:20,959 --> 00:11:26,040
point cloud that is localized to the

248
00:11:23,040 --> 00:11:26,040
object.

249
00:11:30,560 --> 00:11:35,920
Okay, so this is uh we start with the

250
00:11:33,200 --> 00:11:38,399
the Vario headset. So the Vario XR4 has

251
00:11:35,920 --> 00:11:41,920
been a new release in 2024 and it's been

252
00:11:38,399 --> 00:11:44,959
absolutely awesome. Um very high pixel

253
00:11:41,920 --> 00:11:47,440
uh resolution um and it's much faster.

254
00:11:44,959 --> 00:11:50,160
So we can do things like object tracking

255
00:11:47,440 --> 00:11:53,040
or we can manipulate kind of a plane and

256
00:11:50,160 --> 00:11:56,480
brush it through the 3D point cloud and

257
00:11:53,040 --> 00:11:58,079
kind of see the 2D slices. Um, there's

258
00:11:56,480 --> 00:12:00,320
also built-in eye tracking and

259
00:11:58,079 --> 00:12:02,880
pupilometry, so we can see where the

260
00:12:00,320 --> 00:12:04,959
user is looking. Um, and with all of

261
00:12:02,880 --> 00:12:07,360
this, we can kind of map objects in the

262
00:12:04,959 --> 00:12:09,680
scene, hands, interactions, what the

263
00:12:07,360 --> 00:12:11,920
user is looking at. Um, and so in a

264
00:12:09,680 --> 00:12:14,800
future vision, uh, we want to move

265
00:12:11,920 --> 00:12:17,279
towards kind of a context where aware

266
00:12:14,800 --> 00:12:20,000
assistant um that helps with alignment

267
00:12:17,279 --> 00:12:22,079
or continuous image refinement or even

268
00:12:20,000 --> 00:12:26,720
semantic segmentation.

269
00:12:22,079 --> 00:12:29,519
So uh essentially this is the system. Um

270
00:12:26,720 --> 00:12:32,720
so we're imaging kind of a a phantom

271
00:12:29,519 --> 00:12:34,720
which is a gelatin molded object with a

272
00:12:32,720 --> 00:12:38,079
spring inside. So you can see kind of

273
00:12:34,720 --> 00:12:40,560
the spring and the point cloud overlay

274
00:12:38,079 --> 00:12:42,800
and you know they match up pretty well.

275
00:12:40,560 --> 00:12:48,079
Um

276
00:12:42,800 --> 00:12:52,160
and this system you know also does uh 4D

277
00:12:48,079 --> 00:12:54,399
capture so real time 3D OB uh volutric

278
00:12:52,160 --> 00:12:57,600
capture. So you can see among each of

279
00:12:54,399 --> 00:13:00,160
these time points we're tracking uh this

280
00:12:57,600 --> 00:13:01,600
red small metal ball that's flowing

281
00:13:00,160 --> 00:13:05,519
through a tube. So this is just to show

282
00:13:01,600 --> 00:13:09,040
that um you know it does do these uh

283
00:13:05,519 --> 00:13:11,920
renderings every uh two uh 20

284
00:13:09,040 --> 00:13:14,639
milliseconds.

285
00:13:11,920 --> 00:13:17,360
So again, yeah, this is the interface um

286
00:13:14,639 --> 00:13:20,639
of using the headset. You know, there's

287
00:13:17,360 --> 00:13:24,000
it runs off of a desktop and a laptop.

288
00:13:20,639 --> 00:13:27,639
Um but there's point clouds inside that

289
00:13:24,000 --> 00:13:27,639
that can be manipulated.

290
00:13:29,279 --> 00:13:33,600
Um so essentially we we wanted to

291
00:13:31,760 --> 00:13:35,920
perform a user study to capture the

292
00:13:33,600 --> 00:13:38,720
system in action. Um in order to capture

293
00:13:35,920 --> 00:13:41,519
that we needed to make you know each

294
00:13:38,720 --> 00:13:44,399
pair wise combination. So 2D imaging and

295
00:13:41,519 --> 00:13:46,880
on a screen is the conventional form. Um

296
00:13:44,399 --> 00:13:49,920
but to understand the advantages of 3D

297
00:13:46,880 --> 00:13:52,399
imaging plus AR we also created 2D

298
00:13:49,920 --> 00:13:55,120
imaging and AR and also 3D imaging on

299
00:13:52,399 --> 00:13:57,519
the screen and used these four systems

300
00:13:55,120 --> 00:14:01,600
and brought you know 18 participants

301
00:13:57,519 --> 00:14:04,000
through um a user study um to capture

302
00:14:01,600 --> 00:14:06,959
the effects. Um but before that I guess

303
00:14:04,000 --> 00:14:11,360
we also understood you know how accurate

304
00:14:06,959 --> 00:14:14,079
is this visualization. Um so with the uh

305
00:14:11,360 --> 00:14:17,040
vis visual fiducial marker tracking we

306
00:14:14,079 --> 00:14:21,199
can get you know average errors within 4

307
00:14:17,040 --> 00:14:23,440
millimeters. Um so seems sufficient for

308
00:14:21,199 --> 00:14:26,560
uh certain identification purposes maybe

309
00:14:23,440 --> 00:14:29,040
not um for certain localization things.

310
00:14:26,560 --> 00:14:32,240
Um however

311
00:14:29,040 --> 00:14:34,720
uh when the marker is oluded you can no

312
00:14:32,240 --> 00:14:36,560
longer track the point cloud so then you

313
00:14:34,720 --> 00:14:39,920
know it becomes very costly to lose that

314
00:14:36,560 --> 00:14:43,040
tracking. Uh so instead we started using

315
00:14:39,920 --> 00:14:46,079
the the Vario controller um and

316
00:14:43,040 --> 00:14:48,480
developed a uh a snap fit mechanism for

317
00:14:46,079 --> 00:14:52,079
our transducer to essentially use the

318
00:14:48,480 --> 00:14:54,880
controller as as the tracker um and you

319
00:14:52,079 --> 00:14:57,040
know localize a point cloud to that. Um

320
00:14:54,880 --> 00:15:00,560
and that allows it to be still be

321
00:14:57,040 --> 00:15:02,639
rendered when it's oluded and um it the

322
00:15:00,560 --> 00:15:05,279
also doubles as a handle for our

323
00:15:02,639 --> 00:15:08,000
transducer which um is ergonomically

324
00:15:05,279 --> 00:15:10,720
nice.

325
00:15:08,000 --> 00:15:13,680
Um so we performed this user study uh

326
00:15:10,720 --> 00:15:16,320
where we lead 18 18 um you know

327
00:15:13,680 --> 00:15:18,560
participants nine research experts or

328
00:15:16,320 --> 00:15:20,720
clinical experts and nine noviceses

329
00:15:18,560 --> 00:15:22,880
who've never used ultrasound through two

330
00:15:20,720 --> 00:15:26,160
tasks. Um the first task is object

331
00:15:22,880 --> 00:15:28,079
identification task um where there's you

332
00:15:26,160 --> 00:15:29,920
know these cups you can't see through

333
00:15:28,079 --> 00:15:32,639
them and there's all these metal objects

334
00:15:29,920 --> 00:15:34,560
inside from springs to balls to screws.

335
00:15:32,639 --> 00:15:36,560
Um we use these objects because they

336
00:15:34,560 --> 00:15:39,839
reflect well in ultrasound and you know

337
00:15:36,560 --> 00:15:41,600
are easy to see with our system. Um so

338
00:15:39,839 --> 00:15:43,839
this is what the interface would be

339
00:15:41,600 --> 00:15:47,680
would look like when the users um are

340
00:15:43,839 --> 00:15:50,079
are working with the system.

341
00:15:47,680 --> 00:15:52,079
Uh and this is a short video kind of

342
00:15:50,079 --> 00:15:55,920
just capturing you know what it looks

343
00:15:52,079 --> 00:15:58,160
like to do this task. So as the images

344
00:15:55,920 --> 00:16:00,800
are are loaded this is in three times

345
00:15:58,160 --> 00:16:03,920
speed. Um there's two visualizations, a

346
00:16:00,800 --> 00:16:06,880
large one, um and a small one that's at

347
00:16:03,920 --> 00:16:08,639
real life size. Um so you can see the

348
00:16:06,880 --> 00:16:11,920
screw pretty well. You can see all the

349
00:16:08,639 --> 00:16:13,519
threads in the screw. Um and then

350
00:16:11,920 --> 00:16:16,320
there's, you know, another object. This

351
00:16:13,519 --> 00:16:18,639
is a mesh ball. Um so you can kind of

352
00:16:16,320 --> 00:16:20,639
see kind of the curvature on the ball.

353
00:16:18,639 --> 00:16:22,240
Um the ultrasound tends to just reflect

354
00:16:20,639 --> 00:16:24,320
off the top surface. So that's why

355
00:16:22,240 --> 00:16:28,000
you're not seeing the whole volume of

356
00:16:24,320 --> 00:16:31,120
the ball. But um yeah, so that was task

357
00:16:28,000 --> 00:16:32,880
one um identifying the objects and you

358
00:16:31,120 --> 00:16:35,360
know the results are pretty interesting

359
00:16:32,880 --> 00:16:37,759
in that we see that this is an accuracy

360
00:16:35,360 --> 00:16:41,199
plot versus our systems. We see that the

361
00:16:37,759 --> 00:16:44,160
3D plus MR system participants were able

362
00:16:41,199 --> 00:16:48,079
to perform uh you know most accurate and

363
00:16:44,160 --> 00:16:49,759
with a smaller uh uh variance. Um and

364
00:16:48,079 --> 00:16:52,639
then the other interesting thing is

365
00:16:49,759 --> 00:16:56,480
between experts in orange and noviceses

366
00:16:52,639 --> 00:16:58,240
in in teal um

367
00:16:56,480 --> 00:17:01,120
uh we see that there's you know

368
00:16:58,240 --> 00:17:03,920
comparable per performance um within our

369
00:17:01,120 --> 00:17:06,240
system um between people experts who've

370
00:17:03,920 --> 00:17:08,400
you know used ultrasound many times and

371
00:17:06,240 --> 00:17:10,799
uh noviceses who've seen it for the very

372
00:17:08,400 --> 00:17:13,679
first time. Um so it is an equalizing

373
00:17:10,799 --> 00:17:16,160
force and you know they perform better

374
00:17:13,679 --> 00:17:20,160
on average 17% than the other systems.

375
00:17:16,160 --> 00:17:22,480
So um it kind of shows that maybe the 3D

376
00:17:20,160 --> 00:17:25,360
aspect is also helping with object

377
00:17:22,480 --> 00:17:27,120
identification. Um you can see in that

378
00:17:25,360 --> 00:17:30,160
the other system that performed fairly

379
00:17:27,120 --> 00:17:32,799
well is 3D plus screen. Um so I think

380
00:17:30,160 --> 00:17:34,799
the 3D is giving context as to you know

381
00:17:32,799 --> 00:17:39,280
what the objects are, what their full

382
00:17:34,799 --> 00:17:41,440
shape is and how to mentally map that.

383
00:17:39,280 --> 00:17:43,679
Um something else that we found was very

384
00:17:41,440 --> 00:17:45,840
interesting was a perceived performance

385
00:17:43,679 --> 00:17:49,039
versus accuracy. So we also captured

386
00:17:45,840 --> 00:17:51,520
NASA TLX scores um on all of these tasks

387
00:17:49,039 --> 00:17:54,080
and so we asked users how well they

388
00:17:51,520 --> 00:17:58,840
think they performed. Um but we see that

389
00:17:54,080 --> 00:17:58,840
for the 3D MR system

390
00:17:59,280 --> 00:18:03,679
uh that you know users performed well

391
00:18:01,679 --> 00:18:06,080
and they thought they performed well. So

392
00:18:03,679 --> 00:18:08,080
they performed about as well you know as

393
00:18:06,080 --> 00:18:10,799
as they they thought and with high

394
00:18:08,080 --> 00:18:14,760
confidence um and the variance was much

395
00:18:10,799 --> 00:18:14,760
larger for the other systems.

396
00:18:15,200 --> 00:18:22,880
Um our second task was uh a task where

397
00:18:19,679 --> 00:18:25,520
you know a localization task. So we have

398
00:18:22,880 --> 00:18:27,440
a tissue phantom with a bunch of wire

399
00:18:25,520 --> 00:18:29,600
targets in them. So that's what they

400
00:18:27,440 --> 00:18:32,000
would look like if you know it weren't

401
00:18:29,600 --> 00:18:34,400
oluded on the image on the left. Um so

402
00:18:32,000 --> 00:18:37,600
these targets run through the phantom

403
00:18:34,400 --> 00:18:40,480
and um in ultrasound appear as dots. Um,

404
00:18:37,600 --> 00:18:43,200
so we basically cover that uh

405
00:18:40,480 --> 00:18:45,200
visualization and have the user use the

406
00:18:43,200 --> 00:18:47,440
ultrasound scanning systems and mark

407
00:18:45,200 --> 00:18:49,840
where they think the dots are um to

408
00:18:47,440 --> 00:18:53,280
scale.

409
00:18:49,840 --> 00:18:57,400
Um, so that's an image of of Hari using

410
00:18:53,280 --> 00:18:57,400
the 3D system.

411
00:18:57,600 --> 00:19:01,919
Um, and what this looks like in

412
00:18:59,360 --> 00:19:04,720
practice, who

413
00:19:01,919 --> 00:19:06,480
is, uh, the user is given kind of a a

414
00:19:04,720 --> 00:19:08,880
marker on the left hand to kind of

415
00:19:06,480 --> 00:19:11,200
pinpoint virtual objects to real life

416
00:19:08,880 --> 00:19:14,080
objects and then the visualization is

417
00:19:11,200 --> 00:19:17,840
shown, um, and they use a pen to mark

418
00:19:14,080 --> 00:19:20,720
where they think the points are. Um so

419
00:19:17,840 --> 00:19:24,160
the task looks fairly easy um with the

420
00:19:20,720 --> 00:19:26,640
the 3D system um because you know the

421
00:19:24,160 --> 00:19:28,400
user is able to see both objects and

422
00:19:26,640 --> 00:19:30,880
just mark where they see think the

423
00:19:28,400 --> 00:19:33,280
bright spots are. Um so there is some

424
00:19:30,880 --> 00:19:36,000
weird parallax effects that some users

425
00:19:33,280 --> 00:19:39,280
reported was kind of um uncomfortable

426
00:19:36,000 --> 00:19:41,120
but um by and large they're able to to

427
00:19:39,280 --> 00:19:44,120
understand the points and mark them

428
00:19:41,120 --> 00:19:44,120
accurately.

429
00:19:44,320 --> 00:19:51,760
So the results of this uh were that um

430
00:19:48,320 --> 00:19:53,520
our system as well as the 2D plus MR

431
00:19:51,760 --> 00:19:56,240
system performed very well relative to

432
00:19:53,520 --> 00:20:00,640
the screen systems which had kind of a

433
00:19:56,240 --> 00:20:02,480
larger spread. Um

434
00:20:00,640 --> 00:20:04,320
and you know I think this kind of

435
00:20:02,480 --> 00:20:08,160
demonstrates you know with the outliers

436
00:20:04,320 --> 00:20:12,000
even excluded uh that um there is

437
00:20:08,160 --> 00:20:14,720
significance with the um MR systems and

438
00:20:12,000 --> 00:20:17,440
that users no longer have to create a

439
00:20:14,720 --> 00:20:21,679
mental map that is you know basically

440
00:20:17,440 --> 00:20:24,000
reference to an exact scale dimension um

441
00:20:21,679 --> 00:20:25,760
and instead they can just if they trust

442
00:20:24,000 --> 00:20:28,720
the system they can just mark what they

443
00:20:25,760 --> 00:20:31,679
see. Um so it's a difference in kind of

444
00:20:28,720 --> 00:20:33,919
a mental framework too um where the

445
00:20:31,679 --> 00:20:37,360
users are no longer relying on a mental

446
00:20:33,919 --> 00:20:40,799
map but um which may be bad in some

447
00:20:37,360 --> 00:20:42,720
contexts um but if the overlay is

448
00:20:40,799 --> 00:20:45,679
accurate um you know they really are

449
00:20:42,720 --> 00:20:47,919
able to perform better

450
00:20:45,679 --> 00:20:51,600
and I guess we also saw similar levels

451
00:20:47,919 --> 00:20:54,720
of uh performance

452
00:20:51,600 --> 00:20:57,280
um with noviceses and experts. Um so

453
00:20:54,720 --> 00:20:59,919
this slide is showing efficiency also.

454
00:20:57,280 --> 00:21:01,360
So this uh represents the number of

455
00:20:59,919 --> 00:21:03,200
points that were marked and the amount

456
00:21:01,360 --> 00:21:05,360
of time that they used to complete the

457
00:21:03,200 --> 00:21:09,120
task and kind of the average distance

458
00:21:05,360 --> 00:21:11,280
away from the the true target. So you

459
00:21:09,120 --> 00:21:14,960
kind of see that again with the 3D and

460
00:21:11,280 --> 00:21:17,200
MR system um the average distance is low

461
00:21:14,960 --> 00:21:18,960
which is good. It means it's accurate.

462
00:21:17,200 --> 00:21:22,640
um there's a larger spread in

463
00:21:18,960 --> 00:21:26,480
efficiency, but um users of this system

464
00:21:22,640 --> 00:21:29,280
kind of reach the max um rates of points

465
00:21:26,480 --> 00:21:31,120
per time. So they're able to both

466
00:21:29,280 --> 00:21:33,039
identify points very quickly and mark

467
00:21:31,120 --> 00:21:37,120
them accurately relative to the other

468
00:21:33,039 --> 00:21:42,600
systems. Um we see also good uh you know

469
00:21:37,120 --> 00:21:42,600
performance in 2D um plus MR.

470
00:21:43,679 --> 00:21:48,400
So let's see.

471
00:21:46,320 --> 00:21:50,640
Um so yeah, that that was kind of the

472
00:21:48,400 --> 00:21:52,559
end of the study. Um these are results

473
00:21:50,640 --> 00:21:57,039
are still to be published. But I guess

474
00:21:52,559 --> 00:22:00,000
looking forward um what we really used

475
00:21:57,039 --> 00:22:02,240
to do was to create kind of this image

476
00:22:00,000 --> 00:22:04,400
processing pipeline that feeds things

477
00:22:02,240 --> 00:22:05,919
directly into the AR environment.

478
00:22:04,400 --> 00:22:08,400
However, we weren't really able to

479
00:22:05,919 --> 00:22:10,480
capture other aspects like user states

480
00:22:08,400 --> 00:22:13,600
and real-time inputs from the other

481
00:22:10,480 --> 00:22:17,120
aspects of the system. Um, however, we

482
00:22:13,600 --> 00:22:19,360
can feed all of these things through uh

483
00:22:17,120 --> 00:22:22,480
potentially to give context to an AI

484
00:22:19,360 --> 00:22:25,039
assistant to assess Gab's focus to help

485
00:22:22,480 --> 00:22:27,600
uh 3D semantic segmentation and

486
00:22:25,039 --> 00:22:30,000
eventually to create assets and generate

487
00:22:27,600 --> 00:22:32,720
um guidance markers or view synthesized

488
00:22:30,000 --> 00:22:35,360
views um and feed them back into the AR

489
00:22:32,720 --> 00:22:38,240
environment um so that instead

490
00:22:35,360 --> 00:22:41,520
potentially one day instead of this loop

491
00:22:38,240 --> 00:22:43,200
we can have um a separate

492
00:22:41,520 --> 00:22:45,440
intervention where a medical assistant

493
00:22:43,200 --> 00:22:48,480
can kind of bridge the patient and the

494
00:22:45,440 --> 00:22:50,240
physician um or even patients can

495
00:22:48,480 --> 00:22:53,760
perform these um interventions on

496
00:22:50,240 --> 00:22:55,919
themselves and scan at home.

497
00:22:53,760 --> 00:22:57,679
Um so with that that's that's all I

498
00:22:55,919 --> 00:22:59,760
have. Thank you so much for listening. I

499
00:22:57,679 --> 00:23:02,480
just like to give a quick thank you to

500
00:22:59,760 --> 00:23:04,880
um MIT Nano um the Center for

501
00:23:02,480 --> 00:23:09,120
Translational and Clinical Research and

502
00:23:04,880 --> 00:23:11,200
um the MIT Heels Collaborative. Thanks.

503
00:23:09,120 --> 00:23:13,679
>> Thank you so much Jason. Uh really

504
00:23:11,200 --> 00:23:15,679
awesome stuff everybody. If you do have

505
00:23:13,679 --> 00:23:17,760
questions um feel free to put them in

506
00:23:15,679 --> 00:23:20,159
chat and because we have two speakers

507
00:23:17,760 --> 00:23:22,720
today we'll try to get to them uh at the

508
00:23:20,159 --> 00:23:26,159
end. So for the interest of time I'm now

509
00:23:22,720 --> 00:23:28,400
going to introduce April. So thank you.

510
00:23:26,159 --> 00:23:30,320
>> Hi there. My name is April. I am a PhD

511
00:23:28,400 --> 00:23:32,559
candidate in mechanical engineering uh

512
00:23:30,320 --> 00:23:34,720
here at MIT. Uh I'm going to talk today

513
00:23:32,559 --> 00:23:37,360
about a sort of different use of AR for

514
00:23:34,720 --> 00:23:38,640
volume ultrasound. Um this is a I want

515
00:23:37,360 --> 00:23:40,640
to say up front this is an ongoing

516
00:23:38,640 --> 00:23:42,960
project and so we are um still in

517
00:23:40,640 --> 00:23:45,840
development and excited about uh what's

518
00:23:42,960 --> 00:23:48,640
to come. So again to start off very uh

519
00:23:45,840 --> 00:23:50,000
broadly uh as Jason had mentioned uh

520
00:23:48,640 --> 00:23:52,159
ultrasound is a pretty unique medical

521
00:23:50,000 --> 00:23:54,640
imaging modality and it has some major

522
00:23:52,159 --> 00:23:58,240
advantages over other modalities such as

523
00:23:54,640 --> 00:24:00,400
X-ray CT or MRI. Um to name a few it's

524
00:23:58,240 --> 00:24:02,320
tends to be lower cost. Um, you can also

525
00:24:00,400 --> 00:24:04,720
look at real-time images. Uh, and so

526
00:24:02,320 --> 00:24:06,960
imaging can, at least in theory, be a

527
00:24:04,720 --> 00:24:08,559
faster process. Um, it's also safe

528
00:24:06,960 --> 00:24:11,200
because there's no ionizing radiation

529
00:24:08,559 --> 00:24:13,600
like with CT or X-ray. Um, and then it's

530
00:24:11,200 --> 00:24:15,760
portable, so it can be used at the

531
00:24:13,600 --> 00:24:18,080
patient's bedside, uh, which is a major

532
00:24:15,760 --> 00:24:21,279
advantage over um, having to travel to a

533
00:24:18,080 --> 00:24:23,600
CT or an MRI scanner. Um, that being

534
00:24:21,279 --> 00:24:27,520
said, there are some things that limit

535
00:24:23,600 --> 00:24:29,919
ultrasound. Um to name just a few again

536
00:24:27,520 --> 00:24:31,360
uh one is the need for trained users. Um

537
00:24:29,919 --> 00:24:34,080
so synenographers are the medical

538
00:24:31,360 --> 00:24:37,279
professionals who uh train in depth on

539
00:24:34,080 --> 00:24:39,120
ultrasound. Um but again as was

540
00:24:37,279 --> 00:24:43,520
previously said a lot of other

541
00:24:39,120 --> 00:24:46,000
clinicians so um nurses assistants MDs

542
00:24:43,520 --> 00:24:48,480
uh etc don't have significant training

543
00:24:46,000 --> 00:24:52,480
in ultrasound. Um and they have to go

544
00:24:48,480 --> 00:24:54,880
through this this uh loop of uh ordering

545
00:24:52,480 --> 00:24:56,559
an ultrasound exam. uh the synographer

546
00:24:54,880 --> 00:24:58,400
comes and takes the images, those go to

547
00:24:56,559 --> 00:25:00,080
a radiologist who interprets them and

548
00:24:58,400 --> 00:25:02,320
then communicates the information back

549
00:25:00,080 --> 00:25:04,640
to the original clinician. Um and so

550
00:25:02,320 --> 00:25:06,720
that really takes away from some of the

551
00:25:04,640 --> 00:25:10,240
uh potential advantages of ultrasound,

552
00:25:06,720 --> 00:25:13,039
namely it being fast and uh convenient.

553
00:25:10,240 --> 00:25:14,720
Um that doesn't really happen in in real

554
00:25:13,039 --> 00:25:18,480
life uh if it has to go through this

555
00:25:14,720 --> 00:25:21,440
sort of uh uh complicated loop.

556
00:25:18,480 --> 00:25:24,559
Um, additionally, um, if you compare

557
00:25:21,440 --> 00:25:26,000
ultrasound to CT and MRI, CT and MRI,

558
00:25:24,559 --> 00:25:28,080
you've maybe seen the images of

559
00:25:26,000 --> 00:25:30,159
scrolling through in three dimensions

560
00:25:28,080 --> 00:25:31,679
because you've got this volutric image,

561
00:25:30,159 --> 00:25:33,520
there's a lot of anatomical context

562
00:25:31,679 --> 00:25:35,760
that's preserved. So, you can see not

563
00:25:33,520 --> 00:25:37,520
only an imaging target, a particular

564
00:25:35,760 --> 00:25:40,159
organ, but also what's going on around

565
00:25:37,520 --> 00:25:42,799
it. Um, this is an example ultrasound

566
00:25:40,159 --> 00:25:44,240
image here on the far right. Uh, it's

567
00:25:42,799 --> 00:25:46,640
got the tip of the liver and then a

568
00:25:44,240 --> 00:25:48,080
little bit of kidney under it. But I've

569
00:25:46,640 --> 00:25:49,600
done a lot of kidney ultrasounds and I

570
00:25:48,080 --> 00:25:50,960
can tell you this particular image could

571
00:25:49,600 --> 00:25:54,240
be captured from a lot of different

572
00:25:50,960 --> 00:25:57,600
angles. Um, and from this single 2D

573
00:25:54,240 --> 00:25:59,120
image, it's not really clear um what is

574
00:25:57,600 --> 00:26:01,440
surrounding this image, like what is the

575
00:25:59,120 --> 00:26:04,159
anatomical context. Um, but this

576
00:26:01,440 --> 00:26:06,000
honestly is the the type of image that a

577
00:26:04,159 --> 00:26:08,400
radiologist would get to interpret. It's

578
00:26:06,000 --> 00:26:11,600
just a single 2D image maybe that has

579
00:26:08,400 --> 00:26:14,559
some labels or uh measurements on it. Um

580
00:26:11,600 --> 00:26:16,799
these uh limitations kind of combine to

581
00:26:14,559 --> 00:26:18,960
ultimately produce uh poor repeatability

582
00:26:16,799 --> 00:26:22,480
and reproducibility in ultrasound that

583
00:26:18,960 --> 00:26:24,320
really limits the uh potential impact

584
00:26:22,480 --> 00:26:27,679
and the potential use of ultrasound in

585
00:26:24,320 --> 00:26:29,919
the medical imaging space.

586
00:26:27,679 --> 00:26:32,880
Um so we like to talk about volume

587
00:26:29,919 --> 00:26:35,120
ultrasound as one potential um sort of

588
00:26:32,880 --> 00:26:36,880
answer to some of these challenges. uh

589
00:26:35,120 --> 00:26:38,400
to quickly go through some of the

590
00:26:36,880 --> 00:26:40,799
specific applications of volume

591
00:26:38,400 --> 00:26:43,840
ultrasound. Um I've got a few examples

592
00:26:40,799 --> 00:26:45,039
here. One uh really simply is to

593
00:26:43,840 --> 00:26:46,960
actually just improve volume

594
00:26:45,039 --> 00:26:48,960
measurements. Um so in certain

595
00:26:46,960 --> 00:26:51,279
applications, volume itself is an

596
00:26:48,960 --> 00:26:55,039
important biomarker. Uh the graph on the

597
00:26:51,279 --> 00:26:57,039
upper right is uh a a diagram of what

598
00:26:55,039 --> 00:26:59,360
happens in a disease known as polycystic

599
00:26:57,039 --> 00:27:01,039
kidney disease. Uh cysts grow in the

600
00:26:59,360 --> 00:27:03,279
kidney and progressively impair the

601
00:27:01,039 --> 00:27:05,039
function of the kidney. Um, if you can

602
00:27:03,279 --> 00:27:06,640
see the blue line at the top, it kind of

603
00:27:05,039 --> 00:27:08,799
stays flat for a long time and then

604
00:27:06,640 --> 00:27:10,880
starts to decrease. That's a measure of

605
00:27:08,799 --> 00:27:12,880
kidney function. Um, and you can see

606
00:27:10,880 --> 00:27:15,360
it's just not very sensitive early on.

607
00:27:12,880 --> 00:27:16,880
Um, and so it doesn't show changes in

608
00:27:15,360 --> 00:27:18,880
kidney function until there's already

609
00:27:16,880 --> 00:27:20,640
been significant damage to the kidney.

610
00:27:18,880 --> 00:27:24,640
This is a lifelong disease that people

611
00:27:20,640 --> 00:27:27,360
deal with over uh many many decades.

612
00:27:24,640 --> 00:27:29,360
Uh, the colorful line, the green to red,

613
00:27:27,360 --> 00:27:31,600
that's kidney size. So that's the total

614
00:27:29,360 --> 00:27:32,960
kidney volume. Um in a lot of studies

615
00:27:31,600 --> 00:27:35,360
that has been shown to be a more

616
00:27:32,960 --> 00:27:37,520
sensitive and earlier biome for uh the

617
00:27:35,360 --> 00:27:39,440
progression of of polycystic kidney

618
00:27:37,520 --> 00:27:41,919
disease. Um and so there's been a

619
00:27:39,440 --> 00:27:43,919
movement to use volume as the standard

620
00:27:41,919 --> 00:27:45,360
uh biome for this disease because

621
00:27:43,919 --> 00:27:48,240
earlier detection means earlier

622
00:27:45,360 --> 00:27:51,200
treatment and um longer lasting

623
00:27:48,240 --> 00:27:53,760
functional kidneys. Um

624
00:27:51,200 --> 00:27:55,600
but uh those that those volume

625
00:27:53,760 --> 00:27:56,960
measurements are typically done via MRI

626
00:27:55,600 --> 00:27:58,559
which again doesn't have the same

627
00:27:56,960 --> 00:28:01,840
advantages as ultrasound. It can't

628
00:27:58,559 --> 00:28:04,480
usually be done in um in a or at the

629
00:28:01,840 --> 00:28:06,080
bedside or at a clinical uh like

630
00:28:04,480 --> 00:28:08,480
doctor's office setting. You have to go

631
00:28:06,080 --> 00:28:11,279
to a special facility to get those um

632
00:28:08,480 --> 00:28:12,880
scans. So using volume ultrasound, you

633
00:28:11,279 --> 00:28:14,640
can get more accurate volume or you can

634
00:28:12,880 --> 00:28:17,440
get more accurate volume measurements of

635
00:28:14,640 --> 00:28:19,760
targets like kidney um which is useful

636
00:28:17,440 --> 00:28:22,240
for for a variety of diseases. You can

637
00:28:19,760 --> 00:28:24,080
also start to understand how a

638
00:28:22,240 --> 00:28:26,480
particular imaging target such as a

639
00:28:24,080 --> 00:28:28,159
kidney changes over time. Um, so when

640
00:28:26,480 --> 00:28:29,760
you get volume, you can register

641
00:28:28,159 --> 00:28:31,919
multiple volumes to one another and

642
00:28:29,760 --> 00:28:34,799
start to see the way the shapes change.

643
00:28:31,919 --> 00:28:36,240
Um, how uh different measurements might

644
00:28:34,799 --> 00:28:37,360
be changing over time. And that's

645
00:28:36,240 --> 00:28:41,520
something that can only be done with

646
00:28:37,360 --> 00:28:43,840
with volume, not a single 2D image. Um,

647
00:28:41,520 --> 00:28:47,200
those uh

648
00:28:43,840 --> 00:28:49,200
uh those advantages also help uh the

649
00:28:47,200 --> 00:28:50,960
repeatability of ultrasound. So we talk

650
00:28:49,200 --> 00:28:53,919
about operator to operator repeatability

651
00:28:50,960 --> 00:28:56,480
or reproducibility. Um, so if I take one

652
00:28:53,919 --> 00:28:58,640
measurement with uh my ultrasound and

653
00:28:56,480 --> 00:29:00,080
then I hand the device to another person

654
00:28:58,640 --> 00:29:01,520
and that person tries to take the same

655
00:29:00,080 --> 00:29:04,480
measurement, the chances that those

656
00:29:01,520 --> 00:29:08,159
numbers are the same uh is is lower with

657
00:29:04,480 --> 00:29:10,000
ultrasound. Um, but with volume, you can

658
00:29:08,159 --> 00:29:11,440
start to see again the context of what's

659
00:29:10,000 --> 00:29:13,520
happening. You can start to understand

660
00:29:11,440 --> 00:29:15,360
the the whole shape and start to take

661
00:29:13,520 --> 00:29:18,320
measurements at consistent locations

662
00:29:15,360 --> 00:29:20,960
which improves the uh repeatability. And

663
00:29:18,320 --> 00:29:23,440
then lastly, um visualization during

664
00:29:20,960 --> 00:29:26,880
procedures. You can imagine if you are

665
00:29:23,440 --> 00:29:28,559
doing a procedure in in a body, it's 3D

666
00:29:26,880 --> 00:29:31,120
uh but you're looking at this 2D image.

667
00:29:28,559 --> 00:29:33,760
So this particular image is uh the

668
00:29:31,120 --> 00:29:35,919
placement of a central line. Um they're

669
00:29:33,760 --> 00:29:39,120
trying to get a large needle and

670
00:29:35,919 --> 00:29:41,520
catheter into that sort of squishy uh

671
00:29:39,120 --> 00:29:42,720
black hole towards the top. Um there are

672
00:29:41,520 --> 00:29:45,520
other things around it that you really

673
00:29:42,720 --> 00:29:48,320
don't want to poke with a needle. And

674
00:29:45,520 --> 00:29:49,440
that little yellow dot is uh the needle

675
00:29:48,320 --> 00:29:51,600
that they're looking at. So you can

676
00:29:49,440 --> 00:29:53,679
imagine it's just very hard to visualize

677
00:29:51,600 --> 00:29:58,159
that needle in 2D when you're working on

678
00:29:53,679 --> 00:30:00,399
this inherently 3D uh body.

679
00:29:58,159 --> 00:30:02,000
So how do we achieve volume ultrasound?

680
00:30:00,399 --> 00:30:04,000
Um Jason talked about one way. I'm going

681
00:30:02,000 --> 00:30:06,559
to talk about a slightly different uh

682
00:30:04,000 --> 00:30:08,960
method for it. Uh what it boils down to

683
00:30:06,559 --> 00:30:11,039
is collecting two two streams of data at

684
00:30:08,960 --> 00:30:12,720
the same time. The first one being the

685
00:30:11,039 --> 00:30:15,279
ultrasound B mode images that you would

686
00:30:12,720 --> 00:30:17,520
typically collect and the second being

687
00:30:15,279 --> 00:30:19,760
uh the poses of the probe that you're

688
00:30:17,520 --> 00:30:22,080
using to collect the images. So pose is

689
00:30:19,760 --> 00:30:25,600
just a fancy word saying meaning uh the

690
00:30:22,080 --> 00:30:28,320
translation and rotation of that probe.

691
00:30:25,600 --> 00:30:30,640
Um and together that sort of describes

692
00:30:28,320 --> 00:30:33,600
where the probe is and thus where the

693
00:30:30,640 --> 00:30:35,919
images are in 3D space. There are

694
00:30:33,600 --> 00:30:39,520
different ways to measure this uh these

695
00:30:35,919 --> 00:30:42,159
poses. I'll just name a few. One is a

696
00:30:39,520 --> 00:30:43,919
system like Optitra. Um so this is

697
00:30:42,159 --> 00:30:45,440
what's pictured as a smaller version of

698
00:30:43,919 --> 00:30:48,240
what the immersion lab offers in terms

699
00:30:45,440 --> 00:30:51,039
of optitra. Um but that is optical

700
00:30:48,240 --> 00:30:54,720
tracking of something like an ultrasound

701
00:30:51,039 --> 00:30:58,799
transducer. They're also sort of um

702
00:30:54,720 --> 00:31:00,559
heavier duty uh robotic arms. Uh these

703
00:30:58,799 --> 00:31:03,039
are

704
00:31:00,559 --> 00:31:05,120
uh very accurate in terms of uh tracking

705
00:31:03,039 --> 00:31:07,919
probe pose. uh but they can be very

706
00:31:05,120 --> 00:31:09,760
expensive and and not as portable. And

707
00:31:07,919 --> 00:31:11,679
then finally, one thing we've used in

708
00:31:09,760 --> 00:31:13,600
our lab is a little off-the-shelf

709
00:31:11,679 --> 00:31:15,440
sensor. It's about $300, so it's very

710
00:31:13,600 --> 00:31:17,279
cheap compared to the ultrasound probe.

711
00:31:15,440 --> 00:31:19,200
Um and this sensor has a camera on it

712
00:31:17,279 --> 00:31:20,960
and some sensors in it that help it to

713
00:31:19,200 --> 00:31:23,120
map its environment and localize the

714
00:31:20,960 --> 00:31:24,159
probe within that environment. Um, so

715
00:31:23,120 --> 00:31:26,399
there's lots of different ways to

716
00:31:24,159 --> 00:31:30,159
measure this these poses, but together

717
00:31:26,399 --> 00:31:33,200
these two streams of information um can

718
00:31:30,159 --> 00:31:36,480
uh be aggregated to form an ultrasound

719
00:31:33,200 --> 00:31:38,480
volume uh like these two images shown

720
00:31:36,480 --> 00:31:40,480
here.

721
00:31:38,480 --> 00:31:41,600
Uh we can take this a step further and

722
00:31:40,480 --> 00:31:43,200
talk about guided ultrasound

723
00:31:41,600 --> 00:31:45,919
acquisition. So this is something unique

724
00:31:43,200 --> 00:31:48,159
that volume ultrasound enables. Um you

725
00:31:45,919 --> 00:31:50,080
start by doing the regular ultrasound

726
00:31:48,159 --> 00:31:52,960
scanning again collecting the poses

727
00:31:50,080 --> 00:31:55,120
along with it. uh you aggregate it into

728
00:31:52,960 --> 00:31:57,200
this uh 3D volume. So you do the

729
00:31:55,120 --> 00:31:59,519
reconstruction. This is an example of a

730
00:31:57,200 --> 00:32:01,039
kidney model and then from that

731
00:31:59,519 --> 00:32:02,720
reconstruction because you're

732
00:32:01,039 --> 00:32:04,960
aggregating the information and placing

733
00:32:02,720 --> 00:32:07,840
it into context you can start to

734
00:32:04,960 --> 00:32:10,480
understand uh where information is

735
00:32:07,840 --> 00:32:13,679
missing. So there's a little bit of a

736
00:32:10,480 --> 00:32:15,840
lag but um in ultrasound we often have

737
00:32:13,679 --> 00:32:17,519
shadowed images. So in this particular

738
00:32:15,840 --> 00:32:20,960
kidney image, kind of right down the

739
00:32:17,519 --> 00:32:22,799
middle is that shadow that's from a rib.

740
00:32:20,960 --> 00:32:24,320
Um, and obviously you're missing

741
00:32:22,799 --> 00:32:26,559
information there. From a different

742
00:32:24,320 --> 00:32:28,159
angle, you can get that information. And

743
00:32:26,559 --> 00:32:30,640
so what we can do with volume ultrasound

744
00:32:28,159 --> 00:32:32,320
is we can direct a user to those areas

745
00:32:30,640 --> 00:32:35,279
that are missing information or need

746
00:32:32,320 --> 00:32:37,519
more certainty. Um, so we can guide them

747
00:32:35,279 --> 00:32:39,519
and they can scan further and we can

748
00:32:37,519 --> 00:32:43,799
continue the cycle until we have an

749
00:32:39,519 --> 00:32:43,799
ultrasound volume that we're happy with.

750
00:32:44,080 --> 00:32:47,919
Okay, so that's the ultrasound side of

751
00:32:46,159 --> 00:32:49,519
things. Where does AR come into the

752
00:32:47,919 --> 00:32:51,360
picture?

753
00:32:49,519 --> 00:32:53,519
Um, I'll start broadly again and say

754
00:32:51,360 --> 00:32:56,159
that AR for medical applications is this

755
00:32:53,519 --> 00:32:58,799
this uh rapidly expanding and growing

756
00:32:56,159 --> 00:33:00,799
field. This is just sort of a sample uh

757
00:32:58,799 --> 00:33:04,320
I know it's hard to read, but a sample

758
00:33:00,799 --> 00:33:07,440
list of uh FDA cleared ARVR medical

759
00:33:04,320 --> 00:33:10,480
devices. Um until recently a lot of the

760
00:33:07,440 --> 00:33:13,279
things on that list were uh along the

761
00:33:10,480 --> 00:33:15,360
the lines of surgical guidance or

762
00:33:13,279 --> 00:33:18,240
procedural guidance and visualization.

763
00:33:15,360 --> 00:33:22,320
Um so in surgery being able to see

764
00:33:18,240 --> 00:33:25,440
either pre-operative scans or where your

765
00:33:22,320 --> 00:33:29,279
um instrument will interact with those

766
00:33:25,440 --> 00:33:30,960
those um those images. Um a lot of

767
00:33:29,279 --> 00:33:34,320
that's been sort of the leading use case

768
00:33:30,960 --> 00:33:35,760
so far. Uh more recently there have been

769
00:33:34,320 --> 00:33:39,600
um different use cases which is

770
00:33:35,760 --> 00:33:43,039
exciting. Uh this particular uh uh

771
00:33:39,600 --> 00:33:45,840
example just for one example uh is a

772
00:33:43,039 --> 00:33:47,840
intended as an atome use device for

773
00:33:45,840 --> 00:33:49,200
people with chronic low back pain and it

774
00:33:47,840 --> 00:33:51,679
kind of guides people through like

775
00:33:49,200 --> 00:33:53,120
breathing exercises and meditations and

776
00:33:51,679 --> 00:33:55,200
things that have been shown to help with

777
00:33:53,120 --> 00:33:58,000
chronic pain. And so u totally different

778
00:33:55,200 --> 00:34:00,799
use case uh exciting that uh things are

779
00:33:58,000 --> 00:34:02,000
expanding as we go. Um in the research

780
00:34:00,799 --> 00:34:03,200
space not so much in the commercial

781
00:34:02,000 --> 00:34:04,720
space but in the research space there

782
00:34:03,200 --> 00:34:07,039
have also been applications specifically

783
00:34:04,720 --> 00:34:12,320
with ultrasound. Uh so this image is a

784
00:34:07,039 --> 00:34:15,280
person using um an AR system to biopsy

785
00:34:12,320 --> 00:34:17,520
an olive within a turkey breast. Um so

786
00:34:15,280 --> 00:34:19,359
he he's got sort of an image. You can

787
00:34:17,520 --> 00:34:21,040
see the ultrasound image is projected

788
00:34:19,359 --> 00:34:23,359
onto the phantom so he can kind of

789
00:34:21,040 --> 00:34:25,760
understand where the image that he's

790
00:34:23,359 --> 00:34:27,679
taking with the probe is in uh the

791
00:34:25,760 --> 00:34:30,560
context of that phantom and how his

792
00:34:27,679 --> 00:34:32,560
instrument will interact with it.

793
00:34:30,560 --> 00:34:35,280
Um so it's a really rapidly expanding

794
00:34:32,560 --> 00:34:38,000
space. Um how do we see AR being used

795
00:34:35,280 --> 00:34:42,480
for our specific context?

796
00:34:38,000 --> 00:34:44,800
Um there's a couple of of big um

797
00:34:42,480 --> 00:34:46,560
uh things we'd like to use it for. So,

798
00:34:44,800 --> 00:34:51,599
first of all, we're using a Microsoft

799
00:34:46,560 --> 00:34:53,119
Hollow Lens 2. Um, this is an augmented

800
00:34:51,599 --> 00:34:55,440
reality device rather than a virtual

801
00:34:53,119 --> 00:34:57,280
reality device. So, uh, it's a pass

802
00:34:55,440 --> 00:34:58,960
through, so you can see something

803
00:34:57,280 --> 00:35:01,440
projected onto what's in front of you,

804
00:34:58,960 --> 00:35:03,200
but you can also see, um, what's in

805
00:35:01,440 --> 00:35:04,400
front of you in in real life. So, you

806
00:35:03,200 --> 00:35:07,200
can see the phantom, you can see the

807
00:35:04,400 --> 00:35:08,880
patient you're working on. Um, and we

808
00:35:07,200 --> 00:35:12,800
hope to use this number one as a

809
00:35:08,880 --> 00:35:14,240
tracking tool. Um, so there's uh

810
00:35:12,800 --> 00:35:16,079
something called Aruko markers. I think

811
00:35:14,240 --> 00:35:17,520
Jason mentioned them too, but uh they're

812
00:35:16,079 --> 00:35:22,480
a little bit like QR codes, but they're

813
00:35:17,520 --> 00:35:24,640
just um little pieces of uh paper in

814
00:35:22,480 --> 00:35:27,200
this case uh attached to a probe that

815
00:35:24,640 --> 00:35:29,680
make it easy to track. Um so we can use

816
00:35:27,200 --> 00:35:32,800
computer vision algorithms to track and

817
00:35:29,680 --> 00:35:37,040
get that pose of an ultrasound probe as

818
00:35:32,800 --> 00:35:39,040
we move it um

819
00:35:37,040 --> 00:35:41,200
as we move it over a phantom. So the

820
00:35:39,040 --> 00:35:44,000
second thing we would like to use the or

821
00:35:41,200 --> 00:35:46,000
we plan to use the the AR device for is

822
00:35:44,000 --> 00:35:48,000
more for visualization. So there's a few

823
00:35:46,000 --> 00:35:50,480
different sort of aspects there. The

824
00:35:48,000 --> 00:35:54,400
first is what I call volume orientation.

825
00:35:50,480 --> 00:35:57,200
Um so taking an ultrasound probe seeing

826
00:35:54,400 --> 00:35:59,760
where that image is within the context

827
00:35:57,200 --> 00:36:03,440
of the volume that you're scanning. So

828
00:35:59,760 --> 00:36:05,280
volume orientation. Um another one is uh

829
00:36:03,440 --> 00:36:08,320
voxal coverage. So if we talk about

830
00:36:05,280 --> 00:36:10,880
reconstructing a voxal grid um and we

831
00:36:08,320 --> 00:36:12,400
want to understand sort of where have we

832
00:36:10,880 --> 00:36:14,160
collected a lot of information where do

833
00:36:12,400 --> 00:36:16,079
we still need to collect information

834
00:36:14,160 --> 00:36:18,400
that's image or that's information that

835
00:36:16,079 --> 00:36:21,040
can be also communicated via an AR

836
00:36:18,400 --> 00:36:23,440
application. Um and then the last one is

837
00:36:21,040 --> 00:36:26,400
that guidance piece I mentioned. Um you

838
00:36:23,440 --> 00:36:28,240
can sort of instruct a user where they

839
00:36:26,400 --> 00:36:32,240
need to scan further in order to

840
00:36:28,240 --> 00:36:33,920
complete an ultrasound volume.

841
00:36:32,240 --> 00:36:35,920
So, a little bit a few more details

842
00:36:33,920 --> 00:36:37,440
about our sort of system architecture.

843
00:36:35,920 --> 00:36:40,000
Um, like I said, we we're using the

844
00:36:37,440 --> 00:36:41,920
Hello Lens 2 headset. We've got an

845
00:36:40,000 --> 00:36:44,240
ultrasound probe uh with that Aruka

846
00:36:41,920 --> 00:36:46,640
marker marker attached. Um, and a

847
00:36:44,240 --> 00:36:48,079
phantom. A phantom is a model of um

848
00:36:46,640 --> 00:36:50,480
something we'd like to image in real

849
00:36:48,079 --> 00:36:52,880
life. So, this phantom uh you can just

850
00:36:50,480 --> 00:36:54,480
barely see in the middle is a model of a

851
00:36:52,880 --> 00:36:56,320
kidney.

852
00:36:54,480 --> 00:36:57,839
Um that's also got an Aruka marker

853
00:36:56,320 --> 00:36:59,760
attached. And then, of course, there we

854
00:36:57,839 --> 00:37:00,880
can communicate back to the computer. on

855
00:36:59,760 --> 00:37:02,720
the computer we're running something

856
00:37:00,880 --> 00:37:04,880
called uh ROSS 2 which is robot

857
00:37:02,720 --> 00:37:07,119
operating system 2. Um and what that

858
00:37:04,880 --> 00:37:09,839
does is it sort of manages uh multiple

859
00:37:07,119 --> 00:37:12,320
streams of information.

860
00:37:09,839 --> 00:37:14,960
So uh first of all like we said we can

861
00:37:12,320 --> 00:37:18,160
use computer vision um and the hollow

862
00:37:14,960 --> 00:37:20,960
lens to track uh the ultrasound probe as

863
00:37:18,160 --> 00:37:23,200
it moves. So as it moves it can output a

864
00:37:20,960 --> 00:37:24,880
stream of poses. Um, we can also track

865
00:37:23,200 --> 00:37:26,560
the phantom, which nominally is not

866
00:37:24,880 --> 00:37:28,079
moving too much. Um, but could

867
00:37:26,560 --> 00:37:29,760
theoretically, you can imagine if that

868
00:37:28,079 --> 00:37:32,560
phantom were a person, they certainly

869
00:37:29,760 --> 00:37:34,240
would move. So that pose information

870
00:37:32,560 --> 00:37:37,119
from both the ultrasound and the phantom

871
00:37:34,240 --> 00:37:38,560
can be fed back to the computer.

872
00:37:37,119 --> 00:37:41,119
We've also got the ultrasound

873
00:37:38,560 --> 00:37:43,839
information

874
00:37:41,119 --> 00:37:45,280
which can be fed to the computer and

875
00:37:43,839 --> 00:37:47,440
then kind of like you had seen in those

876
00:37:45,280 --> 00:37:50,720
other examples, you can project the

877
00:37:47,440 --> 00:37:52,720
ultrasound image back to um the probe in

878
00:37:50,720 --> 00:37:54,400
real life, back to the headset uh and it

879
00:37:52,720 --> 00:37:59,760
can be displayed under the probe in real

880
00:37:54,400 --> 00:38:01,680
life as sort of volume uh orientation.

881
00:37:59,760 --> 00:38:03,200
Uh and then on the computer we've got

882
00:38:01,680 --> 00:38:05,920
some image processing, the

883
00:38:03,200 --> 00:38:09,839
reconstruction happening. Um and we can

884
00:38:05,920 --> 00:38:13,200
do sort of a little or a lot in terms of

885
00:38:09,839 --> 00:38:15,839
um the reconstruction and and how we

886
00:38:13,200 --> 00:38:17,280
process it and um what sort of

887
00:38:15,839 --> 00:38:20,400
information we want to give back to the

888
00:38:17,280 --> 00:38:22,480
user. And then finally we take that

889
00:38:20,400 --> 00:38:25,280
information from our image processing

890
00:38:22,480 --> 00:38:30,640
and reconstruction um and feed it back

891
00:38:25,280 --> 00:38:33,520
to the um hollow lens for uh guidance or

892
00:38:30,640 --> 00:38:35,200
for visualization of uh the volume or

893
00:38:33,520 --> 00:38:38,000
guidance.

894
00:38:35,200 --> 00:38:41,280
Um here's a quick demo.

895
00:38:38,000 --> 00:38:43,760
Let's see.

896
00:38:41,280 --> 00:38:47,200
There it goes. Um so this is really

897
00:38:43,760 --> 00:38:48,320
highlighting the tracking tool. Um, so

898
00:38:47,200 --> 00:38:50,240
you can see we've actually got three

899
00:38:48,320 --> 00:38:53,359
Aruka markers because more is better in

900
00:38:50,240 --> 00:38:55,680
this case on our 3D printed model probe.

901
00:38:53,359 --> 00:38:58,960
Um, and we're displaying kind of a a

902
00:38:55,680 --> 00:39:00,560
placeholder uh image along the bottom.

903
00:38:58,960 --> 00:39:01,760
You can see there's some lag. Uh, so

904
00:39:00,560 --> 00:39:03,760
like I said, this project is in

905
00:39:01,760 --> 00:39:05,520
development. And so here we're kind of

906
00:39:03,760 --> 00:39:07,680
trying to test the limits of how well

907
00:39:05,520 --> 00:39:09,040
this tracking works. And you can see it

908
00:39:07,680 --> 00:39:10,640
does start to fail at some points. So

909
00:39:09,040 --> 00:39:14,400
when the arro markers are not very

910
00:39:10,640 --> 00:39:16,960
visible um it it struggles to um display

911
00:39:14,400 --> 00:39:20,800
the image or if we move really fast um

912
00:39:16,960 --> 00:39:22,800
it doesn't uh quite keep up. So uh

913
00:39:20,800 --> 00:39:26,640
that's one thing we're doing now is is

914
00:39:22,800 --> 00:39:29,760
trying to um define the limits of the

915
00:39:26,640 --> 00:39:32,079
system and where we might uh incorporate

916
00:39:29,760 --> 00:39:35,760
other uh tracking methods. For example,

917
00:39:32,079 --> 00:39:37,520
optitra in uh the immersion lab to sort

918
00:39:35,760 --> 00:39:41,040
of either supplement or replace some of

919
00:39:37,520 --> 00:39:44,960
these functions that um may or may not

920
00:39:41,040 --> 00:39:47,040
work as well as they can in theory. This

921
00:39:44,960 --> 00:39:49,599
is sort of an example of a voxal grid.

922
00:39:47,040 --> 00:39:51,280
Um, so if you can imagine, so now you

923
00:39:49,599 --> 00:39:52,480
can see the image is within that grid.

924
00:39:51,280 --> 00:39:55,839
So you can imagine you're you're

925
00:39:52,480 --> 00:39:57,920
scanning a phantom. Um, and that sort of

926
00:39:55,839 --> 00:40:02,320
image follows you as you're as you're

927
00:39:57,920 --> 00:40:03,520
scanning. So very early example. Um, one

928
00:40:02,320 --> 00:40:05,119
of the next steps that we're really

929
00:40:03,520 --> 00:40:08,160
interested or really excited to think

930
00:40:05,119 --> 00:40:10,000
about is how we communicate uh, our

931
00:40:08,160 --> 00:40:12,640
guidance piece. So how do we visualize

932
00:40:10,000 --> 00:40:15,440
the guidance that um, can happen with

933
00:40:12,640 --> 00:40:16,560
volume ultrasound? As one example, I

934
00:40:15,440 --> 00:40:19,440
want to highlight the work of my

935
00:40:16,560 --> 00:40:20,720
labmate, uh, Chian Lynn. Um, she really

936
00:40:19,440 --> 00:40:23,440
is the person who developed this

937
00:40:20,720 --> 00:40:26,320
guidance. This is guidance on without

938
00:40:23,440 --> 00:40:28,320
AR, so like on a 2D computer screen. Um,

939
00:40:26,320 --> 00:40:30,880
but in essence, what she's got is the

940
00:40:28,320 --> 00:40:33,280
lighter red probe is sort of uh where

941
00:40:30,880 --> 00:40:36,320
you are, and the darker red is where it

942
00:40:33,280 --> 00:40:38,160
suggests your next uh position should be

943
00:40:36,320 --> 00:40:40,240
uh in order to gather all of the

944
00:40:38,160 --> 00:40:42,800
information you need uh for a volume

945
00:40:40,240 --> 00:40:44,800
ultrasound. So, that's one uh

946
00:40:42,800 --> 00:40:48,000
possibility. Another possibility is this

947
00:40:44,800 --> 00:40:50,720
is a 2D image, but you can imagine in 3D

948
00:40:48,000 --> 00:40:53,440
um trying to almost color in like a

949
00:40:50,720 --> 00:40:55,920
voxal grid um as you scan and get more

950
00:40:53,440 --> 00:40:58,000
information. Um once a voxil is happy,

951
00:40:55,920 --> 00:41:00,079
it turns purple uh and you move on to

952
00:40:58,000 --> 00:41:02,560
the uncolored voxels. So we're really

953
00:41:00,079 --> 00:41:06,560
excited to think about that next. Um

954
00:41:02,560 --> 00:41:08,400
overall, we think this uh AR for volume

955
00:41:06,560 --> 00:41:10,480
ultrasound could potentially be used for

956
00:41:08,400 --> 00:41:13,359
education and training. Uh we can

957
00:41:10,480 --> 00:41:15,280
envision if a clinician is wanting to

958
00:41:13,359 --> 00:41:17,200
get to know how to use ultrasound and

959
00:41:15,280 --> 00:41:19,200
they need to practice especially the

960
00:41:17,200 --> 00:41:21,599
movements of of what ultrasound feels

961
00:41:19,200 --> 00:41:24,079
like um and how to scan thoroughly over

962
00:41:21,599 --> 00:41:27,599
a particular area. Um you could imagine

963
00:41:24,079 --> 00:41:30,000
using a system like this um to to

964
00:41:27,599 --> 00:41:31,839
supplement that training. We also think

965
00:41:30,000 --> 00:41:34,000
this is potentially just an accessible

966
00:41:31,839 --> 00:41:36,319
use of ultrasound um potentially in

967
00:41:34,000 --> 00:41:38,560
remote health contexts um for somebody

968
00:41:36,319 --> 00:41:40,560
who maybe doesn't have an expert level

969
00:41:38,560 --> 00:41:42,640
of training for ultrasound. So we're

970
00:41:40,560 --> 00:41:44,880
very excited uh to move forward with

971
00:41:42,640 --> 00:41:48,280
this project and uh happy to take

972
00:41:44,880 --> 00:41:48,280
questions now.

973
00:41:58,480 --> 00:42:03,040
Awesome. Um Jason, if you want to come

974
00:42:00,400 --> 00:42:06,000
up and uh there are a few people here in

975
00:42:03,040 --> 00:42:07,760
the audience. So awesome, awesome work.

976
00:42:06,000 --> 00:42:10,000
I mean it looks like a lot of stuff has

977
00:42:07,760 --> 00:42:11,680
been done. Um a lot of progress since

978
00:42:10,000 --> 00:42:14,240
kind of the beginning of of the semester

979
00:42:11,680 --> 00:42:15,920
even. So let's just uh we'll look at

980
00:42:14,240 --> 00:42:17,599
some of the questions in chat and if any

981
00:42:15,920 --> 00:42:19,599
of you guys have any questions in the

982
00:42:17,599 --> 00:42:22,160
audience, feel free to just uh say

983
00:42:19,599 --> 00:42:24,640
something. Um but I'll get things

984
00:42:22,160 --> 00:42:27,200
rolling. Um there was a quick comment

985
00:42:24,640 --> 00:42:28,400
about who makes the $300 probe. That may

986
00:42:27,200 --> 00:42:29,920
have been. Yeah.

987
00:42:28,400 --> 00:42:31,599
>> Uh, so the probe, the ultrasound probe

988
00:42:29,920 --> 00:42:34,240
itself is not $300. Point of care

989
00:42:31,599 --> 00:42:36,400
ultrasound uh, probes are in the range

990
00:42:34,240 --> 00:42:39,040
of thousands of dollars. Um, the

991
00:42:36,400 --> 00:42:42,079
attachment that tracks the pose is an

992
00:42:39,040 --> 00:42:45,200
Intel product that's around $300.

993
00:42:42,079 --> 00:42:46,560
>> Awesome. Thank you. Um, and I did notice

994
00:42:45,200 --> 00:42:49,040
some of you guys did join a little bit

995
00:42:46,560 --> 00:42:50,560
later. This will be recorded, so uh, if

996
00:42:49,040 --> 00:42:53,359
you guys have any questions after, feel

997
00:42:50,560 --> 00:42:54,800
free to just email them. Um, but I I

998
00:42:53,359 --> 00:42:57,119
have another question as well. So, it

999
00:42:54,800 --> 00:42:58,880
looked like both of you guys used uh a

1000
00:42:57,119 --> 00:43:00,800
different headset in terms of virtual or

1001
00:42:58,880 --> 00:43:02,319
augmented reality. Could each one of you

1002
00:43:00,800 --> 00:43:04,160
just kind of highlight the reasons why

1003
00:43:02,319 --> 00:43:06,720
you chose that headmounted display over

1004
00:43:04,160 --> 00:43:07,200
the other? Um maybe Jason, you can

1005
00:43:06,720 --> 00:43:07,760
start.

1006
00:43:07,200 --> 00:43:11,680
>> Um

1007
00:43:07,760 --> 00:43:14,000
>> and you can come. I I love honestly the

1008
00:43:11,680 --> 00:43:17,200
the hollow lens system and I think it's

1009
00:43:14,000 --> 00:43:20,240
that sort of AR is important for medical

1010
00:43:17,200 --> 00:43:22,800
contexts because a lot of the times um

1011
00:43:20,240 --> 00:43:24,400
you know medical people need to trust

1012
00:43:22,800 --> 00:43:26,400
what they're seeing in real life. They

1013
00:43:24,400 --> 00:43:29,119
don't want a glitch to happen and all of

1014
00:43:26,400 --> 00:43:31,920
a sudden everything's off. So I do like

1015
00:43:29,119 --> 00:43:35,040
that aspect but the hollow lens is also

1016
00:43:31,920 --> 00:43:36,800
you know it's like wireless and um it

1017
00:43:35,040 --> 00:43:39,280
can't

1018
00:43:36,800 --> 00:43:41,359
compute as much. Um, so that's why we

1019
00:43:39,280 --> 00:43:44,400
needed the Vario. It's really just the

1020
00:43:41,359 --> 00:43:47,119
highest end of computation. It can plug

1021
00:43:44,400 --> 00:43:50,079
it directly into the PC, run the GPU,

1022
00:43:47,119 --> 00:43:52,160
and send the images directly across. Um,

1023
00:43:50,079 --> 00:43:54,720
and the other thing was it's the highest

1024
00:43:52,160 --> 00:43:57,599
resolution that I could find. So the

1025
00:43:54,720 --> 00:43:59,520
pass through is pretty fairly good and

1026
00:43:57,599 --> 00:44:01,760
they use it in like fighter jets and

1027
00:43:59,520 --> 00:44:04,880
stuff which is cool. So high stakes

1028
00:44:01,760 --> 00:44:07,760
situations, but it is very heavy and not

1029
00:44:04,880 --> 00:44:09,440
really practical in that sense. Yeah,

1030
00:44:07,760 --> 00:44:11,680
>> I think maybe for like one piece of

1031
00:44:09,440 --> 00:44:14,079
additional context, the Vario, the pass

1032
00:44:11,680 --> 00:44:15,599
through is basically like it it videos

1033
00:44:14,079 --> 00:44:17,359
what's around you and then projects the

1034
00:44:15,599 --> 00:44:19,599
video back to you. So you can still see

1035
00:44:17,359 --> 00:44:21,040
what's around you, but instead of it

1036
00:44:19,599 --> 00:44:22,640
being like looking through a glass,

1037
00:44:21,040 --> 00:44:25,200
you're looking at a video essentially.

1038
00:44:22,640 --> 00:44:26,880
So um that can sort of increase the

1039
00:44:25,200 --> 00:44:30,240
likelihood of motion sickness for some

1040
00:44:26,880 --> 00:44:32,160
people. Um but it's yeah, it's

1041
00:44:30,240 --> 00:44:33,920
trade-offs are definitely available for

1042
00:44:32,160 --> 00:44:35,599
both. I think a lot of the existing

1043
00:44:33,920 --> 00:44:37,680
medical devices that are FDA cleared out

1044
00:44:35,599 --> 00:44:41,200
there use hollow lens or something like

1045
00:44:37,680 --> 00:44:42,880
it um where you can see

1046
00:44:41,200 --> 00:44:43,839
uh through the glasses what's in front

1047
00:44:42,880 --> 00:44:45,839
of you.

1048
00:44:43,839 --> 00:44:46,960
>> The hope is they'll converge at

1049
00:44:45,839 --> 00:44:49,920
>> Yeah. someday.

1050
00:44:46,960 --> 00:44:52,000
>> Got it. Got it. Thank you. Um and on

1051
00:44:49,920 --> 00:44:54,160
that note, I mean you talked about the

1052
00:44:52,000 --> 00:44:56,640
computation, right? Being able to render

1053
00:44:54,160 --> 00:44:58,319
all of this and I saw in in some of your

1054
00:44:56,640 --> 00:45:00,800
videos you had a little bit of latency.

1055
00:44:58,319 --> 00:45:02,720
Now, was that due to I guess the the

1056
00:45:00,800 --> 00:45:04,480
rendering in in which it had to render

1057
00:45:02,720 --> 00:45:06,800
or is that streaming somewhere?

1058
00:45:04,480 --> 00:45:08,560
>> I think it's the the rendering. Yeah. Um

1059
00:45:06,800 --> 00:45:10,480
I think I think that's the slow point

1060
00:45:08,560 --> 00:45:12,480
because actually reading the poses like

1061
00:45:10,480 --> 00:45:13,200
actually tracking the probe is pretty

1062
00:45:12,480 --> 00:45:13,520
pretty good.

1063
00:45:13,200 --> 00:45:16,640
>> Okay.

1064
00:45:13,520 --> 00:45:18,240
>> U but it's rendering back the image is a

1065
00:45:16,640 --> 00:45:20,400
little bit laggy at the moment.

1066
00:45:18,240 --> 00:45:22,720
>> And and for you, I mean you have you're

1067
00:45:20,400 --> 00:45:25,760
going directly into the PC. So this is a

1068
00:45:22,720 --> 00:45:27,920
PC VR experience. Um I guess what is

1069
00:45:25,760 --> 00:45:29,680
kind of the minimum GPU requirement

1070
00:45:27,920 --> 00:45:31,680
that's you're you're kind of bottling

1071
00:45:29,680 --> 00:45:33,920
neck bottlenecking out of?

1072
00:45:31,680 --> 00:45:37,440
>> Um yeah that's a good question. So I

1073
00:45:33,920 --> 00:45:39,680
think uh one aspect of it was we were

1074
00:45:37,440 --> 00:45:41,359
looking through the VR software and I

1075
00:45:39,680 --> 00:45:44,240
think Unreal Engine was the only one

1076
00:45:41,359 --> 00:45:47,440
that supported kind of large point cloud

1077
00:45:44,240 --> 00:45:49,359
representations millions of points and

1078
00:45:47,440 --> 00:45:52,880
>> they do efficient representation with

1079
00:45:49,359 --> 00:45:56,240
octry representation. So it was it was

1080
00:45:52,880 --> 00:45:59,520
just specwise the only system that could

1081
00:45:56,240 --> 00:46:02,960
load the the um frames that we have in

1082
00:45:59,520 --> 00:46:06,240
in near real time. And then um but the

1083
00:46:02,960 --> 00:46:07,760
point processing I think yeah that that

1084
00:46:06,240 --> 00:46:10,000
was at that point it was just like okay

1085
00:46:07,760 --> 00:46:14,000
if we're using Unreal anyways let's just

1086
00:46:10,000 --> 00:46:14,480
use the best GPUs we can to um render.

1087
00:46:14,000 --> 00:46:16,640
>> Yeah.

1088
00:46:14,480 --> 00:46:18,000
>> But we I think we were running on a 3080

1089
00:46:16,640 --> 00:46:20,960
at some point.

1090
00:46:18,000 --> 00:46:21,440
It runs on a laptop GPU also sometimes.

1091
00:46:20,960 --> 00:46:24,160
>> Okay, good.

1092
00:46:21,440 --> 00:46:26,960
>> Um but it is laggy. Yeah. Sure. Awesome.

1093
00:46:24,160 --> 00:46:29,040
Um and we got a question. Um how to

1094
00:46:26,960 --> 00:46:31,760
increase the speed of integration of

1095
00:46:29,040 --> 00:46:33,280
visualization in real life of object

1096
00:46:31,760 --> 00:46:36,319
identification.

1097
00:46:33,280 --> 00:46:39,040
Um I am also wondering about dynamic

1098
00:46:36,319 --> 00:46:41,680
transfer function. Is it also crucial

1099
00:46:39,040 --> 00:46:43,680
for patients? Um so maybe we could start

1100
00:46:41,680 --> 00:46:45,520
with the first part of that question on

1101
00:46:43,680 --> 00:46:48,720
how to increase the speed of integration

1102
00:46:45,520 --> 00:46:51,920
of visualization in real life. Um so I

1103
00:46:48,720 --> 00:46:55,200
think and that's based on object uh

1104
00:46:51,920 --> 00:46:55,599
identification. So you're using um

1105
00:46:55,200 --> 00:46:56,960
>> codes.

1106
00:46:55,599 --> 00:46:57,920
>> Yes. Could you could you share a little

1107
00:46:56,960 --> 00:47:00,960
bit about that?

1108
00:46:57,920 --> 00:47:03,280
>> Yeah. Um the speed has been a consistent

1109
00:47:00,960 --> 00:47:05,040
issue and I think we've we've sort of

1110
00:47:03,280 --> 00:47:07,359
cycled through several different uh

1111
00:47:05,040 --> 00:47:09,440
potential solutions uh based on what's

1112
00:47:07,359 --> 00:47:12,720
out there with different types of codes.

1113
00:47:09,440 --> 00:47:17,599
So, our codes, uh QR codes, other sort

1114
00:47:12,720 --> 00:47:20,720
of um similar similar ideas. Um

1115
00:47:17,599 --> 00:47:22,880
increasing the speed.

1116
00:47:20,720 --> 00:47:24,640
Yeah, it's a challenge.

1117
00:47:22,880 --> 00:47:28,800
Um and I think that's that's common

1118
00:47:24,640 --> 00:47:32,480
across a lot of um a lot of these

1119
00:47:28,800 --> 00:47:36,000
applications. Um, one one slow piece is

1120
00:47:32,480 --> 00:47:38,400
like we're basically um taking an image

1121
00:47:36,000 --> 00:47:42,079
from what the headset is seeing and then

1122
00:47:38,400 --> 00:47:43,520
processing it. Um, and so, you know, and

1123
00:47:42,079 --> 00:47:46,800
we're doing that at a certain frame rate

1124
00:47:43,520 --> 00:47:49,040
to to try and decrease the lagging. Um,

1125
00:47:46,800 --> 00:47:50,800
so we can process at a slower frame

1126
00:47:49,040 --> 00:47:53,359
rate. Um, but there's a trade-off

1127
00:47:50,800 --> 00:47:56,800
between u again that sort of lagging

1128
00:47:53,359 --> 00:47:58,880
that we're seeing um in terms of when we

1129
00:47:56,800 --> 00:48:00,720
move fast. So if we're moving slowly, it

1130
00:47:58,880 --> 00:48:02,319
works really well. Uh but if we're

1131
00:48:00,720 --> 00:48:04,880
moving really fast, which usually you're

1132
00:48:02,319 --> 00:48:06,000
not with ultrasound, but um that's where

1133
00:48:04,880 --> 00:48:07,839
it starts to break down.

1134
00:48:06,000 --> 00:48:10,319
>> Okay. And is this one reason why you're

1135
00:48:07,839 --> 00:48:11,920
thinking of the optitra integration? So

1136
00:48:10,319 --> 00:48:13,920
to kind of that up using infrared

1137
00:48:11,920 --> 00:48:16,240
reflective markers rather than kind of

1138
00:48:13,920 --> 00:48:18,079
uh image recognition uh processing.

1139
00:48:16,240 --> 00:48:19,280
>> Yes. Nominally, we'd like to use both at

1140
00:48:18,079 --> 00:48:21,920
the same time and sort of compare them

1141
00:48:19,280 --> 00:48:24,079
and say like what are the limits of this

1142
00:48:21,920 --> 00:48:25,599
uh computer vision sort of solution um

1143
00:48:24,079 --> 00:48:26,800
compared to something like Optack where

1144
00:48:25,599 --> 00:48:30,640
we almost get ground truth.

1145
00:48:26,800 --> 00:48:32,720
>> Sure. Um but yeah, it is it is a big uh

1146
00:48:30,640 --> 00:48:34,160
snag point in this particular workflow.

1147
00:48:32,720 --> 00:48:35,040
>> Got it. Jason, do you have anything to

1148
00:48:34,160 --> 00:48:36,480
to add to that?

1149
00:48:35,040 --> 00:48:38,960
>> Yeah, I think the main thing we noticed

1150
00:48:36,480 --> 00:48:41,359
was we were struggling with the visual

1151
00:48:38,960 --> 00:48:43,760
markers for a little bit in terms of it

1152
00:48:41,359 --> 00:48:46,400
was just overloading the system and how

1153
00:48:43,760 --> 00:48:49,119
much computation it was having to do and

1154
00:48:46,400 --> 00:48:51,440
would crash the application often. So I

1155
00:48:49,119 --> 00:48:52,880
think that's we were forced to move to a

1156
00:48:51,440 --> 00:48:55,040
different solution which in this case

1157
00:48:52,880 --> 00:48:56,800
was just the controller. Um, but that

1158
00:48:55,040 --> 00:48:59,040
really sped things up because I think

1159
00:48:56,800 --> 00:49:01,839
it's all built in. You know, you can

1160
00:48:59,040 --> 00:49:03,760
overlay 3D objects onto controllers very

1161
00:49:01,839 --> 00:49:05,119
easily and it used them very quickly.

1162
00:49:03,760 --> 00:49:07,200
So, I think that was kind of the

1163
00:49:05,119 --> 00:49:08,880
inspiration of like, oh, let's just tie

1164
00:49:07,200 --> 00:49:09,200
everything to the controller anyways.

1165
00:49:08,880 --> 00:49:09,920
Um,

1166
00:49:09,200 --> 00:49:11,760
>> right.

1167
00:49:09,920 --> 00:49:14,880
>> But I I wish there were more tools like

1168
00:49:11,760 --> 00:49:18,079
that to track objects like like any

1169
00:49:14,880 --> 00:49:20,640
object and turn any object into a

1170
00:49:18,079 --> 00:49:22,960
virtually tracked object as well and

1171
00:49:20,640 --> 00:49:25,200
that you can overlay visualizations on.

1172
00:49:22,960 --> 00:49:27,520
I think that was the missing point is

1173
00:49:25,200 --> 00:49:30,960
what is real, what is virtual, how do

1174
00:49:27,520 --> 00:49:32,160
you get the user to unite the two kind

1175
00:49:30,960 --> 00:49:32,800
of in the interface.

1176
00:49:32,160 --> 00:49:35,440
>> Yeah.

1177
00:49:32,800 --> 00:49:37,280
>> And with your study, um, you compared

1178
00:49:35,440 --> 00:49:40,079
kind of the novice and and kind of

1179
00:49:37,280 --> 00:49:41,920
experienced users of ultrasound. Did you

1180
00:49:40,079 --> 00:49:44,000
ask as well if they were familiar with

1181
00:49:41,920 --> 00:49:45,599
virtual or augmented reality? Were those

1182
00:49:44,000 --> 00:49:48,720
first-time users as well?

1183
00:49:45,599 --> 00:49:50,559
>> Uh, many of them were and some of them

1184
00:49:48,720 --> 00:49:53,440
none of them had used augmented reality

1185
00:49:50,559 --> 00:49:56,400
before. I think some of them had used um

1186
00:49:53,440 --> 00:49:58,400
VR and some experts even in the training

1187
00:49:56,400 --> 00:50:00,160
context where you know they learned to

1188
00:49:58,400 --> 00:50:00,720
use the ultrasound tools.

1189
00:50:00,160 --> 00:50:02,960
>> Sure.

1190
00:50:00,720 --> 00:50:04,640
>> VR. Yeah. No, it's interesting because

1191
00:50:02,960 --> 00:50:06,400
people feel they have kind of different

1192
00:50:04,640 --> 00:50:09,359
comfort levels using these headmounted

1193
00:50:06,400 --> 00:50:11,200
displays. So um very interesting stuff.

1194
00:50:09,359 --> 00:50:12,880
All right. So yes, we have one question

1195
00:50:11,200 --> 00:50:15,680
here.

1196
00:50:12,880 --> 00:50:18,160
>> Yeah. Yeah. I think and I know of a hide

1197
00:50:15,680 --> 00:50:20,559
tracker like Yeah. like their bands or

1198
00:50:18,160 --> 00:50:21,359
something or there's like a RF.

1199
00:50:20,559 --> 00:50:23,280
>> Yeah. Okay.

1200
00:50:21,359 --> 00:50:26,240
>> It's just smaller version.

1201
00:50:23,280 --> 00:50:29,720
>> Oh, Cedric. Yes. Yes.

1202
00:50:26,240 --> 00:50:29,720
>> It's really tiny.

1203
00:50:30,000 --> 00:50:35,880
>> Oh, interesting. Yeah.

1204
00:50:31,280 --> 00:50:35,880
>> We also both

1205
00:50:42,079 --> 00:50:48,000
useful

1206
00:50:44,480 --> 00:50:51,559
now the Russian And it's like a pencil

1207
00:50:48,000 --> 00:50:51,559
that is very

1208
00:50:55,359 --> 00:50:59,760
you could actually scalp or gives you

1209
00:50:58,079 --> 00:51:02,760
all.

1210
00:50:59,760 --> 00:51:02,760
>> Wow.

1211
00:51:07,119 --> 00:51:10,240
>> Yeah, that's true.

1212
00:51:08,640 --> 00:51:12,559
>> I hadn't thought about that for a while

1213
00:51:10,240 --> 00:51:15,839
because their development ecosystem was

1214
00:51:12,559 --> 00:51:18,880
closed for for a little bit. Yeah. So

1215
00:51:15,839 --> 00:51:19,119
yeah. Yeah, that's be cool to revisit

1216
00:51:18,880 --> 00:51:21,040
for.

1217
00:51:19,119 --> 00:51:23,520
>> It's an exciting field. Like it it turns

1218
00:51:21,040 --> 00:51:24,880
over really fast and it's pretty pretty

1219
00:51:23,520 --> 00:51:25,520
interesting.

1220
00:51:24,880 --> 00:51:27,440
>> Yeah.

1221
00:51:25,520 --> 00:51:29,839
>> Awesome. Um we probably have time for

1222
00:51:27,440 --> 00:51:33,599
one more question. Uh what is the device

1223
00:51:29,839 --> 00:51:35,280
that the probe interfaces with? Um I'm

1224
00:51:33,599 --> 00:51:37,280
wondering if that is the

1225
00:51:35,280 --> 00:51:39,920
>> device

1226
00:51:37,280 --> 00:51:41,680
>> or the

1227
00:51:39,920 --> 00:51:46,000
um it could be the phantoms.

1228
00:51:41,680 --> 00:51:48,960
>> The phantoms. Yeah. Sure.

1229
00:51:46,000 --> 00:51:53,280
>> Jonathan, could you specify a little bit

1230
00:51:48,960 --> 00:51:54,559
of what device you're you're mentioning?

1231
00:51:53,280 --> 00:51:56,800
>> And for those who didn't hear the

1232
00:51:54,559 --> 00:52:00,240
previous comment, it was mentioning uh

1233
00:51:56,800 --> 00:52:02,640
MedVR as a as a platform to to work with

1234
00:52:00,240 --> 00:52:05,520
individuals on on related questions such

1235
00:52:02,640 --> 00:52:07,200
as these. And then the Hive tracking uh

1236
00:52:05,520 --> 00:52:09,680
or the Hive Tracker as being an

1237
00:52:07,200 --> 00:52:11,119
alternative um for for object

1238
00:52:09,680 --> 00:52:12,559
identification.

1239
00:52:11,119 --> 00:52:13,839
>> I have a quick question for Jason while

1240
00:52:12,559 --> 00:52:15,599
we're waiting. I know you guys did

1241
00:52:13,839 --> 00:52:16,880
interviews at the end of your your

1242
00:52:15,599 --> 00:52:18,880
studies. What were some of the like

1243
00:52:16,880 --> 00:52:20,000
qualitative feedback you got on the on

1244
00:52:18,880 --> 00:52:22,640
your systems?

1245
00:52:20,000 --> 00:52:24,640
>> Um yeah, so we we actually, you know,

1246
00:52:22,640 --> 00:52:27,119
were compiled that into this knowledge

1247
00:52:24,640 --> 00:52:31,119
graph which I I think reference maybe in

1248
00:52:27,119 --> 00:52:33,119
the paper. Um, but yeah, a lot of people

1249
00:52:31,119 --> 00:52:37,280
a lot of the the feedback was like,

1250
00:52:33,119 --> 00:52:39,599
yeah, it was it's kind of clunky and um

1251
00:52:37,280 --> 00:52:42,400
disorienting sometimes to use a VR

1252
00:52:39,599 --> 00:52:45,839
system when you could just look at

1253
00:52:42,400 --> 00:52:48,319
something and and try your best to

1254
00:52:45,839 --> 00:52:50,960
mentally map it. Um but I think there

1255
00:52:48,319 --> 00:52:52,160
was just two camps of thought of like

1256
00:52:50,960 --> 00:52:53,599
you know experts who are very

1257
00:52:52,160 --> 00:52:55,920
comfortable with the process of mental

1258
00:52:53,599 --> 00:52:57,040
mapping and that's just how they expect

1259
00:52:55,920 --> 00:52:59,520
things to be

1260
00:52:57,040 --> 00:53:01,359
>> and then the noviceses who really didn't

1261
00:52:59,520 --> 00:53:02,559
know what to expect. So the the VR

1262
00:53:01,359 --> 00:53:04,079
systems really help them to

1263
00:53:02,559 --> 00:53:06,640
contextualize

1264
00:53:04,079 --> 00:53:08,480
and learn very quickly. But I think at

1265
00:53:06,640 --> 00:53:10,559
some point there is some convergence

1266
00:53:08,480 --> 00:53:13,119
that's still needing to make a mental

1267
00:53:10,559 --> 00:53:14,960
model and how detailed and how accurate

1268
00:53:13,119 --> 00:53:18,319
that mental model may be affected by the

1269
00:53:14,960 --> 00:53:20,000
two things. But um yeah, I think when I

1270
00:53:18,319 --> 00:53:21,920
was using it, just regardless, I was

1271
00:53:20,000 --> 00:53:24,480
starting to, you know, try to think of

1272
00:53:21,920 --> 00:53:26,640
where things were um that maybe that's

1273
00:53:24,480 --> 00:53:28,240
just how you use ultrasound as as a

1274
00:53:26,640 --> 00:53:29,040
system. So

1275
00:53:28,240 --> 00:53:31,599
>> that's interesting.

1276
00:53:29,040 --> 00:53:33,200
>> Yeah. Awesome. Awesome. Well, thank you

1277
00:53:31,599 --> 00:53:35,440
again, guys. Just one one more round of

1278
00:53:33,200 --> 00:53:38,559
applause for those of you in here. Uh

1279
00:53:35,440 --> 00:53:41,040
thank you. Appreciate it. And um that

1280
00:53:38,559 --> 00:53:43,359
comes to the hour, everybody. So just

1281
00:53:41,040 --> 00:53:45,280
want to make one final uh final

1282
00:53:43,359 --> 00:53:47,280
announcement. Our our next immerse

1283
00:53:45,280 --> 00:53:49,680
series is actually already scheduled.

1284
00:53:47,280 --> 00:53:52,160
It's for Wednesday, November 19th at the

1285
00:53:49,680 --> 00:53:54,640
same time at 11:00 a.m. And this will be

1286
00:53:52,160 --> 00:53:58,000
the user experience for robotic TE

1287
00:53:54,640 --> 00:53:59,760
operation by uh Rolando Montasano. And

1288
00:53:58,000 --> 00:54:01,599
he'll speak a little bit about some of

1289
00:53:59,760 --> 00:54:03,839
the tools that he worked with here in

1290
00:54:01,599 --> 00:54:06,400
the immersion lab, including uh the Toby

1291
00:54:03,839 --> 00:54:08,960
glasses for for eyetracking. So um thank

1292
00:54:06,400 --> 00:54:12,359
you all for joining us and um we'll see

1293
00:54:08,960 --> 00:54:12,359
you next time.


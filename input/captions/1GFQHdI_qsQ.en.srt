1
00:00:00,000 --> 00:00:05,020

2
00:00:05,020 --> 00:00:06,900
Good afternoon.

3
00:00:06,900 --> 00:00:10,830
I'm Anantha Chandrakasan, MIT's
Chief Innovation and Strategy

4
00:00:10,830 --> 00:00:14,190
Officer and the
Dean of Engineering.

5
00:00:14,190 --> 00:00:18,090
It is my honor to introduce
our panelists and moderator

6
00:00:18,090 --> 00:00:20,880
for the session
on collaboration.

7
00:00:20,880 --> 00:00:25,410
Our panel brings together global
luminaries in biotechnology

8
00:00:25,410 --> 00:00:26,760
and health care.

9
00:00:26,760 --> 00:00:31,890
And they work with us right here
in the Boston Cambridge area.

10
00:00:31,890 --> 00:00:36,790
They've each received numerous
prestigious awards and honors,

11
00:00:36,790 --> 00:00:41,220
and you can review them in their
detailed biographies online.

12
00:00:41,220 --> 00:00:44,580
During today's
discussion, our panelists

13
00:00:44,580 --> 00:00:48,090
will explore the rapidly
changing landscape

14
00:00:48,090 --> 00:00:52,320
of life sciences research
and how we can collectively

15
00:00:52,320 --> 00:00:56,940
embrace and shape the new
challenges and opportunities

16
00:00:56,940 --> 00:00:59,280
that lie ahead.

17
00:00:59,280 --> 00:01:03,750
Moderating our discussion
today is Dr. Noubar Afeyan.

18
00:01:03,750 --> 00:01:06,720
Dr. Afeyan is the
Founder and CEO

19
00:01:06,720 --> 00:01:10,110
of Flagship Pioneering
and co-founder

20
00:01:10,110 --> 00:01:13,110
and Board Chairman of Moderna.

21
00:01:13,110 --> 00:01:15,690
Because of COVID,
virtually everyone

22
00:01:15,690 --> 00:01:21,080
knows about Moderna, a world
leader in mRNA technology.

23
00:01:21,080 --> 00:01:26,450
Some of you might not know as
much about Flagship Pioneering.

24
00:01:26,450 --> 00:01:30,500
Flagship Pioneering empowers
entrepreneurially-minded

25
00:01:30,500 --> 00:01:34,640
scientists to invent solutions
to health and sustainability

26
00:01:34,640 --> 00:01:37,910
challenges that seem unsolvable.

27
00:01:37,910 --> 00:01:42,296
The result has been the
creation of more than 100

28
00:01:42,296 --> 00:01:45,440
first in category
bioplatform companies

29
00:01:45,440 --> 00:01:49,700
that are having significant
real world impact.

30
00:01:49,700 --> 00:01:54,080
During his career as an
inventor, an entrepreneur,

31
00:01:54,080 --> 00:01:57,710
and a CEO, Noubar has
co-founded and helped

32
00:01:57,710 --> 00:02:02,270
build over 70 life science
and technology startups.

33
00:02:02,270 --> 00:02:06,550
Terrific to have you
moderate the panel today.

34
00:02:06,550 --> 00:02:10,930
Noubar will be joined by our
four distinguished panelists.

35
00:02:10,930 --> 00:02:14,980
Dr. Anne Klibanski is
the President and CEO

36
00:02:14,980 --> 00:02:19,480
of Mass General Brigham,
or MGB, a world class,

37
00:02:19,480 --> 00:02:23,710
nonprofit, Boston-based
integrated health care system.

38
00:02:23,710 --> 00:02:27,760
It is the largest private
employer in Massachusetts.

39
00:02:27,760 --> 00:02:32,240
We all know that MGB delivers
world class health care.

40
00:02:32,240 --> 00:02:36,010
However, it is also a
leading hub for innovation

41
00:02:36,010 --> 00:02:40,030
in health care, helping
to bring academic research

42
00:02:40,030 --> 00:02:42,610
from the lab to the patient.

43
00:02:42,610 --> 00:02:46,990
Anne and her team have overseen
substantial investments

44
00:02:46,990 --> 00:02:50,560
in leading edge research
as well as the creation

45
00:02:50,560 --> 00:02:53,450
of more than 300 companies.

46
00:02:53,450 --> 00:02:56,120
With Anne's leadership,
MGB is building

47
00:02:56,120 --> 00:03:00,080
the integrated academic health
care system of the future,

48
00:03:00,080 --> 00:03:03,410
and it's a system
that puts patients

49
00:03:03,410 --> 00:03:05,900
at the center of it all.

50
00:03:05,900 --> 00:03:09,740
Anne has been instrumental
in shaping the MIT MGB

51
00:03:09,740 --> 00:03:11,270
collaborations.

52
00:03:11,270 --> 00:03:13,650
It is truly a pleasure
to work with you, Anne,

53
00:03:13,650 --> 00:03:17,830
to work on advancing
health care.

54
00:03:17,830 --> 00:03:21,190
Robert Langer is the
David H. Koch Institute

55
00:03:21,190 --> 00:03:26,710
Professor, one of only nine
Institute professors at MIT.

56
00:03:26,710 --> 00:03:30,970
Bob is a world renowned
biomedical and biochemical

57
00:03:30,970 --> 00:03:35,290
engineer who has pioneered the
development of new materials

58
00:03:35,290 --> 00:03:38,570
for controlled drug
delivery systems,

59
00:03:38,570 --> 00:03:41,950
particularly for continuous
controlled delivery

60
00:03:41,950 --> 00:03:45,320
of genetically
engineered proteins.

61
00:03:45,320 --> 00:03:49,370
He has written over 1,600
articles and 16 books and holds

62
00:03:49,370 --> 00:03:53,270
more than 1,500 issued
and pending patents.

63
00:03:53,270 --> 00:03:57,620
His patents have been licensed
to over 400 companies.

64
00:03:57,620 --> 00:04:01,400
As an academic, my favorite
metric is that he is the most

65
00:04:01,400 --> 00:04:11,400
cited engineer in history with
an H index of 327 with 437,533

66
00:04:11,400 --> 00:04:14,410
citations, at least
as of yesterday.

67
00:04:14,410 --> 00:04:16,529
[LAUGHTER]

68
00:04:16,529 --> 00:04:19,240
It is estimated that
Bob's research--

69
00:04:19,240 --> 00:04:23,970
[APPLAUSE]

70
00:04:23,970 --> 00:04:25,390

71
00:04:25,390 --> 00:04:27,880
It is estimated that Bob's
research has improved

72
00:04:27,880 --> 00:04:32,840
the lives of over two billion--
with a B-- people and counting.

73
00:04:32,840 --> 00:04:35,890
I'm very grateful to Bob
for all of his advice

74
00:04:35,890 --> 00:04:39,070
in the creation of MIT.

75
00:04:39,070 --> 00:04:42,220
Christopher Viehbacher
is the president and CEO

76
00:04:42,220 --> 00:04:47,170
of Biogen, one of Cambridge's
leading global biotechnology

77
00:04:47,170 --> 00:04:48,340
companies.

78
00:04:48,340 --> 00:04:51,430
Chris has extensive
international experience

79
00:04:51,430 --> 00:04:53,990
in large pharmaceutical
companies,

80
00:04:53,990 --> 00:04:57,200
including GlaxoSmithKline
and Sanofi,

81
00:04:57,200 --> 00:04:59,680
where he was the global CEO.

82
00:04:59,680 --> 00:05:03,650
As the co-founder of
Gurnet Point Capital,

83
00:05:03,650 --> 00:05:06,860
a Cambridge-based health
care investment fund,

84
00:05:06,860 --> 00:05:09,550
he also values the
role of startups

85
00:05:09,550 --> 00:05:13,300
in moving good science
out into the world.

86
00:05:13,300 --> 00:05:16,990
As CEO of Biogen, Chris
is creating a new path

87
00:05:16,990 --> 00:05:19,390
by broadening the
company's investments

88
00:05:19,390 --> 00:05:24,260
in advancing innovations in
immunology and important--

89
00:05:24,260 --> 00:05:27,040
increasingly important
field of research.

90
00:05:27,040 --> 00:05:29,710
We're delighted to have a
long-standing collaboration

91
00:05:29,710 --> 00:05:31,940
with Biogen, as we've
heard this morning,

92
00:05:31,940 --> 00:05:35,660
and delighted to have
you join us, Chris.

93
00:05:35,660 --> 00:05:40,760
Finally, Dr. Reshma Kewalramani
is the CEO and President

94
00:05:40,760 --> 00:05:44,450
of Vertex Pharmaceuticals, a
global biotech company that

95
00:05:44,450 --> 00:05:46,760
was founded here in Cambridge.

96
00:05:46,760 --> 00:05:49,910
Now it's headquartered
in the Boston seaport.

97
00:05:49,910 --> 00:05:52,420
Reshma is literally on her way.

98
00:05:52,420 --> 00:05:54,860
She'll be here in a
couple of minutes.

99
00:05:54,860 --> 00:05:59,060
With training in internal
medicine and nephrology

100
00:05:59,060 --> 00:06:01,990
and extensive
business experience,

101
00:06:01,990 --> 00:06:05,720
Reshma's leadership bridges
the medical, biopharmaceutical,

102
00:06:05,720 --> 00:06:08,660
and the drug
manufacturing domains.

103
00:06:08,660 --> 00:06:11,030
Using this expertise,
she has helped

104
00:06:11,030 --> 00:06:15,080
vertex from increasingly
effective cystic fibrosis

105
00:06:15,080 --> 00:06:18,830
treatments to a new
CRISPR-based gene editing

106
00:06:18,830 --> 00:06:23,060
therapy for sickle cell
disease and transfusion

107
00:06:23,060 --> 00:06:28,040
dependent beta
thalassemia that FDA

108
00:06:28,040 --> 00:06:29,930
approved within the past year.

109
00:06:29,930 --> 00:06:32,970
It's been a pleasure to work
with Reshma, who's here,

110
00:06:32,970 --> 00:06:37,140
and brainstorm how academia
and industry can work together

111
00:06:37,140 --> 00:06:38,400
in this space.

112
00:06:38,400 --> 00:06:42,120
We're very delighted to have
this incredibly distinguished

113
00:06:42,120 --> 00:06:44,310
group join us today.

114
00:06:44,310 --> 00:06:46,840
And now I will turn
it over to Noubar,

115
00:06:46,840 --> 00:06:50,207
who's going to make some opening
remarks and lead the discussion.

116
00:06:50,207 --> 00:06:53,596
[APPLAUSE]

117
00:06:53,596 --> 00:06:55,970

118
00:06:55,970 --> 00:06:58,580
Well, thank you, and I feel
like introducing Anantha

119
00:06:58,580 --> 00:07:01,700
after that very elaborate
introduction you

120
00:07:01,700 --> 00:07:03,740
made for all of us.

121
00:07:03,740 --> 00:07:05,820
Thanks for your
leadership, Anantha,

122
00:07:05,820 --> 00:07:09,010
for originating this
initiative and for allowing

123
00:07:09,010 --> 00:07:11,850
me to participate in
this very special event.

124
00:07:11,850 --> 00:07:13,850
I just want to make a
couple of framing comments

125
00:07:13,850 --> 00:07:15,930
and then we'll get right
into the discussion.

126
00:07:15,930 --> 00:07:19,790
I came to MIT in 1983 to
pursue a doctorate thesis

127
00:07:19,790 --> 00:07:22,370
at what was then the beginning
of this awkward marriage

128
00:07:22,370 --> 00:07:24,560
between engineering and biology.

129
00:07:24,560 --> 00:07:27,050
You heard about that from
Phil Sharp this morning.

130
00:07:27,050 --> 00:07:29,370
It was called biochemical
engineering at the time,

131
00:07:29,370 --> 00:07:31,430
and I had the great
honor of working

132
00:07:31,430 --> 00:07:34,250
with one of the founders
of that field, an Institute

133
00:07:34,250 --> 00:07:37,790
professor, Professor Danny Wong,
who unfortunately passed away

134
00:07:37,790 --> 00:07:39,490
a few years ago.

135
00:07:39,490 --> 00:07:43,630
I came here as an immigrant
fleeing a Civil War in Lebanon

136
00:07:43,630 --> 00:07:45,190
after a few years
in Montreal, where

137
00:07:45,190 --> 00:07:47,120
I did an undergraduate degree.

138
00:07:47,120 --> 00:07:50,810
But 40 years later,
I had the honor

139
00:07:50,810 --> 00:07:54,940
of delivering the commencement
address just this spring,

140
00:07:54,940 --> 00:07:58,130
and just as great an honor
to be here with you today

141
00:07:58,130 --> 00:08:00,510
on this very special occasion.

142
00:08:00,510 --> 00:08:03,450
As the saying goes,
what a country.

143
00:08:03,450 --> 00:08:05,400
And even more
appropriate today, what

144
00:08:05,400 --> 00:08:08,760
an Institute MIT has become.

145
00:08:08,760 --> 00:08:11,500
As a visiting committee member
in biological engineering,

146
00:08:11,500 --> 00:08:12,980
chemical engineering,
and biology,

147
00:08:12,980 --> 00:08:14,730
those of you who are
on MIT know that this

148
00:08:14,730 --> 00:08:17,170
is a very important part
of MIT'S governance,

149
00:08:17,170 --> 00:08:21,000
I've had a front row seat on
the two decade long discussion

150
00:08:21,000 --> 00:08:25,260
about how MIT should best go
about becoming more relevant

151
00:08:25,260 --> 00:08:27,160
in the biotech ecosystem.

152
00:08:27,160 --> 00:08:29,730
It is already extremely
relevant, but how could

153
00:08:29,730 --> 00:08:30,470
it do more?

154
00:08:30,470 --> 00:08:33,100
How could it be more
impactful, not only here,

155
00:08:33,100 --> 00:08:35,049
but in the whole world?

156
00:08:35,049 --> 00:08:38,690
And looking at that today and
participating in the program,

157
00:08:38,690 --> 00:08:41,799
I think that HEALS is a
very appropriate response

158
00:08:41,799 --> 00:08:43,419
to that challenge.

159
00:08:43,419 --> 00:08:47,690
As was announced by President
Sally Kornbluth this morning,

160
00:08:47,690 --> 00:08:50,320
my wife Anna and I were
pleased to contribute

161
00:08:50,320 --> 00:08:52,060
in a small way to
this initiative

162
00:08:52,060 --> 00:08:54,560
through supporting fellowships,
graduate fellowships.

163
00:08:54,560 --> 00:08:56,410
This is our way
of paying forward.

164
00:08:56,410 --> 00:08:57,468
I did a degree here.

165
00:08:57,468 --> 00:09:00,010
I have two daughters who have
done three degrees between them

166
00:09:00,010 --> 00:09:00,710
here.

167
00:09:00,710 --> 00:09:02,950
And I think that
everybody here who

168
00:09:02,950 --> 00:09:05,300
has the means to
contribute through HEALS,

169
00:09:05,300 --> 00:09:07,400
whether it's through
involvement or otherwise,

170
00:09:07,400 --> 00:09:08,840
I would urge
everybody to do that.

171
00:09:08,840 --> 00:09:11,860
This is the beginning and
it's got a long way to go.

172
00:09:11,860 --> 00:09:14,510
And Anantha didn't ask
me to make this plea,

173
00:09:14,510 --> 00:09:17,050
but I want to make it
because I think everything

174
00:09:17,050 --> 00:09:20,990
you saw today is really--
it's hard to fathom,

175
00:09:20,990 --> 00:09:23,800
but I get to see in many,
many other institutions

176
00:09:23,800 --> 00:09:25,340
similar presentations.

177
00:09:25,340 --> 00:09:27,260
And as I was saying
during one of the breaks,

178
00:09:27,260 --> 00:09:29,930
most basketball teams have
one seven foot player.

179
00:09:29,930 --> 00:09:32,930
None of them has 12
seven feet players.

180
00:09:32,930 --> 00:09:35,450
And what you saw today
were the equivalent

181
00:09:35,450 --> 00:09:39,000
of seven foot tall players
in every single area.

182
00:09:39,000 --> 00:09:42,620
So we couldn't be more pleased
with our ability to support.

183
00:09:42,620 --> 00:09:45,590
Now, as a segue to
this session, we're

184
00:09:45,590 --> 00:09:47,090
going to have a
very important topic

185
00:09:47,090 --> 00:09:48,370
to discuss to wrap up the day.

186
00:09:48,370 --> 00:09:50,370
And I wanted to share
with you one last thought,

187
00:09:50,370 --> 00:09:56,180
which is a curious, coincidental
connection between the words

188
00:09:56,180 --> 00:09:59,240
that start with the
letter C. In addition

189
00:09:59,240 --> 00:10:02,400
to curious, coincidental,
and connection, bear with me.

190
00:10:02,400 --> 00:10:04,230
I am a bit of a
geek, so I went here.

191
00:10:04,230 --> 00:10:09,050
So I call these the C's
that drive the biotech--

192
00:10:09,050 --> 00:10:11,960
world leading biotech
position of Cambridge.

193
00:10:11,960 --> 00:10:13,730
Now, let me try
these out on you.

194
00:10:13,730 --> 00:10:18,870
Concentration of capital,
culture, connections,

195
00:10:18,870 --> 00:10:22,550
creativity, community,
critical mass.

196
00:10:22,550 --> 00:10:24,600
We have the critical
mass in this field,

197
00:10:24,600 --> 00:10:26,540
in my view, bar none.

198
00:10:26,540 --> 00:10:29,760
Competition and collaboration.

199
00:10:29,760 --> 00:10:33,265
And it's that last C that this
panel will be talking about.

200
00:10:33,265 --> 00:10:35,640
We're going to do this by my
asking them a few questions,

201
00:10:35,640 --> 00:10:38,390
and then we'll have a
discussion, which I hope and I'm

202
00:10:38,390 --> 00:10:39,340
sure you'll enjoy.

203
00:10:39,340 --> 00:10:39,840
Thank you.

204
00:10:39,840 --> 00:10:43,760
[APPLAUSE]

205
00:10:43,760 --> 00:10:46,710

206
00:10:46,710 --> 00:10:49,530
So we're going to
start-- we're going

207
00:10:49,530 --> 00:10:51,520
to go down this group here.

208
00:10:51,520 --> 00:10:55,350
But let me start, Anne, with
you to talk about the research

209
00:10:55,350 --> 00:10:58,260
mission of Mass General.

210
00:10:58,260 --> 00:11:01,150
Obviously, Mass General is
a huge research institution

211
00:11:01,150 --> 00:11:04,690
in addition to being among the
best hospitals on the planet.

212
00:11:04,690 --> 00:11:07,950
How do you think about the
differences in this mission

213
00:11:07,950 --> 00:11:10,170
when that's being
done in a hospital

214
00:11:10,170 --> 00:11:13,440
setting versus academia,
and how is it different,

215
00:11:13,440 --> 00:11:14,450
how is it similar?

216
00:11:14,450 --> 00:11:15,600
Let's start with that.

217
00:11:15,600 --> 00:11:19,440
Yeah, so I love starting
with Mass General Brigham

218
00:11:19,440 --> 00:11:22,450
because we are an integrated
health care system.

219
00:11:22,450 --> 00:11:26,490
And we start and
end with patients.

220
00:11:26,490 --> 00:11:29,400
So when I think about
health care innovation, when

221
00:11:29,400 --> 00:11:30,990
I think about
collaboration, when

222
00:11:30,990 --> 00:11:34,350
I think about all of the
things that we are all here

223
00:11:34,350 --> 00:11:38,330
to think about, it
has to, in the end,

224
00:11:38,330 --> 00:11:39,973
begin and end with patience.

225
00:11:39,973 --> 00:11:41,640
So starting with the
health care system,

226
00:11:41,640 --> 00:11:43,057
thank you for that
because I think

227
00:11:43,057 --> 00:11:44,670
that is a fundamental thing.

228
00:11:44,670 --> 00:11:49,550
And just as an anecdote,
I've spent my life

229
00:11:49,550 --> 00:11:53,840
before doing this job as a
researcher, as a clinician.

230
00:11:53,840 --> 00:11:56,120
Just today, and I
do this sometimes,

231
00:11:56,120 --> 00:11:57,720
I like to walk
around the hospital.

232
00:11:57,720 --> 00:12:00,290
I can walk around Mass General,
or the Brigham, or Mass Eye

233
00:12:00,290 --> 00:12:02,100
and Ear, or McLean,
or Spaulding,

234
00:12:02,100 --> 00:12:04,020
any of the institutions
in the system.

235
00:12:04,020 --> 00:12:08,000
And it's always wonderful
to just go and walk

236
00:12:08,000 --> 00:12:10,180
on one of the floors,
talk to a few Fellows.

237
00:12:10,180 --> 00:12:12,650
I talked to a few
oncology Fellows today.

238
00:12:12,650 --> 00:12:15,360
I talked to a few nurses who
work in labor and delivery.

239
00:12:15,360 --> 00:12:16,470
What does that do?

240
00:12:16,470 --> 00:12:20,540
It grounds me, and it should
ground all of us in, ultimately,

241
00:12:20,540 --> 00:12:24,800
these phenomenal people who
are 100% focused on patients,

242
00:12:24,800 --> 00:12:26,550
whether it's through
the research they do,

243
00:12:26,550 --> 00:12:28,920
the training they do, the
clinical care they deliver.

244
00:12:28,920 --> 00:12:31,730
So I just want to
emphasize that part of it

245
00:12:31,730 --> 00:12:35,330
because I think that
is just so critical.

246
00:12:35,330 --> 00:12:38,100
To get to your question
about research,

247
00:12:38,100 --> 00:12:40,200
when we think about
the missions, certainly

248
00:12:40,200 --> 00:12:41,700
the missions of
Mass General Brigham

249
00:12:41,700 --> 00:12:43,742
and this is the missions
of so many, particularly

250
00:12:43,742 --> 00:12:45,750
in the academic
health care system,

251
00:12:45,750 --> 00:12:49,020
it's really providing the
highest level of, really,

252
00:12:49,020 --> 00:12:53,760
integrated quality care
and an academic system.

253
00:12:53,760 --> 00:12:56,010
You have to go to that
mission and tie it

254
00:12:56,010 --> 00:12:58,900
to the next mission, which
is research and innovation.

255
00:12:58,900 --> 00:13:02,520
And what distinguishes us and
other academic health care

256
00:13:02,520 --> 00:13:04,150
system is that tie.

257
00:13:04,150 --> 00:13:06,870
It's bringing the best of
research and innovation

258
00:13:06,870 --> 00:13:10,630
and infusing it, instilling
it into clinical care,

259
00:13:10,630 --> 00:13:12,540
that highest level
of clinical care.

260
00:13:12,540 --> 00:13:14,562
And the other missions,
when you think about it,

261
00:13:14,562 --> 00:13:16,020
when you think
about training, when

262
00:13:16,020 --> 00:13:17,620
you think about
servicing community,

263
00:13:17,620 --> 00:13:19,060
they all come together.

264
00:13:19,060 --> 00:13:22,570
Research is the fundamental
driver of the system.

265
00:13:22,570 --> 00:13:26,370
And we are the largest
academic health care

266
00:13:26,370 --> 00:13:29,860
system in the country
in terms of NIH funding.

267
00:13:29,860 --> 00:13:33,750
We have an enormous amount
of funding, and most of it

268
00:13:33,750 --> 00:13:35,250
is federal funding.

269
00:13:35,250 --> 00:13:37,080
I'm going to take a
pass on where that's

270
00:13:37,080 --> 00:13:38,620
going to go in the future.

271
00:13:38,620 --> 00:13:41,620
That's an important topic
very much on our minds.

272
00:13:41,620 --> 00:13:43,260
But that's not
really your question.

273
00:13:43,260 --> 00:13:46,260
Your question is, what does it
look like in an academic health

274
00:13:46,260 --> 00:13:47,320
care system?

275
00:13:47,320 --> 00:13:51,660
So I would say that research
and the, again, infusion

276
00:13:51,660 --> 00:13:53,850
of that research
into clinical care

277
00:13:53,850 --> 00:13:57,340
is what that looks like in an
academic health care system.

278
00:13:57,340 --> 00:14:00,180
Now, in contrast to many
academic health care systems

279
00:14:00,180 --> 00:14:03,420
around the country, we
are not under a university

280
00:14:03,420 --> 00:14:04,540
or a medical school.

281
00:14:04,540 --> 00:14:06,490
We are affiliated with Harvard.

282
00:14:06,490 --> 00:14:09,000
But the grants,
the research, that

283
00:14:09,000 --> 00:14:12,420
is all done on our campuses.

284
00:14:12,420 --> 00:14:16,320
That's something that I think
is very special because it ties

285
00:14:16,320 --> 00:14:19,350
together that research
mission, the researchers

286
00:14:19,350 --> 00:14:21,790
with the clinicians,
they sit together.

287
00:14:21,790 --> 00:14:26,470
And in fact, when you look
at a lot of our clinicians,

288
00:14:26,470 --> 00:14:28,690
particularly those in
the subspecialties,

289
00:14:28,690 --> 00:14:30,580
they spend a lot of
their time in research.

290
00:14:30,580 --> 00:14:35,250
So this translation of
research into those things that

291
00:14:35,250 --> 00:14:38,440
will really affect
people, the new therapies,

292
00:14:38,440 --> 00:14:42,220
the clinical trials, the new
discoveries, the new devices,

293
00:14:42,220 --> 00:14:45,780
the diagnostics, it's
being lived in real time

294
00:14:45,780 --> 00:14:47,170
at the hospitals.

295
00:14:47,170 --> 00:14:51,390
So if I think about what this
looks like in a university basis

296
00:14:51,390 --> 00:14:54,420
or in a hospital basis, I'm
putting that all together

297
00:14:54,420 --> 00:15:01,350
and saying, the phenomenal
work that gets done here at MIT

298
00:15:01,350 --> 00:15:04,650
is absolutely ripe
for that collaboration

299
00:15:04,650 --> 00:15:06,690
to come to our hospitals.

300
00:15:06,690 --> 00:15:10,960
But every day these things
are a real life laboratory.

301
00:15:10,960 --> 00:15:14,190
So taking all of the
work that goes on

302
00:15:14,190 --> 00:15:16,420
and bringing it to
another laboratory,

303
00:15:16,420 --> 00:15:18,610
that is the clinical laboratory.

304
00:15:18,610 --> 00:15:20,910
And I think, sometimes,
the challenge,

305
00:15:20,910 --> 00:15:25,150
when we think about this,
is they're still in pieces.

306
00:15:25,150 --> 00:15:29,280
And some of it is a bit
of linguistic dissonance

307
00:15:29,280 --> 00:15:32,040
because the language
of the basic scientists

308
00:15:32,040 --> 00:15:34,060
may not be the
language of clinicians.

309
00:15:34,060 --> 00:15:35,940
We hear a lot about that.

310
00:15:35,940 --> 00:15:38,230
These are things that
you can overcome.

311
00:15:38,230 --> 00:15:41,220
But living all of
that together means

312
00:15:41,220 --> 00:15:44,310
that every day, top
of mind for the people

313
00:15:44,310 --> 00:15:49,330
who are delivering care, who are
trying to solve those problems,

314
00:15:49,330 --> 00:15:53,290
are deeply embedded,
living with, connected to.

315
00:15:53,290 --> 00:15:57,660
And it can be a
geographical collaboration,

316
00:15:57,660 --> 00:15:59,000
a conceptual collaboration.

317
00:15:59,000 --> 00:16:01,250
There are many, many different
forms of collaboration.

318
00:16:01,250 --> 00:16:02,833
I'm looking at that
word collaboration

319
00:16:02,833 --> 00:16:06,020
and thinking of the many,
many things that means.

320
00:16:06,020 --> 00:16:07,820
Some begin with a C, some don't.

321
00:16:07,820 --> 00:16:10,750
And just thinking
about what we can

322
00:16:10,750 --> 00:16:15,850
create with a university
like MIT, and part of it

323
00:16:15,850 --> 00:16:16,730
is the people.

324
00:16:16,730 --> 00:16:18,410
You bring the people together.

325
00:16:18,410 --> 00:16:20,000
Part of it is the ideas.

326
00:16:20,000 --> 00:16:23,900
But I have found,
certainly in our system,

327
00:16:23,900 --> 00:16:27,130
the way to get the best
and the brightest people

328
00:16:27,130 --> 00:16:31,750
working together is to give
them a problem to solve.

329
00:16:31,750 --> 00:16:33,950
You give them a
problem to solve,

330
00:16:33,950 --> 00:16:37,090
and that's where you get
the energy, the passion,

331
00:16:37,090 --> 00:16:39,490
and the talent working together.

332
00:16:39,490 --> 00:16:43,600
So basically, we're going to
try to fill in the Charles

333
00:16:43,600 --> 00:16:46,673
River between MIT
and MGB and increase

334
00:16:46,673 --> 00:16:47,840
the lanes on the Longfellow.

335
00:16:47,840 --> 00:16:50,570
That's basically what we
have to do with HEALS.

336
00:16:50,570 --> 00:16:53,245
We can get the urban
planning folks involved in--

337
00:16:53,245 --> 00:16:55,188
They will solve that for us.

338
00:16:55,188 --> 00:16:55,730
That's right.

339
00:16:55,730 --> 00:16:58,300
So the other thing we
heard on the introduction

340
00:16:58,300 --> 00:17:02,920
was that MGB itself is heavily
involved in a lot of translation

341
00:17:02,920 --> 00:17:04,490
and a lot of companies.

342
00:17:04,490 --> 00:17:07,960
How is MGB going about
thinking about another form

343
00:17:07,960 --> 00:17:10,900
of collaboration, which
is between industry

344
00:17:10,900 --> 00:17:13,990
startups and the kind of
science that's done there?

345
00:17:13,990 --> 00:17:15,050
It's interesting.

346
00:17:15,050 --> 00:17:18,829
I was the Chief Academic Officer
before taking on this role,

347
00:17:18,829 --> 00:17:22,369
and that was back in 2012.

348
00:17:22,369 --> 00:17:25,210
And when I started,
I had spent my life

349
00:17:25,210 --> 00:17:27,400
as a researcher
and most of my work

350
00:17:27,400 --> 00:17:31,880
was NIH funded, although
because I was in rare diseases,

351
00:17:31,880 --> 00:17:34,700
I was very interested in
partnering with industry.

352
00:17:34,700 --> 00:17:38,200
So I had a lot of collaborations
going with industry because I

353
00:17:38,200 --> 00:17:41,135
knew that for rare
diseases, you really

354
00:17:41,135 --> 00:17:43,510
weren't going to get anywhere
unless they had an industry

355
00:17:43,510 --> 00:17:44,300
collaboration.

356
00:17:44,300 --> 00:17:45,710
That was sort of a given.

357
00:17:45,710 --> 00:17:48,960
And I think when I
think now about MGB

358
00:17:48,960 --> 00:17:50,710
and how it's thinking
about it, the reason

359
00:17:50,710 --> 00:17:53,890
I'm going back to 2012
is because I really

360
00:17:53,890 --> 00:17:56,920
think there has been a cultural
transformation in the thinking

361
00:17:56,920 --> 00:18:00,380
of a lot of our scientists,
and that's not unique to MGB.

362
00:18:00,380 --> 00:18:05,480
And there are a lot of ideas
about why that is taking place.

363
00:18:05,480 --> 00:18:08,240
But let me start by
what is taking place.

364
00:18:08,240 --> 00:18:12,080
The cultural transformation for
many, many of our investigators,

365
00:18:12,080 --> 00:18:15,130
and we, again, have thousands
of investigators, many of them

366
00:18:15,130 --> 00:18:21,610
have spent their lives focused
on the research in a singularly

367
00:18:21,610 --> 00:18:26,260
focused way, which if you
think about where it leads to--

368
00:18:26,260 --> 00:18:29,890
and this is what I was
taught when I was first

369
00:18:29,890 --> 00:18:34,390
doing my training after clinical
fellowship-- it leads to grants.

370
00:18:34,390 --> 00:18:35,360
That's good.

371
00:18:35,360 --> 00:18:36,680
Ideas lead to grants.

372
00:18:36,680 --> 00:18:40,550
And that leads to papers and
that leads to promotions.

373
00:18:40,550 --> 00:18:43,160
That leads to an
academic reputation.

374
00:18:43,160 --> 00:18:46,690
That leads to making
important discoveries

375
00:18:46,690 --> 00:18:49,250
in a field, whether basic,
whether they're translational,

376
00:18:49,250 --> 00:18:50,330
no matter what they are.

377
00:18:50,330 --> 00:18:55,790
So the end was that piece of
scholarly work and its impact.

378
00:18:55,790 --> 00:18:59,810
The shift is to broaden out
what impact really means.

379
00:18:59,810 --> 00:19:03,490
And I think the cultural
shift among many--

380
00:19:03,490 --> 00:19:05,590
and it's interesting,
some of the surgeons

381
00:19:05,590 --> 00:19:06,620
were way ahead of this.

382
00:19:06,620 --> 00:19:09,550
They would come up with
ideas and they were more

383
00:19:09,550 --> 00:19:12,050
keen on seeing that instrument.

384
00:19:12,050 --> 00:19:13,430
What's that new instrument?

385
00:19:13,430 --> 00:19:15,070
How do I operate better?

386
00:19:15,070 --> 00:19:17,510
What is that invention that
will make things happen?

387
00:19:17,510 --> 00:19:19,703
There were always a bit
more focused on that.

388
00:19:19,703 --> 00:19:21,120
I don't want to
overly generalize,

389
00:19:21,120 --> 00:19:22,440
but that's what I was saying.

390
00:19:22,440 --> 00:19:24,920
But it was really getting
all of those investigators

391
00:19:24,920 --> 00:19:28,670
to understand the full
life cycle of an idea

392
00:19:28,670 --> 00:19:31,440
and how to have the
biggest impact on patients.

393
00:19:31,440 --> 00:19:33,860
And that, I think, was
a very different way

394
00:19:33,860 --> 00:19:35,870
of thinking about
industry, thinking

395
00:19:35,870 --> 00:19:38,190
about pharmaceutical
companies, startups,

396
00:19:38,190 --> 00:19:42,830
how do you actually take that
idea and bring it to patients?

397
00:19:42,830 --> 00:19:44,550
You can't do that by yourself.

398
00:19:44,550 --> 00:19:46,920
You can't do that
only with a grant.

399
00:19:46,920 --> 00:19:49,820
What you have to do is have
those critical partnerships

400
00:19:49,820 --> 00:19:53,640
and go through the
life cycle of an idea.

401
00:19:53,640 --> 00:19:57,410
And it has to go to a company
or start a company or a partner

402
00:19:57,410 --> 00:19:58,770
with a company.

403
00:19:58,770 --> 00:20:01,350
You need to get a
product in the end,

404
00:20:01,350 --> 00:20:04,610
whether it's a drug or
a device, whether it's

405
00:20:04,610 --> 00:20:06,800
an algorithm,
something that then you

406
00:20:06,800 --> 00:20:08,400
can bring back to patients.

407
00:20:08,400 --> 00:20:10,700
And I think for our
investigators, particularly

408
00:20:10,700 --> 00:20:13,040
those who are more
translational, but also,

409
00:20:13,040 --> 00:20:16,430
some of the more basic
science investigators, that

410
00:20:16,430 --> 00:20:20,510
understanding that if you really
wanted to impact human health,

411
00:20:20,510 --> 00:20:23,470
you had to think more
broadly, and I would just say,

412
00:20:23,470 --> 00:20:24,620
complete the circle.

413
00:20:24,620 --> 00:20:26,840
So that's the cultural
change that took place.

414
00:20:26,840 --> 00:20:28,490
And I think at Mass
General Brigham,

415
00:20:28,490 --> 00:20:32,900
it is just now fundamental and
very much core to who we are.

416
00:20:32,900 --> 00:20:35,750
I would also say that if you
look at a lot of our trainees,

417
00:20:35,750 --> 00:20:37,250
they're already there.

418
00:20:37,250 --> 00:20:38,690
They don't need it.

419
00:20:38,690 --> 00:20:39,770
They're already there.

420
00:20:39,770 --> 00:20:41,720
They come in and they're
already thinking,

421
00:20:41,720 --> 00:20:43,640
how do I take this idea?

422
00:20:43,640 --> 00:20:45,140
Where does it go?

423
00:20:45,140 --> 00:20:46,700
What's the result of it?

424
00:20:46,700 --> 00:20:49,160
How do you partner?

425
00:20:49,160 --> 00:20:52,520
And some will actually start
companies and go there.

426
00:20:52,520 --> 00:20:54,070
Some will join industry.

427
00:20:54,070 --> 00:20:56,480
People have very
different career paths.

428
00:20:56,480 --> 00:20:59,290
But I think it speaks to
the broadening of what

429
00:20:59,290 --> 00:21:02,950
that circle looks like and
the interdependencies of all

430
00:21:02,950 --> 00:21:04,490
these different sectors.

431
00:21:04,490 --> 00:21:07,820
So the concept is
academics are not

432
00:21:07,820 --> 00:21:09,400
an endpoint in and of itself.

433
00:21:09,400 --> 00:21:10,190
Super.

434
00:21:10,190 --> 00:21:15,570
Bob, you cover a lot of these
same topics from the MIT angle.

435
00:21:15,570 --> 00:21:19,620
You run a lab that does basic
research, applied research,

436
00:21:19,620 --> 00:21:22,700
engineering, translation,
and a lot more.

437
00:21:22,700 --> 00:21:24,520
But you didn't
start out that way.

438
00:21:24,520 --> 00:21:30,410
So how and when did unmet
clinical need and translation

439
00:21:30,410 --> 00:21:33,390
get into the way you think
about research directions?

440
00:21:33,390 --> 00:21:36,410
And also, how would
you-- because we

441
00:21:36,410 --> 00:21:38,510
saw a lot of younger
academics who

442
00:21:38,510 --> 00:21:41,500
don't come in with connections
to the clinical world,

443
00:21:41,500 --> 00:21:44,720
how have you forged these
kinds of relationships

444
00:21:44,720 --> 00:21:46,170
with the clinical world?

445
00:21:46,170 --> 00:21:48,620
Yeah, well, it's
a great question.

446
00:21:48,620 --> 00:21:50,730
So for me, I mean,
Noubar knows this,

447
00:21:50,730 --> 00:21:56,720
but I got my degree in chemical
engineering in 1974 at MIT.

448
00:21:56,720 --> 00:22:00,260
And then, when I got it,
almost all my colleagues

449
00:22:00,260 --> 00:22:01,830
went to work for oil companies.

450
00:22:01,830 --> 00:22:04,850
They had a lot of jobs
that paid a lot of money.

451
00:22:04,850 --> 00:22:07,660
Anyhow, I ended up doing
something very different.

452
00:22:07,660 --> 00:22:11,860
I wasn't that excited about the
oil companies and I had lots--

453
00:22:11,860 --> 00:22:17,520
and I ended up getting a job as
a postdoc at Children's Hospital

454
00:22:17,520 --> 00:22:19,230
with a surgeon
named Judah Folkman.

455
00:22:19,230 --> 00:22:21,730
And by the way, for chemical
engineers at that time,

456
00:22:21,730 --> 00:22:24,670
nobody did anything like that
because it paid so much less

457
00:22:24,670 --> 00:22:29,020
and it also didn't look like
a very smart career move

458
00:22:29,020 --> 00:22:31,330
according to everybody
that I talked to.

459
00:22:31,330 --> 00:22:33,820
But I was fascinated by it.

460
00:22:33,820 --> 00:22:36,540
And so I went there
and I was actually

461
00:22:36,540 --> 00:22:39,130
the only engineer in the
hospital at the time,

462
00:22:39,130 --> 00:22:41,640
and certainly, in
the surgery lab.

463
00:22:41,640 --> 00:22:44,640
And the way I got
started, he had this idea

464
00:22:44,640 --> 00:22:46,333
that if you could
stop blood vessels,

465
00:22:46,333 --> 00:22:48,000
that maybe that would
be a whole new way

466
00:22:48,000 --> 00:22:50,620
to think about treating cancer.

467
00:22:50,620 --> 00:22:51,120
people.

468
00:22:51,120 --> 00:22:52,330
Thought he was crazy.

469
00:22:52,330 --> 00:22:54,070
They didn't think
that made any sense.

470
00:22:54,070 --> 00:22:56,500
But at any rate, there
was no way to study it.

471
00:22:56,500 --> 00:22:58,260
And so what I--

472
00:22:58,260 --> 00:23:01,170
so we had to develop
what's called a bioassay.

473
00:23:01,170 --> 00:23:04,240
And to do that,
we had to create,

474
00:23:04,240 --> 00:23:06,060
we thought, tiny
little particles

475
00:23:06,060 --> 00:23:08,110
that could deliver
a large molecules.

476
00:23:08,110 --> 00:23:11,940
And Dr. Folkman would
talk to different experts.

477
00:23:11,940 --> 00:23:14,800
At that point, drug delivery
was hardly done at all.

478
00:23:14,800 --> 00:23:17,590
There was only one company
in the world working on it

479
00:23:17,590 --> 00:23:19,350
and he went-- he was
an advisor to them

480
00:23:19,350 --> 00:23:21,010
and he asked them
if they could help.

481
00:23:21,010 --> 00:23:23,160
And they just said this
delivering a large molecule

482
00:23:23,160 --> 00:23:24,160
would be impossible.

483
00:23:24,160 --> 00:23:26,740
Anyway, I spent several
years working on it,

484
00:23:26,740 --> 00:23:28,330
failed hundreds of times.

485
00:23:28,330 --> 00:23:32,020
But finally, got a
way to get it to work.

486
00:23:32,020 --> 00:23:35,940
And then, we published
articles in Nature in 1976

487
00:23:35,940 --> 00:23:37,890
showing that you could
for the first time

488
00:23:37,890 --> 00:23:40,900
deliver large molecules,
including it was the first paper

489
00:23:40,900 --> 00:23:42,460
to deliver nucleic acids.

490
00:23:42,460 --> 00:23:45,480
And also, we published a
paper the same year in Science

491
00:23:45,480 --> 00:23:49,860
showing that you could use
it to stop blood vessels.

492
00:23:49,860 --> 00:23:54,720
So that was kind of my
first taste of everything.

493
00:23:54,720 --> 00:23:58,560
And of course, it took many,
many years before those--

494
00:23:58,560 --> 00:24:01,265
I mean, the first one took
Genentech doing great work

495
00:24:01,265 --> 00:24:02,640
building on some
of the things we

496
00:24:02,640 --> 00:24:06,670
did before that would lead to
Avastin and many other drugs.

497
00:24:06,670 --> 00:24:08,700
Second one, of
course, that's where

498
00:24:08,700 --> 00:24:11,550
I got involved in starting
some companies, including

499
00:24:11,550 --> 00:24:14,970
a number with you, Noubar,
using drug delivery

500
00:24:14,970 --> 00:24:18,430
techniques to protect and
deliver different molecules,

501
00:24:18,430 --> 00:24:20,460
including messenger RNA.

502
00:24:20,460 --> 00:24:26,110
And Noubar and I
have shared that.

503
00:24:26,110 --> 00:24:27,720
But the thing is to
try to figure out

504
00:24:27,720 --> 00:24:30,250
what the applications are,
That's, a team effort.

505
00:24:30,250 --> 00:24:34,920
I mean, all these things have
very broad potential uses

506
00:24:34,920 --> 00:24:38,580
and figuring out what the ones
that are going to be important

507
00:24:38,580 --> 00:24:40,120
you don't necessarily know.

508
00:24:40,120 --> 00:24:42,940
Certainly, when we publish
those papers in 1976,

509
00:24:42,940 --> 00:24:45,540
we had, obviously, no
idea that messenger RNA

510
00:24:45,540 --> 00:24:48,660
would be important, that
COVID would even exist.

511
00:24:48,660 --> 00:24:53,950
And so, really, it ends up being
a team effort over the years.

512
00:24:53,950 --> 00:24:56,370
And also, to go over part
of your question, what

513
00:24:56,370 --> 00:25:00,240
was great for me personally
was being in a hospital

514
00:25:00,240 --> 00:25:02,980
with a lot of clinicians
working next door to them,

515
00:25:02,980 --> 00:25:05,850
and it would lead to
more and more ideas.

516
00:25:05,850 --> 00:25:08,700
And some of them are
my best friends, even

517
00:25:08,700 --> 00:25:10,650
today, 50 years later.

518
00:25:10,650 --> 00:25:13,110
So another one was
Jay Vacanti, who

519
00:25:13,110 --> 00:25:15,450
started at Children's
and went to Mass General.

520
00:25:15,450 --> 00:25:17,140
He came to see me one
day and said, Bob,

521
00:25:17,140 --> 00:25:18,730
could we make new
tissues and organs?

522
00:25:18,730 --> 00:25:20,430
And we came up with
this idea that would

523
00:25:20,430 --> 00:25:22,060
lead to tissue engineering.

524
00:25:22,060 --> 00:25:23,980
And again, we didn't
the right applications.

525
00:25:23,980 --> 00:25:25,397
He was talking
about liver, but it

526
00:25:25,397 --> 00:25:27,280
would lead to a lot
of other things,

527
00:25:27,280 --> 00:25:29,410
including organs and
tissues on a chip.

528
00:25:29,410 --> 00:25:32,520
And of course, the other
great thing about what's

529
00:25:32,520 --> 00:25:34,830
happened in terms
of clinical things,

530
00:25:34,830 --> 00:25:37,120
and this is, I think,
the beauty of Boston,

531
00:25:37,120 --> 00:25:39,550
you have MIT and all
of the hospitals.

532
00:25:39,550 --> 00:25:42,880
You get all these
incredible Fellows

533
00:25:42,880 --> 00:25:46,120
who come to your lab for
several years from Mass General,

534
00:25:46,120 --> 00:25:49,080
from the Brigham, from
Children's Hospital and Beth

535
00:25:49,080 --> 00:25:50,010
Israel.

536
00:25:50,010 --> 00:25:53,640
Jeez, I mean, I've probably
had about 20 or 30 summer,

537
00:25:53,640 --> 00:25:56,910
[INAUDIBLE] Traverso,
professors at MIT now

538
00:25:56,910 --> 00:26:00,120
and some have started companies.

539
00:26:00,120 --> 00:26:02,730
So it's just been-- so
you just get ingrained

540
00:26:02,730 --> 00:26:05,220
in that because of all
the great people around.

541
00:26:05,220 --> 00:26:08,290
So on the company
side, then, you also

542
00:26:08,290 --> 00:26:11,810
have been a prolific founder
of a number of companies.

543
00:26:11,810 --> 00:26:14,650
And I'd say probably
so much so that it

544
00:26:14,650 --> 00:26:19,190
must affect how you train your
students and the postdocs,

545
00:26:19,190 --> 00:26:20,870
or at least what
exposure they get.

546
00:26:20,870 --> 00:26:22,780
Because if they
want to be like you,

547
00:26:22,780 --> 00:26:25,030
most academics who
don't do startups

548
00:26:25,030 --> 00:26:27,760
have their graduate
students and postdocs

549
00:26:27,760 --> 00:26:29,450
being trained to be like them.

550
00:26:29,450 --> 00:26:31,420
Well, in your case,
they also need

551
00:26:31,420 --> 00:26:32,920
to learn how to
start companies, how

552
00:26:32,920 --> 00:26:35,050
to influence large companies.

553
00:26:35,050 --> 00:26:36,730
I ask it seriously.

554
00:26:36,730 --> 00:26:40,540
How do you think you
have incorporated or have

555
00:26:40,540 --> 00:26:43,390
you some of the things you have
learned in the startup world

556
00:26:43,390 --> 00:26:47,020
into the way you actually train
the students and run your lab?

557
00:26:47,020 --> 00:26:50,410
Yeah, well, I mean,
part of it to me is--

558
00:26:50,410 --> 00:26:52,730
I don't know that
I do that much,

559
00:26:52,730 --> 00:26:55,070
but I think probably--
as my wife would say,

560
00:26:55,070 --> 00:26:57,200
I'm probably the opposite
of a micromanager.

561
00:26:57,200 --> 00:27:00,400
I try to come up with
big ideas and give people

562
00:27:00,400 --> 00:27:04,540
a lot of freedom, but with
clear objectives in mind

563
00:27:04,540 --> 00:27:08,400
and try to get big
papers and big patents.

564
00:27:08,400 --> 00:27:11,660
And that does happen,
to your point.

565
00:27:11,660 --> 00:27:15,110
But people see,
it's not just me.

566
00:27:15,110 --> 00:27:18,680
I mean, Noubar, again,
knows a lot of this.

567
00:27:18,680 --> 00:27:22,070
I started a couple
companies back in the '80s.

568
00:27:22,070 --> 00:27:26,580
And then, like Jay Vacanti,
he said, well, can we do one?

569
00:27:26,580 --> 00:27:28,860
And then, I had this
postdoc, David Edwards,

570
00:27:28,860 --> 00:27:32,450
who you know and he said,
well, Bob, I want to--

571
00:27:32,450 --> 00:27:34,260
people-- so it kind
of gets ingrained.

572
00:27:34,260 --> 00:27:35,370
And so it's not just me.

573
00:27:35,370 --> 00:27:38,180
People see the older graduate
students and postdocs

574
00:27:38,180 --> 00:27:41,550
and colleagues doing it,
and it kind of just happens.

575
00:27:41,550 --> 00:27:44,480
I think, a lot of times with
companies, people don't--

576
00:27:44,480 --> 00:27:47,910
like if you go to some
other universities,

577
00:27:47,910 --> 00:27:50,310
they think it's like,
how could you ever do it?

578
00:27:50,310 --> 00:27:51,930
It just seems almost impossible.

579
00:27:51,930 --> 00:27:55,230
But when they see people a few
years older than them do it,

580
00:27:55,230 --> 00:27:57,630
they think, well, yeah,
that could be nice.

581
00:27:57,630 --> 00:27:59,450
And when we started,
I think it was

582
00:27:59,450 --> 00:28:01,902
AIR, which was David started.

583
00:28:01,902 --> 00:28:03,860
Jeez, I don't know how
many people from the lab

584
00:28:03,860 --> 00:28:06,680
when they graduated went
there and they ended up

585
00:28:06,680 --> 00:28:08,520
doing very well.

586
00:28:08,520 --> 00:28:11,520
And so I think it just--
they'd see that by example.

587
00:28:11,520 --> 00:28:13,990
And then, finally, we
have great seminars

588
00:28:13,990 --> 00:28:18,570
as we had Noubar once give us a
lecture and I still remember it.

589
00:28:18,570 --> 00:28:20,330
He starts out about
entrepreneurship

590
00:28:20,330 --> 00:28:24,800
and how everything, really,
with entrepreneurship, almost

591
00:28:24,800 --> 00:28:27,170
every scientific-- every
scientific discipline

592
00:28:27,170 --> 00:28:29,700
is really embedded in that.

593
00:28:29,700 --> 00:28:32,060
And some of the examples
of the things that you did.

594
00:28:32,060 --> 00:28:36,000
And sometimes, with me,
sometimes with many others.

595
00:28:36,000 --> 00:28:37,430
And I think people
just see that.

596
00:28:37,430 --> 00:28:38,880
And I think that--

597
00:28:38,880 --> 00:28:42,080
so having role models, I think,
ends up being a really big deal.

598
00:28:42,080 --> 00:28:44,420
Super, Chris.

599
00:28:44,420 --> 00:28:46,310
You've been in large
companies, you're

600
00:28:46,310 --> 00:28:48,480
in a slightly less
large company,

601
00:28:48,480 --> 00:28:52,040
but it's still really
large compared to startups,

602
00:28:52,040 --> 00:28:55,130
and you've done a lot in
the various hats you've worn

603
00:28:55,130 --> 00:28:58,160
partnerships with academia.

604
00:28:58,160 --> 00:29:01,800
Talk about what you've
seen works in that arena,

605
00:29:01,800 --> 00:29:03,350
the value of such partnerships.

606
00:29:03,350 --> 00:29:06,930
We're in the collaboration
section of this day.

607
00:29:06,930 --> 00:29:10,010
It'd be great to get your
insights on that, plus maybe

608
00:29:10,010 --> 00:29:14,300
some things that you've found
over the years doesn't work.

609
00:29:14,300 --> 00:29:17,960
Yeah, I mean, Andrew Lowe
gave a really nice synthesis

610
00:29:17,960 --> 00:29:19,880
about how drugs get developed.

611
00:29:19,880 --> 00:29:22,400
And there is
certainly, OK, you have

612
00:29:22,400 --> 00:29:24,540
to have some idea of
what causes a disease.

613
00:29:24,540 --> 00:29:26,207
And, then you're going
to find a target.

614
00:29:26,207 --> 00:29:28,710
You find a molecule and
you do a clinical trial.

615
00:29:28,710 --> 00:29:32,660
But in actual fact,
there's just a never ending

616
00:29:32,660 --> 00:29:36,170
series of puzzles that
present themselves to which

617
00:29:36,170 --> 00:29:37,440
you have to find an answer.

618
00:29:37,440 --> 00:29:40,760
And pretty much developing any--

619
00:29:40,760 --> 00:29:42,890
particularly first
in class drug,

620
00:29:42,890 --> 00:29:46,040
there is no pathway to follow.

621
00:29:46,040 --> 00:29:48,450
And even if you find
a molecule, well,

622
00:29:48,450 --> 00:29:50,240
how do I deliver the molecule?

623
00:29:50,240 --> 00:29:53,070
If it's a small molecule,
how do I make it soluble?

624
00:29:53,070 --> 00:29:55,100
I mean, do I need a device?

625
00:29:55,100 --> 00:29:56,780
What's an endpoint?

626
00:29:56,780 --> 00:29:58,910
Even if I have a
molecule, how am I

627
00:29:58,910 --> 00:30:03,210
going to measure whether
this is working or not?

628
00:30:03,210 --> 00:30:07,460
Even if I know that, then I
might have another problem here

629
00:30:07,460 --> 00:30:12,290
to solve on scaling up in
manufacturing, for example.

630
00:30:12,290 --> 00:30:16,310
We heard the presentation
earlier about nanoparticles

631
00:30:16,310 --> 00:30:19,940
and what a role that played
in getting mRNA, actually,

632
00:30:19,940 --> 00:30:22,790
to where it needs to go
to make the mRNA vaccine.

633
00:30:22,790 --> 00:30:25,520
So even after we figured
out mRNA and what it does,

634
00:30:25,520 --> 00:30:27,570
we still had to deliver it.

635
00:30:27,570 --> 00:30:33,650
And so when you're
in the company,

636
00:30:33,650 --> 00:30:36,660
you're really focused
on value creation,

637
00:30:36,660 --> 00:30:39,570
as we heard from one of the
entrepreneurs this afternoon.

638
00:30:39,570 --> 00:30:41,962
So your job is really
trying to take that molecule

639
00:30:41,962 --> 00:30:43,670
and move it as fast,
but you don't really

640
00:30:43,670 --> 00:30:47,090
have the capacity to do an
awful lot of basic research

641
00:30:47,090 --> 00:30:49,170
and a lot of discovery research.

642
00:30:49,170 --> 00:30:51,590
But in some ways, a
lot of these things

643
00:30:51,590 --> 00:30:53,970
you have to discover
just to solve them.

644
00:30:53,970 --> 00:30:56,597
And that's where you
need these partnerships.

645
00:30:56,597 --> 00:30:57,930
How do you solve these problems?

646
00:30:57,930 --> 00:31:00,140
And you're not going to
always have the capability

647
00:31:00,140 --> 00:31:02,160
inside your own company.

648
00:31:02,160 --> 00:31:05,100
Now, a lot of companies
do think they need that,

649
00:31:05,100 --> 00:31:08,610
and that sometimes is a problem.

650
00:31:08,610 --> 00:31:10,850
But generally, I mean, you
look at all the cool stuff

651
00:31:10,850 --> 00:31:14,000
we heard today and all the
different technologies.

652
00:31:14,000 --> 00:31:17,520
And you think about,
Bob, you haven't just

653
00:31:17,520 --> 00:31:19,140
developed molecules,
you've developed

654
00:31:19,140 --> 00:31:20,830
how to get things to places.

655
00:31:20,830 --> 00:31:23,040
And that's where you
got to figure out,

656
00:31:23,040 --> 00:31:27,210
what's the right combination of
people who are trying to drive

657
00:31:27,210 --> 00:31:30,990
something to an endpoint and
people who are really having

658
00:31:30,990 --> 00:31:34,500
the time and maybe the risk
capital or the government

659
00:31:34,500 --> 00:31:38,190
capital to actually solve some
of these basic problems that

660
00:31:38,190 --> 00:31:39,250
need to be done?

661
00:31:39,250 --> 00:31:43,050
Now, it happens to happen is
some level of trust has to exist

662
00:31:43,050 --> 00:31:45,400
and a sense of common purpose.

663
00:31:45,400 --> 00:31:49,270
And you were saying it starts
and ends with the patient.

664
00:31:49,270 --> 00:31:53,460
And that has to be for
everybody in the chain.

665
00:31:53,460 --> 00:31:58,420
You can get hung up on things
like intellectual property,

666
00:31:58,420 --> 00:32:02,110
for example, can get in the way
of some of these collaborations.

667
00:32:02,110 --> 00:32:03,870
And that's where a
certain amount of trust

668
00:32:03,870 --> 00:32:05,760
is going to be needed
to try to figure out,

669
00:32:05,760 --> 00:32:08,200
how do we share some
of these things?

670
00:32:08,200 --> 00:32:11,250
Because if different people
and different organizations

671
00:32:11,250 --> 00:32:13,390
are solving different
parts of the problem,

672
00:32:13,390 --> 00:32:16,030
somewhere there has to
be return on all of that.

673
00:32:16,030 --> 00:32:19,530
Otherwise, they
can't survive either.

674
00:32:19,530 --> 00:32:25,633
And so, sometimes, that might
be an advisor at Mass General

675
00:32:25,633 --> 00:32:27,300
and they're doing
clinical trials for us

676
00:32:27,300 --> 00:32:30,310
and they can advise us how
to-- where's the unmet need?

677
00:32:30,310 --> 00:32:32,530
How should we design
this clinical trial?

678
00:32:32,530 --> 00:32:36,230
It might be coming to MIT to
solve some of these delivery

679
00:32:36,230 --> 00:32:36,730
problems.

680
00:32:36,730 --> 00:32:39,150
So there's sort
of a never ending

681
00:32:39,150 --> 00:32:41,110
series of these collaborations.

682
00:32:41,110 --> 00:32:44,340
It's not just one project.

683
00:32:44,340 --> 00:32:49,610
It is creating a porosity almost
between the organizations.

684
00:32:49,610 --> 00:32:55,630
Now, you also find that all
of this depends on people.

685
00:32:55,630 --> 00:32:59,040
And I always say,
running companies

686
00:32:59,040 --> 00:33:01,930
would be easy if it weren't
for all the people inside them.

687
00:33:01,930 --> 00:33:04,050
[LAUGHTER]

688
00:33:04,050 --> 00:33:07,690
And people really create
the complexities in this.

689
00:33:07,690 --> 00:33:09,550
And you get egos involved.

690
00:33:09,550 --> 00:33:13,650
You get different incentives
that are not aligned,

691
00:33:13,650 --> 00:33:15,540
and that can cause problems.

692
00:33:15,540 --> 00:33:16,680
Personalities.

693
00:33:16,680 --> 00:33:20,870
And so there has to be, in some
ways, some sort of alliance

694
00:33:20,870 --> 00:33:26,270
management, generally, to try
to smooth those problems out.

695
00:33:26,270 --> 00:33:28,940
One of the things that
you don't want to create

696
00:33:28,940 --> 00:33:32,520
is a sense of one is a
subcontractor to another.

697
00:33:32,520 --> 00:33:38,360
There has to be a respect for
the intellect, the talent,

698
00:33:38,360 --> 00:33:42,470
the capability on both
sides of a collaboration

699
00:33:42,470 --> 00:33:46,680
to say, OK, we are not going
to succeed without the other.

700
00:33:46,680 --> 00:33:50,270
So you have to create a lot
of the right people dynamics

701
00:33:50,270 --> 00:33:51,420
to make this as well.

702
00:33:51,420 --> 00:33:52,850
Sometimes we can
get carried away

703
00:33:52,850 --> 00:33:57,260
with the science or the
problem, but the number

704
00:33:57,260 --> 00:33:58,700
of times I've seen
collaborations

705
00:33:58,700 --> 00:34:01,280
that don't work that just come
back to basic people problems

706
00:34:01,280 --> 00:34:02,550
is a real issue.

707
00:34:02,550 --> 00:34:06,510
And so, certainly,
whenever we start one,

708
00:34:06,510 --> 00:34:10,880
create the relationship and
build the relationship over time

709
00:34:10,880 --> 00:34:14,210
and build it on the respect
and capability of what

710
00:34:14,210 --> 00:34:15,389
the other brings.

711
00:34:15,389 --> 00:34:18,030
But as I say, if
you don't do that,

712
00:34:18,030 --> 00:34:19,699
you're never going
to get to the end

713
00:34:19,699 --> 00:34:22,040
because these
collaborations just don't

714
00:34:22,040 --> 00:34:25,010
start at the very beginning.

715
00:34:25,010 --> 00:34:27,060
Because in Andrew's
model, it was sort of,

716
00:34:27,060 --> 00:34:28,940
hey, there's the idea,
you create the patent,

717
00:34:28,940 --> 00:34:30,570
and then, it goes
to the companies.

718
00:34:30,570 --> 00:34:34,230
Well, it's not quite so simple.

719
00:34:34,230 --> 00:34:36,780
It's these constant
collaborations.

720
00:34:36,780 --> 00:34:39,989
And that's why I think it's so
helpful to be in this ecosystem.

721
00:34:39,989 --> 00:34:42,949
Biogen is across
the street from MIT.

722
00:34:42,949 --> 00:34:46,159
We're across the river from MGH.

723
00:34:46,159 --> 00:34:50,280
And when you talk about
those relationships,

724
00:34:50,280 --> 00:34:53,030
that makes it a whole lot easier
when people know each other

725
00:34:53,030 --> 00:34:54,989
and see each other all the time.

726
00:34:54,989 --> 00:34:58,100
And I do think that is
this proximity of all

727
00:34:58,100 --> 00:35:00,500
of the talent and
people that we have

728
00:35:00,500 --> 00:35:04,290
make those people issues a
whole lot easier to deal with.

729
00:35:04,290 --> 00:35:05,720
And I think that's what--

730
00:35:05,720 --> 00:35:07,670
since collaboration
is so critical

731
00:35:07,670 --> 00:35:09,180
and people issues
are so critical,

732
00:35:09,180 --> 00:35:12,450
I think that's what makes
this work here super.

733
00:35:12,450 --> 00:35:16,620
And Reshma, you're are
leading a native kind

734
00:35:16,620 --> 00:35:19,200
of Cambridge-born
company, Vertex,

735
00:35:19,200 --> 00:35:21,570
one of the great
standout successes

736
00:35:21,570 --> 00:35:26,160
of the biotech industry,
really, in the biotech era.

737
00:35:26,160 --> 00:35:27,972
You're not literally
in Cambridge,

738
00:35:27,972 --> 00:35:29,430
but you're in the
greater Cambridge

739
00:35:29,430 --> 00:35:31,740
area is kind of how we view it.

740
00:35:31,740 --> 00:35:34,770
And so with that
in mind, give us

741
00:35:34,770 --> 00:35:39,720
also your view on this topic,
if you don't mind, on industry,

742
00:35:39,720 --> 00:35:42,245
or at least Vertex's
collaborations with academia.

743
00:35:42,245 --> 00:35:43,620
And in particular,
obviously, you

744
00:35:43,620 --> 00:35:45,750
have David Altshuler
from MIT, you

745
00:35:45,750 --> 00:35:49,020
have Doug Milton from Harvard,
and many leading academics

746
00:35:49,020 --> 00:35:50,440
who have gone into industry.

747
00:35:50,440 --> 00:35:52,890
So give us your sense of
this dynamic of collaboration

748
00:35:52,890 --> 00:35:55,960
between biotech and university--
research universities.

749
00:35:55,960 --> 00:35:58,930
Yeah, I think a lot has
been said about this,

750
00:35:58,930 --> 00:36:05,040
so maybe I'll point out two
or three additional points.

751
00:36:05,040 --> 00:36:09,090
The work that we
do in biopharma,

752
00:36:09,090 --> 00:36:12,420
biotech, the work
of drug development

753
00:36:12,420 --> 00:36:15,820
is a very particular
kind of work

754
00:36:15,820 --> 00:36:19,260
and, honestly, doesn't
happen in academia.

755
00:36:19,260 --> 00:36:23,170
I left academia because after
my own circuitous journey,

756
00:36:23,170 --> 00:36:27,670
I realized that when I started
as a physician scientist,

757
00:36:27,670 --> 00:36:32,350
I thought what I wanted to be
was a triple threat, run my lab,

758
00:36:32,350 --> 00:36:34,327
see patients, teach students.

759
00:36:34,327 --> 00:36:36,160
I really thought that's
what I wanted to do.

760
00:36:36,160 --> 00:36:39,000
And I fashioned my
entire life to do that.

761
00:36:39,000 --> 00:36:41,010
Until I actually did
it and I realized

762
00:36:41,010 --> 00:36:43,410
I was doing research in
areas that didn't actually

763
00:36:43,410 --> 00:36:44,350
interest me.

764
00:36:44,350 --> 00:36:46,510
But that's where
the funding was.

765
00:36:46,510 --> 00:36:48,190
That's where the
grant money was.

766
00:36:48,190 --> 00:36:52,050
And I just decided one day
I was not going to do that.

767
00:36:52,050 --> 00:36:55,440
And then, I realized when I said
to myself all those years ago

768
00:36:55,440 --> 00:36:58,500
that I wanted to do
research, I actually

769
00:36:58,500 --> 00:37:00,460
meant I wanted to
make medicines.

770
00:37:00,460 --> 00:37:03,400
I didn't know how to
say it prospectively.

771
00:37:03,400 --> 00:37:06,310
But when I was there, I realized
that's what I actually meant.

772
00:37:06,310 --> 00:37:09,100
And then, once I decided that's
what I really wanted to do,

773
00:37:09,100 --> 00:37:12,700
it turned out to be extremely
difficult, if not impossible,

774
00:37:12,700 --> 00:37:14,430
to do in academia.

775
00:37:14,430 --> 00:37:18,180
You need to have all of
the basic science discovery

776
00:37:18,180 --> 00:37:21,900
infrastructure, which I
think academia has in spades.

777
00:37:21,900 --> 00:37:26,530
Then you need clinical
development, regulatory affairs,

778
00:37:26,530 --> 00:37:29,430
manufacturing, and a
whole lot of capital.

779
00:37:29,430 --> 00:37:32,390
That was not
available in spades.

780
00:37:32,390 --> 00:37:34,610
And then you need
another group of people

781
00:37:34,610 --> 00:37:37,730
who could take that medicine
and actually bring it out

782
00:37:37,730 --> 00:37:39,450
to patients around the globe.

783
00:37:39,450 --> 00:37:42,420
You need access, you
need health economics,

784
00:37:42,420 --> 00:37:45,510
you need a sales and
marketing infrastructure.

785
00:37:45,510 --> 00:37:47,850
And I actually left
for that reason.

786
00:37:47,850 --> 00:37:50,270
When I went to my
chair and I told them

787
00:37:50,270 --> 00:37:52,350
all this exciting
stuff I wanted to do,

788
00:37:52,350 --> 00:37:54,260
they said, OK, you are at--

789
00:37:54,260 --> 00:37:56,220
I was at the Brigham
at that time.

790
00:37:56,220 --> 00:38:00,380
You have 20 hours of
statisticians time.

791
00:38:00,380 --> 00:38:01,440
20 hours.

792
00:38:01,440 --> 00:38:04,200
I wouldn't even be able to
write one protocol in 20 hours.

793
00:38:04,200 --> 00:38:08,580
And that's what drove
me to go to biotech.

794
00:38:08,580 --> 00:38:11,300
And I went to a company
on the West Coast.

795
00:38:11,300 --> 00:38:13,670
And the collaborations
that I saw there

796
00:38:13,670 --> 00:38:16,790
and the collaborations
we do at Vertex

797
00:38:16,790 --> 00:38:23,250
are along these lines of
the very best innovation,

798
00:38:23,250 --> 00:38:25,890
and we have
fantastic scientists.

799
00:38:25,890 --> 00:38:31,950
But given the vast amount
of science that can be done,

800
00:38:31,950 --> 00:38:35,260
it cannot all be done
within the walls of vertex.

801
00:38:35,260 --> 00:38:39,310
So we partner often
with academics,

802
00:38:39,310 --> 00:38:42,780
with small biotech companies,
and with others who

803
00:38:42,780 --> 00:38:45,160
are just doing basic
science research.

804
00:38:45,160 --> 00:38:48,480
We also collaborate
in-- then in-license

805
00:38:48,480 --> 00:38:53,290
and/or acquire companies because
that company, that technology,

806
00:38:53,290 --> 00:38:57,250
their asset works perfectly
for what we want to do.

807
00:38:57,250 --> 00:39:00,810
And then, the third
way we partner is there

808
00:39:00,810 --> 00:39:02,790
are some unique
problems that come up

809
00:39:02,790 --> 00:39:05,590
that you don't expect to
come up along the lines.

810
00:39:05,590 --> 00:39:08,400
We might be making a
medicine for cystic fibrosis

811
00:39:08,400 --> 00:39:11,710
or we might be making a medicine
for sickle cell disease.

812
00:39:11,710 --> 00:39:13,290
But along the way,
you realize you

813
00:39:13,290 --> 00:39:17,170
need some data set, you
need some algorithms,

814
00:39:17,170 --> 00:39:20,850
you need to understand how to
do certain off-targeting work

815
00:39:20,850 --> 00:39:22,350
that we don't know
how to do inside.

816
00:39:22,350 --> 00:39:24,142
We just know that it's
a new problem that's

817
00:39:24,142 --> 00:39:25,210
come up along the way.

818
00:39:25,210 --> 00:39:28,080
And working with
academia, institutions

819
00:39:28,080 --> 00:39:32,050
like MIT and Harvard, has
been incredible for us.

820
00:39:32,050 --> 00:39:34,740
One of our medicines that
was just recently approved

821
00:39:34,740 --> 00:39:37,720
came from a partnership
with CRISPR Therapeutics,

822
00:39:37,720 --> 00:39:39,790
a small biotech
company right here.

823
00:39:39,790 --> 00:39:41,400
Another one of our
programs that's

824
00:39:41,400 --> 00:39:45,570
just in phase III development
as of the last couple of weeks

825
00:39:45,570 --> 00:39:49,300
came to us by purchasing
Doug Melton's company.

826
00:39:49,300 --> 00:39:51,720
So if you said, look,
you've got to do work

827
00:39:51,720 --> 00:39:54,450
without collaborating, I'd
say patients would suffer.

828
00:39:54,450 --> 00:39:58,150
It is absolutely
essential to what we do.

829
00:39:58,150 --> 00:39:58,650
Super.

830
00:39:58,650 --> 00:40:00,250
So staying with you.

831
00:40:00,250 --> 00:40:02,172
The other thing
that MIT contributes

832
00:40:02,172 --> 00:40:03,630
and as such
universities contribute

833
00:40:03,630 --> 00:40:07,620
to Vertex and to Biogen and
others is human capital,

834
00:40:07,620 --> 00:40:08,345
is the students.

835
00:40:08,345 --> 00:40:11,010

836
00:40:11,010 --> 00:40:13,140
And with HEALS
today and what we're

837
00:40:13,140 --> 00:40:15,210
kind of celebrating
and launching,

838
00:40:15,210 --> 00:40:18,600
I know that MIT very much is
interested in what more it

839
00:40:18,600 --> 00:40:22,330
can do to better prepare
students, graduate students,

840
00:40:22,330 --> 00:40:26,520
postdocs, everyone to be even
more impactful in biopharma

841
00:40:26,520 --> 00:40:27,510
industry.

842
00:40:27,510 --> 00:40:31,110
So with a lens towards the
future, what types of things

843
00:40:31,110 --> 00:40:33,660
would you expect
that MIT could maybe

844
00:40:33,660 --> 00:40:37,390
add to its arsenal of how
it's preparing students?

845
00:40:37,390 --> 00:40:44,320
I think President Kornbluth's
focus at MIT on life sciences

846
00:40:44,320 --> 00:40:45,790
is really critical.

847
00:40:45,790 --> 00:40:47,680
I happen to be
married to an engineer

848
00:40:47,680 --> 00:40:49,510
and it's not that awkward.

849
00:40:49,510 --> 00:40:50,700
We do OK.

850
00:40:50,700 --> 00:40:52,990
[LAUGHTER]

851
00:40:52,990 --> 00:40:57,820
But I realized that we actually
think completely differently.

852
00:40:57,820 --> 00:41:00,920
To be a fantastic
practicing physician,

853
00:41:00,920 --> 00:41:02,890
you need to connect dots.

854
00:41:02,890 --> 00:41:04,870
And you need to
repeatedly connect

855
00:41:04,870 --> 00:41:06,860
the dots the same exact way.

856
00:41:06,860 --> 00:41:11,500
Photophobia, neck, pain,
fever, you think meningitis.

857
00:41:11,500 --> 00:41:13,430
And you think that
every single time.

858
00:41:13,430 --> 00:41:14,750
Otherwise, a patient will die.

859
00:41:14,750 --> 00:41:17,030
So it's a lot of
pattern recognition.

860
00:41:17,030 --> 00:41:19,340
It's not that good to
be all that creative.

861
00:41:19,340 --> 00:41:22,300
As an engineer, my
husband sees every problem

862
00:41:22,300 --> 00:41:25,180
and he sees the
most, I don't know,

863
00:41:25,180 --> 00:41:28,270
this-- a small, obscure
piece of evidence

864
00:41:28,270 --> 00:41:33,380
that he wants that to be proven
to him based on first principles

865
00:41:33,380 --> 00:41:34,430
that it's true.

866
00:41:34,430 --> 00:41:36,677
And all I say is,
photophobia, neck pain,

867
00:41:36,677 --> 00:41:37,760
fever, that is meningitis.

868
00:41:37,760 --> 00:41:39,530
[LAUGHTER]

869
00:41:39,530 --> 00:41:42,620
I think there is a lot of
benefit to bringing engineering

870
00:41:42,620 --> 00:41:45,620
into the life sciences,
and the best element of it

871
00:41:45,620 --> 00:41:48,690
is something that Anne
said, it helps patients.

872
00:41:48,690 --> 00:41:52,440
You can use engineering to make
tires and pencils, I suppose,

873
00:41:52,440 --> 00:41:57,300
but there's no better cause
than to do this in health care.

874
00:41:57,300 --> 00:42:00,890
What I think that does
mean is introducing

875
00:42:00,890 --> 00:42:07,110
physicians like myself
to engineers, to math,

876
00:42:07,110 --> 00:42:08,850
to technology.

877
00:42:08,850 --> 00:42:11,780
In our medical school existence,
we don't learn a whole lot

878
00:42:11,780 --> 00:42:12,560
about that.

879
00:42:12,560 --> 00:42:15,710
And ensuring that
engineers, even if they're

880
00:42:15,710 --> 00:42:18,360
mechanical engineers and
not biomedical engineers,

881
00:42:18,360 --> 00:42:21,210
have a good, strong
foundation in biology.

882
00:42:21,210 --> 00:42:23,300
I find that a lot of
engineers are turned off

883
00:42:23,300 --> 00:42:26,550
by biology because they
think it's rote memorization.

884
00:42:26,550 --> 00:42:29,390
And as a physician,
I have to admit

885
00:42:29,390 --> 00:42:31,880
I'm a little turned
off in my earlier days

886
00:42:31,880 --> 00:42:33,770
from engineering
because I thought it was

887
00:42:33,770 --> 00:42:35,920
about oil and building bridges.

888
00:42:35,920 --> 00:42:36,860
[LAUGHTER]

889
00:42:36,860 --> 00:42:39,560
So I think that
there is a lot more

890
00:42:39,560 --> 00:42:43,820
we can do to make sure that
engineers know mechanical,

891
00:42:43,820 --> 00:42:48,710
computer science, electrical
that there's a lot of great work

892
00:42:48,710 --> 00:42:51,120
that they can do in biopharma.

893
00:42:51,120 --> 00:42:54,290
And the only way we can do that
is to make sure that, one, we

894
00:42:54,290 --> 00:42:56,460
talk about it, two, we
have seminars like this,

895
00:42:56,460 --> 00:42:59,580
but three, internships
and fellowships,

896
00:42:59,580 --> 00:43:02,060
there needs to be a lot
more movement of engineers

897
00:43:02,060 --> 00:43:03,180
into biopharma.

898
00:43:03,180 --> 00:43:05,190
There already is
quite a bit of that.

899
00:43:05,190 --> 00:43:07,042
If you're a PhD in
the life sciences,

900
00:43:07,042 --> 00:43:08,750
there's actually an
entire Vertex program

901
00:43:08,750 --> 00:43:11,820
that welcomes you and you have
the opportunity to do that.

902
00:43:11,820 --> 00:43:15,950
We need to do more to make
that opportunity for engineers.

903
00:43:15,950 --> 00:43:18,320
Chris, same question to you.

904
00:43:18,320 --> 00:43:25,070
Yeah, I think I've been
a trustee, actually,

905
00:43:25,070 --> 00:43:26,850
of Northeastern
University for 10 years.

906
00:43:26,850 --> 00:43:29,000
And I think one of the
interesting things they do

907
00:43:29,000 --> 00:43:32,510
is they've got this
experiential learning, which

908
00:43:32,510 --> 00:43:35,270
used to be called interns.

909
00:43:35,270 --> 00:43:37,490
It goes back to something
I was saying earlier.

910
00:43:37,490 --> 00:43:41,520
A lot of the problems in life
are really people problems.

911
00:43:41,520 --> 00:43:45,270
And if you can get the
people to work together,

912
00:43:45,270 --> 00:43:47,430
you can solve an
awful lot of things.

913
00:43:47,430 --> 00:43:49,562
But the higher you go
up in an organization,

914
00:43:49,562 --> 00:43:51,770
the more you're going to be
focused on getting people

915
00:43:51,770 --> 00:43:54,120
to work together effectively.

916
00:43:54,120 --> 00:43:56,840
And I think younger
students, often,

917
00:43:56,840 --> 00:43:59,300
it's a question of
how much do I know?

918
00:43:59,300 --> 00:44:01,170
What's my technical knowledge?

919
00:44:01,170 --> 00:44:02,370
What's my capability?

920
00:44:02,370 --> 00:44:05,660
But at some point, if you're
creating these collaborations,

921
00:44:05,660 --> 00:44:08,160
or at some point, you're
going to lead a team,

922
00:44:08,160 --> 00:44:12,080
you have to develop some
of these softer skills.

923
00:44:12,080 --> 00:44:16,280
And I think that's important
to start to introduce even

924
00:44:16,280 --> 00:44:17,970
in engineering and sciences.

925
00:44:17,970 --> 00:44:20,400
I don't think that
often gets enough.

926
00:44:20,400 --> 00:44:23,960
Some of that can be through
the fellowship program

927
00:44:23,960 --> 00:44:25,830
that you've
generously sponsored.

928
00:44:25,830 --> 00:44:28,290
We've got fellowship programs.

929
00:44:28,290 --> 00:44:31,280
We have an intake
of MBA students

930
00:44:31,280 --> 00:44:33,350
and we bring them through.

931
00:44:33,350 --> 00:44:36,990
But there is an element, once
you get inside a company,

932
00:44:36,990 --> 00:44:38,610
you are in an organization.

933
00:44:38,610 --> 00:44:40,670
And once you're in
an organization,

934
00:44:40,670 --> 00:44:43,070
you have to learn
about culture, you

935
00:44:43,070 --> 00:44:46,400
have to learn about leadership,
and the other element

936
00:44:46,400 --> 00:44:49,100
I would say is business acumen.

937
00:44:49,100 --> 00:44:52,320
Andrew's omics were fabulous.

938
00:44:52,320 --> 00:44:55,320
I mean, economics
is fundamental.

939
00:44:55,320 --> 00:44:57,327
I mean, you have to raise money.

940
00:44:57,327 --> 00:44:58,410
You've had to raise money.

941
00:44:58,410 --> 00:45:02,070
You deal with omic economics
a lot at the hospital.

942
00:45:02,070 --> 00:45:05,190
We do it as company CEOs.

943
00:45:05,190 --> 00:45:08,670
And the reality is nothing is
going to happen without capital.

944
00:45:08,670 --> 00:45:15,080
And so I remember I had hired
one guy when I was at Sanofi

945
00:45:15,080 --> 00:45:18,810
and he was one of the first
MDs to do an MBA as well.

946
00:45:18,810 --> 00:45:21,660
And at Harvard, they
almost said, well,

947
00:45:21,660 --> 00:45:22,950
why are you doing that?

948
00:45:22,950 --> 00:45:25,750
Now, today, that is
a lot more common,

949
00:45:25,750 --> 00:45:27,940
and you see these
combination degrees.

950
00:45:27,940 --> 00:45:29,420
I think Wharton,
for instance, you

951
00:45:29,420 --> 00:45:33,250
can get a combined science
and finance degree.

952
00:45:33,250 --> 00:45:37,230
But people certainly who have
the scientific capability, who

953
00:45:37,230 --> 00:45:40,530
bring these other human
capabilities as well

954
00:45:40,530 --> 00:45:44,540
as the business acumen, I think,
will really go a long way.

955
00:45:44,540 --> 00:45:48,170
So continuing the
discussion, we've

956
00:45:48,170 --> 00:45:52,410
gone 30 minutes without
using the AI expression.

957
00:45:52,410 --> 00:45:54,560
So we see we're disciplined.

958
00:45:54,560 --> 00:45:56,490
But now I do want
to turn to that.

959
00:45:56,490 --> 00:45:59,600
Because we heard today that
this was the 50th anniversary

960
00:45:59,600 --> 00:46:04,310
of the Cancer Center here and
how much molecular biology

961
00:46:04,310 --> 00:46:05,460
influenced all that.

962
00:46:05,460 --> 00:46:07,730
And then, we heard about how
engineering got involved.

963
00:46:07,730 --> 00:46:10,070
And now, we're all kind
of-- not only do we

964
00:46:10,070 --> 00:46:12,230
have to combine
biology, engineering,

965
00:46:12,230 --> 00:46:14,000
patients, clinical
care, but now we

966
00:46:14,000 --> 00:46:18,840
have to get into AI or AI omics
if Andrew's expression works.

967
00:46:18,840 --> 00:46:21,450
But that's kind of unfolding
in front of our eyes.

968
00:46:21,450 --> 00:46:25,520
So taking out AI as it
relates to productivity gains

969
00:46:25,520 --> 00:46:31,490
in our regular life, how are
each of you thinking about this

970
00:46:31,490 --> 00:46:32,330
as--

971
00:46:32,330 --> 00:46:35,150
or are you-- as a
pillar of what you're

972
00:46:35,150 --> 00:46:36,780
building on in the future?

973
00:46:36,780 --> 00:46:41,630
Obviously, at MGB, you go from
the data generation, data access

974
00:46:41,630 --> 00:46:43,340
set of issues that
AI raises all the way

975
00:46:43,340 --> 00:46:46,290
to many, many
other applications.

976
00:46:46,290 --> 00:46:48,360
So maybe, if you
don't mind, I also

977
00:46:48,360 --> 00:46:50,430
wouldn't mind because
this is being filmed

978
00:46:50,430 --> 00:46:53,250
that we take a little
bit of the opportunity

979
00:46:53,250 --> 00:46:56,260
to just project a bit over
the next 10, 15 years.

980
00:46:56,260 --> 00:46:59,070
And so when this group HEALS
gets together and celebrates

981
00:46:59,070 --> 00:47:00,828
their anniversary,
we can look back

982
00:47:00,828 --> 00:47:02,620
and they can make fun
of what we projected.

983
00:47:02,620 --> 00:47:06,280
And with that, tell us
the current reality,

984
00:47:06,280 --> 00:47:09,010
how you're thinking about it,
and how you see the future.

985
00:47:09,010 --> 00:47:11,760
So you brought up a
lot of different things

986
00:47:11,760 --> 00:47:13,830
that come together.

987
00:47:13,830 --> 00:47:19,680
When you think about a patient
from a purely clinical point

988
00:47:19,680 --> 00:47:22,260
of view, you're always
thinking about bringing

989
00:47:22,260 --> 00:47:27,370
in multidisciplinary
strengths to solve a problem.

990
00:47:27,370 --> 00:47:29,410
I'll just get to
the problem-solving.

991
00:47:29,410 --> 00:47:32,670
So you could have a
patient and no one

992
00:47:32,670 --> 00:47:35,310
really knows what's going on
and there's an internist there.

993
00:47:35,310 --> 00:47:38,470
And someone will say, yeah, I
think I know what's going on,

994
00:47:38,470 --> 00:47:41,350
but I'm wondering if maybe
this relates to endocrinology.

995
00:47:41,350 --> 00:47:44,410
Then the endocrinologist will
come in and say, well, no,

996
00:47:44,410 --> 00:47:47,290
this is not endocrinology at
all, but I think it's this.

997
00:47:47,290 --> 00:47:48,900
So at the end of
it all, you might

998
00:47:48,900 --> 00:47:52,660
have five different
medical subspecialists

999
00:47:52,660 --> 00:47:55,780
all with their own point of
view, their own expertise,

1000
00:47:55,780 --> 00:48:00,030
their own view of the world, and
their own learnings who are all

1001
00:48:00,030 --> 00:48:01,330
focused around the patient.

1002
00:48:01,330 --> 00:48:03,960
So then, if you broaden
it out, you get more

1003
00:48:03,960 --> 00:48:08,820
into these themes of, it's not
just multidisciplinary in terms

1004
00:48:08,820 --> 00:48:11,980
of medicine, what else
are you bringing in?

1005
00:48:11,980 --> 00:48:16,270
And then, you get into the
technologies, the engineering.

1006
00:48:16,270 --> 00:48:18,630
Now you're bringing
in multidisciplines

1007
00:48:18,630 --> 00:48:21,900
of a different point or a
different part of it that's

1008
00:48:21,900 --> 00:48:23,290
all focused in.

1009
00:48:23,290 --> 00:48:26,560
So when you talk about this
in terms of the clinical care,

1010
00:48:26,560 --> 00:48:29,070
the AI, the engineering,
et cetera, I just

1011
00:48:29,070 --> 00:48:31,260
want to put the
patient at the center

1012
00:48:31,260 --> 00:48:32,640
and think about
these things that

1013
00:48:32,640 --> 00:48:36,030
are going to be wraparounds
in terms of how you ultimately

1014
00:48:36,030 --> 00:48:40,450
solve the problem of
what's the diagnosis, OK?

1015
00:48:40,450 --> 00:48:41,880
What's the treatment?

1016
00:48:41,880 --> 00:48:43,477
How do you find the
right treatment?

1017
00:48:43,477 --> 00:48:45,310
How do you get the
treatment to the patient?

1018
00:48:45,310 --> 00:48:47,530
All are wrapped
around the patient.

1019
00:48:47,530 --> 00:48:50,970
So when I think of AI right now,
and I'll try and summarize this

1020
00:48:50,970 --> 00:48:53,140
maybe in three
points, number one,

1021
00:48:53,140 --> 00:48:56,640
it is, what we doing
in terms of AI that

1022
00:48:56,640 --> 00:48:59,260
is helping the clinician?

1023
00:48:59,260 --> 00:49:01,510
That's the easiest thing to do.

1024
00:49:01,510 --> 00:49:05,050
So that is, how do you
take and deal with burnout?

1025
00:49:05,050 --> 00:49:07,290
How do you look at
different data sets

1026
00:49:07,290 --> 00:49:10,410
and put them together
that are already existing

1027
00:49:10,410 --> 00:49:14,500
that will help the
clinician do what?

1028
00:49:14,500 --> 00:49:16,330
Write a better note?

1029
00:49:16,330 --> 00:49:18,430
OK, well, that's
great, actually.

1030
00:49:18,430 --> 00:49:22,240
But that is here and
we want to go here.

1031
00:49:22,240 --> 00:49:25,560
So if I look at the parts
of this, number one is,

1032
00:49:25,560 --> 00:49:28,020
how do we broaden out
the knowledge base

1033
00:49:28,020 --> 00:49:31,200
beyond the physician,
their own experience,

1034
00:49:31,200 --> 00:49:33,280
to the five physicians
in the group,

1035
00:49:33,280 --> 00:49:36,090
to the medical literature,
to what we all based

1036
00:49:36,090 --> 00:49:39,190
on these different articles,
different observations,

1037
00:49:39,190 --> 00:49:42,750
and be able to have a massive
amount of data all compiled

1038
00:49:42,750 --> 00:49:45,880
together to put it together
in the most objective form?

1039
00:49:45,880 --> 00:49:49,780
So number one is, how will this
help us in terms of diagnosis?

1040
00:49:49,780 --> 00:49:52,120
And there are a lot
of issues about this.

1041
00:49:52,120 --> 00:49:54,642
I mean, there's a radiology
conference many years ago that

1042
00:49:54,642 --> 00:49:56,100
basically said,
will there be a job

1043
00:49:56,100 --> 00:49:58,420
for radiologists in five years?

1044
00:49:58,420 --> 00:50:00,280
That's not really the question.

1045
00:50:00,280 --> 00:50:03,960
The question is, how do we put
together lots of different data

1046
00:50:03,960 --> 00:50:05,190
sets in--

1047
00:50:05,190 --> 00:50:11,190
that are huge, that have been
applied in a gold standard way

1048
00:50:11,190 --> 00:50:12,730
that are validated.

1049
00:50:12,730 --> 00:50:13,710
What does that mean?

1050
00:50:13,710 --> 00:50:15,720
That are equitable so
that you can actually

1051
00:50:15,720 --> 00:50:17,500
make a real diagnosis.

1052
00:50:17,500 --> 00:50:19,900
So I think the diagnostic
possibilities--

1053
00:50:19,900 --> 00:50:23,050
because we're already seeing
it-- are extraordinary.

1054
00:50:23,050 --> 00:50:26,070
And it's going to be hard
because of all the issues

1055
00:50:26,070 --> 00:50:29,170
that we have with AI that we
could spend another hour on.

1056
00:50:29,170 --> 00:50:33,970
So I think the second thing is,
how do you personalize therapy?

1057
00:50:33,970 --> 00:50:36,480
How do you match
therapy to the person?

1058
00:50:36,480 --> 00:50:39,960
That's been one of the
single most pressing

1059
00:50:39,960 --> 00:50:41,410
therapeutic problems.

1060
00:50:41,410 --> 00:50:42,760
We look at drug trials.

1061
00:50:42,760 --> 00:50:44,140
We have broad answers.

1062
00:50:44,140 --> 00:50:46,640
But then, there's that subset
that could have done this.

1063
00:50:46,640 --> 00:50:50,110
It's the personalized medicine
that we keep talking about

1064
00:50:50,110 --> 00:50:51,350
that we're not there.

1065
00:50:51,350 --> 00:50:53,630
AI can definitely
help us get there.

1066
00:50:53,630 --> 00:50:55,930
So I think the
predictive properties

1067
00:50:55,930 --> 00:50:58,850
of this in terms of
diagnostic accuracy,

1068
00:50:58,850 --> 00:51:04,610
in terms of looking at targeted
therapies, drug discovery,

1069
00:51:04,610 --> 00:51:05,690
I could go on and on.

1070
00:51:05,690 --> 00:51:08,590
But honestly, I think it's going
to revolutionize health care.

1071
00:51:08,590 --> 00:51:11,860
I was at a Microsoft
meeting about two years ago

1072
00:51:11,860 --> 00:51:16,180
and they had a presentation
about AI in the car industry.

1073
00:51:16,180 --> 00:51:19,180
And I learned more about
the application of AI

1074
00:51:19,180 --> 00:51:21,610
to health care in
that presentation

1075
00:51:21,610 --> 00:51:23,480
than I'd ever thought of before.

1076
00:51:23,480 --> 00:51:25,250
And you could say,
how is that possible?

1077
00:51:25,250 --> 00:51:26,390
It's the car industry.

1078
00:51:26,390 --> 00:51:29,230
Because the concepts that they
were talking about in terms

1079
00:51:29,230 --> 00:51:32,440
of data and how you view
it and what it means

1080
00:51:32,440 --> 00:51:36,130
and how you can envision the
future needs were extraordinary.

1081
00:51:36,130 --> 00:51:36,640
Super.

1082
00:51:36,640 --> 00:51:41,930
Bob, maybe put on the kind of
science if you look forward--

1083
00:51:41,930 --> 00:51:44,280
maybe just take the
forward question.

1084
00:51:44,280 --> 00:51:48,560
If everybody had access to all
the knowledge you have gathered

1085
00:51:48,560 --> 00:51:51,470
and your imagination
in the form of ability

1086
00:51:51,470 --> 00:51:54,960
to create new patterns,
how do you compete?

1087
00:51:54,960 --> 00:51:56,990
And then, what does
that look like?

1088
00:51:56,990 --> 00:51:59,160
Yeah, well, one other
thing I was going to say,

1089
00:51:59,160 --> 00:52:00,360
and because I wasn't--

1090
00:52:00,360 --> 00:52:02,700
I was talking to students and
thesis committees all day,

1091
00:52:02,700 --> 00:52:05,100
so I didn't hear some
of the earlier sessions.

1092
00:52:05,100 --> 00:52:08,450
But I hope it was
said at some point,

1093
00:52:08,450 --> 00:52:12,710
if it was the 50th anniversary
of the Cancer Center, jeez,

1094
00:52:12,710 --> 00:52:15,920
I think MIT has been doing AI
research for way more than 50

1095
00:52:15,920 --> 00:52:19,200
years and really deserves a lot
of credit for pioneering it,

1096
00:52:19,200 --> 00:52:21,800
people like Seymour
Papert and others.

1097
00:52:21,800 --> 00:52:24,720
And we ourselves
have used it for--

1098
00:52:24,720 --> 00:52:26,690
I mean, again, in science,
things-- actually,

1099
00:52:26,690 --> 00:52:29,270
for Chris's point,
like about solubility.

1100
00:52:29,270 --> 00:52:33,380
We came up with ways of
doing high throughput

1101
00:52:33,380 --> 00:52:36,390
systems for solubility
with Mike Simon,

1102
00:52:36,390 --> 00:52:38,840
looking at thousands and
thousands of combinations

1103
00:52:38,840 --> 00:52:41,930
and analyzing what you could--

1104
00:52:41,930 --> 00:52:44,600
and keep iterating
until you get something

1105
00:52:44,600 --> 00:52:46,550
that does make the
drug soluble enough

1106
00:52:46,550 --> 00:52:48,500
with FDA approved excipients.

1107
00:52:48,500 --> 00:52:52,705
But I think, going forward, the
way I think about it is, I mean,

1108
00:52:52,705 --> 00:52:54,080
I don't know if
it's what I know,

1109
00:52:54,080 --> 00:52:58,850
but I think it's like to me, it
does go to the science like--

1110
00:52:58,850 --> 00:53:03,960
to data, where can large
amounts of data be very useful?

1111
00:53:03,960 --> 00:53:06,350
One of the things I do
feel, like when I mentioned

1112
00:53:06,350 --> 00:53:08,300
this idea of tissue
engineering before,

1113
00:53:08,300 --> 00:53:11,750
is you could have-- to the
extent that you can make organs

1114
00:53:11,750 --> 00:53:14,570
and tissues on a
chip that really do

1115
00:53:14,570 --> 00:53:17,750
simulate the human
model, which are doing

1116
00:53:17,750 --> 00:53:19,260
quite a bit of that at MIT.

1117
00:53:19,260 --> 00:53:22,160
I could envision that
as the years go by

1118
00:53:22,160 --> 00:53:28,010
could just screen thousands,
maybe millions of molecules

1119
00:53:28,010 --> 00:53:31,860
and find new targets, find new
drugs using things like that

1120
00:53:31,860 --> 00:53:34,900
and use AI to predict
what's the next iteration

1121
00:53:34,900 --> 00:53:38,960
to the next iteration till you
maybe would have someday help

1122
00:53:38,960 --> 00:53:40,350
Alzheimer's or other things.

1123
00:53:40,350 --> 00:53:43,620
Because right now, if you have
to do everything in humans,

1124
00:53:43,620 --> 00:53:45,440
that's pretty tough.

1125
00:53:45,440 --> 00:53:48,770
But we're working with
Li-Huei Tsai, for example,

1126
00:53:48,770 --> 00:53:50,480
with the postdoc, Alice Stanton.

1127
00:53:50,480 --> 00:53:53,320
So we have a brain on a
chip where we could take,

1128
00:53:53,320 --> 00:53:55,750
actually, anybody's
cells here, and actually,

1129
00:53:55,750 --> 00:53:57,190
with Merit Cudkowicz,
we're going

1130
00:53:57,190 --> 00:53:59,110
to be talking to her about--

1131
00:53:59,110 --> 00:54:01,030
I was her pre-med
advisor and now she's

1132
00:54:01,030 --> 00:54:03,820
head of neurology at
MGH about maybe using

1133
00:54:03,820 --> 00:54:05,870
it to find new targets for ALS.

1134
00:54:05,870 --> 00:54:08,230
And so I just
think, again, where

1135
00:54:08,230 --> 00:54:12,100
you could take these things
and get thousands and thousands

1136
00:54:12,100 --> 00:54:14,920
of molecules, maybe
millions, and then

1137
00:54:14,920 --> 00:54:17,650
use it to find new targets
and new molecules that

1138
00:54:17,650 --> 00:54:19,420
could treat disease.

1139
00:54:19,420 --> 00:54:20,710
Super.

1140
00:54:20,710 --> 00:54:24,040
Maybe, Chris, to continue with
a view towards maybe a little

1141
00:54:24,040 --> 00:54:26,300
bit the present and a
lot more of the future.

1142
00:54:26,300 --> 00:54:28,300
And it's OK to speculate.

1143
00:54:28,300 --> 00:54:30,520
On the area of drug
discovery, drug development,

1144
00:54:30,520 --> 00:54:33,950
and the delivery of
clinical products,

1145
00:54:33,950 --> 00:54:37,870
how do you see this play out/

1146
00:54:37,870 --> 00:54:40,660
Well, first, I would go
back to the economics

1147
00:54:40,660 --> 00:54:41,750
before we go anywhere.

1148
00:54:41,750 --> 00:54:45,110
Because some of us were
at a dinner last night.

1149
00:54:45,110 --> 00:54:48,790
Sally and Susan,
various 50 members

1150
00:54:48,790 --> 00:54:51,530
of the broader ecosystem here.

1151
00:54:51,530 --> 00:54:53,350
And there was a lot
of concern raised

1152
00:54:53,350 --> 00:54:55,510
about the threat on innovation.

1153
00:54:55,510 --> 00:54:58,070
Certainly, we have a
current new administration,

1154
00:54:58,070 --> 00:55:00,610
but I would argue that
innovation was somewhat

1155
00:55:00,610 --> 00:55:02,960
under threat even before.

1156
00:55:02,960 --> 00:55:07,030
But now we're talking about
overhead recovery rates

1157
00:55:07,030 --> 00:55:08,650
and grants.

1158
00:55:08,650 --> 00:55:13,280
We're looking at pricing
implications for our industry.

1159
00:55:13,280 --> 00:55:17,960
And I think when you look
at the federal deficit,

1160
00:55:17,960 --> 00:55:20,500
you look at the
percentage of people

1161
00:55:20,500 --> 00:55:24,020
who are going to be over
the age of 65 by 2030,

1162
00:55:24,020 --> 00:55:27,350
it's going to be significantly
higher than where it is now.

1163
00:55:27,350 --> 00:55:30,640
And I'm sure, Anne, you would
agree that, actually, it's

1164
00:55:30,640 --> 00:55:34,540
those people that are pretty
heavy users of health care.

1165
00:55:34,540 --> 00:55:40,400
And we see already that Medicare
is potentially not solvent

1166
00:55:40,400 --> 00:55:42,090
just when I'm about to join it.

1167
00:55:42,090 --> 00:55:45,590
[LAUGHTER]

1168
00:55:45,590 --> 00:55:49,110
There is a massive amount
of economic pressure.

1169
00:55:49,110 --> 00:55:51,680
And when you go back to the
presentation by I think it was

1170
00:55:51,680 --> 00:55:55,230
Professor Lauffenburger this
morning where he started-- well,

1171
00:55:55,230 --> 00:55:58,250
we start with-- once we
actually get it out of academia,

1172
00:55:58,250 --> 00:56:01,130
we're still looking at
10,000 molecules to get one

1173
00:56:01,130 --> 00:56:02,370
that's approved.

1174
00:56:02,370 --> 00:56:07,160
And somewhere, I think, we have
to be changing fundamentally

1175
00:56:07,160 --> 00:56:09,630
the model of how we're doing
research and development.

1176
00:56:09,630 --> 00:56:14,210
Because society is telling
us that pricing and cost

1177
00:56:14,210 --> 00:56:17,420
is important, and we're going to
have to do this a whole lot more

1178
00:56:17,420 --> 00:56:18,180
efficiently.

1179
00:56:18,180 --> 00:56:21,260
If I look at clinical
trials, as much innovation

1180
00:56:21,260 --> 00:56:24,530
as we do on the molecular
level, we have done very little

1181
00:56:24,530 --> 00:56:26,610
on the actual process level.

1182
00:56:26,610 --> 00:56:29,610
And so what we're doing
at Biogen, for instance,

1183
00:56:29,610 --> 00:56:30,720
we have dry labs.

1184
00:56:30,720 --> 00:56:33,000
If you're in small
molecule chemistry,

1185
00:56:33,000 --> 00:56:36,770
you can actually now use
AI to, actually, develop

1186
00:56:36,770 --> 00:56:38,820
a more optimized molecule.

1187
00:56:38,820 --> 00:56:41,690
We used AI to create
virtual waiting rooms

1188
00:56:41,690 --> 00:56:46,800
for hospitals to actually find
patients for clinical trials.

1189
00:56:46,800 --> 00:56:50,640
Today, if I'm going to do
a study with 400 patients,

1190
00:56:50,640 --> 00:56:54,355
we're going to have to go to
400 or 500 clinical trial sites.

1191
00:56:54,355 --> 00:56:55,230
I mean, that's crazy.

1192
00:56:55,230 --> 00:56:56,130
Who does that?

1193
00:56:56,130 --> 00:56:59,820
If we could do 400
patients in 100 sites,

1194
00:56:59,820 --> 00:57:03,210
you have a massive
benefit on productivity.

1195
00:57:03,210 --> 00:57:07,350
So I think AI is not
just a cool tool,

1196
00:57:07,350 --> 00:57:11,100
I think we have to figure out
how do we reverse engineer now

1197
00:57:11,100 --> 00:57:13,170
how we're doing
research and development

1198
00:57:13,170 --> 00:57:17,240
because I don't think that
this pressure economically

1199
00:57:17,240 --> 00:57:24,440
on us as universities, as
biopharmaceutical companies is

1200
00:57:24,440 --> 00:57:26,070
going to go away any time soon.

1201
00:57:26,070 --> 00:57:29,180
And AI strikes me as a
way we can revolutionize

1202
00:57:29,180 --> 00:57:30,940
how we're doing things.

1203
00:57:30,940 --> 00:57:33,070
Reshma.

1204
00:57:33,070 --> 00:57:36,910
Maybe I'll give you
some practical examples

1205
00:57:36,910 --> 00:57:38,770
of what we do.

1206
00:57:38,770 --> 00:57:41,270
I think that there's
a lot of scope today.

1207
00:57:41,270 --> 00:57:45,100
We don't have to envision too
far into the future for AI

1208
00:57:45,100 --> 00:57:46,540
in imaging.

1209
00:57:46,540 --> 00:57:51,670
So for us, part of what we do
when we do our type 1 diabetes

1210
00:57:51,670 --> 00:57:55,300
cell therapy, our scientists
will describe the cells

1211
00:57:55,300 --> 00:57:58,760
as fluffy, cloud-like, plump.

1212
00:57:58,760 --> 00:58:01,610
And some of those are good and
some of those are not good.

1213
00:58:01,610 --> 00:58:03,880
And right now, you have a
scientist looking at a tube

1214
00:58:03,880 --> 00:58:06,170
to see if it's fluffy,
cloudy, or plump.

1215
00:58:06,170 --> 00:58:09,130
That we are
converting reasonably

1216
00:58:09,130 --> 00:58:13,030
with ease into an
imaging AI model that

1217
00:58:13,030 --> 00:58:15,980
will tell us these are the good
cells, these are the bad cells.

1218
00:58:15,980 --> 00:58:18,160
I think that is
already here and now.

1219
00:58:18,160 --> 00:58:22,880
We try to do that with studies
in clinical development

1220
00:58:22,880 --> 00:58:24,200
when you have to take biopsies.

1221
00:58:24,200 --> 00:58:28,120
I think that's a good place to
go and that's easy to do now.

1222
00:58:28,120 --> 00:58:30,890
I think the other place
that's really ripe,

1223
00:58:30,890 --> 00:58:35,030
it's not exactly now, but it's
maybe the day after tomorrow,

1224
00:58:35,030 --> 00:58:37,490
in manufacturing,
now that we're going

1225
00:58:37,490 --> 00:58:41,660
from chronic small molecules
or biologics molecules

1226
00:58:41,660 --> 00:58:43,110
that you take by
mouth every day,

1227
00:58:43,110 --> 00:58:46,340
biologics that you may take
once a month to these one

1228
00:58:46,340 --> 00:58:50,540
and done curative therapies,
the manufacturing of those

1229
00:58:50,540 --> 00:58:56,390
and the quality release of those
is an enormous human task, far

1230
00:58:56,390 --> 00:58:57,960
better done by computers.

1231
00:58:57,960 --> 00:58:59,970
But it's actually manual.

1232
00:58:59,970 --> 00:59:03,920
We still write batch
records in a log sheet

1233
00:59:03,920 --> 00:59:07,430
by one human being who is
then checking the same thing

1234
00:59:07,430 --> 00:59:10,980
to other human beings because
that's all we have right now.

1235
00:59:10,980 --> 00:59:13,530
So we don't need fanciful AI.

1236
00:59:13,530 --> 00:59:18,920
We just need not to be faxing
things back together or PDFing.

1237
00:59:18,920 --> 00:59:21,870
We just need to automate
simpler things like that,

1238
00:59:21,870 --> 00:59:24,710
and that'll get us a
huge bang for our buck.

1239
00:59:24,710 --> 00:59:29,460
In the distant future, right
now, we do what Bob describes.

1240
00:59:29,460 --> 00:59:32,240
We have really
smart people taking

1241
00:59:32,240 --> 00:59:35,150
30, 40 years of
experience and recognizing

1242
00:59:35,150 --> 00:59:40,130
that that carbon
moiety or that oxygen

1243
00:59:40,130 --> 00:59:42,350
atom in that spot,
that's where it usually

1244
00:59:42,350 --> 00:59:46,620
triggers a signal for maybe
a drug-induced liver injury.

1245
00:59:46,620 --> 00:59:48,980
It would be great to
catalog all of that

1246
00:59:48,980 --> 00:59:52,020
and to have that be a
little bit more automated.

1247
00:59:52,020 --> 00:59:54,780
It's not as bad as
I portray it to be.

1248
00:59:54,780 --> 00:59:56,660
Even today, we have
software and we

1249
00:59:56,660 --> 01:00:01,142
have algorithms that tip you
off to this is a red flag.

1250
01:00:01,142 --> 01:00:02,850
When you have this
moiety in this corner,

1251
01:00:02,850 --> 01:00:03,975
it's not going to work out.

1252
01:00:03,975 --> 01:00:07,620
We have ways of making things
more soluble or less soluble.

1253
01:00:07,620 --> 01:00:12,800
But I would say we are 70%,
80% human, 10%, 20% computer.

1254
01:00:12,800 --> 01:00:15,960
And there is a lot more
ability to do that.

1255
01:00:15,960 --> 01:00:20,340
But if we just tackle the simple
stuff, like in manufacturing,

1256
01:00:20,340 --> 01:00:23,270
like in batch records,
like in imaging,

1257
01:00:23,270 --> 01:00:27,140
and I agree with Chris
on clinical trials.

1258
01:00:27,140 --> 01:00:29,390
Today, when you do clinical
trials and now we're doing

1259
01:00:29,390 --> 01:00:31,760
clinical trials of
30,000, 40,000 people,

1260
01:00:31,760 --> 01:00:34,170
because the effect
size is smaller,

1261
01:00:34,170 --> 01:00:38,010
because we've made health
care better, there are people,

1262
01:00:38,010 --> 01:00:43,580
doctors, physicians, scientists
who are reading through reams

1263
01:00:43,580 --> 01:00:45,000
of safety data.

1264
01:00:45,000 --> 01:00:47,690
That's called line listing
review because we literally

1265
01:00:47,690 --> 01:00:49,280
review lines of data.

1266
01:00:49,280 --> 01:00:51,690
That is far better
done by a computer.

1267
01:00:51,690 --> 01:00:54,810
It's not there yet, but
that's the low lying fruit.

1268
01:00:54,810 --> 01:00:55,310
Super.

1269
01:00:55,310 --> 01:00:57,510
Well, look, we're out of time.

1270
01:00:57,510 --> 01:00:59,540
I think this has just
been a glimpse of what

1271
01:00:59,540 --> 01:01:03,060
interdisciplinary collaborative
discussions will look like.

1272
01:01:03,060 --> 01:01:06,770
Hopefully, it will happen at
every classroom and every corner

1273
01:01:06,770 --> 01:01:08,220
of MIT going forward.

1274
01:01:08,220 --> 01:01:10,250
And please join me in
thanking our panelists

1275
01:01:10,250 --> 01:01:11,220
for this discussion.

1276
01:01:11,220 --> 01:01:11,910
Thank you, guys.

1277
01:01:11,910 --> 01:01:15,560
[APPLAUSE]

1278
01:01:15,560 --> 01:01:18,000


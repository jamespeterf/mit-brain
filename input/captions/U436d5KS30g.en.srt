1
00:00:00,599 --> 00:00:03,520
I promise I'm going to be brief because

2
00:00:02,120 --> 00:00:05,040
I hate to stand

3
00:00:03,520 --> 00:00:08,240
between

4
00:00:05,040 --> 00:00:10,040
um between everybody in their lunch um

5
00:00:08,240 --> 00:00:11,400
but at first I gotta you know we should

6
00:00:10,040 --> 00:00:13,200
have had a panel because I've got to

7
00:00:11,400 --> 00:00:15,000
answer some of the questions that that

8
00:00:13,200 --> 00:00:17,119
that you asked earlier especially of

9
00:00:15,000 --> 00:00:19,119
Patty you asked whether um these

10
00:00:17,119 --> 00:00:20,640
technological innovations were who they

11
00:00:19,119 --> 00:00:22,199
going to benefit whose Ox is going to

12
00:00:20,640 --> 00:00:25,439
get gored and who's going to get rich as

13
00:00:22,199 --> 00:00:27,480
a result of them and uh and what she

14
00:00:25,439 --> 00:00:29,720
said was exactly right um the media

15
00:00:27,480 --> 00:00:31,840
laboratory is about democratization it

16
00:00:29,720 --> 00:00:33,680
is about that and and that is our dream

17
00:00:31,840 --> 00:00:37,040
and our hope does that dream always work

18
00:00:33,680 --> 00:00:38,760
out I can't say but what I can do is

19
00:00:37,040 --> 00:00:40,440
something I hate to do which is when

20
00:00:38,760 --> 00:00:41,800
somebody asks me a question instead of

21
00:00:40,440 --> 00:00:43,840
giving them the answer I tell them where

22
00:00:41,800 --> 00:00:45,239
they can look for the answer right you

23
00:00:43,840 --> 00:00:47,360
know and I'm going to do that but

24
00:00:45,239 --> 00:00:50,239
there's a new book out called power and

25
00:00:47,360 --> 00:00:52,719
Progress written by Deron asoglu and

26
00:00:50,239 --> 00:00:54,640
Simon Johnson uh at the Sloan School in

27
00:00:52,719 --> 00:00:58,359
MIT and it's it's kind of thick but it's

28
00:00:54,640 --> 00:01:01,039
a good read and it it dwells on exactly

29
00:00:58,359 --> 00:01:03,039
that historically from the Middle Ages

30
00:01:01,039 --> 00:01:07,000
to the present and the future and and

31
00:01:03,039 --> 00:01:09,159
the results are are are um surprising

32
00:01:07,000 --> 00:01:11,920
okay in the sense that sometimes it does

33
00:01:09,159 --> 00:01:15,119
benefit some differentially and other

34
00:01:11,920 --> 00:01:16,799
times it is a democratizing agent so I I

35
00:01:15,119 --> 00:01:19,240
commend that book to you Simon is going

36
00:01:16,799 --> 00:01:21,920
to join us at the media lab in in a

37
00:01:19,240 --> 00:01:24,400
couple of weeks um the second question I

38
00:01:21,920 --> 00:01:26,920
could spend all day on and I won't and

39
00:01:24,400 --> 00:01:31,200
that was um about

40
00:01:26,920 --> 00:01:32,360
misinformation and uh uh boy

41
00:01:31,200 --> 00:01:35,159
you know there's good newss and there's

42
00:01:32,360 --> 00:01:38,520
bad news right I mean misinformation and

43
00:01:35,159 --> 00:01:41,040
detection of of misinformation has been

44
00:01:38,520 --> 00:01:43,240
widely studied and it's imperfect

45
00:01:41,040 --> 00:01:46,159
because nobody can characterize what

46
00:01:43,240 --> 00:01:49,079
misinformation is is it Omission is it

47
00:01:46,159 --> 00:01:52,040
bias is it a deliberate lie and what's

48
00:01:49,079 --> 00:01:54,560
even worse is that we've seen the

49
00:01:52,040 --> 00:01:58,360
Perfection of a variety of techniques

50
00:01:54,560 --> 00:02:00,479
originated by Geral in World War II

51
00:01:58,360 --> 00:02:03,360
where if you give people enough

52
00:02:00,479 --> 00:02:06,280
information you undermine their

53
00:02:03,360 --> 00:02:08,640
epistemological epistemological basis

54
00:02:06,280 --> 00:02:11,879
for making a decision in other words if

55
00:02:08,640 --> 00:02:14,200
I pepper you with lies you won't be able

56
00:02:11,879 --> 00:02:16,519
to deduce the truth from among them

57
00:02:14,200 --> 00:02:18,720
because your ability to reason has been

58
00:02:16,519 --> 00:02:22,160
undermined by all of those but the good

59
00:02:18,720 --> 00:02:24,920
news is um we will get better at it and

60
00:02:22,160 --> 00:02:29,200
you don't have to be perfect the bad

61
00:02:24,920 --> 00:02:31,720
news is who cares okay because the

62
00:02:29,200 --> 00:02:34,959
people who are biased by misinformation

63
00:02:31,720 --> 00:02:36,760
are not going to use Hussein's app and

64
00:02:34,959 --> 00:02:38,800
they're not going to use Patty's app and

65
00:02:36,760 --> 00:02:42,959
they're not going to look for the truth

66
00:02:38,800 --> 00:02:45,080
because that's the problem as well um so

67
00:02:42,959 --> 00:02:46,400
it's it's difficult and I could I could

68
00:02:45,080 --> 00:02:48,400
spend forever on it you know the

69
00:02:46,400 --> 00:02:51,319
statement the lies travel around the

70
00:02:48,400 --> 00:02:53,400
world before the truth gets its boots on

71
00:02:51,319 --> 00:02:57,360
um that statement was made by Jonathan

72
00:02:53,400 --> 00:02:59,159
Swift 300 years ago so this problem is

73
00:02:57,360 --> 00:03:01,519
pervasive and what you don't know

74
00:02:59,159 --> 00:03:04,040
necessarily is the followon sentence to

75
00:03:01,519 --> 00:03:07,879
that which is that and by the time the

76
00:03:04,040 --> 00:03:10,200
truth catches up it's done its damage um

77
00:03:07,879 --> 00:03:13,280
so indeed it is a problem and indeed

78
00:03:10,200 --> 00:03:15,720
many of us in the laboratory work on it

79
00:03:13,280 --> 00:03:18,159
I also omitted from when I gave you the

80
00:03:15,720 --> 00:03:20,840
introduction um something that should be

81
00:03:18,159 --> 00:03:23,080
clear in what what goes on throughout

82
00:03:20,840 --> 00:03:26,120
the laboratory as a whole and that is

83
00:03:23,080 --> 00:03:28,200
that um to some extent AI is an

84
00:03:26,120 --> 00:03:30,360
infrastructure it's been part of our

85
00:03:28,200 --> 00:03:33,439
course since the beginning Marvin Minsky

86
00:03:30,360 --> 00:03:36,319
was in the AI lab uh sorry in the media

87
00:03:33,439 --> 00:03:38,319
lab um from well before it started so

88
00:03:36,319 --> 00:03:40,680
we've been developing that kind of thing

89
00:03:38,319 --> 00:03:42,439
but it's implicit it's implicit in the

90
00:03:40,680 --> 00:03:44,720
work that goes on throughout the

91
00:03:42,439 --> 00:03:48,319
laboratory because that's the goal

92
00:03:44,720 --> 00:03:49,840
solving human ends as Patty demonstrated

93
00:03:48,319 --> 00:03:52,720
and AI is an

94
00:03:49,840 --> 00:03:54,120
infrastructure um to do that so I'm

95
00:03:52,720 --> 00:03:56,200
going to give you a couple of examples

96
00:03:54,120 --> 00:04:00,000
of of of the work in my group and I I

97
00:03:56,200 --> 00:04:01,680
promise I I won't keep you uh for for

98
00:04:00,000 --> 00:04:05,480
very long and some of you will be able

99
00:04:01,680 --> 00:04:08,720
to go and and try them um but the idea

100
00:04:05,480 --> 00:04:12,159
is is that wisdom perspective

101
00:04:08,720 --> 00:04:15,439
observation okay speculation imagination

102
00:04:12,159 --> 00:04:18,799
introspection Common Sense humor these

103
00:04:15,439 --> 00:04:22,759
are all facets of of of Being Human that

104
00:04:18,799 --> 00:04:25,600
we have not yet implemented in a machine

105
00:04:22,759 --> 00:04:28,440
okay uh maybe someday we will and there

106
00:04:25,600 --> 00:04:30,840
are people who believe in self-driving

107
00:04:28,440 --> 00:04:32,720
cars and all kinds of M magic like Ai

108
00:04:30,840 --> 00:04:34,960
and stuff like that that it will become

109
00:04:32,720 --> 00:04:37,840
perfect and it will become human and it

110
00:04:34,960 --> 00:04:40,080
and it will become intelligent um I

111
00:04:37,840 --> 00:04:44,360
believe like many of the others who

112
00:04:40,080 --> 00:04:46,759
you've heard uh today uh that uh that

113
00:04:44,360 --> 00:04:49,280
doesn't matter in the long run because

114
00:04:46,759 --> 00:04:51,600
in the immediate term we can use these

115
00:04:49,280 --> 00:04:55,120
systems to make us better and Patty

116
00:04:51,600 --> 00:04:58,840
showed you several examples of it um so

117
00:04:55,120 --> 00:05:01,600
so the idea is is to use AI in service

118
00:04:58,840 --> 00:05:03,960
of these human traits of these traits of

119
00:05:01,600 --> 00:05:06,199
wisdom of these traits of speculation of

120
00:05:03,960 --> 00:05:08,360
these traits of of observation that

121
00:05:06,199 --> 00:05:11,440
haven't been implemented in machines

122
00:05:08,360 --> 00:05:13,639
when I was in high school I and my group

123
00:05:11,440 --> 00:05:16,919
of friends would wander around and the

124
00:05:13,639 --> 00:05:20,520
people that we admired most were people

125
00:05:16,919 --> 00:05:22,319
who simply walked around noticing things

126
00:05:20,520 --> 00:05:24,400
these were people who would say to you

127
00:05:22,319 --> 00:05:28,039
did you know that there's a different

128
00:05:24,400 --> 00:05:31,039
version of Columbus's ships every 6 feet

129
00:05:28,039 --> 00:05:33,600
in the 59th Street lumus Circle subway

130
00:05:31,039 --> 00:05:35,880
station in New York or Marvin walking

131
00:05:33,600 --> 00:05:38,639
down the street with Nicholas musing to

132
00:05:35,880 --> 00:05:41,840
himself and turning to Nick and saying I

133
00:05:38,639 --> 00:05:44,639
wonder how glue works it was observation

134
00:05:41,840 --> 00:05:47,280
it was noticing it was being prodded and

135
00:05:44,639 --> 00:05:49,319
thinking about new things so that's the

136
00:05:47,280 --> 00:05:53,240
kind of stuff that that my my group

137
00:05:49,319 --> 00:05:55,560
works on the means by which we do that

138
00:05:53,240 --> 00:05:58,039
is through interactions I've spent my

139
00:05:55,560 --> 00:06:00,319
life building interactive systems the

140
00:05:58,039 --> 00:06:02,520
goal is that we learn through activity

141
00:06:00,319 --> 00:06:04,720
and conversation the goal is that we

142
00:06:02,520 --> 00:06:08,080
learn through that action if I could

143
00:06:04,720 --> 00:06:10,319
inject French or tennis into your head

144
00:06:08,080 --> 00:06:12,639
you wouldn't know French or tennis you

145
00:06:10,319 --> 00:06:14,919
might have some facility with it but it

146
00:06:12,639 --> 00:06:17,440
is the experience of interacting and

147
00:06:14,919 --> 00:06:19,880
learning it which is the vehicle for

148
00:06:17,440 --> 00:06:21,639
learning when we tried doing this 40

149
00:06:19,880 --> 00:06:23,759
years ago it was unbelievably

150
00:06:21,639 --> 00:06:26,720
complicated because if you wanted to

151
00:06:23,759 --> 00:06:30,360
make something interactive you had to

152
00:06:26,720 --> 00:06:32,800
essentially create and in advance all of

153
00:06:30,360 --> 00:06:35,599
the options and Alternatives and twists

154
00:06:32,800 --> 00:06:38,360
and turns that that conversation might

155
00:06:35,599 --> 00:06:41,000
make plus you had to lace them together

156
00:06:38,360 --> 00:06:43,639
into a coherent hole it was a lot of

157
00:06:41,000 --> 00:06:45,840
work and not only that Society wasn't

158
00:06:43,639 --> 00:06:48,360
even necessarily ready for it so they

159
00:06:45,840 --> 00:06:50,440
weren't used to that form of interaction

160
00:06:48,360 --> 00:06:53,080
people thought of video as a laid-back

161
00:06:50,440 --> 00:06:54,560
experience you just let it flow over you

162
00:06:53,080 --> 00:06:56,520
they didn't think of it as something

163
00:06:54,560 --> 00:06:58,720
that that could draw you in well things

164
00:06:56,520 --> 00:07:00,120
have changed for one thing there's lots

165
00:06:58,720 --> 00:07:02,520
of data out there

166
00:07:00,120 --> 00:07:04,560
so you don't have to gather it all for

167
00:07:02,520 --> 00:07:06,840
another maybe there's some help in

168
00:07:04,560 --> 00:07:09,960
organizing it um by using some of the

169
00:07:06,840 --> 00:07:11,720
large language models that we have to

170
00:07:09,960 --> 00:07:14,039
give you some sense of the benefit of

171
00:07:11,720 --> 00:07:17,319
that conversation one of the ways that I

172
00:07:14,039 --> 00:07:19,800
often describe it is to say look your

173
00:07:17,319 --> 00:07:21,520
mother isn't always right but you do

174
00:07:19,800 --> 00:07:24,879
learn something from talking with her

175
00:07:21,520 --> 00:07:26,960
usually and so so you do so so the nice

176
00:07:24,879 --> 00:07:29,599
thing about building systems that are

177
00:07:26,960 --> 00:07:31,319
based on this interaction is that the

178
00:07:29,599 --> 00:07:33,520
system you're interacting with needn't

179
00:07:31,319 --> 00:07:35,639
be perfect okay we're not building

180
00:07:33,520 --> 00:07:37,479
answer machines where if the answer is

181
00:07:35,639 --> 00:07:40,160
wrong it's a problem we're building

182
00:07:37,479 --> 00:07:42,879
machines whose goal is to provoke whose

183
00:07:40,160 --> 00:07:45,879
goal is to create activity whose goal is

184
00:07:42,879 --> 00:07:47,960
to inspire and let you do things so up

185
00:07:45,879 --> 00:07:51,080
there is is one of one of the examples

186
00:07:47,960 --> 00:07:53,960
that that some people are interested in

187
00:07:51,080 --> 00:07:57,240
um this is an organizational

188
00:07:53,960 --> 00:07:59,759
representation of the 4,000 projects in

189
00:07:57,240 --> 00:08:02,440
in the recent memory of of of the media

190
00:07:59,759 --> 00:08:04,599
laboratory so when I told you what the

191
00:08:02,440 --> 00:08:08,919
diversity of the laboratory was this is

192
00:08:04,599 --> 00:08:11,039
a an example a portrayal of of exactly

193
00:08:08,919 --> 00:08:13,360
that diversity now if if I want to

194
00:08:11,039 --> 00:08:15,319
consign somebody to infinite hell and

195
00:08:13,360 --> 00:08:17,120
they ask me about the media lab then I

196
00:08:15,319 --> 00:08:20,039
say oh that's easy just go to our

197
00:08:17,120 --> 00:08:21,680
website that that could take forever and

198
00:08:20,039 --> 00:08:25,840
you'll never find what you're looking

199
00:08:21,680 --> 00:08:28,360
for so instead we took the raw text of

200
00:08:25,840 --> 00:08:31,479
those 4,000 projects created an

201
00:08:28,360 --> 00:08:34,039
embedding of them about 1500 vectors

202
00:08:31,479 --> 00:08:36,959
then created a visualization of that and

203
00:08:34,039 --> 00:08:39,399
used that text to Cluster the

204
00:08:36,959 --> 00:08:42,479
information and see which correlates

205
00:08:39,399 --> 00:08:44,600
with it so the different colored dots on

206
00:08:42,479 --> 00:08:47,320
that screen are representations of the

207
00:08:44,600 --> 00:08:50,320
different groups within the laboratory

208
00:08:47,320 --> 00:08:52,839
and the clustering shows the overlaps

209
00:08:50,320 --> 00:08:55,760
and the title now of course as you can

210
00:08:52,839 --> 00:08:57,760
imagine you can zoom in and explore that

211
00:08:55,760 --> 00:09:00,519
and go all the way down to the project

212
00:08:57,760 --> 00:09:03,760
level and you can see which projects are

213
00:09:00,519 --> 00:09:04,680
are close by and adjacent to that um

214
00:09:03,760 --> 00:09:06,800
more

215
00:09:04,680 --> 00:09:08,920
interestingly what you can also do is

216
00:09:06,800 --> 00:09:11,920
you can play a movie of how that's

217
00:09:08,920 --> 00:09:14,000
developed over the years so in this case

218
00:09:11,920 --> 00:09:16,839
i' I've given you just a snapshot not

219
00:09:14,000 --> 00:09:18,880
the entire movie um but the snapshot

220
00:09:16,839 --> 00:09:19,640
here is showing what the lab was like

221
00:09:18,880 --> 00:09:23,440
from

222
00:09:19,640 --> 00:09:26,360
1984 until around 2000 the groupings

223
00:09:23,440 --> 00:09:29,839
change the clusterings change it's all

224
00:09:26,360 --> 00:09:32,800
Dynamic and uh and the areas of you can

225
00:09:29,839 --> 00:09:35,440
see have changed and evolved over the

226
00:09:32,800 --> 00:09:38,440
years from what it was in

227
00:09:35,440 --> 00:09:41,720
1984 um to what it is to what it is

228
00:09:38,440 --> 00:09:46,000
today um in addition to that you can

229
00:09:41,720 --> 00:09:49,240
view this data in the context of other

230
00:09:46,000 --> 00:09:52,000
data sets so what you're looking at now

231
00:09:49,240 --> 00:09:56,160
is the media

232
00:09:52,000 --> 00:09:58,480
lab's domains of research overlapped and

233
00:09:56,160 --> 00:10:01,600
viewed in the context of published

234
00:09:58,480 --> 00:10:03,800
papers by Microsoft research okay so

235
00:10:01,600 --> 00:10:06,000
Microsoft research is shown in yellow

236
00:10:03,800 --> 00:10:08,480
our work is shown in purple you can see

237
00:10:06,000 --> 00:10:11,240
the areas where there's overlaps you can

238
00:10:08,480 --> 00:10:13,839
see the areas where there's differences

239
00:10:11,240 --> 00:10:16,880
between those two now the clusterings

240
00:10:13,839 --> 00:10:20,040
may not be perfect they may not be exact

241
00:10:16,880 --> 00:10:23,360
but the idea is for you to be able to

242
00:10:20,040 --> 00:10:26,240
explore those and think of ideas and

243
00:10:23,360 --> 00:10:30,160
think of overlaps with your own data and

244
00:10:26,240 --> 00:10:32,800
with your own goals and if you like you

245
00:10:30,160 --> 00:10:35,600
can take this system and propose a

246
00:10:32,800 --> 00:10:38,440
project of course you can search but

247
00:10:35,600 --> 00:10:41,040
this is about exploration not search

248
00:10:38,440 --> 00:10:43,639
likewise it's about provocation so you

249
00:10:41,040 --> 00:10:47,040
can propose a project you can propose a

250
00:10:43,639 --> 00:10:49,839
project by picking ones that exist and

251
00:10:47,040 --> 00:10:52,639
saying what happens if I merge these two

252
00:10:49,839 --> 00:10:56,040
can you help me create a project that's

253
00:10:52,639 --> 00:10:58,120
the admixture of both of those and we

254
00:10:56,040 --> 00:11:01,519
can do that very often what it comes up

255
00:10:58,120 --> 00:11:03,399
with is a absurd not not something that

256
00:11:01,519 --> 00:11:05,440
you would necessarily want to do but

257
00:11:03,399 --> 00:11:07,440
that doesn't matter you see because

258
00:11:05,440 --> 00:11:10,320
that's the conversation with your mother

259
00:11:07,440 --> 00:11:12,959
it doesn't matter what happens is it's

260
00:11:10,320 --> 00:11:15,399
there for you to learn it's not there

261
00:11:12,959 --> 00:11:17,760
for it to learn you can propose your own

262
00:11:15,399 --> 00:11:21,240
project and it will find ones that

263
00:11:17,760 --> 00:11:23,240
overlap and coincide with that um well

264
00:11:21,240 --> 00:11:27,040
who cares about that well it turns

265
00:11:23,240 --> 00:11:29,680
out um that when we talk with our

266
00:11:27,040 --> 00:11:31,720
supporters in the laboratory they've

267
00:11:29,680 --> 00:11:33,399
found uses for this kind of thing that

268
00:11:31,720 --> 00:11:35,880
that we never thought of they use it for

269
00:11:33,399 --> 00:11:38,519
competitive intelligence and they take

270
00:11:35,880 --> 00:11:41,480
public data to find out what other

271
00:11:38,519 --> 00:11:43,639
companies are doing and what other ideas

272
00:11:41,480 --> 00:11:47,440
are becoming popular and they use that

273
00:11:43,639 --> 00:11:49,519
to explore that rich database and decide

274
00:11:47,440 --> 00:11:52,000
where they're going some of them like

275
00:11:49,519 --> 00:11:54,399
Delite uses it for example for

276
00:11:52,000 --> 00:11:56,760
brainstorming now you bring a group of

277
00:11:54,399 --> 00:11:59,959
people together and you start putting up

278
00:11:56,760 --> 00:12:02,000
data and information unstructured that's

279
00:11:59,959 --> 00:12:05,160
the whole point our system and what

280
00:12:02,000 --> 00:12:07,760
large language models um bring to the

281
00:12:05,160 --> 00:12:10,600
table as they bring you the ability to

282
00:12:07,760 --> 00:12:12,680
have some proposed structure presented

283
00:12:10,600 --> 00:12:15,240
to you and computed for you so they use

284
00:12:12,680 --> 00:12:17,320
it as a brainstorming solution others

285
00:12:15,240 --> 00:12:21,320
use it to explore the patent space one

286
00:12:17,320 --> 00:12:23,720
of the databases we have is uh I forgot

287
00:12:21,320 --> 00:12:26,519
how many a million patents you know from

288
00:12:23,720 --> 00:12:29,399
the last 10 years you can explore those

289
00:12:26,519 --> 00:12:32,040
and find holes in the world of of patent

290
00:12:29,399 --> 00:12:34,720
space some people use it for marketing a

291
00:12:32,040 --> 00:12:37,279
variety of people use it just simply to

292
00:12:34,720 --> 00:12:39,720
organize their own corporate history

293
00:12:37,279 --> 00:12:41,079
you've probably run across this right

294
00:12:39,720 --> 00:12:44,000
especially if you're in a large

295
00:12:41,079 --> 00:12:46,560
corporation the most valuable people in

296
00:12:44,000 --> 00:12:48,839
that Corporation are the people who know

297
00:12:46,560 --> 00:12:50,920
what everyone else is doing not

298
00:12:48,839 --> 00:12:53,519
necessarily because they've done it all

299
00:12:50,920 --> 00:12:56,480
themselves these are the critical social

300
00:12:53,519 --> 00:12:58,040
nodes that um distribute information

301
00:12:56,480 --> 00:13:00,279
throughout the company everybody's got

302
00:12:58,040 --> 00:13:03,079
records prints and all of these kinds of

303
00:13:00,279 --> 00:13:04,720
things can you ever find any of those

304
00:13:03,079 --> 00:13:06,800
and that was what originally motivated

305
00:13:04,720 --> 00:13:10,000
us with the media lab's research and the

306
00:13:06,800 --> 00:13:12,680
answer is no um where are we going to go

307
00:13:10,000 --> 00:13:14,560
with it well we're going to take it in a

308
00:13:12,680 --> 00:13:16,399
lot of other directions obviously the

309
00:13:14,560 --> 00:13:19,440
question is begged to make it be

310
00:13:16,399 --> 00:13:22,399
multimedia so it's not just words that

311
00:13:19,440 --> 00:13:24,959
it takes um but rather that it accepts

312
00:13:22,399 --> 00:13:27,480
pictures and sounds and movies and

313
00:13:24,959 --> 00:13:30,160
slides and all of those kinds of of data

314
00:13:27,480 --> 00:13:33,079
so the integration of all of of those is

315
00:13:30,160 --> 00:13:35,560
is what we're doing and allowing you to

316
00:13:33,079 --> 00:13:38,160
manipulate the clustering is another

317
00:13:35,560 --> 00:13:41,120
kind of one of the the next obvious

318
00:13:38,160 --> 00:13:43,639
Dimensions we've dictated the clustering

319
00:13:41,120 --> 00:13:46,480
and the layout of the graph but letting

320
00:13:43,639 --> 00:13:49,760
you play with that as a plastic surface

321
00:13:46,480 --> 00:13:52,440
to explore as well as using it as a lens

322
00:13:49,760 --> 00:13:54,040
into which to focus is probably where

323
00:13:52,440 --> 00:13:55,519
we're going to take that next for those

324
00:13:54,040 --> 00:13:57,880
of you who are coming by the laboratory

325
00:13:55,519 --> 00:14:00,480
you'll be able to see it for those of

326
00:13:57,880 --> 00:14:03,120
you who are not you are welcome to use

327
00:14:00,480 --> 00:14:08,800
it uh the URL I should have put in the

328
00:14:03,120 --> 00:14:10,759
slides is latent lab. a okay so and

329
00:14:08,800 --> 00:14:12,399
that's public so you can do that you're

330
00:14:10,759 --> 00:14:15,120
welcome to look at the media labs and

331
00:14:12,399 --> 00:14:16,959
all of the other public databases that

332
00:14:15,120 --> 00:14:19,199
are in the system there's nothing

333
00:14:16,959 --> 00:14:21,639
private to it and so feel free to

334
00:14:19,199 --> 00:14:25,000
explore all by yourself so that's an

335
00:14:21,639 --> 00:14:27,839
example of what we do um it's

336
00:14:25,000 --> 00:14:29,440
provocative it's conversational it's a

337
00:14:27,839 --> 00:14:31,959
learning system it's it's not a

338
00:14:29,440 --> 00:14:34,959
searching system it's an exploration

339
00:14:31,959 --> 00:14:38,040
system another thing that we work on is

340
00:14:34,959 --> 00:14:40,279
more specul speculative rather and and

341
00:14:38,040 --> 00:14:42,839
the idea is for those of you who are you

342
00:14:40,279 --> 00:14:44,320
know American or in the United States

343
00:14:42,839 --> 00:14:47,040
you probably heard there's a television

344
00:14:44,320 --> 00:14:49,560
show called Last Week Tonight by John

345
00:14:47,040 --> 00:14:52,120
Oliver it's a I actually like like the

346
00:14:49,560 --> 00:14:53,560
show well we said about the task of

347
00:14:52,120 --> 00:14:56,199
saying what if we could make our own

348
00:14:53,560 --> 00:14:58,199
show and we'll call it next week tonight

349
00:14:56,199 --> 00:15:01,959
okay so in this case now what we're

350
00:14:58,199 --> 00:15:06,480
doing is we're using um Ai and these

351
00:15:01,959 --> 00:15:09,800
large language models to speculate or

352
00:15:06,480 --> 00:15:12,480
predict the future but really as an

353
00:15:09,800 --> 00:15:14,759
exploration engine for you now if you

354
00:15:12,480 --> 00:15:17,600
think about the future particularly with

355
00:15:14,759 --> 00:15:20,480
respect to things like news I don't know

356
00:15:17,600 --> 00:15:23,600
how much of you how many of you are news

357
00:15:20,480 --> 00:15:26,199
mavens but if you read the newspaper

358
00:15:23,600 --> 00:15:30,079
most of the time or listen to the radio

359
00:15:26,199 --> 00:15:33,639
most of the time tomorrow's news is the

360
00:15:30,079 --> 00:15:37,160
same as today's okay yeah we had seven

361
00:15:33,639 --> 00:15:38,920
days of speculation before the debates

362
00:15:37,160 --> 00:15:41,040
um a couple of weeks ago and then when

363
00:15:38,920 --> 00:15:43,839
the debates came along we had three days

364
00:15:41,040 --> 00:15:46,639
of speculation as to who did best in in

365
00:15:43,839 --> 00:15:49,000
the debates right but pretty much it's

366
00:15:46,639 --> 00:15:50,920
like Steph J ghoul's theory of evolution

367
00:15:49,000 --> 00:15:53,519
we live in a world of punctuated

368
00:15:50,920 --> 00:15:56,759
equilibrium and that is to say things

369
00:15:53,519 --> 00:15:59,279
move along in a predictable way and then

370
00:15:56,759 --> 00:16:02,120
there's suddenly a major event like an

371
00:15:59,279 --> 00:16:04,519
asteroid falling in Mexico that changes

372
00:16:02,120 --> 00:16:07,279
that equilibrium or the Cambrian

373
00:16:04,519 --> 00:16:09,319
explosion that changes that so if you

374
00:16:07,279 --> 00:16:12,440
think about it and look at it maybe it's

375
00:16:09,319 --> 00:16:14,560
a bit like a power law most often

376
00:16:12,440 --> 00:16:17,480
tomorrow's news is going to be like

377
00:16:14,560 --> 00:16:20,199
today's and the impact that that's going

378
00:16:17,480 --> 00:16:21,959
to have the unforeseen impact is is

379
00:16:20,199 --> 00:16:25,279
small but

380
00:16:21,959 --> 00:16:26,959
occasionally less often than continuity

381
00:16:25,279 --> 00:16:28,199
there'll be a weather event maybe

382
00:16:26,959 --> 00:16:31,199
there's going to be a flood maybe a

383
00:16:28,199 --> 00:16:34,199
hurricane form something like that and

384
00:16:31,199 --> 00:16:36,079
the impact of that is greater uh maybe

385
00:16:34,199 --> 00:16:38,839
someone will discover a new source of

386
00:16:36,079 --> 00:16:41,079
lithium and that will change the balance

387
00:16:38,839 --> 00:16:42,800
of how we build Energy Systems and

388
00:16:41,079 --> 00:16:46,519
batteries in the future or

389
00:16:42,800 --> 00:16:49,920
Transportation you never know uh a barge

390
00:16:46,519 --> 00:16:51,680
or a ship might crash into a bridge uh

391
00:16:49,920 --> 00:16:54,000
it's been known to happen but you know

392
00:16:51,680 --> 00:16:56,480
there are Transportation things the

393
00:16:54,000 --> 00:16:58,519
impact of which is larger and the

394
00:16:56,480 --> 00:17:01,360
occurrence of them is rarer and of

395
00:16:58,519 --> 00:17:03,319
course nuclear disasters uh let's hope

396
00:17:01,360 --> 00:17:06,199
those are extremely rare but we know

397
00:17:03,319 --> 00:17:10,079
that the impact of those is higher so

398
00:17:06,199 --> 00:17:13,839
now what we can do is we can both take

399
00:17:10,079 --> 00:17:16,319
that and we can take your own

400
00:17:13,839 --> 00:17:18,959
suggestions as to what you think might

401
00:17:16,319 --> 00:17:20,559
disrupt your operations and I don't know

402
00:17:18,959 --> 00:17:22,520
whether it's a business plan or whether

403
00:17:20,559 --> 00:17:26,839
you're just planning a picnic for the

404
00:17:22,520 --> 00:17:29,280
weekend and say what would happen if the

405
00:17:26,839 --> 00:17:32,200
following things occurred Federal

406
00:17:29,280 --> 00:17:34,320
Reserve reduces interest rates by 2%

407
00:17:32,200 --> 00:17:36,679
which I suppose by now they might well

408
00:17:34,320 --> 00:17:37,960
have done uh if not they'll be doing it

409
00:17:36,679 --> 00:17:42,200
later this

410
00:17:37,960 --> 00:17:46,880
afternoon and you we can create for you

411
00:17:42,200 --> 00:17:50,520
a set of news articles that show and a

412
00:17:46,880 --> 00:17:53,600
narrative form what the impact of those

413
00:17:50,520 --> 00:17:57,240
might be and allow you to explore and

414
00:17:53,600 --> 00:17:59,919
juggle those I showed you my power law

415
00:17:57,240 --> 00:18:01,400
of Impact versus versus likelihood of

416
00:17:59,919 --> 00:18:04,240
occurrence but you all have a different

417
00:18:01,400 --> 00:18:06,520
one because you all have your own set of

418
00:18:04,240 --> 00:18:10,039
potentially disruptive events and what

419
00:18:06,520 --> 00:18:13,159
you want to see is what might happen if

420
00:18:10,039 --> 00:18:15,919
any of those occurred so we present that

421
00:18:13,159 --> 00:18:18,679
as news and let you interact with that

422
00:18:15,919 --> 00:18:21,200
the narrative is important because it

423
00:18:18,679 --> 00:18:24,880
needs to be again conversational and

424
00:18:21,200 --> 00:18:28,039
draw you out in a way that a list or an

425
00:18:24,880 --> 00:18:30,799
Excel spreadsheet wouldn't so that's

426
00:18:28,039 --> 00:18:33,640
where we be come truly speculative where

427
00:18:30,799 --> 00:18:36,240
making up the news I have no idea

428
00:18:33,640 --> 00:18:39,559
whether this is a good idea or a bad

429
00:18:36,240 --> 00:18:41,159
idea um but it's an example of one of

430
00:18:39,559 --> 00:18:43,919
the kinds of things that that we're

431
00:18:41,159 --> 00:18:45,919
going to try and we're going to test and

432
00:18:43,919 --> 00:18:48,559
see how much we can learn from we're not

433
00:18:45,919 --> 00:18:50,600
going to test how accurate we are okay

434
00:18:48,559 --> 00:18:53,280
we're not going to wait for those black

435
00:18:50,600 --> 00:18:55,600
swans to occur because let's hope that

436
00:18:53,280 --> 00:18:59,159
many of them don't occur but we're going

437
00:18:55,600 --> 00:19:01,440
to test whether you are prepared learned

438
00:18:59,159 --> 00:19:05,080
or what would happen in a variety of

439
00:19:01,440 --> 00:19:07,880
scenarios associated with those and

440
00:19:05,080 --> 00:19:10,799
finally and I'm only going to talk about

441
00:19:07,880 --> 00:19:14,280
this one very briefly um we're trying to

442
00:19:10,799 --> 00:19:17,760
use these interactions in real scenarios

443
00:19:14,280 --> 00:19:20,880
to allow you to explore and learn and

444
00:19:17,760 --> 00:19:23,400
focus and concentrate so this is a

445
00:19:20,880 --> 00:19:26,000
project on audio focus the Genesis of

446
00:19:23,400 --> 00:19:29,360
which was simply to allow you to use

447
00:19:26,000 --> 00:19:31,679
your head to focus your attention so

448
00:19:29,360 --> 00:19:34,280
that you could diminish the background

449
00:19:31,679 --> 00:19:36,720
distractions that make it hard and allow

450
00:19:34,280 --> 00:19:39,320
you to focus more on what you wanted to

451
00:19:36,720 --> 00:19:41,400
hear I have an image of friends with a

452
00:19:39,320 --> 00:19:44,080
hearing aid they put the microphone down

453
00:19:41,400 --> 00:19:46,480
on the table but they get all the noise

454
00:19:44,080 --> 00:19:48,440
from the rest of the restaurant and it's

455
00:19:46,480 --> 00:19:51,400
very difficult for them to direct that

456
00:19:48,440 --> 00:19:54,159
attention or think of sitting at a

457
00:19:51,400 --> 00:19:56,120
Thanksgiving table dinner and you end up

458
00:19:54,159 --> 00:19:59,039
having a conversation with the people on

459
00:19:56,120 --> 00:20:01,240
your end but sometimes you need a way to

460
00:19:59,039 --> 00:20:04,440
be able to focus on and bring into

461
00:20:01,240 --> 00:20:07,120
attention the others so we're using that

462
00:20:04,440 --> 00:20:10,320
and we're using AI to change and

463
00:20:07,120 --> 00:20:12,440
disambiguate and clarify the sounds that

464
00:20:10,320 --> 00:20:13,960
you can hear and there are uses for that

465
00:20:12,440 --> 00:20:17,400
that we didn't even think of when we

466
00:20:13,960 --> 00:20:20,280
started like for example if you have a

467
00:20:17,400 --> 00:20:23,280
debate where several people are talking

468
00:20:20,280 --> 00:20:25,600
in turn maybe you can organize that

469
00:20:23,280 --> 00:20:28,080
debate by topic let them all talk at

470
00:20:25,600 --> 00:20:30,480
once and you can let your attention go

471
00:20:28,080 --> 00:20:32,919
between the so that you can pick out

472
00:20:30,480 --> 00:20:35,240
what you want to learn from that debate

473
00:20:32,919 --> 00:20:38,360
in onethird of the time as opposed to

474
00:20:35,240 --> 00:20:40,440
listening to the entire time so that's

475
00:20:38,360 --> 00:20:42,640
all I'm going to say now and I won't

476
00:20:40,440 --> 00:20:46,120
keep you long from lunch but keep in

477
00:20:42,640 --> 00:20:49,760
mind that's the idea it's that diversity

478
00:20:46,120 --> 00:20:52,159
it's that merging of passion fun and the

479
00:20:49,760 --> 00:20:55,840
search for knowledge and that ability to

480
00:20:52,159 --> 00:20:58,159
work across disciplines and across ideas

481
00:20:55,840 --> 00:21:00,440
that characterize the way we do

482
00:20:58,159 --> 00:21:03,360
invention ions people think we innovate

483
00:21:00,440 --> 00:21:05,039
I don't think we innovate I was finally

484
00:21:03,360 --> 00:21:06,799
told the difference between invention

485
00:21:05,039 --> 00:21:09,600
and Innovation by a friend Jack

486
00:21:06,799 --> 00:21:13,120
Greenberg who was CEO of McDonald's for

487
00:21:09,600 --> 00:21:15,760
a while he said I get it Andy um

488
00:21:13,120 --> 00:21:17,640
Innovation invention is a bunch of guys

489
00:21:15,760 --> 00:21:19,400
messing around in the laboratory

490
00:21:17,640 --> 00:21:23,120
Innovation is a change in business

491
00:21:19,400 --> 00:21:25,240
process we concentrate on the invention

492
00:21:23,120 --> 00:21:27,520
but it isn't messing it's pointing you

493
00:21:25,240 --> 00:21:30,440
the way for you to innovate in the

494
00:21:27,520 --> 00:21:33,400
future so I hope you enjoyed the morning

495
00:21:30,440 --> 00:21:34,679
and we'll talk again thank you thank you

496
00:21:33,400 --> 00:21:39,400
very much

497
00:21:34,679 --> 00:21:39,400
Andie thank you again okay


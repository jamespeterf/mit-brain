1
00:00:02,000 --> 00:00:06,640
Uh yeah, thank you so much. So I um was

2
00:00:04,319 --> 00:00:09,920
assigned the task of like giving a

3
00:00:06,640 --> 00:00:11,519
primer just like by myself basically to

4
00:00:09,920 --> 00:00:15,120
uh set the scene and talk about the

5
00:00:11,519 --> 00:00:17,600
sequence to function models uh with some

6
00:00:15,120 --> 00:00:19,279
u historical context and a little bit of

7
00:00:17,600 --> 00:00:21,279
a language modeling tool and this is all

8
00:00:19,279 --> 00:00:23,680
just to set the scene for the next talk

9
00:00:21,279 --> 00:00:25,519
which is I think way more exciting uh

10
00:00:23,680 --> 00:00:28,560
than this one. So stay for the next one

11
00:00:25,519 --> 00:00:31,119
as well. Um so let me introduce the

12
00:00:28,560 --> 00:00:33,840
group first. Uh so sur so the right half

13
00:00:31,119 --> 00:00:35,760
of the team is basically here today and

14
00:00:33,840 --> 00:00:38,719
the left half is in South San Francisco

15
00:00:35,760 --> 00:00:40,399
at Genantic. Uh we are basically a group

16
00:00:38,719 --> 00:00:42,480
of people uh interested in regulatory

17
00:00:40,399 --> 00:00:44,640
genomics at Genantic.

18
00:00:42,480 --> 00:00:46,800
Um developing and applying AML methods,

19
00:00:44,640 --> 00:00:48,480
most sequence uh models, DNA and RNA

20
00:00:46,800 --> 00:00:51,280
sequence models uh to understand rules

21
00:00:48,480 --> 00:00:54,079
of gene regulation um and to support

22
00:00:51,280 --> 00:00:56,640
nucleus based medicine or therapeutics

23
00:00:54,079 --> 00:00:58,879
like cell and gene therapy for example

24
00:00:56,640 --> 00:01:01,039
and also to analyze um disease

25
00:00:58,879 --> 00:01:03,039
associated variants with these models to

26
00:01:01,039 --> 00:01:07,360
have um basically more like mechanistic

27
00:01:03,039 --> 00:01:10,720
insights into um diseases.

28
00:01:07,360 --> 00:01:13,200
Um so we are in in Janentech and Jed is

29
00:01:10,720 --> 00:01:15,600
the R&D part of Genantech led by Aviv uh

30
00:01:13,200 --> 00:01:18,320
and GCS is the computational sciences or

31
00:01:15,600 --> 00:01:22,080
the computational branch of Jed uh led

32
00:01:18,320 --> 00:01:23,759
by John Marioni and Braid is the the

33
00:01:22,080 --> 00:01:27,360
biology research and AI development

34
00:01:23,759 --> 00:01:28,799
department uh where we are in. Um so

35
00:01:27,360 --> 00:01:31,439
let's start with the the fundamental

36
00:01:28,799 --> 00:01:34,720
question uh of uh regulatory genomics

37
00:01:31,439 --> 00:01:36,240
which is basically all cells have like

38
00:01:34,720 --> 00:01:39,520
mostly the same genome but they

39
00:01:36,240 --> 00:01:41,920
interpret it very differently. Um

40
00:01:39,520 --> 00:01:43,600
so can we understand this code or how

41
00:01:41,920 --> 00:01:45,360
cells interpret these code differently

42
00:01:43,600 --> 00:01:47,040
so that they can function differently.

43
00:01:45,360 --> 00:01:49,439
Uh let me introduce some maybe basic

44
00:01:47,040 --> 00:01:53,040
concepts just so that we are all like on

45
00:01:49,439 --> 00:01:54,960
the same page. Uh so genes have proximal

46
00:01:53,040 --> 00:01:56,960
regulatory elements driving expression

47
00:01:54,960 --> 00:01:59,119
called promoters. um transcription

48
00:01:56,960 --> 00:02:01,840
factors are the proteins binding to

49
00:01:59,119 --> 00:02:03,920
regulatory elements uh and more dist

50
00:02:01,840 --> 00:02:05,280
elements and typically more cell type

51
00:02:03,920 --> 00:02:09,840
specific dist elements are called

52
00:02:05,280 --> 00:02:12,080
enhancers where TFS also bind um and

53
00:02:09,840 --> 00:02:14,959
cells basically express different uh

54
00:02:12,080 --> 00:02:17,920
repar of transcription factors to um

55
00:02:14,959 --> 00:02:20,319
modulate their gene expression profiles.

56
00:02:17,920 --> 00:02:22,640
And the second mechanism is also to make

57
00:02:20,319 --> 00:02:24,959
um the chromatin where these regulator

58
00:02:22,640 --> 00:02:28,000
elements are like physically accessible

59
00:02:24,959 --> 00:02:29,360
or inaccessible uh to regulate the the

60
00:02:28,000 --> 00:02:31,360
gene expression. So in this case for

61
00:02:29,360 --> 00:02:34,239
example the enhancer is accessible and

62
00:02:31,360 --> 00:02:37,680
here is not accessible and so on and so

63
00:02:34,239 --> 00:02:39,920
forth. So the two main mechanisms of uh

64
00:02:37,680 --> 00:02:42,080
gene regulation but these are really

65
00:02:39,920 --> 00:02:44,239
super high level principles. So uh we

66
00:02:42,080 --> 00:02:47,440
are interested in how exactly this works

67
00:02:44,239 --> 00:02:49,040
for like each gene in each cell type uh

68
00:02:47,440 --> 00:02:50,720
where these regulatory elements are and

69
00:02:49,040 --> 00:02:52,560
how exactly they are driving expression

70
00:02:50,720 --> 00:02:55,519
in different context. So this is kind of

71
00:02:52,560 --> 00:02:57,200
the fundamental uh question. Uh maybe

72
00:02:55,519 --> 00:02:58,879
let me introduce also some essays as

73
00:02:57,200 --> 00:03:01,840
well. Maybe all of you are already

74
00:02:58,879 --> 00:03:04,239
familiar but um just for the sake of

75
00:03:01,840 --> 00:03:08,319
completeness. Uh so chipsseek is the

76
00:03:04,239 --> 00:03:09,680
essay where we um profile binding site

77
00:03:08,319 --> 00:03:11,840
of proteins for example like

78
00:03:09,680 --> 00:03:14,560
transcription factors or histones and

79
00:03:11,840 --> 00:03:17,920
attackic and DNA seek um measure the

80
00:03:14,560 --> 00:03:20,000
accessibility of chromatin um and cage

81
00:03:17,920 --> 00:03:22,319
and RNA seek are the transcription level

82
00:03:20,000 --> 00:03:24,879
uh essays. So cage for the transcription

83
00:03:22,319 --> 00:03:27,040
initiation and RNA core the entire

84
00:03:24,879 --> 00:03:29,040
process of initiation and elongation

85
00:03:27,040 --> 00:03:32,720
which we can use as a proxy of steady

86
00:03:29,040 --> 00:03:34,799
state um mRNA concentrations

87
00:03:32,720 --> 00:03:38,080
um and we have these experimental

88
00:03:34,799 --> 00:03:39,680
methods basically to profile um these

89
00:03:38,080 --> 00:03:41,760
molecular events like genomite for

90
00:03:39,680 --> 00:03:44,239
example for the RNA seek what we end up

91
00:03:41,760 --> 00:03:47,519
with is a a huge one-dimensional vector

92
00:03:44,239 --> 00:03:50,239
of counts um showing where exactly the

93
00:03:47,519 --> 00:03:52,159
um expression or transcription happens

94
00:03:50,239 --> 00:03:54,560
And and similarly for a taxic and

95
00:03:52,159 --> 00:03:58,640
chipsseek we have these genomide um

96
00:03:54,560 --> 00:04:00,239
profiles of count. Um and because of the

97
00:03:58,640 --> 00:04:03,519
the sequence preference or sequence

98
00:04:00,239 --> 00:04:05,040
specific of the TFS uh we see strong

99
00:04:03,519 --> 00:04:08,000
association between some sequence

100
00:04:05,040 --> 00:04:10,640
features and and these uh dysfunctional

101
00:04:08,000 --> 00:04:13,200
tracks let's call it uh for chips for

102
00:04:10,640 --> 00:04:15,360
example it's maybe a simpler rule. So

103
00:04:13,200 --> 00:04:17,519
wherever the TF binds there's a specific

104
00:04:15,360 --> 00:04:20,079
motive for example underlying the the

105
00:04:17,519 --> 00:04:22,479
binding sites or these chips peaks for

106
00:04:20,079 --> 00:04:24,080
attack it's like a bit more complex

107
00:04:22,479 --> 00:04:26,160
because we have the combinator

108
00:04:24,080 --> 00:04:27,840
combinatorial rules of or combin

109
00:04:26,160 --> 00:04:30,400
combination of motifs basically driving

110
00:04:27,840 --> 00:04:32,479
the the accessibility and for RNA seek

111
00:04:30,400 --> 00:04:34,639
it's basically more advanced because or

112
00:04:32,479 --> 00:04:37,440
like more complex because of the distal

113
00:04:34,639 --> 00:04:40,720
regulators. So it's not uh maybe from

114
00:04:37,440 --> 00:04:42,639
like bottom up um the signal and rules

115
00:04:40,720 --> 00:04:44,960
get more complex and also more like

116
00:04:42,639 --> 00:04:48,320
distal uh from more local to more like

117
00:04:44,960 --> 00:04:50,560
global dist signal. Um so in addition to

118
00:04:48,320 --> 00:04:52,240
experimental methods we have basically u

119
00:04:50,560 --> 00:04:54,639
in silicon or like computational methods

120
00:04:52,240 --> 00:04:57,520
to study these associations of sequence

121
00:04:54,639 --> 00:04:59,280
features to functional tracks. Uh and

122
00:04:57,520 --> 00:05:02,880
the main method that I will talk about

123
00:04:59,280 --> 00:05:05,840
here is sequence to function models. Um

124
00:05:02,880 --> 00:05:07,360
so this is a super brief and very

125
00:05:05,840 --> 00:05:10,639
non-comprehensive

126
00:05:07,360 --> 00:05:13,120
u list of uh models that maybe initiated

127
00:05:10,639 --> 00:05:14,960
this whole uh research.

128
00:05:13,120 --> 00:05:16,800
Um so the machine learning formulation

129
00:05:14,960 --> 00:05:19,360
of the problem I just described. So

130
00:05:16,800 --> 00:05:22,560
which is um associating these sequences

131
00:05:19,360 --> 00:05:24,160
with the functional uh genomic signal is

132
00:05:22,560 --> 00:05:25,919
uh basically training a convolutional

133
00:05:24,160 --> 00:05:27,520
neural net with the with the DNA

134
00:05:25,919 --> 00:05:30,160
sequences.

135
00:05:27,520 --> 00:05:33,039
So if for example we have an attackic or

136
00:05:30,160 --> 00:05:38,000
DNA or chips crack um or the binding

137
00:05:33,039 --> 00:05:39,440
sites um where the um the the binary

138
00:05:38,000 --> 00:05:42,240
labels indicate whether there's a

139
00:05:39,440 --> 00:05:43,919
binding or like accessibility or or not.

140
00:05:42,240 --> 00:05:47,440
Uh this is kind of the label that the

141
00:05:43,919 --> 00:05:49,039
neural network is predicting and the um

142
00:05:47,440 --> 00:05:50,960
the surrounding sequence is basically

143
00:05:49,039 --> 00:05:52,960
the input of the the neural neural

144
00:05:50,960 --> 00:05:55,680
network. So as I described for the

145
00:05:52,960 --> 00:05:57,919
attack DNAs and and cheap cases uh this

146
00:05:55,680 --> 00:06:00,000
is relatively local. So a relatively

147
00:05:57,919 --> 00:06:04,520
small model typically explains the

148
00:06:00,000 --> 00:06:04,520
signal really well. Uh question

149
00:06:04,960 --> 00:06:08,720
these are quantitative values. These are

150
00:06:06,800 --> 00:06:10,960
not categorical labels that you're

151
00:06:08,720 --> 00:06:12,639
predicting, right? So the original

152
00:06:10,960 --> 00:06:14,240
tracks are counts because we basically

153
00:06:12,639 --> 00:06:16,080
count like how many reads are mapped to

154
00:06:14,240 --> 00:06:19,440
this specific position for like each

155
00:06:16,080 --> 00:06:21,360
base. Uh but we can transform or um

156
00:06:19,440 --> 00:06:23,680
normalize them in different ways but the

157
00:06:21,360 --> 00:06:26,160
original signal is basically count.

158
00:06:23,680 --> 00:06:28,000
Yeah. So the first generation or first

159
00:06:26,160 --> 00:06:30,080
wave of methods basically simplified the

160
00:06:28,000 --> 00:06:31,759
question. So they binarize the signal.

161
00:06:30,080 --> 00:06:33,919
So whether there's a binding event or

162
00:06:31,759 --> 00:06:35,919
not for example uh sorry the prediction

163
00:06:33,919 --> 00:06:37,520
is maybe easier and the the loss

164
00:06:35,919 --> 00:06:42,240
function is like very typical binary

165
00:06:37,520 --> 00:06:43,919
cross entropy. Um and it was a the first

166
00:06:42,240 --> 00:06:47,120
generation of these models used a

167
00:06:43,919 --> 00:06:49,840
multitask setting. So from one um from

168
00:06:47,120 --> 00:06:55,039
the same input DNA you basically predict

169
00:06:49,840 --> 00:06:56,479
like multiple um binary events. Um

170
00:06:55,039 --> 00:06:58,560
then the second generation or like

171
00:06:56,479 --> 00:07:01,039
second kind of wave of models is the

172
00:06:58,560 --> 00:07:03,199
profile models. So instead of binarizing

173
00:07:01,039 --> 00:07:05,759
and losing some information for the

174
00:07:03,199 --> 00:07:07,840
functional tracks people switched I

175
00:07:05,759 --> 00:07:11,840
think JA initiated it in the BPET paper

176
00:07:07,840 --> 00:07:14,319
in uh uh 2021 instead of binarizing the

177
00:07:11,840 --> 00:07:17,120
event basically take the whole shape and

178
00:07:14,319 --> 00:07:20,960
magnitude of the the signal into account

179
00:07:17,120 --> 00:07:23,120
uh by just modeling the profile exactly.

180
00:07:20,960 --> 00:07:24,800
uh and there are many interesting

181
00:07:23,120 --> 00:07:26,639
features of the the profiles and the

182
00:07:24,800 --> 00:07:28,240
shape of the profiles especially the

183
00:07:26,639 --> 00:07:29,919
attack signal is like really interesting

184
00:07:28,240 --> 00:07:33,360
and swag will also mention some

185
00:07:29,919 --> 00:07:35,440
interesting properties of it um it

186
00:07:33,360 --> 00:07:38,000
started with the chip nexus or like

187
00:07:35,440 --> 00:07:40,319
chips seek tracks uh and now there's a

188
00:07:38,000 --> 00:07:43,120
recent prep from Kaja lab um extending

189
00:07:40,319 --> 00:07:47,199
this to a taxi uh with lots of

190
00:07:43,120 --> 00:07:48,800
interesting analysis uh check it out um

191
00:07:47,199 --> 00:07:50,400
but the models are still local right

192
00:07:48,800 --> 00:07:53,440
because we are still predicting like

193
00:07:50,400 --> 00:07:56,240
accessibility for example or like um TFC

194
00:07:53,440 --> 00:07:58,879
uh which is a local signal. Uh so the

195
00:07:56,240 --> 00:08:00,960
models are still taking 1 to 2 KB input

196
00:07:58,879 --> 00:08:03,280
window and then predicting also like 1

197
00:08:00,960 --> 00:08:05,680
KB output for example in the base pair

198
00:08:03,280 --> 00:08:09,440
resolution. So for each base uh there's

199
00:08:05,680 --> 00:08:11,680
a prediction made. Um but this changed a

200
00:08:09,440 --> 00:08:13,680
few things in the uh in in modeling

201
00:08:11,680 --> 00:08:15,599
basically one is like the loss function

202
00:08:13,680 --> 00:08:17,919
for example like how what is the right

203
00:08:15,599 --> 00:08:19,440
way of uh modeling the profile itself.

204
00:08:17,919 --> 00:08:22,080
Should we take the count structure into

205
00:08:19,440 --> 00:08:24,240
account for example like using a a poson

206
00:08:22,080 --> 00:08:27,520
or like a multinnomial loss for example

207
00:08:24,240 --> 00:08:29,680
within this window window. Um and the

208
00:08:27,520 --> 00:08:31,120
receptive field is more important here

209
00:08:29,680 --> 00:08:32,640
as well because in the binary you

210
00:08:31,120 --> 00:08:34,640
basically use the entire sequence but in

211
00:08:32,640 --> 00:08:36,320
this case we need to think about what

212
00:08:34,640 --> 00:08:38,800
the right receptive field of an

213
00:08:36,320 --> 00:08:41,919
individual base like on the output side

214
00:08:38,800 --> 00:08:44,159
should be on the input side. Um so these

215
00:08:41,919 --> 00:08:47,200
are the new challenges that emerge in

216
00:08:44,159 --> 00:08:49,040
the profile modeling.

217
00:08:47,200 --> 00:08:52,399
And third and maybe the last kind of

218
00:08:49,040 --> 00:08:56,160
wave of or like group of methods uh is

219
00:08:52,399 --> 00:08:57,920
basically larger models. Um so imagine

220
00:08:56,160 --> 00:09:00,880
instead of like looking at individual

221
00:08:57,920 --> 00:09:02,959
binding sites or um attackic peaks you

222
00:09:00,880 --> 00:09:05,440
just tile the entire genome and for each

223
00:09:02,959 --> 00:09:07,839
tile you just stack all the functional

224
00:09:05,440 --> 00:09:11,200
data you have including chipsseek attack

225
00:09:07,839 --> 00:09:13,440
DNA seek um

226
00:09:11,200 --> 00:09:16,240
and like cage for example KC like the

227
00:09:13,440 --> 00:09:18,080
transcription initiation uh and these

228
00:09:16,240 --> 00:09:20,399
types are really really large like 200

229
00:09:18,080 --> 00:09:23,040
to 500 KB

230
00:09:20,399 --> 00:09:24,399
um and this this is how you train the

231
00:09:23,040 --> 00:09:25,920
model basically without selecting any

232
00:09:24,399 --> 00:09:27,760
specific by positive and negative

233
00:09:25,920 --> 00:09:29,360
regions. You tile the entire genome,

234
00:09:27,760 --> 00:09:32,160
stack all the functional tracks you have

235
00:09:29,360 --> 00:09:35,360
as a as a profile uh and and you make a

236
00:09:32,160 --> 00:09:37,279
prediction. Uh scaling becomes an issue.

237
00:09:35,360 --> 00:09:40,240
Um there are some tricks for example

238
00:09:37,279 --> 00:09:43,360
like bin the output uh like eight or 32

239
00:09:40,240 --> 00:09:45,680
base pair bin output is like one simple

240
00:09:43,360 --> 00:09:47,920
trick uh to reduce the dimensionality of

241
00:09:45,680 --> 00:09:50,480
the output. But the the idea is to

242
00:09:47,920 --> 00:09:52,080
basically treat all of them uh the same

243
00:09:50,480 --> 00:09:54,000
and make all the predictions all at

244
00:09:52,080 --> 00:09:56,880
once. So these are extremely large

245
00:09:54,000 --> 00:09:59,040
models um both in terms of the input

246
00:09:56,880 --> 00:10:01,680
length but also in terms of the the

247
00:09:59,040 --> 00:10:05,440
number of things that they predict um so

248
00:10:01,680 --> 00:10:08,959
7 8,000 tracks are from multiple

249
00:10:05,440 --> 00:10:12,000
organisms like from human and mouse um

250
00:10:08,959 --> 00:10:14,640
predicted by this the same model.

251
00:10:12,000 --> 00:10:16,720
Um

252
00:10:14,640 --> 00:10:19,600
yeah, this is for example like one nice

253
00:10:16,720 --> 00:10:22,079
example from the Bourzo paper uh uh from

254
00:10:19,600 --> 00:10:25,120
from Kico where they added the RNAC

255
00:10:22,079 --> 00:10:26,720
profiles which I think changed the um

256
00:10:25,120 --> 00:10:29,519
sequence to function modeling quite a

257
00:10:26,720 --> 00:10:31,200
lot. So initially like people interested

258
00:10:29,519 --> 00:10:33,360
in like regulatory genomics were using

259
00:10:31,200 --> 00:10:35,120
these models for different downstream

260
00:10:33,360 --> 00:10:37,760
tasks that I will also mention in the

261
00:10:35,120 --> 00:10:39,360
next slides. uh but with the uh gene

262
00:10:37,760 --> 00:10:41,839
expression modeling I think it opens up

263
00:10:39,360 --> 00:10:44,720
like new avenues and basically new types

264
00:10:41,839 --> 00:10:46,880
of analysis that one can do with these

265
00:10:44,720 --> 00:10:48,800
profiles. So the training didn't change

266
00:10:46,880 --> 00:10:51,839
much. Uh still there are large like

267
00:10:48,800 --> 00:10:53,519
tiles of uh windows. It's RN seek is

268
00:10:51,839 --> 00:10:56,480
just like added as a new modality and

269
00:10:53,519 --> 00:10:59,839
the training is is basically the same.

270
00:10:56,480 --> 00:11:01,760
Um but models learned like started

271
00:10:59,839 --> 00:11:04,000
learning basically lots of new things

272
00:11:01,760 --> 00:11:06,079
right for example if you add an track

273
00:11:04,000 --> 00:11:08,560
the we are basically guiding the model

274
00:11:06,079 --> 00:11:11,519
to learn about like splicing uh splicing

275
00:11:08,560 --> 00:11:13,120
to or like alternative polination and uh

276
00:11:11,519 --> 00:11:15,279
basically new information about

277
00:11:13,120 --> 00:11:18,079
regulatory genomics. So in this case we

278
00:11:15,279 --> 00:11:20,000
see the EGFR gene and all the peaks

279
00:11:18,079 --> 00:11:22,959
basically represent the reads mapped to

280
00:11:20,000 --> 00:11:25,839
the exonic regions. Um and and the

281
00:11:22,959 --> 00:11:29,040
prediction looks looks really good. Um

282
00:11:25,839 --> 00:11:30,640
but there are a few issues. So um issue

283
00:11:29,040 --> 00:11:34,480
number one is basically this is limited

284
00:11:30,640 --> 00:11:36,079
to um GTEX and encode balic tracks. Um

285
00:11:34,480 --> 00:11:38,480
and there is lots of cool biology

286
00:11:36,079 --> 00:11:40,399
happening in single cell for example uh

287
00:11:38,480 --> 00:11:43,519
which is not really modeled in in this

288
00:11:40,399 --> 00:11:45,279
case. And the second one is basically um

289
00:11:43,519 --> 00:11:47,680
people with like more focusing on

290
00:11:45,279 --> 00:11:49,120
expression in in many cases they don't

291
00:11:47,680 --> 00:11:50,720
really care much about profiles. They

292
00:11:49,120 --> 00:11:52,640
care about the expression levels across

293
00:11:50,720 --> 00:11:54,560
conditions across tissues or different

294
00:11:52,640 --> 00:11:57,279
regulators of different genes in

295
00:11:54,560 --> 00:12:00,399
different contexts. Um so although the

296
00:11:57,279 --> 00:12:02,399
profile modeling of RNA seek enables

297
00:12:00,399 --> 00:12:05,279
different types of analysis for many

298
00:12:02,399 --> 00:12:07,760
people um there are different questions

299
00:12:05,279 --> 00:12:09,600
that we ask about like the the what are

300
00:12:07,760 --> 00:12:11,360
the regulators of a specific gene in

301
00:12:09,600 --> 00:12:14,000
different contexts.

302
00:12:11,360 --> 00:12:16,240
Um and if you basically keep adding the

303
00:12:14,000 --> 00:12:19,279
single and another another issue is that

304
00:12:16,240 --> 00:12:22,320
the single cell arc profiles are not

305
00:12:19,279 --> 00:12:23,760
super trivial to to um preprocess in in

306
00:12:22,320 --> 00:12:26,399
many cases we don't even have access to

307
00:12:23,760 --> 00:12:29,200
it. people simply use like the counts.

308
00:12:26,399 --> 00:12:31,360
Uh so count is kind of the main

309
00:12:29,200 --> 00:12:33,760
representation of the data in single

310
00:12:31,360 --> 00:12:36,720
seric. So it doesn't fully fit in this

311
00:12:33,760 --> 00:12:38,480
paradigm that is now a basically a

312
00:12:36,720 --> 00:12:43,120
continuation of the uh previous

313
00:12:38,480 --> 00:12:45,040
iterations of these models. Question

314
00:12:43,120 --> 00:12:47,920
uh when you just referred to the counts

315
00:12:45,040 --> 00:12:49,279
are you talking about uh gene by count?

316
00:12:47,920 --> 00:12:50,959
Yes. Okay. Thank you. And by gene

317
00:12:49,279 --> 00:12:55,040
matrices

318
00:12:50,959 --> 00:12:57,680
coms represent the expression levels.

319
00:12:55,040 --> 00:12:59,680
So the last um model I will talk about

320
00:12:57,680 --> 00:13:03,760
is like our work decima basically where

321
00:12:59,680 --> 00:13:05,680
we um did this. Um so the the visual

322
00:13:03,760 --> 00:13:07,920
representation is different but the idea

323
00:13:05,680 --> 00:13:10,079
is to have the sequences around the

324
00:13:07,920 --> 00:13:12,399
genes like a pretty large window same as

325
00:13:10,079 --> 00:13:14,720
as the war model like half megabase

326
00:13:12,399 --> 00:13:16,480
window and predicting expression of

327
00:13:14,720 --> 00:13:18,079
genes in different context. So this is a

328
00:13:16,480 --> 00:13:20,560
busy slide but let me walk you through

329
00:13:18,079 --> 00:13:22,720
it. Uh so the sequence window is same as

330
00:13:20,560 --> 00:13:24,320
the Bzo model and the model is already

331
00:13:22,720 --> 00:13:27,040
uh pre-trained. So we are find

332
00:13:24,320 --> 00:13:28,880
technically fine-tuning Borso model. Um

333
00:13:27,040 --> 00:13:30,560
and we show them and and this is a gene

334
00:13:28,880 --> 00:13:32,880
level model. So the observations are

335
00:13:30,560 --> 00:13:34,399
genes but the model is pre-trained on

336
00:13:32,880 --> 00:13:37,360
the entire genome with different

337
00:13:34,399 --> 00:13:40,959
modalities like chipsseek attack and RNA

338
00:13:37,360 --> 00:13:43,360
and and DNA. Uh and for each gene we

339
00:13:40,959 --> 00:13:45,360
have um thousands of different contexts

340
00:13:43,360 --> 00:13:47,519
where this gene is is expressed. Right?

341
00:13:45,360 --> 00:13:49,680
So these are the columns uh that are

342
00:13:47,519 --> 00:13:51,680
shown here. uh and rows are different

343
00:13:49,680 --> 00:13:53,120
pseudo box. So instead of using the

344
00:13:51,680 --> 00:13:56,079
single cell data really at the single

345
00:13:53,120 --> 00:13:58,000
cell level uh we collapse single cells

346
00:13:56,079 --> 00:14:00,079
to like pseudo box representing

347
00:13:58,000 --> 00:14:03,360
different cell types in different

348
00:14:00,079 --> 00:14:05,760
studies, conditions and tissues. Uh so

349
00:14:03,360 --> 00:14:08,639
this basically uh gives us thousands of

350
00:14:05,760 --> 00:14:11,120
pseudobach profiles. Uh now that we have

351
00:14:08,639 --> 00:14:14,000
many atlases uh that are already syped

352
00:14:11,120 --> 00:14:16,639
and nicely annotated um we can simply

353
00:14:14,000 --> 00:14:18,880
access these uh annotated atlas data

354
00:14:16,639 --> 00:14:21,600
sets and prepare the pseudo box and

355
00:14:18,880 --> 00:14:24,079
fine-tune the model on these pseudo box.

356
00:14:21,600 --> 00:14:26,240
Uh so let's say you look at EGFR but in

357
00:14:24,079 --> 00:14:28,639
this case you look at it in the healthy

358
00:14:26,240 --> 00:14:30,639
fibroblast context let's say Crohn's

359
00:14:28,639 --> 00:14:32,720
disease fibroblast context macrofage

360
00:14:30,639 --> 00:14:37,760
context and and so on and so forth. So

361
00:14:32,720 --> 00:14:39,760
each row in this case is is one suitable

362
00:14:37,760 --> 00:14:41,040
Um and this solves some of the issues

363
00:14:39,760 --> 00:14:42,480
that I mentioned. So we don't really

364
00:14:41,040 --> 00:14:43,760
care much about profiles. We are

365
00:14:42,480 --> 00:14:46,800
interested in different sets of

366
00:14:43,760 --> 00:14:49,839
questions like the um context specific

367
00:14:46,800 --> 00:14:52,079
regulators of these genes. Um and we

368
00:14:49,839 --> 00:14:54,639
also want to scale it up in terms of uh

369
00:14:52,079 --> 00:14:57,920
samples and studies and single cell data

370
00:14:54,639 --> 00:15:00,720
sets. Um and this is led by Avantic and

371
00:14:57,920 --> 00:15:02,480
and Alex. Um

372
00:15:00,720 --> 00:15:05,440
so how do we use these models? what what

373
00:15:02,480 --> 00:15:07,839
are they useful uh or what what do

374
00:15:05,440 --> 00:15:10,800
people use it uh for in general and I

375
00:15:07,839 --> 00:15:12,639
will exemplify uh major some major

376
00:15:10,800 --> 00:15:16,000
common downstream tasks using the

377
00:15:12,639 --> 00:15:18,240
decimal model one question um how much

378
00:15:16,000 --> 00:15:21,760
did using Boroy for like the

379
00:15:18,240 --> 00:15:24,720
pre-training help versus just training a

380
00:15:21,760 --> 00:15:28,079
model from scratch and I'm just curious

381
00:15:24,720 --> 00:15:32,720
because like the human cell atlas right

382
00:15:28,079 --> 00:15:34,639
it's human data and everybody has

383
00:15:32,720 --> 00:15:37,680
different snips and whatever and then

384
00:15:34,639 --> 00:15:39,760
Borzo is trained on I think like cell

385
00:15:37,680 --> 00:15:41,600
lines and it's just very different

386
00:15:39,760 --> 00:15:45,839
genetic background. So I'm just kind of

387
00:15:41,600 --> 00:15:47,600
curious if Borzoy helped a lot or just

388
00:15:45,839 --> 00:15:50,160
just because of that kind of issue.

389
00:15:47,600 --> 00:15:51,600
Yeah, it it helps really a lot. I mean

390
00:15:50,160 --> 00:15:54,560
this is the the short answer. you don't

391
00:15:51,600 --> 00:15:57,759
have the full ablations uh because one

392
00:15:54,560 --> 00:15:59,839
can technically do also boro like models

393
00:15:57,759 --> 00:16:02,320
but also leaving out or like holding out

394
00:15:59,839 --> 00:16:04,240
some modalities entirely uh like an

395
00:16:02,320 --> 00:16:06,639
attack only boro for example or like the

396
00:16:04,240 --> 00:16:08,720
the full model or also decima from

397
00:16:06,639 --> 00:16:12,639
scratch instead of pre-training uh but

398
00:16:08,720 --> 00:16:14,160
overall it helps a lot um and one simple

399
00:16:12,639 --> 00:16:15,839
way to see it is basically if you look

400
00:16:14,160 --> 00:16:18,079
at the gradients of the model it nicely

401
00:16:15,839 --> 00:16:21,040
overlaps with the attackic signal so the

402
00:16:18,079 --> 00:16:22,880
taxic is one of the main um modality

403
00:16:21,040 --> 00:16:25,040
ities that model is still kind of

404
00:16:22,880 --> 00:16:28,240
remembering and and using for expression

405
00:16:25,040 --> 00:16:30,320
prediction. Um but yeah, it helps really

406
00:16:28,240 --> 00:16:32,160
a lot.

407
00:16:30,320 --> 00:16:34,000
Um

408
00:16:32,160 --> 00:16:36,720
yeah, so common downstream tasks. So

409
00:16:34,000 --> 00:16:38,880
this I think most of these tasks were

410
00:16:36,720 --> 00:16:42,639
already in the deepc paper in 2015 and

411
00:16:38,880 --> 00:16:45,680
we still keep um using or basically

412
00:16:42,639 --> 00:16:47,440
exploring these models uh uh using like

413
00:16:45,680 --> 00:16:49,279
in the context of these uh downstream

414
00:16:47,440 --> 00:16:51,199
tasks. One is basically interpretation.

415
00:16:49,279 --> 00:16:53,600
So the models are relatively

416
00:16:51,199 --> 00:16:55,279
interpretable. Um when we make the

417
00:16:53,600 --> 00:16:56,639
prediction, we can simply take like the

418
00:16:55,279 --> 00:16:58,800
gradients or interpret the model in

419
00:16:56,639 --> 00:17:00,160
different ways to find uh the sequence

420
00:16:58,800 --> 00:17:03,839
elements that are really driving the

421
00:17:00,160 --> 00:17:05,679
prediction. Um which is kind of the main

422
00:17:03,839 --> 00:17:08,160
methodology to understand the regulatory

423
00:17:05,679 --> 00:17:10,400
rules uh that we are interested in. Uh

424
00:17:08,160 --> 00:17:12,319
synthetic sequence design is is another

425
00:17:10,400 --> 00:17:15,600
interesting direction uh that is getting

426
00:17:12,319 --> 00:17:17,120
more popular these days. um uh basically

427
00:17:15,600 --> 00:17:18,799
designing promoters and enhancers for

428
00:17:17,120 --> 00:17:20,720
like therapeutic applications with

429
00:17:18,799 --> 00:17:23,839
desired properties which is typically

430
00:17:20,720 --> 00:17:27,280
cell type specific uh expression uh but

431
00:17:23,839 --> 00:17:28,799
I will show some um

432
00:17:27,280 --> 00:17:31,600
basically generalizations or like

433
00:17:28,799 --> 00:17:34,000
different kind of flavors of it uh in in

434
00:17:31,600 --> 00:17:36,480
the next slides as well. So var effect

435
00:17:34,000 --> 00:17:38,000
prediction is another common task. So

436
00:17:36,480 --> 00:17:40,320
basically querying the model with some

437
00:17:38,000 --> 00:17:43,120
counterfactual counterfactuals which is

438
00:17:40,320 --> 00:17:45,039
like what if I had the reference al in

439
00:17:43,120 --> 00:17:49,360
this case and how would it change the

440
00:17:45,039 --> 00:17:51,200
the predictions. So this gives us um

441
00:17:49,360 --> 00:17:53,200
a method to quantify the predicted

442
00:17:51,200 --> 00:17:54,559
effect of a of a variant for example uh

443
00:17:53,200 --> 00:17:57,200
so that we have a more mechanistic

444
00:17:54,559 --> 00:17:59,760
understanding of the variant. uh this

445
00:17:57,200 --> 00:18:02,240
might link for example the TF uh that is

446
00:17:59,760 --> 00:18:04,480
affected by the variant uh in a in the

447
00:18:02,240 --> 00:18:07,600
context of a specific uh regulatory

448
00:18:04,480 --> 00:18:09,360
element in in a um linked to a specific

449
00:18:07,600 --> 00:18:12,160
gene in the context of a specific cell

450
00:18:09,360 --> 00:18:14,240
type for example and there are some nice

451
00:18:12,160 --> 00:18:16,160
papers using these models as oracles and

452
00:18:14,240 --> 00:18:17,440
they basically come come up with really

453
00:18:16,160 --> 00:18:20,320
interesting creative insilica

454
00:18:17,440 --> 00:18:22,720
experiments um like given that the model

455
00:18:20,320 --> 00:18:26,400
takes a really large like the large most

456
00:18:22,720 --> 00:18:28,880
of these apply to large models uh the

457
00:18:26,400 --> 00:18:30,400
the third category basically especially

458
00:18:28,880 --> 00:18:33,039
the last one because you can come up

459
00:18:30,400 --> 00:18:35,679
with some creative ways of um quering

460
00:18:33,039 --> 00:18:38,799
these models uh like in the cream paper

461
00:18:35,679 --> 00:18:40,240
for example Shush Shushan um came up

462
00:18:38,799 --> 00:18:42,000
with like interesting ways for example

463
00:18:40,240 --> 00:18:43,840
if you move the a specific regulator

464
00:18:42,000 --> 00:18:45,360
element around like closer to TSS or

465
00:18:43,840 --> 00:18:47,440
like farther from TSS how would it

466
00:18:45,360 --> 00:18:50,000
change the expression or if you shuffle

467
00:18:47,440 --> 00:18:52,160
a specific enhancer sequence what is the

468
00:18:50,000 --> 00:18:54,960
impact of it in in a specific gene and

469
00:18:52,160 --> 00:18:56,640
so on and so forth. Um and in our

470
00:18:54,960 --> 00:18:59,200
examples for example we are using these

471
00:18:56,640 --> 00:19:00,799
large models to um score shorter

472
00:18:59,200 --> 00:19:04,880
sequences

473
00:19:00,799 --> 00:19:06,400
um where we use um basically we use like

474
00:19:04,880 --> 00:19:09,520
shorter regulatory elements in the

475
00:19:06,400 --> 00:19:11,919
context of um uh yeah I will I will show

476
00:19:09,520 --> 00:19:14,320
basically how we how we use it in this

477
00:19:11,919 --> 00:19:16,320
context. So the first example is about

478
00:19:14,320 --> 00:19:18,799
the interpretability like as I mentioned

479
00:19:16,320 --> 00:19:21,039
the decimal model is making predictions

480
00:19:18,799 --> 00:19:24,400
uh of gene expression in thousands of

481
00:19:21,039 --> 00:19:25,600
contexts. uh one thing for example to

482
00:19:24,400 --> 00:19:27,200
look at I mean the first thing to look

483
00:19:25,600 --> 00:19:29,200
at for example in the context of one

484
00:19:27,200 --> 00:19:32,400
specific gene is whether the predictions

485
00:19:29,200 --> 00:19:35,280
make sense or um it basically accurately

486
00:19:32,400 --> 00:19:37,919
predicts the um the gene expression. So

487
00:19:35,280 --> 00:19:41,760
this is a test set gene a gene that I

488
00:19:37,919 --> 00:19:43,760
like um because the some of the genes

489
00:19:41,760 --> 00:19:45,840
expressed in a few very different cell

490
00:19:43,760 --> 00:19:47,200
types but not markers of these cell

491
00:19:45,840 --> 00:19:49,520
types and also not the housekeeping

492
00:19:47,200 --> 00:19:51,120
genes I think are really interesting. Uh

493
00:19:49,520 --> 00:19:54,160
so in this case we see that the

494
00:19:51,120 --> 00:19:55,360
expression is uh highly correlated uh

495
00:19:54,160 --> 00:19:57,440
the predicted expression is highly

496
00:19:55,360 --> 00:19:59,440
correlated with the measured expression.

497
00:19:57,440 --> 00:20:03,360
Um and there are some tricks in the

498
00:19:59,440 --> 00:20:05,600
model to um force the model to capture

499
00:20:03,360 --> 00:20:07,919
like cell type specificity uh more

500
00:20:05,600 --> 00:20:09,520
accurately and which is what we see in

501
00:20:07,919 --> 00:20:12,320
this panel here. So this gene is

502
00:20:09,520 --> 00:20:15,919
expressed in some brain cell types and

503
00:20:12,320 --> 00:20:17,919
some lung epithelial cells um which is

504
00:20:15,919 --> 00:20:19,840
what we are showing on the right side.

505
00:20:17,919 --> 00:20:21,760
uh and we see a similar pattern for the

506
00:20:19,840 --> 00:20:23,600
predictions as well. So the predictions

507
00:20:21,760 --> 00:20:26,720
look good. Uh then we can start looking

508
00:20:23,600 --> 00:20:29,039
at the regulators of this gene. Um which

509
00:20:26,720 --> 00:20:32,480
is what we see here. So basically we

510
00:20:29,039 --> 00:20:34,400
look at the gradients. Um

511
00:20:32,480 --> 00:20:36,240
so yeah this this part is really

512
00:20:34,400 --> 00:20:39,039
critical I think because we look at the

513
00:20:36,240 --> 00:20:41,039
gradients of a specific output uh with

514
00:20:39,039 --> 00:20:43,440
respect to input and we basically show

515
00:20:41,039 --> 00:20:46,640
the uh input sequence regions driving

516
00:20:43,440 --> 00:20:49,360
the predictions uh of this gene in the

517
00:20:46,640 --> 00:20:50,880
context of a spec one specific cell type

518
00:20:49,360 --> 00:20:52,720
because it will get more complicated in

519
00:20:50,880 --> 00:20:55,120
the next slides. And in this case we

520
00:20:52,720 --> 00:20:58,159
basically look around the the TSS region

521
00:20:55,120 --> 00:20:59,600
and we see the regulators of the um

522
00:20:58,159 --> 00:21:01,919
regulators of the of the gene for

523
00:20:59,600 --> 00:21:04,720
example the RFIX uh motifs around the

524
00:21:01,919 --> 00:21:06,960
TSS. Um

525
00:21:04,720 --> 00:21:08,400
but since the uh the input window is

526
00:21:06,960 --> 00:21:10,159
basically half megabase you see

527
00:21:08,400 --> 00:21:15,400
different patterns throughout the the

528
00:21:10,159 --> 00:21:15,400
entire window. Uh question

529
00:21:17,200 --> 00:21:21,120
input to output are those integrated

530
00:21:19,679 --> 00:21:23,600
gradients from input to output that

531
00:21:21,120 --> 00:21:28,360
we're talking about. Yes, the input uh

532
00:21:23,600 --> 00:21:28,360
input times gradient.

533
00:21:28,799 --> 00:21:34,320
Um so another thing for example we can

534
00:21:32,000 --> 00:21:36,799
look look at is not the the proximal

535
00:21:34,320 --> 00:21:38,880
elements but also the um the distal

536
00:21:36,799 --> 00:21:41,280
ones. So in this case we are looking at

537
00:21:38,880 --> 00:21:44,240
um again the attributions

538
00:21:41,280 --> 00:21:47,440
um of the expression of the fab fab P1

539
00:21:44,240 --> 00:21:50,080
team and this is uh the Tata box nicely

540
00:21:47,440 --> 00:21:52,640
captured by the model around the TSS. So

541
00:21:50,080 --> 00:21:54,159
the model recognizes it as a as a

542
00:21:52,640 --> 00:21:56,799
promoter. I think this is also one of

543
00:21:54,159 --> 00:21:59,120
the um features that are learned during

544
00:21:56,799 --> 00:22:00,720
the pre-training. So the model is not

545
00:21:59,120 --> 00:22:02,400
maybe learning what a promoter looks

546
00:22:00,720 --> 00:22:04,400
like because it probably knows it really

547
00:22:02,400 --> 00:22:05,919
well already from the pre-training. uh

548
00:22:04,400 --> 00:22:07,200
and the cool thing about this gene is

549
00:22:05,919 --> 00:22:09,919
also it's expressed in two very

550
00:22:07,200 --> 00:22:12,799
different cell types like entites

551
00:22:09,919 --> 00:22:15,360
and now we can look at the attributions

552
00:22:12,799 --> 00:22:17,360
uh of the entite signal and hpocy signal

553
00:22:15,360 --> 00:22:20,720
separately and then see basically if the

554
00:22:17,360 --> 00:22:22,480
model is capturing any sype specificity

555
00:22:20,720 --> 00:22:24,480
and in the proximal case or in the

556
00:22:22,480 --> 00:22:26,480
promoter case you basically don't see a

557
00:22:24,480 --> 00:22:28,320
big difference so it just sees a

558
00:22:26,480 --> 00:22:30,400
promoter

559
00:22:28,320 --> 00:22:32,320
but if you look at a dist element which

560
00:22:30,400 --> 00:22:34,400
is the enhancer of potentially the

561
00:22:32,320 --> 00:22:37,039
enhancer reputative enhancer of FAP P1

562
00:22:34,400 --> 00:22:38,480
gene uh the attributions look different

563
00:22:37,039 --> 00:22:41,679
because the model interprets the the

564
00:22:38,480 --> 00:22:44,080
enhancer differently. So uh we see three

565
00:22:41,679 --> 00:22:48,960
transcription factors in the entite case

566
00:22:44,080 --> 00:22:52,000
the SEP CDX and RX. Uh and only two of

567
00:22:48,960 --> 00:22:53,679
them light up in the height case. Uh so

568
00:22:52,000 --> 00:22:55,840
this is basically what we mean by the

569
00:22:53,679 --> 00:22:58,720
regulatory grammar or or the regulatory

570
00:22:55,840 --> 00:23:00,159
code that drives expression. Um so

571
00:22:58,720 --> 00:23:01,760
although the cells are looking at the

572
00:23:00,159 --> 00:23:04,080
the same genome they basically interpret

573
00:23:01,760 --> 00:23:06,480
it differently because the they express

574
00:23:04,080 --> 00:23:10,240
different transcription factors which is

575
00:23:06,480 --> 00:23:11,919
uh what I show here. So uh CBP a

576
00:23:10,240 --> 00:23:14,240
transcription factor across different

577
00:23:11,919 --> 00:23:17,039
cell types. Uh we see high expression

578
00:23:14,240 --> 00:23:20,640
both entites

579
00:23:17,039 --> 00:23:22,640
uh and the model picks it up um in the

580
00:23:20,640 --> 00:23:25,280
sequence but not using the expression of

581
00:23:22,640 --> 00:23:27,039
these transcription factors. uh and CDX

582
00:23:25,280 --> 00:23:30,320
is a more enter specific transcription

583
00:23:27,039 --> 00:23:32,400
factor uh which basically aligns really

584
00:23:30,320 --> 00:23:35,919
well with uh this finding because we see

585
00:23:32,400 --> 00:23:40,320
the the motif of CDX uh in the enhancer

586
00:23:35,919 --> 00:23:42,880
of P1 gene in anes

587
00:23:40,320 --> 00:23:45,679
you're attributing the motif to the TF

588
00:23:42,880 --> 00:23:49,840
based on prior knowledge right not okay

589
00:23:45,679 --> 00:23:52,080
yes yes exactly um so basically we look

590
00:23:49,840 --> 00:23:54,480
at the attributions and then um there

591
00:23:52,080 --> 00:23:56,559
are like simple ways of using cataloges

592
00:23:54,480 --> 00:23:58,480
like Jasper or Hokamoko for example to

593
00:23:56,559 --> 00:24:00,640
like scan and then associate the known

594
00:23:58,480 --> 00:24:02,640
motifs to the uh small regions of

595
00:24:00,640 --> 00:24:04,960
attributions.

596
00:24:02,640 --> 00:24:06,960
Um do you hold out the prediction like

597
00:24:04,960 --> 00:24:08,480
these genes are they held out during

598
00:24:06,960 --> 00:24:10,159
training or does the model have access

599
00:24:08,480 --> 00:24:12,480
to the fact that these actually are

600
00:24:10,159 --> 00:24:14,000
expressed in the yeah all of the genes

601
00:24:12,480 --> 00:24:15,760
uh that are in the paper and also in the

602
00:24:14,000 --> 00:24:17,919
stock are basically tested genes. So the

603
00:24:15,760 --> 00:24:20,240
genes that are not seen during training

604
00:24:17,919 --> 00:24:24,000
including fat P1. No, no. I mean like

605
00:24:20,240 --> 00:24:26,080
CVPA, CDX2 and the transcription factors

606
00:24:24,000 --> 00:24:29,120
are they does the model have are they

607
00:24:26,080 --> 00:24:31,840
included in the they may or may not be

608
00:24:29,120 --> 00:24:34,960
in the training set but the model

609
00:24:31,840 --> 00:24:37,840
doesn't really know that this the motif

610
00:24:34,960 --> 00:24:40,000
of this gene is basically the CDX2 gene

611
00:24:37,840 --> 00:24:42,480
that it already saw in the training. So

612
00:24:40,000 --> 00:24:45,120
it's purely sequence model. It might

613
00:24:42,480 --> 00:24:47,600
know some of the motives regulating CDX

614
00:24:45,120 --> 00:24:50,880
but not there is no explicit link

615
00:24:47,600 --> 00:24:54,159
between the CDX gene and the motifs of

616
00:24:50,880 --> 00:24:56,799
the CDX gene in the model. Yeah. But

617
00:24:54,159 --> 00:24:59,120
implicitly there would be that with the

618
00:24:56,799 --> 00:25:01,279
fact that that like if you know every

619
00:24:59,120 --> 00:25:03,919
cell type that's expressing CDX2 is also

620
00:25:01,279 --> 00:25:06,720
expressing

621
00:25:03,919 --> 00:25:09,279
one.

622
00:25:06,720 --> 00:25:10,799
Um

623
00:25:09,279 --> 00:25:12,480
I mean when they look at when the model

624
00:25:10,799 --> 00:25:14,799
looks at the enhancer of the FAP P1 gene

625
00:25:12,480 --> 00:25:18,400
there is like no explicit signal saying

626
00:25:14,799 --> 00:25:20,240
that CDX2 gene itself is also expressed

627
00:25:18,400 --> 00:25:22,720
in this cell type right because like

628
00:25:20,240 --> 00:25:24,559
each gene is a different observation and

629
00:25:22,720 --> 00:25:25,840
it might have seen it during training or

630
00:25:24,559 --> 00:25:28,240
maybe it's in the test set I don't know

631
00:25:25,840 --> 00:25:30,080
exactly uh but these are kind of

632
00:25:28,240 --> 00:25:33,400
different observations from the model's

633
00:25:30,080 --> 00:25:33,400
point of view

634
00:25:34,000 --> 00:25:38,960
but there are different models that also

635
00:25:36,080 --> 00:25:40,320
condition the sequence uh on the

636
00:25:38,960 --> 00:25:42,320
expression of specific transcription

637
00:25:40,320 --> 00:25:44,480
factors that make the model more aware

638
00:25:42,320 --> 00:25:46,799
of it explicitly.

639
00:25:44,480 --> 00:25:48,640
Yeah. Um I have a question which is uh

640
00:25:46,799 --> 00:25:50,320
do you have an intuition on why the sign

641
00:25:48,640 --> 00:25:52,320
of this input times gradient is positive

642
00:25:50,320 --> 00:25:56,720
for DFS but it felt like it was negative

643
00:25:52,320 --> 00:25:58,320
in the DSS uh in the case before. Okay.

644
00:25:56,720 --> 00:26:01,840
Yeah. negative attribution basically

645
00:25:58,320 --> 00:26:03,440
means so um

646
00:26:01,840 --> 00:26:05,679
there are I think two potential

647
00:26:03,440 --> 00:26:08,320
mechanisms like one is maybe more

648
00:26:05,679 --> 00:26:10,480
biological uh version is a repressor for

649
00:26:08,320 --> 00:26:12,240
example if there's always the model sees

650
00:26:10,480 --> 00:26:13,760
a motif and the expression is always low

651
00:26:12,240 --> 00:26:15,760
and whenever the model doesn't see the

652
00:26:13,760 --> 00:26:17,360
motif then expression is high so

653
00:26:15,760 --> 00:26:18,720
biologically it might be a repressor so

654
00:26:17,360 --> 00:26:20,880
the model can pick it up and this is

655
00:26:18,720 --> 00:26:22,880
what we see in different cases like in

656
00:26:20,880 --> 00:26:24,240
neuronal cells and non-neuronal cells

657
00:26:22,880 --> 00:26:26,559
for example there are like really strong

658
00:26:24,240 --> 00:26:30,159
repressors but in some cases it might be

659
00:26:26,559 --> 00:26:32,240
an artifact too uh which is potentially

660
00:26:30,159 --> 00:26:34,320
because of the multitasking. So imagine

661
00:26:32,240 --> 00:26:36,320
a scenario for example um you have bunch

662
00:26:34,320 --> 00:26:38,720
of neuron subtypes and then microia for

663
00:26:36,320 --> 00:26:41,200
example and then you are making a and

664
00:26:38,720 --> 00:26:42,640
the model saw lots of neuron specific

665
00:26:41,200 --> 00:26:44,400
motifs for example in the neuron

666
00:26:42,640 --> 00:26:47,360
regions. So when the model looks at the

667
00:26:44,400 --> 00:26:50,960
microia uh enhancer let's say the lack

668
00:26:47,360 --> 00:26:52,720
of a a neuronal motif is already a good

669
00:26:50,960 --> 00:26:54,799
it might be a good predictor of the

670
00:26:52,720 --> 00:26:56,799
presence of a microbia specific signal.

671
00:26:54,799 --> 00:26:59,840
So you can see an upside down neuron

672
00:26:56,799 --> 00:27:01,200
motif picked up by the model. But in

673
00:26:59,840 --> 00:27:02,960
this case there's a really strong

674
00:27:01,200 --> 00:27:05,679
contrast between all the neuron subtypes

675
00:27:02,960 --> 00:27:07,679
and microia right like if this is how

676
00:27:05,679 --> 00:27:09,360
you form formulated the whole uh the

677
00:27:07,679 --> 00:27:10,960
problem. But if you have like thousands

678
00:27:09,360 --> 00:27:14,400
of things I think this signal will be

679
00:27:10,960 --> 00:27:17,279
like diluted and be less of an issue. Uh

680
00:27:14,400 --> 00:27:19,200
but still there is no clear or like we

681
00:27:17,279 --> 00:27:21,039
cannot say certainly that it's always a

682
00:27:19,200 --> 00:27:23,120
repressor when we see it in in these

683
00:27:21,039 --> 00:27:25,679
cases. Uh but if there's like prior

684
00:27:23,120 --> 00:27:28,000
biology known about specific repressors

685
00:27:25,679 --> 00:27:32,840
then uh yeah like you feel more

686
00:27:28,000 --> 00:27:32,840
confident about the thing question.

687
00:27:33,200 --> 00:27:36,320
Did you say that repressors would be

688
00:27:34,799 --> 00:27:38,559
positive and activators would be

689
00:27:36,320 --> 00:27:40,640
negative.

690
00:27:38,559 --> 00:27:42,640
So depends on where you look at um if

691
00:27:40,640 --> 00:27:44,159
it's a a repressor in in neurons let's

692
00:27:42,640 --> 00:27:46,640
say

693
00:27:44,159 --> 00:27:48,720
um then whenever the model sees a

694
00:27:46,640 --> 00:27:51,279
repressor then there is like no neuronal

695
00:27:48,720 --> 00:27:52,880
expression right so whenever there is

696
00:27:51,279 --> 00:27:54,720
like no motive there is let's say a high

697
00:27:52,880 --> 00:27:58,320
neuronal expression I'm just like making

698
00:27:54,720 --> 00:28:00,399
it up if you look at the attributions in

699
00:27:58,320 --> 00:28:01,840
the scope of neuron expression then you

700
00:28:00,399 --> 00:28:03,360
will see an upside down because it's

701
00:28:01,840 --> 00:28:04,720
negatively impacting the expression

702
00:28:03,360 --> 00:28:06,480
right whenever you see it there is no

703
00:28:04,720 --> 00:28:08,480
expression but if you look at it in

704
00:28:06,480 --> 00:28:10,480
another cell type you might see it

705
00:28:08,480 --> 00:28:12,799
basically the the other way around. So

706
00:28:10,480 --> 00:28:15,120
it might still it may not repress the

707
00:28:12,799 --> 00:28:16,559
expression. So it might cause or it

708
00:28:15,120 --> 00:28:18,320
doesn't really repress any expression.

709
00:28:16,559 --> 00:28:20,399
So you you see it the other way around.

710
00:28:18,320 --> 00:28:23,120
So depends on

711
00:28:20,399 --> 00:28:26,279
um yeah what part of the output you are

712
00:28:23,120 --> 00:28:26,279
looking at.

713
00:28:28,000 --> 00:28:33,200
Okay. So now let's make it basically

714
00:28:30,000 --> 00:28:34,960
more complicated. Uh now that we have uh

715
00:28:33,200 --> 00:28:36,480
the expression of these genes in many

716
00:28:34,960 --> 00:28:38,960
different contexts, we can ask like more

717
00:28:36,480 --> 00:28:40,320
complex questions too. Like initially um

718
00:28:38,960 --> 00:28:41,840
it was all about like cell type

719
00:28:40,320 --> 00:28:44,399
specificity, right? Different comparing

720
00:28:41,840 --> 00:28:47,279
different cell types or um finding

721
00:28:44,399 --> 00:28:49,279
regulators of cell type specific signal.

722
00:28:47,279 --> 00:28:51,200
Um but this is basically a generic

723
00:28:49,279 --> 00:28:54,240
concept, right? So we just select an

724
00:28:51,200 --> 00:28:56,080
output or we select two groups of uh

725
00:28:54,240 --> 00:28:58,720
pseudo box like a positive group, let's

726
00:28:56,080 --> 00:29:00,080
say, and a negative group. Um then we

727
00:28:58,720 --> 00:29:02,080
look at the local change which is

728
00:29:00,080 --> 00:29:06,159
basically the we subtract like positive

729
00:29:02,080 --> 00:29:07,279
and and negative um and calculate the

730
00:29:06,159 --> 00:29:08,720
gradients with respect to this

731
00:29:07,279 --> 00:29:10,880
differential signal. So instead of

732
00:29:08,720 --> 00:29:13,120
looking at an attributions of an an

733
00:29:10,880 --> 00:29:18,159
specific output we look at the the

734
00:29:13,120 --> 00:29:21,120
attributions in a differential way. Um

735
00:29:18,159 --> 00:29:22,399
so the model then we try we ask the

736
00:29:21,120 --> 00:29:24,080
question that like what are the the

737
00:29:22,399 --> 00:29:28,000
sequence drivers of this differential

738
00:29:24,080 --> 00:29:29,840
signal. So if you uh define positive as

739
00:29:28,000 --> 00:29:31,600
one cell type and negative as the rest

740
00:29:29,840 --> 00:29:34,720
for example you do like the typical cell

741
00:29:31,600 --> 00:29:36,159
type specificity type of analysis. U but

742
00:29:34,720 --> 00:29:38,640
we can also define it in in different

743
00:29:36,159 --> 00:29:39,919
ways right because now we have basically

744
00:29:38,640 --> 00:29:42,399
more flexibility or like broader

745
00:29:39,919 --> 00:29:44,159
coverage of biology with single science.

746
00:29:42,399 --> 00:29:46,240
Uh and once we have the differential

747
00:29:44,159 --> 00:29:49,279
signal uh we do the same thing. We look

748
00:29:46,240 --> 00:29:51,919
at these regions of high attribution and

749
00:29:49,279 --> 00:29:54,159
and through a method called TF modiscoco

750
00:29:51,919 --> 00:29:56,480
um we cluster all these regions and

751
00:29:54,159 --> 00:29:59,919
assign them to like non motives which is

752
00:29:56,480 --> 00:30:04,799
like in this case for example gtt gct a

753
00:29:59,919 --> 00:30:07,360
driver motif so um this then

754
00:30:04,799 --> 00:30:09,600
um it doesn't give you a specific gene

755
00:30:07,360 --> 00:30:11,919
so you kind of marginalize the gene but

756
00:30:09,600 --> 00:30:13,760
it gives you a specific TF explaining

757
00:30:11,919 --> 00:30:15,279
differences between the positives and

758
00:30:13,760 --> 00:30:18,480
negatives that you define and we can

759
00:30:15,279 --> 00:30:19,919
define in many arbitrary ways. So for

760
00:30:18,480 --> 00:30:22,240
example, instead of looking at like

761
00:30:19,919 --> 00:30:25,600
entite versus hpetite in the previous

762
00:30:22,240 --> 00:30:27,279
case, we can look at the T-Rex um but

763
00:30:25,600 --> 00:30:29,279
more like subtle changes in T-Rex, for

764
00:30:27,279 --> 00:30:30,480
example, cycling and non- cycling T-Rex

765
00:30:29,279 --> 00:30:33,120
and ask the model what are the

766
00:30:30,480 --> 00:30:35,440
regulators of these two cell states in

767
00:30:33,120 --> 00:30:38,640
this case. Uh and we see some usual

768
00:30:35,440 --> 00:30:40,399
suspects like the E2F for example. Um

769
00:30:38,640 --> 00:30:42,799
but in this case we are basically

770
00:30:40,399 --> 00:30:44,559
looking at the logage correlation. So we

771
00:30:42,799 --> 00:30:46,240
are not looking at the correlation

772
00:30:44,559 --> 00:30:48,240
between predicted and measured

773
00:30:46,240 --> 00:30:51,120
expression but we are looking at the

774
00:30:48,240 --> 00:30:54,840
predicted and measured lo changes

775
00:30:51,120 --> 00:30:54,840
between these two groups

776
00:30:55,200 --> 00:30:59,360
and uh like another contrast that we can

777
00:30:57,760 --> 00:31:02,080
create also is the cross tissue

778
00:30:59,360 --> 00:31:03,760
analysis. So we can look at the cardiac

779
00:31:02,080 --> 00:31:06,720
fibroblast versus non-cardiac

780
00:31:03,760 --> 00:31:08,240
fibroblast. Um so a bit also similar to

781
00:31:06,720 --> 00:31:09,760
cell type analysis but not exactly the

782
00:31:08,240 --> 00:31:12,000
same. So we are looking at the same set

783
00:31:09,760 --> 00:31:13,840
type but across uh different context

784
00:31:12,000 --> 00:31:16,640
like in in different tissues for example

785
00:31:13,840 --> 00:31:18,000
heart versus uh other tissues and also

786
00:31:16,640 --> 00:31:20,240
they asked the model what are the the

787
00:31:18,000 --> 00:31:23,440
regulator drivers of this specific

788
00:31:20,240 --> 00:31:25,600
differential attribution. So um this is

789
00:31:23,440 --> 00:31:27,840
kind of the sequence to function way of

790
00:31:25,600 --> 00:31:30,159
like pitching the model right because it

791
00:31:27,840 --> 00:31:33,760
feels like a uh like an extension of the

792
00:31:30,159 --> 00:31:36,960
existing models. But if you think as as

793
00:31:33,760 --> 00:31:38,240
a single sinic person um it basically

794
00:31:36,960 --> 00:31:39,600
it's very similar to differentially

795
00:31:38,240 --> 00:31:42,399
expression analysis where you just

796
00:31:39,600 --> 00:31:43,840
compare different groups of cells but

797
00:31:42,399 --> 00:31:45,679
instead of getting like bunch of genes

798
00:31:43,840 --> 00:31:47,360
that are differentially expressed you

799
00:31:45,679 --> 00:31:49,039
get an additional information about what

800
00:31:47,360 --> 00:31:51,200
TFS are regulating or driving this

801
00:31:49,039 --> 00:31:53,200
differentiation. So I think in a way it

802
00:31:51,200 --> 00:31:55,360
basically adds like another layer of

803
00:31:53,200 --> 00:31:57,200
information on top of the regular

804
00:31:55,360 --> 00:32:00,159
differential expression as if that we

805
00:31:57,200 --> 00:32:03,120
typically do. Question. So you're saying

806
00:32:00,159 --> 00:32:05,919
that um these motifs that are being

807
00:32:03,120 --> 00:32:07,679
picked up here uh might drive multiple

808
00:32:05,919 --> 00:32:09,440
genes in this differential expression

809
00:32:07,679 --> 00:32:12,559
scenario.

810
00:32:09,440 --> 00:32:14,880
Yeah. Basically

811
00:32:12,559 --> 00:32:16,799
uh what we do is we have some genes that

812
00:32:14,880 --> 00:32:18,399
we want to target, right? For example,

813
00:32:16,799 --> 00:32:20,720
differential express genes between these

814
00:32:18,399 --> 00:32:24,080
two states. let's say the cycling T-Rex

815
00:32:20,720 --> 00:32:26,720
and the non-cycling T-Rex. Then um for

816
00:32:24,080 --> 00:32:28,159
each each of these genes, we run the

817
00:32:26,720 --> 00:32:30,799
same query. So we look at the

818
00:32:28,159 --> 00:32:33,120
differential attributions and cluster

819
00:32:30,799 --> 00:32:35,360
the motifs that we see. And when you do

820
00:32:33,120 --> 00:32:37,600
it across genes that are informative in

821
00:32:35,360 --> 00:32:39,760
the context of the specific question, we

822
00:32:37,600 --> 00:32:41,279
end up with like bunch of motifs. So

823
00:32:39,760 --> 00:32:42,799
these are the ones that are over

824
00:32:41,279 --> 00:32:44,480
represented

825
00:32:42,799 --> 00:32:47,120
across genes that are differentially

826
00:32:44,480 --> 00:32:49,360
expressed between these two groups in

827
00:32:47,120 --> 00:32:52,240
the differential attributions.

828
00:32:49,360 --> 00:32:54,080
So I think I mean same as this but just

829
00:32:52,240 --> 00:32:55,360
imagine you do it like with multiple

830
00:32:54,080 --> 00:32:57,120
relevant genes and you kind of

831
00:32:55,360 --> 00:33:00,480
marginalize the gene dimension so that

832
00:32:57,120 --> 00:33:03,360
you end up with um the contrast that you

833
00:33:00,480 --> 00:33:06,320
have and then the TFS driving it. And

834
00:33:03,360 --> 00:33:08,720
the third example is uh maybe a bit more

835
00:33:06,320 --> 00:33:10,880
complex uh but we look at the again the

836
00:33:08,720 --> 00:33:12,000
same cell type but across conditions. So

837
00:33:10,880 --> 00:33:13,519
this is maybe a more familiar

838
00:33:12,000 --> 00:33:16,399
differential expression analysis like

839
00:33:13,519 --> 00:33:20,000
healthy uh uh like an healthy individual

840
00:33:16,399 --> 00:33:22,320
and a chron uh patient and we see like

841
00:33:20,000 --> 00:33:25,360
similar patterns basically uh motifs

842
00:33:22,320 --> 00:33:28,240
driving this uh these differences. So in

843
00:33:25,360 --> 00:33:31,039
this cases we are not expecting to see

844
00:33:28,240 --> 00:33:33,200
motives driving um the fibroblast

845
00:33:31,039 --> 00:33:34,559
expression itself but only the

846
00:33:33,200 --> 00:33:38,480
differences between a healthy fiber

847
00:33:34,559 --> 00:33:41,519
blast and a diseased fiber blast.

848
00:33:38,480 --> 00:33:44,399
Um another example um is sequence

849
00:33:41,519 --> 00:33:47,600
design. Like as I mentioned um synthetic

850
00:33:44,399 --> 00:33:51,039
sequence design is is one of the u cool

851
00:33:47,600 --> 00:33:53,039
directions um that these models are

852
00:33:51,039 --> 00:33:55,440
really useful for. Um and the way we

853
00:33:53,039 --> 00:33:57,679
formulated here is uh is slightly

854
00:33:55,440 --> 00:33:59,279
different because in the sequence design

855
00:33:57,679 --> 00:34:01,279
typically we design like smaller

856
00:33:59,279 --> 00:34:03,200
sequences like 200 500 base pair

857
00:34:01,279 --> 00:34:05,760
sequences but these are like super large

858
00:34:03,200 --> 00:34:09,200
models. So how do we like reconcile

859
00:34:05,760 --> 00:34:11,599
these two? So Laura um uh in my team

860
00:34:09,200 --> 00:34:13,839
basically formulated it as a as a nice

861
00:34:11,599 --> 00:34:16,079
incilica experiment where we have a a

862
00:34:13,839 --> 00:34:18,639
short random sequence and and some cargo

863
00:34:16,079 --> 00:34:21,280
and then we kind of implant it in a in a

864
00:34:18,639 --> 00:34:24,079
scoring locus in a safe locus where kind

865
00:34:21,280 --> 00:34:26,000
of nothing happens. Uh and if the model

866
00:34:24,079 --> 00:34:28,560
responds to this sequence then we just

867
00:34:26,000 --> 00:34:29,919
assume that there is uh expression there

868
00:34:28,560 --> 00:34:32,240
are patterns that are driving the

869
00:34:29,919 --> 00:34:33,520
expression. So almost as if like we are

870
00:34:32,240 --> 00:34:35,919
doing the experiment where we integrate

871
00:34:33,520 --> 00:34:37,440
a reporter essay uh like a reporter

872
00:34:35,919 --> 00:34:39,280
construct and then running a reporter

873
00:34:37,440 --> 00:34:41,760
essay which kind of lights up the EDFP

874
00:34:39,280 --> 00:34:44,960
even the cargo gene is uh is this the

875
00:34:41,760 --> 00:34:46,800
standard reporter SA genes uh then one

876
00:34:44,960 --> 00:34:48,159
can start with a random gene uh and this

877
00:34:46,800 --> 00:34:49,599
is kind of the scoring function it

878
00:34:48,159 --> 00:34:52,480
scores like this short regulatory

879
00:34:49,599 --> 00:34:54,639
element um and model again makes like

880
00:34:52,480 --> 00:34:58,480
8,000 9,000 different predictions right

881
00:34:54,639 --> 00:35:01,119
so if this uh fake cargo gene would

882
00:34:58,480 --> 00:35:03,280
light up in these different context

883
00:35:01,119 --> 00:35:05,119
Um so then we can basically start with a

884
00:35:03,280 --> 00:35:06,960
random sequence and in a in a very

885
00:35:05,119 --> 00:35:09,760
simple directed evolution kind of method

886
00:35:06,960 --> 00:35:12,160
we can keep mutating it until we are

887
00:35:09,760 --> 00:35:14,640
happy with the from the design objective

888
00:35:12,160 --> 00:35:16,480
point of view and in this case uh so

889
00:35:14,640 --> 00:35:17,920
self type specific regulator design is a

890
00:35:16,480 --> 00:35:19,599
very standard task. So you have for

891
00:35:17,920 --> 00:35:21,760
example a fiber specific element or a

892
00:35:19,599 --> 00:35:23,280
microfase specific element and so on.

893
00:35:21,760 --> 00:35:25,200
But in this case since we have lots of

894
00:35:23,280 --> 00:35:28,560
different condition and context we tried

895
00:35:25,200 --> 00:35:30,000
something a bit more difficult. Um so

896
00:35:28,560 --> 00:35:31,520
initially we basically start with a

897
00:35:30,000 --> 00:35:33,200
random sequence and we make a fiber

898
00:35:31,520 --> 00:35:36,000
blast specific element right so the

899
00:35:33,200 --> 00:35:38,160
contrast here is fiberblast versus rest.

900
00:35:36,000 --> 00:35:40,400
Uh so the model basically makes like 50

901
00:35:38,160 --> 00:35:42,560
edits to come up with a fibroblast

902
00:35:40,400 --> 00:35:43,920
specific element and then we basically

903
00:35:42,560 --> 00:35:46,560
continue with a slightly different

904
00:35:43,920 --> 00:35:48,720
objective which is higher expression in

905
00:35:46,560 --> 00:35:50,960
an inron fibroblast and a lower

906
00:35:48,720 --> 00:35:53,040
expression in the other fibroblast. So

907
00:35:50,960 --> 00:35:55,119
in a way it's a a very simplified

908
00:35:53,040 --> 00:35:57,440
version of a multi- uh objective

909
00:35:55,119 --> 00:35:59,760
optimization uh but we are not doing it

910
00:35:57,440 --> 00:36:01,839
jointly. We just do it uh sequentially

911
00:35:59,760 --> 00:36:04,800
like fibroblast specific first and then

912
00:36:01,839 --> 00:36:06,800
disease fibroblast specific then this we

913
00:36:04,800 --> 00:36:09,440
can also interpret because basically we

914
00:36:06,800 --> 00:36:12,240
know where the model edits which motifs

915
00:36:09,440 --> 00:36:14,320
um exist in the sequence and and so on

916
00:36:12,240 --> 00:36:18,760
and most of the motives basically make

917
00:36:14,320 --> 00:36:18,760
sense. Um

918
00:36:19,040 --> 00:36:23,359
yeah and the the last case I think is

919
00:36:21,200 --> 00:36:26,000
variant effect prediction. This is also

920
00:36:23,359 --> 00:36:28,000
are you sorry are you gonna I I don't

921
00:36:26,000 --> 00:36:31,119
know if this is possible but can you

922
00:36:28,000 --> 00:36:33,200
test this in fiber I mean it's kind of I

923
00:36:31,119 --> 00:36:35,359
imagine hard to get fiberglass out of

924
00:36:33,200 --> 00:36:38,880
Crohn's and edit them but like is there

925
00:36:35,359 --> 00:36:40,720
some sort of idea that you want to at

926
00:36:38,880 --> 00:36:42,560
least put some fibroblast in some sort

927
00:36:40,720 --> 00:36:44,560
of inflammatory condition in a cell

928
00:36:42,560 --> 00:36:45,839
culture and see if you can get whatever

929
00:36:44,560 --> 00:36:48,560
cargo this is to be expressed

930
00:36:45,839 --> 00:36:49,520
specifically. Yeah, I think it's really

931
00:36:48,560 --> 00:36:51,920
interesting. It would be really

932
00:36:49,520 --> 00:36:58,359
interesting to test it um like with an

933
00:36:51,920 --> 00:36:58,359
experiment um if it's doable. Yeah.

934
00:36:58,720 --> 00:37:02,640
Yeah. So the variant effect prediction

935
00:37:00,640 --> 00:37:05,599
um example again with with the with the

936
00:37:02,640 --> 00:37:07,839
same model um so we again follow the the

937
00:37:05,599 --> 00:37:09,280
standard formulation of the web task

938
00:37:07,839 --> 00:37:11,359
which is to query the model with two

939
00:37:09,280 --> 00:37:13,200
different of a a specific variant that

940
00:37:11,359 --> 00:37:15,520
we're interested in and look at the

941
00:37:13,200 --> 00:37:18,960
differences between the expression

942
00:37:15,520 --> 00:37:22,960
um expression profiles. Um and if there

943
00:37:18,960 --> 00:37:24,560
is like a um significantly high um

944
00:37:22,960 --> 00:37:27,280
differential signal between these two

945
00:37:24,560 --> 00:37:31,359
cases, basically we can nominate um a

946
00:37:27,280 --> 00:37:33,599
cell type and a gene um as a mechanistic

947
00:37:31,359 --> 00:37:37,359
explanation of the uh of of this

948
00:37:33,599 --> 00:37:39,920
variant. Um

949
00:37:37,359 --> 00:37:43,200
and for this uh we basically picked the

950
00:37:39,920 --> 00:37:45,119
the biggest um available single cell QTL

951
00:37:43,200 --> 00:37:48,320
data set like 1K 1K. I think there's a

952
00:37:45,119 --> 00:37:50,720
follow-up now uh a larger uh data set

953
00:37:48,320 --> 00:37:54,079
but in uh this one they have I think 900

954
00:37:50,720 --> 00:37:57,839
or 1,000 individuals um profiled with

955
00:37:54,079 --> 00:37:59,920
single sac and and the the um immune

956
00:37:57,839 --> 00:38:01,359
cell types are profiled and they have

957
00:37:59,920 --> 00:38:03,280
the genotypes of the individuals. So

958
00:38:01,359 --> 00:38:06,960
they just call the uh they find the

959
00:38:03,280 --> 00:38:09,680
variants that are uh driving the uh the

960
00:38:06,960 --> 00:38:12,240
expression in these individuals. Um so

961
00:38:09,680 --> 00:38:15,200
this is a a reprocessed version of the

962
00:38:12,240 --> 00:38:19,040
1K 1K single set EQL study from EQR

963
00:38:15,200 --> 00:38:20,880
catalog. Um and there are a few ways of

964
00:38:19,040 --> 00:38:23,760
doing it. So you can look look up like

965
00:38:20,880 --> 00:38:26,640
specific variants and then uh nominate a

966
00:38:23,760 --> 00:38:30,480
specific regulatory mechanism or uh you

967
00:38:26,640 --> 00:38:32,240
can do it kind of more um broadly where

968
00:38:30,480 --> 00:38:34,160
we formulate the question as a

969
00:38:32,240 --> 00:38:36,880
classification whether a variant is a

970
00:38:34,160 --> 00:38:39,520
cell type specific um EQ for example

971
00:38:36,880 --> 00:38:42,720
single cell EQL or not. So in this case

972
00:38:39,520 --> 00:38:45,599
we have the fine map variance um

973
00:38:42,720 --> 00:38:47,520
analyzed by the EQI catalog with the

974
00:38:45,599 --> 00:38:49,839
posterior inclusion probability like

975
00:38:47,520 --> 00:38:52,640
higher than 0.9 for example the the more

976
00:38:49,839 --> 00:38:55,760
confidently fine mapped variances are

977
00:38:52,640 --> 00:38:58,640
positives and uh the gene match 20

978
00:38:55,760 --> 00:39:00,240
negatives for um for each positive

979
00:38:58,640 --> 00:39:01,520
variant that we have and then this is

980
00:39:00,240 --> 00:39:03,599
basically a binary classification

981
00:39:01,520 --> 00:39:06,160
problem whether this variant is a single

982
00:39:03,599 --> 00:39:07,680
cell eql in different cell types. So we

983
00:39:06,160 --> 00:39:09,520
do it like different for each different

984
00:39:07,680 --> 00:39:10,960
different cell type. Then for each cell

985
00:39:09,520 --> 00:39:13,680
type this is a different classification

986
00:39:10,960 --> 00:39:17,280
problem and we have the the AUPRC's of

987
00:39:13,680 --> 00:39:19,280
the classification results. Um and in in

988
00:39:17,280 --> 00:39:21,760
many cases the model is doing a really

989
00:39:19,280 --> 00:39:24,079
good job uh distinguishing these uh the

990
00:39:21,760 --> 00:39:26,320
variants that are um increasing or

991
00:39:24,079 --> 00:39:29,520
decreasing expression uh in the context

992
00:39:26,320 --> 00:39:31,200
of different specific cell types. Uh but

993
00:39:29,520 --> 00:39:34,640
the cool thing is now we can do it for

994
00:39:31,200 --> 00:39:36,160
like remaining 8,000 um conditions or

995
00:39:34,640 --> 00:39:38,320
like different cell types right so this

996
00:39:36,160 --> 00:39:41,599
is a nice validation that the model

997
00:39:38,320 --> 00:39:43,280
picks up uh the variant signal and this

998
00:39:41,599 --> 00:39:45,760
is another way to look at it so for like

999
00:39:43,280 --> 00:39:48,560
each uh sorry coach on the previous plot

1000
00:39:45,760 --> 00:39:53,520
um so what do you think is driving like

1001
00:39:48,560 --> 00:39:56,560
performance is it the number of cells in

1002
00:39:53,520 --> 00:39:59,359
these data sets like platelets for

1003
00:39:56,560 --> 00:40:01,839
instance are not often been found in a

1004
00:39:59,359 --> 00:40:04,400
single cell data. I mean or what do you

1005
00:40:01,839 --> 00:40:06,560
think is kind of differentiating the

1006
00:40:04,400 --> 00:40:08,160
cell types here? I think this we haven't

1007
00:40:06,560 --> 00:40:10,880
checked it but this should be correlated

1008
00:40:08,160 --> 00:40:13,119
with uh maybe the the size of the of

1009
00:40:10,880 --> 00:40:15,760
these populations

1010
00:40:13,119 --> 00:40:17,839
um and maybe the data quality as well.

1011
00:40:15,760 --> 00:40:20,240
Um but it's a function of multiple

1012
00:40:17,839 --> 00:40:21,760
things like if

1013
00:40:20,240 --> 00:40:23,520
um

1014
00:40:21,760 --> 00:40:25,119
if variants are affecting a gene that is

1015
00:40:23,520 --> 00:40:27,040
not really well captured by the model

1016
00:40:25,119 --> 00:40:29,599
maybe the the dist elements are maybe

1017
00:40:27,040 --> 00:40:31,280
like really far away or the model is

1018
00:40:29,599 --> 00:40:33,839
having issues basically understanding

1019
00:40:31,280 --> 00:40:35,680
the regulatory rules of a specific gene.

1020
00:40:33,839 --> 00:40:37,119
Uh yeah if there are more variance for

1021
00:40:35,680 --> 00:40:40,240
example impacting this gene this might

1022
00:40:37,119 --> 00:40:43,359
affect it too. uh so at the gene level

1023
00:40:40,240 --> 00:40:45,440
or at the cell type level model has

1024
00:40:43,359 --> 00:40:47,680
uh different like levels of performance

1025
00:40:45,440 --> 00:40:49,760
right so based on these combinations

1026
00:40:47,680 --> 00:40:52,240
model can perform poorly too but one I

1027
00:40:49,760 --> 00:40:53,920
think really interesting thing is that

1028
00:40:52,240 --> 00:40:56,560
if you look at the variants that are

1029
00:40:53,920 --> 00:40:59,440
flagged by these models it's often a

1030
00:40:56,560 --> 00:41:00,800
combination of common eqtls and also the

1031
00:40:59,440 --> 00:41:03,200
rare variance so model doesn't really

1032
00:41:00,800 --> 00:41:05,520
have an explicit notion of uh frequency

1033
00:41:03,200 --> 00:41:07,040
right the a frequency so I think the

1034
00:41:05,520 --> 00:41:10,079
right way would be to basically look at

1035
00:41:07,040 --> 00:41:11,760
all the functional variance without I

1036
00:41:10,079 --> 00:41:13,440
mean if we have such data without

1037
00:41:11,760 --> 00:41:15,680
thinking too much about the frequencies

1038
00:41:13,440 --> 00:41:17,440
and the combination of it will be

1039
00:41:15,680 --> 00:41:19,599
probably more captured because otherwise

1040
00:41:17,440 --> 00:41:21,920
the model will flag more rare variants

1041
00:41:19,599 --> 00:41:24,560
as well which might show up as the false

1042
00:41:21,920 --> 00:41:28,400
positives in the EQL context although

1043
00:41:24,560 --> 00:41:30,240
they might have an impact but not u

1044
00:41:28,400 --> 00:41:34,680
captured in EQL simply because they're

1045
00:41:30,240 --> 00:41:34,680
not common enough question

1046
00:41:35,040 --> 00:41:40,400
are those cell type labels taken from

1047
00:41:37,040 --> 00:41:42,400
the cell ontology ology.

1048
00:41:40,400 --> 00:41:45,359
Uh these are the author provided cell

1049
00:41:42,400 --> 00:41:47,760
types. I think author provided cell

1050
00:41:45,359 --> 00:41:49,760
types. So the the authors annotated the

1051
00:41:47,760 --> 00:41:52,319
paper. But we have to match the cell

1052
00:41:49,760 --> 00:41:54,880
types that we have in our model and then

1053
00:41:52,319 --> 00:41:58,800
the uh cell types that the model uh the

1054
00:41:54,880 --> 00:42:01,680
authors provided in this paper.

1055
00:41:58,800 --> 00:42:03,280
So I need to speed up. Um then we can

1056
00:42:01,680 --> 00:42:05,839
look at the fine map variance and their

1057
00:42:03,280 --> 00:42:07,839
effect sizes uh and correlate it with

1058
00:42:05,839 --> 00:42:09,440
the uh lock fold changes which is kind

1059
00:42:07,839 --> 00:42:13,280
of the main score that the desma

1060
00:42:09,440 --> 00:42:17,040
produces. Uh and it looks reasonable

1061
00:42:13,280 --> 00:42:19,440
basically. Uh this I will skip

1062
00:42:17,040 --> 00:42:21,520
uh yeah maybe like some some notes and

1063
00:42:19,440 --> 00:42:23,200
or conclusion about the the this

1064
00:42:21,520 --> 00:42:26,240
section. I think the major trend as you

1065
00:42:23,200 --> 00:42:28,000
see um is concepts like emerge in the

1066
00:42:26,240 --> 00:42:30,240
machine learning field and it's applied

1067
00:42:28,000 --> 00:42:32,560
maybe unsurprisingly in in regulatory

1068
00:42:30,240 --> 00:42:34,720
genomics lots of like architecture

1069
00:42:32,560 --> 00:42:37,280
decisions loss functions and and machine

1070
00:42:34,720 --> 00:42:39,839
learning concepts are uh really quickly

1071
00:42:37,280 --> 00:42:42,319
adapted uh and applied to regulatory

1072
00:42:39,839 --> 00:42:44,400
genomics related questions. Uh and there

1073
00:42:42,319 --> 00:42:46,000
are like many different ways of uh

1074
00:42:44,400 --> 00:42:48,000
designing these models. Different loss

1075
00:42:46,000 --> 00:42:51,440
functions, how to structure the output

1076
00:42:48,000 --> 00:42:52,960
for example. So um like in in terms of

1077
00:42:51,440 --> 00:42:54,880
like these components there there are

1078
00:42:52,960 --> 00:42:56,640
really big differences. Although models

1079
00:42:54,880 --> 00:42:59,040
might look similar basically sequence to

1080
00:42:56,640 --> 00:43:00,800
function is the main kind of principle

1081
00:42:59,040 --> 00:43:02,960
uh there are still lots of hidden

1082
00:43:00,800 --> 00:43:06,000
challenges within each of these these

1083
00:43:02,960 --> 00:43:07,520
directions. Uh but two major groups like

1084
00:43:06,000 --> 00:43:09,119
if you basically really construct this

1085
00:43:07,520 --> 00:43:11,040
space and cluster these groups like you

1086
00:43:09,119 --> 00:43:14,000
will see a models that are really small

1087
00:43:11,040 --> 00:43:15,200
and efficient and single task uh and the

1088
00:43:14,000 --> 00:43:17,839
models that are really large and

1089
00:43:15,200 --> 00:43:20,000
multitask. Uh and there are like pros

1090
00:43:17,839 --> 00:43:21,839
and cons. Uh multitask models are more

1091
00:43:20,000 --> 00:43:24,480
convenient if you don't want to load

1092
00:43:21,839 --> 00:43:26,880
like hundreds or thousands of of models.

1093
00:43:24,480 --> 00:43:28,480
Um and in some cases there are questions

1094
00:43:26,880 --> 00:43:30,160
where we don't really know where to look

1095
00:43:28,480 --> 00:43:32,160
at. Uh so if you have single task

1096
00:43:30,160 --> 00:43:34,000
models, you load the model that you have

1097
00:43:32,160 --> 00:43:35,599
in mind and basically query the model.

1098
00:43:34,000 --> 00:43:38,720
But if there is like a big multitask

1099
00:43:35,599 --> 00:43:40,240
model, it might guide you basically uh

1100
00:43:38,720 --> 00:43:42,960
about like where to where to look at

1101
00:43:40,240 --> 00:43:47,920
like in which context uh that you need

1102
00:43:42,960 --> 00:43:49,440
to look at. Um and so um so are these

1103
00:43:47,920 --> 00:43:51,760
models foundational? So it depends on

1104
00:43:49,440 --> 00:43:53,200
what the the definition is. Uh but if

1105
00:43:51,760 --> 00:43:55,440
you remember the definition from the

1106
00:43:53,200 --> 00:43:57,359
original Stanford report, it's basically

1107
00:43:55,440 --> 00:43:59,440
any model trained on large data sets

1108
00:43:57,359 --> 00:44:01,040
that can be adapted to a wide range of

1109
00:43:59,440 --> 00:44:03,440
downstream tasks. It it seems like

1110
00:44:01,040 --> 00:44:07,280
pretty foundational to me. Although they

1111
00:44:03,440 --> 00:44:10,000
mention this svision in the report, um

1112
00:44:07,280 --> 00:44:12,319
it's basically not a a requirement. But

1113
00:44:10,000 --> 00:44:14,000
um if people can come up with

1114
00:44:12,319 --> 00:44:15,599
applications that you didn't even think

1115
00:44:14,000 --> 00:44:17,920
about when you train the model I think

1116
00:44:15,599 --> 00:44:22,240
it's foundation enough

1117
00:44:17,920 --> 00:44:24,079
um and some open problems um

1118
00:44:22,240 --> 00:44:25,920
so as you imagine like one of the trends

1119
00:44:24,079 --> 00:44:27,280
is like just having more and more tracks

1120
00:44:25,920 --> 00:44:29,040
right like the models are predicting

1121
00:44:27,280 --> 00:44:31,040
like the large the third category is

1122
00:44:29,040 --> 00:44:32,400
predicting more and more tracks um but

1123
00:44:31,040 --> 00:44:34,800
there is some kind of structure between

1124
00:44:32,400 --> 00:44:37,440
these between these modalities so the

1125
00:44:34,800 --> 00:44:39,440
attack chipsseek are related or histo

1126
00:44:37,440 --> 00:44:42,079
modifications and attack are related or

1127
00:44:39,440 --> 00:44:44,400
attack and expression are related. Uh

1128
00:44:42,079 --> 00:44:45,920
but these these are not really used

1129
00:44:44,400 --> 00:44:49,200
because we just like stack everything

1130
00:44:45,920 --> 00:44:50,560
and predict all at once. Um so there are

1131
00:44:49,200 --> 00:44:52,000
some attempts to basically move things

1132
00:44:50,560 --> 00:44:53,520
around. So instead of having the

1133
00:44:52,000 --> 00:44:54,800
sequence as input and everything as the

1134
00:44:53,520 --> 00:44:56,720
output, you can move some of the things

1135
00:44:54,800 --> 00:44:59,119
from output to input. For example, his

1136
00:44:56,720 --> 00:45:00,880
modifications or attack and sequence can

1137
00:44:59,119 --> 00:45:03,200
be your input and then you can predict

1138
00:45:00,880 --> 00:45:05,040
kind of the rest. Uh but this is this

1139
00:45:03,200 --> 00:45:07,200
feels a bit arbitrary. we have some some

1140
00:45:05,040 --> 00:45:09,359
notion of uh causality or like

1141
00:45:07,200 --> 00:45:10,880
associations between the tracks. Uh but

1142
00:45:09,359 --> 00:45:14,640
there is no principled approach I think

1143
00:45:10,880 --> 00:45:16,160
to um fully exploit this. Uh and the

1144
00:45:14,640 --> 00:45:18,079
second one I want to mention is like the

1145
00:45:16,160 --> 00:45:19,599
design is more like a byproduct or like

1146
00:45:18,079 --> 00:45:21,200
it's an auxiliary function. The model

1147
00:45:19,599 --> 00:45:23,200
doesn't really know about design but we

1148
00:45:21,200 --> 00:45:25,040
kind of force the model to design things

1149
00:45:23,200 --> 00:45:26,560
typically with like directed evolution.

1150
00:45:25,040 --> 00:45:28,800
So it's not a fundamental part of the

1151
00:45:26,560 --> 00:45:30,800
training. uh and you can use language

1152
00:45:28,800 --> 00:45:32,079
models basically to uh especially the

1153
00:45:30,800 --> 00:45:34,160
auto reggressive language models to

1154
00:45:32,079 --> 00:45:37,599
design sequences when you prompt them

1155
00:45:34,160 --> 00:45:41,839
with uh different functional uh prompts.

1156
00:45:37,599 --> 00:45:43,440
Interpretation I think is limited um

1157
00:45:41,839 --> 00:45:45,280
there are lots of interpretivity methods

1158
00:45:43,440 --> 00:45:47,119
that I also show showed in the previous

1159
00:45:45,280 --> 00:45:48,800
slides but if you think about the

1160
00:45:47,119 --> 00:45:51,280
counterfactuals we are limited to the

1161
00:45:48,800 --> 00:45:53,040
counterfactuals of the sequence. So we

1162
00:45:51,280 --> 00:45:55,920
since the sequence is the only input the

1163
00:45:53,040 --> 00:45:57,599
only cool uh creative experiments we can

1164
00:45:55,920 --> 00:45:59,440
do is to perturb the the sequence and

1165
00:45:57,599 --> 00:46:01,280
then see what happens in the output. But

1166
00:45:59,440 --> 00:46:04,319
if the sequence remains the same but we

1167
00:46:01,280 --> 00:46:06,640
can change the functional tracks uh that

1168
00:46:04,319 --> 00:46:09,520
would be a really cool way of perturbing

1169
00:46:06,640 --> 00:46:11,040
uh um biology too. But these models

1170
00:46:09,520 --> 00:46:14,000
don't really allow it since everything

1171
00:46:11,040 --> 00:46:16,560
is like on the output side. Um and

1172
00:46:14,000 --> 00:46:17,839
uncertainty and like whether the when we

1173
00:46:16,560 --> 00:46:19,280
have these like cool creative

1174
00:46:17,839 --> 00:46:21,520
experiments whether we are going out of

1175
00:46:19,280 --> 00:46:24,400
distribution or not is something we also

1176
00:46:21,520 --> 00:46:25,920
don't often check. uh or if uh the

1177
00:46:24,400 --> 00:46:28,319
sequences that they're requiring the

1178
00:46:25,920 --> 00:46:29,839
model with are they like human like or

1179
00:46:28,319 --> 00:46:32,319
is the model really confident about

1180
00:46:29,839 --> 00:46:34,720
these answers is not uh fully

1181
00:46:32,319 --> 00:46:36,480
established. I think another hot topic

1182
00:46:34,720 --> 00:46:38,880
is like predicting gene expression

1183
00:46:36,480 --> 00:46:40,960
variation across individuals. Uh there

1184
00:46:38,880 --> 00:46:43,440
are many groups now studying this. It's

1185
00:46:40,960 --> 00:46:45,839
it's really exciting. uh although we

1186
00:46:43,440 --> 00:46:47,599
have um the power to understand

1187
00:46:45,839 --> 00:46:49,839
mechanism of individual variants when we

1188
00:46:47,599 --> 00:46:52,079
use them jointly to predict expression

1189
00:46:49,839 --> 00:46:54,400
of a specific individual these models

1190
00:46:52,079 --> 00:46:56,079
often fail because they are trained uh

1191
00:46:54,400 --> 00:46:58,560
on the reference genome so they're not

1192
00:46:56,079 --> 00:47:01,280
really aware of the um genetic variation

1193
00:46:58,560 --> 00:47:05,200
in human populations. Uh but there are

1194
00:47:01,280 --> 00:47:06,640
some uh some cool attempts there as well

1195
00:47:05,200 --> 00:47:08,000
and the the software is often

1196
00:47:06,640 --> 00:47:09,520
fragmented. there are like people just

1197
00:47:08,000 --> 00:47:11,359
like implement things in in arbitrary

1198
00:47:09,520 --> 00:47:13,839
frameworks and this makes it difficult

1199
00:47:11,359 --> 00:47:16,160
to like put them um in the same context

1200
00:47:13,839 --> 00:47:17,599
and use them jointly. Uh so we have a

1201
00:47:16,160 --> 00:47:19,920
paper that I will show in the next slide

1202
00:47:17,599 --> 00:47:21,599
too but um

1203
00:47:19,920 --> 00:47:24,319
uh like basically check out the the

1204
00:47:21,599 --> 00:47:26,319
preprint too. Um so what we did is

1205
00:47:24,319 --> 00:47:29,520
basically we fixed the framework to like

1206
00:47:26,319 --> 00:47:32,079
pietorch um either reimplemented or uh

1207
00:47:29,520 --> 00:47:34,560
deployed the implementations of these

1208
00:47:32,079 --> 00:47:37,040
models implemented in PyTorch. Uh so

1209
00:47:34,560 --> 00:47:39,839
this is a model zoo but also like after

1210
00:47:37,040 --> 00:47:42,079
you load the model some uh standard sets

1211
00:47:39,839 --> 00:47:45,119
of uh downstream tasks are like simple

1212
00:47:42,079 --> 00:47:47,200
functions to design sequences uh predict

1213
00:47:45,119 --> 00:47:50,240
variant effects or like interpret the

1214
00:47:47,200 --> 00:47:52,640
models and so on. So simply um check out

1215
00:47:50,240 --> 00:47:54,319
the the QR code and can see the code as

1216
00:47:52,640 --> 00:47:55,599
well. So briefly about language

1217
00:47:54,319 --> 00:47:58,880
modeling. This is not really something

1218
00:47:55,599 --> 00:48:01,280
that I am really uh expert on. Uh but

1219
00:47:58,880 --> 00:48:05,280
just to set the scene and um give it to

1220
00:48:01,280 --> 00:48:08,480
to Sur I will briefly mention um what

1221
00:48:05,280 --> 00:48:12,079
genomic language models capture.

1222
00:48:08,480 --> 00:48:15,119
Um so one major category in genomics is

1223
00:48:12,079 --> 00:48:16,880
mass language models. Uh

1224
00:48:15,119 --> 00:48:19,920
where we basically mask like individual

1225
00:48:16,880 --> 00:48:22,960
base pairs and predict the uh predict

1226
00:48:19,920 --> 00:48:24,720
these bases from the context. Right? So

1227
00:48:22,960 --> 00:48:27,200
uh for example these bases are are

1228
00:48:24,720 --> 00:48:28,559
masked and predicted uh from the context

1229
00:48:27,200 --> 00:48:31,599
and these are basically practices

1230
00:48:28,559 --> 00:48:34,400
adopted um from NLP like many things

1231
00:48:31,599 --> 00:48:35,760
that I listed on the earlier slides

1232
00:48:34,400 --> 00:48:38,000
architecture decisions and loss

1233
00:48:35,760 --> 00:48:40,400
functions and so on. uh mass language

1234
00:48:38,000 --> 00:48:42,880
modeling also emerged in NLP and then it

1235
00:48:40,400 --> 00:48:45,520
kind of changed the the AI landscape

1236
00:48:42,880 --> 00:48:47,440
completely in NLP context and people

1237
00:48:45,520 --> 00:48:49,839
naturally asked like if we can simply

1238
00:48:47,440 --> 00:48:52,319
apply it to genomics or not or can we

1239
00:48:49,839 --> 00:48:55,839
basically build foundation models using

1240
00:48:52,319 --> 00:48:57,760
uh these the same principles that um

1241
00:48:55,839 --> 00:49:01,280
enable people to build foundation models

1242
00:48:57,760 --> 00:49:03,440
in other fields. Um

1243
00:49:01,280 --> 00:49:06,160
so there are like many models now there

1244
00:49:03,440 --> 00:49:08,319
there is also maybe not fully complete

1245
00:49:06,160 --> 00:49:10,480
list uh but many different uh mass

1246
00:49:08,319 --> 00:49:13,119
language models like GPN GPN MSA from

1247
00:49:10,480 --> 00:49:15,040
Yunong's lab and DNA bird and others uh

1248
00:49:13,119 --> 00:49:17,040
kodicious is one model that I think Sag

1249
00:49:15,040 --> 00:49:18,720
will mention as well uh and there are

1250
00:49:17,040 --> 00:49:22,400
some auto reggressive language models as

1251
00:49:18,720 --> 00:49:26,640
well basically where we yes

1252
00:49:22,400 --> 00:49:29,280
is the single base pair uh masking is a

1253
00:49:26,640 --> 00:49:31,040
single base masking the common practice

1254
00:49:29,280 --> 00:49:32,640
right now or are they experimenting with

1255
00:49:31,040 --> 00:49:34,880
are people experimenting with different

1256
00:49:32,640 --> 00:49:39,119
sizes of masks and do they see that it

1257
00:49:34,880 --> 00:49:40,800
matters? Uh yeah do you know? Um yeah so

1258
00:49:39,119 --> 00:49:42,240
there are people encode the input

1259
00:49:40,800 --> 00:49:44,800
differently in some cases there is also

1260
00:49:42,240 --> 00:49:47,200
like camera encodings or like the the

1261
00:49:44,800 --> 00:49:50,319
bite pair encodings as well. Uh some of

1262
00:49:47,200 --> 00:49:51,920
the models are like really so for if you

1263
00:49:50,319 --> 00:49:54,160
really want to mask a single base pair

1264
00:49:51,920 --> 00:49:56,079
then um it it makes a lot of sense to

1265
00:49:54,160 --> 00:49:59,760
basically encode the input as single

1266
00:49:56,079 --> 00:50:01,359
nucleotides. Uh but what they do is like

1267
00:49:59,760 --> 00:50:03,040
in training not really one base pair at

1268
00:50:01,359 --> 00:50:04,880
a time but like some fraction of bases

1269
00:50:03,040 --> 00:50:07,359
randomly like 15% for example are

1270
00:50:04,880 --> 00:50:09,760
randomly mass and some bases are also

1271
00:50:07,359 --> 00:50:11,440
like randomly um mutated as well to make

1272
00:50:09,760 --> 00:50:14,480
the model like more robust. Okay. But

1273
00:50:11,440 --> 00:50:19,440
when you say 15% it's like single bases

1274
00:50:14,480 --> 00:50:24,240
at 15 b 15% of the um right? Yeah. Mhm.

1275
00:50:19,440 --> 00:50:25,839
Not so much like a region of five bases

1276
00:50:24,240 --> 00:50:27,760
right next to no not continuous like

1277
00:50:25,839 --> 00:50:30,480
segments of the input but like random

1278
00:50:27,760 --> 00:50:32,960
bases. Um yeah and these are like

1279
00:50:30,480 --> 00:50:36,480
relatively simple or like smaller models

1280
00:50:32,960 --> 00:50:38,240
uh in terms of like context length um

1281
00:50:36,480 --> 00:50:40,000
and training strategies differ as well.

1282
00:50:38,240 --> 00:50:42,400
Some are human specific which is

1283
00:50:40,000 --> 00:50:44,559
extremely challenging I think and some

1284
00:50:42,400 --> 00:50:46,319
like simply augment these models with

1285
00:50:44,559 --> 00:50:48,720
the genomes of other species hundreds or

1286
00:50:46,319 --> 00:50:51,359
even thousands of species species LM is

1287
00:50:48,720 --> 00:50:53,680
is a nice one but it's now adopted in

1288
00:50:51,359 --> 00:50:55,839
many different language models I think

1289
00:50:53,680 --> 00:50:58,960
uh I will highlight GKMSA because it's a

1290
00:50:55,839 --> 00:51:01,200
it's a cool model and I like Gonzalo and

1291
00:50:58,960 --> 00:51:04,160
Yunong um it's one of the earliest

1292
00:51:01,200 --> 00:51:05,760
models it's a small uh context model

1293
00:51:04,160 --> 00:51:07,599
where the input is basically not just

1294
00:51:05,760 --> 00:51:10,160
the human sequence but like a multiple

1295
00:51:07,599 --> 00:51:12,160
sequence alignment of the uh the DNA

1296
00:51:10,160 --> 00:51:14,160
sequence and the masking is done for

1297
00:51:12,160 --> 00:51:16,400
like a human for example. So the model

1298
00:51:14,160 --> 00:51:18,319
is in this case. So there are some nice

1299
00:51:16,400 --> 00:51:20,000
uh creative ways of injecting inductive

1300
00:51:18,319 --> 00:51:22,160
bias, right? So this in this case the

1301
00:51:20,000 --> 00:51:24,640
model so the authors basically know very

1302
00:51:22,160 --> 00:51:27,359
well that uh conservation is really the

1303
00:51:24,640 --> 00:51:28,559
main source of um information for this.

1304
00:51:27,359 --> 00:51:29,920
It should be the main source of

1305
00:51:28,559 --> 00:51:32,720
information. So they inject it

1306
00:51:29,920 --> 00:51:34,480
explicitly. Um then this is the input.

1307
00:51:32,720 --> 00:51:37,839
Um the output is basically the

1308
00:51:34,480 --> 00:51:39,760
probability of each base for the mas u

1309
00:51:37,839 --> 00:51:43,119
positions and as I mentioned in this

1310
00:51:39,760 --> 00:51:46,000
case like 15% of positions are masked

1311
00:51:43,119 --> 00:51:47,440
um

1312
00:51:46,000 --> 00:51:50,240
yeah so this is one of the earlier

1313
00:51:47,440 --> 00:51:51,760
models I think GPN was an an arabidopsis

1314
00:51:50,240 --> 00:51:54,800
model without multiple sequence

1315
00:51:51,760 --> 00:51:56,559
alignment uh but

1316
00:51:54,800 --> 00:51:58,000
without multiple sequence alignment I

1317
00:51:56,559 --> 00:51:59,839
think if you apply it to human genome

1318
00:51:58,000 --> 00:52:02,480
directly the signal is really really

1319
00:51:59,839 --> 00:52:05,200
difficult to pick it up uh so then They

1320
00:52:02,480 --> 00:52:07,280
basically augmented the model with um

1321
00:52:05,200 --> 00:52:10,160
aligned sequences from from many other

1322
00:52:07,280 --> 00:52:13,599
species as well. And also how these

1323
00:52:10,160 --> 00:52:16,000
models use genomes of other species. The

1324
00:52:13,599 --> 00:52:17,599
way they use it is also different.

1325
00:52:16,000 --> 00:52:19,359
Sometimes they just pull all the

1326
00:52:17,599 --> 00:52:22,559
sequences and train one model on the

1327
00:52:19,359 --> 00:52:24,000
pulled um sequence. Sometimes they use

1328
00:52:22,559 --> 00:52:25,839
the multiple sequence alignment. And in

1329
00:52:24,000 --> 00:52:28,240
some cases they also have a an

1330
00:52:25,839 --> 00:52:30,079
additional token uh encoding the

1331
00:52:28,240 --> 00:52:32,720
species. So you really condition the

1332
00:52:30,079 --> 00:52:34,800
model on the species and then this the

1333
00:52:32,720 --> 00:52:37,760
sequence from this species and the model

1334
00:52:34,800 --> 00:52:39,440
learns more explicitly about um the

1335
00:52:37,760 --> 00:52:42,880
features of the sequence condition on

1336
00:52:39,440 --> 00:52:45,680
the species token. Um in this case 100

1337
00:52:42,880 --> 00:52:48,319
vertebrate species um leveraging

1338
00:52:45,680 --> 00:52:50,000
conservation and the genomic context in

1339
00:52:48,319 --> 00:52:52,240
this case and variant effect predictions

1340
00:52:50,000 --> 00:52:53,440
or like pathogenicity of the variance is

1341
00:52:52,240 --> 00:52:55,760
the main application downstream

1342
00:52:53,440 --> 00:52:57,599
application in this case. Uh so the way

1343
00:52:55,760 --> 00:52:59,760
it works is basically you compare the

1344
00:52:57,599 --> 00:53:02,160
probabilities of like a and c for

1345
00:52:59,760 --> 00:53:05,359
example. If your reference al is a and

1346
00:53:02,160 --> 00:53:07,520
the alternative al is c. Uh then the the

1347
00:53:05,359 --> 00:53:11,119
local change of of this gives you a

1348
00:53:07,520 --> 00:53:13,440
score of how um severely this variant

1349
00:53:11,119 --> 00:53:15,119
might be breaking things in the genomes

1350
00:53:13,440 --> 00:53:17,760
that you are looking at which is more or

1351
00:53:15,119 --> 00:53:20,720
less a proxy of um ptoenity of the

1352
00:53:17,760 --> 00:53:23,520
variant. Uh and there are comparisons to

1353
00:53:20,720 --> 00:53:27,200
like CAD which is um more like a feature

1354
00:53:23,520 --> 00:53:29,119
engineered version of the um of of

1355
00:53:27,200 --> 00:53:32,400
variance and variance scoring and

1356
00:53:29,119 --> 00:53:35,119
protein language models or like Philop

1357
00:53:32,400 --> 00:53:37,040
question. Can I ask you a question about

1358
00:53:35,119 --> 00:53:38,559
the masking actually? Yes. kind of

1359
00:53:37,040 --> 00:53:40,079
related to the question just now is like

1360
00:53:38,559 --> 00:53:42,480
what is your opinion on masking

1361
00:53:40,079 --> 00:53:44,720
individual bases randomly versus masking

1362
00:53:42,480 --> 00:53:47,280
like curs because for example you might

1363
00:53:44,720 --> 00:53:48,800
assume that DNA regulatory elements are

1364
00:53:47,280 --> 00:53:52,319
like you know have they have motifs

1365
00:53:48,800 --> 00:53:53,760
right so so what is your opinion on that

1366
00:53:52,319 --> 00:53:55,200
yeah I think they will serve different

1367
00:53:53,760 --> 00:53:56,960
purposes like if you mask the entire

1368
00:53:55,200 --> 00:53:58,480
motif then the question you're asking is

1369
00:53:56,960 --> 00:54:00,400
like is there anything else in the

1370
00:53:58,480 --> 00:54:01,920
context like other motifs for example

1371
00:54:00,400 --> 00:54:04,000
that are predictive of this specific

1372
00:54:01,920 --> 00:54:05,599
motif that you are masking but if you

1373
00:54:04,000 --> 00:54:06,480
mask individual bases it's different

1374
00:54:05,599 --> 00:54:08,480
then

1375
00:54:06,480 --> 00:54:10,240
maybe across but also within the motif

1376
00:54:08,480 --> 00:54:12,880
as well. So if you see the entire motif

1377
00:54:10,240 --> 00:54:14,559
but only one basis must the model will

1378
00:54:12,880 --> 00:54:16,559
have like lots of power to understand

1379
00:54:14,559 --> 00:54:19,200
what this motif is because it kind of

1380
00:54:16,559 --> 00:54:22,000
reoccurs in many different contexts. Uh

1381
00:54:19,200 --> 00:54:23,680
but then maybe your power to detect the

1382
00:54:22,000 --> 00:54:26,480
interactions between motives will be

1383
00:54:23,680 --> 00:54:28,400
limited um because you are basically

1384
00:54:26,480 --> 00:54:30,319
superimposing two two questions at the

1385
00:54:28,400 --> 00:54:32,319
same time. So you look share information

1386
00:54:30,319 --> 00:54:34,400
across motifs but also within motif as

1387
00:54:32,319 --> 00:54:36,559
well. But camera encoding I think is a

1388
00:54:34,400 --> 00:54:38,480
really really strong prior that we don't

1389
00:54:36,559 --> 00:54:40,880
entirely need is my very personal

1390
00:54:38,480 --> 00:54:44,559
opinion because we force the model in a

1391
00:54:40,880 --> 00:54:45,839
um in a very specific direction. Um yeah

1392
00:54:44,559 --> 00:54:48,160
so the var effect prediction is

1393
00:54:45,839 --> 00:54:49,440
basically um looking at the differences

1394
00:54:48,160 --> 00:54:51,760
of the probabilities of two different

1395
00:54:49,440 --> 00:54:53,520
alles which is kind of the main score

1396
00:54:51,760 --> 00:54:56,480
that the model generates and it's

1397
00:54:53,520 --> 00:54:59,280
comparable or in some cases superior uh

1398
00:54:56,480 --> 00:55:00,720
than CAD and ESM or phop which are also

1399
00:54:59,280 --> 00:55:03,040
other approaches exploiting

1400
00:55:00,720 --> 00:55:06,480
conservation. uh there are multiple

1401
00:55:03,040 --> 00:55:09,680
evaluations um I will highlight two so

1402
00:55:06,480 --> 00:55:13,040
one is from Anu's lab um

1403
00:55:09,680 --> 00:55:15,119
they design different uh tasks basically

1404
00:55:13,040 --> 00:55:16,720
different like levels of in in in the

1405
00:55:15,119 --> 00:55:18,960
order of increasing order of

1406
00:55:16,720 --> 00:55:21,440
difficulties so for example whether a

1407
00:55:18,960 --> 00:55:23,200
given sequence is an enhancer or not for

1408
00:55:21,440 --> 00:55:24,800
example like one regular terminal

1409
00:55:23,200 --> 00:55:26,880
classification where the language models

1410
00:55:24,800 --> 00:55:29,200
perform really well too uh but this is a

1411
00:55:26,880 --> 00:55:31,119
relatively easy question uh but as you

1412
00:55:29,200 --> 00:55:32,160
go basically more to more difficult

1413
00:55:31,119 --> 00:55:33,839
tasks

1414
00:55:32,160 --> 00:55:35,440
which typically involve more like cell

1415
00:55:33,839 --> 00:55:38,400
type specific signal then the model

1416
00:55:35,440 --> 00:55:40,079
starts failing. So um because it's not

1417
00:55:38,400 --> 00:55:42,319
basically the model really sees right.

1418
00:55:40,079 --> 00:55:45,359
So the model is u learning more like

1419
00:55:42,319 --> 00:55:47,119
rules of conser uh biology but not

1420
00:55:45,359 --> 00:55:50,000
exactly the cell type specific elements

1421
00:55:47,119 --> 00:55:52,400
and the regulatory gram grammar. uh so

1422
00:55:50,000 --> 00:55:54,240
in cases like the accessibility QTS or

1423
00:55:52,400 --> 00:55:56,799
accessibility prediction itself the

1424
00:55:54,240 --> 00:55:58,480
models uh don't really work well but in

1425
00:55:56,799 --> 00:56:00,480
so there are sets of questions that

1426
00:55:58,480 --> 00:56:02,640
these models should be used for and some

1427
00:56:00,480 --> 00:56:05,359
other questions that the models maybe

1428
00:56:02,640 --> 00:56:07,680
shouldn't use for and trade team is a

1429
00:56:05,359 --> 00:56:11,599
recent preent so the second evaluation

1430
00:56:07,680 --> 00:56:14,240
where we work together um so Gonzalo

1431
00:56:11,599 --> 00:56:16,480
basically um structured two variant data

1432
00:56:14,240 --> 00:56:18,880
sets one is non-coding variants from OMI

1433
00:56:16,480 --> 00:56:23,440
so one group just went through all data

1434
00:56:18,880 --> 00:56:25,839
set and flag the non-coding ones um the

1435
00:56:23,440 --> 00:56:27,839
non-coding rare variants linked to

1436
00:56:25,839 --> 00:56:30,160
mandelian traits and this is like one

1437
00:56:27,839 --> 00:56:32,640
data set basically you have some causal

1438
00:56:30,160 --> 00:56:36,319
non-coding rare variants and a match

1439
00:56:32,640 --> 00:56:38,079
negative set from nomad um and for the

1440
00:56:36,319 --> 00:56:41,040
complex traits we have UK bio bank

1441
00:56:38,079 --> 00:56:44,400
finite UK bio banks variance basically

1442
00:56:41,040 --> 00:56:46,400
from from Hillary's lab um and also a

1443
00:56:44,400 --> 00:56:48,480
negative set basically with the very low

1444
00:56:46,400 --> 00:56:50,160
um fine mapping kind of score and then

1445
00:56:48,480 --> 00:56:52,160
there different criteria to to match

1446
00:56:50,160 --> 00:56:54,079
these positives and negatives like as

1447
00:56:52,160 --> 00:56:58,400
challenging as as we can and then we

1448
00:56:54,079 --> 00:56:59,839
asked if the models can classify or like

1449
00:56:58,400 --> 00:57:03,280
succeed in this like classification

1450
00:56:59,839 --> 00:57:04,799
task. Uh and the results um this is like

1451
00:57:03,280 --> 00:57:06,240
super busy and I won't really go through

1452
00:57:04,799 --> 00:57:08,720
we can spend an hour I think looking at

1453
00:57:06,240 --> 00:57:10,079
this figure and try to make sense of it

1454
00:57:08,720 --> 00:57:11,920
but there are different ways of looking

1455
00:57:10,079 --> 00:57:16,160
at it the zero shot or like the probing

1456
00:57:11,920 --> 00:57:18,000
based um ways of like scoring it. uh but

1457
00:57:16,160 --> 00:57:19,440
the TLDDR I think is like CAD is

1458
00:57:18,000 --> 00:57:21,520
performing really well. This is the last

1459
00:57:19,440 --> 00:57:24,640
version of CAD uh which includes some

1460
00:57:21,520 --> 00:57:26,480
machine learning as well. Uh and models

1461
00:57:24,640 --> 00:57:28,000
um sequence to function models perform

1462
00:57:26,480 --> 00:57:31,839
better

1463
00:57:28,000 --> 00:57:33,119
at complex traits. Um and the GP and MSA

1464
00:57:31,839 --> 00:57:34,960
or like the language some of the

1465
00:57:33,119 --> 00:57:38,559
language models perform better in in in

1466
00:57:34,960 --> 00:57:41,920
mand mandelian traits. um basically is

1467
00:57:38,559 --> 00:57:44,079
the is the TLDDR and lots of large

1468
00:57:41,920 --> 00:57:46,960
extremely big uh language models also

1469
00:57:44,079 --> 00:57:50,000
fail uh in in both of these tasks

1470
00:57:46,960 --> 00:57:52,000
interestingly. Uh so my very personal

1471
00:57:50,000 --> 00:57:55,200
kind of opinion about language modeling

1472
00:57:52,000 --> 00:57:58,880
uh maybe the last um yeah I think the

1473
00:57:55,200 --> 00:58:01,760
last slide. So um most of these

1474
00:57:58,880 --> 00:58:03,760
practices that we copied from NLP uh

1475
00:58:01,760 --> 00:58:06,559
they are not I think really applicable

1476
00:58:03,760 --> 00:58:08,000
um because if you think about NLP uh the

1477
00:58:06,559 --> 00:58:09,680
one thing is the language is like very

1478
00:58:08,000 --> 00:58:11,359
much structured. We don't have like

1479
00:58:09,680 --> 00:58:14,160
simply random words or like things that

1480
00:58:11,359 --> 00:58:16,640
are shuffled or not informative. And the

1481
00:58:14,160 --> 00:58:19,440
second thing is uh in addition to this

1482
00:58:16,640 --> 00:58:22,319
very structured language the the ratio

1483
00:58:19,440 --> 00:58:25,119
of labeled and unlabeled data sets is

1484
00:58:22,319 --> 00:58:27,040
like hugely different. Uh a vast

1485
00:58:25,119 --> 00:58:28,880
majority of it is like unlabelled data

1486
00:58:27,040 --> 00:58:30,720
and we have very small labelled data. So

1487
00:58:28,880 --> 00:58:32,400
this ratio is different. But if you look

1488
00:58:30,720 --> 00:58:33,839
at the the genome basically the the

1489
00:58:32,400 --> 00:58:38,319
structure is loser especially in the

1490
00:58:33,839 --> 00:58:40,160
non-coding regions. Um and also the um

1491
00:58:38,319 --> 00:58:42,400
the label data is like really abundant

1492
00:58:40,160 --> 00:58:44,240
and by labeling it's kind of nature's

1493
00:58:42,400 --> 00:58:45,920
way of labeling it which is basically an

1494
00:58:44,240 --> 00:58:48,960
experiment. So if you think about all

1495
00:58:45,920 --> 00:58:50,400
the experimental data um and how loose

1496
00:58:48,960 --> 00:58:52,720
the structured the language itself is

1497
00:58:50,400 --> 00:58:54,880
it's a really bad combination when you

1498
00:58:52,720 --> 00:58:57,440
simply apply the uh the principles from

1499
00:58:54,880 --> 00:58:59,200
language modeling. So this is like one

1500
00:58:57,440 --> 00:59:02,400
kind of interesting way of like

1501
00:58:59,200 --> 00:59:05,280
visualizing it that I came up with

1502
00:59:02,400 --> 00:59:07,040
yesterday. Um basically so if the models

1503
00:59:05,280 --> 00:59:08,799
if there's like one specific signal that

1504
00:59:07,040 --> 00:59:12,880
a specific cell type is paying attention

1505
00:59:08,799 --> 00:59:14,480
to um the the the genome is basically a

1506
00:59:12,880 --> 00:59:15,760
superimposition of all the cell type

1507
00:59:14,480 --> 00:59:17,520
specific elements. So there are

1508
00:59:15,760 --> 00:59:19,359
different regions that are active in a

1509
00:59:17,520 --> 00:59:21,040
specific context but when the language

1510
00:59:19,359 --> 00:59:22,559
model looks at it bas it basically looks

1511
00:59:21,040 --> 00:59:24,319
at the genome without any functional

1512
00:59:22,559 --> 00:59:26,799
data and it won't really be able to

1513
00:59:24,319 --> 00:59:29,440
delineate all these uh segments that are

1514
00:59:26,799 --> 00:59:31,680
functional in different context. So uh

1515
00:59:29,440 --> 00:59:33,119
if you really want to the model to pick

1516
00:59:31,680 --> 00:59:34,640
up the the context or cell type have

1517
00:59:33,119 --> 00:59:37,359
specific effects then the functional

1518
00:59:34,640 --> 00:59:39,520
data is really useful. But I think still

1519
00:59:37,359 --> 00:59:41,040
seeing these models as a datadriven and

1520
00:59:39,520 --> 00:59:43,280
more like modernized version of

1521
00:59:41,040 --> 00:59:45,200
conservation models or like modeling

1522
00:59:43,280 --> 00:59:48,400
conservation is is a better way to see

1523
00:59:45,200 --> 00:59:52,400
it rather than uh foundational models of

1524
00:59:48,400 --> 00:59:55,040
of the genome. Uh so yes that I would

1525
00:59:52,400 --> 00:59:56,319
like to conclude. Um so sequence to

1526
00:59:55,040 --> 00:59:58,079
function models it's a very well

1527
00:59:56,319 --> 01:00:00,559
established framework. Uh but there are

1528
00:59:58,079 --> 01:00:02,960
still some really cool um challenges

1529
01:00:00,559 --> 01:00:05,359
like open problems to take on. Um

1530
01:00:02,960 --> 01:00:06,799
language model is a really great tool I

1531
01:00:05,359 --> 01:00:08,480
uh as you will see in the next slide

1532
01:00:06,799 --> 01:00:10,240
too. Uh if you use it in in different

1533
01:00:08,480 --> 01:00:12,240
ways I think it will be really useful

1534
01:00:10,240 --> 01:00:14,640
and functional data is like abundant and

1535
01:00:12,240 --> 01:00:17,200
essential. Uh inductive bias is

1536
01:00:14,640 --> 01:00:19,440
basically where the the creativity plays

1537
01:00:17,200 --> 01:00:21,119
plays a huge role. In some cases it's

1538
01:00:19,440 --> 01:00:23,200
maybe simple just like switching from

1539
01:00:21,119 --> 01:00:26,240
convolution to dilated convolution for

1540
01:00:23,200 --> 01:00:28,960
example. But in some cases it's um for

1541
01:00:26,240 --> 01:00:30,480
example avoiding the repetitive regions

1542
01:00:28,960 --> 01:00:32,079
um in the language model training is a

1543
01:00:30,480 --> 01:00:33,920
nice inductive bias. So it doesn't have

1544
01:00:32,079 --> 01:00:36,960
to be a fancy modeling decision but also

1545
01:00:33,920 --> 01:00:40,079
simple decisions about preprocessing or

1546
01:00:36,960 --> 01:00:43,599
um structuring your input uh as some

1547
01:00:40,079 --> 01:00:45,200
room to inject in inductive bias. And

1548
01:00:43,599 --> 01:00:47,280
for whatever reason these two

1549
01:00:45,200 --> 01:00:49,760
communities are like relatively

1550
01:00:47,280 --> 01:00:51,760
distinct. Um although they are modeling

1551
01:00:49,760 --> 01:00:53,520
like very similar things still like some

1552
01:00:51,760 --> 01:00:55,599
sequence features of the of the genome

1553
01:00:53,520 --> 01:00:57,200
from different perspectives both the

1554
01:00:55,599 --> 01:01:00,400
models and the communities are are

1555
01:00:57,200 --> 01:01:02,480
distinct um something to think about and

1556
01:01:00,400 --> 01:01:04,720
also new frameworks I think can really

1557
01:01:02,480 --> 01:01:06,400
bridge this uh but how so I will leave

1558
01:01:04,720 --> 01:01:08,640
you with this cliffhanger so that you

1559
01:01:06,400 --> 01:01:10,319
can stay for for the second talk with

1560
01:01:08,640 --> 01:01:13,040
this I would like to thank all the uh

1561
01:01:10,319 --> 01:01:15,280
collaborators the team members and also

1562
01:01:13,040 --> 01:01:17,119
uh my son which is like the last name

1563
01:01:15,280 --> 01:01:19,200
without whom I think I could have slept

1564
01:01:17,119 --> 01:01:21,599
better and I would have had a better

1565
01:01:19,200 --> 01:01:25,000
memory as well. So, thank you so much

1566
01:01:21,599 --> 01:01:25,000
for your attention.


1
00:00:16,400 --> 00:00:22,720
But yeah, we are very glad to have John

2
00:00:20,080 --> 00:00:24,880
Hull with us here. So, John, please.

3
00:00:22,720 --> 00:00:28,080
>> Well, thanks very much. It's a real

4
00:00:24,880 --> 00:00:30,640
pleasure to be here. Um, let me just say

5
00:00:28,080 --> 00:00:32,079
a little bit by way of introduction. I I

6
00:00:30,640 --> 00:00:35,920
I've probably got a similar background

7
00:00:32,079 --> 00:00:38,559
to many of you. Math was always my my

8
00:00:35,920 --> 00:00:44,719
best subject at high school.

9
00:00:38,559 --> 00:00:47,120
That was uh that was in the UK and um I

10
00:00:44,719 --> 00:00:52,000
not surprisingly ended up doing a math

11
00:00:47,120 --> 00:00:54,879
undergraduate at Cambridge. Um

12
00:00:52,000 --> 00:00:57,360
and you know after

13
00:00:54,879 --> 00:01:01,199
graduating I decided that I wanted to

14
00:00:57,360 --> 00:01:04,159
apply my math in business. So I did a

15
00:01:01,199 --> 00:01:08,880
master's in operational research which

16
00:01:04,159 --> 00:01:14,400
was a fairly new thing in those days. Um

17
00:01:08,880 --> 00:01:17,600
but uh and then an amusing little

18
00:01:14,400 --> 00:01:20,000
factoid, I I I worked for two years

19
00:01:17,600 --> 00:01:21,840
after graduating with my masters. I

20
00:01:20,000 --> 00:01:24,880
worked for two years for a shoe

21
00:01:21,840 --> 00:01:26,640
retailer. Everybody sort of bursts out

22
00:01:24,880 --> 00:01:30,159
laughing when they hear this. Actually,

23
00:01:26,640 --> 00:01:32,960
it was a large shoe retailer in the UK.

24
00:01:30,159 --> 00:01:35,360
It had 2,000 outlets. And actually, it

25
00:01:32,960 --> 00:01:39,119
was a pretty interesting job. I mean it

26
00:01:35,360 --> 00:01:42,320
was all about deciding which outlets

27
00:01:39,119 --> 00:01:44,400
should stock which shoes in which sizes

28
00:01:42,320 --> 00:01:47,119
and so on and then you know which

29
00:01:44,400 --> 00:01:48,560
outlets should be closed and where we

30
00:01:47,119 --> 00:01:50,000
should look for new outlets and that

31
00:01:48,560 --> 00:01:52,479
sort of thing. So there's lots of

32
00:01:50,000 --> 00:01:55,600
interesting stuff

33
00:01:52,479 --> 00:01:59,759
but um after two years

34
00:01:55,600 --> 00:02:02,799
I with this company I sort of moved back

35
00:01:59,759 --> 00:02:04,320
into the academic world.

36
00:02:02,799 --> 00:02:06,960
I

37
00:02:04,320 --> 00:02:10,160
I I won't uh I won't bore you with all

38
00:02:06,960 --> 00:02:15,200
the details, but uh I wound up I got got

39
00:02:10,160 --> 00:02:17,520
my PhD and ended up teaching here at

40
00:02:15,200 --> 00:02:19,120
University of Toronto in what we call

41
00:02:17,520 --> 00:02:21,280
the Joseph L. Rottman School of

42
00:02:19,120 --> 00:02:23,200
Management. And I've been been at

43
00:02:21,280 --> 00:02:25,840
University of Toronto for about 30 years

44
00:02:23,200 --> 00:02:27,840
now.

45
00:02:25,840 --> 00:02:29,760
probably

46
00:02:27,840 --> 00:02:34,879
um

47
00:02:29,760 --> 00:02:37,760
probably I'm best known for my work on

48
00:02:34,879 --> 00:02:39,840
derivatives which I understand you guys

49
00:02:37,760 --> 00:02:41,920
have had quite a bit of instruction in

50
00:02:39,840 --> 00:02:43,519
but um

51
00:02:41,920 --> 00:02:46,160
and you know most of my 30 years has

52
00:02:43,519 --> 00:02:48,480
been spent doing research in derivatives

53
00:02:46,160 --> 00:02:52,160
but about I guess it was about seven

54
00:02:48,480 --> 00:02:55,760
eight years ago I

55
00:02:52,160 --> 00:02:57,440
began to see that uh you machine

56
00:02:55,760 --> 00:03:00,319
learning

57
00:02:57,440 --> 00:03:05,000
and AI were becoming really important to

58
00:03:00,319 --> 00:03:05,000
our students. And so

59
00:03:05,040 --> 00:03:10,000
I sort of switched my focus and in fact

60
00:03:07,760 --> 00:03:16,760
all of my teaching is now in the machine

61
00:03:10,000 --> 00:03:16,760
learning area and pretty much every

62
00:03:17,360 --> 00:03:23,760
so let me advance slide. pretty much

63
00:03:20,640 --> 00:03:28,239
every um

64
00:03:23,760 --> 00:03:31,440
course that we offer at Rottman actually

65
00:03:28,239 --> 00:03:33,920
has either a compulsory course or an

66
00:03:31,440 --> 00:03:35,440
elective in machine learning. So it's

67
00:03:33,920 --> 00:03:39,120
not just me that teaches machine

68
00:03:35,440 --> 00:03:43,920
learning. Now got quite a few colleagues

69
00:03:39,120 --> 00:03:46,959
who who who do so as well.

70
00:03:43,920 --> 00:03:49,920
I I wrote a book which is now in its

71
00:03:46,959 --> 00:03:52,159
third edition um machine learning in

72
00:03:49,920 --> 00:03:55,680
business an introduction to the world of

73
00:03:52,159 --> 00:03:57,519
data science and um you can you can find

74
00:03:55,680 --> 00:04:00,480
out more information on the book from my

75
00:03:57,519 --> 00:04:05,519
website but I'm not saying you should

76
00:04:00,480 --> 00:04:07,439
buy the book now um in fact

77
00:04:05,519 --> 00:04:10,400
re the reverse is true because the

78
00:04:07,439 --> 00:04:12,720
fourth edition will be coming out in

79
00:04:10,400 --> 00:04:14,720
probably about two months.

80
00:04:12,720 --> 00:04:17,199
The fourth edition is going to be with

81
00:04:14,720 --> 00:04:20,239
three co-authors who are actually the

82
00:04:17,199 --> 00:04:24,560
other people who teach uh teach machine

83
00:04:20,239 --> 00:04:26,880
learning here at Robman. So, you know,

84
00:04:24,560 --> 00:04:30,560
the fourth edition is going to deal with

85
00:04:26,880 --> 00:04:34,639
um you know, I mean, third edition came

86
00:04:30,560 --> 00:04:37,520
out in I think it was 2021.

87
00:04:34,639 --> 00:04:40,720
And since then, of course, we've had a

88
00:04:37,520 --> 00:04:43,440
lot of things happen in uh natural

89
00:04:40,720 --> 00:04:46,960
language processing, large language

90
00:04:43,440 --> 00:04:50,400
models, that sort of thing. So I wanted

91
00:04:46,960 --> 00:04:52,320
to you know bring the book up to date

92
00:04:50,400 --> 00:04:55,520
and my colleagues have helped me do

93
00:04:52,320 --> 00:04:58,000
that. So um you know I'm going really

94
00:04:55,520 --> 00:05:00,240
today's presentations in three parts.

95
00:04:58,000 --> 00:05:03,759
I'm going to talk about the nature of

96
00:05:00,240 --> 00:05:06,160
machine learning. Um then I'm going to

97
00:05:03,759 --> 00:05:08,639
move on to talk about applications of

98
00:05:06,160 --> 00:05:10,160
neural networks and finally what I've

99
00:05:08,639 --> 00:05:12,240
been working on quite a lot over the

100
00:05:10,160 --> 00:05:15,440
last little while applications of re

101
00:05:12,240 --> 00:05:17,440
reinforcement learning. Okay. Um, I

102
00:05:15,440 --> 00:05:19,440
don't know whether there's any easy way

103
00:05:17,440 --> 00:05:22,479
you can interrupt me to ask questions,

104
00:05:19,440 --> 00:05:24,720
but I'm I'm happy to be interrupted with

105
00:05:22,479 --> 00:05:27,120
any questions you have as we go along.

106
00:05:24,720 --> 00:05:31,080
Is is it possible for them to interrupt

107
00:05:27,120 --> 00:05:31,080
me with questions?

108
00:05:34,240 --> 00:05:37,360
>> I will I will hear them.

109
00:05:35,919 --> 00:05:39,280
>> Yes, I think you will.

110
00:05:37,360 --> 00:05:42,479
>> Good. Good. Okay. No, I don't mind being

111
00:05:39,280 --> 00:05:44,080
interrupted at all. Okay.

112
00:05:42,479 --> 00:05:48,440
So

113
00:05:44,080 --> 00:05:48,440
uh next slide please.

114
00:05:49,280 --> 00:05:54,639
So what is machine learning? It's uh

115
00:05:51,840 --> 00:05:57,280
it's a branch of AI and the idea

116
00:05:54,639 --> 00:06:00,240
underlying machine learning is is that

117
00:05:57,280 --> 00:06:03,280
we give a computer access to lots of

118
00:06:00,240 --> 00:06:04,720
data and just learn let it learn learn

119
00:06:03,280 --> 00:06:08,960
about the relationships between

120
00:06:04,720 --> 00:06:10,400
variables and make predictions.

121
00:06:08,960 --> 00:06:14,560
Some of the techniques of machine

122
00:06:10,400 --> 00:06:17,600
learning date back to quite a long way.

123
00:06:14,560 --> 00:06:20,400
The key thing that's different today is

124
00:06:17,600 --> 00:06:22,800
that computers are really fast. So we

125
00:06:20,400 --> 00:06:24,880
had all these techniques for doing what

126
00:06:22,800 --> 00:06:27,759
we call machine learning quite some time

127
00:06:24,880 --> 00:06:30,400
ago, but really computers weren't fast

128
00:06:27,759 --> 00:06:33,120
enough to make them a practical tool.

129
00:06:30,400 --> 00:06:35,039
We're now reaching the stage where all

130
00:06:33,120 --> 00:06:37,840
of these ideas

131
00:06:35,039 --> 00:06:41,520
suddenly become practical tools because

132
00:06:37,840 --> 00:06:44,639
of the speed of the machines. Okay. I

133
00:06:41,520 --> 00:06:48,080
think you know it's important to

134
00:06:44,639 --> 00:06:50,479
distinguish between machine learning and

135
00:06:48,080 --> 00:06:53,600
all the automation that's gone on before

136
00:06:50,479 --> 00:06:55,600
it. I mean computers have been used for

137
00:06:53,600 --> 00:06:57,919
many years to automate many business

138
00:06:55,600 --> 00:07:01,199
decisions, payroll, sending out

139
00:06:57,919 --> 00:07:02,800
invoices, so on.

140
00:07:01,199 --> 00:07:05,039
This is what we could call the third

141
00:07:02,800 --> 00:07:08,639
industrial revolution.

142
00:07:05,039 --> 00:07:11,520
Okay. And uh machine learning is central

143
00:07:08,639 --> 00:07:13,520
to the fourth industrial revolution.

144
00:07:11,520 --> 00:07:16,160
You want a bit of background here. The

145
00:07:13,520 --> 00:07:21,440
first industrial revolution was steam

146
00:07:16,160 --> 00:07:24,000
and water power which was uh about 1760

147
00:07:21,440 --> 00:07:26,800
to 1840. The second industrial

148
00:07:24,000 --> 00:07:29,199
revolution was electricity and mass

149
00:07:26,800 --> 00:07:32,560
production.

150
00:07:29,199 --> 00:07:35,039
This is gen this is this is not me. This

151
00:07:32,560 --> 00:07:39,599
is what's generally considered to be the

152
00:07:35,039 --> 00:07:41,840
case and this was 1840 to 1920.

153
00:07:39,599 --> 00:07:45,199
Then

154
00:07:41,840 --> 00:07:46,960
basically computers and digitization

155
00:07:45,199 --> 00:07:49,680
were the third industrial revolution and

156
00:07:46,960 --> 00:07:52,240
we've really had you know we now know

157
00:07:49,680 --> 00:07:55,680
how to use computers to automate things

158
00:07:52,240 --> 00:07:58,160
that human beings do. Um

159
00:07:55,680 --> 00:07:59,840
and uh

160
00:07:58,160 --> 00:08:01,360
I say we can call that computers and

161
00:07:59,840 --> 00:08:03,520
digitization.

162
00:08:01,360 --> 00:08:05,919
And that you we could say that went from

163
00:08:03,520 --> 00:08:08,479
maybe 1950

164
00:08:05,919 --> 00:08:11,199
to the year 2000.

165
00:08:08,479 --> 00:08:13,919
And then

166
00:08:11,199 --> 00:08:16,400
we're now living through the fourth

167
00:08:13,919 --> 00:08:18,319
industrial revolution and we'll be

168
00:08:16,400 --> 00:08:20,479
living through it for quite some time

169
00:08:18,319 --> 00:08:22,879
which is really

170
00:08:20,479 --> 00:08:24,639
you know AI machine learning and

171
00:08:22,879 --> 00:08:27,520
everything

172
00:08:24,639 --> 00:08:31,720
we're going to be talking about today.

173
00:08:27,520 --> 00:08:31,720
Okay ne next slide please.

174
00:08:33,120 --> 00:08:39,680
So if you want to

175
00:08:36,000 --> 00:08:43,440
let's go back to six slide six. Um if

176
00:08:39,680 --> 00:08:45,120
you want to sort of distinguish between

177
00:08:43,440 --> 00:08:46,720
um

178
00:08:45,120 --> 00:08:50,399
the third and the fourth industrial

179
00:08:46,720 --> 00:08:52,720
revolution um

180
00:08:50,399 --> 00:08:55,040
one example I use is with loan

181
00:08:52,720 --> 00:08:58,560
applications. I mean let's suppose we've

182
00:08:55,040 --> 00:09:00,399
got loan officers in a company and there

183
00:08:58,560 --> 00:09:02,080
are certain rules they use to decide

184
00:09:00,399 --> 00:09:03,040
whether a loan should be accepted or

185
00:09:02,080 --> 00:09:06,680
not.

186
00:09:03,040 --> 00:09:06,680
and um

187
00:09:07,519 --> 00:09:11,680
those those rules have been worked out,

188
00:09:10,160 --> 00:09:12,800
then we could automate their activities

189
00:09:11,680 --> 00:09:15,440
and that would just be the third

190
00:09:12,800 --> 00:09:17,440
industrial revolution. If we didn't know

191
00:09:15,440 --> 00:09:19,040
the rules,

192
00:09:17,440 --> 00:09:21,519
we could actually use machine learning

193
00:09:19,040 --> 00:09:23,360
to determine the rules.

194
00:09:21,519 --> 00:09:26,800
We'd collect a lot of lots and lots of

195
00:09:23,360 --> 00:09:28,640
data on loans that

196
00:09:26,800 --> 00:09:31,760
came before the loan officers and the

197
00:09:28,640 --> 00:09:34,880
decisions that were made and it would be

198
00:09:31,760 --> 00:09:36,640
an application of machine learning.

199
00:09:34,880 --> 00:09:40,240
We could go one step further though and

200
00:09:36,640 --> 00:09:43,519
we could also say well let's try and

201
00:09:40,240 --> 00:09:45,760
improve on the rules. So then we could

202
00:09:43,519 --> 00:09:48,560
collect lots of data on decisions that

203
00:09:45,760 --> 00:09:53,360
were made by the loan officers and how

204
00:09:48,560 --> 00:09:55,680
those decisions worked out and u

205
00:09:53,360 --> 00:09:58,959
try and improve the rules for accepting

206
00:09:55,680 --> 00:10:01,920
or rejecting loans.

207
00:09:58,959 --> 00:10:04,720
So the first bullet point here is the

208
00:10:01,920 --> 00:10:06,800
third industrial revolution digitization

209
00:10:04,720 --> 00:10:08,480
fairly straightforward and then the last

210
00:10:06,800 --> 00:10:12,720
two would be applications of machine

211
00:10:08,480 --> 00:10:12,720
learning. Okay, next slide.

212
00:10:13,839 --> 00:10:18,320
So uh I'm sure you've all been trained

213
00:10:16,480 --> 00:10:20,240
in statistics

214
00:10:18,320 --> 00:10:24,399
and we all know that what we're supposed

215
00:10:20,240 --> 00:10:26,160
to do in statistics is

216
00:10:24,399 --> 00:10:28,399
sit down

217
00:10:26,160 --> 00:10:30,320
comfortable chair

218
00:10:28,399 --> 00:10:31,839
not look at any data and develop a

219
00:10:30,320 --> 00:10:34,000
hypothesis.

220
00:10:31,839 --> 00:10:36,399
Then we collect data and test the

221
00:10:34,000 --> 00:10:39,600
hypothesis. That's the sort of standard

222
00:10:36,399 --> 00:10:43,360
way of doing things in statistics.

223
00:10:39,600 --> 00:10:45,360
Machine learning is different. What we

224
00:10:43,360 --> 00:10:47,200
do, we don't develop any hypotheses in

225
00:10:45,360 --> 00:10:49,279
machine learning. We go out and we

226
00:10:47,200 --> 00:10:51,200
collect the data

227
00:10:49,279 --> 00:10:53,680
and we try and explain the data. We try

228
00:10:51,200 --> 00:10:56,160
different models

229
00:10:53,680 --> 00:10:58,399
and we find

230
00:10:56,160 --> 00:11:00,560
patterns in the data or try and develop

231
00:10:58,399 --> 00:11:03,600
predictive tool or something like that.

232
00:11:00,560 --> 00:11:06,160
The key difference between machine

233
00:11:03,600 --> 00:11:08,480
learning and the traditional

234
00:11:06,160 --> 00:11:11,519
statistics

235
00:11:08,480 --> 00:11:13,519
um statistical approach is that in

236
00:11:11,519 --> 00:11:15,120
machine learning

237
00:11:13,519 --> 00:11:17,600
we

238
00:11:15,120 --> 00:11:18,880
collect the data first where in

239
00:11:17,600 --> 00:11:20,560
statistics you're not supposed to

240
00:11:18,880 --> 00:11:22,720
collect the data first. You're supposed

241
00:11:20,560 --> 00:11:25,200
to develop the hypothesis before you've

242
00:11:22,720 --> 00:11:28,720
even looked at the data.

243
00:11:25,200 --> 00:11:31,680
Okay. Um

244
00:11:28,720 --> 00:11:31,680
uh next slide.

245
00:11:33,360 --> 00:11:36,959
So

246
00:11:35,200 --> 00:11:40,000
there's various types of machine

247
00:11:36,959 --> 00:11:42,240
learning algorithms.

248
00:11:40,000 --> 00:11:44,640
Unsupervised learning which is basically

249
00:11:42,240 --> 00:11:49,040
just looking for patterns in the data or

250
00:11:44,640 --> 00:11:50,880
clusters in the data. Um supervised

251
00:11:49,040 --> 00:11:53,120
learning which is where we're trying to

252
00:11:50,880 --> 00:11:56,079
predict something or classify the data

253
00:11:53,120 --> 00:11:59,200
in some way. And then reinforcement

254
00:11:56,079 --> 00:12:00,880
learning which is multi-stage decision

255
00:11:59,200 --> 00:12:03,680
making which we'll be talking a bit

256
00:12:00,880 --> 00:12:06,800
about later on.

257
00:12:03,680 --> 00:12:11,200
And there's you know there's other ways

258
00:12:06,800 --> 00:12:14,399
of subdividing the algorithms but um

259
00:12:11,200 --> 00:12:16,000
you know this is

260
00:12:14,399 --> 00:12:18,880
this you know this is one quick

261
00:12:16,000 --> 00:12:21,519
classification if you like. Machine

262
00:12:18,880 --> 00:12:24,160
learning has its own terminology.

263
00:12:21,519 --> 00:12:26,240
Um and actually this when I first got

264
00:12:24,160 --> 00:12:28,160
into machine learning as I say it was

265
00:12:26,240 --> 00:12:30,240
something like seven or eight years ago

266
00:12:28,160 --> 00:12:33,760
I was pretty confused because the

267
00:12:30,240 --> 00:12:38,240
terminology is different from statistics

268
00:12:33,760 --> 00:12:40,079
you know in um

269
00:12:38,240 --> 00:12:42,320
statistics for example we talk about

270
00:12:40,079 --> 00:12:47,200
dependent variables independent

271
00:12:42,320 --> 00:12:48,880
variables and so on. uh whereas uh

272
00:12:47,200 --> 00:12:50,480
in machine learning we talk about

273
00:12:48,880 --> 00:12:52,639
features

274
00:12:50,480 --> 00:12:54,639
and targets.

275
00:12:52,639 --> 00:12:56,639
Targets as its name implies is the thing

276
00:12:54,639 --> 00:12:59,360
you're trying to predict perhaps and

277
00:12:56,639 --> 00:13:02,399
features are the independent variables

278
00:12:59,360 --> 00:13:04,480
you're trying to predict from. You know

279
00:13:02,399 --> 00:13:08,480
think things like labels, activation

280
00:13:04,480 --> 00:13:10,320
functions and so on. In fact,

281
00:13:08,480 --> 00:13:12,800
when I when I wrote my book, which I

282
00:13:10,320 --> 00:13:15,120
showed you earlier, I have a whole

283
00:13:12,800 --> 00:13:19,120
section, I think it's about 10 pages

284
00:13:15,120 --> 00:13:20,800
long, showing all the terminology

285
00:13:19,120 --> 00:13:25,040
which uh you know, which machine

286
00:13:20,800 --> 00:13:27,360
learning uses um

287
00:13:25,040 --> 00:13:30,160
some of which is quite different from

288
00:13:27,360 --> 00:13:33,279
the terminology that statistics uses and

289
00:13:30,160 --> 00:13:36,639
and other branches.

290
00:13:33,279 --> 00:13:38,560
It's uh

291
00:13:36,639 --> 00:13:42,160
It's one of the things that you know

292
00:13:38,560 --> 00:13:45,519
just takes a bit of getting used to. Um

293
00:13:42,160 --> 00:13:47,839
and you know these this terminology

294
00:13:45,519 --> 00:13:50,000
unsupervised learning supervised

295
00:13:47,839 --> 00:13:53,920
learning for example I mean where does

296
00:13:50,000 --> 00:13:57,360
that come from? Unsupervised learning

297
00:13:53,920 --> 00:14:00,480
well with unsupervised learning you're

298
00:13:57,360 --> 00:14:02,240
just looking for patterns in the data.

299
00:14:00,480 --> 00:14:04,240
So you could say, you know, you don't

300
00:14:02,240 --> 00:14:06,160
really need to

301
00:14:04,240 --> 00:14:08,560
you don't really need any supervision

302
00:14:06,160 --> 00:14:11,800
because all you're doing is just looking

303
00:14:08,560 --> 00:14:11,800
for patterns.

304
00:14:11,839 --> 00:14:15,600
And

305
00:14:14,000 --> 00:14:18,639
so you just all you need to do is to

306
00:14:15,600 --> 00:14:20,480
throw the data at the at the software

307
00:14:18,639 --> 00:14:22,720
and the software will find patterns for

308
00:14:20,480 --> 00:14:24,880
you. Whereas supervised learning, you've

309
00:14:22,720 --> 00:14:27,040
got to do a bit of supervision because

310
00:14:24,880 --> 00:14:28,720
you got to tell

311
00:14:27,040 --> 00:14:31,120
you got to tell the computer what you

312
00:14:28,720 --> 00:14:33,839
want it to do with the data. You want it

313
00:14:31,120 --> 00:14:37,040
to predict something, classify data in

314
00:14:33,839 --> 00:14:38,720
some way and so on.

315
00:14:37,040 --> 00:14:43,199
So

316
00:14:38,720 --> 00:14:45,199
okay, sorry uh next slide.

317
00:14:43,199 --> 00:14:47,440
So just you you one slide on

318
00:14:45,199 --> 00:14:51,519
unsupervised learning then. So in a

319
00:14:47,440 --> 00:14:53,760
typical application what you're asking

320
00:14:51,519 --> 00:14:57,920
you know you

321
00:14:53,760 --> 00:15:00,160
you give the software data

322
00:14:57,920 --> 00:15:02,399
and you ask it to divide the data into

323
00:15:00,160 --> 00:15:05,279
clusters so that observations in the

324
00:15:02,399 --> 00:15:09,199
same cluster have similar feature

325
00:15:05,279 --> 00:15:11,519
values. Okay. So a typical application

326
00:15:09,199 --> 00:15:13,839
would be a company wants to understand

327
00:15:11,519 --> 00:15:16,720
its customers better.

328
00:15:13,839 --> 00:15:20,800
So it collects attributes of its

329
00:15:16,720 --> 00:15:22,639
customers. There may be you know

330
00:15:20,800 --> 00:15:24,880
10 10 different attributes that it

331
00:15:22,639 --> 00:15:28,000
collects you know like how much the

332
00:15:24,880 --> 00:15:30,800
customer spends every year um how many

333
00:15:28,000 --> 00:15:33,600
different products the customer buys

334
00:15:30,800 --> 00:15:36,079
where the customer is located and so on

335
00:15:33,600 --> 00:15:37,600
and so on.

336
00:15:36,079 --> 00:15:40,600
And

337
00:15:37,600 --> 00:15:40,600
basically

338
00:15:40,800 --> 00:15:46,399
you you give the uh software a list of

339
00:15:43,920 --> 00:15:49,839
your customers with those sort of

340
00:15:46,399 --> 00:15:52,320
attributes and it will

341
00:15:49,839 --> 00:15:55,360
classify them or cluster them. So you

342
00:15:52,320 --> 00:15:57,440
say, "Oh yeah, we've got customers that

343
00:15:55,360 --> 00:15:59,199
look like this. We've got customers that

344
00:15:57,440 --> 00:16:01,279
look like this. We've got customers and

345
00:15:59,199 --> 00:16:04,480
and and so on."

346
00:16:01,279 --> 00:16:06,560
And I'm told that, you know, this is

347
00:16:04,480 --> 00:16:10,399
actually quite a powerful tool because

348
00:16:06,560 --> 00:16:12,560
sometimes you get to find cluster

349
00:16:10,399 --> 00:16:14,959
clusters of customers that you never

350
00:16:12,560 --> 00:16:17,279
really thought of as being a cluster of

351
00:16:14,959 --> 00:16:20,639
your customers before, but you know,

352
00:16:17,279 --> 00:16:25,519
this tool has actually enabled you to

353
00:16:20,639 --> 00:16:28,880
sort of find find the clusters.

354
00:16:25,519 --> 00:16:31,519
Okay, next next slide.

355
00:16:28,880 --> 00:16:33,199
So supervised learning is where you are

356
00:16:31,519 --> 00:16:36,800
you're not just trying to understand the

357
00:16:33,199 --> 00:16:38,079
data and create clusters from your data.

358
00:16:36,800 --> 00:16:41,440
You're actually trying to predict

359
00:16:38,079 --> 00:16:45,279
something typically.

360
00:16:41,440 --> 00:16:48,160
And what you do

361
00:16:45,279 --> 00:16:50,560
is you divide your data into three sets.

362
00:16:48,160 --> 00:16:52,480
Training set, a validation set, and a

363
00:16:50,560 --> 00:16:54,959
test set.

364
00:16:52,480 --> 00:16:57,360
Because remember what we're doing here

365
00:16:54,959 --> 00:16:59,920
is not we haven't got a hypothesis.

366
00:16:57,360 --> 00:17:03,360
you've just got a lot of data.

367
00:16:59,920 --> 00:17:06,480
And so you typically you put about 60%

368
00:17:03,360 --> 00:17:08,640
of your data into the training set, 20%

369
00:17:06,480 --> 00:17:10,480
into the validation set, and 20% into

370
00:17:08,640 --> 00:17:12,799
the test set. And hopefully you've got

371
00:17:10,480 --> 00:17:16,880
quite a lot of data.

372
00:17:12,799 --> 00:17:19,919
Okay? So

373
00:17:16,880 --> 00:17:22,480
you develop different models

374
00:17:19,919 --> 00:17:25,360
using the training set.

375
00:17:22,480 --> 00:17:27,280
So you try out different models

376
00:17:25,360 --> 00:17:30,880
and we'll see some examples of this in a

377
00:17:27,280 --> 00:17:34,960
moment and

378
00:17:30,880 --> 00:17:37,840
you compare those models using

379
00:17:34,960 --> 00:17:40,160
validation set say well this model seems

380
00:17:37,840 --> 00:17:43,840
to do better than this other model when

381
00:17:40,160 --> 00:17:46,960
test when tested on you know the

382
00:17:43,840 --> 00:17:50,080
parameters of the model are determined

383
00:17:46,960 --> 00:17:53,200
using the training set

384
00:17:50,080 --> 00:17:58,240
and then you can see how well the models

385
00:17:53,200 --> 00:18:01,600
work on the validation set and uh

386
00:17:58,240 --> 00:18:05,640
decide which seems to be the best model

387
00:18:01,600 --> 00:18:05,640
for explaining the data.

388
00:18:06,320 --> 00:18:12,480
Typically, you know,

389
00:18:10,000 --> 00:18:15,520
you can find a really complex model

390
00:18:12,480 --> 00:18:18,480
sometimes anyway that will explain the

391
00:18:15,520 --> 00:18:20,640
data in the training set, but then it

392
00:18:18,480 --> 00:18:22,799
does not

393
00:18:20,640 --> 00:18:25,840
do well on the validation set. So, the

394
00:18:22,799 --> 00:18:28,559
model can be too complex

395
00:18:25,840 --> 00:18:31,120
as we'll see. So you you want to

396
00:18:28,559 --> 00:18:34,400
typically you want to a rule of thumb is

397
00:18:31,120 --> 00:18:37,120
you want to increase model complexity

398
00:18:34,400 --> 00:18:39,280
until the model starts to perform worse

399
00:18:37,120 --> 00:18:41,760
on the validation set. So once you've

400
00:18:39,280 --> 00:18:43,360
chosen a particular model, you can

401
00:18:41,760 --> 00:18:45,600
increase its complexity and the

402
00:18:43,360 --> 00:18:47,360
parameters and so on, but as soon as it

403
00:18:45,600 --> 00:18:49,760
starts to perform worse on the

404
00:18:47,360 --> 00:18:52,960
validation set, you know, you've

405
00:18:49,760 --> 00:18:55,360
overfitted the training set

406
00:18:52,960 --> 00:18:58,640
and then the test set is sort of kept to

407
00:18:55,360 --> 00:19:01,440
one one side and it's, you know, it's

408
00:18:58,640 --> 00:19:04,480
not being involved in the selection of

409
00:19:01,440 --> 00:19:07,840
the model or anything like that. And so

410
00:19:04,480 --> 00:19:10,960
it provides a good final out of sample

411
00:19:07,840 --> 00:19:14,360
indication as to how well the chosen

412
00:19:10,960 --> 00:19:14,360
model works.

413
00:19:14,400 --> 00:19:19,840
Yeah, next slide please.

414
00:19:17,200 --> 00:19:23,360
Thanks.

415
00:19:19,840 --> 00:19:26,400
So this is this is an example that I use

416
00:19:23,360 --> 00:19:29,039
in the book. It's a pretty uh trivial

417
00:19:26,400 --> 00:19:31,039
example in a way, but it's for

418
00:19:29,039 --> 00:19:33,440
predicting salaries for people in a

419
00:19:31,039 --> 00:19:36,160
certain profession in a certain area as

420
00:19:33,440 --> 00:19:38,240
a function of age and we try out

421
00:19:36,160 --> 00:19:40,080
different models

422
00:19:38,240 --> 00:19:41,679
um

423
00:19:40,080 --> 00:19:43,520
didn't have a huge amount of data for

424
00:19:41,679 --> 00:19:47,280
this particular one. We try out

425
00:19:43,520 --> 00:19:50,960
different models which are

426
00:19:47,280 --> 00:19:54,080
just polomials polomials

427
00:19:50,960 --> 00:19:56,640
of the person age. So the first the

428
00:19:54,080 --> 00:19:59,440
extreme left model is a fifth order

429
00:19:56,640 --> 00:20:02,160
polomial and it fits it fits the data

430
00:19:59,440 --> 00:20:04,640
pretty well.

431
00:20:02,160 --> 00:20:07,679
But actually

432
00:20:04,640 --> 00:20:12,679
what it

433
00:20:07,679 --> 00:20:12,679
what is fitting is the um

434
00:20:13,280 --> 00:20:16,280
first

435
00:20:18,000 --> 00:20:25,120
60% of data that you use to compare your

436
00:20:21,440 --> 00:20:29,039
models. Okay, it doesn't fit the

437
00:20:25,120 --> 00:20:32,559
validation set well.

438
00:20:29,039 --> 00:20:34,880
So it's overfitting. You find

439
00:20:32,559 --> 00:20:37,440
the linear model is underfitting and the

440
00:20:34,880 --> 00:20:42,799
best model actually for the data that I

441
00:20:37,440 --> 00:20:45,679
used was um was a quadratic model.

442
00:20:42,799 --> 00:20:50,520
So salary increases and then sort of

443
00:20:45,679 --> 00:20:50,520
slightly tails off as you get older.

444
00:20:51,120 --> 00:20:55,840
So it's an example of you know if you

445
00:20:53,440 --> 00:20:57,520
just it depends how much data you've got

446
00:20:55,840 --> 00:21:02,080
of course

447
00:20:57,520 --> 00:21:05,360
for um for comparing your models but it

448
00:21:02,080 --> 00:21:08,880
you know but it it quite often happens

449
00:21:05,360 --> 00:21:12,760
that you wind up overfitting

450
00:21:08,880 --> 00:21:12,760
a model and

451
00:21:16,320 --> 00:21:21,760
maybe we just go back a slide or

452
00:21:19,360 --> 00:21:25,679
to uh

453
00:21:21,760 --> 00:21:28,960
yeah so training sorry so the training

454
00:21:25,679 --> 00:21:30,720
so you use the training set but it's you

455
00:21:28,960 --> 00:21:33,039
know you find that you have actually

456
00:21:30,720 --> 00:21:35,280
fitted the training set really well but

457
00:21:33,039 --> 00:21:36,880
the model

458
00:21:35,280 --> 00:21:39,679
doesn't extend well to the validation

459
00:21:36,880 --> 00:21:44,400
set so you then say you've overfitted

460
00:21:39,679 --> 00:21:45,840
the training set okay so that's example

461
00:21:44,400 --> 00:21:48,320
of what I'm talking about increased

462
00:21:45,840 --> 00:21:51,679
model complexity until the model starts

463
00:21:48,320 --> 00:21:54,720
to perform worse on the validation set.

464
00:21:51,679 --> 00:21:56,880
Thanks, Peter. Let's uh let's move on.

465
00:21:54,720 --> 00:21:58,880
Neural networks. Well, maybe I I'll just

466
00:21:56,880 --> 00:22:02,400
stop there. Are there any questions that

467
00:21:58,880 --> 00:22:06,919
uh anybody really wants to ask or points

468
00:22:02,400 --> 00:22:06,919
anybody wants to make before we move on?

469
00:22:12,559 --> 00:22:21,280
Okay. If not, um, okay, let's move on to

470
00:22:18,240 --> 00:22:23,120
the next slide. And the next slide. So,

471
00:22:21,280 --> 00:22:26,120
we're now going to talk about neural

472
00:22:23,120 --> 00:22:26,120
networks.

473
00:22:26,320 --> 00:22:34,960
And here's a picture of an artificial

474
00:22:29,760 --> 00:22:38,159
neural network. It's abbreviated ANN.

475
00:22:34,960 --> 00:22:42,320
So basically what we're trying to do is

476
00:22:38,159 --> 00:22:44,880
to in this example predict something

477
00:22:42,320 --> 00:22:48,960
from certain variables. So the input

478
00:22:44,880 --> 00:22:52,520
layer would be the variables

479
00:22:48,960 --> 00:22:52,520
that we know.

480
00:22:52,640 --> 00:22:57,440
Okay. And the output layer are the one

481
00:22:55,760 --> 00:23:00,159
or more things we're trying to predict.

482
00:22:57,440 --> 00:23:02,400
Now I know I've got multiple variables

483
00:23:00,159 --> 00:23:04,080
in the output layer here. Typically

484
00:23:02,400 --> 00:23:06,000
though

485
00:23:04,080 --> 00:23:08,480
in many applications there's only one

486
00:23:06,000 --> 00:23:10,640
thing you're trying to predict. So let's

487
00:23:08,480 --> 00:23:12,159
think in ter I mean if there's multiple

488
00:23:10,640 --> 00:23:14,640
things you're trying to predict then

489
00:23:12,159 --> 00:23:16,480
obviously you've got to

490
00:23:14,640 --> 00:23:18,559
in terms of your objective you've got to

491
00:23:16,480 --> 00:23:20,240
wait how important is it to predict this

492
00:23:18,559 --> 00:23:22,320
one how important is it to predict that

493
00:23:20,240 --> 00:23:24,080
one and so on. So let you know let's

494
00:23:22,320 --> 00:23:27,600
just for the moment assume there's only

495
00:23:24,080 --> 00:23:30,880
one variable in the output layer.

496
00:23:27,600 --> 00:23:34,799
The models that you're most

497
00:23:30,880 --> 00:23:36,559
familiar with are models that

498
00:23:34,799 --> 00:23:39,600
predict

499
00:23:36,559 --> 00:23:43,919
the output from the input in one go as

500
00:23:39,600 --> 00:23:48,320
it were. Linear regression

501
00:23:43,919 --> 00:23:51,679
uh would be a classic example. Um

502
00:23:48,320 --> 00:23:54,480
but you know

503
00:23:51,679 --> 00:23:57,760
any any more complicated model is is

504
00:23:54,480 --> 00:24:00,720
also likely to you know predict the

505
00:23:57,760 --> 00:24:03,280
output directly from the input. The key

506
00:24:00,720 --> 00:24:06,320
thing that we're doing with an

507
00:24:03,280 --> 00:24:09,120
artificial neural network is we're not

508
00:24:06,320 --> 00:24:11,600
doing it all in one go.

509
00:24:09,120 --> 00:24:13,600
We're get we're using the input layer,

510
00:24:11,600 --> 00:24:15,840
the variables

511
00:24:13,600 --> 00:24:18,240
that we know

512
00:24:15,840 --> 00:24:20,080
to predict

513
00:24:18,240 --> 00:24:24,559
these variables in the first hidden

514
00:24:20,080 --> 00:24:25,919
layer. V11, V12, V13 and so on. And then

515
00:24:24,559 --> 00:24:28,080
we use those variables in the first

516
00:24:25,919 --> 00:24:32,720
hidden layer to predict variables in the

517
00:24:28,080 --> 00:24:37,080
second hidden layer. V21, V22, V23 and

518
00:24:32,720 --> 00:24:37,080
so on. And then the third hidden layer.

519
00:24:37,360 --> 00:24:42,000
So the key thing is about a neural

520
00:24:40,080 --> 00:24:44,720
network is that you're going through a

521
00:24:42,000 --> 00:24:47,600
number of stages in predicting the

522
00:24:44,720 --> 00:24:49,440
output from the input.

523
00:24:47,600 --> 00:24:51,679
It's not all done in one go. So we're

524
00:24:49,440 --> 00:24:53,200
not we're not writing down a nice neat

525
00:24:51,679 --> 00:24:55,039
equation

526
00:24:53,200 --> 00:24:57,600
for the relationship between the output

527
00:24:55,039 --> 00:24:59,919
and the input and predict predicting the

528
00:24:57,600 --> 00:25:03,120
parameters of that equation. We're

529
00:24:59,919 --> 00:25:04,960
saying there's a number of stages we go

530
00:25:03,120 --> 00:25:08,640
through

531
00:25:04,960 --> 00:25:11,640
in getting from the input to the output

532
00:25:08,640 --> 00:25:11,640
and

533
00:25:11,760 --> 00:25:16,320
um

534
00:25:14,400 --> 00:25:19,039
that makes the model of course a lot

535
00:25:16,320 --> 00:25:22,559
more flexible.

536
00:25:19,039 --> 00:25:24,480
Uh next slide.

537
00:25:22,559 --> 00:25:29,200
So

538
00:25:24,480 --> 00:25:32,080
what's the relationship between

539
00:25:29,200 --> 00:25:35,919
the values in one layer and the values

540
00:25:32,080 --> 00:25:38,919
in the previous layer?

541
00:25:35,919 --> 00:25:38,919
Well,

542
00:25:39,120 --> 00:25:45,760
what we're doing is we're relating the

543
00:25:41,200 --> 00:25:47,600
values at one neuron to a linear

544
00:25:45,760 --> 00:25:50,799
combination of values in the previous

545
00:25:47,600 --> 00:25:52,080
layer. And

546
00:25:50,799 --> 00:25:54,400
we're using these things called

547
00:25:52,080 --> 00:25:57,120
activation functions to do it. Maybe we

548
00:25:54,400 --> 00:25:59,760
go back a slide. Uh now, Peter, if we

549
00:25:57,120 --> 00:26:04,960
could. And so

550
00:25:59,760 --> 00:26:06,320
if we look here, V11 is related to the

551
00:26:04,960 --> 00:26:10,480
variables in the input layer, the

552
00:26:06,320 --> 00:26:12,640
variables we know, V 01, V 02, V 03. And

553
00:26:10,480 --> 00:26:16,799
what we do, what we do is we apply

554
00:26:12,640 --> 00:26:21,200
weights to those variables. So we have a

555
00:26:16,799 --> 00:26:27,799
weight times v 01 plus a weight time v

556
00:26:21,200 --> 00:26:27,799
02 plus a weight time v 03 and so on.

557
00:26:28,320 --> 00:26:32,559
And then once we got this weighted

558
00:26:30,960 --> 00:26:36,480
average

559
00:26:32,559 --> 00:26:40,240
of the v 01, v 02, v 03, we apply a

560
00:26:36,480 --> 00:26:43,520
function to it to get v11. And then we

561
00:26:40,240 --> 00:26:47,679
do the same thing for v12. We take a,

562
00:26:43,520 --> 00:26:51,039
you know, a weighted average of V 01, V

563
00:26:47,679 --> 00:26:55,360
02, V 03 and so on different weighted

564
00:26:51,039 --> 00:26:58,960
average and apply a function to it to

565
00:26:55,360 --> 00:27:03,360
get V12 and so on.

566
00:26:58,960 --> 00:27:07,760
And then to go from the V1s, V12s, V13s

567
00:27:03,360 --> 00:27:12,640
to V21, V22, V23, we do the same thing.

568
00:27:07,760 --> 00:27:15,120
So V21 for example, we take a weighted

569
00:27:12,640 --> 00:27:21,320
average of

570
00:27:15,120 --> 00:27:21,320
V11, V12, V13, V14 and so on

571
00:27:22,000 --> 00:27:28,400
and apply a function to it this

572
00:27:25,120 --> 00:27:30,720
activation function to get V21.

573
00:27:28,400 --> 00:27:32,480
Okay. And then so what are the thing is

574
00:27:30,720 --> 00:27:34,960
what are the parameters of this model?

575
00:27:32,480 --> 00:27:36,960
the parameters of the weights. What

576
00:27:34,960 --> 00:27:41,200
weights

577
00:27:36,960 --> 00:27:44,559
what weights do we apply to the V's

578
00:27:41,200 --> 00:27:49,279
in going from one layer to the next

579
00:27:44,559 --> 00:27:51,440
layer. Okay? And you know there's a lot

580
00:27:49,279 --> 00:27:54,159
of weights in this example that you got

581
00:27:51,440 --> 00:27:56,799
in front of you there because when we're

582
00:27:54,159 --> 00:28:00,720
determining V11, we've got a weight

583
00:27:56,799 --> 00:28:03,440
associated with V01, V 02, V 03, and so

584
00:28:00,720 --> 00:28:03,440
on.

585
00:28:03,600 --> 00:28:08,559
But if even if there are only three

586
00:28:05,039 --> 00:28:12,080
inputs, that's three weights. And then

587
00:28:08,559 --> 00:28:14,320
V12 is another three weights. V13 is

588
00:28:12,080 --> 00:28:16,480
another three weights and so on. So you

589
00:28:14,320 --> 00:28:19,120
can wind up with a lot of weights. But

590
00:28:16,480 --> 00:28:20,799
those are the variables that uh those

591
00:28:19,120 --> 00:28:23,120
weights

592
00:28:20,799 --> 00:28:25,919
are are the variables you're trying to

593
00:28:23,120 --> 00:28:28,799
determine. And then the activation

594
00:28:25,919 --> 00:28:31,919
function is something you apply after

595
00:28:28,799 --> 00:28:34,080
you've applied the weights.

596
00:28:31,919 --> 00:28:37,760
Okay. So, can we move on to the next

597
00:28:34,080 --> 00:28:40,399
slide now? So, you see

598
00:28:37,760 --> 00:28:44,480
a number of different activation

599
00:28:40,399 --> 00:28:47,039
functions that you could use. FY fy

600
00:28:44,480 --> 00:28:49,919
equals y means that you've just applied

601
00:28:47,039 --> 00:28:52,240
weights to the variables in the previous

602
00:28:49,919 --> 00:28:53,360
layer and then you've just haven't done

603
00:28:52,240 --> 00:28:55,360
anything else to them. You've just said

604
00:28:53,360 --> 00:28:57,440
that that's going to give you the value

605
00:28:55,360 --> 00:29:01,279
in the new layer.

606
00:28:57,440 --> 00:29:03,520
Now if throughout

607
00:29:01,279 --> 00:29:06,399
the whole

608
00:29:03,520 --> 00:29:08,240
neural network you just use the identity

609
00:29:06,399 --> 00:29:11,120
if you think about it you would just

610
00:29:08,240 --> 00:29:12,720
have a linear model.

611
00:29:11,120 --> 00:29:17,200
Okay.

612
00:29:12,720 --> 00:29:19,520
So if uh you know the variables in the

613
00:29:17,200 --> 00:29:21,520
first layer were a linear function of

614
00:29:19,520 --> 00:29:23,760
the input layer, the variables in the

615
00:29:21,520 --> 00:29:26,320
second layer were a line were linear

616
00:29:23,760 --> 00:29:28,880
functions of the variables in the first

617
00:29:26,320 --> 00:29:30,880
layer and so on and you went all the way

618
00:29:28,880 --> 00:29:32,000
through then it would just be a linear

619
00:29:30,880 --> 00:29:33,600
model and that wouldn't be very

620
00:29:32,000 --> 00:29:35,039
interesting because if we want to have a

621
00:29:33,600 --> 00:29:37,919
linear model we don't have to go through

622
00:29:35,039 --> 00:29:41,679
all this. However,

623
00:29:37,919 --> 00:29:44,480
as we'll see, you often use the identity

624
00:29:41,679 --> 00:29:48,720
just for the final layer.

625
00:29:44,480 --> 00:29:52,480
You see, sigmoid is a a popular um

626
00:29:48,720 --> 00:29:56,679
activation function. So sing the so once

627
00:29:52,480 --> 00:29:56,679
you've uh determined

628
00:29:57,600 --> 00:30:04,159
the uh weighted average

629
00:30:01,360 --> 00:30:08,880
of the variables in the previous layer

630
00:30:04,159 --> 00:30:10,399
you you take one 1 - 1 + e to the minus

631
00:30:08,880 --> 00:30:13,840
that

632
00:30:10,399 --> 00:30:17,840
to get the value at the new node and so

633
00:30:13,840 --> 00:30:20,480
on. hyperbolic tangent ru and so on lots

634
00:30:17,840 --> 00:30:23,600
of different activation functions. So

635
00:30:20,480 --> 00:30:25,600
you get the idea you've

636
00:30:23,600 --> 00:30:27,120
you're really saying that the

637
00:30:25,600 --> 00:30:31,919
relationship

638
00:30:27,120 --> 00:30:34,880
with between the output and the input is

639
00:30:31,919 --> 00:30:39,279
a kind of a convolution

640
00:30:34,880 --> 00:30:40,960
of a lot of these activation functions

641
00:30:39,279 --> 00:30:44,080
applied

642
00:30:40,960 --> 00:30:47,880
to weighted averages.

643
00:30:44,080 --> 00:30:47,880
Okay, next. Um

644
00:30:49,120 --> 00:30:52,600
so uh

645
00:30:55,120 --> 00:31:01,039
how do we actually solve the model?

646
00:30:58,720 --> 00:31:03,200
Well,

647
00:31:01,039 --> 00:31:07,360
basically

648
00:31:03,200 --> 00:31:09,840
you've got lot typically in in these

649
00:31:07,360 --> 00:31:11,840
in models you've got lots of parameter

650
00:31:09,840 --> 00:31:14,799
values all the different weights that

651
00:31:11,840 --> 00:31:17,600
you're applying

652
00:31:14,799 --> 00:31:20,799
and uh

653
00:31:17,600 --> 00:31:23,120
you say well you start off by assuming

654
00:31:20,799 --> 00:31:24,720
some values for the weights probably not

655
00:31:23,120 --> 00:31:27,279
very good values but you assume some

656
00:31:24,720 --> 00:31:29,600
values and then you calculate gradients

657
00:31:27,279 --> 00:31:32,960
you say Well,

658
00:31:29,600 --> 00:31:37,039
we're perhaps we're trying to minimize

659
00:31:32,960 --> 00:31:40,000
some value or or minimize a function.

660
00:31:37,039 --> 00:31:42,799
So, we're trying to determine the input

661
00:31:40,000 --> 00:31:44,799
values that will minimize some function.

662
00:31:42,799 --> 00:31:46,799
So, we calculate gradients to determine

663
00:31:44,799 --> 00:31:50,679
the direction in which the parameter

664
00:31:46,799 --> 00:31:50,679
values should be changed

665
00:31:50,880 --> 00:31:56,240
to improve things to actually make the

666
00:31:53,519 --> 00:31:58,080
function smaller. And then you take a

667
00:31:56,240 --> 00:31:59,840
step

668
00:31:58,080 --> 00:32:02,559
and then do the whole thing again.

669
00:31:59,840 --> 00:32:04,480
Calculate the gradients

670
00:32:02,559 --> 00:32:06,240
and

671
00:32:04,480 --> 00:32:08,880
and

672
00:32:06,240 --> 00:32:12,159
move the parameter values again in a

673
00:32:08,880 --> 00:32:14,720
certain direction and so on.

674
00:32:12,159 --> 00:32:18,559
So

675
00:32:14,720 --> 00:32:23,200
it's it's it's a case of

676
00:32:18,559 --> 00:32:25,919
Phoenix somebody trying to call me. Um,

677
00:32:23,200 --> 00:32:29,039
so

678
00:32:25,919 --> 00:32:31,200
basically what you need is you're trying

679
00:32:29,039 --> 00:32:33,519
to minimize some function. What you need

680
00:32:31,200 --> 00:32:36,159
is the partial derivative of that

681
00:32:33,519 --> 00:32:38,720
function with respect to all these

682
00:32:36,159 --> 00:32:41,120
parameters, all these weights that

683
00:32:38,720 --> 00:32:44,240
define your model.

684
00:32:41,120 --> 00:32:45,840
Now that seems a pretty tricky task, but

685
00:32:44,240 --> 00:32:48,840
actually

686
00:32:45,840 --> 00:32:48,840
um

687
00:32:49,279 --> 00:32:55,440
there was I mean clever maybe you could

688
00:32:52,320 --> 00:32:59,200
say almost obvious way of doing this is

689
00:32:55,440 --> 00:33:02,720
to say what we're really talking about

690
00:32:59,200 --> 00:33:05,200
with this model is

691
00:33:02,720 --> 00:33:06,960
the final thing that we're interested in

692
00:33:05,200 --> 00:33:12,720
being a function of a function of a

693
00:33:06,960 --> 00:33:14,799
function. In other words, if you know,

694
00:33:12,720 --> 00:33:18,480
we're we're a function of the final

695
00:33:14,799 --> 00:33:21,840
weights and those final weights are a

696
00:33:18,480 --> 00:33:23,519
function of the

697
00:33:21,840 --> 00:33:25,519
weights that come immediately before the

698
00:33:23,519 --> 00:33:30,240
final weights and then those final

699
00:33:25,519 --> 00:33:34,240
weights, you know, so each weight

700
00:33:30,240 --> 00:33:37,760
and of course in in calculus we know how

701
00:33:34,240 --> 00:33:39,760
to calculate the gradient of a function.

702
00:33:37,760 --> 00:33:43,200
of a function of a function. So there

703
00:33:39,760 --> 00:33:45,440
are some clever shortcuts

704
00:33:43,200 --> 00:33:48,320
or um

705
00:33:45,440 --> 00:33:50,399
you know for calculating these gradients

706
00:33:48,320 --> 00:33:53,519
that you need

707
00:33:50,399 --> 00:33:55,679
to to sort of move the parameters in the

708
00:33:53,519 --> 00:33:58,240
right direction. Okay, you're not

709
00:33:55,679 --> 00:34:02,120
starting from scratch in terms of

710
00:33:58,240 --> 00:34:02,120
calculating each gradient.

711
00:34:03,519 --> 00:34:08,039
Uh next next slide please.

712
00:34:09,119 --> 00:34:13,520
So this is a very simple example but it

713
00:34:11,280 --> 00:34:15,040
illustrates the nature of what you're

714
00:34:13,520 --> 00:34:17,119
doing. I mean let's suppose you wanted

715
00:34:15,040 --> 00:34:18,720
to calculate the value of x that

716
00:34:17,119 --> 00:34:21,040
minimizes

717
00:34:18,720 --> 00:34:25,679
this function

718
00:34:21,040 --> 00:34:27,679
y = x^2 - 8x + 20. Of course you know we

719
00:34:25,679 --> 00:34:31,839
could all do this with calculus very

720
00:34:27,679 --> 00:34:34,639
quickly and x= 4 is the answer. But

721
00:34:31,839 --> 00:34:38,159
suppose we we were doing it in the way

722
00:34:34,639 --> 00:34:41,280
that I just described.

723
00:34:38,159 --> 00:34:44,159
Then we'd start with some estimate of x.

724
00:34:41,280 --> 00:34:46,320
It might be x= 1. Not a very good

725
00:34:44,159 --> 00:34:49,320
estimate. And then we'd look at the

726
00:34:46,320 --> 00:34:49,320
gradient

727
00:34:50,639 --> 00:34:56,800
of um

728
00:34:53,200 --> 00:34:59,839
of this when x= 1.

729
00:34:56,800 --> 00:35:03,920
And what is it? It's you know 2x

730
00:34:59,839 --> 00:35:07,960
minus 8. So it's the gradient is minus

731
00:35:03,920 --> 00:35:07,960
6. So we move

732
00:35:09,680 --> 00:35:15,520
you know you know we move the value that

733
00:35:12,720 --> 00:35:17,520
we're looking at in the direction which

734
00:35:15,520 --> 00:35:20,320
minimizes

735
00:35:17,520 --> 00:35:23,440
um

736
00:35:20,320 --> 00:35:26,079
y which you know the gradient was minus

737
00:35:23,440 --> 00:35:26,960
6. So we take the negative of the

738
00:35:26,079 --> 00:35:30,560
gradient because we're trying to

739
00:35:26,960 --> 00:35:33,599
minimize something and

740
00:35:30,560 --> 00:35:36,160
move it in the direction indicated by

741
00:35:33,599 --> 00:35:38,480
the gradient

742
00:35:36,160 --> 00:35:39,839
by a certain amount and we see that

743
00:35:38,480 --> 00:35:41,760
we're then at a little bit more than

744
00:35:39,839 --> 00:35:44,880
two. Then we calculate the gradient

745
00:35:41,760 --> 00:35:47,839
again. Move again. Calate gradient

746
00:35:44,880 --> 00:35:49,760
again. So you can see how this method

747
00:35:47,839 --> 00:35:52,000
would work

748
00:35:49,760 --> 00:35:54,240
in this very simple example where

749
00:35:52,000 --> 00:35:56,960
there's

750
00:35:54,240 --> 00:36:00,320
when there's only one thing that we

751
00:35:56,960 --> 00:36:03,200
we're having to estimate.

752
00:36:00,320 --> 00:36:04,800
Okay. And

753
00:36:03,200 --> 00:36:08,000
obviously when there's many things we

754
00:36:04,800 --> 00:36:10,000
want to estimate um it's the same basic

755
00:36:08,000 --> 00:36:11,839
principle except we're we're working in

756
00:36:10,000 --> 00:36:17,000
many dimensions.

757
00:36:11,839 --> 00:36:17,000
Okay. Uh next slide please.

758
00:36:17,440 --> 00:36:22,560
So we continue training the model until

759
00:36:20,880 --> 00:36:24,480
the results for the validation set

760
00:36:22,560 --> 00:36:27,119
diverge from those for the training set.

761
00:36:24,480 --> 00:36:28,880
We don't want to overtrain.

762
00:36:27,119 --> 00:36:31,680
Choosing the learning rate is important.

763
00:36:28,880 --> 00:36:34,400
The learning rate is how far we move.

764
00:36:31,680 --> 00:36:36,720
Once we've once we've estimated the

765
00:36:34,400 --> 00:36:40,560
gradient,

766
00:36:36,720 --> 00:36:42,720
we have we have to uh decide how far we

767
00:36:40,560 --> 00:36:47,599
want to move in the direction indicated

768
00:36:42,720 --> 00:36:51,119
by the gradient. And um

769
00:36:47,599 --> 00:36:54,400
that's uh well there are you know there

770
00:36:51,119 --> 00:36:57,359
are some clever ways of determining the

771
00:36:54,400 --> 00:36:59,040
the learning rate as it's called but

772
00:36:57,359 --> 00:37:02,880
clearly if we could just go back to the

773
00:36:59,040 --> 00:37:04,800
previous slide a moment um you can I

774
00:37:02,880 --> 00:37:06,720
think you can see here if you choose a

775
00:37:04,800 --> 00:37:09,599
really

776
00:37:06,720 --> 00:37:12,320
small learning rate

777
00:37:09,599 --> 00:37:15,440
then I mean the gradient at one would be

778
00:37:12,320 --> 00:37:17,119
the same but you'd move only very short

779
00:37:15,440 --> 00:37:19,119
amounts and then you calculate the

780
00:37:17,119 --> 00:37:21,040
gradient again and move a very short

781
00:37:19,119 --> 00:37:23,440
amount and so on. You'd never actually

782
00:37:21,040 --> 00:37:25,359
reach the bottom of the you never in a

783
00:37:23,440 --> 00:37:27,200
reasonable time reach the bottom of the

784
00:37:25,359 --> 00:37:29,520
curve. If you made the learning rate too

785
00:37:27,200 --> 00:37:32,320
small because the learning rate is just

786
00:37:29,520 --> 00:37:34,400
is determining how far you move once

787
00:37:32,320 --> 00:37:35,680
you've determined the gradient. On the

788
00:37:34,400 --> 00:37:37,359
other hand, if the learning rate is too

789
00:37:35,680 --> 00:37:40,000
big, you could oscillate and sort of

790
00:37:37,359 --> 00:37:42,480
move from above the minimum to below the

791
00:37:40,000 --> 00:37:45,040
minimum to above the minimum to to below

792
00:37:42,480 --> 00:37:47,920
the minimum and so on.

793
00:37:45,040 --> 00:37:50,480
So determining the learning rate is

794
00:37:47,920 --> 00:37:52,320
important and some you know you can do

795
00:37:50,480 --> 00:37:58,800
it by trial and error as I say there's

796
00:37:52,320 --> 00:38:03,599
some clever ways of of doing it as well.

797
00:37:58,800 --> 00:38:05,359
Okay. Um next slide please. Um it's also

798
00:38:03,599 --> 00:38:08,079
turns out to be best to scale the

799
00:38:05,359 --> 00:38:09,599
variables.

800
00:38:08,079 --> 00:38:11,200
When you're doing all of this and back

801
00:38:09,599 --> 00:38:13,440
propagation is used to calculate the

802
00:38:11,200 --> 00:38:16,240
partial derivatives that that's what I

803
00:38:13,440 --> 00:38:18,400
mentioned before, which is really just

804
00:38:16,240 --> 00:38:19,680
saying the partial derivatives, you're

805
00:38:18,400 --> 00:38:21,359
talking about taking the partial

806
00:38:19,680 --> 00:38:23,359
derivative of something which is a

807
00:38:21,359 --> 00:38:24,960
function of a function. We've known how

808
00:38:23,359 --> 00:38:26,560
to do that in calculus for quite a long

809
00:38:24,960 --> 00:38:30,560
time.

810
00:38:26,560 --> 00:38:34,400
Okay. Uh next slide, please.

811
00:38:30,560 --> 00:38:36,960
So here's, you know, one application

812
00:38:34,400 --> 00:38:39,359
that we've used it for. We may may seem

813
00:38:36,960 --> 00:38:43,200
a little artificial, but actually it's

814
00:38:39,359 --> 00:38:45,680
not as I'll explain in a minute. But

815
00:38:43,200 --> 00:38:49,040
basically, I generated 10,000 call

816
00:38:45,680 --> 00:38:52,560
option prices using the black shells

817
00:38:49,040 --> 00:38:56,079
model and added a normally distributed

818
00:38:52,560 --> 00:38:58,880
error. So I I generated a lot of data. I

819
00:38:56,079 --> 00:39:02,880
said that you know

820
00:38:58,880 --> 00:39:05,200
the asset price S the strike price K the

821
00:39:02,880 --> 00:39:10,240
risk-free rate

822
00:39:05,200 --> 00:39:12,480
um the volatility sigma and the time to

823
00:39:10,240 --> 00:39:14,000
maturity uh you you can see in the

824
00:39:12,480 --> 00:39:17,440
second bullet point there what I chose

825
00:39:14,000 --> 00:39:20,560
as the um

826
00:39:17,440 --> 00:39:23,280
as the ranges there. So we we we we

827
00:39:20,560 --> 00:39:24,880
sampled parameters randomly and then

828
00:39:23,280 --> 00:39:28,320
added

829
00:39:24,880 --> 00:39:31,119
a normally distributed error term

830
00:39:28,320 --> 00:39:33,119
to the black shells model and then said

831
00:39:31,119 --> 00:39:36,000
you know

832
00:39:33,119 --> 00:39:39,560
let's see how well the model can

833
00:39:36,000 --> 00:39:39,560
actually determine

834
00:39:39,839 --> 00:39:46,000
what the function is

835
00:39:42,400 --> 00:39:49,440
and actually use three hidden layers 20

836
00:39:46,000 --> 00:39:54,160
neurons per layer

837
00:39:49,440 --> 00:39:56,720
and sigmoid activation function

838
00:39:54,160 --> 00:39:58,560
except the final layer and this is a

839
00:39:56,720 --> 00:40:00,800
point if I'd used the sigmoid activation

840
00:39:58,560 --> 00:40:03,920
function everywhere it wouldn't have

841
00:40:00,800 --> 00:40:05,839
worked because

842
00:40:03,920 --> 00:40:09,119
sigmoid activation function gives you a

843
00:40:05,839 --> 00:40:11,920
value between zero and one and of course

844
00:40:09,119 --> 00:40:15,280
the black shells m price is not between

845
00:40:11,920 --> 00:40:19,440
zero and one so

846
00:40:15,280 --> 00:40:23,040
I I I used the um

847
00:40:19,440 --> 00:40:25,599
identity activation function for the

848
00:40:23,040 --> 00:40:27,839
final layer. And that's not uncommon to

849
00:40:25,599 --> 00:40:30,560
use the identity activation function for

850
00:40:27,839 --> 00:40:32,000
the final layer because the activation

851
00:40:30,560 --> 00:40:34,560
functions you're using for earlier

852
00:40:32,000 --> 00:40:37,520
layers may be constraining the answer

853
00:40:34,560 --> 00:40:40,400
you get.

854
00:40:37,520 --> 00:40:42,640
And you know divided the observation

855
00:40:40,400 --> 00:40:45,440
between the training set validation set

856
00:40:42,640 --> 00:40:47,839
and the test set in the way that we were

857
00:40:45,440 --> 00:40:50,160
discussing earlier. 6,000 for the

858
00:40:47,839 --> 00:40:54,480
training set, 2,000 for the validation

859
00:40:50,160 --> 00:40:59,920
set, 2,000 for the test set.

860
00:40:54,480 --> 00:41:02,720
Uh we have the next slide please, Peter.

861
00:40:59,920 --> 00:41:06,480
So you can see

862
00:41:02,720 --> 00:41:08,160
um what happens the epoch of the

863
00:41:06,480 --> 00:41:11,520
training set is increased which just

864
00:41:08,160 --> 00:41:13,440
basically means you know we continue to

865
00:41:11,520 --> 00:41:15,440
try and match

866
00:41:13,440 --> 00:41:16,960
the training set data as closely as

867
00:41:15,440 --> 00:41:20,800
possible.

868
00:41:16,960 --> 00:41:23,839
It imp improves things

869
00:41:20,800 --> 00:41:26,400
for the validation set up to a certain

870
00:41:23,839 --> 00:41:28,720
point and then

871
00:41:26,400 --> 00:41:34,319
starts to get worse. See what's go going

872
00:41:28,720 --> 00:41:38,319
on better. Um, next slide

873
00:41:34,319 --> 00:41:40,400
we can sort of take a moving average.

874
00:41:38,319 --> 00:41:43,359
And this is so you can see what's going

875
00:41:40,400 --> 00:41:48,480
on here. We uh keep trying to improve

876
00:41:43,359 --> 00:41:50,480
the model but we stop after 2575

877
00:41:48,480 --> 00:41:55,599
epochs. Just think about the epoch as a

878
00:41:50,480 --> 00:41:58,160
trial. Okay. So you can see that

879
00:41:55,599 --> 00:42:00,160
things improve

880
00:41:58,160 --> 00:42:03,440
for

881
00:42:00,160 --> 00:42:05,280
the validation set up to a certain point

882
00:42:03,440 --> 00:42:08,880
and then they then they seem to get

883
00:42:05,280 --> 00:42:10,800
worse. So it's best to stop. So the

884
00:42:08,880 --> 00:42:14,880
model that we actually wound up with was

885
00:42:10,800 --> 00:42:18,440
the model after 25

886
00:42:14,880 --> 00:42:18,440
75 epochs.

887
00:42:19,119 --> 00:42:24,319
Um, next slide, please.

888
00:42:22,319 --> 00:42:27,200
So

889
00:42:24,319 --> 00:42:29,839
we only had 10,000 observations, but we

890
00:42:27,200 --> 00:42:33,680
found that the neural network actually

891
00:42:29,839 --> 00:42:36,400
imitated the black shells mer.

892
00:42:33,680 --> 00:42:39,359
In other words, the random noise that we

893
00:42:36,400 --> 00:42:42,079
added to the black shells mer prices

894
00:42:39,359 --> 00:42:46,160
didn't, you know, it managed to overcome

895
00:42:42,079 --> 00:42:47,760
that random noise pretty well.

896
00:42:46,160 --> 00:42:49,599
Okay,

897
00:42:47,760 --> 00:42:51,359
there more details about that in my

898
00:42:49,599 --> 00:42:54,880
book.

899
00:42:51,359 --> 00:42:56,319
So, the next slide.

900
00:42:54,880 --> 00:42:59,440
Now, you may say, well, that's a pretty

901
00:42:56,319 --> 00:43:02,240
artificial example. We don't need a

902
00:42:59,440 --> 00:43:03,599
model to

903
00:43:02,240 --> 00:43:05,920
you know we don't need to use neural

904
00:43:03,599 --> 00:43:10,240
networks to determine the black shells

905
00:43:05,920 --> 00:43:13,119
model um because we have a formula but

906
00:43:10,240 --> 00:43:17,200
it turns out that actually derivatives

907
00:43:13,119 --> 00:43:19,599
companies are are using neural networks

908
00:43:17,200 --> 00:43:21,200
to value exotic derivatives. There are

909
00:43:19,599 --> 00:43:24,160
some derivatives which can only be

910
00:43:21,200 --> 00:43:26,400
valued using Monte Carlo simulation

911
00:43:24,160 --> 00:43:28,560
and Monte Carlo simulation is slow. It

912
00:43:26,400 --> 00:43:30,240
can take, you know, three or four

913
00:43:28,560 --> 00:43:33,200
minutes to come up with a price. And if

914
00:43:30,240 --> 00:43:34,720
you've got, you know, if you got a

915
00:43:33,200 --> 00:43:37,599
client on the end of the end of the

916
00:43:34,720 --> 00:43:40,560
line, that may not be very good.

917
00:43:37,599 --> 00:43:42,400
So

918
00:43:40,560 --> 00:43:46,000
basically, instead of doing this for the

919
00:43:42,400 --> 00:43:49,280
blacksholes model, you could do it for

920
00:43:46,000 --> 00:43:51,280
some exotic derivatives model. I mean

921
00:43:49,280 --> 00:43:56,520
you run your multiolor simulation many

922
00:43:51,280 --> 00:43:56,520
many times to create data

923
00:43:56,640 --> 00:44:03,440
which relates the price to the inputs

924
00:44:01,520 --> 00:44:06,319
and then you create a neural network to

925
00:44:03,440 --> 00:44:08,800
replicate the prices as closely as

926
00:44:06,319 --> 00:44:11,680
possible and then after you've done that

927
00:44:08,800 --> 00:44:14,079
you have a really fast way I mean

928
00:44:11,680 --> 00:44:16,319
obviously you don't you know if you're

929
00:44:14,079 --> 00:44:19,760
doing this in the way that I'm

930
00:44:16,319 --> 00:44:22,000
describing you wouldn't actually add an

931
00:44:19,760 --> 00:44:26,319
to it. You You just want to create the

932
00:44:22,000 --> 00:44:29,680
prices as accurately as possible. And

933
00:44:26,319 --> 00:44:31,760
once you've got a neural network

934
00:44:29,680 --> 00:44:33,760
that will actually create these exotic

935
00:44:31,760 --> 00:44:36,720
option prices,

936
00:44:33,760 --> 00:44:38,720
you can then very very quickly calculate

937
00:44:36,720 --> 00:44:40,480
any new price you want to because all

938
00:44:38,720 --> 00:44:42,800
you're doing

939
00:44:40,480 --> 00:44:44,720
to work

940
00:44:42,800 --> 00:44:48,800
to calculate a new price is working

941
00:44:44,720 --> 00:44:50,400
forward through the neural network.

942
00:44:48,800 --> 00:44:52,800
So

943
00:44:50,400 --> 00:44:55,119
you know instead of being three or four

944
00:44:52,800 --> 00:44:58,119
minutes it's uh you know almost

945
00:44:55,119 --> 00:44:58,119
instantaneous

946
00:44:59,599 --> 00:45:04,880
because you work as I say you work

947
00:45:01,920 --> 00:45:07,680
forward through the neural network to

948
00:45:04,880 --> 00:45:09,599
obtain the price and this this can also

949
00:45:07,680 --> 00:45:13,200
be useful for scenario analysis because

950
00:45:09,599 --> 00:45:15,839
scenario analysis can be very slow if

951
00:45:13,200 --> 00:45:18,000
you're having to calculate this exotic

952
00:45:15,839 --> 00:45:21,119
option over and over again using Monte

953
00:45:18,000 --> 00:45:26,000
Carlo simulation. But if you can if

954
00:45:21,119 --> 00:45:30,079
you've constructed a neural network

955
00:45:26,000 --> 00:45:32,160
to produce a price then it's you know

956
00:45:30,079 --> 00:45:35,599
much faster

957
00:45:32,160 --> 00:45:38,160
and scenario analysis is is perfectly

958
00:45:35,599 --> 00:45:40,720
feasible.

959
00:45:38,160 --> 00:45:44,599
Um can we have the

960
00:45:40,720 --> 00:45:44,599
the next slide please?

961
00:45:45,440 --> 00:45:50,800
Another thing we've looked at as part of

962
00:45:46,960 --> 00:45:53,359
our research is we've looked at uh the

963
00:45:50,800 --> 00:45:56,400
relationship

964
00:45:53,359 --> 00:46:00,079
between volatilities and um how

965
00:45:56,400 --> 00:46:03,560
volatilities change as the uh return on

966
00:46:00,079 --> 00:46:03,560
the asset changes.

967
00:46:04,400 --> 00:46:12,560
If you know this the standard way of

968
00:46:09,119 --> 00:46:14,480
doing hedging of course is to say well

969
00:46:12,560 --> 00:46:17,520
I mean let's talk about delta hedging

970
00:46:14,480 --> 00:46:22,359
but it applies to other hedging as well.

971
00:46:17,520 --> 00:46:22,359
With delta hedging you say well

972
00:46:22,560 --> 00:46:29,280
how does the price of the option change

973
00:46:27,280 --> 00:46:30,880
when the price of the underlying asset

974
00:46:29,280 --> 00:46:34,000
changes? And we'll assume that the

975
00:46:30,880 --> 00:46:36,160
implied volatility remains the same.

976
00:46:34,000 --> 00:46:40,000
That's the standard assumption. Implied

977
00:46:36,160 --> 00:46:43,680
volatility remains the same. And you you

978
00:46:40,000 --> 00:46:45,760
just calculate delta as the

979
00:46:43,680 --> 00:46:48,480
rate of change

980
00:46:45,760 --> 00:46:52,319
of the option price with respect to the

981
00:46:48,480 --> 00:46:54,560
asset price. Um

982
00:46:52,319 --> 00:46:56,880
but

983
00:46:54,560 --> 00:47:00,160
perhaps there's a tendency for the

984
00:46:56,880 --> 00:47:02,079
volatility to change

985
00:47:00,160 --> 00:47:04,560
as the

986
00:47:02,079 --> 00:47:06,480
um asset price changes. In other words,

987
00:47:04,560 --> 00:47:11,280
if there's a positive return on the

988
00:47:06,480 --> 00:47:14,960
asset, so the asset price goes up,

989
00:47:11,280 --> 00:47:19,200
there's less o overall

990
00:47:14,960 --> 00:47:21,520
the company is less highly levered.

991
00:47:19,200 --> 00:47:24,720
At least in the market value sense, the

992
00:47:21,520 --> 00:47:26,880
company is less highly levered and so

993
00:47:24,720 --> 00:47:29,760
maybe the implied volatility goes down.

994
00:47:26,880 --> 00:47:32,640
Whereas if the return on the asset goes

995
00:47:29,760 --> 00:47:34,800
down,

996
00:47:32,640 --> 00:47:35,920
company becomes more highly levered and

997
00:47:34,800 --> 00:47:39,200
therefore there's a tendency for the

998
00:47:35,920 --> 00:47:41,520
volatility to goes up. So maybe we

999
00:47:39,200 --> 00:47:45,119
should take this into account when

1000
00:47:41,520 --> 00:47:47,920
calculating delta.

1001
00:47:45,119 --> 00:47:49,359
So can I have the the next slide please,

1002
00:47:47,920 --> 00:47:52,359
Peter?

1003
00:47:49,359 --> 00:47:52,359
So

1004
00:47:52,640 --> 00:47:56,119
we uh

1005
00:47:56,400 --> 00:48:01,200
calculated

1006
00:47:58,079 --> 00:48:03,920
um the neural network to investigate

1007
00:48:01,200 --> 00:48:07,119
this and to see what's the relationship

1008
00:48:03,920 --> 00:48:11,040
between the daily asset price return and

1009
00:48:07,119 --> 00:48:13,040
the change in the implied volatility.

1010
00:48:11,040 --> 00:48:16,640
And

1011
00:48:13,040 --> 00:48:19,520
um so input layer had money time to

1012
00:48:16,640 --> 00:48:21,359
maturity daily asset price return and

1013
00:48:19,520 --> 00:48:25,599
the output layer had change in implied

1014
00:48:21,359 --> 00:48:30,599
volatility. Next next slide please.

1015
00:48:25,599 --> 00:48:30,599
Um these were all the

1016
00:48:31,680 --> 00:48:38,400
um all the details. In the interest of

1017
00:48:34,319 --> 00:48:40,880
time let's move on. Next slide please.

1018
00:48:38,400 --> 00:48:43,599
And

1019
00:48:40,880 --> 00:48:46,000
We can see that

1020
00:48:43,599 --> 00:48:50,160
you know

1021
00:48:46,000 --> 00:48:53,839
we actually in this particular case

1022
00:48:50,160 --> 00:48:57,040
found that uh validation set started to

1023
00:48:53,839 --> 00:49:00,559
get worse after 5,826

1024
00:48:57,040 --> 00:49:02,720
epochs. You kind of see that see that a

1025
00:49:00,559 --> 00:49:05,599
little bit in this diagram. So we

1026
00:49:02,720 --> 00:49:07,760
stopped the training after 5,826

1027
00:49:05,599 --> 00:49:10,800
epochs.

1028
00:49:07,760 --> 00:49:10,800
Next slide.

1029
00:49:12,800 --> 00:49:17,520
It wasn't you know at first at first

1030
00:49:16,160 --> 00:49:21,920
we're pretty disappointed with the

1031
00:49:17,520 --> 00:49:25,440
result of this research because the um

1032
00:49:21,920 --> 00:49:28,000
the test set which is final result it

1033
00:49:25,440 --> 00:49:31,520
actually only gave an 11% improvement

1034
00:49:28,000 --> 00:49:33,520
over a simpler analytic model that uh my

1035
00:49:31,520 --> 00:49:35,599
colleague Alan White and I had worked on

1036
00:49:33,520 --> 00:49:40,400
in 2017.

1037
00:49:35,599 --> 00:49:42,880
So you know it didn't give a hugely

1038
00:49:40,400 --> 00:49:46,079
better relationship between the return

1039
00:49:42,880 --> 00:49:47,680
on the asset and the volatility.

1040
00:49:46,079 --> 00:49:49,359
However,

1041
00:49:47,680 --> 00:49:54,240
we played around with it a bit and when

1042
00:49:49,359 --> 00:49:57,280
the VIX index was used as a feature,

1043
00:49:54,240 --> 00:49:59,599
there was a further improvement of 60%.

1044
00:49:57,280 --> 00:50:02,000
And what we found was that the behavior

1045
00:49:59,599 --> 00:50:04,559
of the volatility surface was different

1046
00:50:02,000 --> 00:50:06,880
in high and low volatility environments.

1047
00:50:04,559 --> 00:50:08,720
In other words, if you want to predict

1048
00:50:06,880 --> 00:50:11,520
what's going to happen to the volatility

1049
00:50:08,720 --> 00:50:14,800
surface, so you know how to change the

1050
00:50:11,520 --> 00:50:17,680
implied volatility when you change the

1051
00:50:14,800 --> 00:50:19,119
underlying asset price,

1052
00:50:17,680 --> 00:50:21,040
you really want to know whether you're

1053
00:50:19,119 --> 00:50:23,520
in a high volatility environment or a

1054
00:50:21,040 --> 00:50:25,760
low volatility environment. So that this

1055
00:50:23,520 --> 00:50:28,559
actually gave kind of an interesting

1056
00:50:25,760 --> 00:50:30,800
result

1057
00:50:28,559 --> 00:50:34,680
which you'd be unlikely to get just

1058
00:50:30,800 --> 00:50:34,680
playing around with the data.

1059
00:50:35,599 --> 00:50:43,359
Uh, next slide, please. Okay, so um,

1060
00:50:40,720 --> 00:50:45,520
we've got 20 minutes left, so let's use

1061
00:50:43,359 --> 00:50:49,119
the last 20 minutes to talk about

1062
00:50:45,520 --> 00:50:51,520
reinforcement learning, which has been a

1063
00:50:49,119 --> 00:50:54,319
subject of quite a lot of my work over

1064
00:50:51,520 --> 00:50:56,880
the last little while. Uh, next slide,

1065
00:50:54,319 --> 00:50:59,440
please. So, what is reinforcement

1066
00:50:56,880 --> 00:51:01,359
learning? is concerned with finding a

1067
00:50:59,440 --> 00:51:05,440
strategy for taking a series of

1068
00:51:01,359 --> 00:51:07,839
decisions rather than just one.

1069
00:51:05,440 --> 00:51:09,680
So you're you're in some sort of an

1070
00:51:07,839 --> 00:51:15,319
environment is changing in an

1071
00:51:09,680 --> 00:51:15,319
unpredictable way and you have to decide

1072
00:51:15,599 --> 00:51:19,359
well you've had to decide what decision

1073
00:51:17,040 --> 00:51:20,319
you're going to take today. But you know

1074
00:51:19,359 --> 00:51:22,960
you're going to have to take another

1075
00:51:20,319 --> 00:51:24,400
decision tomorrow and another the next

1076
00:51:22,960 --> 00:51:29,440
day. you know, you're going to be taking

1077
00:51:24,400 --> 00:51:31,760
a series of decisions, not a single one.

1078
00:51:29,440 --> 00:51:33,280
And uh

1079
00:51:31,760 --> 00:51:35,920
this has actually been a hugely

1080
00:51:33,280 --> 00:51:38,640
successful. It's a it's kind of like a

1081
00:51:35,920 --> 00:51:40,880
trial and error kind of approach to

1082
00:51:38,640 --> 00:51:43,599
this, but it's been hugely successful.

1083
00:51:40,880 --> 00:51:46,240
I'm sure many of you have heard of um

1084
00:51:43,599 --> 00:51:48,800
the success

1085
00:51:46,240 --> 00:51:52,079
that software has had in playing games

1086
00:51:48,800 --> 00:51:54,640
like chess and go

1087
00:51:52,079 --> 00:51:57,520
that actually we've developed software

1088
00:51:54,640 --> 00:52:00,480
that can be the best human players of

1089
00:51:57,520 --> 00:52:03,280
chess and go. I used to play a lot of

1090
00:52:00,480 --> 00:52:05,839
chess when I was younger and uh in a way

1091
00:52:03,280 --> 00:52:08,480
it's disappointing but

1092
00:52:05,839 --> 00:52:12,079
you know computers can now do this so

1093
00:52:08,480 --> 00:52:12,079
much better than human beings.

1094
00:52:12,319 --> 00:52:17,200
Uh next slide please. So the general

1095
00:52:15,280 --> 00:52:19,359
model is

1096
00:52:17,200 --> 00:52:21,680
you have actions,

1097
00:52:19,359 --> 00:52:25,280
states and rewards.

1098
00:52:21,680 --> 00:52:26,880
So you take an action

1099
00:52:25,280 --> 00:52:28,559
um

1100
00:52:26,880 --> 00:52:32,000
you start with a certain state which I

1101
00:52:28,559 --> 00:52:33,520
call S0. You take a certain action time

1102
00:52:32,000 --> 00:52:38,160
zero

1103
00:52:33,520 --> 00:52:40,240
and that moves you to a new state and

1104
00:52:38,160 --> 00:52:42,079
maybe you get a reward. Then you take

1105
00:52:40,240 --> 00:52:45,839
another action

1106
00:52:42,079 --> 00:52:50,160
which will move you to yet another state

1107
00:52:45,839 --> 00:52:53,280
perhaps give you a reward and so on.

1108
00:52:50,160 --> 00:52:56,240
So you got to look ahead and think of

1109
00:52:53,280 --> 00:52:58,960
all the actions you're going to have to

1110
00:52:56,240 --> 00:53:01,440
take not just at time zero but at future

1111
00:52:58,960 --> 00:53:03,920
times

1112
00:53:01,440 --> 00:53:06,960
and the states at future times are

1113
00:53:03,920 --> 00:53:10,839
somewhat uncertain.

1114
00:53:06,960 --> 00:53:10,839
Uh next slide please.

1115
00:53:11,520 --> 00:53:16,720
So one of the fundamental I mean this is

1116
00:53:13,839 --> 00:53:19,359
really a trial and error sort of process

1117
00:53:16,720 --> 00:53:21,839
but um

1118
00:53:19,359 --> 00:53:24,079
if you and obviously you you don't you

1119
00:53:21,839 --> 00:53:26,160
don't know anything when you start. So

1120
00:53:24,079 --> 00:53:30,000
you're going to sort of be choosing some

1121
00:53:26,160 --> 00:53:32,880
sort of a random strategy and and then

1122
00:53:30,000 --> 00:53:35,119
slowly over time you learn that you know

1123
00:53:32,880 --> 00:53:37,040
doing this in this situation works out

1124
00:53:35,119 --> 00:53:40,880
well whereas doing something else in

1125
00:53:37,040 --> 00:53:42,800
that situation works out badly.

1126
00:53:40,880 --> 00:53:45,760
And this is where exploration versus

1127
00:53:42,800 --> 00:53:48,720
exploitation comes in. At any given

1128
00:53:45,760 --> 00:53:53,480
time, there's a certain probability that

1129
00:53:48,720 --> 00:53:53,480
you'll randomly choose a decision.

1130
00:53:54,640 --> 00:53:58,400
Okay? And that's referred to as

1131
00:53:56,400 --> 00:54:00,400
exploration. And there's a certain

1132
00:53:58,400 --> 00:54:02,000
probability that you'll assume you'll

1133
00:54:00,400 --> 00:54:05,440
choose the decisions that's actually

1134
00:54:02,000 --> 00:54:08,440
worked out best so far, which is called

1135
00:54:05,440 --> 00:54:08,440
exploitation.

1136
00:54:08,720 --> 00:54:12,960
So, initially the probability of

1137
00:54:11,359 --> 00:54:14,960
exploration is one because you don't

1138
00:54:12,960 --> 00:54:17,280
know it. So you're going to randomly

1139
00:54:14,960 --> 00:54:22,559
choose a decision

1140
00:54:17,280 --> 00:54:25,680
and then over time you'll slowly reduce

1141
00:54:22,559 --> 00:54:27,839
the probability of exploration

1142
00:54:25,680 --> 00:54:30,079
and increase the probability of

1143
00:54:27,839 --> 00:54:32,160
exploitation. And after a sufficient

1144
00:54:30,079 --> 00:54:33,599
number of trials,

1145
00:54:32,160 --> 00:54:35,119
you know, you'll probably decide that

1146
00:54:33,599 --> 00:54:36,880
actually

1147
00:54:35,119 --> 00:54:38,640
the probability of exploitation should

1148
00:54:36,880 --> 00:54:39,920
be one.

1149
00:54:38,640 --> 00:54:42,920
In other words, you've pretty much

1150
00:54:39,920 --> 00:54:42,920
decided

1151
00:54:43,520 --> 00:54:50,599
that you know you know what the best

1152
00:54:45,280 --> 00:54:50,599
decision is in all different situations.

1153
00:54:50,960 --> 00:54:55,760
Uh next slide please.

1154
00:54:54,400 --> 00:54:58,559
So I don't know whether any of you have

1155
00:54:55,760 --> 00:55:02,000
come across this game Nim

1156
00:54:58,559 --> 00:55:05,920
okay but uh it's a it's a very simple

1157
00:55:02,000 --> 00:55:07,680
game but uh it's a good game for

1158
00:55:05,920 --> 00:55:11,440
illustrating

1159
00:55:07,680 --> 00:55:14,800
uh how reinforcement learning works. So

1160
00:55:11,440 --> 00:55:18,079
suppose we got two two players

1161
00:55:14,800 --> 00:55:20,960
and you know so I'm playing against you

1162
00:55:18,079 --> 00:55:23,760
and there's a pile of matches on the

1163
00:55:20,960 --> 00:55:26,880
table

1164
00:55:23,760 --> 00:55:30,559
and we take turns.

1165
00:55:26,880 --> 00:55:33,800
Each each of us can pick up one, two or

1166
00:55:30,559 --> 00:55:33,800
three matches

1167
00:55:34,640 --> 00:55:40,240
and you lose the game if you have to

1168
00:55:36,240 --> 00:55:41,760
pick up the last match. Okay. So part of

1169
00:55:40,240 --> 00:55:43,680
matches

1170
00:55:41,760 --> 00:55:45,599
take turns picking up one, two, or three

1171
00:55:43,680 --> 00:55:49,920
matches and the person who has to pick

1172
00:55:45,599 --> 00:55:51,760
up the last match loses.

1173
00:55:49,920 --> 00:55:54,240
Well,

1174
00:55:51,760 --> 00:55:56,319
if you are being good mathematicians,

1175
00:55:54,240 --> 00:56:00,760
you'd work out how to play this game

1176
00:55:56,319 --> 00:56:00,760
very quickly. Um,

1177
00:56:01,359 --> 00:56:07,200
basically, I mean, let's

1178
00:56:04,319 --> 00:56:10,880
suppose there are only five matches

1179
00:56:07,200 --> 00:56:12,319
on the table and it's your goal. There

1180
00:56:10,880 --> 00:56:14,799
are five matches on the table and it's

1181
00:56:12,319 --> 00:56:17,520
your go, I'm going to win because if you

1182
00:56:14,799 --> 00:56:19,119
pick up one match, I'll pick up three

1183
00:56:17,520 --> 00:56:20,640
matches and you have to pick up the last

1184
00:56:19,119 --> 00:56:24,240
match.

1185
00:56:20,640 --> 00:56:26,559
If you know if you pick up two matches,

1186
00:56:24,240 --> 00:56:29,440
I'll pick up two matches and you have to

1187
00:56:26,559 --> 00:56:31,359
pick up the last match and so on.

1188
00:56:29,440 --> 00:56:34,160
So if I can leave you with five matches

1189
00:56:31,359 --> 00:56:36,400
on the table, I win.

1190
00:56:34,160 --> 00:56:38,000
Then we can go one stage beyond that.

1191
00:56:36,400 --> 00:56:40,000
Let's suppose I can leave you with nine

1192
00:56:38,000 --> 00:56:42,799
matches

1193
00:56:40,000 --> 00:56:44,240
on the table.

1194
00:56:42,799 --> 00:56:47,680
then I can make sure I leave you with

1195
00:56:44,240 --> 00:56:49,680
five matches next time because you know

1196
00:56:47,680 --> 00:56:52,079
again there are nine matches on the

1197
00:56:49,680 --> 00:56:56,599
table.

1198
00:56:52,079 --> 00:56:56,599
You pick up one, I pick up three,

1199
00:56:56,720 --> 00:57:00,559
you're then left with five matches on

1200
00:56:58,240 --> 00:57:02,559
the table.

1201
00:57:00,559 --> 00:57:04,480
Okay? You pick up two, I pick up two,

1202
00:57:02,559 --> 00:57:07,359
you're left with five matches. And very

1203
00:57:04,480 --> 00:57:10,480
quickly you decide that

1204
00:57:07,359 --> 00:57:13,680
actually the way to win this game

1205
00:57:10,480 --> 00:57:19,760
is to always leave your opponent if you

1206
00:57:13,680 --> 00:57:22,799
can with four n + one matches. Okay.

1207
00:57:19,760 --> 00:57:27,680
So I mean you know

1208
00:57:22,799 --> 00:57:31,040
suppose uh n is five 4n + one is 21. So,

1209
00:57:27,680 --> 00:57:33,119
if I can leave you with 21 matches,

1210
00:57:31,040 --> 00:57:35,599
I will win

1211
00:57:33,119 --> 00:57:39,119
because I'll leave you with 21 matches,

1212
00:57:35,599 --> 00:57:42,319
then whatever you do next time round,

1213
00:57:39,119 --> 00:57:44,559
I'll leave you with 17 matches

1214
00:57:42,319 --> 00:57:49,760
and then the next time round I'll leave

1215
00:57:44,559 --> 00:57:51,280
you with 13 matches and so on. So,

1216
00:57:49,760 --> 00:57:53,920
okay.

1217
00:57:51,280 --> 00:57:57,280
However, let's see how well the machine

1218
00:57:53,920 --> 00:58:01,200
does at u

1219
00:57:57,280 --> 00:58:02,640
working out this best strategy. And I'm

1220
00:58:01,200 --> 00:58:04,960
going to assume there's only eight

1221
00:58:02,640 --> 00:58:07,599
matches initially on the table, although

1222
00:58:04,960 --> 00:58:11,119
you'll find on my on my website you can

1223
00:58:07,599 --> 00:58:13,200
find some uh software for

1224
00:58:11,119 --> 00:58:17,520
seeing how well the machine does in a

1225
00:58:13,200 --> 00:58:19,839
lot of other situations. But um

1226
00:58:17,520 --> 00:58:21,760
we'll assume that there's the reward is

1227
00:58:19,839 --> 00:58:24,319
plus one from winning and minus one from

1228
00:58:21,760 --> 00:58:26,799
losing and the your opponent behaves

1229
00:58:24,319 --> 00:58:29,280
randomly.

1230
00:58:26,799 --> 00:58:31,119
I can u

1231
00:58:29,280 --> 00:58:35,200
change things so the opponent learns as

1232
00:58:31,119 --> 00:58:38,640
well if I want to. But okay.

1233
00:58:35,200 --> 00:58:40,640
So basically we start with this state

1234
00:58:38,640 --> 00:58:43,440
action table.

1235
00:58:40,640 --> 00:58:46,319
Okay. State is the number of matches to

1236
00:58:43,440 --> 00:58:49,200
little left one to eight and the action

1237
00:58:46,319 --> 00:58:52,200
is the number picked up. Next slide

1238
00:58:49,200 --> 00:58:52,200
please.

1239
00:58:53,520 --> 00:58:58,720
So basically as I say it's trial and

1240
00:58:57,200 --> 00:59:01,040
error.

1241
00:58:58,720 --> 00:59:03,760
So let's suppose I mean you don't know

1242
00:59:01,040 --> 00:59:05,839
anything. So randomly you choose to pick

1243
00:59:03,760 --> 00:59:08,240
up one match. Randomly your opponent

1244
00:59:05,839 --> 00:59:10,400
picks up three matches. Randomly you

1245
00:59:08,240 --> 00:59:12,480
choose to pick up one match. Randomly

1246
00:59:10,400 --> 00:59:14,240
your opponent picks up three matches,

1247
00:59:12,480 --> 00:59:18,000
you win.

1248
00:59:14,240 --> 00:59:20,640
Okay, so

1249
00:59:18,000 --> 00:59:23,040
we can update Q81.

1250
00:59:20,640 --> 00:59:25,200
8 being the number of matches on the

1251
00:59:23,040 --> 00:59:27,839
table and the one being the number

1252
00:59:25,200 --> 00:59:29,280
picked up. So the first argument is the

1253
00:59:27,839 --> 00:59:31,440
number of matches on the table. The

1254
00:59:29,280 --> 00:59:33,920
second is the number picked up. So we

1255
00:59:31,440 --> 00:59:36,960
know from that that

1256
00:59:33,920 --> 00:59:38,960
we have a trial where

1257
00:59:36,960 --> 00:59:42,240
we win

1258
00:59:38,960 --> 00:59:45,119
Q81 leads to a win and Q41 leads to a

1259
00:59:42,240 --> 00:59:48,319
win.

1260
00:59:45,119 --> 00:59:52,280
So we update

1261
00:59:48,319 --> 00:59:52,280
Q81 and Q41.

1262
00:59:53,119 --> 00:59:56,720
Okay.

1263
00:59:54,720 --> 00:59:58,799
And we have to have a par an updating

1264
00:59:56,720 --> 01:00:01,520
parameter. the formula formula for

1265
00:59:58,799 --> 01:00:04,480
updating is

1266
01:00:01,520 --> 01:00:07,200
is is there and we say well okay we

1267
01:00:04,480 --> 01:00:11,200
don't want to update too much

1268
01:00:07,200 --> 01:00:14,400
we'll give it 5% weight

1269
01:00:11,200 --> 01:00:21,359
so we have the old Q

1270
01:00:14,400 --> 01:00:23,119
SA plus 5% of the gain minus the old QSA

1271
01:00:21,359 --> 01:00:26,720
and

1272
01:00:23,119 --> 01:00:26,720
can we have the next slide

1273
01:00:29,119 --> 01:00:36,000
On each trial, we observe certain

1274
01:00:32,240 --> 01:00:39,200
states, take action in those states, and

1275
01:00:36,000 --> 01:00:42,960
the gain used in updating the cues can

1276
01:00:39,200 --> 01:00:46,160
be either the final reward

1277
01:00:42,960 --> 01:00:48,160
referred to as the Monte Carlo method,

1278
01:00:46,160 --> 01:00:50,799
or it can be the value at the next

1279
01:00:48,160 --> 01:00:55,839
state, assuming the best decision is

1280
01:00:50,799 --> 01:00:55,839
taken. So, you know, if I pick up

1281
01:00:56,079 --> 01:01:02,480
You know if I pick up one match and you

1282
01:00:59,200 --> 01:01:04,880
pick up one match then the value and

1283
01:01:02,480 --> 01:01:07,680
there are six matches on the table and

1284
01:01:04,880 --> 01:01:09,599
in terms of updating instead of waiting

1285
01:01:07,680 --> 01:01:11,760
to see whether I win or lose I could

1286
01:01:09,599 --> 01:01:13,920
just say how good is it for me if there

1287
01:01:11,760 --> 01:01:16,640
are just six matches left on the table

1288
01:01:13,920 --> 01:01:18,880
and that would be you know the way we

1289
01:01:16,640 --> 01:01:21,119
would do the updating. So we start with

1290
01:01:18,880 --> 01:01:23,760
the Q's all zero and then we update them

1291
01:01:21,119 --> 01:01:28,280
in the way that I was describing.

1292
01:01:23,760 --> 01:01:28,280
Um, next slide please.

1293
01:01:29,920 --> 01:01:33,760
And uh, with the Monte Carlo method,

1294
01:01:32,400 --> 01:01:36,799
which is where we wait and see whether

1295
01:01:33,760 --> 01:01:38,720
we win or not, you can see I mean we all

1296
01:01:36,799 --> 01:01:40,559
know that

1297
01:01:38,720 --> 01:01:43,680
with eight matches on the table, if it's

1298
01:01:40,559 --> 01:01:45,680
our go, we pick up three and leave our

1299
01:01:43,680 --> 01:01:48,160
opponent with five matches on the table.

1300
01:01:45,680 --> 01:01:50,240
That's the best decision. After a

1301
01:01:48,160 --> 01:01:52,000
thousand trials,

1302
01:01:50,240 --> 01:01:53,760
it hasn't really found the best

1303
01:01:52,000 --> 01:01:56,400
decision. It still looks as though

1304
01:01:53,760 --> 01:02:00,400
picking up one match is marginally

1305
01:01:56,400 --> 01:02:03,520
better. The Q value is 0.562

1306
01:02:00,400 --> 01:02:05,680
as opposed to 522.

1307
01:02:03,520 --> 01:02:07,599
After 5,000 trials, it's definitely

1308
01:02:05,680 --> 01:02:10,559
beginning to look that it's best to pick

1309
01:02:07,599 --> 01:02:12,799
up three matches and after 10,000 trials

1310
01:02:10,559 --> 01:02:14,480
for sure.

1311
01:02:12,799 --> 01:02:17,119
So, you see what's happening here. We're

1312
01:02:14,480 --> 01:02:20,880
just doing more and more trials.

1313
01:02:17,119 --> 01:02:24,000
And uh what

1314
01:02:20,880 --> 01:02:26,640
what we did here was we had this epsilon

1315
01:02:24,000 --> 01:02:30,480
parameter which is determines you know

1316
01:02:26,640 --> 01:02:32,400
whether you behave randomly or you use

1317
01:02:30,480 --> 01:02:34,000
the best

1318
01:02:32,400 --> 01:02:37,200
decision that seems to have worked out

1319
01:02:34,000 --> 01:02:42,280
so far. We have epsilon starting at one

1320
01:02:37,200 --> 01:02:42,280
and having this decay factor of.9995.

1321
01:02:43,200 --> 01:02:47,520
So it it it does appear that uh

1322
01:02:45,920 --> 01:02:52,000
reinforcement learning finds the best

1323
01:02:47,520 --> 01:02:54,000
decision. Uh next slide please.

1324
01:02:52,000 --> 01:02:55,599
And if in fact it finds it even more

1325
01:02:54,000 --> 01:03:01,119
quickly with temporal difference

1326
01:02:55,599 --> 01:03:03,040
learning. This is where you look to see

1327
01:03:01,119 --> 01:03:05,359
you know how much is it how much does it

1328
01:03:03,040 --> 01:03:07,280
turn out to be worth to be in the next

1329
01:03:05,359 --> 01:03:09,359
situation that you're in after you've

1330
01:03:07,280 --> 01:03:12,720
taken the first decision. And it turns

1331
01:03:09,359 --> 01:03:14,319
out that as often is the case, temporal

1332
01:03:12,720 --> 01:03:19,280
difference learning works better than

1333
01:03:14,319 --> 01:03:21,440
the raw Monte Carlo simulation.

1334
01:03:19,280 --> 01:03:25,839
But it's definitely,

1335
01:03:21,440 --> 01:03:30,000
you know, worked out that uh you know,

1336
01:03:25,839 --> 01:03:31,520
it's best it's best to pick up uh three

1337
01:03:30,000 --> 01:03:33,359
matches.

1338
01:03:31,520 --> 01:03:35,359
It's not and it doesn't look so bad to

1339
01:03:33,359 --> 01:03:36,720
pick up two matches or one match because

1340
01:03:35,359 --> 01:03:39,119
remember your opponent's behaving

1341
01:03:36,720 --> 01:03:41,280
randomly.

1342
01:03:39,119 --> 01:03:43,520
So you and when you've learned a lot,

1343
01:03:41,280 --> 01:03:47,599
you can behave much better than your

1344
01:03:43,520 --> 01:03:49,680
opponent. I've done I've done other

1345
01:03:47,599 --> 01:03:52,880
tests where the opponent is learning as

1346
01:03:49,680 --> 01:03:54,799
well, in which case you

1347
01:03:52,880 --> 01:03:57,039
you know picking up two matches or one

1348
01:03:54,799 --> 01:04:01,280
match is going to allow your opponent to

1349
01:03:57,039 --> 01:04:03,599
win. Um and so you have you know

1350
01:04:01,280 --> 01:04:06,480
negative numbers opposite the two and

1351
01:04:03,599 --> 01:04:09,440
the one.

1352
01:04:06,480 --> 01:04:12,799
Uh next

1353
01:04:09,440 --> 01:04:15,799
slide please.

1354
01:04:12,799 --> 01:04:15,799
So

1355
01:04:16,000 --> 01:04:22,799
so this is you know this this NIM

1356
01:04:19,520 --> 01:04:25,119
game illustrates

1357
01:04:22,799 --> 01:04:28,480
admittedly in a fairly simple situation

1358
01:04:25,119 --> 01:04:31,359
how reinforcement learning works. Um,

1359
01:04:28,480 --> 01:04:33,119
very often you've got a much more

1360
01:04:31,359 --> 01:04:34,960
complex

1361
01:04:33,119 --> 01:04:38,160
um,

1362
01:04:34,960 --> 01:04:42,920
state action table to be sort of filled

1363
01:04:38,160 --> 01:04:42,920
in. And uh,

1364
01:04:43,680 --> 01:04:49,359
you have to sort of combine

1365
01:04:47,280 --> 01:04:51,039
uh, reinforcement learning with

1366
01:04:49,359 --> 01:04:53,760
artificial neural networks because you

1367
01:04:51,039 --> 01:04:58,480
got this state action table. You're able

1368
01:04:53,760 --> 01:05:00,160
to fill in some of the

1369
01:04:58,480 --> 01:05:03,760
some of the numbers in the state action

1370
01:05:00,160 --> 01:05:05,599
table but not all of them. But you you

1371
01:05:03,760 --> 01:05:08,480
know there's some nonlinear general

1372
01:05:05,599 --> 01:05:10,799
nonlinear function which is describing

1373
01:05:08,480 --> 01:05:12,960
the whole table and you have to do the

1374
01:05:10,799 --> 01:05:15,440
best you can with the numbers that you

1375
01:05:12,960 --> 01:05:19,400
do have in the table.

1376
01:05:15,440 --> 01:05:19,400
Uh next slide please.

1377
01:05:19,599 --> 01:05:27,599
Okay so five minutes left. Um what I've

1378
01:05:23,920 --> 01:05:32,000
been spending a lot of my time in the

1379
01:05:27,599 --> 01:05:34,319
last uh little while on is saying you

1380
01:05:32,000 --> 01:05:38,200
know can we use reinforcement learning

1381
01:05:34,319 --> 01:05:38,200
for hedging derivatives.

1382
01:05:38,799 --> 01:05:42,640
The traditional approach to hedging is

1383
01:05:40,640 --> 01:05:45,200
of course Greek letters where you know

1384
01:05:42,640 --> 01:05:48,720
you calculate delta, gamma, vega and so

1385
01:05:45,200 --> 01:05:50,240
on and you're really you're really

1386
01:05:48,720 --> 01:05:54,599
looking a very short period of time

1387
01:05:50,240 --> 01:05:54,599
ahead because you're saying

1388
01:05:55,119 --> 01:06:02,720
what's the uh partial derivative of the

1389
01:05:59,280 --> 01:06:05,280
value of my portfolio with respect to

1390
01:06:02,720 --> 01:06:07,359
whatever it is the underlying asset

1391
01:06:05,280 --> 01:06:09,359
price

1392
01:06:07,359 --> 01:06:10,960
volatility or whatever.

1393
01:06:09,359 --> 01:06:13,520
um

1394
01:06:10,960 --> 01:06:16,000
reinforcement learning sort of has has a

1395
01:06:13,520 --> 01:06:18,880
different approach. It says let's take

1396
01:06:16,000 --> 01:06:24,520
let's look several periods ahead and try

1397
01:06:18,880 --> 01:06:24,520
and take a decision which will work well

1398
01:06:25,920 --> 01:06:31,280
over our over our time horizon. So what

1399
01:06:29,039 --> 01:06:35,559
have we found?

1400
01:06:31,280 --> 01:06:35,559
Um next slide.

1401
01:06:36,880 --> 01:06:42,079
This is my last slide. Um, so what we

1402
01:06:39,280 --> 01:06:45,039
found is that, you know, we've found

1403
01:06:42,079 --> 01:06:46,960
that, you know, in some situations using

1404
01:06:45,039 --> 01:06:48,720
reinforcement learning for hedging, in

1405
01:06:46,960 --> 01:06:50,960
other words, looking several periods

1406
01:06:48,720 --> 01:06:54,559
ahead and seeing which strategies will

1407
01:06:50,960 --> 01:06:58,480
work out best is um

1408
01:06:54,559 --> 01:07:01,839
can be useful for vanilla options.

1409
01:06:58,480 --> 01:07:04,480
It um

1410
01:07:01,839 --> 01:07:09,119
it does about the overall it does about

1411
01:07:04,480 --> 01:07:13,119
the same as the Greek letter hedging

1412
01:07:09,119 --> 01:07:14,799
but it does save transaction costs

1413
01:07:13,119 --> 01:07:16,319
and actually saves significant amounts

1414
01:07:14,799 --> 01:07:17,839
of transaction costs because you can

1415
01:07:16,319 --> 01:07:20,640
think about it this way you know you're

1416
01:07:17,839 --> 01:07:23,200
hedging a vanilla option

1417
01:07:20,640 --> 01:07:25,119
I mean let's just talk in terms of delta

1418
01:07:23,200 --> 01:07:28,559
I mean you know let's suppose delta is

1419
01:07:25,119 --> 01:07:34,000
0.5 right now

1420
01:07:28,559 --> 01:07:37,200
and delta goes up to 7

1421
01:07:34,000 --> 01:07:39,440
but maybe there's a 50% chance that at

1422
01:07:37,200 --> 01:07:43,440
your next hedging date delta will go

1423
01:07:39,440 --> 01:07:46,000
back down to 0.5. So the question is

1424
01:07:43,440 --> 01:07:50,079
should you

1425
01:07:46,000 --> 01:07:52,480
should you uh change

1426
01:07:50,079 --> 01:07:55,760
you know should you do your hedging

1427
01:07:52,480 --> 01:07:57,680
to reflect delta going from 0.5 to 7

1428
01:07:55,760 --> 01:08:00,000
even though you know there's a 50%

1429
01:07:57,680 --> 01:08:03,359
chance it'll go back down to 0.5 or is

1430
01:08:00,000 --> 01:08:06,000
it better to wait

1431
01:08:03,359 --> 01:08:09,240
and see what happens over perhaps two

1432
01:08:06,000 --> 01:08:09,240
time periods

1433
01:08:09,520 --> 01:08:13,839
and the answer is if there's a lot of

1434
01:08:11,119 --> 01:08:16,239
transaction costs

1435
01:08:13,839 --> 01:08:19,440
it's better to wait. So we find

1436
01:08:16,239 --> 01:08:22,960
reinforcement learning can save quite a

1437
01:08:19,440 --> 01:08:24,400
lot of transaction costs even though we

1438
01:08:22,960 --> 01:08:27,040
when you don't take account of

1439
01:08:24,400 --> 01:08:30,239
transaction costs there's not a huge

1440
01:08:27,040 --> 01:08:33,520
saving for for options typically

1441
01:08:30,239 --> 01:08:35,839
okay and of course transaction costs are

1442
01:08:33,520 --> 01:08:39,359
really important when it comes to vega

1443
01:08:35,839 --> 01:08:42,000
and gamma hedging as well

1444
01:08:39,359 --> 01:08:45,679
as some exotic options such as barrier

1445
01:08:42,000 --> 01:08:48,159
options we find reinforcement learning

1446
01:08:45,679 --> 01:08:52,080
produces superior results even when

1447
01:08:48,159 --> 01:08:54,560
there are no transaction costs.

1448
01:08:52,080 --> 01:08:56,319
And one of the nice things about using

1449
01:08:54,560 --> 01:08:59,520
reinforcement learning is that you can

1450
01:08:56,319 --> 01:09:02,080
choose your objective function.

1451
01:08:59,520 --> 01:09:07,279
Okay? Whereas of course you can't do

1452
01:09:02,080 --> 01:09:09,440
that with Greek letter hedging. So

1453
01:09:07,279 --> 01:09:12,159
um

1454
01:09:09,440 --> 01:09:14,319
you know we've experimented with you

1455
01:09:12,159 --> 01:09:17,759
know looking at the tail of the

1456
01:09:14,319 --> 01:09:21,440
distribution and var 95 is a shortand

1457
01:09:17,759 --> 01:09:24,239
for you want the 95th percentile point

1458
01:09:21,440 --> 01:09:27,120
of the loss distribution

1459
01:09:24,239 --> 01:09:30,640
to be as high as possible

1460
01:09:27,120 --> 01:09:33,359
or C bar 95 is where you want the

1461
01:09:30,640 --> 01:09:38,120
conditional value of risk which is the

1462
01:09:33,359 --> 01:09:38,120
average beyond on the 95th percentile

1463
01:09:38,319 --> 01:09:42,799
of the loss distribution to be as low as

1464
01:09:41,279 --> 01:09:44,880
possible.

1465
01:09:42,799 --> 01:09:48,640
So, you know, you can have an objective

1466
01:09:44,880 --> 01:09:51,759
function that focuses

1467
01:09:48,640 --> 01:09:54,800
on the um

1468
01:09:51,759 --> 01:09:56,480
things you're most concerned about,

1469
01:09:54,800 --> 01:09:59,199
which is the perhaps the tail of the

1470
01:09:56,480 --> 01:10:01,840
distribution. We find it's robust, gives

1471
01:09:59,199 --> 01:10:04,800
good results during stress periods. And

1472
01:10:01,840 --> 01:10:07,360
it's interesting JP Morgan

1473
01:10:04,800 --> 01:10:09,199
is you know our main comp competitor in

1474
01:10:07,360 --> 01:10:12,640
terms of doing this research is JP

1475
01:10:09,199 --> 01:10:14,960
Morgan. JP Morgan's been doing a lot of

1476
01:10:12,640 --> 01:10:17,360
um work looking at reinforcement

1477
01:10:14,960 --> 01:10:19,679
learning for hedging.

1478
01:10:17,360 --> 01:10:22,480
Of course the disadvantage

1479
01:10:19,679 --> 01:10:25,840
of reinforcement learning is that it's

1480
01:10:22,480 --> 01:10:28,960
much more computationally demanding

1481
01:10:25,840 --> 01:10:31,440
than traditional approaches. you

1482
01:10:28,960 --> 01:10:34,239
you've got to run these trial and error

1483
01:10:31,440 --> 01:10:36,159
programs which you know can take a few

1484
01:10:34,239 --> 01:10:38,800
minutes

1485
01:10:36,159 --> 01:10:40,960
but they're getting faster.

1486
01:10:38,800 --> 01:10:43,040
So whereas it it takes no time at all to

1487
01:10:40,960 --> 01:10:45,520
calculate a brief letter. It it will

1488
01:10:43,040 --> 01:10:47,600
take you a little while to calculate the

1489
01:10:45,520 --> 01:10:49,120
best strategy

1490
01:10:47,600 --> 01:10:50,880
for doing reinforcement learning

1491
01:10:49,120 --> 01:10:53,280
hedging.

1492
01:10:50,880 --> 01:10:56,080
But I think come back to my earlier

1493
01:10:53,280 --> 01:11:01,159
point that computers are now

1494
01:10:56,080 --> 01:11:01,159
sufficiently fast that um

1495
01:11:01,520 --> 01:11:06,400
you know that that it's becoming a

1496
01:11:03,280 --> 01:11:10,719
feasible tool.

1497
01:11:06,400 --> 01:11:13,679
So uh brings me to my last slide.

1498
01:11:10,719 --> 01:11:15,840
Um we're one minute over the four

1499
01:11:13,679 --> 01:11:19,040
o'clock mark, but if anybody wants to

1500
01:11:15,840 --> 01:11:21,199
ask any questions, I'd be happy to to

1501
01:11:19,040 --> 01:11:24,800
answer them. Well, I have a question for

1502
01:11:21,199 --> 01:11:27,360
you uh John. Um about the choice of

1503
01:11:24,800 --> 01:11:30,960
activation functions

1504
01:11:27,360 --> 01:11:33,520
um you know have you found as you did in

1505
01:11:30,960 --> 01:11:36,719
this case that I guess it was was it the

1506
01:11:33,520 --> 01:11:39,360
sigmoid function was uh was applied in

1507
01:11:36,719 --> 01:11:42,800
your example

1508
01:11:39,360 --> 01:11:45,840
or was it the reu?

1509
01:11:42,800 --> 01:11:49,920
Yeah, we've we've had a lot of success

1510
01:11:45,840 --> 01:11:53,679
with the sigmoid function. Um that may

1511
01:11:49,920 --> 01:11:55,520
be just chance chance events or maybe

1512
01:11:53,679 --> 01:11:59,840
there's something

1513
01:11:55,520 --> 01:12:00,960
um special about the sigmoid function,

1514
01:11:59,840 --> 01:12:03,520
you know. I mean, of course, there's

1515
01:12:00,960 --> 01:12:05,199
nothing to stop you trying

1516
01:12:03,520 --> 01:12:07,440
several different activation functions

1517
01:12:05,199 --> 01:12:10,960
and seeing which works out best in a

1518
01:12:07,440 --> 01:12:15,600
particular situation. Um

1519
01:12:10,960 --> 01:12:18,560
and we did that in uh

1520
01:12:15,600 --> 01:12:20,960
you know in our implied volatility

1521
01:12:18,560 --> 01:12:23,120
research and we concluded that the

1522
01:12:20,960 --> 01:12:25,440
sigmoid function works worked out best

1523
01:12:23,120 --> 01:12:29,199
as a matter of fact but we we tried

1524
01:12:25,440 --> 01:12:32,199
several different activation functions.

1525
01:12:29,199 --> 01:12:32,199
So,

1526
01:12:32,560 --> 01:12:37,520
but

1527
01:12:35,280 --> 01:12:41,040
>> I think I if I remember correctly, all

1528
01:12:37,520 --> 01:12:42,560
the activation functions we tried

1529
01:12:41,040 --> 01:12:45,040
were

1530
01:12:42,560 --> 01:12:48,920
pretty close to each other in terms of

1531
01:12:45,040 --> 01:12:48,920
how well they worked out.

1532
01:12:49,840 --> 01:12:54,960
>> So, I think choosing the activation

1533
01:12:52,000 --> 01:12:59,280
function may not be in many situations

1534
01:12:54,960 --> 01:13:01,679
anyway may not be a big deal.

1535
01:12:59,280 --> 01:13:04,320
What you also have to think is you know

1536
01:13:01,679 --> 01:13:05,760
how many

1537
01:13:04,320 --> 01:13:09,679
you know how big do you want the models

1538
01:13:05,760 --> 01:13:12,560
to be you know how many neurons

1539
01:13:09,679 --> 01:13:15,360
per step how many steps in total and

1540
01:13:12,560 --> 01:13:18,400
that sort of thing

1541
01:13:15,360 --> 01:13:20,480
I think that's typ typically what

1542
01:13:18,400 --> 01:13:22,400
happens

1543
01:13:20,480 --> 01:13:24,800
you you know you're going to benefit

1544
01:13:22,400 --> 01:13:28,880
from uh sort of building the neural

1545
01:13:24,800 --> 01:13:31,679
network with say two layers and then use

1546
01:13:28,880 --> 01:13:35,679
the results of that to add a third layer

1547
01:13:31,679 --> 01:13:37,280
or is the three layer neural network

1548
01:13:35,679 --> 01:13:39,360
just built independently?

1549
01:13:37,280 --> 01:13:42,080
>> That's a good question. As far as I

1550
01:13:39,360 --> 01:13:44,080
know, you've got to start from scratch

1551
01:13:42,080 --> 01:13:48,640
when you go from say two layers to three

1552
01:13:44,080 --> 01:13:51,120
layers. Uh you can't

1553
01:13:48,640 --> 01:13:53,280
you can't use what you've done with two

1554
01:13:51,120 --> 01:13:57,920
layers

1555
01:13:53,280 --> 01:13:59,840
as a shortcut to doing three layers.

1556
01:13:57,920 --> 01:14:00,800
I may be wrong there, but I don't think

1557
01:13:59,840 --> 01:14:03,360
the same way.

1558
01:14:00,800 --> 01:14:05,920
>> Right.

1559
01:14:03,360 --> 01:14:10,640
>> Actually, for the class's benefit, um I

1560
01:14:05,920 --> 01:14:13,280
checked your references um and uh on

1561
01:14:10,640 --> 01:14:16,080
your uh Toronto

1562
01:14:13,280 --> 01:14:18,960
uh website, you actually have material

1563
01:14:16,080 --> 01:14:21,440
like uh the Python code for various

1564
01:14:18,960 --> 01:14:23,440
examples in your book. So, I think

1565
01:14:21,440 --> 01:14:25,280
students might find that very accessible

1566
01:14:23,440 --> 01:14:28,320
and useful.

1567
01:14:25,280 --> 01:14:29,520
Yeah. Yeah. There's very I should have

1568
01:14:28,320 --> 01:14:33,120
mentioned this. Yeah. There's a lot on

1569
01:14:29,520 --> 01:14:35,520
my website, you know, I think

1570
01:14:33,120 --> 01:14:40,400
lots of uh lots of different things

1571
01:14:35,520 --> 01:14:41,679
we've done at different times on um

1572
01:14:40,400 --> 01:14:43,760
you know, on this sort of machine

1573
01:14:41,679 --> 01:14:46,159
learning research.

1574
01:14:43,760 --> 01:14:50,000
So, if you want to if you want to read

1575
01:14:46,159 --> 01:14:52,719
more about it, um certainly my website

1576
01:14:50,000 --> 01:14:56,960
would be a good place to go. Um how do

1577
01:14:52,719 --> 01:14:59,040
you uh choose the objective functions in

1578
01:14:56,960 --> 01:15:02,080
your examples?

1579
01:14:59,040 --> 01:15:04,239
Was there um

1580
01:15:02,080 --> 01:15:05,760
is some issues involved with choosing

1581
01:15:04,239 --> 01:15:09,440
those specifically

1582
01:15:05,760 --> 01:15:12,719
>> and what and what was and what was the

1583
01:15:09,440 --> 01:15:16,400
difference between them?

1584
01:15:12,719 --> 01:15:18,960
Uh yeah, I think

1585
01:15:16,400 --> 01:15:21,040
I think every situation is different as

1586
01:15:18,960 --> 01:15:24,040
far as that's concerned and you've got

1587
01:15:21,040 --> 01:15:24,040
to

1588
01:15:24,080 --> 01:15:28,560
you've got to think,

1589
01:15:26,960 --> 01:15:30,719
you know, what what objective function

1590
01:15:28,560 --> 01:15:35,120
fits in with

1591
01:15:30,719 --> 01:15:37,360
with what I'm trying to do um

1592
01:15:35,120 --> 01:15:39,679
in in in the particular situation that

1593
01:15:37,360 --> 01:15:42,080
you're working on. Okay. I mean, if

1594
01:15:39,679 --> 01:15:44,560
you're

1595
01:15:42,080 --> 01:15:46,080
I mean, if you're if you got some exotic

1596
01:15:44,560 --> 01:15:49,199
option and you're trying to match the

1597
01:15:46,080 --> 01:15:51,600
price as closely as possible,

1598
01:15:49,199 --> 01:15:53,360
then obviously it's the difference

1599
01:15:51,600 --> 01:15:56,159
between

1600
01:15:53,360 --> 01:15:59,040
the price you're trying to match

1601
01:15:56,159 --> 01:16:00,960
and the price given by the neural

1602
01:15:59,040 --> 01:16:03,120
network

1603
01:16:00,960 --> 01:16:05,199
is going to be most,

1604
01:16:03,120 --> 01:16:08,920
you know, there going to be an objective

1605
01:16:05,199 --> 01:16:08,920
that you're trying to minimize.


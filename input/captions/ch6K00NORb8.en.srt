1
00:00:00,852 --> 00:00:03,187
(air whooshing)

2
00:00:03,187 --> 00:00:04,770
(dramatic music)

3
00:00:04,770 --> 00:00:05,640
- I'm Sara Beery.

4
00:00:05,640 --> 00:00:08,010
I am a new assistant professor at MIT

5
00:00:08,010 --> 00:00:11,250
and I'm also a PI at the Computer
Science and AI Laboratory.

6
00:00:11,250 --> 00:00:13,260
And my new research
group is really focused

7
00:00:13,260 --> 00:00:18,240
at this intersection between
AI, biodiversity, and ecology.

8
00:00:18,240 --> 00:00:20,850
We're interested in
developing AI techniques

9
00:00:20,850 --> 00:00:24,510
that help us better understand
how species are changing

10
00:00:24,510 --> 00:00:25,890
at a global scale.

11
00:00:25,890 --> 00:00:28,410
And we do this across
different data modalities.

12
00:00:28,410 --> 00:00:31,230
Everything from images
to acoustics, to sonar,

13
00:00:31,230 --> 00:00:32,790
to remote sensing data.

14
00:00:32,790 --> 00:00:34,930
And we combine these different modalities

15
00:00:34,930 --> 00:00:38,130
and try to interpret them,
so that we can understand

16
00:00:38,130 --> 00:00:40,230
how species are changing
at a global scale.

17
00:00:40,230 --> 00:00:42,870
So actually, I've always
loved the natural world.

18
00:00:42,870 --> 00:00:46,110
I grew up camping with my
family in the Pacific Northwest,

19
00:00:46,110 --> 00:00:48,090
but actually my first passion was dance.

20
00:00:48,090 --> 00:00:51,120
I started training as a
ballerina very seriously.

21
00:00:51,120 --> 00:00:53,220
I got my first job offer
with the Atlanta Ballet

22
00:00:53,220 --> 00:00:54,330
when I was only 16,

23
00:00:54,330 --> 00:00:57,090
and I moved from Seattle
to Atlanta by myself

24
00:00:57,090 --> 00:00:58,440
to join a ballet company.

25
00:00:58,440 --> 00:01:01,440
I lived in sort of like
a not super great area

26
00:01:01,440 --> 00:01:03,450
that was kind of close to Georgia Tech.

27
00:01:03,450 --> 00:01:05,760
They would put posters
on the telephone poles

28
00:01:05,760 --> 00:01:08,490
for scientific talk that
always advertised free food,

29
00:01:08,490 --> 00:01:10,770
so I would go.

30
00:01:10,770 --> 00:01:12,910
I almost immediately found myself

31
00:01:13,770 --> 00:01:15,690
hooked on the science,

32
00:01:15,690 --> 00:01:17,880
and not specifically science writ large,

33
00:01:17,880 --> 00:01:19,440
but it was eyeopening to me

34
00:01:19,440 --> 00:01:22,080
in terms of how science and technology

35
00:01:22,080 --> 00:01:24,510
can be used as a force for public good.

36
00:01:24,510 --> 00:01:25,770
And that planted the seed.

37
00:01:25,770 --> 00:01:28,290
So, I went on and I continued
to do professional ballet

38
00:01:28,290 --> 00:01:29,130
for six years.

39
00:01:29,130 --> 00:01:31,980
I loved it, but I always started,

40
00:01:31,980 --> 00:01:36,690
I started to think about
how I might instead go back

41
00:01:36,690 --> 00:01:39,180
after I finished, after
I retired from ballet,

42
00:01:39,180 --> 00:01:40,350
and become a scientist.

43
00:01:40,350 --> 00:01:41,470
And I ended up doing that.

44
00:01:41,470 --> 00:01:42,840
I went back.

45
00:01:42,840 --> 00:01:43,980
I retired from ballet

46
00:01:43,980 --> 00:01:46,890
and I started a career in
electrical engineering.

47
00:01:46,890 --> 00:01:49,110
So one of the projects I
actually started in my PhD

48
00:01:49,110 --> 00:01:52,440
and have brought to my lab
here at MIT is a project

49
00:01:52,440 --> 00:01:54,390
looking at improving the sustainability

50
00:01:54,390 --> 00:01:56,310
of the salmon fisheries from Alaska

51
00:01:56,310 --> 00:01:59,253
all the way down through
Canada to Northern California.

52
00:02:00,090 --> 00:02:02,520
- This project is
working with stakeholders

53
00:02:02,520 --> 00:02:04,350
in fishery management and conservation,

54
00:02:04,350 --> 00:02:06,330
who are interested in monitoring

55
00:02:06,330 --> 00:02:08,700
the number of salmon migrating every year.

56
00:02:08,700 --> 00:02:11,280
And to do this, they
deploy sonar video cameras

57
00:02:11,280 --> 00:02:12,972
at rivers around the world

58
00:02:12,972 --> 00:02:15,060
and they have technicians deployed there

59
00:02:15,060 --> 00:02:17,460
throughout the migration
season, counting how many salmon

60
00:02:17,460 --> 00:02:19,770
are moving by the cameras every day.

61
00:02:19,770 --> 00:02:21,990
We're working on developing
computer vision algorithms

62
00:02:21,990 --> 00:02:23,760
to make the process more efficient

63
00:02:23,760 --> 00:02:25,080
and more accurate for them.

64
00:02:25,080 --> 00:02:27,090
So most of these sonar camera deployments

65
00:02:27,090 --> 00:02:30,570
are out in the field with
limited connectivity and power.

66
00:02:30,570 --> 00:02:31,890
A solution that we've been working on

67
00:02:31,890 --> 00:02:34,620
for deploying these algorithms
uses edge computing.

68
00:02:34,620 --> 00:02:37,770
It's basically a low power,
low cost Linux computer

69
00:02:37,770 --> 00:02:41,190
that can be deployed out in
the field and powered by solar.

70
00:02:41,190 --> 00:02:44,273
And we can deploy the
model on this device.

71
00:02:44,273 --> 00:02:46,350
And we have a software
application that runs,

72
00:02:46,350 --> 00:02:50,250
that allows technicians to
analyze all of their video.

73
00:02:50,250 --> 00:02:51,780
The way that the algorithm works

74
00:02:51,780 --> 00:02:54,150
is that each individual fish

75
00:02:54,150 --> 00:02:56,460
has different colored box drawn around it.

76
00:02:56,460 --> 00:02:58,560
It has a length estimation.

77
00:02:58,560 --> 00:02:59,393
And then at the bottom,

78
00:02:59,393 --> 00:03:02,250
we say how many fish
have gone left or right,

79
00:03:02,250 --> 00:03:04,230
and they, based on the
orientation of the camera,

80
00:03:04,230 --> 00:03:06,780
then change this to upstream
or downstream counts.

81
00:03:06,780 --> 00:03:09,630
- So our interests are really,
from a research perspective,

82
00:03:09,630 --> 00:03:13,020
how do you effectively use human time,

83
00:03:13,020 --> 00:03:15,750
human decisions throughout this process,

84
00:03:15,750 --> 00:03:18,600
so that you can maintain the
reliability of the system,

85
00:03:18,600 --> 00:03:21,540
but also make it reasonably deployable.

86
00:03:21,540 --> 00:03:23,070
The next project I wanna talk about

87
00:03:23,070 --> 00:03:24,990
is a little more open-ended.

88
00:03:24,990 --> 00:03:26,850
And here, what we're interested in

89
00:03:26,850 --> 00:03:28,530
is as we start collecting

90
00:03:28,530 --> 00:03:30,240
these large repositories of data

91
00:03:30,240 --> 00:03:33,030
from different data modalities
like the fish sonar,

92
00:03:33,030 --> 00:03:35,520
but actually specifically in this project,

93
00:03:35,520 --> 00:03:38,910
data collected from passionate
volunteers around the world

94
00:03:38,910 --> 00:03:41,370
who will take photos of plants and animals

95
00:03:41,370 --> 00:03:44,280
that then become species
occurrence records.

96
00:03:44,280 --> 00:03:46,650
And the way that they do that,
one mechanism they do that,

97
00:03:46,650 --> 00:03:49,080
is through a platform called iNaturalist.

98
00:03:49,080 --> 00:03:51,900
- We're using embedding
models, which are AI models

99
00:03:51,900 --> 00:03:54,390
that are trained to find
the semantic relationships

100
00:03:54,390 --> 00:03:56,220
between images and text.

101
00:03:56,220 --> 00:03:57,810
So, we're able to pre-compute

102
00:03:57,810 --> 00:04:00,090
these sort of semantically
meaningful embeddings

103
00:04:00,090 --> 00:04:02,010
on all of our 5 million images.

104
00:04:02,010 --> 00:04:03,840
So when you're trying to search through

105
00:04:03,840 --> 00:04:05,220
and you give us a piece of text

106
00:04:05,220 --> 00:04:06,780
describing what you're looking for,

107
00:04:06,780 --> 00:04:08,910
we can, in less than
a second, look through

108
00:04:08,910 --> 00:04:11,280
and compare with all the
millions of images we have

109
00:04:11,280 --> 00:04:14,220
to give you exactly the closest
natural you're looking for.

110
00:04:14,220 --> 00:04:17,400
We hope that our dataset
will provide the foundation

111
00:04:17,400 --> 00:04:20,160
and the motivation for
researchers in the field

112
00:04:20,160 --> 00:04:22,320
to actually work on building models

113
00:04:22,320 --> 00:04:24,060
that are not just generally good,

114
00:04:24,060 --> 00:04:26,670
but actually useful for scientists.

115
00:04:26,670 --> 00:04:29,040
One great example is California condors.

116
00:04:29,040 --> 00:04:32,190
This is a species that
almost went extinct in 1982.

117
00:04:32,190 --> 00:04:34,260
There were only 22 individuals left.

118
00:04:34,260 --> 00:04:36,150
But because of a successful
breeding program,

119
00:04:36,150 --> 00:04:38,550
now there's a stable
population of hundreds.

120
00:04:38,550 --> 00:04:40,500
And scientists still want to track them

121
00:04:40,500 --> 00:04:42,060
to monitor the population

122
00:04:42,060 --> 00:04:44,100
and understand where they
are and what they're doing.

123
00:04:44,100 --> 00:04:47,100
So, all California
condors have tags on them

124
00:04:47,100 --> 00:04:51,480
with a color and a few symbols
that identify who they are.

125
00:04:51,480 --> 00:04:53,790
And so, scientists can't
be everywhere all at once.

126
00:04:53,790 --> 00:04:55,080
So, it's been really difficult

127
00:04:55,080 --> 00:04:57,120
to be able to successfully monitor them

128
00:04:57,120 --> 00:04:58,560
and see where they're going.

129
00:04:58,560 --> 00:05:01,620
But now with citizen
science and regular people

130
00:05:01,620 --> 00:05:03,810
taking pictures of these
birds they find interesting

131
00:05:03,810 --> 00:05:06,690
and uploading them with geotag locations,

132
00:05:06,690 --> 00:05:09,030
we can automatically mine this information

133
00:05:09,030 --> 00:05:11,160
with these vision language
models that understand

134
00:05:11,160 --> 00:05:14,880
both text and images to
pinpoint all of their locations

135
00:05:14,880 --> 00:05:15,750
and track them in a way

136
00:05:15,750 --> 00:05:17,490
that we've never been able to do before.

137
00:05:17,490 --> 00:05:19,440
- So we can try to design systems

138
00:05:19,440 --> 00:05:21,600
that enable lots of scientists

139
00:05:21,600 --> 00:05:24,600
to do diverse science efficiently

140
00:05:24,600 --> 00:05:26,880
and hopefully opening up whole new avenues

141
00:05:26,880 --> 00:05:28,800
for scientific discovery.

142
00:05:28,800 --> 00:05:32,160
When I was in grad school,
I was passionately working

143
00:05:32,160 --> 00:05:34,920
on developing these tools
for colleges in the field,

144
00:05:34,920 --> 00:05:36,840
but I realized I hadn't
had that experience

145
00:05:36,840 --> 00:05:38,880
of actually trying to collect data

146
00:05:38,880 --> 00:05:41,370
and deploy monitoring
systems in the field myself.

147
00:05:41,370 --> 00:05:43,920
So, I went out of my way
towards the end of my PhD

148
00:05:43,920 --> 00:05:46,770
to actually start curating
some of that experience.

149
00:05:46,770 --> 00:05:48,750
I really found it invaluable.

150
00:05:48,750 --> 00:05:51,600
My first version of
this, I planned a survey

151
00:05:51,600 --> 00:05:54,600
using static cameras in
Laikipia County and Kenya,

152
00:05:54,600 --> 00:05:57,330
sort of north of Mount Kenya,
where we were trying to study

153
00:05:57,330 --> 00:05:59,700
an endangered species of Grevy's zebra.

154
00:05:59,700 --> 00:06:03,120
And I went out and I placed
all of those cameras myself,

155
00:06:03,120 --> 00:06:06,270
hiking out sometimes miles into the forest

156
00:06:06,270 --> 00:06:08,790
with a ranger with a gun,
because you're dealing

157
00:06:08,790 --> 00:06:12,300
with very dangerous large
species out in the Savannah.

158
00:06:12,300 --> 00:06:16,470
And really understanding
how much time and effort

159
00:06:16,470 --> 00:06:19,830
goes into collecting
every single data point,

160
00:06:19,830 --> 00:06:21,870
it really gives you a different mentality

161
00:06:21,870 --> 00:06:24,000
about how to value that data.

162
00:06:24,000 --> 00:06:25,260
But not only that,

163
00:06:25,260 --> 00:06:29,040
there are things that you don't
even realize are challenges

164
00:06:29,040 --> 00:06:32,430
if you're just sitting behind
your computer writing code

165
00:06:32,430 --> 00:06:35,190
that actually really
reframe the priorities

166
00:06:35,190 --> 00:06:36,510
I think I have in my research.

167
00:06:36,510 --> 00:06:38,760
I found that experience
incredibly rewarding

168
00:06:38,760 --> 00:06:41,550
but also incredibly informative,

169
00:06:41,550 --> 00:06:44,760
and it's now something I
really seek to continue to do

170
00:06:44,760 --> 00:06:46,230
in my lab here.

171
00:06:46,230 --> 00:06:49,140
I want to require all of my
grad students to go to the field

172
00:06:49,140 --> 00:06:52,530
to be working much more hands
on with specific projects.

173
00:06:52,530 --> 00:06:53,850
Maybe not for every project,

174
00:06:53,850 --> 00:06:57,330
but I think it's really valuable context.

175
00:06:57,330 --> 00:06:59,640
And it does actually
mean that often our group

176
00:06:59,640 --> 00:07:02,490
and my own research, we've
brought new challenges

177
00:07:02,490 --> 00:07:04,500
to the machine learning
community, framed problems

178
00:07:04,500 --> 00:07:07,770
in ways that potentially they
hadn't before seeing them.

179
00:07:07,770 --> 00:07:11,790
And I think it's really that
application driven innovation

180
00:07:11,790 --> 00:07:13,590
that really helps us move the needle on

181
00:07:13,590 --> 00:07:15,840
in terms of what machine
learning needs to do.

182
00:07:15,840 --> 00:07:18,210
One of the things I'm really
excited about moving forward

183
00:07:18,210 --> 00:07:20,610
is actually starting to bridge the gaps

184
00:07:20,610 --> 00:07:23,550
between these different data modalities

185
00:07:23,550 --> 00:07:25,740
that are being collected globally.

186
00:07:25,740 --> 00:07:29,160
Combining these
hyperspectral imaging systems

187
00:07:29,160 --> 00:07:33,660
from space with drones,
capturing individual animals

188
00:07:33,660 --> 00:07:35,340
moving through the environment,

189
00:07:35,340 --> 00:07:39,150
with static networks of
bioacoustic sensors photos

190
00:07:39,150 --> 00:07:41,610
collected by passionate human volunteers,

191
00:07:41,610 --> 00:07:43,050
actually sharing information

192
00:07:43,050 --> 00:07:44,970
across these modalities of data.

193
00:07:44,970 --> 00:07:47,040
So that we can get a
much more nuanced picture

194
00:07:47,040 --> 00:07:48,480
of the tree of life.

195
00:07:48,480 --> 00:07:49,650
I think if I had any advice

196
00:07:49,650 --> 00:07:52,290
for anyone who's excited to
get started in this field,

197
00:07:52,290 --> 00:07:55,710
it would be to just talk to people.

198
00:07:55,710 --> 00:07:56,910
And there is increasingly

199
00:07:56,910 --> 00:07:59,460
these amazing communities resources

200
00:07:59,460 --> 00:08:01,020
that are coming together.

201
00:08:01,020 --> 00:08:02,100
I run a Slack channel

202
00:08:02,100 --> 00:08:05,700
that has 2,500 global researchers on it,

203
00:08:05,700 --> 00:08:08,070
just working on AI for conservation.

204
00:08:08,070 --> 00:08:10,560
Getting onto these
platforms, meeting people,

205
00:08:10,560 --> 00:08:13,410
asking questions, putting
yourself out there,

206
00:08:13,410 --> 00:08:17,220
but learning about sort of all
of the different diverse ways

207
00:08:17,220 --> 00:08:19,260
that people are sort of
tackling these problems.

208
00:08:19,260 --> 00:08:21,453
I would love to see this continue to grow.


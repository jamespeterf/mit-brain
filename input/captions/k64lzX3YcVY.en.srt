1
00:00:04,920 --> 00:00:09,880
I now have a very hard task I need to

2
00:00:07,680 --> 00:00:11,400
pronounce names properly which I will

3
00:00:09,880 --> 00:00:13,280
I'm sure not do but let me introduce

4
00:00:11,400 --> 00:00:16,680
each of our panelists ask them to join

5
00:00:13,280 --> 00:00:21,960
me up here and I'll start with paramar

6
00:00:16,680 --> 00:00:21,960
from uh scg if you could please join

7
00:00:28,000 --> 00:00:33,480
me and then a Tom from leader fold

8
00:00:34,810 --> 00:00:42,660
[Music]

9
00:00:38,440 --> 00:00:46,900
group JJ Jang from CP

10
00:00:42,660 --> 00:00:46,900
[Music]

11
00:00:47,239 --> 00:00:54,600
group and finally cherum porn from

12
00:00:50,160 --> 00:00:54,600
Bangkok Bank please join us

13
00:00:55,360 --> 00:01:03,889
[Music]

14
00:01:05,799 --> 00:01:10,799
so for me this is going to be fun it's

15
00:01:08,600 --> 00:01:13,320
like an oral exam um but I won't treat

16
00:01:10,799 --> 00:01:15,799
it that way but the goal is to talk

17
00:01:13,320 --> 00:01:18,280
about integration of AI into businesses

18
00:01:15,799 --> 00:01:20,680
and we've got four leading Executives

19
00:01:18,280 --> 00:01:23,400
from from a range of of disciplines um

20
00:01:20,680 --> 00:01:25,479
here in Thailand to give us that sense

21
00:01:23,400 --> 00:01:27,880
um I'm going to moderate this I'm going

22
00:01:25,479 --> 00:01:29,560
to ask panelists um we won't get to all

23
00:01:27,880 --> 00:01:32,439
10 questions I gave you we'll get to

24
00:01:29,560 --> 00:01:35,000
most of them them um I'd encourage you

25
00:01:32,439 --> 00:01:36,439
to keep your answers succinct but to the

26
00:01:35,000 --> 00:01:39,200
point we want to hear what you have to

27
00:01:36,439 --> 00:01:40,439
think but we each spend 10 minutes on a

28
00:01:39,200 --> 00:01:42,680
question we're going to do one and a

29
00:01:40,439 --> 00:01:44,719
half questions uh and I'm going to jump

30
00:01:42,680 --> 00:01:45,920
around on the questions but I I know

31
00:01:44,719 --> 00:01:48,200
you've all thought about these and I

32
00:01:45,920 --> 00:01:52,320
want to start with the integration

33
00:01:48,200 --> 00:01:54,280
question um AI continues to evolve um

34
00:01:52,320 --> 00:01:57,039
what are the most impactful ways in

35
00:01:54,280 --> 00:01:59,960
which your company either has or plans

36
00:01:57,039 --> 00:02:02,560
to integrate AI into your operations and

37
00:01:59,960 --> 00:02:05,759
if you can share an explicit example uh

38
00:02:02,560 --> 00:02:08,039
of how AI has driven a business outcome

39
00:02:05,759 --> 00:02:09,720
that would be great um and I don't know

40
00:02:08,039 --> 00:02:12,160
if somebody wants to start if not I just

41
00:02:09,720 --> 00:02:15,680
pick volunteers but

42
00:02:12,160 --> 00:02:20,160
uh per okay I think I'm next to you

43
00:02:15,680 --> 00:02:22,200
so uh it's very clearly that SD has uh

44
00:02:20,160 --> 00:02:24,080
looked at AI as uh something that

45
00:02:22,200 --> 00:02:27,760
provide huge

46
00:02:24,080 --> 00:02:30,519
opportunities and also threats okay uh

47
00:02:27,760 --> 00:02:33,760
we are you know looking for to get

48
00:02:30,519 --> 00:02:36,640
benefit from AI in in four level uh the

49
00:02:33,760 --> 00:02:39,239
very basic one is the for each of our

50
00:02:36,640 --> 00:02:43,239
individ uh individual employees to have

51
00:02:39,239 --> 00:02:46,040
their know productivity gain okay uh uh

52
00:02:43,239 --> 00:02:47,519
roughly we have just done a survey and

53
00:02:46,040 --> 00:02:49,760
uh they said that they are gaining

54
00:02:47,519 --> 00:02:52,760
around 10% of productivity which was to

55
00:02:49,760 --> 00:02:55,800
our surprise okay maybe because the the

56
00:02:52,760 --> 00:02:57,640
the base is very low I think the next

57
00:02:55,800 --> 00:03:02,040
level of benefits that we we are trying

58
00:02:57,640 --> 00:03:06,080
to get is to have uh and of uh big

59
00:03:02,040 --> 00:03:08,640
impact on productivity gains and better

60
00:03:06,080 --> 00:03:10,680
customer experience and we are seeing

61
00:03:08,640 --> 00:03:13,200
some of the benefits already I give you

62
00:03:10,680 --> 00:03:16,319
some example maybe later in in the in

63
00:03:13,200 --> 00:03:19,239
the session and finally uh we are not

64
00:03:16,319 --> 00:03:22,959
there yet but I think we are aiming uh

65
00:03:19,239 --> 00:03:25,560
to achieve that that is to to have ai to

66
00:03:22,959 --> 00:03:30,080
help us come up with either new business

67
00:03:25,560 --> 00:03:32,200
model or a business reprocess okay we

68
00:03:30,080 --> 00:03:34,920
can even with the same uh business we

69
00:03:32,200 --> 00:03:38,080
can totally overhaul the uh the process

70
00:03:34,920 --> 00:03:41,920
how we how we do business and uh we have

71
00:03:38,080 --> 00:03:45,200
so far you know structure ourself and uh

72
00:03:41,920 --> 00:03:48,000
uh employ resources accordingly okay for

73
00:03:45,200 --> 00:03:52,920
example on the second level of getting

74
00:03:48,000 --> 00:03:55,519
big impact we have uh know uh example uh

75
00:03:52,920 --> 00:03:57,200
group groups of people in four main

76
00:03:55,519 --> 00:04:00,040
areas

77
00:03:57,200 --> 00:04:02,239
operations R&D

78
00:04:00,040 --> 00:04:05,760
uh sales and marketing and then the

79
00:04:02,239 --> 00:04:08,840
admin administrative uh uh activities so

80
00:04:05,760 --> 00:04:11,840
we have champion on each of the uh you

81
00:04:08,840 --> 00:04:14,879
know uh of the discipline and quite

82
00:04:11,840 --> 00:04:17,280
fortunate that you know uh as a congrate

83
00:04:14,879 --> 00:04:19,239
we have various kind of knowledge and

84
00:04:17,280 --> 00:04:21,479
expertise and with this kind of

85
00:04:19,239 --> 00:04:24,080
structure we are seeing some of the

86
00:04:21,479 --> 00:04:26,960
cross pollination some cross Lage of all

87
00:04:24,080 --> 00:04:29,120
the you know AI activities and and

88
00:04:26,960 --> 00:04:31,360
benefits I guess I would stop here first

89
00:04:29,120 --> 00:04:33,039
so that other yeah thank you if I can

90
00:04:31,360 --> 00:04:35,080
add to it really quickly really

91
00:04:33,039 --> 00:04:37,360
interesting to hear the range and I'm

92
00:04:35,080 --> 00:04:39,120
fascinated by the fact that early on

93
00:04:37,360 --> 00:04:40,560
things like productivity Improvement are

94
00:04:39,120 --> 00:04:42,759
things you can do but you ultimately

95
00:04:40,560 --> 00:04:44,800
want to get to business processes and

96
00:04:42,759 --> 00:04:48,759
business plans and that's I think really

97
00:04:44,800 --> 00:04:51,120
valuable but thank you that's great H

98
00:04:48,759 --> 00:04:55,400
yep okay um I have a good pleasure from

99
00:04:51,120 --> 00:04:57,880
him so let me try uh so for M groups so

100
00:04:55,400 --> 00:05:00,639
we operate uh our biobased business from

101
00:04:57,880 --> 00:05:03,600
Shuka of course and along the w chains

102
00:05:00,639 --> 00:05:06,560
so uh we focus on um Farm to Table value

103
00:05:03,600 --> 00:05:09,199
Shain Transformations which uh it evolve

104
00:05:06,560 --> 00:05:12,120
from the digital Transformations into AI

105
00:05:09,199 --> 00:05:15,039
transformation strategies so we focus

106
00:05:12,120 --> 00:05:17,639
around four dimension of transformation

107
00:05:15,039 --> 00:05:19,960
balance scard so the first area is

108
00:05:17,639 --> 00:05:21,880
around to improve business performance

109
00:05:19,960 --> 00:05:25,600
uh both the Top Line uh and the bottom

110
00:05:21,880 --> 00:05:27,840
line uh among our 30 project of AIML

111
00:05:25,600 --> 00:05:29,759
that we are running uh we have around

112
00:05:27,840 --> 00:05:32,400
six projects that already reached

113
00:05:29,759 --> 00:05:34,160
technology liness level seven and above

114
00:05:32,400 --> 00:05:36,840
which have start to uh generate the

115
00:05:34,160 --> 00:05:39,639
business impact like uh over 5 million

116
00:05:36,840 --> 00:05:41,600
some of models for examples so that is

117
00:05:39,639 --> 00:05:43,639
one category of the intention that we

118
00:05:41,600 --> 00:05:46,039
aim to use AI to drive business

119
00:05:43,639 --> 00:05:49,080
performance second uh Dimension is

120
00:05:46,039 --> 00:05:51,759
around to improve stakeholder experience

121
00:05:49,080 --> 00:05:54,280
in our case uh it's not just customer

122
00:05:51,759 --> 00:05:57,400
but it's a Upstream meaning Farmers

123
00:05:54,280 --> 00:06:00,000
supplier communities to the customer so

124
00:05:57,400 --> 00:06:02,520
in our case uh we uh provide provide the

125
00:06:00,000 --> 00:06:05,000
tools like AI to improve stakeholder

126
00:06:02,520 --> 00:06:07,840
experience like to the farmers we

127
00:06:05,000 --> 00:06:10,440
provide the um tools like ekyc to

128
00:06:07,840 --> 00:06:12,880
onboard them so in the past it took a

129
00:06:10,440 --> 00:06:16,240
few weeks for them to on board to engage

130
00:06:12,880 --> 00:06:18,759
with midon and now with the AI and ekyc

131
00:06:16,240 --> 00:06:22,199
and Technologies we reduce the time to

132
00:06:18,759 --> 00:06:25,120
just 5 minutes uh for uh 25 Farmers

133
00:06:22,199 --> 00:06:27,160
across uh the factory that we operat so

134
00:06:25,120 --> 00:06:29,880
that improve the experience of our

135
00:06:27,160 --> 00:06:33,639
stakeholders uh in term of productivity

136
00:06:29,880 --> 00:06:37,319
we also um Drive adoption of AI uh at

137
00:06:33,639 --> 00:06:41,280
the current stage we um develop mgpt the

138
00:06:37,319 --> 00:06:44,520
internal version of the the GPT uh 40 uh

139
00:06:41,280 --> 00:06:47,319
and already used by um 2.5 th000

140
00:06:44,520 --> 00:06:50,479
employees uh with the Run rate of

141
00:06:47,319 --> 00:06:53,560
consumption um close to 1 billion token

142
00:06:50,479 --> 00:06:56,560
annually so um that also improve the

143
00:06:53,560 --> 00:06:58,800
productivity of our employee as well uh

144
00:06:56,560 --> 00:07:01,479
and finally we focus on the digital

145
00:06:58,800 --> 00:07:04,680
capability of employee so we aim to

146
00:07:01,479 --> 00:07:07,560
drive like 5,000 uh digital uh AI

147
00:07:04,680 --> 00:07:10,479
literacy of employee which we work with

148
00:07:07,560 --> 00:07:12,919
uh h a lot to develop the capability

149
00:07:10,479 --> 00:07:15,080
development programs yeah so already a

150
00:07:12,919 --> 00:07:16,520
lot in place which is really great thank

151
00:07:15,080 --> 00:07:20,520
you

152
00:07:16,520 --> 00:07:23,199
JJ yeah so CP group is a lot

153
00:07:20,520 --> 00:07:25,160
conglomerate in many vertical so I just

154
00:07:23,199 --> 00:07:28,599
mention a few

155
00:07:25,160 --> 00:07:32,400
examples so we use the food for traffic

156
00:07:28,599 --> 00:07:35,120
of our Telecom to help open 7-Eleven

157
00:07:32,400 --> 00:07:38,680
store choosing the right location right

158
00:07:35,120 --> 00:07:41,440
that helps with 14% increase of revenue

159
00:07:38,680 --> 00:07:46,039
for the new Star open so I think that's

160
00:07:41,440 --> 00:07:49,560
good and then the we use AI technology

161
00:07:46,039 --> 00:07:53,039
you our fintech solution have zero zero

162
00:07:49,560 --> 00:07:56,120
account being taken over by scammers or

163
00:07:53,039 --> 00:07:59,599
so so I think that's a another another

164
00:07:56,120 --> 00:08:01,639
thing right and we use uh customer

165
00:07:59,599 --> 00:08:06,120
support AI technology in customer

166
00:08:01,639 --> 00:08:09,680
interface that improve uh NPA score to

167
00:08:06,120 --> 00:08:13,120
over 95% right so I just mention a few

168
00:08:09,680 --> 00:08:15,840
example that past we have been doing

169
00:08:13,120 --> 00:08:19,599
right and then we also use AI for

170
00:08:15,840 --> 00:08:23,520
network uh Telecom Network Energy

171
00:08:19,599 --> 00:08:27,319
Management that helps reduce energy cost

172
00:08:23,520 --> 00:08:30,879
by 10% over so I think that's a that's a

173
00:08:27,319 --> 00:08:33,919
few example but we Haven the there are

174
00:08:30,879 --> 00:08:36,760
many AI from the large language motor

175
00:08:33,919 --> 00:08:40,519
side we are getting in but that's that's

176
00:08:36,760 --> 00:08:42,959
we'll talk later yeah okay and and again

177
00:08:40,519 --> 00:08:45,040
I think interesting that there are lots

178
00:08:42,959 --> 00:08:47,240
of productivity things that are easier

179
00:08:45,040 --> 00:08:49,360
to deal with but thinking about

180
00:08:47,240 --> 00:08:50,920
improving the customer experience is

181
00:08:49,360 --> 00:08:52,640
part of this as well and all of you are

182
00:08:50,920 --> 00:08:55,320
thinking about that at some level of of

183
00:08:52,640 --> 00:08:58,959
how do you change it CH

184
00:08:55,320 --> 00:09:02,640
por U at the bank there at least uh

185
00:08:58,959 --> 00:09:05,120
three specific areas and one General the

186
00:09:02,640 --> 00:09:08,480
first specific area is on the fraud

187
00:09:05,120 --> 00:09:10,760
fraud detection yes and uh has been in

188
00:09:08,480 --> 00:09:13,200
the past three years the number of fraud

189
00:09:10,760 --> 00:09:17,560
case increased dramatically especially

190
00:09:13,200 --> 00:09:20,360
on the retail like Mobile Banking uh so

191
00:09:17,560 --> 00:09:24,519
we have a lot of rules now that popping

192
00:09:20,360 --> 00:09:28,640
up and it's getting better and better um

193
00:09:24,519 --> 00:09:31,720
the second one will be the uh uh for

194
00:09:28,640 --> 00:09:34,680
most of the time to transfer fund to the

195
00:09:31,720 --> 00:09:37,680
other person now you you require a if

196
00:09:34,680 --> 00:09:41,720
it's above 50,000 B you require the face

197
00:09:37,680 --> 00:09:46,519
recognition the live uh test that type

198
00:09:41,720 --> 00:09:50,720
of thing so and and this has to um I

199
00:09:46,519 --> 00:09:56,440
think every few months you notice a uh a

200
00:09:50,720 --> 00:10:00,839
new a new a better performance uh coming

201
00:09:56,440 --> 00:10:06,279
up uh faster and more accurate Etc

202
00:10:00,839 --> 00:10:09,959
uh the third one is is about the um the

203
00:10:06,279 --> 00:10:13,720
credit card the the delinquency

204
00:10:09,959 --> 00:10:17,200
prediction uh using the uh more data

205
00:10:13,720 --> 00:10:19,440
than what we the bank used before but

206
00:10:17,200 --> 00:10:22,399
for us this is just a beginning but I

207
00:10:19,440 --> 00:10:25,720
think this is an area of a of a

208
00:10:22,399 --> 00:10:27,320
tremendous opportunity to improve uh the

209
00:10:25,720 --> 00:10:30,680
last one is on

210
00:10:27,320 --> 00:10:34,880
operational uh this is spand across most

211
00:10:30,680 --> 00:10:37,279
of the bank area because we are in

212
00:10:34,880 --> 00:10:40,480
almost every area we have all like

213
00:10:37,279 --> 00:10:43,920
paperwork or operational and so these

214
00:10:40,480 --> 00:10:47,639
now we focus on the input uh because a

215
00:10:43,920 --> 00:10:51,959
lot of input now we just automated using

216
00:10:47,639 --> 00:10:55,480
uh character recognition uh uh uh using

217
00:10:51,959 --> 00:10:58,920
image Etc so that that improved uh on

218
00:10:55,480 --> 00:11:01,600
the cost side a great deal so these are

219
00:10:58,920 --> 00:11:05,000
great and I'm going to follow up for

220
00:11:01,600 --> 00:11:07,639
those of you who want to to respond to

221
00:11:05,000 --> 00:11:08,680
it and chairo part of it was driven by

222
00:11:07,639 --> 00:11:10,880
what you said there are things that are

223
00:11:08,680 --> 00:11:12,480
operational that improve the performance

224
00:11:10,880 --> 00:11:16,600
of the company that's valuable it

225
00:11:12,480 --> 00:11:19,279
reduces costs but your example of of um

226
00:11:16,600 --> 00:11:20,800
you know a transfer of funds above a

227
00:11:19,279 --> 00:11:22,560
certain level that now it needs to do

228
00:11:20,800 --> 00:11:25,560
face recognition before it will accept

229
00:11:22,560 --> 00:11:28,000
it makes me wonder about and again for

230
00:11:25,560 --> 00:11:30,720
any of you that want to respond to it

231
00:11:28,000 --> 00:11:32,800
what's your customer EXP acceptance of

232
00:11:30,720 --> 00:11:35,240
these Technologies I mean do people

233
00:11:32,800 --> 00:11:37,880
resist a change in how they deal with

234
00:11:35,240 --> 00:11:39,639
things or do they see this as a plus of

235
00:11:37,880 --> 00:11:42,200
you know it's safer or it's better it's

236
00:11:39,639 --> 00:11:44,920
more more efficient and again invite any

237
00:11:42,200 --> 00:11:46,360
of you that would want to to ask but CH

238
00:11:44,920 --> 00:11:48,279
point if you don't mind since you raised

239
00:11:46,360 --> 00:11:50,120
it you know customer acceptance do they

240
00:11:48,279 --> 00:11:55,959
find it invasive to do it or they find

241
00:11:50,120 --> 00:11:59,360
it reassuring I heard both uh uh uh some

242
00:11:55,959 --> 00:12:03,920
who really scared about the uh the the

243
00:11:59,360 --> 00:12:06,680
fraud case Etc they they accept it quite

244
00:12:03,920 --> 00:12:09,600
well but they complain that why sometime

245
00:12:06,680 --> 00:12:12,440
you ask them to Blink three times and

246
00:12:09,600 --> 00:12:14,279
smile and then and then uh uh you have

247
00:12:12,440 --> 00:12:15,720
to take off your glasses and then we

248
00:12:14,279 --> 00:12:18,800
couldn't understand the instruction that

249
00:12:15,720 --> 00:12:21,920
type of thing okay yeah U so yeah that

250
00:12:18,800 --> 00:12:24,639
there's both both ways others experience

251
00:12:21,920 --> 00:12:27,600
with with customer

252
00:12:24,639 --> 00:12:30,760
acceptance uh it's not an issue in our

253
00:12:27,600 --> 00:12:33,199
case because uh know since we have tried

254
00:12:30,760 --> 00:12:35,560
to enhance the capability of our shb we

255
00:12:33,199 --> 00:12:38,920
never ask the customer to do anything

256
00:12:35,560 --> 00:12:41,600
more so it's uh they don't feel anything

257
00:12:38,920 --> 00:12:45,360
except that they get better faster

258
00:12:41,600 --> 00:12:47,720
response more accurate response and uh

259
00:12:45,360 --> 00:12:50,279
better information okay so basically we

260
00:12:47,720 --> 00:12:51,839
we hide everything behind uh the engine

261
00:12:50,279 --> 00:12:56,120
so that they they don't feel anything

262
00:12:51,839 --> 00:12:58,079
yeah yeah yeah uh in our case um it's

263
00:12:56,120 --> 00:13:01,199
it's more about when we do the

264
00:12:58,079 --> 00:13:03,959
technology adoption for the the farmers

265
00:13:01,199 --> 00:13:07,199
uh especially um many of them are older

266
00:13:03,959 --> 00:13:09,800
Generations so it's um it's not like we

267
00:13:07,199 --> 00:13:12,600
to them the tools the AI and whatsoever

268
00:13:09,800 --> 00:13:15,160
and and um expect them to use it uh we

269
00:13:12,600 --> 00:13:18,120
still mix it with a human touch so we

270
00:13:15,160 --> 00:13:21,440
still need the people um to be with them

271
00:13:18,120 --> 00:13:24,000
uh explain the Technologies uh uh

272
00:13:21,440 --> 00:13:26,320
explain why it iserve to use when we

273
00:13:24,000 --> 00:13:29,600
scan the phas if they have question we

274
00:13:26,320 --> 00:13:32,880
answer when we scan the I ID card we

275
00:13:29,600 --> 00:13:35,720
answer all that uh so yeah human tou is

276
00:13:32,880 --> 00:13:37,680
what we we use to uh achieve the change

277
00:13:35,720 --> 00:13:39,839
management part with the farmer

278
00:13:37,680 --> 00:13:42,480
especially those who who don't familiar

279
00:13:39,839 --> 00:13:45,000
with the Technologies uh yeah and and we

280
00:13:42,480 --> 00:13:47,079
still that is the the key point that we

281
00:13:45,000 --> 00:13:49,399
need to keep uh when we roll out

282
00:13:47,079 --> 00:13:50,360
technology with the the farmer groups

283
00:13:49,399 --> 00:13:52,680
yeah

284
00:13:50,360 --> 00:13:54,519
great JJ do you want to add to this you

285
00:13:52,680 --> 00:13:56,800
don't have to but I'd love to hear I I

286
00:13:54,519 --> 00:13:59,279
think it's very good I you the Bankok

287
00:13:56,800 --> 00:14:04,720
thing with face recognition right is

288
00:13:59,279 --> 00:14:08,920
quite simply so we we do the uh the uh

289
00:14:04,720 --> 00:14:11,839
EC right the the the kyc for the for the

290
00:14:08,920 --> 00:14:14,480
our true money wet we make the biometric

291
00:14:11,839 --> 00:14:17,040
process is simil right so to improve

292
00:14:14,480 --> 00:14:20,040
customer experience and and customer

293
00:14:17,040 --> 00:14:23,440
care after all we use AI to improve

294
00:14:20,040 --> 00:14:27,000
customer experience and enhance NPS

295
00:14:23,440 --> 00:14:29,160
score right so so so I think indan is

296
00:14:27,000 --> 00:14:31,800
generally helpful right as long as you

297
00:14:29,160 --> 00:14:34,880
simplify the step all the time right and

298
00:14:31,800 --> 00:14:38,600
make it secure so so I think it's is

299
00:14:34,880 --> 00:14:42,320
well accepted yeah that's great so I'm

300
00:14:38,600 --> 00:14:47,040
going to switch to a a second topic

301
00:14:42,320 --> 00:14:51,040
um as preface I think there are a lot of

302
00:14:47,040 --> 00:14:53,519
workers that feel threatened um AI is

303
00:14:51,040 --> 00:14:54,519
changing jobs uh it it's making some

304
00:14:53,519 --> 00:14:57,360
jobs

305
00:14:54,519 --> 00:14:59,720
much less useful if you like it's

306
00:14:57,360 --> 00:15:01,320
certainly changing jobs I

307
00:14:59,720 --> 00:15:03,240
I shouldn't say it's my favorite example

308
00:15:01,320 --> 00:15:06,440
but when people ask me about jobs that

309
00:15:03,240 --> 00:15:09,480
are are going to go away I would not

310
00:15:06,440 --> 00:15:12,600
want to be a paralal today um at least

311
00:15:09,480 --> 00:15:15,120
in the US because an AI system can do

312
00:15:12,600 --> 00:15:16,720
the search it can do the uh writing of

313
00:15:15,120 --> 00:15:19,120
motions it can do a lot of the things

314
00:15:16,720 --> 00:15:20,839
although as you heard uh a lawyer in New

315
00:15:19,120 --> 00:15:22,720
Jersey who had it actually write a

316
00:15:20,839 --> 00:15:25,360
motion and didn't check it got into deep

317
00:15:22,720 --> 00:15:26,560
trouble when it invented cases but you

318
00:15:25,360 --> 00:15:30,279
know there are jobs that are going to

319
00:15:26,560 --> 00:15:32,720
change with that as background

320
00:15:30,279 --> 00:15:35,199
my question for you is how are your

321
00:15:32,720 --> 00:15:38,160
companies thinking about this both the

322
00:15:35,199 --> 00:15:41,319
talent gap of of hiring new employees

323
00:15:38,160 --> 00:15:44,079
that have experience in this but also

324
00:15:41,319 --> 00:15:46,519
just internal training or other ways of

325
00:15:44,079 --> 00:15:49,519
trying to help student sorry help

326
00:15:46,519 --> 00:15:50,680
workers upscale and related to that is

327
00:15:49,519 --> 00:15:53,759
this a place where you think

328
00:15:50,680 --> 00:15:56,519
universities should help um but I guess

329
00:15:53,759 --> 00:15:59,639
let me phrase it better the question is

330
00:15:56,519 --> 00:16:01,800
how are you dealing with um the Gap and

331
00:15:59,639 --> 00:16:03,680
how are you dealing with trying to help

332
00:16:01,800 --> 00:16:05,600
employees adjust to the fact that their

333
00:16:03,680 --> 00:16:07,720
job may change

334
00:16:05,600 --> 00:16:08,759
um par Mar I'm going to start with you

335
00:16:07,720 --> 00:16:10,160
again eventually I'm going to go to the

336
00:16:08,759 --> 00:16:13,120
other end and start down there so you're

337
00:16:10,160 --> 00:16:15,839
not always trapped first but please okay

338
00:16:13,120 --> 00:16:18,360
uh I think I I will start with the

339
00:16:15,839 --> 00:16:20,600
mindset uh I know you start with the

340
00:16:18,360 --> 00:16:23,759
question of do people feel threat of you

341
00:16:20,600 --> 00:16:25,720
know having AI replacing them I think

342
00:16:23,759 --> 00:16:28,360
our mindset is not doing the same with

343
00:16:25,720 --> 00:16:29,480
less resources our mindset is doing more

344
00:16:28,360 --> 00:16:32,240
with the same res

345
00:16:29,480 --> 00:16:34,199
resources okay so our employee feel save

346
00:16:32,240 --> 00:16:36,079
that they're not going to be replaced

347
00:16:34,199 --> 00:16:38,519
but we want them to be more productive

348
00:16:36,079 --> 00:16:41,160
so we can grow business with the same

349
00:16:38,519 --> 00:16:45,519
amount of resources so obviously we have

350
00:16:41,160 --> 00:16:49,120
been uh you know uh Paving a road map on

351
00:16:45,519 --> 00:16:53,120
how to develop our uh talents I think we

352
00:16:49,120 --> 00:16:56,720
use both not both all know buy borrow

353
00:16:53,120 --> 00:16:59,560
and Bill uh on on the bill side we have

354
00:16:56,720 --> 00:17:01,480
uh come up with uh you know very

355
00:16:59,560 --> 00:17:05,280
activities and training programs to make

356
00:17:01,480 --> 00:17:08,280
sure that I know our people firstly well

357
00:17:05,280 --> 00:17:11,880
aware of the benefit of AI and they know

358
00:17:08,280 --> 00:17:13,280
how to upskill themselves yeah yeah no

359
00:17:11,880 --> 00:17:14,839
that's a really good point it's a really

360
00:17:13,280 --> 00:17:18,559
good

361
00:17:14,839 --> 00:17:21,760
point uh as for M group some what see uh

362
00:17:18,559 --> 00:17:24,079
they separate between two part the the

363
00:17:21,760 --> 00:17:26,439
uh collaboration with universities and

364
00:17:24,079 --> 00:17:27,919
the talent souring part and also the

365
00:17:26,439 --> 00:17:30,640
second part is around the talent

366
00:17:27,919 --> 00:17:33,080
development uh but before that um I

367
00:17:30,640 --> 00:17:36,360
think m is quite lucky that uh people

368
00:17:33,080 --> 00:17:38,280
don't fear about placing jobs because uh

369
00:17:36,360 --> 00:17:40,720
we aim for a lot of business expansion

370
00:17:38,280 --> 00:17:43,160
and people feel like with that Target we

371
00:17:40,720 --> 00:17:46,400
we never have enough people to to reach

372
00:17:43,160 --> 00:17:49,120
the goal um so uh obviously AI will be

373
00:17:46,400 --> 00:17:51,600
part of the the the the tools that help

374
00:17:49,120 --> 00:17:53,320
uh people reach the goal um and we we

375
00:17:51,600 --> 00:17:56,200
don't uh people don't don't have the

376
00:17:53,320 --> 00:17:59,120
culture to fear the Technologies uh back

377
00:17:56,200 --> 00:18:02,000
to the thaan sings uh we we do a lot of

378
00:17:59,120 --> 00:18:05,360
mou with universities to to Source the

379
00:18:02,000 --> 00:18:07,679
AI uh Talent uh with the professor um

380
00:18:05,360 --> 00:18:10,159
like with the professor in the satellite

381
00:18:07,679 --> 00:18:12,360
image processing that process um

382
00:18:10,159 --> 00:18:14,919
satellite image that uh land scan

383
00:18:12,360 --> 00:18:16,880
through the cloud for example uh

384
00:18:14,919 --> 00:18:20,080
Professor that work on the specific

385
00:18:16,880 --> 00:18:22,039
industry in the architect for example

386
00:18:20,080 --> 00:18:25,080
and and so on or like logistic

387
00:18:22,039 --> 00:18:27,320
optimization no uh in in that case and

388
00:18:25,080 --> 00:18:31,159
we also do a lot of uh program with uh

389
00:18:27,320 --> 00:18:33,480
student uh because now uh we cannot uh

390
00:18:31,159 --> 00:18:35,480
recruit them after they graduate but we

391
00:18:33,480 --> 00:18:37,360
need to uh make the student have

392
00:18:35,480 --> 00:18:39,720
exposure with the project that we work

393
00:18:37,360 --> 00:18:42,799
with them since year one even year one

394
00:18:39,720 --> 00:18:45,320
in the bachelor degree um so uh like for

395
00:18:42,799 --> 00:18:48,120
example recently we have the yes Heaton

396
00:18:45,320 --> 00:18:50,320
event that we invite uh student from our

397
00:18:48,120 --> 00:18:53,400
University in Thailand uh and then we

398
00:18:50,320 --> 00:18:55,360
got around 60 people invited uh screen

399
00:18:53,400 --> 00:18:57,440
and then compete in the the business

400
00:18:55,360 --> 00:18:59,280
case of M group in four different

401
00:18:57,440 --> 00:19:01,559
business unit and then that is one

402
00:18:59,280 --> 00:19:03,360
example of how we develop the pipeline

403
00:19:01,559 --> 00:19:05,559
of the salent that we bring to the the

404
00:19:03,360 --> 00:19:08,280
company uh in term of the skill

405
00:19:05,559 --> 00:19:10,600
development um this one thank to HR they

406
00:19:08,280 --> 00:19:13,159
have like digital capability road map

407
00:19:10,600 --> 00:19:16,360
for uh executive level and employee

408
00:19:13,159 --> 00:19:18,720
level how we going to develop uh AI

409
00:19:16,360 --> 00:19:21,159
understanding for both executive level

410
00:19:18,720 --> 00:19:23,760
uh and for employee and then we try and

411
00:19:21,159 --> 00:19:26,840
we also try to promote employee to uh

412
00:19:23,760 --> 00:19:29,799
competitive in the the even internally

413
00:19:26,840 --> 00:19:32,320
as well um like uh live last year uh we

414
00:19:29,799 --> 00:19:34,880
have around 10 buus that compete in the

415
00:19:32,320 --> 00:19:38,400
internal competition to build some um

416
00:19:34,880 --> 00:19:40,440
local application some of them use AI uh

417
00:19:38,400 --> 00:19:42,720
and and that is kind of the culture and

418
00:19:40,440 --> 00:19:46,480
capab development programs that we have

419
00:19:42,720 --> 00:19:49,840
in organization to promote them right

420
00:19:46,480 --> 00:19:53,280
JJ our primary responsibility is to

421
00:19:49,840 --> 00:19:57,280
protect our existing invest investment

422
00:19:53,280 --> 00:20:01,039
so we will upscale the uh employee right

423
00:19:57,280 --> 00:20:04,240
through many AI training program we we

424
00:20:01,039 --> 00:20:06,840
done a lot of training and our CEO and

425
00:20:04,240 --> 00:20:10,240
many executive here plead some of the

426
00:20:06,840 --> 00:20:11,960
program to build Innovation ecosystem so

427
00:20:10,240 --> 00:20:15,480
we have we are building a center of

428
00:20:11,960 --> 00:20:18,240
Excellency for technology partnership uh

429
00:20:15,480 --> 00:20:21,600
with International partner startup at

430
00:20:18,240 --> 00:20:24,400
University we're doing a executive

431
00:20:21,600 --> 00:20:27,440
training program with MIT in the

432
00:20:24,400 --> 00:20:29,200
planning as well so so this is our our

433
00:20:27,440 --> 00:20:31,960
group CEOs which

434
00:20:29,200 --> 00:20:35,200
right we have two digital academy which

435
00:20:31,960 --> 00:20:37,720
help train we have CP University and we

436
00:20:35,200 --> 00:20:40,720
have this Center of exellency being set

437
00:20:37,720 --> 00:20:43,159
up here and to facilitate that uh

438
00:20:40,720 --> 00:20:47,600
process right of course we're open to

439
00:20:43,159 --> 00:20:51,240
talk top expert in Ai and uh and we keep

440
00:20:47,600 --> 00:20:53,880
a constant uh discussion with startup

441
00:20:51,240 --> 00:20:57,400
and uh and big and small technology

442
00:20:53,880 --> 00:21:00,360
company and China us Japan Singapore

443
00:20:57,400 --> 00:21:03,480
Israel England right so we build all

444
00:21:00,360 --> 00:21:07,480
this ecosystem so we don't we stay on

445
00:21:03,480 --> 00:21:13,120
top of the curve that's great Turn Point

446
00:21:07,480 --> 00:21:17,120
uh uh to drive uh ahead fast uh uh we

447
00:21:13,120 --> 00:21:20,440
focus on the driving from the mid level

448
00:21:17,120 --> 00:21:22,320
up the top of per perid first so try to

449
00:21:20,440 --> 00:21:26,159
get the leader to pull their

450
00:21:22,320 --> 00:21:28,960
organization forward so we use Partners

451
00:21:26,159 --> 00:21:31,039
we have uh three group of Partners first

452
00:21:28,960 --> 00:21:33,760
is definitely

453
00:21:31,039 --> 00:21:35,360
universities uh uh both local and

454
00:21:33,760 --> 00:21:38,679
International International definitely

455
00:21:35,360 --> 00:21:41,000
is a m uh at the bank of bank we use

456
00:21:38,679 --> 00:21:44,559
many program with MIT you know action

457
00:21:41,000 --> 00:21:48,919
learning Etc you have students coming in

458
00:21:44,559 --> 00:21:50,600
uh and that helps a lot um the second

459
00:21:48,919 --> 00:21:54,880
one would be

460
00:21:50,600 --> 00:21:57,200
the uh the software vendors yes because

461
00:21:54,880 --> 00:21:59,400
they are real expert in some of the area

462
00:21:57,200 --> 00:22:02,640
so so we use them

463
00:21:59,400 --> 00:22:05,480
um and the last one would be the the

464
00:22:02,640 --> 00:22:10,440
Consultants that has some specific

465
00:22:05,480 --> 00:22:14,760
knowledge um and uh this way if we can

466
00:22:10,440 --> 00:22:17,240
change the mindset and get the um get

467
00:22:14,760 --> 00:22:22,640
the top management and middle management

468
00:22:17,240 --> 00:22:25,360
get their feet wet uh uh and we relying

469
00:22:22,640 --> 00:22:29,000
on them to drive the rest

470
00:22:25,360 --> 00:22:31,400
yeah what I heard here was a a lot of

471
00:22:29,000 --> 00:22:34,000
examples of ways in which you can

472
00:22:31,400 --> 00:22:36,039
partner with universities uh I like your

473
00:22:34,000 --> 00:22:38,480
example of also looking to the vendors

474
00:22:36,039 --> 00:22:40,200
as an example you know grow with Google

475
00:22:38,480 --> 00:22:43,919
is an interesting approach to trying to

476
00:22:40,200 --> 00:22:46,360
deal with it part of my question is MIT

477
00:22:43,919 --> 00:22:48,760
has certainly thought about using our

478
00:22:46,360 --> 00:22:51,720
online learning platform not just to

479
00:22:48,760 --> 00:22:54,559
offer MIT courses but to think about

480
00:22:51,720 --> 00:22:57,120
could we create more specialized courses

481
00:22:54,559 --> 00:22:59,880
smaller courses many employees don't

482
00:22:57,120 --> 00:23:01,600
have 6 months to do something but and

483
00:22:59,880 --> 00:23:03,440
I'm I'm inferring that this would be

484
00:23:01,600 --> 00:23:06,279
something that you would see valuable in

485
00:23:03,440 --> 00:23:07,640
in terms of doing let me put one other

486
00:23:06,279 --> 00:23:10,880
piece on

487
00:23:07,640 --> 00:23:12,840
this what's the role of the government

488
00:23:10,880 --> 00:23:14,559
and I'll give you the example with the

489
00:23:12,840 --> 00:23:16,960
as I'm sure you may know with the chips

490
00:23:14,559 --> 00:23:17,760
act in in the US which passed last year

491
00:23:16,960 --> 00:23:20,320
on

492
00:23:17,760 --> 00:23:22,640
semiconductors part of that Act created

493
00:23:20,320 --> 00:23:25,200
funding from the federal government to

494
00:23:22,640 --> 00:23:27,679
encourage universities to create

495
00:23:25,200 --> 00:23:29,559
specifically upskilling programs for

496
00:23:27,679 --> 00:23:32,039
people in that IND whose job was going

497
00:23:29,559 --> 00:23:33,960
to go away I don't mean to put the Thai

498
00:23:32,039 --> 00:23:35,880
government on the spot here but but you

499
00:23:33,960 --> 00:23:38,279
know is there a role for the government

500
00:23:35,880 --> 00:23:39,880
to provide funding or do you think that

501
00:23:38,279 --> 00:23:41,559
the companies just need to take care of

502
00:23:39,880 --> 00:23:43,320
that themselves and just anybody who

503
00:23:41,559 --> 00:23:44,360
wants to comment on that I'm curious

504
00:23:43,320 --> 00:23:46,919
your

505
00:23:44,360 --> 00:23:50,919
thoughts JJ looks like you're ready to

506
00:23:46,919 --> 00:23:54,880
go I think I think government role is to

507
00:23:50,919 --> 00:23:56,919
provide a sovereignty AI infrastructure

508
00:23:54,880 --> 00:23:59,000
right I think they're in the plan

509
00:23:56,919 --> 00:24:02,000
indirectly building s

510
00:23:59,000 --> 00:24:04,480
infrastructure right it's very difficult

511
00:24:02,000 --> 00:24:07,159
I think for TI private company to jump

512
00:24:04,480 --> 00:24:09,640
in that space because this is a big boys

513
00:24:07,159 --> 00:24:12,880
game in some require billions of

514
00:24:09,640 --> 00:24:16,159
billions of dollar so we have to

515
00:24:12,880 --> 00:24:19,880
essentially play our game smartly based

516
00:24:16,159 --> 00:24:21,880
on uh leveraging the Giants sit on the

517
00:24:19,880 --> 00:24:24,080
shoulder of the Giants right and the

518
00:24:21,880 --> 00:24:27,600
leverage of domain knowledge and do a

519
00:24:24,080 --> 00:24:29,399
way that don't get obsolete right but

520
00:24:27,600 --> 00:24:32,360
riding on the evolution of the

521
00:24:29,399 --> 00:24:34,600
foundation model and and both over the

522
00:24:32,360 --> 00:24:37,919
world right so I think the agentic

523
00:24:34,600 --> 00:24:40,880
framework as well as the the the the

524
00:24:37,919 --> 00:24:42,399
application side which will try to shine

525
00:24:40,880 --> 00:24:46,039
right and government of course should

526
00:24:42,399 --> 00:24:48,640
support that effort with some some some

527
00:24:46,039 --> 00:24:51,399
infrastructure support right but if they

528
00:24:48,640 --> 00:24:53,080
have the money right and and that's a

529
00:24:51,399 --> 00:24:56,960
thing that I

530
00:24:53,080 --> 00:24:59,039
feel chort please the government has a

531
00:24:56,960 --> 00:25:03,640
very important role as especially on the

532
00:24:59,039 --> 00:25:07,399
education side and I think we have too

533
00:25:03,640 --> 00:25:10,120
little number of uh too small number of

534
00:25:07,399 --> 00:25:13,720
graduates in the science and technology

535
00:25:10,120 --> 00:25:16,120
area and uh when I had a chance uh that

536
00:25:13,720 --> 00:25:19,240
was way back about 10 years ago when it

537
00:25:16,120 --> 00:25:21,320
was a stock exchange you went to Mexico

538
00:25:19,240 --> 00:25:24,080
and you heard the president saying about

539
00:25:21,320 --> 00:25:27,559
that country and they produce 100,000

540
00:25:24,080 --> 00:25:30,600
engineer per year and I'm looking back

541
00:25:27,559 --> 00:25:32,799
it what are we doing here and and and

542
00:25:30,600 --> 00:25:35,559
that was 10 years ago but

543
00:25:32,799 --> 00:25:38,520
nowadays the science technology is much

544
00:25:35,559 --> 00:25:40,520
more important than 10 years ago yes and

545
00:25:38,520 --> 00:25:43,279
that's a I think a great point that

546
00:25:40,520 --> 00:25:45,760
universities can help with which is to

547
00:25:43,279 --> 00:25:48,159
think about how can we influence earlier

548
00:25:45,760 --> 00:25:50,520
education how can we influence K12

549
00:25:48,159 --> 00:25:52,799
education an elementary school student

550
00:25:50,520 --> 00:25:54,799
today uh and this came up in an earlier

551
00:25:52,799 --> 00:25:56,600
discussion the jobs by the time they

552
00:25:54,799 --> 00:25:58,720
graduate are going to be very different

553
00:25:56,600 --> 00:26:00,200
than what they are today and so so

554
00:25:58,720 --> 00:26:02,120
certainly government can encourage that

555
00:26:00,200 --> 00:26:04,120
but I think it's also an opportunity for

556
00:26:02,120 --> 00:26:06,559
universities to think about how do we

557
00:26:04,120 --> 00:26:08,080
how do we help with this I'm going to

558
00:26:06,559 --> 00:26:10,240
switch gears and again I'm going to pick

559
00:26:08,080 --> 00:26:13,000
up um on on something that a number of

560
00:26:10,240 --> 00:26:17,840
you have raised

561
00:26:13,000 --> 00:26:20,919
um there are lots of users of AI who

562
00:26:17,840 --> 00:26:23,760
worry about ethical issues and ethics

563
00:26:20,919 --> 00:26:25,080
can be around privacy and and chair po

564
00:26:23,760 --> 00:26:26,240
I'm going to use your example again I

565
00:26:25,080 --> 00:26:28,480
don't mean to pick on it but I think it

566
00:26:26,240 --> 00:26:30,200
was a great example of um you know you

567
00:26:28,480 --> 00:26:32,200
do face recognition in order to do a

568
00:26:30,200 --> 00:26:34,840
bank transfer I imagine you have some

569
00:26:32,200 --> 00:26:36,440
customers who are uncomfortable about

570
00:26:34,840 --> 00:26:38,799
what happens to that face image after

571
00:26:36,440 --> 00:26:40,760
it's done I know in the US there are

572
00:26:38,799 --> 00:26:42,480
people who object when they go through

573
00:26:40,760 --> 00:26:44,360
security at an airport that that it's

574
00:26:42,480 --> 00:26:47,080
face recognition so there there are

575
00:26:44,360 --> 00:26:49,080
privacy issues there are also worries

576
00:26:47,080 --> 00:26:51,360
about accountability in in terms of

577
00:26:49,080 --> 00:26:53,919
using this um and and there's just

578
00:26:51,360 --> 00:26:57,200
worries in terms of of legal liability

579
00:26:53,919 --> 00:27:00,520
you know if a autonomous vehicle hits

580
00:26:57,200 --> 00:27:02,760
somebody who's responsible um you know

581
00:27:00,520 --> 00:27:04,679
the owner of the car the programmer who

582
00:27:02,760 --> 00:27:08,279
created it um you know there's a whole

583
00:27:04,679 --> 00:27:11,000
range of of issues around there how are

584
00:27:08,279 --> 00:27:13,200
you and your company thinking about

585
00:27:11,000 --> 00:27:15,760
essentially responsible AI us while

586
00:27:13,200 --> 00:27:17,120
still maximizing what matters to you

587
00:27:15,760 --> 00:27:19,360
which is how well you run the business

588
00:27:17,120 --> 00:27:21,440
how do you think about basically these

589
00:27:19,360 --> 00:27:24,200
ethical issues and I'm going to start in

590
00:27:21,440 --> 00:27:26,039
the middle just to spare people so JJ

591
00:27:24,200 --> 00:27:27,559
we'll go to you first on this one if you

592
00:27:26,039 --> 00:27:29,039
could please just how do you think about

593
00:27:27,559 --> 00:27:32,200
ethical issues

594
00:27:29,039 --> 00:27:36,760
oh first of all transparent explain what

595
00:27:32,200 --> 00:27:38,840
we do right because explainability is a

596
00:27:36,760 --> 00:27:41,760
difficult thing but we explain through

597
00:27:38,840 --> 00:27:44,039
transparency explained how we got there

598
00:27:41,760 --> 00:27:45,880
right you know the whole neuron Network

599
00:27:44,039 --> 00:27:48,279
large language model sometime you don't

600
00:27:45,880 --> 00:27:51,000
really know how it inside work but we

601
00:27:48,279 --> 00:27:53,440
talk about explainability in terms what

602
00:27:51,000 --> 00:27:55,880
data source and why what is the purpose

603
00:27:53,440 --> 00:27:58,799
and and and being transparent and and

604
00:27:55,880 --> 00:28:01,760
make sure we don't do any bu right and

605
00:27:58,799 --> 00:28:04,720
we have governance process also in each

606
00:28:01,760 --> 00:28:07,919
project to to oversee this these things

607
00:28:04,720 --> 00:28:11,960
right to avoid this uh ethical issue

608
00:28:07,919 --> 00:28:15,120
yeah and so so that's it okay no that's

609
00:28:11,960 --> 00:28:16,760
great CH horn okay

610
00:28:15,120 --> 00:28:20,240
um

611
00:28:16,760 --> 00:28:23,600
accountability is the responsibility of

612
00:28:20,240 --> 00:28:26,080
of the the organization that like our

613
00:28:23,600 --> 00:28:30,159
organization we

614
00:28:26,080 --> 00:28:33,360
cannot uh Outsource accountability so

615
00:28:30,159 --> 00:28:34,679
regardless of what if if you use it is

616
00:28:33,360 --> 00:28:37,919
your your

617
00:28:34,679 --> 00:28:39,919
accountability now the the problem is um

618
00:28:37,919 --> 00:28:45,880
there are other layers such as

619
00:28:39,919 --> 00:28:49,760
transparency Etc so as long as you um do

620
00:28:45,880 --> 00:28:54,320
it with care to have the as transparent

621
00:28:49,760 --> 00:29:00,120
as possible uh that would help

622
00:28:54,320 --> 00:29:04,720
um uh but uh for the for the

623
00:29:00,120 --> 00:29:06,919
AI a simple one that that I

624
00:29:04,720 --> 00:29:11,279
experienced an easy

625
00:29:06,919 --> 00:29:12,480
one um was that uh how do you know that

626
00:29:11,279 --> 00:29:15,880
whatever you

627
00:29:12,480 --> 00:29:18,880
say it has your organization name on it

628
00:29:15,880 --> 00:29:22,679
now if if anything that is wrong because

629
00:29:18,880 --> 00:29:25,399
of whatever AI told you to and you don't

630
00:29:22,679 --> 00:29:28,519
understand where it came from yeah then

631
00:29:25,399 --> 00:29:32,080
at the end of the days your um doing the

632
00:29:28,519 --> 00:29:35,320
Christmas I I asked chat gbt to draw a

633
00:29:32,080 --> 00:29:40,240
Christmas picture for me they said okay

634
00:29:35,320 --> 00:29:43,360
U draw a golden eagle standing on a snow

635
00:29:40,240 --> 00:29:45,640
and and the background is MIT Dome yeah

636
00:29:43,360 --> 00:29:47,760
okay it came out very

637
00:29:45,640 --> 00:29:51,200
nice but

638
00:29:47,760 --> 00:29:54,679
unfortunately the Dome has a Capital

639
00:29:51,200 --> 00:29:57,519
Hill Dome on it not an MIT though but

640
00:29:54,679 --> 00:30:01,480
but the bottom is MIT and it has a US

641
00:29:57,519 --> 00:30:04,480
flag on on it said I'm in Thailand I'm

642
00:30:01,480 --> 00:30:07,519
I'm Tha you know so I asked them again

643
00:30:04,480 --> 00:30:11,279
to please remove the flag they came back

644
00:30:07,519 --> 00:30:14,120
with slightly different picture but the

645
00:30:11,279 --> 00:30:17,320
flag flag is still there so chat gbt

646
00:30:14,120 --> 00:30:19,320
does not know us Flags yeah okay so yeah

647
00:30:17,320 --> 00:30:22,000
whatever you do or what do you say to

648
00:30:19,320 --> 00:30:26,279
others and you use the information that

649
00:30:22,000 --> 00:30:28,440
the chat GPT know well bear in mind that

650
00:30:26,279 --> 00:30:32,240
uh it's

651
00:30:28,440 --> 00:30:36,480
not that's not not it's smart but

652
00:30:32,240 --> 00:30:38,320
sometime it he has his own problem it's

653
00:30:36,480 --> 00:30:40,919
a it's a great example and I I

654
00:30:38,320 --> 00:30:43,600
appreciate you're raising the um

655
00:30:40,919 --> 00:30:45,399
ultimately the responsibility rests with

656
00:30:43,600 --> 00:30:47,080
the company it is your name that's on

657
00:30:45,399 --> 00:30:49,720
that and I think that goes back to this

658
00:30:47,080 --> 00:30:52,679
question of how do you help your

659
00:30:49,720 --> 00:30:55,000
employees your staff ask the hard

660
00:30:52,679 --> 00:30:57,080
questions about is this the answer I

661
00:30:55,000 --> 00:30:58,639
want is this something I'm that I'm I'm

662
00:30:57,080 --> 00:31:00,159
I'm willing to deal with

663
00:30:58,639 --> 00:31:03,760
and we'll come to that I think in the

664
00:31:00,159 --> 00:31:06,480
next question but it's a good example

665
00:31:03,760 --> 00:31:09,519
paramat yeah uh you know at the very

666
00:31:06,480 --> 00:31:12,919
beginning of uh our AI Journey uh

667
00:31:09,519 --> 00:31:16,320
responsible AI was one of the very first

668
00:31:12,919 --> 00:31:19,600
topic that we discussed okay uh but

669
00:31:16,320 --> 00:31:21,799
fortunately I think philosophically it's

670
00:31:19,600 --> 00:31:25,240
something similar to the

671
00:31:21,799 --> 00:31:27,919
pdpa okay so when we imp pdpa it's about

672
00:31:25,240 --> 00:31:30,320
you know uh privacy it's about transpar

673
00:31:27,919 --> 00:31:33,760
currency and by protecting others

674
00:31:30,320 --> 00:31:37,080
identity and and information so uh it

675
00:31:33,760 --> 00:31:39,880
was not that difficult for us to you

676
00:31:37,080 --> 00:31:43,120
know uh uh adopt this and uh communicate

677
00:31:39,880 --> 00:31:45,399
to employees but I must accept that you

678
00:31:43,120 --> 00:31:47,080
know you need to take the right balance

679
00:31:45,399 --> 00:31:49,440
because you

680
00:31:47,080 --> 00:31:52,320
want certain level of freedom for our

681
00:31:49,440 --> 00:31:53,799
employees to employ AI but you know at

682
00:31:52,320 --> 00:31:56,399
the same time you want to make sure that

683
00:31:53,799 --> 00:31:59,240
they are using it responsibly so uh we

684
00:31:56,399 --> 00:32:02,120
have uh a body know at the corporate

685
00:31:59,240 --> 00:32:05,519
level that have the governance policy on

686
00:32:02,120 --> 00:32:07,480
that but again I know it's still about

687
00:32:05,519 --> 00:32:10,120
the we call it a self governance okay

688
00:32:07,480 --> 00:32:13,679
because we still want the ball to to

689
00:32:10,120 --> 00:32:16,240
continue rolling yeah that's good call

690
00:32:13,679 --> 00:32:19,679
Yeah in our case um quite similar to um

691
00:32:16,240 --> 00:32:22,840
scg so uh we also treat them uh AI

692
00:32:19,679 --> 00:32:24,600
governance um similar to data governance

693
00:32:22,840 --> 00:32:27,600
uh and personal data protection

694
00:32:24,600 --> 00:32:31,039
governance so all of them are quite of

695
00:32:27,600 --> 00:32:34,159
many in under the GRC government Lis and

696
00:32:31,039 --> 00:32:36,240
compliance uh at the corporate level so

697
00:32:34,159 --> 00:32:38,720
uh we do have the corporate policy

698
00:32:36,240 --> 00:32:41,399
endorsed by chairman level so meaning

699
00:32:38,720 --> 00:32:44,360
all employee need to uh understand the

700
00:32:41,399 --> 00:32:46,600
policy how serious that that we take the

701
00:32:44,360 --> 00:32:49,600
the governance of this kind of thing uh

702
00:32:46,600 --> 00:32:51,519
in place and then uh with all the policy

703
00:32:49,600 --> 00:32:53,279
uh we continue to drive the

704
00:32:51,519 --> 00:32:56,080
understanding of the employee what they

705
00:32:53,279 --> 00:32:59,240
should do or not or should not do under

706
00:32:56,080 --> 00:33:01,679
a different situation and employee we we

707
00:32:59,240 --> 00:33:04,279
also appreciate that uh company has a

708
00:33:01,679 --> 00:33:06,440
clear uh Direction about how what to do

709
00:33:04,279 --> 00:33:08,600
and not to do under different situation

710
00:33:06,440 --> 00:33:10,559
that's great I'm going to follow up on

711
00:33:08,600 --> 00:33:13,320
this um

712
00:33:10,559 --> 00:33:14,919
quickly with an odd question you may

713
00:33:13,320 --> 00:33:18,399
think all my questions are odd but

714
00:33:14,919 --> 00:33:22,240
that's okay um as you think about

715
00:33:18,399 --> 00:33:24,679
ethical use of AI are there cultural

716
00:33:22,240 --> 00:33:25,760
differences and I'll give you an example

717
00:33:24,679 --> 00:33:28,159
which I'll do

718
00:33:25,760 --> 00:33:30,440
quickly for the last several years I

719
00:33:28,159 --> 00:33:32,399
I've given a series of three lectures at

720
00:33:30,440 --> 00:33:34,840
the schwarzman college at Chena which is

721
00:33:32,399 --> 00:33:37,760
a a great program of very International

722
00:33:34,840 --> 00:33:39,880
of of Future Leaders on ethical use of

723
00:33:37,760 --> 00:33:42,000
AI and we were talking about face

724
00:33:39,880 --> 00:33:44,440
recognition and the use of face

725
00:33:42,000 --> 00:33:46,039
recognition and in the US as I'm sure

726
00:33:44,440 --> 00:33:47,679
some of you know there are cities that

727
00:33:46,039 --> 00:33:50,639
have basically banned it there's real

728
00:33:47,679 --> 00:33:52,639
concern about it and one of the students

729
00:33:50,639 --> 00:33:55,200
totally surprised me it's a young woman

730
00:33:52,639 --> 00:33:57,919
from France who was part of the program

731
00:33:55,200 --> 00:33:59,720
who said you know last night at 1:00 in

732
00:33:57,919 --> 00:34:02,639
the morning I was really tired of

733
00:33:59,720 --> 00:34:04,360
working I needed some fresh air so I

734
00:34:02,639 --> 00:34:07,639
just went out and I was walking on the

735
00:34:04,360 --> 00:34:10,359
streets outside of chingua and I felt

736
00:34:07,639 --> 00:34:12,960
completely safe because I knew that

737
00:34:10,359 --> 00:34:14,599
there were security cameras everywhere

738
00:34:12,960 --> 00:34:17,599
that there was face recognition going on

739
00:34:14,599 --> 00:34:19,560
I felt very safe and it made me realize

740
00:34:17,599 --> 00:34:21,560
there may be a cultural difference you

741
00:34:19,560 --> 00:34:23,639
know you wouldn't you wouldn't succeed

742
00:34:21,560 --> 00:34:25,679
with that in San Francisco or Boston but

743
00:34:23,639 --> 00:34:28,320
there she had a very different view so

744
00:34:25,679 --> 00:34:30,440
with that is a weird background

745
00:34:28,320 --> 00:34:33,639
are there cultural differences and and

746
00:34:30,440 --> 00:34:34,760
what you may Implement here will it be

747
00:34:33,639 --> 00:34:36,040
different than something that gets

748
00:34:34,760 --> 00:34:37,679
implemented elsewhere and how do you

749
00:34:36,040 --> 00:34:39,320
deal with that and again if somebody

750
00:34:37,679 --> 00:34:41,560
wants to respond to it I would love just

751
00:34:39,320 --> 00:34:44,159
a reaction but are there cultural

752
00:34:41,560 --> 00:34:46,520
differences to the ethical use of of of

753
00:34:44,159 --> 00:34:49,119
AI

754
00:34:46,520 --> 00:34:50,480
systems JJ you shouldn't nod your head

755
00:34:49,119 --> 00:34:53,079
because I'll take that as a chance to

756
00:34:50,480 --> 00:34:55,359
jump in but please I'm a long time

757
00:34:53,079 --> 00:34:58,839
speaking here so I may speaking out of

758
00:34:55,359 --> 00:35:01,880
steps right so we I I my experience that

759
00:34:58,839 --> 00:35:05,400
we generally follow Europe uh standard

760
00:35:01,880 --> 00:35:08,480
very well like pdpv gdpr right first of

761
00:35:05,400 --> 00:35:12,599
all an AI act right but in terms of

762
00:35:08,480 --> 00:35:15,119
trusting government certainly the China

763
00:35:12,599 --> 00:35:18,520
side privacy is important actually in

764
00:35:15,119 --> 00:35:21,119
China despite whatever the America says

765
00:35:18,520 --> 00:35:23,920
right but they try the government right

766
00:35:21,119 --> 00:35:25,960
because they equally apply to everyone

767
00:35:23,920 --> 00:35:27,800
right even you the in the tally you get

768
00:35:25,960 --> 00:35:32,240
a camera they will make sure that no

769
00:35:27,800 --> 00:35:35,480
body Ste that toilet Ro right so so the

770
00:35:32,240 --> 00:35:38,960
TR of the government I think may be a

771
00:35:35,480 --> 00:35:40,760
little bit different from uh the US side

772
00:35:38,960 --> 00:35:43,880
right it's all about experience right in

773
00:35:40,760 --> 00:35:46,640
China used to be 7 million children get

774
00:35:43,880 --> 00:35:49,640
stolen every year but now with camera

775
00:35:46,640 --> 00:35:52,400
everywhere people are scared right so so

776
00:35:49,640 --> 00:35:56,280
but I think Thailand somewhere in

777
00:35:52,400 --> 00:35:59,880
between so I would say

778
00:35:56,280 --> 00:36:03,560
yeah I have a a case of

779
00:35:59,880 --> 00:36:05,200
Thailand um for information about your

780
00:36:03,560 --> 00:36:08,400
credit

781
00:36:05,200 --> 00:36:13,160
worthiness Tai they don't like anyone to

782
00:36:08,400 --> 00:36:16,400
have it at all uh our our credit

783
00:36:13,160 --> 00:36:18,400
bureau compared to us and China is very

784
00:36:16,400 --> 00:36:21,000
poor in other

785
00:36:18,400 --> 00:36:25,599
words information there is almost

786
00:36:21,000 --> 00:36:30,359
useless to to to to anyone

787
00:36:25,599 --> 00:36:34,760
um uh so so they don't want any of their

788
00:36:30,359 --> 00:36:37,839
information to be public however on your

789
00:36:34,760 --> 00:36:40,760
face your picture we post everything on

790
00:36:37,839 --> 00:36:43,680
online you know Facebook everything you

791
00:36:40,760 --> 00:36:45,599
you you see who you are everywhere I

792
00:36:43,680 --> 00:36:48,359
don't think that's how I care about the

793
00:36:45,599 --> 00:36:50,640
the the the your face is going to be

794
00:36:48,359 --> 00:36:52,800
somewhere else you know no it's it's a

795
00:36:50,640 --> 00:36:54,119
good examp recognize it's a good example

796
00:36:52,800 --> 00:36:56,240
it's a good

797
00:36:54,119 --> 00:36:57,760
example I'm going to link this to

798
00:36:56,240 --> 00:37:01,319
another question that I know we

799
00:36:57,760 --> 00:37:03,119
discussed earlier and that's um the

800
00:37:01,319 --> 00:37:05,200
regulatory landscape because certainly

801
00:37:03,119 --> 00:37:08,920
with ethical use regulations can be part

802
00:37:05,200 --> 00:37:11,040
of that um and as we said earlier today

803
00:37:08,920 --> 00:37:13,640
this is an area that's still very much

804
00:37:11,040 --> 00:37:15,680
evolving um and and again as I said

805
00:37:13,640 --> 00:37:17,319
earlier I give credit to the EU I think

806
00:37:15,680 --> 00:37:20,319
they've taken a good run at this it's a

807
00:37:17,319 --> 00:37:24,720
good start to it my question for each of

808
00:37:20,319 --> 00:37:27,640
you is um how are you as a company

809
00:37:24,720 --> 00:37:30,200
trying to engage with policy makers to

810
00:37:27,640 --> 00:37:33,319
um to ensure that the the things that

811
00:37:30,200 --> 00:37:35,240
you come up with using AI um are aligned

812
00:37:33,319 --> 00:37:37,920
with regulatory requirements how are you

813
00:37:35,240 --> 00:37:40,359
trying to help influence those and what

814
00:37:37,920 --> 00:37:43,280
do you see is the the biggest risks in

815
00:37:40,359 --> 00:37:45,079
in in this space of of um you know

816
00:37:43,280 --> 00:37:47,680
either a lack of Regulation or an

817
00:37:45,079 --> 00:37:50,640
overregulation actually getting in the

818
00:37:47,680 --> 00:37:52,440
way of of of of using AI but the general

819
00:37:50,640 --> 00:37:55,280
question is how are you thinking about

820
00:37:52,440 --> 00:37:56,839
working with policy makers um to to try

821
00:37:55,280 --> 00:38:00,359
and think about the right way to come up

822
00:37:56,839 --> 00:38:02,319
with rails for this and uh I'm trying to

823
00:38:00,359 --> 00:38:04,079
bounce around where I start with so aom

824
00:38:02,319 --> 00:38:05,599
I'm going to start with you but um if

825
00:38:04,079 --> 00:38:09,000
you don't mind and then we'll go down

826
00:38:05,599 --> 00:38:13,599
the road but please thank you uh I think

827
00:38:09,000 --> 00:38:16,359
for Thailand um and in asan regions uh I

828
00:38:13,599 --> 00:38:18,920
think regulatory uh are not really

829
00:38:16,359 --> 00:38:21,280
strict firstly uh as in European

830
00:38:18,920 --> 00:38:24,160
countries um they are quite uh more

831
00:38:21,280 --> 00:38:26,960
favorable to the business so uh for

832
00:38:24,160 --> 00:38:29,880
example um the recent regulation around

833
00:38:26,960 --> 00:38:32,720
data and Cloud uh they are kind of

834
00:38:29,880 --> 00:38:36,680
consult with the business a little bit

835
00:38:32,720 --> 00:38:40,040
whether how leate uh still possible to

836
00:38:36,680 --> 00:38:43,640
allow business to operate in Thailand so

837
00:38:40,040 --> 00:38:46,079
it it kind of um uh B directional uh

838
00:38:43,640 --> 00:38:48,880
consultation between regulation and

839
00:38:46,079 --> 00:38:51,119
private sector side um so I think the

840
00:38:48,880 --> 00:38:53,680
the regulation will not be very strict

841
00:38:51,119 --> 00:38:56,800
but in a way it will not uh really lose

842
00:38:53,680 --> 00:38:59,240
uh as for Thailand so I think uh as for

843
00:38:56,800 --> 00:39:01,720
uh private sect sector we yes definitely

844
00:38:59,240 --> 00:39:04,560
we need to uh continue to monitors uh

845
00:39:01,720 --> 00:39:07,599
the regulation uh as for M group we have

846
00:39:04,560 --> 00:39:10,280
the uh the compliance team to always

847
00:39:07,599 --> 00:39:12,839
monitor the regulation and also uh work

848
00:39:10,280 --> 00:39:15,800
closely with uh uh government sector on

849
00:39:12,839 --> 00:39:18,839
that part so uh once the there are

850
00:39:15,800 --> 00:39:22,280
regulation especially lead to cloud data

851
00:39:18,839 --> 00:39:26,640
or AIS then we translate into the the

852
00:39:22,280 --> 00:39:28,319
GRC operations yeah that's great JJ

853
00:39:26,640 --> 00:39:31,680
regulatory isues how are you thinking

854
00:39:28,319 --> 00:39:34,760
about it my feeling is Tai is quite

855
00:39:31,680 --> 00:39:38,280
conservative in regulation right they're

856
00:39:34,760 --> 00:39:40,240
they're weak lose flexible execution but

857
00:39:38,280 --> 00:39:42,440
they are quite strict in the government

858
00:39:40,240 --> 00:39:45,680
side this is the feedback many startup

859
00:39:42,440 --> 00:39:48,880
coming here they don't fa the the tire

860
00:39:45,680 --> 00:39:51,920
is quite strict right in FDA Food side

861
00:39:48,880 --> 00:39:54,319
of regulation in gen editing right in

862
00:39:51,920 --> 00:39:56,680
data privacy the ACT is quite strong

863
00:39:54,319 --> 00:39:59,720
because they follow the European side

864
00:39:56,680 --> 00:40:02,200
quite strongly right but there is cing

865
00:39:59,720 --> 00:40:06,319
more or less a little bit flexible right

866
00:40:02,200 --> 00:40:09,280
as well right so so I think uh there

867
00:40:06,319 --> 00:40:12,040
there's always Loop loophole gray area

868
00:40:09,280 --> 00:40:14,520
like exom being used by many cosmetic

869
00:40:12,040 --> 00:40:15,800
clinics even though is regulated

870
00:40:14,520 --> 00:40:18,680
completely

871
00:40:15,800 --> 00:40:21,359
forbidden their stem cell they're very s

872
00:40:18,680 --> 00:40:24,040
right being and similarly I expect this

873
00:40:21,359 --> 00:40:26,119
uh some of these areas right that could

874
00:40:24,040 --> 00:40:28,359
be coming in right they just don't know

875
00:40:26,119 --> 00:40:30,760
how to regulate this it right so they

876
00:40:28,359 --> 00:40:33,160
look at the Europeans for the leadership

877
00:40:30,760 --> 00:40:34,359
right which is on the conservative side

878
00:40:33,160 --> 00:40:37,000
and then

879
00:40:34,359 --> 00:40:42,200
adapted execution wise right this is

880
00:40:37,000 --> 00:40:44,280
just my perspective observing here but I

881
00:40:42,200 --> 00:40:46,880
find it in I find it interesting that

882
00:40:44,280 --> 00:40:48,880
again that European model it's not

883
00:40:46,880 --> 00:40:51,200
perfect it may not totally apply but it

884
00:40:48,880 --> 00:40:54,640
is a model that that that placees used

885
00:40:51,200 --> 00:40:58,319
to think about this right CH Point okay

886
00:40:54,640 --> 00:41:02,720
I observed that uh the re reason why the

887
00:40:58,319 --> 00:41:07,520
regulator came up with whatever rules is

888
00:41:02,720 --> 00:41:11,440
because they they uh see the risk has

889
00:41:07,520 --> 00:41:13,960
raised to the level where uh it has some

890
00:41:11,440 --> 00:41:17,000
certain impact on social or or whatever

891
00:41:13,960 --> 00:41:20,240
the day they regulate so what I'm

892
00:41:17,000 --> 00:41:22,079
thinking is that uh we have to be able

893
00:41:20,240 --> 00:41:25,119
to spot the risk

894
00:41:22,079 --> 00:41:27,800
first of of what what are the Rison

895
00:41:25,119 --> 00:41:32,800
using for example if

896
00:41:27,800 --> 00:41:38,119
you um uh want to use

897
00:41:32,800 --> 00:41:41,839
geni um uh the bank will not allow the

898
00:41:38,119 --> 00:41:44,319
uh employees to use a public gen it has

899
00:41:41,839 --> 00:41:46,440
to be an Enterprise wide yeah because

900
00:41:44,319 --> 00:41:49,720
all of the information in public you

901
00:41:46,440 --> 00:41:53,599
assume that it's going to be everywhere

902
00:41:49,720 --> 00:41:57,440
anyway so we have to spot where where

903
00:41:53,599 --> 00:42:00,319
are the risk and if it happen to be uh

904
00:41:57,440 --> 00:42:03,640
something of concern we should find a

905
00:42:00,319 --> 00:42:05,280
way to mitigate it first uh because we

906
00:42:03,640 --> 00:42:07,440
know and if we

907
00:42:05,280 --> 00:42:11,160
write that one will become the

908
00:42:07,440 --> 00:42:13,359
regulation for sure and and therefore

909
00:42:11,160 --> 00:42:17,440
we'll be ready uh rather than be

910
00:42:13,359 --> 00:42:19,640
surprised by by uh the the regulator so

911
00:42:17,440 --> 00:42:22,480
the last thing we want is we want we

912
00:42:19,640 --> 00:42:26,520
don't want to be the last who who be

913
00:42:22,480 --> 00:42:29,119
prepared and so I suggest that stick

914
00:42:26,520 --> 00:42:32,559
closer to the regulator would be also

915
00:42:29,119 --> 00:42:35,000
the best because if if U if you hear

916
00:42:32,559 --> 00:42:39,040
something first uh you better move

917
00:42:35,000 --> 00:42:42,079
quickly yeah it's a great Point perar Ju

918
00:42:39,040 --> 00:42:43,760
Just to add on a little bit I think I

919
00:42:42,079 --> 00:42:46,800
quite agree with that my observation is

920
00:42:43,760 --> 00:42:49,839
that uh latory bodies are still quite

921
00:42:46,800 --> 00:42:52,680
flexible uh uh in this in this

922
00:42:49,839 --> 00:42:56,440
context uh but the other side of the

923
00:42:52,680 --> 00:42:58,000
coin is that you know the risk is now

924
00:42:56,440 --> 00:43:01,160
they are

925
00:42:58,000 --> 00:43:03,240
I think figuring out what to do with it

926
00:43:01,160 --> 00:43:06,079
my my my fear is that because

927
00:43:03,240 --> 00:43:08,480
historically when Ty Regulators want to

928
00:43:06,079 --> 00:43:11,040
come up with something they will go to

929
00:43:08,480 --> 00:43:13,319
you know Europe and Japan and the US and

930
00:43:11,040 --> 00:43:16,520
combine the toughest measure of all the

931
00:43:13,319 --> 00:43:19,079
tree and put into one you know

932
00:43:16,520 --> 00:43:20,359
regulatory paper and if that is the case

933
00:43:19,079 --> 00:43:22,760
I think we're going to be in a very

934
00:43:20,359 --> 00:43:25,160
different environment so I think I agree

935
00:43:22,760 --> 00:43:27,599
with bishon that uh know even though

936
00:43:25,160 --> 00:43:29,640
they are quiet now but once they you

937
00:43:27,599 --> 00:43:31,599
know start to give up some signal we

938
00:43:29,640 --> 00:43:33,520
need to be very proactively work with

939
00:43:31,599 --> 00:43:35,440
them otherwise we're going to be facing

940
00:43:33,520 --> 00:43:38,319
with something that we don't want to see

941
00:43:35,440 --> 00:43:41,920
which is the toughest regulations in the

942
00:43:38,319 --> 00:43:43,760
world and that last point I want to

943
00:43:41,920 --> 00:43:46,040
dwell on just very

944
00:43:43,760 --> 00:43:48,760
briefly there was a study done a few

945
00:43:46,040 --> 00:43:50,880
years ago a survey done by one of the

946
00:43:48,760 --> 00:43:53,000
business Consulting groups I I don't

947
00:43:50,880 --> 00:43:56,000
remember which one it was Bane or kmg or

948
00:43:53,000 --> 00:43:57,960
one of them but um where in different

949
00:43:56,000 --> 00:43:59,040
countries they ask people who do you

950
00:43:57,960 --> 00:44:03,440
most

951
00:43:59,040 --> 00:44:05,480
trust to to come up with regulations and

952
00:44:03,440 --> 00:44:06,880
um it was an interesting study if you're

953
00:44:05,480 --> 00:44:09,400
interested send me a note I'll send it

954
00:44:06,880 --> 00:44:11,280
to you but one of the things that came

955
00:44:09,400 --> 00:44:12,880
up in that study and it goes back to one

956
00:44:11,280 --> 00:44:15,040
of the earlier things said in China they

957
00:44:12,880 --> 00:44:16,760
trust the government to to come up with

958
00:44:15,040 --> 00:44:18,960
that regulation in the US they

959
00:44:16,760 --> 00:44:21,160
absolutely don't trust the government in

960
00:44:18,960 --> 00:44:25,280
Israel it's even lower than the US so go

961
00:44:21,160 --> 00:44:28,839
figure where that is but the one that

962
00:44:25,280 --> 00:44:31,760
consistently was high on on the list to

963
00:44:28,839 --> 00:44:34,280
my surprise was

964
00:44:31,760 --> 00:44:37,440
universities and I think the reasoning

965
00:44:34,280 --> 00:44:39,800
was a nervousness and I think Parma it

966
00:44:37,440 --> 00:44:41,400
relates to what you were saying right no

967
00:44:39,800 --> 00:44:45,040
disrespect but if a government

968
00:44:41,400 --> 00:44:47,680
bureaucrat is setting a regulation on an

969
00:44:45,040 --> 00:44:49,280
advanced piece of technology do they

970
00:44:47,680 --> 00:44:51,720
really understand it well enough to set

971
00:44:49,280 --> 00:44:55,040
it um whereas one hopes that a

972
00:44:51,720 --> 00:44:57,200
university researcher who doesn't have a

973
00:44:55,040 --> 00:44:59,400
vested interest in in it might do a a

974
00:44:57,200 --> 00:45:01,200
better job so I'm curious again any of

975
00:44:59,400 --> 00:45:03,800
you that want to react should

976
00:45:01,200 --> 00:45:05,880
universities play a role working with

977
00:45:03,800 --> 00:45:07,640
companies like yours to help The

978
00:45:05,880 --> 00:45:09,599
Regulators decide on this or should they

979
00:45:07,640 --> 00:45:13,240
stay clear from

980
00:45:09,599 --> 00:45:16,319
it I I actually see a lot of Regulation

981
00:45:13,240 --> 00:45:19,319
recently that uh University uh sector

982
00:45:16,319 --> 00:45:22,160
help to lead the public healing activity

983
00:45:19,319 --> 00:45:24,480
with the private sectors so yeah I think

984
00:45:22,160 --> 00:45:27,319
that that really um good point that that

985
00:45:24,480 --> 00:45:30,680
you mentioned is really um easier for

986
00:45:27,319 --> 00:45:32,960
private sector to to discuss uh openly

987
00:45:30,680 --> 00:45:36,559
uh what are the concerns and and

988
00:45:32,960 --> 00:45:39,599
whatsoever uh yeah so so I think uh yes

989
00:45:36,559 --> 00:45:41,200
uh university did help so you just gave

990
00:45:39,599 --> 00:45:45,599
us more work to do so thank you very

991
00:45:41,200 --> 00:45:48,800
much but it's okay um JJ please go ahead

992
00:45:45,599 --> 00:45:51,720
I my experience the tech government do

993
00:45:48,800 --> 00:45:55,640
does work with University like as TDA

994
00:45:51,720 --> 00:45:58,200
for example for many regulation right so

995
00:45:55,640 --> 00:46:00,440
the private company can provide input

996
00:45:58,200 --> 00:46:03,359
from a business perspective right but

997
00:46:00,440 --> 00:46:06,839
they do work with University and

998
00:46:03,359 --> 00:46:10,200
Research Institute in the way government

999
00:46:06,839 --> 00:46:11,760
Affiliates yeah one last question on

1000
00:46:10,200 --> 00:46:13,240
this and then we're going to switch uh

1001
00:46:11,760 --> 00:46:15,200
and we'll leave a little time at the end

1002
00:46:13,240 --> 00:46:17,640
for questions from all of

1003
00:46:15,200 --> 00:46:20,160
you one of the things in the European

1004
00:46:17,640 --> 00:46:22,240
standards that I found intriguing was

1005
00:46:20,160 --> 00:46:23,520
again they had a set of levels of of of

1006
00:46:22,240 --> 00:46:26,720
AI that you

1007
00:46:23,520 --> 00:46:27,920
needed um the the the guard rails were a

1008
00:46:26,720 --> 00:46:30,280
little little different but one of the

1009
00:46:27,920 --> 00:46:33,079
things in many of them was that they

1010
00:46:30,280 --> 00:46:35,640
tried to Define standards of

1011
00:46:33,079 --> 00:46:37,839
performance that a product needed to

1012
00:46:35,640 --> 00:46:40,960
meet before the government would

1013
00:46:37,839 --> 00:46:44,240
authorize the use of that product in

1014
00:46:40,960 --> 00:46:47,400
your experience is that doable um you

1015
00:46:44,240 --> 00:46:49,440
know can you um can you say you need a

1016
00:46:47,400 --> 00:46:52,079
false positive rate of of this or a

1017
00:46:49,440 --> 00:46:53,760
false negative rate of that can you um

1018
00:46:52,079 --> 00:46:55,079
and I'm sure it depends on the area but

1019
00:46:53,760 --> 00:46:57,839
again for any of you that want to

1020
00:46:55,079 --> 00:47:00,640
respond can is it reasonable to think

1021
00:46:57,839 --> 00:47:04,040
about actually setting standards that a

1022
00:47:00,640 --> 00:47:07,359
new product has to meet before the

1023
00:47:04,040 --> 00:47:07,359
government would authorize its

1024
00:47:07,520 --> 00:47:13,880
use chort please one case is on the

1025
00:47:11,200 --> 00:47:16,480
performance of the the service that the

1026
00:47:13,880 --> 00:47:19,680
bank provide like the bank of Thailand

1027
00:47:16,480 --> 00:47:24,839
has a fairly strict

1028
00:47:19,680 --> 00:47:26,920
U but not regulated but but uh

1029
00:47:24,839 --> 00:47:30,839
supervision or whatever you call they

1030
00:47:26,920 --> 00:47:33,960
can find us uh if our Mobile Banking is

1031
00:47:30,839 --> 00:47:38,079
down more than 8 hours a

1032
00:47:33,960 --> 00:47:41,440
year that is really serious and it's is

1033
00:47:38,079 --> 00:47:44,640
published to uh everyone every month you

1034
00:47:41,440 --> 00:47:49,000
know so uh yes uh from the bank point of

1035
00:47:44,640 --> 00:47:50,680
view the standard can be set you can set

1036
00:47:49,000 --> 00:47:52,960
it that's that's really encouraging to

1037
00:47:50,680 --> 00:47:58,200
to hear JJ

1038
00:47:52,960 --> 00:48:01,000
please just pdpa is the example right we

1039
00:47:58,200 --> 00:48:04,079
follow the government directive to have

1040
00:48:01,000 --> 00:48:06,760
governance framework like having a data

1041
00:48:04,079 --> 00:48:08,839
officer with the process at least the

1042
00:48:06,760 --> 00:48:12,160
governance framework and we have to

1043
00:48:08,839 --> 00:48:15,200
State claims that obey the government

1044
00:48:12,160 --> 00:48:18,280
deadlines for certain degree but in

1045
00:48:15,200 --> 00:48:21,240
reality I'm not aware of anybody get

1046
00:48:18,280 --> 00:48:23,839
fund like the European uh I could be

1047
00:48:21,240 --> 00:48:26,480
wrong but you guys can tell me yeah so

1048
00:48:23,839 --> 00:48:28,520
I'm not aware in CP we got there right

1049
00:48:26,480 --> 00:48:31,520
so so like I said they generally

1050
00:48:28,520 --> 00:48:34,960
conservative on the regulation and

1051
00:48:31,520 --> 00:48:38,200
following the guideline but flexible in

1052
00:48:34,960 --> 00:48:40,760
allowance tolerance in execution so so

1053
00:48:38,200 --> 00:48:43,599
to so sometime we clean up in the back

1054
00:48:40,760 --> 00:48:46,000
hand to make sure we catch up but we are

1055
00:48:43,599 --> 00:48:49,240
may not be at the day one there but we

1056
00:48:46,000 --> 00:48:52,160
make sure the framework is there yeah

1057
00:48:49,240 --> 00:48:53,680
yeah I'm going to do oh sorry P Mar do

1058
00:48:52,160 --> 00:48:55,760
you want to say something oh please just

1059
00:48:53,680 --> 00:48:57,799
quickly I think uh generally

1060
00:48:55,760 --> 00:49:00,240
conceptually if can put standards on

1061
00:48:57,799 --> 00:49:03,880
thing it's good but whether you can

1062
00:49:00,240 --> 00:49:06,520
implement it you know but uh effectively

1063
00:49:03,880 --> 00:49:09,200
is is another story so I think on AI

1064
00:49:06,520 --> 00:49:10,640
something that is still moving very fast

1065
00:49:09,200 --> 00:49:13,160
I hope that they will not come up with

1066
00:49:10,640 --> 00:49:15,359
standards that will know inhibit the

1067
00:49:13,160 --> 00:49:17,520
progress of using

1068
00:49:15,359 --> 00:49:19,359
AI all right I'm going to do one last

1069
00:49:17,520 --> 00:49:20,839
question and then we'll we'll open it up

1070
00:49:19,359 --> 00:49:23,319
to the audience I can see we've already

1071
00:49:20,839 --> 00:49:26,119
got questions showing up

1072
00:49:23,319 --> 00:49:28,119
um it's probably an unfair question so

1073
00:49:26,119 --> 00:49:30,200
you don't have to answer it but um I'd

1074
00:49:28,119 --> 00:49:32,680
love to hear your

1075
00:49:30,200 --> 00:49:35,799
responses if you put

1076
00:49:32,680 --> 00:49:38,160
yourself we're what 2025 put yourself in

1077
00:49:35,799 --> 00:49:41,720
2030 5 years from

1078
00:49:38,160 --> 00:49:44,920
now what would you like to see as a

1079
00:49:41,720 --> 00:49:47,760
trend or capability from AI that would

1080
00:49:44,920 --> 00:49:49,760
have a dramatic effect not only on your

1081
00:49:47,760 --> 00:49:51,359
business but on your clients on your

1082
00:49:49,760 --> 00:49:53,520
customers what you know what would you

1083
00:49:51,359 --> 00:49:55,400
love to see so it's Crystal Ball we

1084
00:49:53,520 --> 00:49:57,119
won't hold you to it I don't know maybe

1085
00:49:55,400 --> 00:49:58,920
Todd when he runs this conference 5

1086
00:49:57,119 --> 00:50:01,440
years from now which you won't do we'll

1087
00:49:58,920 --> 00:50:03,040
ask you so what happened here but you

1088
00:50:01,440 --> 00:50:06,720
get the idea what what would you like to

1089
00:50:03,040 --> 00:50:09,920
see JJ go one thing humanoid robot

1090
00:50:06,720 --> 00:50:14,240
because we will have Labor issue tent

1091
00:50:09,920 --> 00:50:16,799
issue and efficiency issue to humanoid

1092
00:50:14,240 --> 00:50:19,160
robot right and of course today we're

1093
00:50:16,799 --> 00:50:22,280
already doing code writing and customer

1094
00:50:19,160 --> 00:50:25,480
care but in the food factory in the in

1095
00:50:22,280 --> 00:50:27,839
the retail store to do many of the I

1096
00:50:25,480 --> 00:50:30,200
would say more than human intelligence

1097
00:50:27,839 --> 00:50:33,599
right because they can recognize

1098
00:50:30,200 --> 00:50:35,920
misplace item with misplay price tag

1099
00:50:33,599 --> 00:50:38,559
right they can see something lying

1100
00:50:35,920 --> 00:50:40,760
around in the store right that could

1101
00:50:38,559 --> 00:50:42,440
trip customer so they can deal with it

1102
00:50:40,760 --> 00:50:45,920
as well so

1103
00:50:42,440 --> 00:50:48,079
so I I I love it and I'm going to do a a

1104
00:50:45,920 --> 00:50:49,839
blatant piece of advertising here

1105
00:50:48,079 --> 00:50:51,520
there's a company called Boston Dynamics

1106
00:50:49,839 --> 00:50:54,160
that makes a humanoid robot if you

1107
00:50:51,520 --> 00:50:56,680
haven't seen their video from two years

1108
00:50:54,160 --> 00:50:58,559
ago of their dancing robot go check it

1109
00:50:56,680 --> 00:51:00,280
it out it's better than most humans it's

1110
00:50:58,559 --> 00:51:02,720
not what you're looking for but human ey

1111
00:51:00,280 --> 00:51:05,359
robots other things what would you like

1112
00:51:02,720 --> 00:51:06,680
to see Chum porn what what please what

1113
00:51:05,359 --> 00:51:09,280
would you like to

1114
00:51:06,680 --> 00:51:12,400
see I would think

1115
00:51:09,280 --> 00:51:17,000
healthcare like ear early detection like

1116
00:51:12,400 --> 00:51:19,760
the the the the lecture this morning um

1117
00:51:17,000 --> 00:51:22,480
you can detect like breast cancer much

1118
00:51:19,760 --> 00:51:25,240
earlier the have thing uh that would

1119
00:51:22,480 --> 00:51:29,480
help because uh

1120
00:51:25,240 --> 00:51:31,520
um if not we all going to be bankrupt by

1121
00:51:29,480 --> 00:51:35,839
the yeah

1122
00:51:31,520 --> 00:51:39,400
um the cost the cost because now the

1123
00:51:35,839 --> 00:51:43,480
combination of insurance plus the high

1124
00:51:39,400 --> 00:51:44,280
cost in the hospital are uh eating up

1125
00:51:43,480 --> 00:51:47,839
your

1126
00:51:44,280 --> 00:51:52,319
budget so hopefully if we are not sick

1127
00:51:47,839 --> 00:51:53,480
or sick less uh that would help I agree

1128
00:51:52,319 --> 00:51:57,240
it's a great

1129
00:51:53,480 --> 00:51:59,799
example paramat um

1130
00:51:57,240 --> 00:52:02,880
well I might sound a little bit

1131
00:51:59,799 --> 00:52:05,200
different but um to to me I think in

1132
00:52:02,880 --> 00:52:10,119
this world the biggest problem or the

1133
00:52:05,200 --> 00:52:13,799
the most Waring trend is the increase in

1134
00:52:10,119 --> 00:52:18,000
inequality so I hope that AI uh in many

1135
00:52:13,799 --> 00:52:20,680
angles would be able to reduce that Gap

1136
00:52:18,000 --> 00:52:21,880
okay we talk about education how can you

1137
00:52:20,680 --> 00:52:26,359
know but people who doesn't have

1138
00:52:21,880 --> 00:52:29,720
anything can learn very freely uh know

1139
00:52:26,359 --> 00:52:32,079
the early detection of uh diseases of

1140
00:52:29,720 --> 00:52:35,520
the new drugs that are accessible to

1141
00:52:32,079 --> 00:52:38,280
more people so I think in in short to

1142
00:52:35,520 --> 00:52:42,240
reduce inequality yeah it's a great

1143
00:52:38,280 --> 00:52:44,760
example an uh as for me I think uh what

1144
00:52:42,240 --> 00:52:48,119
I wish is that uh in the next like five

1145
00:52:44,760 --> 00:52:50,920
years uh AI will um make sustainability

1146
00:52:48,119 --> 00:52:53,680
more accessible for more organization so

1147
00:52:50,920 --> 00:52:56,520
meaning now when we do the scope one two

1148
00:52:53,680 --> 00:52:58,440
three it take a lot of effort to early

1149
00:52:56,520 --> 00:53:01,000
collect all the information and

1150
00:52:58,440 --> 00:53:03,079
Implement all the actions even for large

1151
00:53:01,000 --> 00:53:06,480
organization along the whole value

1152
00:53:03,079 --> 00:53:09,440
chains uh not to mention nowme how they

1153
00:53:06,480 --> 00:53:12,640
going to do that so uh with the AI

1154
00:53:09,440 --> 00:53:15,400
Automation and everything uh I I hope a

1155
00:53:12,640 --> 00:53:18,160
I will make all the activity around this

1156
00:53:15,400 --> 00:53:21,760
entire scope 123 will become more

1157
00:53:18,160 --> 00:53:23,880
accessible and down to the level yeah so

1158
00:53:21,760 --> 00:53:25,680
I love the examples I think healthc care

1159
00:53:23,880 --> 00:53:27,680
is a great one I think inequality is a

1160
00:53:25,680 --> 00:53:30,160
great one I I I think uh you know

1161
00:53:27,680 --> 00:53:32,200
flexible use of AI is a great one I will

1162
00:53:30,160 --> 00:53:34,119
add my own person I shouldn't say

1163
00:53:32,200 --> 00:53:36,680
personal favorite but but one of the

1164
00:53:34,119 --> 00:53:39,599
examples for me is I really hope that

1165
00:53:36,680 --> 00:53:41,440
the technology for autonomous vehicles

1166
00:53:39,599 --> 00:53:45,000
gets to the level where it can really be

1167
00:53:41,440 --> 00:53:47,160
used because the cost to nations of not

1168
00:53:45,000 --> 00:53:49,040
just fatalities but just injuries is

1169
00:53:47,160 --> 00:53:51,520
massive and just the human loss around

1170
00:53:49,040 --> 00:53:53,839
that if you can drive automobile

1171
00:53:51,520 --> 00:53:56,920
fatalities close to zero it's a huge

1172
00:53:53,839 --> 00:53:58,920
impact on a country with that we have a

1173
00:53:56,920 --> 00:54:00,799
few minutes left um and I'm going to ask

1174
00:53:58,920 --> 00:54:02,720
the staff I know we've got a bunch of

1175
00:54:00,799 --> 00:54:04,839
things on the the list why don't we just

1176
00:54:02,720 --> 00:54:06,839
go to the the one that's at the top of

1177
00:54:04,839 --> 00:54:08,400
the list if you could post it up we'll

1178
00:54:06,839 --> 00:54:11,119
um

1179
00:54:08,400 --> 00:54:13,640
let somebody can do that for me please I

1180
00:54:11,119 --> 00:54:15,119
think it says uh something like we can't

1181
00:54:13,640 --> 00:54:18,880
read all of it because the clock's in

1182
00:54:15,119 --> 00:54:18,880
the way so in your opinion what would

1183
00:54:21,200 --> 00:54:25,400
be I don't see it up can you there we go

1184
00:54:23,920 --> 00:54:28,359
all right so the top one if you could

1185
00:54:25,400 --> 00:54:28,359
just highlight it

1186
00:54:29,000 --> 00:54:32,280
anybody that wants to take this in your

1187
00:54:30,400 --> 00:54:34,480
opinion what would be a good start first

1188
00:54:32,280 --> 00:54:37,200
starting point for a business to start

1189
00:54:34,480 --> 00:54:38,839
integrating AI so what's your advice to

1190
00:54:37,200 --> 00:54:41,640
your colleagues about how do you get

1191
00:54:38,839 --> 00:54:45,000
going and integrating AI into your

1192
00:54:41,640 --> 00:54:47,160
business customer care sorry Customer

1193
00:54:45,000 --> 00:54:50,440
Care customer caring that's a good

1194
00:54:47,160 --> 00:54:50,440
example other

1195
00:54:50,680 --> 00:54:57,920
thoughts chair I I just say just just

1196
00:54:53,640 --> 00:55:01,880
get the the leader of that bu unit to to

1197
00:54:57,920 --> 00:55:06,280
you have to educate them an awareness on

1198
00:55:01,880 --> 00:55:13,520
the benefit or the risk of not having AI

1199
00:55:06,280 --> 00:55:17,040
uh use as as a tool uh and uh yeah yeah

1200
00:55:13,520 --> 00:55:19,920
good AI is not free so you need to use

1201
00:55:17,040 --> 00:55:22,400
it effectively so I think the first like

1202
00:55:19,920 --> 00:55:24,559
like in many cases you have to get the

1203
00:55:22,400 --> 00:55:25,880
problem statement right first don't

1204
00:55:24,559 --> 00:55:27,960
start with AI but start with your

1205
00:55:25,880 --> 00:55:30,520
business cas T and then try to figure

1206
00:55:27,960 --> 00:55:33,359
out how AI can help you do that more

1207
00:55:30,520 --> 00:55:35,799
effectively and cheaply and faster yeah

1208
00:55:33,359 --> 00:55:38,400
yeah good example I think the first

1209
00:55:35,799 --> 00:55:40,599
thing is I think start with the ideation

1210
00:55:38,400 --> 00:55:42,839
among the leadership teams and get the

1211
00:55:40,599 --> 00:55:44,480
commitment and Alignment together what

1212
00:55:42,839 --> 00:55:47,640
the organization should do with with

1213
00:55:44,480 --> 00:55:48,799
thei yeah so increase the trust um you

1214
00:55:47,640 --> 00:55:51,160
know that that you're going to be able

1215
00:55:48,799 --> 00:55:53,680
to use it we got time for one more

1216
00:55:51,160 --> 00:55:55,240
question and so I'm got to try and read

1217
00:55:53,680 --> 00:55:58,839
that

1218
00:55:55,240 --> 00:56:01,119
um I'll do it this way talk about the

1219
00:55:58,839 --> 00:56:02,720
risk of data leakage privacy which is

1220
00:56:01,119 --> 00:56:05,680
believed to be difficult to avoid or

1221
00:56:02,720 --> 00:56:08,920
control is it worth to compare the

1222
00:56:05,680 --> 00:56:13,559
benefit uh of the AI new technology so

1223
00:56:08,920 --> 00:56:13,559
concerns about privacy and data leakage

1224
00:56:16,280 --> 00:56:21,480
thoughts go

1225
00:56:18,359 --> 00:56:23,640
ahead aamc go ahead okay I mean in our

1226
00:56:21,480 --> 00:56:26,440
case it's quite lucky because most of

1227
00:56:23,640 --> 00:56:29,799
the AI are not relate to personal data

1228
00:56:26,440 --> 00:56:32,880
yet so uh we are more around the

1229
00:56:29,799 --> 00:56:37,880
agricultures data around manufacturing

1230
00:56:32,880 --> 00:56:40,640
data for example so uh it's um sensitive

1231
00:56:37,880 --> 00:56:42,960
yes we don't want to have it leak but uh

1232
00:56:40,640 --> 00:56:46,280
at the same time it's not about personal

1233
00:56:42,960 --> 00:56:49,039
data when we we do it with AI so at

1234
00:56:46,280 --> 00:56:52,559
least uh we are quite um sever in this

1235
00:56:49,039 --> 00:56:54,839
case but uh anyway um the company will

1236
00:56:52,559 --> 00:56:57,280
need to do a lot of data protection

1237
00:56:54,839 --> 00:56:59,920
cyber security and everything

1238
00:56:57,280 --> 00:57:03,240
uh but uh I have to admit that at the

1239
00:56:59,920 --> 00:57:05,799
currently M we do the the traditional

1240
00:57:03,240 --> 00:57:09,839
cyber security practice but we are still

1241
00:57:05,799 --> 00:57:12,599
exploring the AI security uh so we still

1242
00:57:09,839 --> 00:57:14,839
exploring with a lot of partner how how

1243
00:57:12,599 --> 00:57:17,720
do we really protect the AI security

1244
00:57:14,839 --> 00:57:19,520
yeah that's great JJ go ahead so I've

1245
00:57:17,720 --> 00:57:22,480
been talking to people about

1246
00:57:19,520 --> 00:57:25,520
architecturing this properly right A lot

1247
00:57:22,480 --> 00:57:28,559
of people doing fine tuning right making

1248
00:57:25,520 --> 00:57:32,400
API Cod that that actually share some of

1249
00:57:28,559 --> 00:57:35,599
the Privacy data right with third party

1250
00:57:32,400 --> 00:57:38,000
so in that respect you also lose out

1251
00:57:35,599 --> 00:57:40,319
when the foundation model evolve become

1252
00:57:38,000 --> 00:57:43,119
more powerful so you have to retain

1253
00:57:40,319 --> 00:57:46,440
again so cost more lot of money or

1254
00:57:43,119 --> 00:57:49,480
alternatively you can take a different

1255
00:57:46,440 --> 00:57:53,319
architecture that using your internal

1256
00:57:49,480 --> 00:57:56,480
data applying traditional AI tools that

1257
00:57:53,319 --> 00:57:58,160
get some database knowledge some graph

1258
00:57:56,480 --> 00:58:01,000
right but let the foundation model

1259
00:57:58,160 --> 00:58:03,880
Loosely Couer so as Foundation model

1260
00:58:01,000 --> 00:58:06,240
evolve increase you don't get affected

1261
00:58:03,880 --> 00:58:08,520
and you save your money and data privacy

1262
00:58:06,240 --> 00:58:11,640
as well risk right of course you have

1263
00:58:08,520 --> 00:58:13,880
all the internal uh governance but I'm

1264
00:58:11,640 --> 00:58:16,359
just talking about from architecture

1265
00:58:13,880 --> 00:58:19,160
perspective that you protect about your

1266
00:58:16,359 --> 00:58:22,799
future because Foundation model evolve

1267
00:58:19,160 --> 00:58:24,559
often supp the specialized model so you

1268
00:58:22,799 --> 00:58:27,880
want to make sure the foundation model

1269
00:58:24,559 --> 00:58:30,960
continue to improve and your specialized

1270
00:58:27,880 --> 00:58:33,720
knowledge remain being applicable to

1271
00:58:30,960 --> 00:58:37,599
that new Foundation model so using

1272
00:58:33,720 --> 00:58:40,480
agentic framework using Loosely AR cered

1273
00:58:37,599 --> 00:58:41,559
architecture this will help as well it's

1274
00:58:40,480 --> 00:58:44,440
a great

1275
00:58:41,559 --> 00:58:46,839
example I'm going to ask the audience a

1276
00:58:44,440 --> 00:58:48,559
favor and I know I've had my back turned

1277
00:58:46,839 --> 00:58:51,079
to this side of the audience much please

1278
00:58:48,559 --> 00:58:52,440
join me in thanking our four panelists

1279
00:58:51,079 --> 00:58:53,799
for what I hope you found a really

1280
00:58:52,440 --> 00:58:56,620
interesting discussion thank you

1281
00:58:53,799 --> 00:59:04,729
gentlemen

1282
00:58:56,620 --> 00:59:04,729
[Music]


1
00:00:06,120 --> 00:00:10,000
I'm Anantha Chandrakasan,
MIT's Provost

2
00:00:10,000 --> 00:00:16,239
and the Head of the MIT
Generative AI Impact Consortium.

3
00:00:16,239 --> 00:00:19,200
It's an absolute
pleasure to welcome you

4
00:00:19,200 --> 00:00:25,200
to the inaugural symposium of
the MIT AI Impact Consortium,

5
00:00:25,200 --> 00:00:27,240
or MGAIC.

6
00:00:27,240 --> 00:00:31,560
The energy in this room
reflects the enormous interest

7
00:00:31,560 --> 00:00:36,200
in the topic of generative
AI and MIT's ability

8
00:00:36,200 --> 00:00:40,200
to drive progress
through collaboration.

9
00:00:40,200 --> 00:00:43,200
There's been a tremendous
amount of interest and work

10
00:00:43,200 --> 00:00:47,680
in industry and in academia
in creating large language

11
00:00:47,680 --> 00:00:51,960
models and its
broad-based applications.

12
00:00:51,960 --> 00:00:57,640
This consortium is focused on
the impact of generative AI

13
00:00:57,640 --> 00:01:01,320
across domains such
as manufacturing,

14
00:01:01,320 --> 00:01:08,720
life sciences, transportation,
design, energy, and so on.

15
00:01:08,720 --> 00:01:12,960
To maximize impact, we
need to bring researchers

16
00:01:12,960 --> 00:01:16,080
across research domains.

17
00:01:16,080 --> 00:01:21,960
MIT is uniquely positioned
to catalyze that convergence,

18
00:01:21,960 --> 00:01:26,280
bringing together researchers
from across the institute

19
00:01:26,280 --> 00:01:31,320
to work across domains and
also to work with our industry

20
00:01:31,320 --> 00:01:33,640
collaborators.

21
00:01:33,640 --> 00:01:37,840
I want to thank the founding
members of our Industrial

22
00:01:37,840 --> 00:01:46,800
Advisory Board, Analog Devices,
Coca-Cola, InterSystems, OpenAI,

23
00:01:46,800 --> 00:01:53,000
SK Telecom, Tata Group, and
TWG Global for stepping forward

24
00:01:53,000 --> 00:01:55,480
as partners in this work.

25
00:01:55,480 --> 00:01:57,840
I would also like
to thank McKinsey

26
00:01:57,840 --> 00:02:03,040
for providing deep insights
and advice to the IAB.

27
00:02:03,040 --> 00:02:06,490
The deep commitment of
the founding members

28
00:02:06,490 --> 00:02:11,570
reflects a shared belief that
bold research done in the open

29
00:02:11,570 --> 00:02:14,090
can shape a better future.

30
00:02:14,090 --> 00:02:16,970
Thanks to their support,
we're able to fund

31
00:02:16,970 --> 00:02:22,850
more than 60 interdisciplinary
projects on campus.

32
00:02:22,850 --> 00:02:26,630
This consortium is more than
a platform for research.

33
00:02:26,630 --> 00:02:31,810
It's a model of how we engage
industry, energize faculty,

34
00:02:31,810 --> 00:02:37,050
empower students, and
deliver impact all at once,

35
00:02:37,050 --> 00:02:41,450
and it is a commitment
to our openness.

36
00:02:41,450 --> 00:02:45,150
So I was really impressed that
these companies signed up,

37
00:02:45,150 --> 00:02:47,050
knowing that all of
the work that we do

38
00:02:47,050 --> 00:02:50,250
is going to be open source.

39
00:02:50,250 --> 00:02:54,870
The work will not just benefit
just the member companies,

40
00:02:54,870 --> 00:02:57,170
but society at large.

41
00:02:57,170 --> 00:03:01,850
And that's why the solutions
that will be emerging

42
00:03:01,850 --> 00:03:04,210
will be open source,
interdisciplinary, and designed

43
00:03:04,210 --> 00:03:06,170
for public good.

44
00:03:06,170 --> 00:03:08,450
And today's program
gives you a glimpse

45
00:03:08,450 --> 00:03:11,710
of what is already happening
and what is coming next.

46
00:03:11,710 --> 00:03:17,090
You will hear from MIT faculty
at the forefront of research,

47
00:03:17,090 --> 00:03:21,930
from innovators shaping the
future of entrepreneurship,

48
00:03:21,930 --> 00:03:24,930
and from students
whose work reminds us

49
00:03:24,930 --> 00:03:28,730
the next generation is
not just ready to lead.

50
00:03:28,730 --> 00:03:32,730
In many ways, they
already are doing so.

51
00:03:32,730 --> 00:03:34,430
This is a pivotal moment.

52
00:03:34,430 --> 00:03:37,490
Generative AI is moving fast.

53
00:03:37,490 --> 00:03:41,450
But the questions it
raises about equity,

54
00:03:41,450 --> 00:03:47,090
creativity, responsibility,
and impact are enduring.

55
00:03:47,090 --> 00:03:50,370
I truly believe it is
our job to make sure

56
00:03:50,370 --> 00:03:55,290
that as the technology advances,
our collective wisdom keeps

57
00:03:55,290 --> 00:03:57,090
pace.

58
00:03:57,090 --> 00:03:59,490
I want to extend
my deepest thanks

59
00:03:59,490 --> 00:04:03,490
to our faculty co-directors,
Professors Vivek Farias, who

60
00:04:03,490 --> 00:04:07,650
is here, and Tim Kraska,
whose dedication and insights

61
00:04:07,650 --> 00:04:11,090
have helped shape MGAIC into a
bold, collaborative initiative

62
00:04:11,090 --> 00:04:11,750
it is today.

63
00:04:11,750 --> 00:04:12,750
So let's thank them.

64
00:04:12,750 --> 00:04:16,117
[APPLAUSE]

65
00:04:19,490 --> 00:04:21,130
I would also like
to take a moment

66
00:04:21,130 --> 00:04:25,730
to thank the amazing staff
of the MGAIC initiative,

67
00:04:25,730 --> 00:04:28,630
the MIT Schwarzman
College of Computing,

68
00:04:28,630 --> 00:04:30,930
and the Office of
Innovation and Strategy

69
00:04:30,930 --> 00:04:33,090
for their amazing
contributions not

70
00:04:33,090 --> 00:04:36,768
only for organizing this event,
but the ongoing activity.

71
00:04:36,768 --> 00:04:38,560
So let's also give them
around of applause.

72
00:04:38,560 --> 00:04:41,828
[APPLAUSE]

73
00:04:45,290 --> 00:04:50,090
It is now my deep honor to
introduce President Sally

74
00:04:50,090 --> 00:04:51,210
Kornbluth.

75
00:04:51,210 --> 00:04:56,290
She has consistently championed
the idea that MIT must not only

76
00:04:56,290 --> 00:05:00,930
respond to the rapid
evolution of generative AI,

77
00:05:00,930 --> 00:05:05,730
but help shape its trajectory
thoughtfully, ethically,

78
00:05:05,730 --> 00:05:09,210
and in service to the
nation and the world.

79
00:05:09,210 --> 00:05:11,890
I'm deeply grateful
for her leadership

80
00:05:11,890 --> 00:05:15,210
in establishing MGAIC as
a presidential priority

81
00:05:15,210 --> 00:05:19,070
and for her continuous
support for the initiative.

82
00:05:19,070 --> 00:05:22,650
Please join me in giving a warm
welcome to MIT President Sally

83
00:05:22,650 --> 00:05:23,510
Kornbluth.

84
00:05:23,510 --> 00:05:26,905
[APPLAUSE]

85
00:05:32,113 --> 00:05:34,030
Thanks so much, Anantha,
for the introduction.

86
00:05:34,030 --> 00:05:36,230
And I just have to say,
today is Anantha's birthday,

87
00:05:36,230 --> 00:05:38,340
so this is a great birthday.

88
00:05:38,340 --> 00:05:41,530
[APPLAUSE]

89
00:05:43,890 --> 00:05:46,130
He's been really outstanding
in his leadership

90
00:05:46,130 --> 00:05:47,670
in bringing this
consortium to life.

91
00:05:47,670 --> 00:05:49,410
So I guess in the
context of MGAIC,

92
00:05:49,410 --> 00:05:52,110
that makes him the chief
magician, so thank you.

93
00:05:52,110 --> 00:05:53,370
[LAUGHTER]

94
00:05:53,370 --> 00:05:56,690
Let me also give a warm
shout-out to our other magicians

95
00:05:56,690 --> 00:06:01,010
here, our faculty co-directors,
not to mention Vivek and Tim,

96
00:06:01,010 --> 00:06:03,770
and to the whole team
of faculty and staff

97
00:06:03,770 --> 00:06:05,750
who organized today's program.

98
00:06:05,750 --> 00:06:07,270
So thanks to all.

99
00:06:07,270 --> 00:06:11,330
Also to the students, to
the early career researchers

100
00:06:11,330 --> 00:06:15,900
who will share their work in
this afternoon's poster session.

101
00:06:15,900 --> 00:06:18,420
And I know that we're all
looking forward to hearing

102
00:06:18,420 --> 00:06:21,600
from today's incredible
speakers and panelists,

103
00:06:21,600 --> 00:06:24,820
starting with the
legendary Yann LeCun.

104
00:06:24,820 --> 00:06:27,220
Today's symposium
is the first of what

105
00:06:27,220 --> 00:06:31,620
I hope will be an annual
flagship event for the MIT

106
00:06:31,620 --> 00:06:34,100
Generative AI Consortium.

107
00:06:34,100 --> 00:06:38,240
Now, at MIT one thing we
do love as well as numbers,

108
00:06:38,240 --> 00:06:39,660
are great acronyms.

109
00:06:39,660 --> 00:06:41,600
UROP, MISTI, DAPER, DUSP.

110
00:06:41,600 --> 00:06:44,020
So we've now added--

111
00:06:44,020 --> 00:06:48,420
this is a little bit of
acronymical sleight of hand

112
00:06:48,420 --> 00:06:52,340
to call this MGAIC,
M-G-A-I-C. But hopefully,

113
00:06:52,340 --> 00:06:54,060
you'll forgive for that.

114
00:06:54,060 --> 00:06:57,220
Easy to remember, fun
to say, et cetera.

115
00:06:57,220 --> 00:07:00,992
But I would argue that
calling this effort MGAIC

116
00:07:00,992 --> 00:07:03,940
also points to something
quite serious, why

117
00:07:03,940 --> 00:07:05,550
we're here together.

118
00:07:05,550 --> 00:07:07,500
Obviously, in this
audience we've

119
00:07:07,500 --> 00:07:11,420
got some fans of the
great scientific sci-fi

120
00:07:11,420 --> 00:07:13,340
master, Arthur C. Clarke.

121
00:07:13,340 --> 00:07:15,460
So remember Clarke's third law.

122
00:07:15,460 --> 00:07:18,100
Any sufficiently
advanced technology

123
00:07:18,100 --> 00:07:20,380
is indistinguishable from magic.

124
00:07:20,380 --> 00:07:23,180
Now, I know I'm
not the first and I

125
00:07:23,180 --> 00:07:26,300
won't be the last to connect
Arthur Clarke's observation

126
00:07:26,300 --> 00:07:31,020
with the black box sensation
of using generative AI.

127
00:07:31,020 --> 00:07:32,140
But put in your prompt.

128
00:07:32,140 --> 00:07:35,740
You get a polished
answer back so fast

129
00:07:35,740 --> 00:07:37,940
it actually feels like magic.

130
00:07:37,940 --> 00:07:41,060
And of course, everyone here
knows that generative AI

131
00:07:41,060 --> 00:07:43,220
does not work by magic.

132
00:07:43,220 --> 00:07:47,780
And yet, even the experts, many
of whom you'll hear from here,

133
00:07:47,780 --> 00:07:52,260
can't always explain
how something does work.

134
00:07:52,260 --> 00:07:56,300
That makes gen AI fundamentally
different from really other

135
00:07:56,300 --> 00:08:00,300
technologies, and it creates a
very important responsibility

136
00:08:00,300 --> 00:08:04,220
for an institution and
a community like MIT.

137
00:08:04,220 --> 00:08:08,620
This audience includes
experts, aspiring experts

138
00:08:08,620 --> 00:08:13,020
on every part of the AI menu,
and I'm certainly not one.

139
00:08:13,020 --> 00:08:15,260
But to explain the
kind of responsibility

140
00:08:15,260 --> 00:08:18,540
I'm talking about, let me
offer as an example something

141
00:08:18,540 --> 00:08:21,540
from my own field in
the life sciences.

142
00:08:21,540 --> 00:08:24,800
My lab explored deep
behavior of cancer cells.

143
00:08:24,800 --> 00:08:28,540
And today, when I talk to
cancer researchers and clinician

144
00:08:28,540 --> 00:08:32,539
scientists on our faculty,
they say that AI already

145
00:08:32,539 --> 00:08:37,020
touches and improves literally
every aspect of their work,

146
00:08:37,020 --> 00:08:39,919
from how they design
experiments and analyze data

147
00:08:39,919 --> 00:08:43,220
to how they keep and manage
records, to how they diagnose

148
00:08:43,220 --> 00:08:45,220
and care for their patients.

149
00:08:45,220 --> 00:08:49,340
They're positioned now to
capitalize on a great many AI

150
00:08:49,340 --> 00:08:51,540
advances immediately.

151
00:08:51,540 --> 00:08:54,660
And I hear tremendous
gratitude and enthusiasm.

152
00:08:54,660 --> 00:08:57,020
So part of MIT's
responsibility is

153
00:08:57,020 --> 00:09:00,020
to keep those advances
coming for the world.

154
00:09:00,020 --> 00:09:04,180
But those researchers and
clinicians on their own

155
00:09:04,180 --> 00:09:08,740
are not in a position to address
AI's risks and mysteries.

156
00:09:08,740 --> 00:09:12,420
How to guarantee accuracy and
guard against hallucinations?

157
00:09:12,420 --> 00:09:14,140
How to get sufficient
patient data

158
00:09:14,140 --> 00:09:18,860
to make the systems work while
also preserving confidentiality?

159
00:09:18,860 --> 00:09:22,860
How to validate the results and
achieve enough explicability

160
00:09:22,860 --> 00:09:25,820
that users feel
safe to trust them?

161
00:09:25,820 --> 00:09:29,860
In short, how can you manage
the magic so that all of us

162
00:09:29,860 --> 00:09:33,180
can confidently rely on it
for critical applications

163
00:09:33,180 --> 00:09:34,700
in the real world?

164
00:09:34,700 --> 00:09:37,760
And so they're counting on
all of you-- our faculty,

165
00:09:37,760 --> 00:09:41,500
our researchers, our students,
together with our consortium

166
00:09:41,500 --> 00:09:42,700
members--

167
00:09:42,700 --> 00:09:44,100
to help.

168
00:09:44,100 --> 00:09:45,540
They're counting
on you to tackle

169
00:09:45,540 --> 00:09:48,960
the whole suite of technical
and ethical challenges

170
00:09:48,960 --> 00:09:51,300
whose solutions
will allow society

171
00:09:51,300 --> 00:09:54,900
to make the most of this
astounding technology.

172
00:09:54,900 --> 00:09:57,180
And in the myriad
of other realms

173
00:09:57,180 --> 00:10:00,740
where AI is also changing
everything, the rest of society

174
00:10:00,740 --> 00:10:02,500
is counting on you too.

175
00:10:02,500 --> 00:10:06,140
It's a big responsibility, but
judging by the depth and breadth

176
00:10:06,140 --> 00:10:09,420
of interest on our campus,
I have every confidence

177
00:10:09,420 --> 00:10:10,940
that we'll succeed.

178
00:10:10,940 --> 00:10:12,980
The excitement is everywhere.

179
00:10:12,980 --> 00:10:16,060
The two new undergraduate majors
we've created in these fields

180
00:10:16,060 --> 00:10:18,860
were effectively
sold out overnight.

181
00:10:18,860 --> 00:10:22,520
And when we announced our first
round of MGAIC seed funding,

182
00:10:22,520 --> 00:10:26,510
we were stunned to receive more
than 180 research proposals

183
00:10:26,510 --> 00:10:29,110
representing every
school in the college.

184
00:10:29,110 --> 00:10:31,570
They covered an
incredible range of ideas,

185
00:10:31,570 --> 00:10:34,930
from fundamental research
to practical applications,

186
00:10:34,930 --> 00:10:39,150
from responsible deployment
to workforce transformation.

187
00:10:39,150 --> 00:10:42,430
Many depend on collaborations
across departments

188
00:10:42,430 --> 00:10:46,630
and disciplines, and crucially,
collaborations with industry

189
00:10:46,630 --> 00:10:47,670
as well.

190
00:10:47,670 --> 00:10:50,150
So I want to close
with a special nod

191
00:10:50,150 --> 00:10:53,710
to the consortium's founding
members, as Anantha did.

192
00:10:53,710 --> 00:10:57,870
Analog Devices, Coca-Cola,
InterSystems, OpenAI, SK

193
00:10:57,870 --> 00:11:01,190
Telecom, Tata, and TWG Global.

194
00:11:01,190 --> 00:11:04,270
What enables the magic
in the MGAIC consortium

195
00:11:04,270 --> 00:11:07,590
is your commitment to explore
very important AI challenges

196
00:11:07,590 --> 00:11:11,507
with us in the best open
source tradition of MIT.

197
00:11:11,507 --> 00:11:13,090
We wouldn't be here
today without you,

198
00:11:13,090 --> 00:11:15,390
and we're deeply grateful
for your willingness

199
00:11:15,390 --> 00:11:17,670
to join us in that vital work.

200
00:11:17,670 --> 00:11:19,710
So thank you all
for coming, and best

201
00:11:19,710 --> 00:11:21,690
wishes for a fascinating day.

202
00:11:21,690 --> 00:11:22,290
Thank you.

203
00:11:22,290 --> 00:11:25,500
[APPLAUSE]


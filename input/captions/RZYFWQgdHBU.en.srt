1
00:00:05,520 --> 00:00:13,719
MIT actually announced the establishment

2
00:00:09,040 --> 00:00:18,000
of MIT Generative AI and impact

3
00:00:13,719 --> 00:00:21,720
consortium and today we are so thrilled

4
00:00:18,000 --> 00:00:23,880
to have one of the faculty

5
00:00:21,720 --> 00:00:28,400
co-directors

6
00:00:23,880 --> 00:00:31,599
professor uh Vivik Filas who is a

7
00:00:28,400 --> 00:00:35,200
Patrick McGovern professor in MIT school

8
00:00:31,599 --> 00:00:39,440
of management. Uh he will give an

9
00:00:35,200 --> 00:00:41,840
overview of the consortium and this is a

10
00:00:39,440 --> 00:00:44,160
great opportunity if you have any

11
00:00:41,840 --> 00:00:46,239
questions to ask the person who's

12
00:00:44,160 --> 00:00:49,079
leading the consortium. The concern

13
00:00:46,239 --> 00:00:53,120
itself is really to

14
00:00:49,079 --> 00:00:56,879
explore the potential of genetic AI

15
00:00:53,120 --> 00:00:59,840
across all industry sectors and foster

16
00:00:56,879 --> 00:01:03,400
the collaborations between industry and

17
00:00:59,840 --> 00:01:05,459
MIT researchers. Now let's welcome

18
00:01:03,400 --> 00:01:13,119
professor Fas.

19
00:01:05,459 --> 00:01:16,159
[Applause]

20
00:01:13,119 --> 00:01:18,720
Okay. Uh, so I am I think the last thing

21
00:01:16,159 --> 00:01:21,759
between you and lunch and so I'm sure

22
00:01:18,720 --> 00:01:23,439
you're hungry after all of the uh the

23
00:01:21,759 --> 00:01:25,439
exciting intellectual stuff you've been

24
00:01:23,439 --> 00:01:28,159
exposed to. Um, and so I'll I'll be I'll

25
00:01:25,439 --> 00:01:29,200
be relatively quick. Um, and uh

26
00:01:28,159 --> 00:01:33,720
hopefully we'll have some time for

27
00:01:29,200 --> 00:01:37,119
questions as well. Um, okay. So, uh,

28
00:01:33,720 --> 00:01:38,799
basically you know you know we just sort

29
00:01:37,119 --> 00:01:40,320
of talked about this Genai impact

30
00:01:38,799 --> 00:01:44,560
consortium, right? What what is this

31
00:01:40,320 --> 00:01:48,479
thing? Um so about a year and a half ago

32
00:01:44,560 --> 00:01:51,439
uh this is in late uh 2023

33
00:01:48,479 --> 00:01:55,119
uh President Cornblue uh organized uh

34
00:01:51,439 --> 00:01:58,320
sort of an AI week at MIT. All right. So

35
00:01:55,119 --> 00:02:01,680
it was a sequence of conferences uh

36
00:01:58,320 --> 00:02:03,200
around campus very very heavily attended

37
00:02:01,680 --> 00:02:05,040
where the idea was to kind of just

38
00:02:03,200 --> 00:02:07,040
understand you know what what was

39
00:02:05,040 --> 00:02:09,599
happening right like what what did we

40
00:02:07,040 --> 00:02:11,840
think as as an institution about uh

41
00:02:09,599 --> 00:02:13,440
generative AI. Um and one of the things

42
00:02:11,840 --> 00:02:16,879
that kind of came out of that was sort

43
00:02:13,440 --> 00:02:19,200
of the need to kind of have a consortium

44
00:02:16,879 --> 00:02:22,160
an effort a centralized effort uh here

45
00:02:19,200 --> 00:02:25,440
at MIT uh that would function on a few

46
00:02:22,160 --> 00:02:27,120
different fronts. Okay. So one very

47
00:02:25,440 --> 00:02:28,800
important front was the following. One

48
00:02:27,120 --> 00:02:30,879
thing we recognized and you've probably

49
00:02:28,800 --> 00:02:32,560
recognized this uh you know the in the

50
00:02:30,879 --> 00:02:35,200
con in the in the conversations this

51
00:02:32,560 --> 00:02:36,800
morning. A lot of the efforts happening

52
00:02:35,200 --> 00:02:39,360
over here a lot of the research that's

53
00:02:36,800 --> 00:02:42,120
actually happening uh you know in Genai

54
00:02:39,360 --> 00:02:45,120
is not siloed. It's it's very sort of

55
00:02:42,120 --> 00:02:47,599
cross-disciplinary by its nature. Okay.

56
00:02:45,120 --> 00:02:49,280
Um and so one very important thing was

57
00:02:47,599 --> 00:02:51,640
how can we actually do something that

58
00:02:49,280 --> 00:02:54,800
brings every single school at MIT

59
00:02:51,640 --> 00:02:56,879
together. Okay. uh this is so this is

60
00:02:54,800 --> 00:02:58,959
not just an effort out of engineering,

61
00:02:56,879 --> 00:03:01,040
out of computing, out of business or out

62
00:02:58,959 --> 00:03:03,280
of science. Uh it's a much broader

63
00:03:01,040 --> 00:03:06,800
thing. Um and so that was sort of one

64
00:03:03,280 --> 00:03:09,440
goal. The other goal was uh impact,

65
00:03:06,800 --> 00:03:11,519
right? So we said look uh this thing is

66
00:03:09,440 --> 00:03:13,120
going to sort of transform pretty much

67
00:03:11,519 --> 00:03:14,640
every industry that we sort of see

68
00:03:13,120 --> 00:03:16,239
around us.

69
00:03:14,640 --> 00:03:18,480
How do we make sure that, you know, from

70
00:03:16,239 --> 00:03:20,560
the get-go, uh, we're kind of plugged

71
00:03:18,480 --> 00:03:22,000
into this that we, right, that like what

72
00:03:20,560 --> 00:03:24,400
we're doing is something we're doing

73
00:03:22,000 --> 00:03:26,080
kind of handinhand, uh, shall we say,

74
00:03:24,400 --> 00:03:28,239
with, uh, you know, things that will

75
00:03:26,080 --> 00:03:30,319
have impact in the real world for real

76
00:03:28,239 --> 00:03:33,200
companies. Okay? How do we kind of bring

77
00:03:30,319 --> 00:03:34,720
them, uh, sort of into the fold? Uh, and

78
00:03:33,200 --> 00:03:38,080
then the final sort of thing, the final

79
00:03:34,720 --> 00:03:40,879
sort of desira was look, everything we

80
00:03:38,080 --> 00:03:42,720
do over here, uh, this is for impact.

81
00:03:40,879 --> 00:03:44,640
This is for the greater good. And so a

82
00:03:42,720 --> 00:03:46,640
third sort of principle was anything

83
00:03:44,640 --> 00:03:48,959
that comes out of this needs to be open

84
00:03:46,640 --> 00:03:51,120
source. Okay. So these are sort of the

85
00:03:48,959 --> 00:03:53,400
principles of this sort of genai impact

86
00:03:51,120 --> 00:03:55,920
consortium. And uh you know uh president

87
00:03:53,400 --> 00:03:57,680
Cornbluth uh you know gave us sort of

88
00:03:55,920 --> 00:04:00,400
the following mission right. So she said

89
00:03:57,680 --> 00:04:03,519
look uh hey what what what what I would

90
00:04:00,400 --> 00:04:06,080
like right is that our community our MIT

91
00:04:03,519 --> 00:04:09,040
community uh you know blaze the way

92
00:04:06,080 --> 00:04:11,760
forward on important new sort of gen AI

93
00:04:09,040 --> 00:04:14,000
solutions. Okay. Uh and so this led to

94
00:04:11,760 --> 00:04:16,400
kind of the founding of the Genaii

95
00:04:14,000 --> 00:04:17,919
Impact Consortium. Uh and what I'd like

96
00:04:16,400 --> 00:04:20,320
to do today is tell you a couple

97
00:04:17,919 --> 00:04:22,320
different things. So we just launched by

98
00:04:20,320 --> 00:04:25,199
the way. So the idea is was very new,

99
00:04:22,320 --> 00:04:28,720
right? So the idea h was middle of last

100
00:04:25,199 --> 00:04:30,479
year, late last year actually. Okay. Um

101
00:04:28,720 --> 00:04:32,960
we put everything together along with

102
00:04:30,479 --> 00:04:34,639
the funding and our sort of initial

103
00:04:32,960 --> 00:04:37,600
founding members who I'll tell you about

104
00:04:34,639 --> 00:04:41,120
in a second. uh and uh over a very short

105
00:04:37,600 --> 00:04:43,919
span of time. We launched in February uh

106
00:04:41,120 --> 00:04:47,520
and we're at a place where we're very

107
00:04:43,919 --> 00:04:50,960
soon going to announce an inaugural set

108
00:04:47,520 --> 00:04:54,160
of research grants that will go to 40 to

109
00:04:50,960 --> 00:04:56,320
50 different investigators around campus

110
00:04:54,160 --> 00:04:58,960
uh to do work uh that we believe is

111
00:04:56,320 --> 00:05:01,120
going to be at the forefront uh of Genai

112
00:04:58,960 --> 00:05:04,479
that is at the forefront of impacting a

113
00:05:01,120 --> 00:05:06,960
whole bunch of companies. Okay. So um

114
00:05:04,479 --> 00:05:08,720
what what does uh the impact consortium

115
00:05:06,960 --> 00:05:11,320
consist of? And by the way, you know, we

116
00:05:08,720 --> 00:05:15,680
pronounce this acronym magic. Okay, so

117
00:05:11,320 --> 00:05:18,880
MGIC, we call it magic. All right. So uh

118
00:05:15,680 --> 00:05:20,720
uh in any event, right? So uh magic is

119
00:05:18,880 --> 00:05:22,960
so so who are our founding members? So

120
00:05:20,720 --> 00:05:25,039
as I said, we launched very recently. We

121
00:05:22,960 --> 00:05:26,479
have seven founding members. I've shown

122
00:05:25,039 --> 00:05:28,479
six over here. The seventh will be

123
00:05:26,479 --> 00:05:30,960
announced very very soon. Uh one of the

124
00:05:28,479 --> 00:05:33,759
things that you'll see okay is that

125
00:05:30,960 --> 00:05:36,320
these guys run the gamut from on the one

126
00:05:33,759 --> 00:05:38,800
hand open AI uh that needs no

127
00:05:36,320 --> 00:05:41,360
introduction uh right to the other hand

128
00:05:38,800 --> 00:05:42,479
uh to the other side you know Coca-Cola

129
00:05:41,360 --> 00:05:45,039
and so you look at a company like

130
00:05:42,479 --> 00:05:47,199
Coca-Cola and you ask yourself hey what

131
00:05:45,039 --> 00:05:49,039
what is you know what does Coca-Cola

132
00:05:47,199 --> 00:05:51,440
have to do with generative AI and it

133
00:05:49,039 --> 00:05:53,919
turns out that Coca-Cola cares very

134
00:05:51,440 --> 00:05:55,199
deeply about citrus greening okay what

135
00:05:53,919 --> 00:05:56,880
is citrus greening I didn't know what

136
00:05:55,199 --> 00:05:57,759
this was I learned what this was a few

137
00:05:56,880 --> 00:05:59,919
months ago

138
00:05:57,759 --> 00:06:02,960
uh but it's basically uh thinking

139
00:05:59,919 --> 00:06:05,039
through how we keep our citrus crops

140
00:06:02,960 --> 00:06:07,120
healthy. It turns out that with climate

141
00:06:05,039 --> 00:06:10,080
change and a whole bunch of other things

142
00:06:07,120 --> 00:06:12,560
uh this has been severely impacted and

143
00:06:10,080 --> 00:06:14,319
so Coca-Cola says well hey listen maybe

144
00:06:12,560 --> 00:06:16,400
Genai can help here. It can help with

145
00:06:14,319 --> 00:06:19,120
precision agriculture. It can help with

146
00:06:16,400 --> 00:06:21,280
thinking about uh you know how we

147
00:06:19,120 --> 00:06:22,520
actually invent perhaps new strains of

148
00:06:21,280 --> 00:06:25,840
of of of

149
00:06:22,520 --> 00:06:27,280
of oranges, right? And things like that.

150
00:06:25,840 --> 00:06:29,199
Uh and so as you can see this kind of

151
00:06:27,280 --> 00:06:31,120
runs the gamut. OpenAI on the one hand,

152
00:06:29,199 --> 00:06:32,639
you know, Coca-Cola on the other and a

153
00:06:31,120 --> 00:06:34,720
whole bunch of different uh folks in

154
00:06:32,639 --> 00:06:36,560
between. Okay. Uh what have these

155
00:06:34,720 --> 00:06:38,319
founding members uh you know actually

156
00:06:36,560 --> 00:06:41,199
done and what do they sort of get in

157
00:06:38,319 --> 00:06:43,199
return? Um so the key thing for any of

158
00:06:41,199 --> 00:06:45,919
these founding members is one they're

159
00:06:43,199 --> 00:06:48,080
huge financial supporters uh you know to

160
00:06:45,919 --> 00:06:50,400
this effort. Uh you know each of these

161
00:06:48,080 --> 00:06:51,840
guys has committed uh you know a couple

162
00:06:50,400 --> 00:06:54,319
million dollars a year for a period of

163
00:06:51,840 --> 00:06:56,560
two years. the seven of them. It funds a

164
00:06:54,319 --> 00:06:58,319
good amount of research. Uh you know

165
00:06:56,560 --> 00:07:00,560
what what what do they get in return?

166
00:06:58,319 --> 00:07:02,560
What they effectively get in return is a

167
00:07:00,560 --> 00:07:05,360
seat at the table essentially

168
00:07:02,560 --> 00:07:08,000
influencing in a very very strong way

169
00:07:05,360 --> 00:07:09,680
our agenda. Okay. Here in terms of what

170
00:07:08,000 --> 00:07:11,919
we do for research and you'll kind of

171
00:07:09,680 --> 00:07:15,039
see how that that that works in very

172
00:07:11,919 --> 00:07:17,759
specific terms in in in a second. Okay.

173
00:07:15,039 --> 00:07:19,199
Um there's also uh you know a deep

174
00:07:17,759 --> 00:07:20,720
connection with all the education

175
00:07:19,199 --> 00:07:22,240
happening at MIT. One of the things we

176
00:07:20,720 --> 00:07:24,800
heard from many of these founding

177
00:07:22,240 --> 00:07:27,599
members uh was sort of the need to kind

178
00:07:24,800 --> 00:07:28,960
of educate themselves as corporations

179
00:07:27,599 --> 00:07:30,479
around how they ought to be thinking

180
00:07:28,960 --> 00:07:31,520
about generative AI, how they ought to

181
00:07:30,479 --> 00:07:34,319
be thinking about generative AI

182
00:07:31,520 --> 00:07:36,639
strategy. Um and even educating their

183
00:07:34,319 --> 00:07:39,360
workforces to some extent uh and we're

184
00:07:36,639 --> 00:07:41,360
helping a lot with that as we sort of as

185
00:07:39,360 --> 00:07:43,440
this grows uh you know we've kind of

186
00:07:41,360 --> 00:07:45,520
closed at these seven founding members.

187
00:07:43,440 --> 00:07:47,360
Uh we just sort of kept it at that. Uh

188
00:07:45,520 --> 00:07:50,080
in fact our goal was five founding

189
00:07:47,360 --> 00:07:52,319
members but it ended up being seven. uh

190
00:07:50,080 --> 00:07:55,440
what we're going to do uh starting later

191
00:07:52,319 --> 00:07:57,520
this year uh is sort of opening up uh

192
00:07:55,440 --> 00:07:59,360
you know the gates to a broader group of

193
00:07:57,520 --> 00:08:01,680
participation from companies. So there's

194
00:07:59,360 --> 00:08:04,240
a whole bunch of companies on this list

195
00:08:01,680 --> 00:08:06,400
uh that that didn't sort of make it into

196
00:08:04,240 --> 00:08:08,240
this sort of founding pool. Uh but

197
00:08:06,400 --> 00:08:10,160
really you know we call these innovation

198
00:08:08,240 --> 00:08:11,599
members. This is going to start uh

199
00:08:10,160 --> 00:08:13,759
beginning year two. So we'll start

200
00:08:11,599 --> 00:08:16,160
recruiting these folks actively uh you

201
00:08:13,759 --> 00:08:17,360
know later uh later this year. Um, and

202
00:08:16,160 --> 00:08:19,280
the idea is to kind of grow the

203
00:08:17,360 --> 00:08:21,919
membership here to something significant

204
00:08:19,280 --> 00:08:24,560
where again really the the the back and

205
00:08:21,919 --> 00:08:26,639
forth is that all of these folks get to

206
00:08:24,560 --> 00:08:29,919
influence the research we're doing here

207
00:08:26,639 --> 00:08:32,880
at MIT in a highly non-trivial way.

208
00:08:29,919 --> 00:08:34,479
Okay. So, um, I'd like to do two things,

209
00:08:32,880 --> 00:08:36,159
right? First, I'd like to tell you a

210
00:08:34,479 --> 00:08:38,000
little bit about the leadership of this

211
00:08:36,159 --> 00:08:40,399
initiative of magic. Like, there's a lot

212
00:08:38,000 --> 00:08:41,360
of people at MIT involved in this and I

213
00:08:40,399 --> 00:08:43,360
want to tell you a little bit about

214
00:08:41,360 --> 00:08:44,880
that. Uh and then the second thing I'd

215
00:08:43,360 --> 00:08:46,800
like to tell you about is what we've

216
00:08:44,880 --> 00:08:48,560
actually done so far. Okay. So in terms

217
00:08:46,800 --> 00:08:50,640
of our process of how we're making

218
00:08:48,560 --> 00:08:52,880
research happen around campus, this very

219
00:08:50,640 --> 00:08:54,240
interdisciplinary research that's impact

220
00:08:52,880 --> 00:08:56,480
driven. What are we doing? I'm going to

221
00:08:54,240 --> 00:08:58,240
talk about that. Okay. So in terms of

222
00:08:56,480 --> 00:09:00,880
the membership, I know you heard from

223
00:08:58,240 --> 00:09:02,640
Dan this morning. Uh but uh you know at

224
00:09:00,880 --> 00:09:05,680
the top we sort of have a deans

225
00:09:02,640 --> 00:09:07,360
oversight group uh led by uh our dean of

226
00:09:05,680 --> 00:09:11,839
engineering Ananta Chandra Kasan. So

227
00:09:07,360 --> 00:09:14,000
Ananta was in fact you know crucial in

228
00:09:11,839 --> 00:09:15,279
really the idea of magic getting this

229
00:09:14,000 --> 00:09:17,760
off the ground and a lot of the

230
00:09:15,279 --> 00:09:19,440
fundraising and so on and so forth. Uh

231
00:09:17,760 --> 00:09:22,160
right in the middle you have uh two

232
00:09:19,440 --> 00:09:24,640
faculty co-directors uh myself and my

233
00:09:22,160 --> 00:09:25,920
colleague Tim Kroska and CESO uh and

234
00:09:24,640 --> 00:09:27,440
then there's a whole bunch of folks

235
00:09:25,920 --> 00:09:29,920
around campus involved in a whole bunch

236
00:09:27,440 --> 00:09:32,080
of different activities. Okay. Uh

237
00:09:29,920 --> 00:09:35,080
ranging from effectively you know

238
00:09:32,080 --> 00:09:37,760
education to undergraduate outreach to

239
00:09:35,080 --> 00:09:40,560
really hiring and things like that.

240
00:09:37,760 --> 00:09:42,240
Okay. U so that's kind of the leadership

241
00:09:40,560 --> 00:09:44,320
and what I'd like to tell you about la

242
00:09:42,240 --> 00:09:46,160
you know next is really what we've been

243
00:09:44,320 --> 00:09:48,279
up to. Okay. What what have we been

244
00:09:46,160 --> 00:09:50,640
doing? what is our you know what's our

245
00:09:48,279 --> 00:09:54,480
2025 outline of goals to kind of give

246
00:09:50,640 --> 00:09:56,640
you a sense okay so uh as I said we

247
00:09:54,480 --> 00:09:59,040
launched very recently barely a month

248
00:09:56,640 --> 00:10:02,560
ago okay so we launched in February that

249
00:09:59,040 --> 00:10:04,720
was our sort of big launch event um and

250
00:10:02,560 --> 00:10:08,560
essentially in February we reached out

251
00:10:04,720 --> 00:10:11,440
to all of campus and we said hey look

252
00:10:08,560 --> 00:10:13,760
we've built this consortium and our job

253
00:10:11,440 --> 00:10:15,920
really our key job as part of this

254
00:10:13,760 --> 00:10:17,760
consortium is to drive interdisciplinary

255
00:10:15,920 --> 00:10:19,920
research across campus, right? Like high

256
00:10:17,760 --> 00:10:22,399
impact interdiciplinary research. And so

257
00:10:19,920 --> 00:10:24,000
we launched a call for proposals. Uh

258
00:10:22,399 --> 00:10:26,000
that call of call for proposals I'm

259
00:10:24,000 --> 00:10:28,560
going to tell you about in a second.

260
00:10:26,000 --> 00:10:30,240
That call is going to fund 40 or 50 odd

261
00:10:28,560 --> 00:10:32,920
research projects that'll get announced.

262
00:10:30,240 --> 00:10:35,360
A first symposium and this is a

263
00:10:32,920 --> 00:10:38,079
researchoriented symposium will happen

264
00:10:35,360 --> 00:10:40,320
in early May. Okay. uh and then

265
00:10:38,079 --> 00:10:42,839
following that in uh in later in

266
00:10:40,320 --> 00:10:45,040
September we'll have a much larger

267
00:10:42,839 --> 00:10:47,360
symposium again kind of focused on

268
00:10:45,040 --> 00:10:50,240
research but much broader sort of impact

269
00:10:47,360 --> 00:10:51,680
around that research okay uh so as you

270
00:10:50,240 --> 00:10:54,000
can sort of see the center of all of

271
00:10:51,680 --> 00:10:56,079
this is around basically doing high

272
00:10:54,000 --> 00:10:58,880
impact research how has that worked what

273
00:10:56,079 --> 00:11:01,200
has our process been uh right so this is

274
00:10:58,880 --> 00:11:03,680
this is really what that process is okay

275
00:11:01,200 --> 00:11:06,720
so one of the key missions of this

276
00:11:03,680 --> 00:11:09,680
impact consortium is this you know seed

277
00:11:06,720 --> 00:11:12,640
funding program that funds research. Um

278
00:11:09,680 --> 00:11:14,480
the idea is we want to open source all

279
00:11:12,640 --> 00:11:18,079
of the work that comes out of this to

280
00:11:14,480 --> 00:11:20,640
the entire world. It's open to all, you

281
00:11:18,079 --> 00:11:23,279
know, every lab essentially all sort of

282
00:11:20,640 --> 00:11:25,680
um uh uh principal investigators around

283
00:11:23,279 --> 00:11:27,279
campus, all researchers around campus.

284
00:11:25,680 --> 00:11:29,440
Um and in particular, one of the things

285
00:11:27,279 --> 00:11:31,120
I'll I've noticed in this first batch of

286
00:11:29,440 --> 00:11:33,200
submissions that we got is that the

287
00:11:31,120 --> 00:11:34,399
teams are very very multi-disiplinary.

288
00:11:33,200 --> 00:11:35,760
Okay? And I'll I'll tell you a little

289
00:11:34,399 --> 00:11:38,160
bit in a second about the kind of work

290
00:11:35,760 --> 00:11:40,000
they've proposed. There's a whole bunch

291
00:11:38,160 --> 00:11:42,000
of thematic areas associated with this.

292
00:11:40,000 --> 00:11:44,079
AI for science, for engineering, for

293
00:11:42,000 --> 00:11:46,800
business, for education, uh you know,

294
00:11:44,079 --> 00:11:50,160
and so forth. And essentially what we're

295
00:11:46,800 --> 00:11:52,160
funding is, you know, 40 roughly 40 uh

296
00:11:50,160 --> 00:11:54,079
might be a little bit more than this uh

297
00:11:52,160 --> 00:11:56,240
you know, one-year projects where the

298
00:11:54,079 --> 00:11:58,160
idea is that these serve as seed grants

299
00:11:56,240 --> 00:11:59,760
to get these projects off the ground.

300
00:11:58,160 --> 00:12:02,079
And you know the money for a single

301
00:11:59,760 --> 00:12:04,480
project ranges anywhere from 50 to to

302
00:12:02,079 --> 00:12:06,560
300k with the median the sweet spot

303
00:12:04,480 --> 00:12:09,120
being roughly around 150k for most

304
00:12:06,560 --> 00:12:10,720
projects. Okay. Uh so what's our

305
00:12:09,120 --> 00:12:13,120
progress so far? What have we done? As I

306
00:12:10,720 --> 00:12:14,399
said this is like really fresh off the

307
00:12:13,120 --> 00:12:16,079
press, right? Like everything's moving

308
00:12:14,399 --> 00:12:18,399
really fast. We have to mobilize really

309
00:12:16,079 --> 00:12:19,920
fast and so all this is really quick uh

310
00:12:18,399 --> 00:12:22,160
and moving very quickly. So we had our

311
00:12:19,920 --> 00:12:24,160
launch event in February. Uh we had

312
00:12:22,160 --> 00:12:26,800
about 600 odd attendees to this launch

313
00:12:24,160 --> 00:12:28,800
event. Um, and then March 7th, we had a

314
00:12:26,800 --> 00:12:30,480
proposal, a call for proposals, right? A

315
00:12:28,800 --> 00:12:34,000
call for these these these seed

316
00:12:30,480 --> 00:12:36,880
proposals. We got 180 research proposals

317
00:12:34,000 --> 00:12:39,600
from 180 different research teams around

318
00:12:36,880 --> 00:12:41,519
campus. Okay, so this is like 180 labs

319
00:12:39,600 --> 00:12:43,920
across campus that want to be part of

320
00:12:41,519 --> 00:12:45,760
this. Okay, there's a whole bunch of

321
00:12:43,920 --> 00:12:47,680
research that's represented over here.

322
00:12:45,760 --> 00:12:49,519
Okay, uh, you know, there's folks that

323
00:12:47,680 --> 00:12:51,360
care about doing generative AI and the

324
00:12:49,519 --> 00:12:52,959
healthcare value chain. There's folks

325
00:12:51,360 --> 00:12:54,320
that are thinking about generative AI

326
00:12:52,959 --> 00:12:56,639
and how it's going to transform

327
00:12:54,320 --> 00:12:58,160
education as a whole. Uh there's folks

328
00:12:56,639 --> 00:12:59,600
that are thinking about generative AI

329
00:12:58,160 --> 00:13:00,959
and bioengineering and chemical

330
00:12:59,600 --> 00:13:02,160
engineering and so on and so forth.

331
00:13:00,959 --> 00:13:03,360
Right? This relates somewhat to that

332
00:13:02,160 --> 00:13:06,160
citrus green screening thing I talked

333
00:13:03,360 --> 00:13:07,519
about but so much more. Uh there are

334
00:13:06,160 --> 00:13:10,519
folks thinking about the transformation

335
00:13:07,519 --> 00:13:13,600
of work. Okay. So as we sort of think

336
00:13:10,519 --> 00:13:16,240
about really every job ranging from the

337
00:13:13,600 --> 00:13:18,000
software engineer on the one hand to uh

338
00:13:16,240 --> 00:13:21,040
doctors and nurses and whatever on the

339
00:13:18,000 --> 00:13:22,480
other uh what are the problems gerine to

340
00:13:21,040 --> 00:13:24,320
that kind of transformation and the

341
00:13:22,480 --> 00:13:26,240
problems people are thinking about uh

342
00:13:24,320 --> 00:13:28,880
sort of run the gamut okay from very

343
00:13:26,240 --> 00:13:31,519
technological issues right to building

344
00:13:28,880 --> 00:13:34,720
agents building robust agents so on and

345
00:13:31,519 --> 00:13:36,720
so forth on the one hand um to strategic

346
00:13:34,720 --> 00:13:38,160
issues right how do how do we think

347
00:13:36,720 --> 00:13:39,760
about a workforce that's being

348
00:13:38,160 --> 00:13:40,880
transformed what does one need to do

349
00:13:39,760 --> 00:13:42,399
with a workforce that's being

350
00:13:40,880 --> 00:13:46,160
transformed and so on and so forth.

351
00:13:42,399 --> 00:13:48,320
Okay. Um so right we've gotten a whole

352
00:13:46,160 --> 00:13:50,880
bunch of these as I said we'll fund

353
00:13:48,320 --> 00:13:54,399
roughly about 40 to 50 of these of these

354
00:13:50,880 --> 00:13:57,360
of these proposals. Um and our goal okay

355
00:13:54,399 --> 00:14:00,480
is at a high level to make this

356
00:13:57,360 --> 00:14:04,079
essentially the engine okay of high

357
00:14:00,480 --> 00:14:07,199
impact genai research on campus here at

358
00:14:04,079 --> 00:14:09,399
MIT. Okay. Driven by sort of the need uh

359
00:14:07,199 --> 00:14:11,680
as I said earlier for highly

360
00:14:09,399 --> 00:14:13,680
interdicciplinary high impact work.

361
00:14:11,680 --> 00:14:16,560
Okay. The last thing I will say and then

362
00:14:13,680 --> 00:14:18,079
I'm going to end over here right uh is

363
00:14:16,560 --> 00:14:20,959
you know for those of you that are at

364
00:14:18,079 --> 00:14:24,720
companies where this might be something

365
00:14:20,959 --> 00:14:27,279
of interest to you um let me let me just

366
00:14:24,720 --> 00:14:30,320
sort of give you a somewhat quick

367
00:14:27,279 --> 00:14:32,240
picture of what this what it means to

368
00:14:30,320 --> 00:14:33,920
participate in this program. Okay. what

369
00:14:32,240 --> 00:14:36,560
does it mean for the company and what

370
00:14:33,920 --> 00:14:38,399
does it mean for MIT? So uh you know

371
00:14:36,560 --> 00:14:39,920
I've already sort of mentioned uh you

372
00:14:38,399 --> 00:14:42,079
know the the inaugural founding members

373
00:14:39,920 --> 00:14:43,600
that pro that part's done right we have

374
00:14:42,079 --> 00:14:45,760
our group of founding members we've

375
00:14:43,600 --> 00:14:47,760
formed that that part's over the next

376
00:14:45,760 --> 00:14:49,440
step is bringing on these innovation

377
00:14:47,760 --> 00:14:52,240
members that I that I've talked about we

378
00:14:49,440 --> 00:14:54,160
have a very big list um what does this

379
00:14:52,240 --> 00:14:57,279
you know what does this involve uh one

380
00:14:54,160 --> 00:15:00,079
this involves uh for you the ability to

381
00:14:57,279 --> 00:15:02,399
effectively deeply influence the work

382
00:15:00,079 --> 00:15:04,800
happening on campus. Okay. Our founding

383
00:15:02,399 --> 00:15:06,639
members contributed a whole bunch of

384
00:15:04,800 --> 00:15:08,240
problems that they thought would be

385
00:15:06,639 --> 00:15:09,680
valuable to them. I gave you one

386
00:15:08,240 --> 00:15:12,560
example, the citrus screening, but there

387
00:15:09,680 --> 00:15:14,160
was a long long list. Okay. Uh and to

388
00:15:12,560 --> 00:15:15,680
folks on campus, this was very exciting,

389
00:15:14,160 --> 00:15:17,199
right? You say, "Hey, like this is

390
00:15:15,680 --> 00:15:19,000
something that's going to deeply impact

391
00:15:17,199 --> 00:15:21,199
and influence the work at these

392
00:15:19,000 --> 00:15:22,880
companies." It'll be the same thing for

393
00:15:21,199 --> 00:15:24,399
the innovation members. Okay? So, in

394
00:15:22,880 --> 00:15:26,720
essence, the big thing you get out of

395
00:15:24,399 --> 00:15:28,959
this is the ability to deeply influence

396
00:15:26,720 --> 00:15:31,440
work on campus. Okay? In a in a very

397
00:15:28,959 --> 00:15:32,639
direct kind of way. All right. the the

398
00:15:31,440 --> 00:15:34,800
financial sort of level for

399
00:15:32,639 --> 00:15:37,120
participation is much lower uh you know

400
00:15:34,800 --> 00:15:38,959
as as an innovation member um and as

401
00:15:37,120 --> 00:15:40,959
such we're looking to to bring in a much

402
00:15:38,959 --> 00:15:42,959
larger a much larger group and of course

403
00:15:40,959 --> 00:15:44,800
you know I'm here representing MIT what

404
00:15:42,959 --> 00:15:47,199
does this represent for MIT what this

405
00:15:44,800 --> 00:15:50,560
represents for MIT is is our ability to

406
00:15:47,199 --> 00:15:52,399
continue doing uh super impactful work

407
00:15:50,560 --> 00:15:54,959
uh that is not siloed that is

408
00:15:52,399 --> 00:15:57,440
crosscutting across campus um and that

409
00:15:54,959 --> 00:16:00,160
speaks very very strongly to uh high

410
00:15:57,440 --> 00:16:02,320
impact as defined by you know some of

411
00:16:00,160 --> 00:16:04,480
our uh some of our partner members. And

412
00:16:02,320 --> 00:16:06,880
so that's kind of what I had over here.

413
00:16:04,480 --> 00:16:08,160
Um you know, I'm happy to sort of uh

414
00:16:06,880 --> 00:16:12,600
happy to sort of go with questions.

415
00:16:08,160 --> 00:16:15,199
Should I take them from here? Okay.

416
00:16:12,600 --> 00:16:17,560
So, okay. So, the first question is why

417
00:16:15,199 --> 00:16:19,639
can't AI generate reasonable images and

418
00:16:17,560 --> 00:16:22,240
depictions with text that's not

419
00:16:19,639 --> 00:16:23,440
distorted? Uh I think that's a

420
00:16:22,240 --> 00:16:24,480
conversation for a different day, but

421
00:16:23,440 --> 00:16:26,800
that's actually changed pretty

422
00:16:24,480 --> 00:16:30,199
dramatically as of a week ago. Uh

423
00:16:26,800 --> 00:16:32,880
there's a new model that OpenAI uh

424
00:16:30,199 --> 00:16:35,079
announced. Let's see. How will magic

425
00:16:32,880 --> 00:16:37,839
influence the integration of current

426
00:16:35,079 --> 00:16:39,839
technologies to license, track, and site

427
00:16:37,839 --> 00:16:41,880
copyrighted materials that have been

428
00:16:39,839 --> 00:16:46,560
invested with or without permissions in

429
00:16:41,880 --> 00:16:49,680
LLMs? Yeah. So, um look, um I think this

430
00:16:46,560 --> 00:16:52,279
is a great question. Uh I think really

431
00:16:49,680 --> 00:16:54,720
what you're speaking to over here

432
00:16:52,279 --> 00:16:56,959
is it's a little bit of the wild wild

433
00:16:54,720 --> 00:17:00,000
west, right? with what's happening with

434
00:16:56,959 --> 00:17:02,560
uh with with large language models u and

435
00:17:00,000 --> 00:17:05,360
it's sort of really disrupting a bunch

436
00:17:02,560 --> 00:17:07,360
of value chains. So like yesterday uh I

437
00:17:05,360 --> 00:17:10,240
spoke with uh the founder of a company

438
00:17:07,360 --> 00:17:12,559
called Tolbit uh that basically is sort

439
00:17:10,240 --> 00:17:15,439
of asking the question of listen you

440
00:17:12,559 --> 00:17:17,520
know as a publisher and this question

441
00:17:15,439 --> 00:17:20,559
really relates quite a bit to publishers

442
00:17:17,520 --> 00:17:22,799
as a publisher right um you know it used

443
00:17:20,559 --> 00:17:24,640
to be that uh there were very fairly

444
00:17:22,799 --> 00:17:26,799
well-established value chains with how

445
00:17:24,640 --> 00:17:28,720
you generated money for the content you

446
00:17:26,799 --> 00:17:30,960
produced right broadly driven by

447
00:17:28,720 --> 00:17:32,960
advertising and things like this in a

448
00:17:30,960 --> 00:17:34,160
world where you go to perplexity or

449
00:17:32,960 --> 00:17:36,080
something like that to get your

450
00:17:34,160 --> 00:17:37,520
information. You know, how how do how do

451
00:17:36,080 --> 00:17:39,039
things work over there? What what are

452
00:17:37,520 --> 00:17:40,400
the economics of this, right? Because

453
00:17:39,039 --> 00:17:42,799
nobody shows up on your site anymore.

454
00:17:40,400 --> 00:17:44,880
How do we think about this? Um my belief

455
00:17:42,799 --> 00:17:46,640
is that a lot of the work we do as part

456
00:17:44,880 --> 00:17:48,559
of this, a lot of the work we fund

457
00:17:46,640 --> 00:17:50,400
because of its crosscutting nature will

458
00:17:48,559 --> 00:17:52,559
hopefully influence answers to questions

459
00:17:50,400 --> 00:17:54,080
like this. The conferences that we, you

460
00:17:52,559 --> 00:17:56,160
know, so a big part of our mission is

461
00:17:54,080 --> 00:17:58,880
organizing a sequence of conferences,

462
00:17:56,160 --> 00:18:01,280
right? Um and this is exactly the kind

463
00:17:58,880 --> 00:18:02,640
of this is exactly the kind of topic uh

464
00:18:01,280 --> 00:18:04,520
that some of these conferences can

465
00:18:02,640 --> 00:18:09,559
actually focus

466
00:18:04,520 --> 00:18:09,559
on. Thank you very much. Thanks.


1
00:00:01,079 --> 00:00:06,960
welcome to the second part of the deep

2
00:00:03,320 --> 00:00:09,960
learning uh day and this second part is

3
00:00:06,960 --> 00:00:11,440
going to focus more on you know given

4
00:00:09,960 --> 00:00:13,280
all the tools that you have seen this

5
00:00:11,440 --> 00:00:14,599
morning how do we build systems around

6
00:00:13,280 --> 00:00:18,840
them and the type of things that you can

7
00:00:14,599 --> 00:00:20,480
do and in this particular hour well 45

8
00:00:18,840 --> 00:00:22,800
minutes so that I will be talking I'm

9
00:00:20,480 --> 00:00:25,800
going to focus on agents which is a kind

10
00:00:22,800 --> 00:00:27,560
of Il defined concept so you know at the

11
00:00:25,800 --> 00:00:30,320
end of these 45 minutes you will be

12
00:00:27,560 --> 00:00:32,840
equally confused don't worry about that

13
00:00:30,320 --> 00:00:35,920
um and and I wanted to just give you a

14
00:00:32,840 --> 00:00:38,680
couple of examples of agents that I find

15
00:00:35,920 --> 00:00:40,559
interesting so the first thing is that

16
00:00:38,680 --> 00:00:42,079
you know when when some of us started

17
00:00:40,559 --> 00:00:44,600
working on the field in particular when

18
00:00:42,079 --> 00:00:47,480
I started around the decade of you know

19
00:00:44,600 --> 00:00:51,680
the year 2000 and so on it was what we

20
00:00:47,480 --> 00:00:53,120
call the Benchmark Golden Era we have a

21
00:00:51,680 --> 00:00:55,359
images for instance if you were building

22
00:00:53,120 --> 00:00:57,800
a computer vision system we had

23
00:00:55,359 --> 00:01:00,199
databases where every single object was

24
00:00:57,800 --> 00:01:02,399
annotated we knew exactly what the

25
00:01:00,199 --> 00:01:04,400
ground truth was we knew what had to be

26
00:01:02,399 --> 00:01:06,760
done there were data sets with lots of

27
00:01:04,400 --> 00:01:10,040
images all annotated According to some

28
00:01:06,760 --> 00:01:12,280
criteria and that allow us to evaluate

29
00:01:10,040 --> 00:01:14,159
algorithms and you could rank them which

30
00:01:12,280 --> 00:01:16,119
one was better which one was worse you

31
00:01:14,159 --> 00:01:18,360
know things were very easy you know you

32
00:01:16,119 --> 00:01:20,560
could take a picture like this one here

33
00:01:18,360 --> 00:01:22,400
run the state-of-the-art computer vision

34
00:01:20,560 --> 00:01:24,400
algorithm at the time ask what is the

35
00:01:22,400 --> 00:01:27,159
content of this picture and the output

36
00:01:24,400 --> 00:01:29,280
was this and you knew this was wrong

37
00:01:27,159 --> 00:01:32,479
everybody will agree with that and you

38
00:01:29,280 --> 00:01:34,520
know minus one point for this detector

39
00:01:32,479 --> 00:01:37,159
and everything everything was very very

40
00:01:34,520 --> 00:01:39,159
clear we are not we are not living in

41
00:01:37,159 --> 00:01:41,840
that time anymore we have models that

42
00:01:39,159 --> 00:01:44,920
can do all kinds of very sophisticated

43
00:01:41,840 --> 00:01:46,840
things and it is really hard to valuate

44
00:01:44,920 --> 00:01:49,479
how they how good they are in fact it's

45
00:01:46,840 --> 00:01:52,159
an open area of research to try to find

46
00:01:49,479 --> 00:01:55,479
ways of evaluating these systems to tell

47
00:01:52,159 --> 00:01:57,759
which one is better than which one and

48
00:01:55,479 --> 00:02:00,200
you know as Philip was showing this

49
00:01:57,759 --> 00:02:03,520
morning there's been a revolution on the

50
00:02:00,200 --> 00:02:05,960
speed of how advances are happening from

51
00:02:03,520 --> 00:02:08,720
the 60s to the year 2000 basically we

52
00:02:05,960 --> 00:02:10,879
went from very simple neural networks to

53
00:02:08,720 --> 00:02:13,040
the first pH detection systems that

54
00:02:10,879 --> 00:02:14,760
actually kind of worked but in the last

55
00:02:13,040 --> 00:02:17,440
decade we had like an acceleration of

56
00:02:14,760 --> 00:02:20,000
all kinds of systems converging to the

57
00:02:17,440 --> 00:02:22,080
large language models that we have today

58
00:02:20,000 --> 00:02:24,640
and they can do all kinds of things know

59
00:02:22,080 --> 00:02:26,720
you can use chpt for many many things

60
00:02:24,640 --> 00:02:29,400
that are really interesting here is an

61
00:02:26,720 --> 00:02:32,120
example of asking chip to solve a high

62
00:02:29,400 --> 00:02:35,560
school math problem where you say well

63
00:02:32,120 --> 00:02:38,360
there is a treasure hunter found a a a

64
00:02:35,560 --> 00:02:40,840
chest filled up with gems there are 175

65
00:02:38,360 --> 00:02:44,040
diamonds and so on and so on how many

66
00:02:40,840 --> 00:02:46,319
gems are in the chest and CH GPT gives

67
00:02:44,040 --> 00:02:48,680
you just an answer with your beautiful

68
00:02:46,319 --> 00:02:50,560
reasoning explaining all the different

69
00:02:48,680 --> 00:02:52,599
equations that you need to think about

70
00:02:50,560 --> 00:02:54,360
where the unknowns are and at the end it

71
00:02:52,599 --> 00:02:55,800
tells you there are the total number of

72
00:02:54,360 --> 00:02:58,280
gems are

73
00:02:55,800 --> 00:03:00,400
225 which is wrong but who cares you

74
00:02:58,280 --> 00:03:02,360
know it's so beautifully written you

75
00:03:00,400 --> 00:03:04,519
it's better written than the question

76
00:03:02,360 --> 00:03:05,680
itself so it's just amazing what the

77
00:03:04,519 --> 00:03:08,879
systems can

78
00:03:05,680 --> 00:03:10,440
do so the ne the the thing that is

79
00:03:08,879 --> 00:03:12,120
happening now that everybody is very

80
00:03:10,440 --> 00:03:14,879
excited about at least for the last two

81
00:03:12,120 --> 00:03:17,239
years now is AI agents and I think this

82
00:03:14,879 --> 00:03:19,280
will remain a very hot topic for the

83
00:03:17,239 --> 00:03:22,080
future and by the future I means the

84
00:03:19,280 --> 00:03:25,760
next six months more or

85
00:03:22,080 --> 00:03:27,680
less so what is that has enabled agents

86
00:03:25,760 --> 00:03:30,760
to appear I think there are a number of

87
00:03:27,680 --> 00:03:33,120
different aspects that uh build what is

88
00:03:30,760 --> 00:03:35,000
the infrastructure of an agent one is

89
00:03:33,120 --> 00:03:37,480
the fact that these models like chpt and

90
00:03:35,000 --> 00:03:39,159
so on they are not unimodel anymore they

91
00:03:37,480 --> 00:03:41,319
are not models that only deal with

92
00:03:39,159 --> 00:03:43,879
language you can actually mix different

93
00:03:41,319 --> 00:03:46,560
modalities for instance you can input

94
00:03:43,879 --> 00:03:50,640
text and a picture like in this case and

95
00:03:46,560 --> 00:03:53,640
you can ask GPT this is gptv what

96
00:03:50,640 --> 00:03:54,959
happened here and you know this is an NE

97
00:03:53,640 --> 00:03:56,920
Network that will take everything as

98
00:03:54,959 --> 00:03:58,680
input images and text everything gets

99
00:03:56,920 --> 00:04:00,200
translated into tokens at the end

100
00:03:58,680 --> 00:04:01,959
everything is kind of the same and it

101
00:04:00,200 --> 00:04:03,959
will just generate an answer and this is

102
00:04:01,959 --> 00:04:06,079
the answer that it gave which is a

103
00:04:03,959 --> 00:04:08,159
pretty good description of what makes

104
00:04:06,079 --> 00:04:10,159
this picture interesting and it could

105
00:04:08,159 --> 00:04:12,120
have been describing what is happening

106
00:04:10,159 --> 00:04:13,840
on the background of the picture but no

107
00:04:12,120 --> 00:04:16,040
it did focus on the object that is

108
00:04:13,840 --> 00:04:18,440
actually interesting for us humans when

109
00:04:16,040 --> 00:04:20,400
you look at this picture you know the

110
00:04:18,440 --> 00:04:22,120
interesting thing is this car in the

111
00:04:20,400 --> 00:04:24,440
swimming pool and that's what chipit is

112
00:04:22,120 --> 00:04:24,440
talking

113
00:04:24,479 --> 00:04:29,120
about there is this you know I was

114
00:04:26,680 --> 00:04:30,360
showing also this example where you know

115
00:04:29,120 --> 00:04:33,080
you have this high high school math

116
00:04:30,360 --> 00:04:34,560
problem and CHP is wrong but there are

117
00:04:33,080 --> 00:04:35,880
also a number of other things that

118
00:04:34,560 --> 00:04:37,360
people have been discovering that you

119
00:04:35,880 --> 00:04:39,639
can do with these models to make them

120
00:04:37,360 --> 00:04:42,199
better besides just training them more

121
00:04:39,639 --> 00:04:44,000
and making them you bigger there are

122
00:04:42,199 --> 00:04:46,199
other things that you can do so for

123
00:04:44,000 --> 00:04:49,199
instance one thing that to students here

124
00:04:46,199 --> 00:04:50,720
at might did was to you know one thing

125
00:04:49,199 --> 00:04:52,960
that happens every time that you ask

126
00:04:50,720 --> 00:04:55,000
your GPT the same question it will

127
00:04:52,960 --> 00:04:56,560
always give you different answers

128
00:04:55,000 --> 00:04:58,199
because it's just sampling from the

129
00:04:56,560 --> 00:05:00,600
probability distribution of different

130
00:04:58,199 --> 00:05:02,440
words and will generate something

131
00:05:00,600 --> 00:05:04,080
different it might actually mean the

132
00:05:02,440 --> 00:05:06,800
same thing but it will have different

133
00:05:04,080 --> 00:05:09,800
wording in this particular case if you

134
00:05:06,800 --> 00:05:11,639
ask to solve this math problem to CH GPT

135
00:05:09,800 --> 00:05:14,199
the first time it gives you the answer

136
00:05:11,639 --> 00:05:15,759
that I showed you before which was wrong

137
00:05:14,199 --> 00:05:18,360
but the second time with a different

138
00:05:15,759 --> 00:05:20,639
instance the same model it just gives

139
00:05:18,360 --> 00:05:22,960
some something different and it actually

140
00:05:20,639 --> 00:05:24,919
happens to be right in this case you as

141
00:05:22,960 --> 00:05:26,639
a user you don't know which one is wrong

142
00:05:24,919 --> 00:05:28,840
or which one is right you just know that

143
00:05:26,639 --> 00:05:30,880
there are two different answers so one

144
00:05:28,840 --> 00:05:32,639
thing that you can have is to you can do

145
00:05:30,880 --> 00:05:35,800
is to have these two agents these two

146
00:05:32,639 --> 00:05:37,880
different language models debate between

147
00:05:35,800 --> 00:05:40,440
themselves so you can now take the

148
00:05:37,880 --> 00:05:43,600
second answer and just copy paste that

149
00:05:40,440 --> 00:05:47,039
text into the dialogue window of the

150
00:05:43,600 --> 00:05:48,880
first llm and tell the LM a different

151
00:05:47,039 --> 00:05:50,960
version of you say something different

152
00:05:48,880 --> 00:05:53,960
here it is and just copy pay the answer

153
00:05:50,960 --> 00:05:56,199
what do you think now so if you do that

154
00:05:53,960 --> 00:05:58,400
it changes its answer it Revis the

155
00:05:56,199 --> 00:06:00,840
answer and in this case agrees that the

156
00:05:58,400 --> 00:06:02,960
right one is the first is the one given

157
00:06:00,840 --> 00:06:04,360
by the second one because you don't know

158
00:06:02,960 --> 00:06:05,639
which one is right you just do the same

159
00:06:04,360 --> 00:06:07,960
thing with the second one with the

160
00:06:05,639 --> 00:06:10,039
second llm you do the same thing you

161
00:06:07,960 --> 00:06:12,479
copy paste the answer given by the first

162
00:06:10,039 --> 00:06:15,319
one and in this case it just still

163
00:06:12,479 --> 00:06:17,560
sticks to its answer so what they found

164
00:06:15,319 --> 00:06:19,880
is that when you have these interactions

165
00:06:17,560 --> 00:06:23,080
between agents they converge more likely

166
00:06:19,880 --> 00:06:26,599
than not to the correct

167
00:06:23,080 --> 00:06:28,360
answer so you can do this with all kinds

168
00:06:26,599 --> 00:06:31,520
of things here is you know trying to

169
00:06:28,360 --> 00:06:35,919
answer you know a question about

170
00:06:31,520 --> 00:06:38,120
uh some mathematical calculation and you

171
00:06:35,919 --> 00:06:41,440
know if you ask this to two different

172
00:06:38,120 --> 00:06:43,840
agents both get it wrong the first time

173
00:06:41,440 --> 00:06:45,360
but once you copy the answer to one

174
00:06:43,840 --> 00:06:46,759
between themselves they realize that

175
00:06:45,360 --> 00:06:49,039
there are other possible answers and

176
00:06:46,759 --> 00:06:51,599
they just start keeping keep revising

177
00:06:49,039 --> 00:06:53,720
their answers so in the second round the

178
00:06:51,599 --> 00:06:56,080
second one got it right and the first

179
00:06:53,720 --> 00:06:57,919
one still got it wrong you can do this

180
00:06:56,080 --> 00:07:00,240
again and again and eventually both of

181
00:06:57,919 --> 00:07:01,960
them converge to the right answer

182
00:07:00,240 --> 00:07:04,120
this is not always the case as you can

183
00:07:01,960 --> 00:07:06,319
imagine this is not always going to be

184
00:07:04,120 --> 00:07:08,039
working but what they showed is that the

185
00:07:06,319 --> 00:07:11,080
more agents you put together the more

186
00:07:08,039 --> 00:07:13,080
rounds there are performance seems to be

187
00:07:11,080 --> 00:07:15,240
improving and you know we haven't really

188
00:07:13,080 --> 00:07:16,759
seen a plateau here you keeps doing

189
00:07:15,240 --> 00:07:18,199
better and better but of course this is

190
00:07:16,759 --> 00:07:21,319
going to Plateau there is so much more

191
00:07:18,199 --> 00:07:23,560
you can do but this is an example of

192
00:07:21,319 --> 00:07:25,360
where creating a society where you have

193
00:07:23,560 --> 00:07:26,560
a few different language models

194
00:07:25,360 --> 00:07:28,639
interacting with each other you can

195
00:07:26,560 --> 00:07:31,080
build something that works better than

196
00:07:28,639 --> 00:07:33,800
each of them in is

197
00:07:31,080 --> 00:07:35,680
ation we have seen also that you can use

198
00:07:33,800 --> 00:07:38,199
these language models to do to write

199
00:07:35,680 --> 00:07:41,479
code and this is another very important

200
00:07:38,199 --> 00:07:44,240
piece that will allow systems to become

201
00:07:41,479 --> 00:07:46,080
agents where you can give an instruction

202
00:07:44,240 --> 00:07:49,159
you give an a specification of something

203
00:07:46,080 --> 00:07:51,240
you want to do and the llm IT outputs

204
00:07:49,159 --> 00:07:53,560
code that you know if you run it

205
00:07:51,240 --> 00:07:57,000
supposedly it will actually do what you

206
00:07:53,560 --> 00:07:59,599
know what you ask it to so this coding

207
00:07:57,000 --> 00:08:02,599
capability is actually a very powerful

208
00:07:59,599 --> 00:08:04,360
way of then having this llm to be able

209
00:08:02,599 --> 00:08:05,879
to actually interact with the world

210
00:08:04,360 --> 00:08:07,960
because once you write code you can

211
00:08:05,879 --> 00:08:11,960
execute that code and that code can

212
00:08:07,960 --> 00:08:14,879
perform operations in the physical

213
00:08:11,960 --> 00:08:16,680
world so you know these language models

214
00:08:14,879 --> 00:08:18,400
are very powerful you know for instance

215
00:08:16,680 --> 00:08:21,159
in coding they are amazing you can go

216
00:08:18,400 --> 00:08:24,080
just the chpt you ask it to you know

217
00:08:21,159 --> 00:08:26,319
write a Matlab script that draws a

218
00:08:24,080 --> 00:08:28,000
bouncing ball inside a square which is a

219
00:08:26,319 --> 00:08:29,919
very typical problem that you know you

220
00:08:28,000 --> 00:08:31,440
do when you are trying to learn coding

221
00:08:29,919 --> 00:08:34,120
and you know this is what the output is

222
00:08:31,440 --> 00:08:37,159
supposed to be just a ball bouncing on

223
00:08:34,120 --> 00:08:39,959
inside a square if you ask this chpt

224
00:08:37,159 --> 00:08:41,680
gives you a script that you know it

225
00:08:39,959 --> 00:08:43,279
looks pretty good with comments and

226
00:08:41,680 --> 00:08:45,080
everything and if you take this and copy

227
00:08:43,279 --> 00:08:47,760
paste it on the M lab window and you run

228
00:08:45,080 --> 00:08:50,640
it indeed this is you know the result it

229
00:08:47,760 --> 00:08:52,519
works really well so you know one can

230
00:08:50,640 --> 00:08:54,720
think these language models are amazing

231
00:08:52,519 --> 00:08:56,720
how they do this well another very

232
00:08:54,720 --> 00:08:58,519
important thing not to forget about is

233
00:08:56,720 --> 00:09:01,200
that these models are trained with a lot

234
00:08:58,519 --> 00:09:03,680
of data and sometimes the power of these

235
00:09:01,200 --> 00:09:06,240
models is not really the model itself

236
00:09:03,680 --> 00:09:09,000
it's the data so in fact you go to

237
00:09:06,240 --> 00:09:11,399
Google and you ask for you know examples

238
00:09:09,000 --> 00:09:13,360
of mlap scripts of bouncing balls inside

239
00:09:11,399 --> 00:09:16,320
the squares you get tons of different

240
00:09:13,360 --> 00:09:18,600
examples and you know CH GPT has learned

241
00:09:16,320 --> 00:09:20,279
from all of those so it's the web

242
00:09:18,600 --> 00:09:22,519
contains a lot of information these

243
00:09:20,279 --> 00:09:24,800
models have been trained with an amount

244
00:09:22,519 --> 00:09:26,640
of data that is just so much bigger than

245
00:09:24,800 --> 00:09:29,160
the amount of data that you have seen in

246
00:09:26,640 --> 00:09:32,000
your life that it's just hard for us to

247
00:09:29,160 --> 00:09:34,600
write our hands our heads around you

248
00:09:32,000 --> 00:09:37,560
know how much data they have

249
00:09:34,600 --> 00:09:39,240
seen these models have all kinds of

250
00:09:37,560 --> 00:09:41,279
really interesting properties for

251
00:09:39,240 --> 00:09:43,240
instance the generative models that K

252
00:09:41,279 --> 00:09:45,279
was describing they show some

253
00:09:43,240 --> 00:09:48,279
interesting uh compositional

254
00:09:45,279 --> 00:09:50,880
capabilities for instance if you ask a

255
00:09:48,279 --> 00:09:52,959
image generative model like Del to draw

256
00:09:50,880 --> 00:09:54,800
an image of a cup of coffee you know it

257
00:09:52,959 --> 00:09:57,600
draws a picture that looks like a cup of

258
00:09:54,800 --> 00:09:59,519
coffee very realistic H if you ask a

259
00:09:57,600 --> 00:10:01,839
picture of a cat you know it generates a

260
00:09:59,519 --> 00:10:05,680
picture that looks like a cat and if you

261
00:10:01,839 --> 00:10:08,440
ask for a cup of cat it gives you this

262
00:10:05,680 --> 00:10:10,480
which is quite amazing now you think oh

263
00:10:08,440 --> 00:10:13,160
wow you know it really understood these

264
00:10:10,480 --> 00:10:15,079
visual concepts and it understood what

265
00:10:13,160 --> 00:10:17,040
will me what will be a coherent

266
00:10:15,079 --> 00:10:18,800
composition between these two concepts

267
00:10:17,040 --> 00:10:20,399
despite that this is something like you

268
00:10:18,800 --> 00:10:23,480
can you cannot have seen this in the

269
00:10:20,399 --> 00:10:24,920
real world well you think you cannot see

270
00:10:23,480 --> 00:10:28,600
this in the real world because if you go

271
00:10:24,920 --> 00:10:30,240
to Google and you query for a cap of cat

272
00:10:28,600 --> 00:10:33,560
then you realize that people are putting

273
00:10:30,240 --> 00:10:35,279
Cuts in sides of Cups very often and

274
00:10:33,560 --> 00:10:37,920
taking pictures of them and putting them

275
00:10:35,279 --> 00:10:40,000
on the web so sometimes some of the

276
00:10:37,920 --> 00:10:42,480
capabilities that we see of these models

277
00:10:40,000 --> 00:10:44,240
they are really a reflection of how rich

278
00:10:42,480 --> 00:10:45,639
is the training data that has been used

279
00:10:44,240 --> 00:10:47,839
to train

280
00:10:45,639 --> 00:10:49,399
them that doesn't mean that they don't

281
00:10:47,839 --> 00:10:51,079
exhibit some of these compositional

282
00:10:49,399 --> 00:10:53,480
capabilities that go beyond what the

283
00:10:51,079 --> 00:10:55,600
training data contains but it's just

284
00:10:53,480 --> 00:10:57,720
hard to know exactly you know what is in

285
00:10:55,600 --> 00:11:00,240
the training data and what is

286
00:10:57,720 --> 00:11:01,880
not so a lot of the power of these

287
00:11:00,240 --> 00:11:03,079
models is coming from the training data

288
00:11:01,880 --> 00:11:06,120
that they

289
00:11:03,079 --> 00:11:09,320
have we have also said that these models

290
00:11:06,120 --> 00:11:12,000
hallucinate if you talk with a with a

291
00:11:09,320 --> 00:11:14,000
chat GPT and you ask for things that you

292
00:11:12,000 --> 00:11:16,200
know might contain some factual

293
00:11:14,000 --> 00:11:18,079
information then they will hallucinate

294
00:11:16,200 --> 00:11:20,399
the stuff so you ask where did I

295
00:11:18,079 --> 00:11:22,519
graduate it from it says you know it's

296
00:11:20,399 --> 00:11:24,839
something it looks nice it's written in

297
00:11:22,519 --> 00:11:28,880
English it looks beautiful the first

298
00:11:24,839 --> 00:11:30,160
piece is true but the second one is not

299
00:11:28,880 --> 00:11:33,200
true

300
00:11:30,160 --> 00:11:35,240
it could have been true but it wasn't

301
00:11:33,200 --> 00:11:36,519
okay so CH is not actually trying to

302
00:11:35,240 --> 00:11:38,120
tell you what is true it's just trying

303
00:11:36,519 --> 00:11:39,440
to tell you something that could be know

304
00:11:38,120 --> 00:11:41,360
it's just sampling from those

305
00:11:39,440 --> 00:11:42,880
probabilities saying oh this is a

306
00:11:41,360 --> 00:11:44,800
sequence of words that could be true

307
00:11:42,880 --> 00:11:46,560
because it has high probability and this

308
00:11:44,800 --> 00:11:48,839
you know it had high probability because

309
00:11:46,560 --> 00:11:51,279
I actually once was I was offer that

310
00:11:48,839 --> 00:11:53,600
possibility so there is some alternative

311
00:11:51,279 --> 00:11:54,800
world where this is true and it just

312
00:11:53,600 --> 00:11:57,160
judge it but it doesn't know in which

313
00:11:54,800 --> 00:12:01,680
one it

314
00:11:57,160 --> 00:12:03,240
is so you know now also I wanted to to

315
00:12:01,680 --> 00:12:05,279
tell you another thing is that you know

316
00:12:03,240 --> 00:12:07,560
these models look very surprising a lot

317
00:12:05,279 --> 00:12:08,800
of the power is coming from the data but

318
00:12:07,560 --> 00:12:11,240
there is another thing that is very

319
00:12:08,800 --> 00:12:13,839
important also is that you know a lot of

320
00:12:11,240 --> 00:12:16,320
complex problems might not be as complex

321
00:12:13,839 --> 00:12:18,600
as they seem for instance let me do a

322
00:12:16,320 --> 00:12:21,079
quiz uh you all know what a linear

323
00:12:18,600 --> 00:12:23,639
function is a linear function is a

324
00:12:21,079 --> 00:12:25,839
function that if you take two inputs the

325
00:12:23,639 --> 00:12:28,360
output is equal to the sum of the

326
00:12:25,839 --> 00:12:30,079
outputs you know if each input is

327
00:12:28,360 --> 00:12:31,720
processed individually

328
00:12:30,079 --> 00:12:33,519
that's one condition the second

329
00:12:31,720 --> 00:12:35,199
condition is that you take an input and

330
00:12:33,519 --> 00:12:38,440
you multiply it by a

331
00:12:35,199 --> 00:12:40,839
scalar the function that applies to that

332
00:12:38,440 --> 00:12:42,839
scale input is equal to the output times

333
00:12:40,839 --> 00:12:45,519
the scalar okay these are the conditions

334
00:12:42,839 --> 00:12:47,560
for a linear function in fact it means

335
00:12:45,519 --> 00:12:50,839
that you know as Philip was showing

336
00:12:47,560 --> 00:12:53,920
before you know a typical neural network

337
00:12:50,839 --> 00:12:55,720
layer is a linear layer where is just a

338
00:12:53,920 --> 00:12:57,920
set of weights and the input and the

339
00:12:55,720 --> 00:13:00,920
output are related by the multiplication

340
00:12:57,920 --> 00:13:02,440
by a matrix so in this particular case

341
00:13:00,920 --> 00:13:04,519
you know this is the drawing that Philip

342
00:13:02,440 --> 00:13:05,600
was showing this morning so I'm going to

343
00:13:04,519 --> 00:13:08,600
do a

344
00:13:05,600 --> 00:13:10,560
quiz I'm going to show you a few

345
00:13:08,600 --> 00:13:12,800
Transformations and I want you to tell

346
00:13:10,560 --> 00:13:14,880
me which ones are linear linear and

347
00:13:12,800 --> 00:13:16,959
which ones are not so here there are

348
00:13:14,880 --> 00:13:19,040
four Transformations the first one is

349
00:13:16,959 --> 00:13:20,959
taking a picture of a picture as input

350
00:13:19,040 --> 00:13:23,279
and then you have to rotate it the

351
00:13:20,959 --> 00:13:24,839
second one is a scaling of the image the

352
00:13:23,279 --> 00:13:26,600
third one is to transform a color

353
00:13:24,839 --> 00:13:30,079
picture into a grayer scale and the

354
00:13:26,600 --> 00:13:33,399
final one is to Def focus a picture so

355
00:13:30,079 --> 00:13:35,839
think about it for 5

356
00:13:33,399 --> 00:13:38,560
seconds okay raise your

357
00:13:35,839 --> 00:13:42,720
hands uh for all of you that think that

358
00:13:38,560 --> 00:13:42,720
number a that a is a linear

359
00:13:43,399 --> 00:13:49,959
function okay let's say there is a 15

360
00:13:47,000 --> 00:13:49,959
people

361
00:13:51,600 --> 00:14:01,040
B no

362
00:13:55,160 --> 00:14:01,040
B okay 30 C

363
00:14:01,279 --> 00:14:06,160
H okay 10 10 again maybe and

364
00:14:07,079 --> 00:14:11,839
D okay and how many people did not raise

365
00:14:10,320 --> 00:14:12,839
their hands at all because they just

366
00:14:11,839 --> 00:14:15,600
didn't

367
00:14:12,839 --> 00:14:18,199
care okay so there are a few okay good

368
00:14:15,600 --> 00:14:21,639
good just to calibrate the the answer

369
00:14:18,199 --> 00:14:23,560
okay they are all linear all of these

370
00:14:21,639 --> 00:14:26,519
functions are linear you can find a

371
00:14:23,560 --> 00:14:29,199
linear implementation for all of

372
00:14:26,519 --> 00:14:32,440
those you know if you take a rotation if

373
00:14:29,199 --> 00:14:34,440
you take two images you sum them and you

374
00:14:32,440 --> 00:14:36,759
rotate it's the same thing that rotating

375
00:14:34,440 --> 00:14:39,000
them and then suming the rotated results

376
00:14:36,759 --> 00:14:40,639
or scaling is the same thing you take

377
00:14:39,000 --> 00:14:42,079
two images you sum them up and then you

378
00:14:40,639 --> 00:14:43,959
do the scaling it's the same thing that

379
00:14:42,079 --> 00:14:46,199
taking the images scaling them and then

380
00:14:43,959 --> 00:14:48,480
summing the result the same thing for

381
00:14:46,199 --> 00:14:50,560
gray scale and the same thing for blur

382
00:14:48,480 --> 00:14:53,120
they are all they can all be implemented

383
00:14:50,560 --> 00:14:55,240
with linear functions what this means is

384
00:14:53,120 --> 00:14:56,959
that a linear layer in a neural network

385
00:14:55,240 --> 00:14:59,279
can do a lot of

386
00:14:56,959 --> 00:15:01,000
things and sometimes a lot of the

387
00:14:59,279 --> 00:15:02,759
operation that we feel oh wow what

388
00:15:01,000 --> 00:15:04,519
amazing is this thing that has happened

389
00:15:02,759 --> 00:15:06,480
here well you know a linear function

390
00:15:04,519 --> 00:15:07,920
could have done it it's not true always

391
00:15:06,480 --> 00:15:10,120
of course not is why neuron networks

392
00:15:07,920 --> 00:15:12,880
have nonlinearities and lots of layers

393
00:15:10,120 --> 00:15:14,560
but linear layers can do a lot of stuff

394
00:15:12,880 --> 00:15:17,759
and sometimes it's also hard to

395
00:15:14,560 --> 00:15:20,160
appreciate how strong can these models

396
00:15:17,759 --> 00:15:22,360
be and the power for from even simple

397
00:15:20,160 --> 00:15:25,000
models like linear

398
00:15:22,360 --> 00:15:27,000
functions okay so now you know this is

399
00:15:25,000 --> 00:15:29,360
you know all the things that are going

400
00:15:27,000 --> 00:15:32,720
into the mix of what is happening now is

401
00:15:29,360 --> 00:15:34,399
in in AI on one side is you know some

402
00:15:32,720 --> 00:15:36,759
problems look complicated but they

403
00:15:34,399 --> 00:15:38,399
actually simple and you know there are

404
00:15:36,759 --> 00:15:40,279
advances in a number of different

405
00:15:38,399 --> 00:15:42,399
directions that are all happening

406
00:15:40,279 --> 00:15:45,440
together and in language models this is

407
00:15:42,399 --> 00:15:47,560
a typical conversation that an agent

408
00:15:45,440 --> 00:15:49,279
that a language model and a human can

409
00:15:47,560 --> 00:15:51,399
have you know where in this case let's

410
00:15:49,279 --> 00:15:52,959
say a human is is a doctor and is

411
00:15:51,399 --> 00:15:54,800
sending some patient reports to the

412
00:15:52,959 --> 00:15:56,600
language model and the language model

413
00:15:54,800 --> 00:15:59,720
that's been trained know with data that

414
00:15:56,600 --> 00:16:01,519
knows a lot about medical uh diagnosis

415
00:15:59,720 --> 00:16:03,160
and so on is just outputting possible

416
00:16:01,519 --> 00:16:05,759
diagnosis and there is a conversation

417
00:16:03,160 --> 00:16:09,279
this is the typical conversation one can

418
00:16:05,759 --> 00:16:12,440
expect with chpt this is not exactly an

419
00:16:09,279 --> 00:16:14,600
agent what an agent is is when you start

420
00:16:12,440 --> 00:16:16,279
incorporating more stuff to it so the

421
00:16:14,600 --> 00:16:18,360
first thing is that the human will not

422
00:16:16,279 --> 00:16:19,880
just provide information with language

423
00:16:18,360 --> 00:16:21,519
it might actually provide information

424
00:16:19,880 --> 00:16:24,959
with different modalities it could use

425
00:16:21,519 --> 00:16:26,480
images Voice Text all of this is going

426
00:16:24,959 --> 00:16:29,160
to enrich the interaction with the

427
00:16:26,480 --> 00:16:31,440
language with the language model the

428
00:16:29,160 --> 00:16:34,399
second thing is that the language model

429
00:16:31,440 --> 00:16:36,440
itself which is at the core of an agent

430
00:16:34,399 --> 00:16:38,079
it also has coding capabilities which

431
00:16:36,440 --> 00:16:40,519
means that it can take some of the

432
00:16:38,079 --> 00:16:42,839
instructions that the human is providing

433
00:16:40,519 --> 00:16:45,680
and translate those instructions into

434
00:16:42,839 --> 00:16:48,600
code that will get executed in order to

435
00:16:45,680 --> 00:16:50,519
use a set of tools for instance the

436
00:16:48,600 --> 00:16:52,279
agent could perform a search on a

437
00:16:50,519 --> 00:16:54,560
database maybe the database contains

438
00:16:52,279 --> 00:16:56,199
electronic health records and the first

439
00:16:54,560 --> 00:16:58,199
thing that it realizes is that given a

440
00:16:56,199 --> 00:17:00,600
question it requires actually to access

441
00:16:58,199 --> 00:17:01,959
the database will write code that will

442
00:17:00,600 --> 00:17:04,160
access the database it will get the

443
00:17:01,959 --> 00:17:05,919
results and it will perform an operation

444
00:17:04,160 --> 00:17:07,880
and then there are also planning tools

445
00:17:05,919 --> 00:17:09,559
that can be attached to this agent one

446
00:17:07,880 --> 00:17:11,439
on thing could be you know debates it

447
00:17:09,559 --> 00:17:13,240
could be interaction with other agents

448
00:17:11,439 --> 00:17:14,959
Chain of Thought which is another tool

449
00:17:13,240 --> 00:17:17,559
for reasoning and Philip will be talking

450
00:17:14,959 --> 00:17:18,959
more about those things the composing a

451
00:17:17,559 --> 00:17:21,039
task into sub goals and then

452
00:17:18,959 --> 00:17:23,799
accomplishing its sub goal independently

453
00:17:21,039 --> 00:17:23,799
and so on and so

454
00:17:24,240 --> 00:17:29,720
on so in that case a conversation could

455
00:17:27,760 --> 00:17:32,919
go this way when you have an agent the

456
00:17:29,720 --> 00:17:36,440
human sends to the agent some patient

457
00:17:32,919 --> 00:17:38,080
reports the agent um sends some possible

458
00:17:36,440 --> 00:17:39,799
diagnosis but it doesn't send this

459
00:17:38,080 --> 00:17:41,960
diagnosis to the doctor it sends the

460
00:17:39,799 --> 00:17:43,760
diagnosis to another agent that it will

461
00:17:41,960 --> 00:17:45,240
disagree or agree with those diagnosis

462
00:17:43,760 --> 00:17:47,720
and it will say in this case okay I

463
00:17:45,240 --> 00:17:50,200
disagree request an x-ray the first

464
00:17:47,720 --> 00:17:52,760
Agent H will interact with the human and

465
00:17:50,200 --> 00:17:55,880
will ask for an x-ray the human gives

466
00:17:52,760 --> 00:17:57,880
the X-ray the agent run some code access

467
00:17:55,880 --> 00:17:59,960
the database to get some health records

468
00:17:57,880 --> 00:18:01,080
from the patient to get more context and

469
00:17:59,960 --> 00:18:03,480
then eventually provides a

470
00:18:01,080 --> 00:18:05,679
recommendation and the human performs

471
00:18:03,480 --> 00:18:07,760
the final diagnosis so this will be an

472
00:18:05,679 --> 00:18:10,559
interaction with an agent where now you

473
00:18:07,760 --> 00:18:12,039
have a system built around llm so in

474
00:18:10,559 --> 00:18:15,240
general an agent is going to be

475
00:18:12,039 --> 00:18:17,400
something that is is a system which

476
00:18:15,240 --> 00:18:19,280
could be an llm at this scoree that is

477
00:18:17,400 --> 00:18:20,919
going to perform actions in the real

478
00:18:19,280 --> 00:18:23,120
world the real world in this case could

479
00:18:20,919 --> 00:18:25,080
be a database or so on it could perform

480
00:18:23,120 --> 00:18:29,000
actions and it will change its Behavior

481
00:18:25,080 --> 00:18:30,600
based on the results of those actions

482
00:18:29,000 --> 00:18:32,640
so for instance when we were talking

483
00:18:30,600 --> 00:18:34,440
about that models hallucinate facts like

484
00:18:32,640 --> 00:18:37,480
here when I was asking where I did

485
00:18:34,440 --> 00:18:39,880
graduate from if you do the same thing

486
00:18:37,480 --> 00:18:41,320
ER in being then what you have is that

487
00:18:39,880 --> 00:18:43,120
you actually get a slightly different

488
00:18:41,320 --> 00:18:45,720
Behavior if you ask the same

489
00:18:43,120 --> 00:18:47,880
question the agent actually realizes

490
00:18:45,720 --> 00:18:50,720
that this question is better answered by

491
00:18:47,880 --> 00:18:52,080
first doing a web search so it will

492
00:18:50,720 --> 00:18:53,840
perform the appropriate it will write

493
00:18:52,080 --> 00:18:55,400
the appropriate code that will be hidden

494
00:18:53,840 --> 00:18:57,640
to you you will not see the code you

495
00:18:55,400 --> 00:18:59,760
will not see the the execution because

496
00:18:57,640 --> 00:19:02,200
there is a parture that all the time the

497
00:18:59,760 --> 00:19:03,679
outputs of the llm and whenever it is

498
00:19:02,200 --> 00:19:06,120
code the only thing that it does is run

499
00:19:03,679 --> 00:19:07,960
it it doesn't show it on the screen so

500
00:19:06,120 --> 00:19:10,000
in this case it will perform a search on

501
00:19:07,960 --> 00:19:11,360
the database and in fact you can see

502
00:19:10,000 --> 00:19:13,440
that sometimes you know there is this

503
00:19:11,360 --> 00:19:16,200
message that appears searching it's just

504
00:19:13,440 --> 00:19:18,679
executing that piece of code and then it

505
00:19:16,200 --> 00:19:20,760
provides an output and the output is a

506
00:19:18,679 --> 00:19:23,200
paraphrasing of the content that is on

507
00:19:20,760 --> 00:19:24,559
those web pages that doesn't mean that

508
00:19:23,200 --> 00:19:26,960
the system will not

509
00:19:24,559 --> 00:19:28,799
hallucinate but it's less likely because

510
00:19:26,960 --> 00:19:30,919
it's going to be used it's going to to

511
00:19:28,799 --> 00:19:33,120
be using information that only needs to

512
00:19:30,919 --> 00:19:35,760
be paraphrased so it doesn't have to

513
00:19:33,120 --> 00:19:37,600
create as much content as if it's just

514
00:19:35,760 --> 00:19:40,120
creating the answer by itself from the

515
00:19:37,600 --> 00:19:41,760
weights store in the neural network so

516
00:19:40,120 --> 00:19:44,159
it's less likely to hallucinate but it's

517
00:19:41,760 --> 00:19:47,039
still possible this not prevents does

518
00:19:44,159 --> 00:19:48,720
not prevent hallucinations 100% but it

519
00:19:47,039 --> 00:19:51,000
can provide for instance Links at the

520
00:19:48,720 --> 00:19:52,720
end that tell you what the sources are

521
00:19:51,000 --> 00:19:55,120
so you click there it opens the web

522
00:19:52,720 --> 00:19:58,159
pages that were used to generate this

523
00:19:55,120 --> 00:20:02,280
answer but this particular text is not

524
00:19:58,159 --> 00:20:04,720
in those web pages as is so it's been

525
00:20:02,280 --> 00:20:08,520
Rewritten so I wanted to show you just a

526
00:20:04,720 --> 00:20:10,039
couple of examples of agentic systems uh

527
00:20:08,520 --> 00:20:11,559
just to go into a little bit more

528
00:20:10,039 --> 00:20:13,919
details of how they actually work and

529
00:20:11,559 --> 00:20:16,240
the type of things that you can do so

530
00:20:13,919 --> 00:20:19,280
the first one is going to be bper GPT

531
00:20:16,240 --> 00:20:21,360
which is a is a vision system and that

532
00:20:19,280 --> 00:20:23,880
was developed uh by researchers at

533
00:20:21,360 --> 00:20:26,720
Columbia University and the second one

534
00:20:23,880 --> 00:20:28,080
is uh an agent for interpreting neural

535
00:20:26,720 --> 00:20:31,600
networks which is something that we've

536
00:20:28,080 --> 00:20:33,320
done here at it but the idea here is you

537
00:20:31,600 --> 00:20:35,320
know these agents are going to be

538
00:20:33,320 --> 00:20:37,919
combining the power of language models

539
00:20:35,320 --> 00:20:40,400
with this coding abilities in order to

540
00:20:37,919 --> 00:20:43,760
solve tasks by also using tools that you

541
00:20:40,400 --> 00:20:46,240
have to provide provide them with so let

542
00:20:43,760 --> 00:20:48,640
me talk first about Viper GPT so this is

543
00:20:46,240 --> 00:20:51,200
a pretty interesting system that tries

544
00:20:48,640 --> 00:20:53,679
to answer questions about the content of

545
00:20:51,200 --> 00:20:55,520
images and the idea the basic idea

546
00:20:53,679 --> 00:20:57,120
consists on the following you have a

547
00:20:55,520 --> 00:20:59,000
picture and you have a question that you

548
00:20:57,120 --> 00:21:01,280
want to have answer and the the system

549
00:20:59,000 --> 00:21:04,120
what is going to do is going to write

550
00:21:01,280 --> 00:21:06,400
code that once it's executed it will

551
00:21:04,120 --> 00:21:08,039
answer your question and I'll explain

552
00:21:06,400 --> 00:21:10,159
now I'll go into the details of how that

553
00:21:08,039 --> 00:21:12,279
works and what I mean by you know

554
00:21:10,159 --> 00:21:15,120
running code and answering

555
00:21:12,279 --> 00:21:17,960
questions so here is an example of how a

556
00:21:15,120 --> 00:21:20,960
conversation with a with a base a vision

557
00:21:17,960 --> 00:21:23,360
based agent can go uh when it doesn't

558
00:21:20,960 --> 00:21:25,799
have this when you don't use this kind

559
00:21:23,360 --> 00:21:28,720
of agentic system agentic structure with

560
00:21:25,799 --> 00:21:31,159
tools and so on this is just uh of the

561
00:21:28,720 --> 00:21:33,400
shelf language model with vision that

562
00:21:31,159 --> 00:21:34,720
runs on the image so if you ask you know

563
00:21:33,400 --> 00:21:36,960
here in this picture what are the boys

564
00:21:34,720 --> 00:21:39,440
eating it just says the right answer

565
00:21:36,960 --> 00:21:41,480
muffins if you say what are the what are

566
00:21:39,440 --> 00:21:43,640
the muffins it says on the table so you

567
00:21:41,480 --> 00:21:46,799
know here is getting things right you

568
00:21:43,640 --> 00:21:51,600
know how many muffins are there it says

569
00:21:46,799 --> 00:21:53,440
two how many kids are there too many So

570
00:21:51,600 --> 00:21:54,799
eventually gets confused and you know

571
00:21:53,440 --> 00:21:56,520
you have these conversations that can

572
00:21:54,799 --> 00:22:00,279
derail very

573
00:21:56,520 --> 00:22:02,400
rapidly so what they proposed was

574
00:22:00,279 --> 00:22:04,039
building an agent that will answer these

575
00:22:02,400 --> 00:22:06,080
questions and the idea will you know is

576
00:22:04,039 --> 00:22:07,919
the following one so you have this image

577
00:22:06,080 --> 00:22:10,640
you want to answer your quer how many

578
00:22:07,919 --> 00:22:13,120
how many muffins can each kid have for

579
00:22:10,640 --> 00:22:15,799
it to be fair so this is a sophisticated

580
00:22:13,120 --> 00:22:17,880
question that requires not just counting

581
00:22:15,799 --> 00:22:19,760
how many kids there are but actually

582
00:22:17,880 --> 00:22:21,880
also accessing some common sense

583
00:22:19,760 --> 00:22:25,240
knowledge about what do you mean by

584
00:22:21,880 --> 00:22:26,760
being fair ER and so on so you know this

585
00:22:25,240 --> 00:22:28,159
is a sophisticated question that will

586
00:22:26,760 --> 00:22:30,960
require reasoning a lot about the

587
00:22:28,159 --> 00:22:33,039
question in order to find the answer and

588
00:22:30,960 --> 00:22:34,679
the propose The Proposal is that then

589
00:22:33,039 --> 00:22:36,600
what you have is a system that will

590
00:22:34,679 --> 00:22:40,240
first write

591
00:22:36,600 --> 00:22:42,360
code so that if you execute this code it

592
00:22:40,240 --> 00:22:44,080
will answer your question so here is the

593
00:22:42,360 --> 00:22:45,799
piece of the code that was generated

594
00:22:44,080 --> 00:22:48,840
after that and I'll explain later how

595
00:22:45,799 --> 00:22:50,360
that works and what is interesting is

596
00:22:48,840 --> 00:22:51,159
that interesting is that if you execute

597
00:22:50,360 --> 00:22:53,679
this

598
00:22:51,159 --> 00:22:56,000
code so the first line will just find

599
00:22:53,679 --> 00:22:58,240
the muffins we'll count them you know

600
00:22:56,000 --> 00:23:01,559
you have a line that counts muffins you

601
00:22:58,240 --> 00:23:03,200
say eight then you look for how many

602
00:23:01,559 --> 00:23:04,679
kits there are the patches that contain

603
00:23:03,200 --> 00:23:06,880
kits then you count them you know there

604
00:23:04,679 --> 00:23:09,000
are two patches and then you you comput

605
00:23:06,880 --> 00:23:10,520
the division of 8 divided by two that

606
00:23:09,000 --> 00:23:11,600
gives you four so the answer to this

607
00:23:10,520 --> 00:23:14,960
question is

608
00:23:11,600 --> 00:23:17,559
four so it's just a much interesting

609
00:23:14,960 --> 00:23:19,640
usage of how you know different tools

610
00:23:17,559 --> 00:23:21,360
that you can run on images will allow

611
00:23:19,640 --> 00:23:24,080
you to answer this question so let me go

612
00:23:21,360 --> 00:23:27,080
in detail now on how all this works so

613
00:23:24,080 --> 00:23:29,960
the first thing is this is not a system

614
00:23:27,080 --> 00:23:31,279
that is trained this is just using a

615
00:23:29,960 --> 00:23:32,360
system that is already pre-trained a

616
00:23:31,279 --> 00:23:34,520
language model that is already

617
00:23:32,360 --> 00:23:39,320
pre-trained that has coding capabilities

618
00:23:34,520 --> 00:23:42,000
like chpt and just as uh Kim was Jun was

619
00:23:39,320 --> 00:23:44,760
showing before what you have is a prompt

620
00:23:42,000 --> 00:23:47,600
that will tell the agent in this

621
00:23:44,760 --> 00:23:49,360
case what kinds of functions it can use

622
00:23:47,600 --> 00:23:51,360
and how it has to call them so there is

623
00:23:49,360 --> 00:23:53,480
a long prompt so here is the beginning

624
00:23:51,360 --> 00:23:55,880
of the prompt and the prom is just the

625
00:23:53,480 --> 00:23:58,520
type of prompt the description that you

626
00:23:55,880 --> 00:24:00,400
will provide that you will write if you

627
00:23:58,520 --> 00:24:02,400
you were writing a python Library where

628
00:24:00,400 --> 00:24:04,159
you have lots of functions and you have

629
00:24:02,400 --> 00:24:06,080
comments and you have examples and you

630
00:24:04,159 --> 00:24:07,320
put all this as text and you just put it

631
00:24:06,080 --> 00:24:09,600
as part of your

632
00:24:07,320 --> 00:24:12,720
prompt and then after this prompt you

633
00:24:09,600 --> 00:24:14,679
attach the question that you have so now

634
00:24:12,720 --> 00:24:16,559
chpt will understand that you know there

635
00:24:14,679 --> 00:24:18,200
are all these functions I can use in

636
00:24:16,559 --> 00:24:20,600
order to answer this question and it

637
00:24:18,200 --> 00:24:24,080
will just write code to answer the

638
00:24:20,600 --> 00:24:25,919
question so what is in this prompt well

639
00:24:24,080 --> 00:24:27,520
there are all kinds of functions for

640
00:24:25,919 --> 00:24:29,000
instance there is going to be a function

641
00:24:27,520 --> 00:24:31,440
that is called fine

642
00:24:29,000 --> 00:24:33,480
that input is a string with the name of

643
00:24:31,440 --> 00:24:37,480
an object that you care and it will

644
00:24:33,480 --> 00:24:39,240
output a an array of patches containing

645
00:24:37,480 --> 00:24:42,200
the objects that you care about so it

646
00:24:39,240 --> 00:24:44,000
will return just small images each one

647
00:24:42,200 --> 00:24:44,799
being a crop containing the object that

648
00:24:44,000 --> 00:24:47,120
you care

649
00:24:44,799 --> 00:24:51,120
about so for instance if you're finding

650
00:24:47,120 --> 00:24:53,240
muffins the result will be these eight

651
00:24:51,120 --> 00:24:55,000
patches there are many other functions

652
00:24:53,240 --> 00:24:57,520
for instance you know anything that has

653
00:24:55,000 --> 00:24:58,960
been built by computer vision scientists

654
00:24:57,520 --> 00:25:01,000
so here you know there's another

655
00:24:58,960 --> 00:25:02,600
function that will compute the depth of

656
00:25:01,000 --> 00:25:06,159
the image this means that it will tell

657
00:25:02,600 --> 00:25:09,120
for each pixel how far away is from the

658
00:25:06,159 --> 00:25:11,360
camera so this is the picture it just

659
00:25:09,120 --> 00:25:13,000
outputs a depth map indicating in this

660
00:25:11,360 --> 00:25:14,799
case it's a colorcoded depth map

661
00:25:13,000 --> 00:25:16,880
indicating which things are nearby the

662
00:25:14,799 --> 00:25:18,480
camera and which things are far away and

663
00:25:16,880 --> 00:25:19,200
there are lots and lots of functions of

664
00:25:18,480 --> 00:25:22,120
this

665
00:25:19,200 --> 00:25:24,159
kind there are going to be functions

666
00:25:22,120 --> 00:25:26,480
that are application specific and these

667
00:25:24,159 --> 00:25:28,720
are the tools that you are providing the

668
00:25:26,480 --> 00:25:30,720
agent with and then the there is just

669
00:25:28,720 --> 00:25:33,320
the generic programming knowledge that

670
00:25:30,720 --> 00:25:35,840
the llm has that it knows how to write

671
00:25:33,320 --> 00:25:39,640
Python scripts and then I can

672
00:25:35,840 --> 00:25:40,919
combine conditions loops and so on with

673
00:25:39,640 --> 00:25:43,520
the tools that you are provided to

674
00:25:40,919 --> 00:25:46,840
create programs that are relatively

675
00:25:43,520 --> 00:25:49,000
complex so and now you also have the

676
00:25:46,840 --> 00:25:51,559
benefit that you have all the common

677
00:25:49,000 --> 00:25:53,880
sense knowledge that the language model

678
00:25:51,559 --> 00:25:56,640
has so when you ask for questions the

679
00:25:53,880 --> 00:25:59,159
language model will use it source of

680
00:25:56,640 --> 00:26:01,080
your it base of Common Sense knowledge

681
00:25:59,159 --> 00:26:03,559
to answer those questions for instance

682
00:26:01,080 --> 00:26:06,600
here if the question is is the animal

683
00:26:03,559 --> 00:26:08,159
that is not gray a dog so that's you

684
00:26:06,600 --> 00:26:09,760
know a sophisticated question this is

685
00:26:08,159 --> 00:26:11,240
actually quite difficult to answer for a

686
00:26:09,760 --> 00:26:14,039
language model directly on the image

687
00:26:11,240 --> 00:26:15,960
because negations get complicated but

688
00:26:14,039 --> 00:26:18,919
here the model just translates this

689
00:26:15,960 --> 00:26:20,799
image into code and then it executes so

690
00:26:18,919 --> 00:26:22,960
the first line finds the images with

691
00:26:20,799 --> 00:26:26,679
cats and dogs then it looks at one is

692
00:26:22,960 --> 00:26:29,679
this gray true is not gray not is this

693
00:26:26,679 --> 00:26:31,480
patch gray false so you this is not

694
00:26:29,679 --> 00:26:34,120
great so it returns

695
00:26:31,480 --> 00:26:36,799
yes so here is you know the answer to

696
00:26:34,120 --> 00:26:36,799
that particular

697
00:26:37,320 --> 00:26:41,000
question here is another example you

698
00:26:39,559 --> 00:26:43,640
know Computing math that is quite

699
00:26:41,000 --> 00:26:46,720
complicated with depreciation of this

700
00:26:43,640 --> 00:26:48,440
car what will be worth in five years so

701
00:26:46,720 --> 00:26:50,120
that requires understanding the make of

702
00:26:48,440 --> 00:26:51,640
the car and then understanding what

703
00:26:50,120 --> 00:26:54,600
depreciation means and so on a lot of

704
00:26:51,640 --> 00:26:56,159
knowledge that the language model has so

705
00:26:54,600 --> 00:26:58,600
it will just look at the code you it

706
00:26:56,159 --> 00:27:01,679
will write the code and and then it

707
00:26:58,600 --> 00:27:04,360
looks at the detects the

708
00:27:01,679 --> 00:27:05,919
car it looks for what is the make of the

709
00:27:04,360 --> 00:27:07,399
car so that gives you access to the

710
00:27:05,919 --> 00:27:09,679
depreciation

711
00:27:07,399 --> 00:27:11,799
rate and then now it has also to the

712
00:27:09,679 --> 00:27:13,840
current access to the current value and

713
00:27:11,799 --> 00:27:15,919
just multiplies those two numbers and it

714
00:27:13,840 --> 00:27:17,600
gets the depreciation so it just gives

715
00:27:15,919 --> 00:27:19,520
you a number which you know might be

716
00:27:17,600 --> 00:27:20,960
right or not but it gives you a sense of

717
00:27:19,520 --> 00:27:22,799
the fact that this system can perform

718
00:27:20,960 --> 00:27:25,120
actually complicated

719
00:27:22,799 --> 00:27:27,279
queries you can actually use it also on

720
00:27:25,120 --> 00:27:29,960
video for instance here there's a movie

721
00:27:27,279 --> 00:27:32,039
and you want to know you know return the

722
00:27:29,960 --> 00:27:34,360
two kids that are farthest from the

723
00:27:32,039 --> 00:27:37,000
woman right before she hacks the girl so

724
00:27:34,360 --> 00:27:39,880
here is the hugging okay so that's the

725
00:27:37,000 --> 00:27:42,600
question and you know just using the pr

726
00:27:39,880 --> 00:27:45,399
that I show before the output is this

727
00:27:42,600 --> 00:27:47,080
piece of code that execute it it

728
00:27:45,399 --> 00:27:49,360
actually looks at you know it passes the

729
00:27:47,080 --> 00:27:53,519
video into segments and it starts you

730
00:27:49,360 --> 00:27:53,519
know looking for when a hack

731
00:27:54,080 --> 00:28:00,120
appears so just executing each looping

732
00:27:56,960 --> 00:28:00,120
over all the frames

733
00:28:03,880 --> 00:28:06,799
until it detects the

734
00:28:19,799 --> 00:28:27,080
hug keeps

735
00:28:22,480 --> 00:28:27,080
executing until it returns

736
00:28:29,000 --> 00:28:33,880
the two patches with the kids so it's a

737
00:28:31,960 --> 00:28:36,360
pretty sophisticated reasoning the

738
00:28:33,880 --> 00:28:37,840
systems are not of course it can fail in

739
00:28:36,360 --> 00:28:39,159
many different ways there are many

740
00:28:37,840 --> 00:28:41,640
different types of failure mod that you

741
00:28:39,159 --> 00:28:44,480
can imagine but this is a sophisticated

742
00:28:41,640 --> 00:28:46,480
question that require like a interesting

743
00:28:44,480 --> 00:28:48,440
processing of the video and it's through

744
00:28:46,480 --> 00:28:50,880
this combination of the power of the llm

745
00:28:48,440 --> 00:28:52,799
is reasoning capabilities and all the

746
00:28:50,880 --> 00:28:55,519
tools that get added to

747
00:28:52,799 --> 00:28:57,480
it so you know this systems have code

748
00:28:55,519 --> 00:28:59,960
available this is the way that you build

749
00:28:57,480 --> 00:29:02,600
the systems basically by engineering The

750
00:28:59,960 --> 00:29:05,880
Prompt working having the right prompt

751
00:29:02,600 --> 00:29:08,320
is actually relatively easy to get it

752
00:29:05,880 --> 00:29:10,159
working it's difficult to get it working

753
00:29:08,320 --> 00:29:12,159
really well so you really need to do

754
00:29:10,159 --> 00:29:14,279
things properly it's very important that

755
00:29:12,159 --> 00:29:16,080
the library is written in a way that

756
00:29:14,279 --> 00:29:17,840
will look like as professionally written

757
00:29:16,080 --> 00:29:19,559
as possible because that's how these

758
00:29:17,840 --> 00:29:21,440
things has been trained it's trained by

759
00:29:19,559 --> 00:29:23,279
looking at code on the web is really

760
00:29:21,440 --> 00:29:24,799
good if things use a standardized

761
00:29:23,279 --> 00:29:27,240
language like if you start changing the

762
00:29:24,799 --> 00:29:28,960
rules of python on the Fly it's just not

763
00:29:27,240 --> 00:29:30,760
going to perform very well so you want

764
00:29:28,960 --> 00:29:32,880
to make sure that you respect you know

765
00:29:30,760 --> 00:29:34,480
as closely as possible all the

766
00:29:32,880 --> 00:29:36,919
conventions that are being used and you

767
00:29:34,480 --> 00:29:39,440
write your functions in ways that are

768
00:29:36,919 --> 00:29:41,399
very you know very familiar to what a

769
00:29:39,440 --> 00:29:44,720
programmer will

770
00:29:41,399 --> 00:29:46,640
be and then it's just a set of API calls

771
00:29:44,720 --> 00:29:49,600
that you do with the language model it

772
00:29:46,640 --> 00:29:52,240
could be an open source model or a close

773
00:29:49,600 --> 00:29:53,960
or a close model that has an API and

774
00:29:52,240 --> 00:29:57,159
it's just a set of API

775
00:29:53,960 --> 00:29:58,840
calls so that was for Viper GPT and the

776
00:29:57,159 --> 00:30:00,840
next one is this multimodal

777
00:29:58,840 --> 00:30:04,320
interpretability agent that we've been

778
00:30:00,840 --> 00:30:06,799
working at MIT in my group so here is is

779
00:30:04,320 --> 00:30:09,720
a similar idea in the construction so

780
00:30:06,799 --> 00:30:12,559
you have a language model that will be

781
00:30:09,720 --> 00:30:14,919
augmented with tools and it will perform

782
00:30:12,559 --> 00:30:16,919
a question you have a question but in

783
00:30:14,919 --> 00:30:19,559
this particular case instead of just

784
00:30:16,919 --> 00:30:21,840
giving the output once and you're done

785
00:30:19,559 --> 00:30:24,200
you have a system that will you know it

786
00:30:21,840 --> 00:30:26,159
will execute some code that will be

787
00:30:24,200 --> 00:30:28,320
based on the question that you have it

788
00:30:26,159 --> 00:30:30,600
will run it on images it will see

789
00:30:28,320 --> 00:30:32,279
results and it will keep writing its

790
00:30:30,600 --> 00:30:34,120
code until it gives you the answer that

791
00:30:32,279 --> 00:30:36,440
you want so it's it's like one degree

792
00:30:34,120 --> 00:30:39,080
more sophistication in how it actually

793
00:30:36,440 --> 00:30:40,600
interacts with the world outside so how

794
00:30:39,080 --> 00:30:42,799
does what is that we are trying to do

795
00:30:40,600 --> 00:30:44,799
here so one of the

796
00:30:42,799 --> 00:30:47,840
challenges H when you build neural

797
00:30:44,799 --> 00:30:49,600
networks is that it's unclear what is

798
00:30:47,840 --> 00:30:51,519
that they are doing now you once you

799
00:30:49,600 --> 00:30:54,120
have trained you have all these weights

800
00:30:51,519 --> 00:30:56,760
and all these neurons and yeah the input

801
00:30:54,120 --> 00:30:59,240
and the output look good but we have no

802
00:30:56,760 --> 00:31:01,799
idea of what is going on inside how is

803
00:30:59,240 --> 00:31:04,480
that this output came about or when is

804
00:31:01,799 --> 00:31:06,159
wrong why is wrong can I predict what it

805
00:31:04,480 --> 00:31:08,519
will be wrong so you want to really

806
00:31:06,159 --> 00:31:11,720
understand what are the different things

807
00:31:08,519 --> 00:31:14,679
that allow the system to work so there

808
00:31:11,720 --> 00:31:16,600
are a lot of different ER directions of

809
00:31:14,679 --> 00:31:20,679
research that try to answer this

810
00:31:16,600 --> 00:31:22,880
question and most of them are based on

811
00:31:20,679 --> 00:31:25,120
very specific ways of analyzing the

812
00:31:22,880 --> 00:31:27,519
content on of a neural network there are

813
00:31:25,120 --> 00:31:30,240
methods that are based on sancy methods

814
00:31:27,519 --> 00:31:32,039
that are B Bas on probing single units

815
00:31:30,240 --> 00:31:34,600
and there are you know a number a

816
00:31:32,039 --> 00:31:38,240
collection of ways every every each of

817
00:31:34,600 --> 00:31:39,919
those very specific on how they analyze

818
00:31:38,240 --> 00:31:42,080
a neural network and they provide one

819
00:31:39,919 --> 00:31:44,600
type of

820
00:31:42,080 --> 00:31:46,240
answer so what we want to do is once you

821
00:31:44,600 --> 00:31:47,840
have a neural network that is capable of

822
00:31:46,240 --> 00:31:49,919
Performing some action like for instance

823
00:31:47,840 --> 00:31:51,799
maybe it's a discrimination where you

824
00:31:49,919 --> 00:31:54,720
know you have a picture and it

825
00:31:51,799 --> 00:31:57,159
classifies this image as being among you

826
00:31:54,720 --> 00:31:58,559
know among a thousand possible classes

827
00:31:57,159 --> 00:32:01,200
so in this case you know it says this is

828
00:31:58,559 --> 00:32:03,480
an airplane but maybe I want to know

829
00:32:01,200 --> 00:32:05,639
what is that unit in the middle there

830
00:32:03,480 --> 00:32:07,000
doing okay so I know what the output

831
00:32:05,639 --> 00:32:08,720
units are doing because they are giving

832
00:32:07,000 --> 00:32:10,399
me my outputs but what is happening in

833
00:32:08,720 --> 00:32:12,600
the middle I want to know what that unit

834
00:32:10,399 --> 00:32:15,200
marketing red is actually

835
00:32:12,600 --> 00:32:16,399
doing so when you are trying to

836
00:32:15,200 --> 00:32:18,600
understand what a neural network is

837
00:32:16,399 --> 00:32:20,679
doing there are many questions that you

838
00:32:18,600 --> 00:32:24,840
might want to ask you might want to know

839
00:32:20,679 --> 00:32:27,919
what is you need 45 in layer 4 doing or

840
00:32:24,840 --> 00:32:30,639
what are the biases in the output class

841
00:32:27,919 --> 00:32:32,000
for the dog class or how many units

842
00:32:30,639 --> 00:32:34,600
inside the neural network actually

843
00:32:32,000 --> 00:32:37,120
detect cars or you know so on and so on

844
00:32:34,600 --> 00:32:39,480
and so on so you really want to have

845
00:32:37,120 --> 00:32:41,519
like the flexibility for understanding

846
00:32:39,480 --> 00:32:43,200
the content of an neuron Network that is

847
00:32:41,519 --> 00:32:44,600
similar to the flexibility that you have

848
00:32:43,200 --> 00:32:46,399
to interact when you interact with a

849
00:32:44,600 --> 00:32:48,360
language model where you can POS any

850
00:32:46,399 --> 00:32:51,240
question so really what you would like

851
00:32:48,360 --> 00:32:52,679
to have is some agent that helps you

852
00:32:51,240 --> 00:32:55,399
understand what another what a neural

853
00:32:52,679 --> 00:32:57,279
network is doing so that you can ask

854
00:32:55,399 --> 00:32:59,120
questions and the this system will

855
00:32:57,279 --> 00:33:01,200
interact with Network and it will answer

856
00:32:59,120 --> 00:33:02,720
your questions so that's what we try to

857
00:33:01,200 --> 00:33:04,919
do what we try to do is to build an

858
00:33:02,720 --> 00:33:07,039
agent that is enhanced with a set of

859
00:33:04,919 --> 00:33:08,440
tools so that it can actually interact

860
00:33:07,039 --> 00:33:12,159
with a neural network that has already

861
00:33:08,440 --> 00:33:13,799
been trained to answer questions about

862
00:33:12,159 --> 00:33:14,919
the mechanism that the neural network

863
00:33:13,799 --> 00:33:18,480
has

864
00:33:14,919 --> 00:33:20,320
learned so let me show you an example of

865
00:33:18,480 --> 00:33:22,200
once this system is built how it works

866
00:33:20,320 --> 00:33:24,760
and then I'll explain what are the

867
00:33:22,200 --> 00:33:26,760
different pieces that make it possible

868
00:33:24,760 --> 00:33:29,159
so let's say that you have a user you

869
00:33:26,760 --> 00:33:31,080
have this agent that will interpret that

870
00:33:29,159 --> 00:33:32,440
we call Maya and at the end at the

871
00:33:31,080 --> 00:33:35,240
bottom you have the neural network that

872
00:33:32,440 --> 00:33:38,519
you want to understand so the user asks

873
00:33:35,240 --> 00:33:40,720
what is the role of unit 122 in layer

874
00:33:38,519 --> 00:33:43,159
four and in this case the neural network

875
00:33:40,720 --> 00:33:45,880
is a rest net uh neural network you know

876
00:33:43,159 --> 00:33:49,760
given with with something that kin

877
00:33:45,880 --> 00:33:51,480
discovered um and is trained to do image

878
00:33:49,760 --> 00:33:52,919
net classification so you want you want

879
00:33:51,480 --> 00:33:56,080
to know What that particular unit is

880
00:33:52,919 --> 00:33:59,080
doing why who cares that's the unit that

881
00:33:56,080 --> 00:34:01,720
you care that I have the sample for so

882
00:33:59,080 --> 00:34:03,039
so here is what Maya will do so the

883
00:34:01,720 --> 00:34:05,240
first thing that it will do is will

884
00:34:03,039 --> 00:34:07,559
translate that question into a code that

885
00:34:05,240 --> 00:34:09,280
it will run in order to experiment on

886
00:34:07,559 --> 00:34:12,200
the neural network and the first thing

887
00:34:09,280 --> 00:34:13,800
that it does it runs a particular tool

888
00:34:12,200 --> 00:34:15,720
that what it does it takes the entire

889
00:34:13,800 --> 00:34:17,879
image net it passes image net through

890
00:34:15,720 --> 00:34:20,159
the entire neural network all of the

891
00:34:17,879 --> 00:34:22,520
images and it records what are the

892
00:34:20,159 --> 00:34:25,280
images that most strongly activated that

893
00:34:22,520 --> 00:34:27,760
particular unit so every unit will react

894
00:34:25,280 --> 00:34:31,040
to different inputs in different way

895
00:34:27,760 --> 00:34:34,040
ways and in general if you have relus

896
00:34:31,040 --> 00:34:37,000
strong activations are considered to be

897
00:34:34,040 --> 00:34:39,040
meaningful so if something activates

898
00:34:37,000 --> 00:34:41,079
very strongly that particular unit then

899
00:34:39,040 --> 00:34:42,839
one could conclude that maybe that's the

900
00:34:41,079 --> 00:34:46,040
particular concept that is driving that

901
00:34:42,839 --> 00:34:48,359
unit so here is the three images that

902
00:34:46,040 --> 00:34:50,520
most strongly activated that particular

903
00:34:48,359 --> 00:34:54,159
unit the numbers in this case is just

904
00:34:50,520 --> 00:34:55,919
the activation score and these units are

905
00:34:54,159 --> 00:34:58,280
convolutions so they react to different

906
00:34:55,919 --> 00:35:00,720
pieces of the image and highlighted

907
00:34:58,280 --> 00:35:03,520
region is the region of the image that

908
00:35:00,720 --> 00:35:07,800
is responsible of that high

909
00:35:03,520 --> 00:35:09,839
Activation so no Maya looks at these

910
00:35:07,800 --> 00:35:12,760
images Maya is based on in this case on

911
00:35:09,839 --> 00:35:14,880
gptv so it can take images as inputs and

912
00:35:12,760 --> 00:35:17,520
it will analyze the output of those

913
00:35:14,880 --> 00:35:20,440
images and it concludes that the highest

914
00:35:17,520 --> 00:35:22,839
activations seem to show B eyes and

915
00:35:20,440 --> 00:35:24,440
indeed if you look at this images you

916
00:35:22,839 --> 00:35:27,119
pay attention you will see that all of

917
00:35:24,440 --> 00:35:29,920
them had a b eye so it's seems to be

918
00:35:27,119 --> 00:35:32,480
high five near the neck and these three

919
00:35:29,920 --> 00:35:34,720
images just by chance happen to have a b

920
00:35:32,480 --> 00:35:37,040
eye so now he wants to be sure that this

921
00:35:34,720 --> 00:35:38,320
is a b tie detector so it does the

922
00:35:37,040 --> 00:35:41,680
following thing it calls a different

923
00:35:38,320 --> 00:35:43,520
tool that now it will generate an image

924
00:35:41,680 --> 00:35:45,160
so this will not be an image that comes

925
00:35:43,520 --> 00:35:46,599
from imag net instead it will be an

926
00:35:45,160 --> 00:35:48,760
image that is just

927
00:35:46,599 --> 00:35:51,400
generated and it generates a phas and it

928
00:35:48,760 --> 00:35:54,160
sees that that does not drive the unit

929
00:35:51,400 --> 00:35:57,079
the activation is very very

930
00:35:54,160 --> 00:36:01,440
low so now it says well now let's edit

931
00:35:57,079 --> 00:36:02,960
this picture and add a b eye to it and

932
00:36:01,440 --> 00:36:06,000
just by doing that change suddenly the

933
00:36:02,960 --> 00:36:07,440
activation goes up again and this image

934
00:36:06,000 --> 00:36:10,040
the only difference with the previous

935
00:36:07,440 --> 00:36:11,640
one is that it contains a b TI all the

936
00:36:10,040 --> 00:36:13,880
rest of the pixels are more or less

937
00:36:11,640 --> 00:36:16,160
identical this is another tool that I

938
00:36:13,880 --> 00:36:18,400
describe later that is capable of taking

939
00:36:16,160 --> 00:36:20,400
an instruction and changing the content

940
00:36:18,400 --> 00:36:22,040
of a picture so now it concludes well

941
00:36:20,400 --> 00:36:24,160
this neuron seems to select to be

942
00:36:22,040 --> 00:36:25,800
selected for both eyes particularly in

943
00:36:24,160 --> 00:36:27,000
the context of formal attire because it

944
00:36:25,800 --> 00:36:28,800
performs more experiments what I'm

945
00:36:27,000 --> 00:36:30,680
showing here it's just a selection just

946
00:36:28,800 --> 00:36:34,000
to give you a hint you know some idea of

947
00:36:30,680 --> 00:36:36,640
what is actually what it's going to do

948
00:36:34,000 --> 00:36:38,599
so this is the full picture of the agent

949
00:36:36,640 --> 00:36:40,440
you have a language model a multimodal

950
00:36:38,599 --> 00:36:42,640
language model in the middle that can

951
00:36:40,440 --> 00:36:44,640
take us input text and images and then

952
00:36:42,640 --> 00:36:46,079
you have a set of tools that it can call

953
00:36:44,640 --> 00:36:48,319
the tools are going to be a set of

954
00:36:46,079 --> 00:36:50,520
functions that I'll describe in a second

955
00:36:48,319 --> 00:36:52,960
and then it has also has functions to

956
00:36:50,520 --> 00:36:55,200
generate data to send data to the neural

957
00:36:52,960 --> 00:36:57,960
network and functions to read the

958
00:36:55,200 --> 00:36:59,960
behavior of the neural network

959
00:36:57,960 --> 00:37:02,640
so for instance one of the tools that it

960
00:36:59,960 --> 00:37:04,200
has is the capability of sending an

961
00:37:02,640 --> 00:37:07,880
image through the neural network and

962
00:37:04,200 --> 00:37:10,599
recording the activations and maps and

963
00:37:07,880 --> 00:37:12,440
activity maps of a particular unit so

964
00:37:10,599 --> 00:37:14,480
you take a picture you indicate a neural

965
00:37:12,440 --> 00:37:17,280
net a unit inside the neural network and

966
00:37:14,480 --> 00:37:20,640
it outputs a number and a selected

967
00:37:17,280 --> 00:37:22,560
area this is one tool another tool is

968
00:37:20,640 --> 00:37:24,839
going to be this data set exampl which

969
00:37:22,560 --> 00:37:27,200
is just it takes a data set of images in

970
00:37:24,839 --> 00:37:29,599
this case let's say imag net again a

971
00:37:27,200 --> 00:37:31,720
unit that you care about and it outputs

972
00:37:29,599 --> 00:37:33,760
the top end images that must strongly

973
00:37:31,720 --> 00:37:37,000
activate that particular unit with their

974
00:37:33,760 --> 00:37:40,720
scores so it's an array you know of T

975
00:37:37,000 --> 00:37:42,240
PS you can have also a image generative

976
00:37:40,720 --> 00:37:44,720
models that's another tool so in this

977
00:37:42,240 --> 00:37:48,079
case is stable diffusion where you take

978
00:37:44,720 --> 00:37:49,480
as input text and it outputs a picture

979
00:37:48,079 --> 00:37:51,640
that corresponds to that particular

980
00:37:49,480 --> 00:37:54,160
caption so that allows the system to

981
00:37:51,640 --> 00:37:56,359
create images that might have might have

982
00:37:54,160 --> 00:37:58,040
properties that he wants to test that

983
00:37:56,359 --> 00:37:59,680
might not be available on the original

984
00:37:58,040 --> 00:38:01,240
data set that you provided with because

985
00:37:59,680 --> 00:38:02,920
maybe you want to test something that is

986
00:38:01,240 --> 00:38:04,319
very fine grain and you really need to

987
00:38:02,920 --> 00:38:07,000
synthesize

988
00:38:04,319 --> 00:38:10,319
it and finally so there are tools to

989
00:38:07,000 --> 00:38:12,800
edit images where the input is one

990
00:38:10,319 --> 00:38:14,440
image then you have an instruction of

991
00:38:12,800 --> 00:38:17,079
what you want to do with that picture

992
00:38:14,440 --> 00:38:19,359
and it outputs just that the image with

993
00:38:17,079 --> 00:38:20,800
that transformation some other things

994
00:38:19,359 --> 00:38:22,359
might have changed on the picture

995
00:38:20,800 --> 00:38:24,440
because this is a generating model that

996
00:38:22,359 --> 00:38:25,760
is doing the operation but most of the

997
00:38:24,440 --> 00:38:28,079
changes are going to be the ones that

998
00:38:25,760 --> 00:38:28,920
you care about but you know other things

999
00:38:28,079 --> 00:38:32,280
could

1000
00:38:28,920 --> 00:38:34,800
happen so this particular tool is based

1001
00:38:32,280 --> 00:38:37,560
on instruct PS to PS which is a is a

1002
00:38:34,800 --> 00:38:39,040
model that allows to take a picture an

1003
00:38:37,560 --> 00:38:41,040
instruction and transform it into

1004
00:38:39,040 --> 00:38:42,599
another picture this is another I want

1005
00:38:41,040 --> 00:38:45,760
to open a parenthesis here because this

1006
00:38:42,599 --> 00:38:49,280
is another very important aspect of

1007
00:38:45,760 --> 00:38:51,040
modern generative models is many times

1008
00:38:49,280 --> 00:38:53,319
you have a model you want to build

1009
00:38:51,040 --> 00:38:54,880
something that solves a particular task

1010
00:38:53,319 --> 00:38:58,079
and we know that you need to have a lot

1011
00:38:54,880 --> 00:39:01,040
of data to train these models but in

1012
00:38:58,079 --> 00:39:03,359
many cases you don't have data like here

1013
00:39:01,040 --> 00:39:04,560
what we need is data that will you know

1014
00:39:03,359 --> 00:39:05,880
this is what we want to build we want to

1015
00:39:04,560 --> 00:39:07,560
build a Neal Network that will take

1016
00:39:05,880 --> 00:39:09,359
these two inputs and output you know the

1017
00:39:07,560 --> 00:39:13,119
transform

1018
00:39:09,359 --> 00:39:15,480
images and you need to have data that

1019
00:39:13,119 --> 00:39:18,079
has this form that are triplets of an

1020
00:39:15,480 --> 00:39:20,160
input image an instruction for the

1021
00:39:18,079 --> 00:39:22,160
change and the output and this is work

1022
00:39:20,160 --> 00:39:25,839
that was done by Tim Brooks and and

1023
00:39:22,160 --> 00:39:28,400
alosa EOS and collaborators at berlay

1024
00:39:25,839 --> 00:39:30,720
so the challenge here is that you need

1025
00:39:28,400 --> 00:39:32,720
to have a lot of data and this data is

1026
00:39:30,720 --> 00:39:33,880
not available out there so one of the

1027
00:39:32,720 --> 00:39:37,119
things that is happening now in the

1028
00:39:33,880 --> 00:39:39,800
field is to use all the

1029
00:39:37,119 --> 00:39:41,920
different tools that we have nowadays

1030
00:39:39,800 --> 00:39:44,079
built know language models generative

1031
00:39:41,920 --> 00:39:46,359
models of different kinds and so on in

1032
00:39:44,079 --> 00:39:49,240
order to generate synthetic data that

1033
00:39:46,359 --> 00:39:52,079
you can use to train new models so for

1034
00:39:49,240 --> 00:39:54,599
instance here this model was trained

1035
00:39:52,079 --> 00:39:57,400
using synthetic data so the way that the

1036
00:39:54,599 --> 00:39:59,040
synthetic data is is generated is quite

1037
00:39:57,400 --> 00:40:01,480
creative and I think that a lot of the

1038
00:39:59,040 --> 00:40:03,640
research now comes into how do you

1039
00:40:01,480 --> 00:40:06,000
figure out ways of generating synthetic

1040
00:40:03,640 --> 00:40:08,119
data that has the conditions that you

1041
00:40:06,000 --> 00:40:10,520
care about so here is how what the

1042
00:40:08,119 --> 00:40:14,280
process was so the creation of the

1043
00:40:10,520 --> 00:40:17,000
training data started by just asking GPT

1044
00:40:14,280 --> 00:40:19,599
to start with a caption of an image and

1045
00:40:17,000 --> 00:40:22,240
propose a sentence that will be an

1046
00:40:19,599 --> 00:40:24,440
instruction for an edit and then another

1047
00:40:22,240 --> 00:40:27,520
sentence that will be the final

1048
00:40:24,440 --> 00:40:29,839
description of the image after that edit

1049
00:40:27,520 --> 00:40:31,240
it so you don't need you know this is

1050
00:40:29,839 --> 00:40:33,839
something that you have you just you can

1051
00:40:31,240 --> 00:40:35,880
take chpt and you can ask it to do this

1052
00:40:33,839 --> 00:40:37,400
and it will create these triplets where

1053
00:40:35,880 --> 00:40:40,560
you know you in this case you say

1054
00:40:37,400 --> 00:40:42,200
photograph of a girl riding a horse and

1055
00:40:40,560 --> 00:40:44,240
then the instruction can be have her

1056
00:40:42,200 --> 00:40:45,720
riding ride a dragon and then you know

1057
00:40:44,240 --> 00:40:47,640
the output should be a photograph of a

1058
00:40:45,720 --> 00:40:49,880
girl riding a dragon so you give one or

1059
00:40:47,640 --> 00:40:52,319
two examples of what you want chpt can

1060
00:40:49,880 --> 00:40:53,599
just generate more of those the only

1061
00:40:52,319 --> 00:40:55,640
thing that you need to start with then

1062
00:40:53,599 --> 00:40:57,119
is a collection of image captions and

1063
00:40:55,640 --> 00:40:59,319
there are lots of databases out there

1064
00:40:57,119 --> 00:41:01,480
that contains a lot of image captions

1065
00:40:59,319 --> 00:41:03,800
that you can use to then ask chpt to

1066
00:41:01,480 --> 00:41:06,280
create Triplets of this kind so this is

1067
00:41:03,800 --> 00:41:07,960
one piece of what you need the second

1068
00:41:06,280 --> 00:41:10,880
thing that you need now is to generate

1069
00:41:07,960 --> 00:41:12,359
also pairs of images of before and after

1070
00:41:10,880 --> 00:41:13,599
and in particular there is a a

1071
00:41:12,359 --> 00:41:15,480
particular approach that is called

1072
00:41:13,599 --> 00:41:18,319
prompt to prompt that allows you to do

1073
00:41:15,480 --> 00:41:20,040
that so if you have two prompts each one

1074
00:41:18,319 --> 00:41:21,920
with a slight variation of the other one

1075
00:41:20,040 --> 00:41:24,000
they can generate two images where the

1076
00:41:21,920 --> 00:41:26,520
only change is whatever changes between

1077
00:41:24,000 --> 00:41:29,640
the two PRS but once you have that

1078
00:41:26,520 --> 00:41:33,000
that's it you're done now you have

1079
00:41:29,640 --> 00:41:34,880
oops now you have pairs of images and

1080
00:41:33,000 --> 00:41:36,240
the instruction you just need to reorder

1081
00:41:34,880 --> 00:41:38,000
you know the order in which inputs and

1082
00:41:36,240 --> 00:41:39,800
outputs are defined and that's it you

1083
00:41:38,000 --> 00:41:41,760
train your model so that's a very

1084
00:41:39,800 --> 00:41:44,200
creative way of creating your training

1085
00:41:41,760 --> 00:41:47,160
data is fully synthetic there there are

1086
00:41:44,200 --> 00:41:49,760
no real examples in this training

1087
00:41:47,160 --> 00:41:52,359
data so this is you know once you have

1088
00:41:49,760 --> 00:41:55,040
defined all these tools this is how the

1089
00:41:52,359 --> 00:41:57,520
Maya pron will look like where you have

1090
00:41:55,040 --> 00:41:59,920
you it's again a bunch of code that will

1091
00:41:57,520 --> 00:42:02,760
look like a python library that is just

1092
00:41:59,920 --> 00:42:05,839
part of what you input in the text

1093
00:42:02,760 --> 00:42:08,079
command and then you ask okay now tell

1094
00:42:05,839 --> 00:42:10,440
me what unit X is doing in this neural

1095
00:42:08,079 --> 00:42:12,480
network and it will just use the code to

1096
00:42:10,440 --> 00:42:13,839
write the script that is necessary to

1097
00:42:12,480 --> 00:42:16,160
understand what the neural network is

1098
00:42:13,839 --> 00:42:20,040
doing what is interesting is that it

1099
00:42:16,160 --> 00:42:21,920
actually will not just run the code and

1100
00:42:20,040 --> 00:42:23,720
give you a straight answer right away it

1101
00:42:21,920 --> 00:42:26,559
will actually keep

1102
00:42:23,720 --> 00:42:28,040
refining creating hypothesis and running

1103
00:42:26,559 --> 00:42:30,480
experiments until it reaches a

1104
00:42:28,040 --> 00:42:32,960
particular answer so it will not stop by

1105
00:42:30,480 --> 00:42:35,319
just running the code once so here is

1106
00:42:32,960 --> 00:42:38,160
what happens in one interaction with

1107
00:42:35,319 --> 00:42:40,839
with Maya so you start saying okay what

1108
00:42:38,160 --> 00:42:42,920
is that particular red unit there doing

1109
00:42:40,839 --> 00:42:44,960
in a particular pre-train model so the

1110
00:42:42,920 --> 00:42:48,880
first thing that it does it creates it

1111
00:42:44,960 --> 00:42:50,800
runs this code that throws all the

1112
00:42:48,880 --> 00:42:52,480
entire image net through the Nal Network

1113
00:42:50,800 --> 00:42:54,800
to see what most strongly activates that

1114
00:42:52,480 --> 00:42:57,319
unit and we don't tell the agent to

1115
00:42:54,800 --> 00:42:59,160
actually start experiments this way it

1116
00:42:57,319 --> 00:43:00,640
decides by itself that does an

1117
00:42:59,160 --> 00:43:02,400
interesting way of starting because it

1118
00:43:00,640 --> 00:43:04,440
will narrow down the number of

1119
00:43:02,400 --> 00:43:07,079
hypothesis so here there are no it

1120
00:43:04,440 --> 00:43:08,960
returns five images and the they are the

1121
00:43:07,079 --> 00:43:10,800
five that it returns so you can see the

1122
00:43:08,960 --> 00:43:12,720
activations in this case goes from zero

1123
00:43:10,800 --> 00:43:14,359
to one so these are strong activations

1124
00:43:12,720 --> 00:43:17,160
and it's highlighting this spherical

1125
00:43:14,359 --> 00:43:20,680
object but in fact you know Maya looks

1126
00:43:17,160 --> 00:43:23,720
at the images and he concludes that

1127
00:43:20,680 --> 00:43:25,640
oops that these images seem to be

1128
00:43:23,720 --> 00:43:27,400
showing a spherical objects interacting

1129
00:43:25,640 --> 00:43:28,880
with hands

1130
00:43:27,400 --> 00:43:30,400
which if you pay attention to the images

1131
00:43:28,880 --> 00:43:32,520
you will see that there is a hand always

1132
00:43:30,400 --> 00:43:35,680
over there not in the selected area but

1133
00:43:32,520 --> 00:43:38,079
just nearby so then it says well let's

1134
00:43:35,680 --> 00:43:40,839
actually check if this is true so let's

1135
00:43:38,079 --> 00:43:43,240
perform some editing experiments to test

1136
00:43:40,839 --> 00:43:44,920
this hypothesis so it runs the following

1137
00:43:43,240 --> 00:43:47,240
experiment it creates it uses two

1138
00:43:44,920 --> 00:43:49,040
prompts to create two images a person

1139
00:43:47,240 --> 00:43:51,079
holding a banana and a person holding a

1140
00:43:49,040 --> 00:43:52,920
cube so these are the two images that

1141
00:43:51,079 --> 00:43:54,400
Reg generate that are not a spherical

1142
00:43:52,920 --> 00:43:55,960
objects it's hand interacting with an

1143
00:43:54,400 --> 00:43:57,480
object but not an spherical object and

1144
00:43:55,960 --> 00:43:59,400
now it runs this through the the neural

1145
00:43:57,480 --> 00:44:02,520
network it has to write code to do that

1146
00:43:59,400 --> 00:44:04,440
too and these are the returns very low

1147
00:44:02,520 --> 00:44:07,480
activations the unit doesn't seem to

1148
00:44:04,440 --> 00:44:11,440
care about this images and now it says

1149
00:44:07,480 --> 00:44:13,800
well now let's uh edit this image from

1150
00:44:11,440 --> 00:44:15,640
non-spherical to aspherical and let's

1151
00:44:13,800 --> 00:44:18,400
analyze again the neuron Activation so

1152
00:44:15,640 --> 00:44:20,160
it runs it runs the tool that transform

1153
00:44:18,400 --> 00:44:21,480
images with an instruction in this case

1154
00:44:20,160 --> 00:44:23,000
there are these are the two commands

1155
00:44:21,480 --> 00:44:26,280
that is sense replace the cube with a

1156
00:44:23,000 --> 00:44:27,960
red ball replace the banana with a ball

1157
00:44:26,280 --> 00:44:29,880
so just to remind these are the two

1158
00:44:27,960 --> 00:44:32,200
input images and after these

1159
00:44:29,880 --> 00:44:34,359
Transformations the first one becomes a

1160
00:44:32,200 --> 00:44:36,160
hand holding a a ball you can see that

1161
00:44:34,359 --> 00:44:37,760
the hand is not perfect this you know

1162
00:44:36,160 --> 00:44:40,599
these models are not perfect so there

1163
00:44:37,760 --> 00:44:42,680
will be a lot of issues there and then

1164
00:44:40,599 --> 00:44:45,200
the banana gets transformed into this

1165
00:44:42,680 --> 00:44:47,559
which is pretty interesting not to see

1166
00:44:45,200 --> 00:44:50,040
the this is a pretty cute uh

1167
00:44:47,559 --> 00:44:51,520
transformation so it runs these images

1168
00:44:50,040 --> 00:44:53,599
through the neural network and it sees

1169
00:44:51,520 --> 00:44:56,319
that now the neural network gets

1170
00:44:53,599 --> 00:44:57,480
activated with these images and in fact

1171
00:44:56,319 --> 00:44:59,000
if you compare it with with the previous

1172
00:44:57,480 --> 00:45:02,359
activations you can see that there's a

1173
00:44:59,000 --> 00:45:05,920
big jump in the in the activations so it

1174
00:45:02,359 --> 00:45:07,760
concludes that yeah indeed this neuron

1175
00:45:05,920 --> 00:45:10,440
seems to be selective for hands

1176
00:45:07,760 --> 00:45:11,960
interacting with physical objects and

1177
00:45:10,440 --> 00:45:13,760
now you can say thank you and because

1178
00:45:11,960 --> 00:45:15,960
it's an llm it will tell you you're are

1179
00:45:13,760 --> 00:45:17,280
welcome and you know just to remind you

1180
00:45:15,960 --> 00:45:20,040
that at the end you're interacting with

1181
00:45:17,280 --> 00:45:21,800
an llm and things can get off hand you

1182
00:45:20,040 --> 00:45:24,960
know quickly depending on what you talk

1183
00:45:21,800 --> 00:45:26,720
about so we know this is correct because

1184
00:45:24,960 --> 00:45:28,359
we actually synthesize this unit is this

1185
00:45:26,720 --> 00:45:30,040
is not real unit inside an neural

1186
00:45:28,359 --> 00:45:32,040
network this is something that we have

1187
00:45:30,040 --> 00:45:33,800
created synthetically so that we can

1188
00:45:32,040 --> 00:45:36,200
evaluate performances in this case we

1189
00:45:33,800 --> 00:45:38,400
are using some which is a segmentation

1190
00:45:36,200 --> 00:45:40,599
algorithm that is driven by text and we

1191
00:45:38,400 --> 00:45:42,640
use that to create a model that will

1192
00:45:40,599 --> 00:45:44,720
actually be selected for balls when

1193
00:45:42,640 --> 00:45:47,319
hands are interacting with them so this

1194
00:45:44,720 --> 00:45:49,720
output was generated by this model that

1195
00:45:47,319 --> 00:45:52,280
we created so we knew exactly what the

1196
00:45:49,720 --> 00:45:53,920
ground truth was so we use that in order

1197
00:45:52,280 --> 00:45:55,920
to evaluate the model we have lots and

1198
00:45:53,920 --> 00:45:58,040
lots of different units that we that are

1199
00:45:55,920 --> 00:46:00,880
fake are not real unit that we use to

1200
00:45:58,040 --> 00:46:02,839
evaluate this model but we find similar

1201
00:46:00,880 --> 00:46:05,119
behaviors on real units so here is

1202
00:46:02,839 --> 00:46:06,920
another one this is a real unit inside a

1203
00:46:05,119 --> 00:46:09,280
neural network this one is selected for

1204
00:46:06,920 --> 00:46:11,480
tennis balls so it runs all these

1205
00:46:09,280 --> 00:46:13,440
experiments it formulates a number of

1206
00:46:11,480 --> 00:46:15,440
hypothesis so it's behaving like a

1207
00:46:13,440 --> 00:46:17,880
scientist and it's running you know it's

1208
00:46:15,440 --> 00:46:20,200
creating prompts that will test each

1209
00:46:17,880 --> 00:46:23,000
single hypothesis then it runs all this

1210
00:46:20,200 --> 00:46:24,680
on the neural network it sees it's

1211
00:46:23,000 --> 00:46:27,200
testing different context whether the

1212
00:46:24,680 --> 00:46:29,599
ball it can be any ball like if it's a

1213
00:46:27,200 --> 00:46:31,160
soccer ball does it work or if it's a

1214
00:46:29,599 --> 00:46:33,000
yellow feeli like maybe it's just the

1215
00:46:31,160 --> 00:46:34,480
color that is selected for and it

1216
00:46:33,000 --> 00:46:37,400
concludes that not this seems to be

1217
00:46:34,480 --> 00:46:39,359
really you know selective for tennis BS

1218
00:46:37,400 --> 00:46:41,240
so at the end it performs a number of

1219
00:46:39,359 --> 00:46:43,599
experiments until it reaches that

1220
00:46:41,240 --> 00:46:45,200
conclusion it's actually quite creative

1221
00:46:43,599 --> 00:46:47,319
these models can get quite creative in

1222
00:46:45,200 --> 00:46:50,480
the experiments they run so here is an

1223
00:46:47,319 --> 00:46:52,400
example where a is run a series of

1224
00:46:50,480 --> 00:46:54,640
experiments and he found a neuron that

1225
00:46:52,400 --> 00:46:57,400
is selective for facial features on

1226
00:46:54,640 --> 00:47:00,760
animals particular selective four eyes

1227
00:46:57,400 --> 00:47:03,280
and noses so then it decides to create a

1228
00:47:00,760 --> 00:47:06,319
picture that will contain a cut face

1229
00:47:03,280 --> 00:47:07,640
with clear eyes and nose and it runs

1230
00:47:06,319 --> 00:47:10,119
this through the neural network here is

1231
00:47:07,640 --> 00:47:11,720
the image and here is the activation so

1232
00:47:10,119 --> 00:47:13,480
effectively it seems to be reactive to

1233
00:47:11,720 --> 00:47:16,760
the nose and a leave it to the eyes and

1234
00:47:13,480 --> 00:47:19,319
it gives some a score and now it says

1235
00:47:16,760 --> 00:47:22,160
well let let's transfer the cat's eyes

1236
00:47:19,319 --> 00:47:25,000
and nose onto coffee cups this is very

1237
00:47:22,160 --> 00:47:27,920
creative like this is a very creative

1238
00:47:25,000 --> 00:47:30,160
experiment and you know run the edit

1239
00:47:27,920 --> 00:47:33,200
tool and it gives you this

1240
00:47:30,160 --> 00:47:35,800
picture which is you know very

1241
00:47:33,200 --> 00:47:38,160
interesting and it runs this and it does

1242
00:47:35,800 --> 00:47:40,599
not activate the unit so this is an

1243
00:47:38,160 --> 00:47:43,040
example of how creative this can get

1244
00:47:40,599 --> 00:47:45,280
this is another example where is detect

1245
00:47:43,040 --> 00:47:47,480
is SE realized that some unit seems to

1246
00:47:45,280 --> 00:47:51,000
be selective for birds and it's focusing

1247
00:47:47,480 --> 00:47:52,880
on the heads so it creates two images of

1248
00:47:51,000 --> 00:47:54,920
birds sitting on a branch and you see

1249
00:47:52,880 --> 00:47:57,319
the times two is using like python

1250
00:47:54,920 --> 00:48:01,280
tricks in order to do these things he

1251
00:47:57,319 --> 00:48:05,079
creates these two images and now he says

1252
00:48:01,280 --> 00:48:08,920
well let's replace the head of the bird

1253
00:48:05,079 --> 00:48:11,200
with a cat head and the head of the bird

1254
00:48:08,920 --> 00:48:14,599
on the second image with a dog head

1255
00:48:11,200 --> 00:48:16,680
which is crazy and then you here are the

1256
00:48:14,599 --> 00:48:18,559
original images these are the transform

1257
00:48:16,680 --> 00:48:20,640
images and let me zoom in you know these

1258
00:48:18,559 --> 00:48:22,480
are the heads that they put there so

1259
00:48:20,640 --> 00:48:25,319
it's really does look like a cat and a

1260
00:48:22,480 --> 00:48:27,520
dog and yeah the activations just go

1261
00:48:25,319 --> 00:48:28,920
down quite substantially

1262
00:48:27,520 --> 00:48:30,720
so it just just concludes his

1263
00:48:28,920 --> 00:48:32,359
experiments and continues doing and then

1264
00:48:30,720 --> 00:48:34,640
of course it has failures for instance

1265
00:48:32,359 --> 00:48:36,599
here it concludes that there is some

1266
00:48:34,640 --> 00:48:40,119
unit after some experiments that seems

1267
00:48:36,599 --> 00:48:41,920
to be Rel reacted to faces so it creates

1268
00:48:40,119 --> 00:48:44,240
an image with a family

1269
00:48:41,920 --> 00:48:46,000
picture the unit seems to actually not

1270
00:48:44,240 --> 00:48:48,760
care about faces but that doesn't seem

1271
00:48:46,000 --> 00:48:51,520
to bother the model and it says well you

1272
00:48:48,760 --> 00:48:53,359
know let's flip the family picture

1273
00:48:51,520 --> 00:48:56,440
upside down just to test if this is

1274
00:48:53,359 --> 00:48:58,720
really selective and flipping an image

1275
00:48:56,440 --> 00:49:00,319
upside down is a very simple task no

1276
00:48:58,720 --> 00:49:01,799
just you can actually write in Python

1277
00:49:00,319 --> 00:49:03,960
the code that will do this is very

1278
00:49:01,799 --> 00:49:06,480
simple but instead of that it uses the

1279
00:49:03,960 --> 00:49:09,200
tool to transform an image which is just

1280
00:49:06,480 --> 00:49:12,839
the wrong tool to use and it gives this

1281
00:49:09,200 --> 00:49:14,160
output which is crazy and it just you

1282
00:49:12,839 --> 00:49:16,680
know it says that it does not activate

1283
00:49:14,160 --> 00:49:18,319
the unit and still it concludes that

1284
00:49:16,680 --> 00:49:20,240
yeah this is you know selective for

1285
00:49:18,319 --> 00:49:22,440
parts of people and so on like this is

1286
00:49:20,240 --> 00:49:25,440
an example of a failure of reasoning

1287
00:49:22,440 --> 00:49:27,319
like the tools did not work the images

1288
00:49:25,440 --> 00:49:29,880
are not supporting the evidence and the

1289
00:49:27,319 --> 00:49:32,280
model still just happily goes and says

1290
00:49:29,880 --> 00:49:34,319
whatever it can whatever it wants to so

1291
00:49:32,280 --> 00:49:36,799
there's some confirmation bias going on

1292
00:49:34,319 --> 00:49:39,000
here so this with this I will conclude

1293
00:49:36,799 --> 00:49:42,240
so you can see agents are just this way

1294
00:49:39,000 --> 00:49:44,839
of creating tools that solve tasks so an

1295
00:49:42,240 --> 00:49:47,319
agent is really an llm at its core in

1296
00:49:44,839 --> 00:49:49,319
general enhanced with tools so that it

1297
00:49:47,319 --> 00:49:51,960
can interact with a world outside

1298
00:49:49,319 --> 00:49:54,040
perform actions get out outputs and

1299
00:49:51,960 --> 00:49:56,240
change its Behavior based on those

1300
00:49:54,040 --> 00:49:58,240
outputs so with that I will conclude I

1301
00:49:56,240 --> 00:50:02,020
can take a couple of questions while

1302
00:49:58,240 --> 00:50:10,329
Philip comes to the podium thank

1303
00:50:02,020 --> 00:50:10,329
[Applause]

1304
00:50:19,280 --> 00:50:23,359
you so the question is what are the most

1305
00:50:21,920 --> 00:50:25,880
promising

1306
00:50:23,359 --> 00:50:28,760
uses what do I think are the most

1307
00:50:25,880 --> 00:50:31,359
promising us uses of Agents well I think

1308
00:50:28,760 --> 00:50:32,880
that agents are there are lots of

1309
00:50:31,359 --> 00:50:34,880
promising uses I think that anything

1310
00:50:32,880 --> 00:50:37,200
that has to do with tool use so I think

1311
00:50:34,880 --> 00:50:39,680
that for instance is they are very

1312
00:50:37,200 --> 00:50:41,359
exciting in in the UC in the education

1313
00:50:39,680 --> 00:50:44,200
domain where you can actually have

1314
00:50:41,359 --> 00:50:45,880
agents per you know helping teach

1315
00:50:44,200 --> 00:50:49,319
material where they will ask questions

1316
00:50:45,880 --> 00:50:51,119
to a student get the results and and

1317
00:50:49,319 --> 00:50:52,839
refine the type of interactions that you

1318
00:50:51,119 --> 00:50:54,559
want to have so that the student

1319
00:50:52,839 --> 00:50:57,400
actually learns some Concepts so that's

1320
00:50:54,559 --> 00:50:58,960
a very interesting area of research uh

1321
00:50:57,400 --> 00:51:01,000
of course in healthcare there are lots

1322
00:50:58,960 --> 00:51:03,520
of potential uses and people are already

1323
00:51:01,000 --> 00:51:05,400
using them in different ways there are

1324
00:51:03,520 --> 00:51:06,720
lots of challenges also with the use so

1325
00:51:05,400 --> 00:51:08,960
you know there has to be an study of

1326
00:51:06,720 --> 00:51:11,359
their failure modes and how to better

1327
00:51:08,960 --> 00:51:13,799
use them and so on but these are like

1328
00:51:11,359 --> 00:51:15,240
some example of interesting areas but I

1329
00:51:13,799 --> 00:51:18,119
think that in scientific discovery there

1330
00:51:15,240 --> 00:51:22,440
are going to be very exciting so let me

1331
00:51:18,119 --> 00:51:22,440
take some more questions over there

1332
00:51:37,160 --> 00:51:41,799
so so the question is some of these

1333
00:51:39,839 --> 00:51:43,920
experiments as is performing experiments

1334
00:51:41,799 --> 00:51:45,799
they seem a bit random and you know is

1335
00:51:43,920 --> 00:51:47,400
there any guidance on how it should

1336
00:51:45,799 --> 00:51:49,599
perform the experiments so that it does

1337
00:51:47,400 --> 00:51:51,200
it's not so Random in this particular

1338
00:51:49,599 --> 00:51:53,880
set of experiments we did not provide

1339
00:51:51,200 --> 00:51:55,400
any guidance uh besides what appears on

1340
00:51:53,880 --> 00:51:57,040
the library with examples but there are

1341
00:51:55,400 --> 00:51:59,359
no examples of how to

1342
00:51:57,040 --> 00:52:00,880
actually we don't guide it on which

1343
00:51:59,359 --> 00:52:02,839
order on what type of experiments you

1344
00:52:00,880 --> 00:52:04,680
should be running first but that's

1345
00:52:02,839 --> 00:52:06,240
something that you can do you can

1346
00:52:04,680 --> 00:52:09,440
incorporate into the library a

1347
00:52:06,240 --> 00:52:11,119
description of what are common uses and

1348
00:52:09,440 --> 00:52:12,599
you know in particular scenarios how it

1349
00:52:11,119 --> 00:52:14,319
should be used to answer particular

1350
00:52:12,599 --> 00:52:16,160
questions that are pretty fine if then

1351
00:52:14,319 --> 00:52:18,359
if the question goes outside of that

1352
00:52:16,160 --> 00:52:20,240
then you know it's left to its own

1353
00:52:18,359 --> 00:52:22,200
devices to figure out some other random

1354
00:52:20,240 --> 00:52:23,559
process but if you have a set of

1355
00:52:22,200 --> 00:52:25,480
interactions that you know are very

1356
00:52:23,559 --> 00:52:27,880
commonly going to happen you could

1357
00:52:25,480 --> 00:52:29,799
provide guidance on how to do that just

1358
00:52:27,880 --> 00:52:32,079
like in the same way that you know

1359
00:52:29,799 --> 00:52:34,359
humans as humans we know exactly which

1360
00:52:32,079 --> 00:52:36,720
steps to follow when we solve tasks for

1361
00:52:34,359 --> 00:52:38,880
which we know there is a procedure that

1362
00:52:36,720 --> 00:52:40,880
normally works so here you can think of

1363
00:52:38,880 --> 00:52:44,160
something similar as how you will you

1364
00:52:40,880 --> 00:52:44,160
know train humans to solve

1365
00:52:44,280 --> 00:52:50,680
tasks so we'll have more time for

1366
00:52:46,520 --> 00:52:50,680
questions after but


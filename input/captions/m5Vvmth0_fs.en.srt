1
00:00:06,080 --> 00:00:11,519
hello everyone and welcome back to Cale

2
00:00:08,880 --> 00:00:14,839
office hours I am Daniela ruse the

3
00:00:11,519 --> 00:00:16,800
director of Cale where we are inventing

4
00:00:14,839 --> 00:00:19,600
the future of computing and making the

5
00:00:16,800 --> 00:00:22,680
world better through Computing today our

6
00:00:19,600 --> 00:00:25,840
Focus will be on health and how

7
00:00:22,680 --> 00:00:28,320
Computing and AI can help with

8
00:00:25,840 --> 00:00:31,240
diagnosing monitoring and treating

9
00:00:28,320 --> 00:00:33,840
disease Dina you have made so many

10
00:00:31,240 --> 00:00:36,920
impactful contributions to communication

11
00:00:33,840 --> 00:00:40,039
and to understanding Wireless signals

12
00:00:36,920 --> 00:00:43,280
how did you think to move from studying

13
00:00:40,039 --> 00:00:45,719
networking to applying Wireless signals

14
00:00:43,280 --> 00:00:48,719
to the healthcare sector maybe about

15
00:00:45,719 --> 00:00:52,920
eight years ago we started looking into

16
00:00:48,719 --> 00:00:55,399
how we can use um radio signals to

17
00:00:52,920 --> 00:00:58,039
monitor physiological signals so that

18
00:00:55,399 --> 00:01:00,320
was the early set of results basically

19
00:00:58,039 --> 00:01:02,519
just understanding that radio signal

20
00:01:00,320 --> 00:01:04,839
bounce around and they bounce out the

21
00:01:02,519 --> 00:01:07,280
human body because we are made of water

22
00:01:04,839 --> 00:01:08,799
so signal comes and reflects and then if

23
00:01:07,280 --> 00:01:10,280
you analyze those Reflections

24
00:01:08,799 --> 00:01:12,280
particularly if you analyze them with

25
00:01:10,280 --> 00:01:15,000
the power of neural network in machine

26
00:01:12,280 --> 00:01:17,520
learning you can start learning things

27
00:01:15,000 --> 00:01:20,560
that you couldn't imagine that these

28
00:01:17,520 --> 00:01:22,600
radio signals around us have or carry

29
00:01:20,560 --> 00:01:25,000
about us such as of course our

30
00:01:22,600 --> 00:01:27,040
respiration the pulsing of our blood

31
00:01:25,000 --> 00:01:28,920
even when you go to sleep we can tell

32
00:01:27,040 --> 00:01:31,400
whether you are in the dreaming stage

33
00:01:28,920 --> 00:01:34,320
for example ra versus you are in light

34
00:01:31,400 --> 00:01:37,880
sleep or deep sleep and then that took

35
00:01:34,320 --> 00:01:40,600
us to the Next Generation not just

36
00:01:37,880 --> 00:01:42,439
monitoring the physiological signals of

37
00:01:40,600 --> 00:01:45,600
people using radio signals without

38
00:01:42,439 --> 00:01:47,960
touching them but also collecting that

39
00:01:45,600 --> 00:01:51,640
data and starting to develop neural

40
00:01:47,960 --> 00:01:54,079
network model for uh diagnosing and

41
00:01:51,640 --> 00:01:56,719
tracking like what's called biomarkers

42
00:01:54,079 --> 00:02:00,600
of diseases for Parkinson's for other

43
00:01:56,719 --> 00:02:04,840
newgeneration diseases and the final

44
00:02:00,600 --> 00:02:08,239
the most recent thing is Gen AI for uh

45
00:02:04,840 --> 00:02:11,039
Medical Data with your algorithms and

46
00:02:08,239 --> 00:02:13,280
your insights in Wireless networking you

47
00:02:11,039 --> 00:02:16,080
can see what we cannot see with a naked

48
00:02:13,280 --> 00:02:17,560
eye how does this work it takes many

49
00:02:16,080 --> 00:02:19,879
years to diagnose Parkinson like

50
00:02:17,560 --> 00:02:22,200
somebody may had Parkinson 10 years ago

51
00:02:19,879 --> 00:02:24,360
and they haven't been diagnosed because

52
00:02:22,200 --> 00:02:26,200
one of the issue is that you wait for

53
00:02:24,360 --> 00:02:28,800
the motor symptoms you know in Parkinson

54
00:02:26,200 --> 00:02:30,360
the Tremor the stiffness of the motion

55
00:02:28,800 --> 00:02:33,120
and these motor symptoms

56
00:02:30,360 --> 00:02:37,040
appear late in the Disease by the time

57
00:02:33,120 --> 00:02:39,280
the motor symptoms appear the uh the

58
00:02:37,040 --> 00:02:43,280
dopamine neurons which are the neurons

59
00:02:39,280 --> 00:02:46,200
involved in in Parkinson about 40 to 80%

60
00:02:43,280 --> 00:02:48,400
are already damaged when we learned this

61
00:02:46,200 --> 00:02:50,599
we were just like oh but can we diagnose

62
00:02:48,400 --> 00:02:52,560
it from other signals now that we have

63
00:02:50,599 --> 00:02:54,720
these devices in people's home and we

64
00:02:52,560 --> 00:02:56,480
just take the wireless signal maybe from

65
00:02:54,720 --> 00:02:58,920
warless we know that we can get people

66
00:02:56,480 --> 00:03:00,480
breathing let me just try to detect

67
00:02:58,920 --> 00:03:01,720
whether they have parking from their

68
00:03:00,480 --> 00:03:04,400
breathing because there are some

69
00:03:01,720 --> 00:03:06,760
hypotheses that breathing like is

70
00:03:04,400 --> 00:03:08,720
impacted by the uh basically that

71
00:03:06,760 --> 00:03:10,760
Parkinson comes from the GS along the

72
00:03:08,720 --> 00:03:12,560
vagus nerve and then it has the

73
00:03:10,760 --> 00:03:15,360
breathing area in the brain so breathing

74
00:03:12,560 --> 00:03:17,200
changes earlier but actually it turned

75
00:03:15,360 --> 00:03:19,280
out that you can diagnose or machine

76
00:03:17,200 --> 00:03:21,519
learning algorithm can diagnose

77
00:03:19,280 --> 00:03:23,959
Parkinson with high accuracy from

78
00:03:21,519 --> 00:03:26,519
someone's breathing what is it that the

79
00:03:23,959 --> 00:03:28,959
intersection of understanding Wireless

80
00:03:26,519 --> 00:03:31,040
signals and understanding machine

81
00:03:28,959 --> 00:03:33,439
learning what is it at this intersection

82
00:03:31,040 --> 00:03:35,959
that helps you solve this problem we are

83
00:03:33,439 --> 00:03:37,959
not trained to look at radio signals but

84
00:03:35,959 --> 00:03:40,760
machine actually when you train them

85
00:03:37,959 --> 00:03:42,439
with the right output they they first

86
00:03:40,760 --> 00:03:45,519
they can sense the signal and they can

87
00:03:42,439 --> 00:03:48,560
start seeing patterns that the human

88
00:03:45,519 --> 00:03:50,400
brain is not trained to see from sensory

89
00:03:48,560 --> 00:03:52,640
signals that we don't have like

90
00:03:50,400 --> 00:03:54,560
electromagnetic waves where does this

91
00:03:52,640 --> 00:03:57,200
data come from the data that you use to

92
00:03:54,560 --> 00:03:59,280
train your models we designed a device

93
00:03:57,200 --> 00:04:01,720
that looks very much like your Wi-Fi box

94
00:03:59,280 --> 00:04:04,640
at home so sit in the background of the

95
00:04:01,720 --> 00:04:06,920
home and it's like analyzing these

96
00:04:04,640 --> 00:04:08,280
radial reflection transmit very low

97
00:04:06,920 --> 00:04:10,360
power Wireless signal analyzing the

98
00:04:08,280 --> 00:04:13,560
reflection and analyze them neural

99
00:04:10,360 --> 00:04:15,560
network and from that it can be like you

100
00:04:13,560 --> 00:04:18,280
don't have to wear devices on yourself

101
00:04:15,560 --> 00:04:20,440
people can live their lives and you can

102
00:04:18,280 --> 00:04:23,360
just get all of that insight to clinical

103
00:04:20,440 --> 00:04:25,240
data but it also convey the information

104
00:04:23,360 --> 00:04:27,520
to the medical doctor to the

105
00:04:25,240 --> 00:04:30,440
practitioner who's the expert and can

106
00:04:27,520 --> 00:04:33,039
help them can this model monitor for

107
00:04:30,440 --> 00:04:35,840
multiple diseases or is it finally tuned

108
00:04:33,039 --> 00:04:38,800
for Parkinson's U monitors multiple

109
00:04:35,840 --> 00:04:41,560
diseases particularly interested also I

110
00:04:38,800 --> 00:04:44,479
find the the biggest opportunity is in

111
00:04:41,560 --> 00:04:47,840
neurology and Immunology so it's very

112
00:04:44,479 --> 00:04:49,520
hard to to study neurological diseases

113
00:04:47,840 --> 00:04:52,240
even things like depression we ask

114
00:04:49,520 --> 00:04:54,919
people how do you feel but give you like

115
00:04:52,240 --> 00:04:57,800
a drug or treatment he said there's no

116
00:04:54,919 --> 00:05:00,240
actual concrete measurements to do that

117
00:04:57,800 --> 00:05:02,880
that's where we are seeing like our

118
00:05:00,240 --> 00:05:05,800
results from being able to concretely

119
00:05:02,880 --> 00:05:08,240
and objectively measure the physiology

120
00:05:05,800 --> 00:05:13,720
of the person and how it changes we can

121
00:05:08,240 --> 00:05:16,039
see a major uh opportunity to have a um

122
00:05:13,720 --> 00:05:17,960
what's called biomarket in this context

123
00:05:16,039 --> 00:05:19,759
digital biomarker for these complex

124
00:05:17,960 --> 00:05:22,000
diseases can you tell us a little bit

125
00:05:19,759 --> 00:05:24,600
more about Immunology what are you

126
00:05:22,000 --> 00:05:27,319
looking at in the space one essential

127
00:05:24,600 --> 00:05:30,000
thing of the immune system is that you

128
00:05:27,319 --> 00:05:31,880
are talking about a dynamic system a

129
00:05:30,000 --> 00:05:34,720
that is changing like it's just your

130
00:05:31,880 --> 00:05:36,520
immune response it's a response flare up

131
00:05:34,720 --> 00:05:38,639
there are flares you change you are in

132
00:05:36,520 --> 00:05:40,400
remission if you have like an autoimmune

133
00:05:38,639 --> 00:05:43,360
disease you are in remission and then

134
00:05:40,400 --> 00:05:46,440
you have a flare but in the whole

135
00:05:43,360 --> 00:05:47,840
medical system we don't have a the like

136
00:05:46,440 --> 00:05:49,800
all of the tests that we do are

137
00:05:47,840 --> 00:05:51,520
snapshots like when we talk in computer

138
00:05:49,800 --> 00:05:53,680
science we talk about snapshots ver

139
00:05:51,520 --> 00:05:55,800
versus like continuous tracking we don't

140
00:05:53,680 --> 00:05:58,039
have the continuous tracking and

141
00:05:55,800 --> 00:06:00,080
clinical data for that continuously can

142
00:05:58,039 --> 00:06:02,680
track a dynamic system like the immune

143
00:06:00,080 --> 00:06:05,800
system there is a hugee opportunity here

144
00:06:02,680 --> 00:06:07,160
to be able to move from snapshots

145
00:06:05,800 --> 00:06:09,880
particularly when you are talking about

146
00:06:07,160 --> 00:06:12,319
inflammatory response immune response to

147
00:06:09,880 --> 00:06:14,919
continuous data and where we can see

148
00:06:12,319 --> 00:06:17,960
where we are using our devices and Ai

149
00:06:14,919 --> 00:06:22,160
and to track these changes so are you

150
00:06:17,960 --> 00:06:24,720
finding that the Wi-Fi signals reflect

151
00:06:22,160 --> 00:06:27,440
differently if there is an immune system

152
00:06:24,720 --> 00:06:30,319
flare up when they bounce off my body

153
00:06:27,440 --> 00:06:32,520
your body the environment they change

154
00:06:30,319 --> 00:06:34,720
based on everything your respiration the

155
00:06:32,520 --> 00:06:37,440
pulsing of the blood the twitching of

156
00:06:34,720 --> 00:06:40,120
your eyes like different muscles all of

157
00:06:37,440 --> 00:06:42,160
the behavior that we have and things

158
00:06:40,120 --> 00:06:44,759
that we don't even think as of as

159
00:06:42,160 --> 00:06:47,560
Behavior so the physics of how the

160
00:06:44,759 --> 00:06:49,960
reflections happen don't change but when

161
00:06:47,560 --> 00:06:52,080
you extract this information from those

162
00:06:49,960 --> 00:06:54,680
Reflections now those change your

163
00:06:52,080 --> 00:06:56,599
respiratory system response to

164
00:06:54,680 --> 00:06:59,240
inflammation is going to be different

165
00:06:56,599 --> 00:07:01,599
your sleep and sleep patterns will

166
00:06:59,240 --> 00:07:04,199
change if somebody has a particular

167
00:07:01,599 --> 00:07:07,039
disease or taking particular drug so

168
00:07:04,199 --> 00:07:09,879
those then you can think about Ai and

169
00:07:07,039 --> 00:07:12,000
two levels one level is like taking

170
00:07:09,879 --> 00:07:14,680
radio signals and extracting from the

171
00:07:12,000 --> 00:07:16,479
physiological signals and then another

172
00:07:14,680 --> 00:07:18,840
level of neural networks that takes

173
00:07:16,479 --> 00:07:20,840
those physiological signal continuously

174
00:07:18,840 --> 00:07:22,520
extract it from the radio signal and

175
00:07:20,840 --> 00:07:23,960
start talking does this person have

176
00:07:22,520 --> 00:07:26,280
Alzheimer does this person have

177
00:07:23,960 --> 00:07:28,840
Parkinson how did their Parkinson change

178
00:07:26,280 --> 00:07:31,400
are they taking anti-depressant are they

179
00:07:28,840 --> 00:07:35,160
responding to is anti-depressant how do

180
00:07:31,400 --> 00:07:38,240
you use generative AI to get to better

181
00:07:35,160 --> 00:07:41,080
results being able to to take some

182
00:07:38,240 --> 00:07:43,960
simple signals or let's say like

183
00:07:41,080 --> 00:07:46,319
something from your Fitbit or some like

184
00:07:43,960 --> 00:07:48,960
your your pulse or something and

185
00:07:46,319 --> 00:07:52,560
transform that using generative AI to

186
00:07:48,960 --> 00:07:55,000
clinical test that was the use of

187
00:07:52,560 --> 00:07:56,919
generative AI that we are looking at and

188
00:07:55,000 --> 00:07:59,960
we actually do have initial data that

189
00:07:56,919 --> 00:08:03,039
shows that this is doable and the

190
00:07:59,960 --> 00:08:05,039
generated data is very much similar to

191
00:08:03,039 --> 00:08:08,000
the actual real data from the medical

192
00:08:05,039 --> 00:08:11,240
test for that person your generative AI

193
00:08:08,000 --> 00:08:14,039
system for medical data is it um what is

194
00:08:11,240 --> 00:08:17,240
the raw data used to train it we move

195
00:08:14,039 --> 00:08:20,120
from one medical modality that is cheap

196
00:08:17,240 --> 00:08:22,479
to a medical modality that is expensive

197
00:08:20,120 --> 00:08:24,560
a cheap medical modality it's it's kind

198
00:08:22,479 --> 00:08:28,080
of like a wellness modality like if I

199
00:08:24,560 --> 00:08:30,199
take the the PPG from uh like the puling

200
00:08:28,080 --> 00:08:33,240
from like AR device

201
00:08:30,199 --> 00:08:37,200
or uh the breathing from radio signal

202
00:08:33,240 --> 00:08:39,680
these are cheap available and easily and

203
00:08:37,200 --> 00:08:42,760
from that I generate something that is

204
00:08:39,680 --> 00:08:45,760
expensive like an EEG signal for example

205
00:08:42,760 --> 00:08:49,080
for the brain Dina it sounds like you

206
00:08:45,760 --> 00:08:51,959
have invented a new technology that is

207
00:08:49,080 --> 00:08:54,560
noninvasive and that gives doctors a

208
00:08:51,959 --> 00:08:57,040
kind of a superpower because it allows

209
00:08:54,560 --> 00:08:59,680
them to see things that are impossible

210
00:08:57,040 --> 00:09:01,200
to see with today's Technologies

211
00:08:59,680 --> 00:09:04,240
medicine I think there's a huge

212
00:09:01,200 --> 00:09:07,399
potential for competition in general I

213
00:09:04,240 --> 00:09:10,120
think even without a there are plenty of

214
00:09:07,399 --> 00:09:12,000
opportunity for competition but with

215
00:09:10,120 --> 00:09:14,279
machine learning also the the

216
00:09:12,000 --> 00:09:16,600
opportunities go even higher thank you

217
00:09:14,279 --> 00:09:19,760
for putting so much thought and effort

218
00:09:16,600 --> 00:09:23,000
in making healthc care better let's go

219
00:09:19,760 --> 00:09:24,720
meet MIT professor John gag John has

220
00:09:23,000 --> 00:09:27,120
been working with artificial

221
00:09:24,720 --> 00:09:28,920
intelligence and machine learning to

222
00:09:27,120 --> 00:09:30,200
develop the field of healthcare

223
00:09:28,920 --> 00:09:32,440
information

224
00:09:30,200 --> 00:09:36,040
and he has been looking at how machine

225
00:09:32,440 --> 00:09:37,640
learning can enhance the diagnosis of

226
00:09:36,040 --> 00:09:40,399
cardiac

227
00:09:37,640 --> 00:09:44,320
disease my first work in healthc care

228
00:09:40,399 --> 00:09:46,839
and AI was in in cardiovascular medicine

229
00:09:44,320 --> 00:09:49,360
and I had the good fortune that Colin

230
00:09:46,839 --> 00:09:52,000
staltz who's a member of cesil and a

231
00:09:49,360 --> 00:09:54,600
faculty member in eecs is also a

232
00:09:52,000 --> 00:09:58,320
practicing cardiologist Colin and I have

233
00:09:54,600 --> 00:10:01,640
been looking a lot at can we use

234
00:09:58,320 --> 00:10:04,040
non-invasive signals to get good

235
00:10:01,640 --> 00:10:06,959
approximations of data that is usually

236
00:10:04,040 --> 00:10:09,519
gathered invasively so the best example

237
00:10:06,959 --> 00:10:11,560
is probably an ECG measures the

238
00:10:09,519 --> 00:10:14,360
electrical activity of the heart every

239
00:10:11,560 --> 00:10:17,040
patient in the hospital is typically has

240
00:10:14,360 --> 00:10:20,600
an ECG connected to them what's been

241
00:10:17,040 --> 00:10:22,480
interesting is the things you might not

242
00:10:20,600 --> 00:10:25,399
expect to be able to get out of that

243
00:10:22,480 --> 00:10:27,640
signal but we think you can with the

244
00:10:25,399 --> 00:10:30,880
right kind of Technology machine

245
00:10:27,640 --> 00:10:32,600
learning machine learning to learn it

246
00:10:30,880 --> 00:10:34,880
but then of course when you're running

247
00:10:32,600 --> 00:10:37,839
it in practice you have to have forward

248
00:10:34,880 --> 00:10:40,399
passes that run fast the role of machine

249
00:10:37,839 --> 00:10:42,959
learning is to train a model that will

250
00:10:40,399 --> 00:10:45,680
give the right predictions is that right

251
00:10:42,959 --> 00:10:48,600
we use machine learning in healthc care

252
00:10:45,680 --> 00:10:51,240
in a lot of different ways sometimes

253
00:10:48,600 --> 00:10:52,279
it's used to train models that we'll

254
00:10:51,240 --> 00:10:55,880
actually

255
00:10:52,279 --> 00:10:58,519
deploy but other times we use it to do

256
00:10:55,880 --> 00:11:00,279
what I'll call science and and learn

257
00:10:58,519 --> 00:11:02,000
about things

258
00:11:00,279 --> 00:11:03,880
and once we've learned about them then

259
00:11:02,000 --> 00:11:05,639
the model maybe you don't need it

260
00:11:03,880 --> 00:11:07,120
anymore you you you've learned something

261
00:11:05,639 --> 00:11:09,560
you've done some experiments it's helped

262
00:11:07,120 --> 00:11:12,160
you learn things if we think of

263
00:11:09,560 --> 00:11:15,720
experience learning as you generating

264
00:11:12,160 --> 00:11:18,000
hypotheses that can then be tested in

265
00:11:15,720 --> 00:11:21,600
clinical settings or in the

266
00:11:18,000 --> 00:11:24,360
lab then you don't have to trust the

267
00:11:21,600 --> 00:11:25,600
model because all the model is doing is

268
00:11:24,360 --> 00:11:28,279
giving you things that you're going to

269
00:11:25,600 --> 00:11:29,959
test once the model generate finds

270
00:11:28,279 --> 00:11:32,880
hypotheses

271
00:11:29,959 --> 00:11:34,320
you can then maybe look for uh

272
00:11:32,880 --> 00:11:38,079
mechanistic

273
00:11:34,320 --> 00:11:40,000
explanations or look for rules maybe

274
00:11:38,079 --> 00:11:41,839
it's just discovering a rule and you can

275
00:11:40,000 --> 00:11:44,240
explain the rule to somebody and oh yeah

276
00:11:41,839 --> 00:11:47,440
that's a sensible Rule and so I think a

277
00:11:44,240 --> 00:11:48,279
lot of the use of machine learning today

278
00:11:47,440 --> 00:11:52,519
in

279
00:11:48,279 --> 00:11:56,079
healthcare is in the science part of it

280
00:11:52,519 --> 00:11:59,399
where we're discovering things that can

281
00:11:56,079 --> 00:12:01,639
then be used in the clinic we started

282
00:11:59,399 --> 00:12:04,320
with communicable diseases and we did

283
00:12:01,639 --> 00:12:06,480
that in conjunction with MGH with the

284
00:12:04,320 --> 00:12:09,160
infection control Department there so

285
00:12:06,480 --> 00:12:11,959
the infection control Department's

286
00:12:09,160 --> 00:12:14,680
responsibility is to reduce the

287
00:12:11,959 --> 00:12:17,079
incidence of healthc care Associated

288
00:12:14,680 --> 00:12:20,800
infections in the hospital we were

289
00:12:17,079 --> 00:12:22,560
approached to look at the question of

290
00:12:20,800 --> 00:12:26,440
could we use machine

291
00:12:22,560 --> 00:12:29,199
learning to find ways to reduce the

292
00:12:26,440 --> 00:12:32,000
prevalence of Health Care infections in

293
00:12:29,199 --> 00:12:36,680
in the hospital and the one we focus on

294
00:12:32,000 --> 00:12:40,079
to start with was uh CI the most common

295
00:12:36,680 --> 00:12:41,920
one it's an intestinal disease bacterial

296
00:12:40,079 --> 00:12:43,480
disease our

297
00:12:41,920 --> 00:12:46,120
models

298
00:12:43,480 --> 00:12:48,800
predicted which patients were most

299
00:12:46,120 --> 00:12:51,360
likely to contract the disease if you

300
00:12:48,800 --> 00:12:53,880
know that someone is likely to contract

301
00:12:51,360 --> 00:12:56,399
the disease you'll be more aggressive

302
00:12:53,880 --> 00:12:57,880
about knowing when to test them and that

303
00:12:56,399 --> 00:13:00,880
will let you discover they have it

304
00:12:57,880 --> 00:13:02,800
sooner and our treatment sooner and so

305
00:13:00,880 --> 00:13:06,279
what we did is we built models that were

306
00:13:02,800 --> 00:13:08,440
quite effective at determining which

307
00:13:06,279 --> 00:13:10,959
members of the population were most

308
00:13:08,440 --> 00:13:13,800
vulnerable so if we look at what makes

309
00:13:10,959 --> 00:13:18,680
people susceptible uh some of what we

310
00:13:13,800 --> 00:13:19,959
found was already known when the uh ant

311
00:13:18,680 --> 00:13:21,800
some

312
00:13:19,959 --> 00:13:23,680
antimicrobials uh increase the

313
00:13:21,800 --> 00:13:27,600
likelihood of Contracting

314
00:13:23,680 --> 00:13:30,040
sedi and some more than others we

315
00:13:27,600 --> 00:13:32,760
found zip code

316
00:13:30,040 --> 00:13:35,760
was important now he said how on Earth

317
00:13:32,760 --> 00:13:38,639
can where a patient lives matter some of

318
00:13:35,760 --> 00:13:40,959
what they think of Hospital acquired was

319
00:13:38,639 --> 00:13:42,920
actually the bacterium was already in

320
00:13:40,959 --> 00:13:44,720
the patient system and then something

321
00:13:42,920 --> 00:13:46,880
that happened in the hospital allowed it

322
00:13:44,720 --> 00:13:49,920
to flourish and get worse and so the

323
00:13:46,880 --> 00:13:51,680
bacterium came from the community and it

324
00:13:49,920 --> 00:13:54,079
was say the treatment in the hospital

325
00:13:51,680 --> 00:13:56,560
that made it flourish suddenly it made

326
00:13:54,079 --> 00:13:58,279
sense and we looked at these zip codes

327
00:13:56,560 --> 00:14:00,680
and for example there were often zip

328
00:13:58,279 --> 00:14:03,279
codes that had a lot of nursing homes in

329
00:14:00,680 --> 00:14:05,680
them so John for this uh work in

330
00:14:03,279 --> 00:14:08,240
communicable diseases can you tell us a

331
00:14:05,680 --> 00:14:11,440
bit about the techniques that you have

332
00:14:08,240 --> 00:14:13,519
used about the computational aspects of

333
00:14:11,440 --> 00:14:16,240
the solutions one of the things that's

334
00:14:13,519 --> 00:14:19,320
interesting about a communicable disease

335
00:14:16,240 --> 00:14:22,079
is is the fact that you need exposure

336
00:14:19,320 --> 00:14:23,320
and that means you have to look at

337
00:14:22,079 --> 00:14:26,279
Network

338
00:14:23,320 --> 00:14:28,320
effects and a lot of machine learning

339
00:14:26,279 --> 00:14:30,440
algorithms don't really deal with

340
00:14:28,320 --> 00:14:32,160
Networks

341
00:14:30,440 --> 00:14:34,800
and so a lot of what we did was was

342
00:14:32,160 --> 00:14:38,360
looking at at connectivity networks to

343
00:14:34,800 --> 00:14:40,720
try and and and build models based upon

344
00:14:38,360 --> 00:14:44,079
that and you use machine learning for

345
00:14:40,720 --> 00:14:47,480
that yes how did you train your models

346
00:14:44,079 --> 00:14:50,480
we were able to get access to all of the

347
00:14:47,480 --> 00:14:52,880
MGH patient records you can look at the

348
00:14:50,480 --> 00:14:55,600
patient record and see which nurses are

349
00:14:52,880 --> 00:14:58,120
visiting which patients which doctors

350
00:14:55,600 --> 00:14:59,680
are visiting which patients where they

351
00:14:58,120 --> 00:15:01,839
are we actually looked at the

352
00:14:59,680 --> 00:15:04,759
architecture of the hospital but the

353
00:15:01,839 --> 00:15:06,839
most important network was the caregiver

354
00:15:04,759 --> 00:15:09,440
Network what are you working on right

355
00:15:06,839 --> 00:15:12,120
now the biggest investment in my lab

356
00:15:09,440 --> 00:15:15,560
right now is in medical imaging and

357
00:15:12,120 --> 00:15:18,000
machine learning has is in the process

358
00:15:15,560 --> 00:15:19,920
of totally revolutionizing Medical

359
00:15:18,000 --> 00:15:22,680
Imaging so if you think of the amount of

360
00:15:19,920 --> 00:15:25,480
data produced by an

361
00:15:22,680 --> 00:15:29,319
MRI it's three-dimensional high

362
00:15:25,480 --> 00:15:31,880
resolution typically and it's more data

363
00:15:29,319 --> 00:15:34,759
than a human can possibly look at there

364
00:15:31,880 --> 00:15:37,519
are a small number of tasks that you

365
00:15:34,759 --> 00:15:38,800
have to do for any kind of image one of

366
00:15:37,519 --> 00:15:41,000
them is

367
00:15:38,800 --> 00:15:45,920
segmentation so that involves you take

368
00:15:41,000 --> 00:15:49,319
an image and you find Regions that are

369
00:15:45,920 --> 00:15:51,480
anatomically significant and separate

370
00:15:49,319 --> 00:15:53,639
them from the rest of the image so

371
00:15:51,480 --> 00:15:56,160
segmentation is very important but not

372
00:15:53,639 --> 00:15:59,120
just for things like tumors for a lot of

373
00:15:56,160 --> 00:16:03,120
say neurological diseases you want to

374
00:15:59,120 --> 00:16:04,880
look at the shape of say the hippocampus

375
00:16:03,120 --> 00:16:06,519
you know what is this exact shape is the

376
00:16:04,880 --> 00:16:09,120
shape changing and to do that you have

377
00:16:06,519 --> 00:16:11,800
to find it and segment it very precisely

378
00:16:09,120 --> 00:16:15,199
we have built something which we call

379
00:16:11,800 --> 00:16:17,240
univers EG Universal segmentor it's

380
00:16:15,199 --> 00:16:18,759
important because the other Universal

381
00:16:17,240 --> 00:16:21,720
segmentors that are out there and there

382
00:16:18,759 --> 00:16:23,759
quite a few work only for natural images

383
00:16:21,720 --> 00:16:27,600
really they don't work very well for

384
00:16:23,759 --> 00:16:29,759
medical images and you need something

385
00:16:27,600 --> 00:16:32,079
that's very Broad

386
00:16:29,759 --> 00:16:35,680
because there are an enormous number of

387
00:16:32,079 --> 00:16:40,399
different modalities ultrasound to x-ray

388
00:16:35,680 --> 00:16:43,120
to to Mr to Optical to ooc all sorts of

389
00:16:40,399 --> 00:16:46,319
things he collected an enormous amount

390
00:16:43,120 --> 00:16:49,399
of data from many different Medical

391
00:16:46,319 --> 00:16:51,560
Imaging modalities many different tasks

392
00:16:49,399 --> 00:16:54,079
we then invented ways to generate

393
00:16:51,560 --> 00:16:56,160
synthetic data if you look at our

394
00:16:54,079 --> 00:16:58,639
synthetic data it doesn't look like any

395
00:16:56,160 --> 00:17:02,759
medical image anyone has ever seen or

396
00:16:58,639 --> 00:17:05,120
any task anyone has ever seen but it

397
00:17:02,759 --> 00:17:07,959
makes it prevents the model from

398
00:17:05,120 --> 00:17:10,480
overfitting to the actual tasks you show

399
00:17:07,959 --> 00:17:13,160
it during the training other thing we've

400
00:17:10,480 --> 00:17:15,679
done with Universe egg is is it's what's

401
00:17:13,160 --> 00:17:17,760
called context based learning at

402
00:17:15,679 --> 00:17:20,400
inference time when someone is trying to

403
00:17:17,760 --> 00:17:23,439
say segment something that they don't

404
00:17:20,400 --> 00:17:26,640
know how to segment what we do is you

405
00:17:23,439 --> 00:17:31,400
give it a small number of examples and

406
00:17:26,640 --> 00:17:32,919
that's used as a prompt to say oh that's

407
00:17:31,400 --> 00:17:35,840
the kind of that's what they're looking

408
00:17:32,919 --> 00:17:38,039
for and then based upon that small

409
00:17:35,840 --> 00:17:40,799
context and all of the other examples

410
00:17:38,039 --> 00:17:43,039
that's been trained on it then can

411
00:17:40,799 --> 00:17:45,120
generate quite good

412
00:17:43,039 --> 00:17:48,400
segmentations and we think eventually

413
00:17:45,120 --> 00:17:51,280
will be as good right now if you train a

414
00:17:48,400 --> 00:17:53,559
a one of model for one modality and one

415
00:17:51,280 --> 00:17:57,720
Anatomy it's slightly better than the

416
00:17:53,559 --> 00:17:59,480
universal segmentor as you think about

417
00:17:57,720 --> 00:18:02,960
computational tools

418
00:17:59,480 --> 00:18:05,840
and their potential in healthare where

419
00:18:02,960 --> 00:18:09,480
do you see us going in the next 3 to 5

420
00:18:05,840 --> 00:18:12,159
years the large population studies will

421
00:18:09,480 --> 00:18:14,679
be the first thing impacted I think by a

422
00:18:12,159 --> 00:18:16,919
lot of the machine learning technology

423
00:18:14,679 --> 00:18:19,840
and I think it'll have enormous impact

424
00:18:16,919 --> 00:18:23,200
on things like tele medicine instead of

425
00:18:19,840 --> 00:18:26,760
having a person move to the clinic we

426
00:18:23,200 --> 00:18:29,559
acquire data and send the data to a

427
00:18:26,760 --> 00:18:33,320
computer and the data the computer looks

428
00:18:29,559 --> 00:18:36,000
at it and I think we can make very quick

429
00:18:33,320 --> 00:18:38,840
inroads in using machine learning to

430
00:18:36,000 --> 00:18:42,080
build models that will

431
00:18:38,840 --> 00:18:44,840
improve the health care system if Health

432
00:18:42,080 --> 00:18:47,720
Care gets less expensive we'll get

433
00:18:44,840 --> 00:18:49,480
better outcomes an awful lot of people

434
00:18:47,720 --> 00:18:51,440
don't get the treatment they need today

435
00:18:49,480 --> 00:18:53,679
because they can't afford it if we can

436
00:18:51,440 --> 00:18:56,280
reduce the cost it isn't just saving

437
00:18:53,679 --> 00:18:58,880
money it will give us better

438
00:18:56,280 --> 00:19:01,919
outcomes John thank you so much for

439
00:18:58,880 --> 00:19:03,919
sharing with us your work your results

440
00:19:01,919 --> 00:19:07,280
and your wisdom about the use of

441
00:19:03,919 --> 00:19:10,000
computational tools in healthcare now

442
00:19:07,280 --> 00:19:12,679
let's go to see what Professor marier

443
00:19:10,000 --> 00:19:17,760
gasmi has been up

444
00:19:12,679 --> 00:19:20,640
to I want to start by asking you about

445
00:19:17,760 --> 00:19:24,159
your work in rule violations and so you

446
00:19:20,640 --> 00:19:27,200
have shown that AI models fail to

447
00:19:24,159 --> 00:19:30,640
reproduce human judgment in identifying

448
00:19:27,200 --> 00:19:32,400
rule violations what is this all about

449
00:19:30,640 --> 00:19:34,640
well the issue is that when we label

450
00:19:32,400 --> 00:19:37,000
machine learning data sets in standard

451
00:19:34,640 --> 00:19:40,000
settings we're always asking people if a

452
00:19:37,000 --> 00:19:42,280
feature exists is a dog big or is a meal

453
00:19:40,000 --> 00:19:44,000
sugary but that's not actually why we

454
00:19:42,280 --> 00:19:45,640
train machine Learning Systems we

455
00:19:44,000 --> 00:19:47,960
usually train them to predict a

456
00:19:45,640 --> 00:19:50,480
violation of some rule is this meal too

457
00:19:47,960 --> 00:19:52,760
sugary for the school rules or is this

458
00:19:50,480 --> 00:19:54,360
dog too large for the building's Rule

459
00:19:52,760 --> 00:19:56,559
and so in that setting it's really

460
00:19:54,360 --> 00:19:58,320
important that we tell people you're

461
00:19:56,559 --> 00:20:00,960
going to be judging whether a dog is

462
00:19:58,320 --> 00:20:02,919
large for a rule violation because what

463
00:20:00,960 --> 00:20:05,679
we found is that people's Judgment of

464
00:20:02,919 --> 00:20:07,679
whether a dog is large actually flips

465
00:20:05,679 --> 00:20:09,679
when you tell them that it's being used

466
00:20:07,679 --> 00:20:11,679
to create a rule in a machine Learning

467
00:20:09,679 --> 00:20:14,240
System how does this translate to

468
00:20:11,679 --> 00:20:16,240
medicine if we have labels that don't

469
00:20:14,240 --> 00:20:18,000
reflect the ultimate judgment that's

470
00:20:16,240 --> 00:20:20,039
being made it's possible that some

471
00:20:18,000 --> 00:20:21,880
people will be denied services that a

472
00:20:20,039 --> 00:20:24,000
human judgment would have given them in

473
00:20:21,880 --> 00:20:26,799
the first place so what can we do about

474
00:20:24,000 --> 00:20:28,799
this we can look at giving more uh

475
00:20:26,799 --> 00:20:30,880
specific prompts to people who are

476
00:20:28,799 --> 00:20:33,960
judging whether a feature is present in

477
00:20:30,880 --> 00:20:35,760
an image or in text or in tabular data

478
00:20:33,960 --> 00:20:38,159
and let them know that this judgment

479
00:20:35,760 --> 00:20:40,240
will be used in a specific human rule

480
00:20:38,159 --> 00:20:41,280
setting and when they have that context

481
00:20:40,240 --> 00:20:42,440
we think that they'll make better

482
00:20:41,280 --> 00:20:44,400
judgments so we can have machine

483
00:20:42,440 --> 00:20:46,960
learning systems that mimic human

484
00:20:44,400 --> 00:20:49,760
judgments what we found is that when you

485
00:20:46,960 --> 00:20:52,400
try to improve the models that are using

486
00:20:49,760 --> 00:20:54,840
this data you have to make assumptions

487
00:20:52,400 --> 00:20:56,200
about how harsh the system should be and

488
00:20:54,840 --> 00:20:58,640
so when we looked at algorithmic

489
00:20:56,200 --> 00:21:01,159
improvements if you can make good gu

490
00:20:58,640 --> 00:21:03,640
guesses about where the threshold might

491
00:21:01,159 --> 00:21:05,200
be for the data so for example I know

492
00:21:03,640 --> 00:21:08,640
you've labeled this feature about a

493
00:21:05,200 --> 00:21:10,640
large dog factually but if I asked you

494
00:21:08,640 --> 00:21:13,000
subjectively whether it's a large dog in

495
00:21:10,640 --> 00:21:14,240
violation of a rule if you can guess

496
00:21:13,000 --> 00:21:16,000
what that would do to somebody's

497
00:21:14,240 --> 00:21:18,120
judgments then you can try to fix some

498
00:21:16,000 --> 00:21:20,000
of this on the algorithm side but

499
00:21:18,120 --> 00:21:22,039
couldn't you tweak it too much the other

500
00:21:20,000 --> 00:21:24,000
way so couldn't the system be abused

501
00:21:22,039 --> 00:21:25,880
then that's why we think there needs to

502
00:21:24,000 --> 00:21:27,440
be a holistic difference in How We

503
00:21:25,880 --> 00:21:29,480
Gather these labels in machine learning

504
00:21:27,440 --> 00:21:30,840
data sets you can't fix it all with the

505
00:21:29,480 --> 00:21:32,720
algorithm this is something we really

506
00:21:30,840 --> 00:21:35,080
need to change from the ground up and

507
00:21:32,720 --> 00:21:36,600
how would this look for medicine well in

508
00:21:35,080 --> 00:21:38,640
medicine what we've been looking at

509
00:21:36,600 --> 00:21:40,120
recently is how we can give doctors

510
00:21:38,640 --> 00:21:42,159
descriptive or prescriptive

511
00:21:40,120 --> 00:21:44,240
recommendations for different kinds of

512
00:21:42,159 --> 00:21:46,200
actions when you think about the ways

513
00:21:44,240 --> 00:21:49,120
that you could give advice to somebody

514
00:21:46,200 --> 00:21:51,360
usually it's based on an if then rule so

515
00:21:49,120 --> 00:21:54,400
if the meal is sugary then it's a rule

516
00:21:51,360 --> 00:21:56,840
violation or if the patient has a risk

517
00:21:54,400 --> 00:21:58,840
of mental illness then refer them to a

518
00:21:56,840 --> 00:22:01,400
psychiatrist and so we want to to look

519
00:21:58,840 --> 00:22:03,799
at whether these descriptions of whether

520
00:22:01,400 --> 00:22:05,799
a meal is sugary or a dog is large were

521
00:22:03,799 --> 00:22:08,400
the right thing to give a patient or

522
00:22:05,799 --> 00:22:11,320
their Advocate versus the Judgment this

523
00:22:08,400 --> 00:22:13,000
prescriptive action of saying that a dog

524
00:22:11,320 --> 00:22:15,039
is in violation or a meal is in

525
00:22:13,000 --> 00:22:17,080
violation or a patient should see a

526
00:22:15,039 --> 00:22:18,600
psychiatrist and so what we did is we

527
00:22:17,080 --> 00:22:20,400
looked at different settings such as

528
00:22:18,600 --> 00:22:22,120
Mental Health crisis lines where you

529
00:22:20,400 --> 00:22:24,360
could either say that a patient has a

530
00:22:22,120 --> 00:22:26,440
risk of violence or that you should call

531
00:22:24,360 --> 00:22:28,039
the police to help that patient and we

532
00:22:26,440 --> 00:22:30,440
wanted to look at what happened when we

533
00:22:28,039 --> 00:22:33,360
gave very biased advice from an AI

534
00:22:30,440 --> 00:22:34,919
system to doctors either descriptively

535
00:22:33,360 --> 00:22:37,360
saying there's always a risk of violence

536
00:22:34,919 --> 00:22:39,240
for minorities or prescriptively saying

537
00:22:37,360 --> 00:22:41,480
you should call the police on minorities

538
00:22:39,240 --> 00:22:43,440
consistently what we found is that if

539
00:22:41,480 --> 00:22:45,520
you give really biased AI advice to

540
00:22:43,440 --> 00:22:46,960
doctors in a descriptive way you just

541
00:22:45,520 --> 00:22:48,760
say that there's a high risk of violence

542
00:22:46,960 --> 00:22:50,440
for all the minority patients doctors

543
00:22:48,760 --> 00:22:52,679
don't listen to it they retain their

544
00:22:50,440 --> 00:22:54,200
original Fair judgment but when you tell

545
00:22:52,679 --> 00:22:56,039
them to call the police

546
00:22:54,200 --> 00:22:57,320
disproportionately then they do listen

547
00:22:56,039 --> 00:22:59,600
to it so this prescriptive

548
00:22:57,320 --> 00:23:01,360
recommendation that tells what to do

549
00:22:59,600 --> 00:23:03,600
somehow short circuits critical thinking

550
00:23:01,360 --> 00:23:05,559
skills and so in health specifically we

551
00:23:03,600 --> 00:23:07,679
need to think carefully about not only

552
00:23:05,559 --> 00:23:10,200
what predictions were making but also

553
00:23:07,679 --> 00:23:11,559
exactly how we deliver those predictions

554
00:23:10,200 --> 00:23:13,559
and what we find is with these

555
00:23:11,559 --> 00:23:15,320
descriptive systems you're giving them

556
00:23:13,559 --> 00:23:17,279
the rules and they're able to follow

557
00:23:15,320 --> 00:23:19,279
through on these judgments and have

558
00:23:17,279 --> 00:23:21,760
really good critical thinking skills but

559
00:23:19,279 --> 00:23:24,240
when we give them the end result just

560
00:23:21,760 --> 00:23:26,000
shortcut to the answer they don't

561
00:23:24,240 --> 00:23:27,840
actually go through the process and so

562
00:23:26,000 --> 00:23:29,400
they miss mistakes that the model might

563
00:23:27,840 --> 00:23:31,559
make and so it's crucial that when you

564
00:23:29,400 --> 00:23:33,960
have a system helping people it helps

565
00:23:31,559 --> 00:23:36,000
them through the thinking process not

566
00:23:33,960 --> 00:23:39,400
through this sort of efficient shortcut

567
00:23:36,000 --> 00:23:43,120
that they could have we find that when

568
00:23:39,400 --> 00:23:44,960
people are very good at the task then

569
00:23:43,120 --> 00:23:47,840
you can train a machine learning system

570
00:23:44,960 --> 00:23:50,200
based on past labels in this data and

571
00:23:47,840 --> 00:23:52,200
then that model will be so good that you

572
00:23:50,200 --> 00:23:54,240
could probably just use a prescriptive

573
00:23:52,200 --> 00:23:56,159
system and say go ahead and follow the

574
00:23:54,240 --> 00:23:58,960
model we think that most of the data we

575
00:23:56,159 --> 00:24:01,279
have while it's good it has errors it

576
00:23:58,960 --> 00:24:03,200
has flaws there's variation and so we

577
00:24:01,279 --> 00:24:05,640
want people to continue to understand

578
00:24:03,200 --> 00:24:08,039
how to make these decisions with advice

579
00:24:05,640 --> 00:24:09,799
but not always follow it now in addition

580
00:24:08,039 --> 00:24:11,960
to descriptive and prescriptive

581
00:24:09,799 --> 00:24:14,600
Solutions you're also considering

582
00:24:11,960 --> 00:24:16,840
normative Solutions normative Solutions

583
00:24:14,600 --> 00:24:20,279
are things that we believe that people

584
00:24:16,840 --> 00:24:22,480
should do in most cases that others have

585
00:24:20,279 --> 00:24:24,640
judged as being the right decisions to

586
00:24:22,480 --> 00:24:26,520
make this doesn't always happen in a

587
00:24:24,640 --> 00:24:28,520
health care setting but there are some

588
00:24:26,520 --> 00:24:29,960
really wellestablished care pathways you

589
00:24:28,520 --> 00:24:32,039
can look at in machine learning for

590
00:24:29,960 --> 00:24:34,799
health where we know the right things to

591
00:24:32,039 --> 00:24:37,039
do we want to reduce the variation in

592
00:24:34,799 --> 00:24:39,000
how different patients are treated and

593
00:24:37,039 --> 00:24:41,080
have a more normative solution because

594
00:24:39,000 --> 00:24:43,399
we know the right answer so how do you

595
00:24:41,080 --> 00:24:45,840
go from descriptive and prescriptive to

596
00:24:43,399 --> 00:24:48,360
normative for many chronic conditions

597
00:24:45,840 --> 00:24:50,000
there's huge variation one person's

598
00:24:48,360 --> 00:24:52,000
diabetes is not another person's

599
00:24:50,000 --> 00:24:54,159
diabetes one person's pregnancy is not a

600
00:24:52,000 --> 00:24:55,840
person's pregnancy and so because

601
00:24:54,159 --> 00:24:57,480
there's a length of time over which you

602
00:24:55,840 --> 00:24:59,720
have different complications there's

603
00:24:57,480 --> 00:25:01,880
going to be so much room for variation

604
00:24:59,720 --> 00:25:04,320
but a septic patient is often a septic

605
00:25:01,880 --> 00:25:05,840
patient they're so acutely ill that the

606
00:25:04,320 --> 00:25:08,240
way that you can treat them the number

607
00:25:05,840 --> 00:25:10,360
of levers you have to pull they're very

608
00:25:08,240 --> 00:25:12,279
small and the variation is also very

609
00:25:10,360 --> 00:25:15,279
small and so we'd like to have more

610
00:25:12,279 --> 00:25:18,120
normative actions this work is so

611
00:25:15,279 --> 00:25:21,720
important and it raises such profound

612
00:25:18,120 --> 00:25:24,200
ethics issues with deploying AI in

613
00:25:21,720 --> 00:25:25,919
medicine when you give advice to

614
00:25:24,200 --> 00:25:27,760
somebody who's already Bound by an

615
00:25:25,919 --> 00:25:30,039
Ethics code as all clinical staff and

616
00:25:27,760 --> 00:25:32,320
clinicians are are what is your

617
00:25:30,039 --> 00:25:34,279
additional responsibility as a technical

618
00:25:32,320 --> 00:25:36,600
person who's contributing to their

619
00:25:34,279 --> 00:25:38,919
interaction with a human system there's

620
00:25:36,600 --> 00:25:41,320
no easy answer but what we're trying to

621
00:25:38,919 --> 00:25:43,679
do right now is understand where all the

622
00:25:41,320 --> 00:25:45,679
biases in the process are from

623
00:25:43,679 --> 00:25:47,600
collecting the data to defining the

624
00:25:45,679 --> 00:25:49,960
labels to developing the algorithm to

625
00:25:47,600 --> 00:25:53,640
deploying specific advice and we think

626
00:25:49,960 --> 00:25:55,320
by codifying those and auditing them and

627
00:25:53,640 --> 00:25:57,240
letting the people actually using the

628
00:25:55,320 --> 00:25:58,919
systems know what's happening we can

629
00:25:57,240 --> 00:26:00,840
have a better end to-end system where

630
00:25:58,919 --> 00:26:02,799
doctors make those judgments what else

631
00:26:00,840 --> 00:26:05,640
are you excited about what's the future

632
00:26:02,799 --> 00:26:09,440
in your lab having systems that can flag

633
00:26:05,640 --> 00:26:12,159
incorrect data from the get-go in large

634
00:26:09,440 --> 00:26:14,360
systems in an unsupervised way this is

635
00:26:12,159 --> 00:26:16,480
definitely a problem in health it's also

636
00:26:14,360 --> 00:26:18,360
a problem in places like computer vision

637
00:26:16,480 --> 00:26:20,320
where we know that images of abuse and

638
00:26:18,360 --> 00:26:22,600
inappropriate treatment make it into

639
00:26:20,320 --> 00:26:24,640
large image data sets and then if you're

640
00:26:22,600 --> 00:26:26,679
not looking through these huge sets of

641
00:26:24,640 --> 00:26:28,840
images they can make it into Downstream

642
00:26:26,679 --> 00:26:31,760
models so if we have systems that can

643
00:26:28,840 --> 00:26:33,919
successfully audit data sets then we can

644
00:26:31,760 --> 00:26:35,840
have a better set of data to learn from

645
00:26:33,919 --> 00:26:37,919
from the beginning and then all the way

646
00:26:35,840 --> 00:26:39,679
on the other side I'm really excited

647
00:26:37,919 --> 00:26:42,360
about understanding how we can take

648
00:26:39,679 --> 00:26:45,360
deployments and deliver advice in a way

649
00:26:42,360 --> 00:26:47,200
that doesn't perpetuate biases but helps

650
00:26:45,360 --> 00:26:50,000
clinicians create more Equitable

651
00:26:47,200 --> 00:26:52,120
Healthcare Systems within their practice

652
00:26:50,000 --> 00:26:55,120
we don't want to create supervised

653
00:26:52,120 --> 00:26:57,080
systems for identifying bad quality or

654
00:26:55,120 --> 00:26:59,039
inappropriate data Within These large

655
00:26:57,080 --> 00:27:01,520
data corpora because that just doesn't

656
00:26:59,039 --> 00:27:03,559
scale instead what we want to do is look

657
00:27:01,520 --> 00:27:05,799
at the different views of data that

658
00:27:03,559 --> 00:27:07,840
exist within large scale embedding

659
00:27:05,799 --> 00:27:10,919
spaces and then use these different

660
00:27:07,840 --> 00:27:14,000
views as self-supervised learning where

661
00:27:10,919 --> 00:27:15,760
one view of an image is contrasted with

662
00:27:14,000 --> 00:27:17,320
another view and we think that

663
00:27:15,760 --> 00:27:19,240
differences between the ways that

664
00:27:17,320 --> 00:27:21,200
different models view data will

665
00:27:19,240 --> 00:27:23,880
highlight when data is inappropriate or

666
00:27:21,200 --> 00:27:27,480
incorrectly labeled marsia that sounds

667
00:27:23,880 --> 00:27:30,520
so interesting and important and I can't

668
00:27:27,480 --> 00:27:34,159
wait to hear about the new results thank

669
00:27:30,520 --> 00:27:34,159
you for having me


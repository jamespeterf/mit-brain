1
00:00:04,400 --> 00:00:11,200
All right. Uh I want to introduce our

2
00:00:07,440 --> 00:00:14,480
next speaker. We have uh Hammed Okravi.

3
00:00:11,200 --> 00:00:16,800
He's visiting us from MIT Lincoln

4
00:00:14,480 --> 00:00:19,279
Laboratory. He's a member of the senior

5
00:00:16,800 --> 00:00:22,240
staff in the cyber security and

6
00:00:19,279 --> 00:00:23,920
resilient systems group there. And he's

7
00:00:22,240 --> 00:00:25,840
going to share his thoughts on cyber

8
00:00:23,920 --> 00:00:27,840
security today. So let's hear it.

9
00:00:25,840 --> 00:00:29,840
>> Thank you.

10
00:00:27,840 --> 00:00:32,160
Thank you.

11
00:00:29,840 --> 00:00:33,840
Thank you everyone. Thank you Jim. Uh as

12
00:00:32,160 --> 00:00:36,079
Jim mentioned, I'm a senior staff member

13
00:00:33,840 --> 00:00:38,079
at MIT Link Laboratory and today I'll

14
00:00:36,079 --> 00:00:41,120
talk about uh securing the stack. I'm

15
00:00:38,079 --> 00:00:43,440
going to talk about cyber security. Um

16
00:00:41,120 --> 00:00:46,000
I'll start by sort of motivating the

17
00:00:43,440 --> 00:00:48,480
problem by looking at what the main pain

18
00:00:46,000 --> 00:00:50,480
points are today and then I'll talk

19
00:00:48,480 --> 00:00:53,280
about some of the technologies that

20
00:00:50,480 --> 00:00:54,879
exist in this area. They're nent

21
00:00:53,280 --> 00:00:56,719
technologies here. There are

22
00:00:54,879 --> 00:00:58,800
technologies that being that are being

23
00:00:56,719 --> 00:01:02,160
built that would help to address some of

24
00:00:58,800 --> 00:01:04,479
these issues. Uh and uh some of them are

25
00:01:02,160 --> 00:01:07,600
built in our group in our lab. Some of

26
00:01:04,479 --> 00:01:11,600
them are being built at other places. Uh

27
00:01:07,600 --> 00:01:14,640
but let's get to it. So

28
00:01:11,600 --> 00:01:18,000
in any area it's helpful to first look

29
00:01:14,640 --> 00:01:20,960
at the trends in that area to see which

30
00:01:18,000 --> 00:01:23,759
way things are shifting. Uh same is true

31
00:01:20,960 --> 00:01:25,280
in cyber security. So if we look at uh

32
00:01:23,759 --> 00:01:27,600
for example the amount of investment

33
00:01:25,280 --> 00:01:29,439
that's being made in cyber security this

34
00:01:27,600 --> 00:01:32,799
is both public and private investment

35
00:01:29,439 --> 00:01:35,600
total dollars uh it is encouraging right

36
00:01:32,799 --> 00:01:38,240
it's going up it's trending upwards uh

37
00:01:35,600 --> 00:01:41,200
it's close to $70 billion being spent

38
00:01:38,240 --> 00:01:43,920
every year in cyber security again both

39
00:01:41,200 --> 00:01:45,920
public and private sectors uh so that

40
00:01:43,920 --> 00:01:48,399
means more and more attention and

41
00:01:45,920 --> 00:01:51,040
investment is being made in in cyber

42
00:01:48,399 --> 00:01:52,960
security but then let's look at the

43
00:01:51,040 --> 00:01:54,560
outcomes are we getting the outcomes

44
00:01:52,960 --> 00:01:57,920
that we expect to get with this

45
00:01:54,560 --> 00:02:00,880
investment? The other two uh two charts

46
00:01:57,920 --> 00:02:04,000
on the top left and bottom right uh top

47
00:02:00,880 --> 00:02:05,439
right and bottom left uh are some sort

48
00:02:04,000 --> 00:02:07,520
of essentially some of the outcomes that

49
00:02:05,439 --> 00:02:09,039
we should see. The first one is showing

50
00:02:07,520 --> 00:02:12,319
the number of software vulnerabilities

51
00:02:09,039 --> 00:02:14,560
that we discover year-over-year in these

52
00:02:12,319 --> 00:02:17,360
uh in these in applications that we use

53
00:02:14,560 --> 00:02:19,920
in data centers and sort of in general

54
00:02:17,360 --> 00:02:22,080
purpose computing. Uh but the trend is

55
00:02:19,920 --> 00:02:24,400
not downward. It's not even plateauing.

56
00:02:22,080 --> 00:02:27,520
It's going up, right? And in some ways

57
00:02:24,400 --> 00:02:30,640
it's exponentially going up. Uh so what

58
00:02:27,520 --> 00:02:32,319
is happening? Uh but it's not just the

59
00:02:30,640 --> 00:02:34,560
number of vulnerabilities either. If we

60
00:02:32,319 --> 00:02:36,400
look at the amount of damages that's

61
00:02:34,560 --> 00:02:39,120
being caused by data breaches in terms

62
00:02:36,400 --> 00:02:41,840
of monetary damages, those are also

63
00:02:39,120 --> 00:02:44,560
trending up, right? So we are spending

64
00:02:41,840 --> 00:02:46,239
more and more in cyber. But on the

65
00:02:44,560 --> 00:02:48,319
outcome side, we don't really see the

66
00:02:46,239 --> 00:02:49,920
outcome that we need to see. We need to

67
00:02:48,319 --> 00:02:51,599
see these going down or maybe

68
00:02:49,920 --> 00:02:54,400
plateauing. But we are not seeing that.

69
00:02:51,599 --> 00:02:56,400
We are seeing things trending upwards.

70
00:02:54,400 --> 00:02:58,560
And according to various sort of threat

71
00:02:56,400 --> 00:03:00,160
studies, uh the attacks are being

72
00:02:58,560 --> 00:03:02,159
attributed more and more to nation

73
00:03:00,160 --> 00:03:04,560
states these days as opposed to sort of

74
00:03:02,159 --> 00:03:06,720
activists or script kitties. So things

75
00:03:04,560 --> 00:03:09,040
are getting more sophisticated. The

76
00:03:06,720 --> 00:03:12,400
stakes are being higher, right? So this

77
00:03:09,040 --> 00:03:15,280
is not for hobby or for fun or activism.

78
00:03:12,400 --> 00:03:18,000
This is serious business. This is now

79
00:03:15,280 --> 00:03:20,080
competition between nation states and we

80
00:03:18,000 --> 00:03:22,560
see things trending in the wrong

81
00:03:20,080 --> 00:03:24,640
direction. So why is it that while we

82
00:03:22,560 --> 00:03:26,319
are spending more and more in cyber we

83
00:03:24,640 --> 00:03:28,400
are not seeing the outcomes we are not

84
00:03:26,319 --> 00:03:30,640
seeing the benefits.

85
00:03:28,400 --> 00:03:32,959
So they always say ask the five wise

86
00:03:30,640 --> 00:03:35,200
right ask why and then why to the to

87
00:03:32,959 --> 00:03:37,599
that reason and keep asking until you

88
00:03:35,200 --> 00:03:40,239
get to the root causes. And if we do

89
00:03:37,599 --> 00:03:42,480
that in cyber, it inevitably goes back

90
00:03:40,239 --> 00:03:45,920
to history of how computer system have

91
00:03:42,480 --> 00:03:47,680
been built over time. Uh now this is

92
00:03:45,920 --> 00:03:50,480
certainly older than most people in this

93
00:03:47,680 --> 00:03:53,200
room. But if we go back to the 60s,

94
00:03:50,480 --> 00:03:55,120
there are influential projects like

95
00:03:53,200 --> 00:03:57,439
project multic.

96
00:03:55,120 --> 00:04:01,280
Project Mac is by the way what led to

97
00:03:57,439 --> 00:04:03,920
MIT sale. uh these were sort of early

98
00:04:01,280 --> 00:04:05,840
influential computer systems that

99
00:04:03,920 --> 00:04:07,519
influenced essentially everything that

100
00:04:05,840 --> 00:04:09,920
came afterwards.

101
00:04:07,519 --> 00:04:12,400
Uh even to this day it's hard to come up

102
00:04:09,920 --> 00:04:14,000
with an idea in computer science that

103
00:04:12,400 --> 00:04:16,479
somebody doesn't say well this was

104
00:04:14,000 --> 00:04:19,040
mentioned somewhere in multics. So it's

105
00:04:16,479 --> 00:04:21,199
amazing right it's few decades

106
00:04:19,040 --> 00:04:23,280
afterwards but we still h live with

107
00:04:21,199 --> 00:04:26,000
those ideas and say very similar

108
00:04:23,280 --> 00:04:27,919
concepts of course you know we have to

109
00:04:26,000 --> 00:04:30,400
acknowledge that computing has become

110
00:04:27,919 --> 00:04:33,040
much more versatile much faster much

111
00:04:30,400 --> 00:04:36,240
more speed much more sort of power

112
00:04:33,040 --> 00:04:38,160
however the core ideas have sort of

113
00:04:36,240 --> 00:04:40,960
remained through uh throughout these

114
00:04:38,160 --> 00:04:43,440
decades so those early projects

115
00:04:40,960 --> 00:04:48,240
influenced commercial successes like

116
00:04:43,440 --> 00:04:51,600
PDP11 IBM systems 60 uh back in 70s and

117
00:04:48,240 --> 00:04:53,840
early 80s and those really led to a lot

118
00:04:51,600 --> 00:04:55,759
of technologies that we use to this day.

119
00:04:53,840 --> 00:04:58,400
So this can be programming languages

120
00:04:55,759 --> 00:05:00,240
like C and C++

121
00:04:58,400 --> 00:05:03,520
operating system designs that we use

122
00:05:00,240 --> 00:05:06,240
today. Uh this really permeates through

123
00:05:03,520 --> 00:05:09,360
all types of them Windows, Linux, Mac OS

124
00:05:06,240 --> 00:05:14,400
even mobile operating systems and the

125
00:05:09,360 --> 00:05:17,440
way we build processors x86 and ARM.

126
00:05:14,400 --> 00:05:20,080
Now that era that era that started in

127
00:05:17,440 --> 00:05:23,120
60s and perhaps sort of uh close to

128
00:05:20,080 --> 00:05:25,759
2000s was the era of what we call add-on

129
00:05:23,120 --> 00:05:29,120
defenses. So people rarely thought about

130
00:05:25,759 --> 00:05:31,199
cyber security back then. One the need

131
00:05:29,120 --> 00:05:32,960
wasn't as well understood. Two the

132
00:05:31,199 --> 00:05:37,039
computers were not powerful enough to be

133
00:05:32,960 --> 00:05:38,720
able to uh defend themselves. Uh so if

134
00:05:37,039 --> 00:05:40,720
there was any defense it was add-on. It

135
00:05:38,720 --> 00:05:42,400
was add-on after the fact. people built

136
00:05:40,720 --> 00:05:44,479
the system and then sort of sprinkled

137
00:05:42,400 --> 00:05:46,160
defenses on top of this machines

138
00:05:44,479 --> 00:05:48,560
afterwards.

139
00:05:46,160 --> 00:05:51,120
Uh and there was this realization that

140
00:05:48,560 --> 00:05:53,280
this wasn't working right. Uh we were

141
00:05:51,120 --> 00:05:55,440
always playing catch-up.

142
00:05:53,280 --> 00:05:58,160
In 2000s and 2010s there were a number

143
00:05:55,440 --> 00:06:00,560
of initiatives most notably by DARPA

144
00:05:58,160 --> 00:06:03,199
DARPA crash and MRC programs but also at

145
00:06:00,560 --> 00:06:05,759
other places that tried to build in

146
00:06:03,199 --> 00:06:07,280
defenses into systems. So they tried to

147
00:06:05,759 --> 00:06:09,120
sort of change the paradigm and

148
00:06:07,280 --> 00:06:11,919
incorporate these defenses more into

149
00:06:09,120 --> 00:06:14,800
systems as they were being designed.

150
00:06:11,919 --> 00:06:17,039
And this really led to this modern era

151
00:06:14,800 --> 00:06:20,560
which we call sort of era of inherently

152
00:06:17,039 --> 00:06:22,800
secure systems. Systems that are really

153
00:06:20,560 --> 00:06:24,479
built to defend themselves to be

154
00:06:22,800 --> 00:06:26,240
resilient against wide classes of

155
00:06:24,479 --> 00:06:28,880
attacks as opposed to sort of reacting

156
00:06:26,240 --> 00:06:30,720
to individuals or instance of attacks.

157
00:06:28,880 --> 00:06:33,440
We are preventing large classes of

158
00:06:30,720 --> 00:06:36,080
vulnerabilities by design. This is by

159
00:06:33,440 --> 00:06:38,319
the way mentioned in various cyber

160
00:06:36,080 --> 00:06:41,120
security strategic plans. I've uh

161
00:06:38,319 --> 00:06:43,759
mentioned one of them here 2025 uh

162
00:06:41,120 --> 00:06:45,600
federal R&D strategic plan that

163
00:06:43,759 --> 00:06:47,600
specifically mentions cyber resilience

164
00:06:45,600 --> 00:06:49,280
by design. But this is not the only

165
00:06:47,600 --> 00:06:51,759
document talking about that. If you look

166
00:06:49,280 --> 00:06:55,360
at various strategic documents they they

167
00:06:51,759 --> 00:06:57,919
need the so they mention the need for uh

168
00:06:55,360 --> 00:07:00,160
inherently secure systems or resilience

169
00:06:57,919 --> 00:07:03,759
by design. Again it goes by various

170
00:07:00,160 --> 00:07:06,000
names but the the core idea is the same.

171
00:07:03,759 --> 00:07:07,599
So I mentioned that a lot of sort of the

172
00:07:06,000 --> 00:07:10,720
problems that we have in cyber security

173
00:07:07,599 --> 00:07:13,520
today are inherited from that past era

174
00:07:10,720 --> 00:07:16,720
right from 80s and 90s and even before

175
00:07:13,520 --> 00:07:20,080
that but what are those exactly like why

176
00:07:16,720 --> 00:07:22,080
is the problem permeating to this day?

177
00:07:20,080 --> 00:07:24,560
Well, it's it would be helpful to look

178
00:07:22,080 --> 00:07:26,160
at a typical cyber attack, right? An

179
00:07:24,560 --> 00:07:29,360
anatomy of a cyber attack. And again,

180
00:07:26,160 --> 00:07:31,919
this is a simplified example, but uh the

181
00:07:29,360 --> 00:07:33,440
core concept is the same if we look at

182
00:07:31,919 --> 00:07:37,199
sort of the vast majority of attacks

183
00:07:33,440 --> 00:07:39,599
today. You know, in a system, we have a

184
00:07:37,199 --> 00:07:41,759
stack like this, right? And this can be

185
00:07:39,599 --> 00:07:43,680
in a data center, it can be in your

186
00:07:41,759 --> 00:07:45,680
personal machine, can be really on your

187
00:07:43,680 --> 00:07:47,919
cell phone as well. It's not that

188
00:07:45,680 --> 00:07:52,080
different. At the bottom we have the

189
00:07:47,919 --> 00:07:54,800
processor x86 or ARM are dominant to to

190
00:07:52,080 --> 00:07:58,080
this day. The operating system Linux,

191
00:07:54,800 --> 00:08:00,639
Windows, Mac, iOS, others libraries that

192
00:07:58,080 --> 00:08:02,160
we rely on. Uh and then on top there are

193
00:08:00,639 --> 00:08:04,160
applications and these are being more

194
00:08:02,160 --> 00:08:06,720
and more AI applications. Of course AI

195
00:08:04,160 --> 00:08:09,360
is is the hype these days. A lot of

196
00:08:06,720 --> 00:08:12,560
applications are AI based. And then user

197
00:08:09,360 --> 00:08:14,800
on top, right? So you're what does a

198
00:08:12,560 --> 00:08:17,199
system do? receives data, processes

199
00:08:14,800 --> 00:08:20,080
data, returns back something. Right?

200
00:08:17,199 --> 00:08:23,120
Now, during normal operations, what a

201
00:08:20,080 --> 00:08:25,440
user does on a system, again, I

202
00:08:23,120 --> 00:08:27,039
intentionally don't sort of narrow this

203
00:08:25,440 --> 00:08:28,639
down to a specific type of application

204
00:08:27,039 --> 00:08:31,199
or a specific type of system because

205
00:08:28,639 --> 00:08:32,880
this general concept applies essentially

206
00:08:31,199 --> 00:08:35,519
everywhere.

207
00:08:32,880 --> 00:08:37,680
But what the user does sends a data for

208
00:08:35,519 --> 00:08:40,000
processing. This data is being copied to

209
00:08:37,680 --> 00:08:42,719
the system usually to a space what we

210
00:08:40,000 --> 00:08:44,560
call buffer, right? And then under the

211
00:08:42,719 --> 00:08:47,120
hood, what's happening is that there is

212
00:08:44,560 --> 00:08:50,320
some piece of hardware, the memory of

213
00:08:47,120 --> 00:08:52,160
that system where this space to hold the

214
00:08:50,320 --> 00:08:54,640
data is sitting right next to important

215
00:08:52,160 --> 00:08:56,160
things like for example the AI model or

216
00:08:54,640 --> 00:08:58,160
it can be, you know, if you're talking

217
00:08:56,160 --> 00:08:59,839
about a system that's controlling

218
00:08:58,160 --> 00:09:01,920
something, it could be the control logic

219
00:08:59,839 --> 00:09:04,560
of that system.

220
00:09:01,920 --> 00:09:07,279
During normal operation, this data is

221
00:09:04,560 --> 00:09:09,440
copied to that space and is processed

222
00:09:07,279 --> 00:09:11,200
and the result is returned back to the

223
00:09:09,440 --> 00:09:13,279
user. Great.

224
00:09:11,200 --> 00:09:15,600
The problem is that under attack what

225
00:09:13,279 --> 00:09:18,000
could happen is that this data could be

226
00:09:15,600 --> 00:09:20,959
malformed. It could be larger than the

227
00:09:18,000 --> 00:09:23,760
space that it needs to be or it could

228
00:09:20,959 --> 00:09:26,320
have some mal uh mal formality in it.

229
00:09:23,760 --> 00:09:28,640
And what happens is that when this data

230
00:09:26,320 --> 00:09:31,680
is copied to that space, it could

231
00:09:28,640 --> 00:09:34,640
overflow. It could overflow to adjacent

232
00:09:31,680 --> 00:09:36,959
data and that data or code could be some

233
00:09:34,640 --> 00:09:39,519
critical thing. It could be the AI model

234
00:09:36,959 --> 00:09:41,839
that's that system is running. It could

235
00:09:39,519 --> 00:09:44,080
be the control logic of that system and

236
00:09:41,839 --> 00:09:46,240
through that an attacker can modify the

237
00:09:44,080 --> 00:09:48,640
behavior of the system and hijack the

238
00:09:46,240 --> 00:09:51,279
control of the system.

239
00:09:48,640 --> 00:09:54,240
Now this is a simplified view of a large

240
00:09:51,279 --> 00:09:57,360
class of attacks today. It accounts for

241
00:09:54,240 --> 00:10:00,160
by various studies 70% of attacks uh or

242
00:09:57,360 --> 00:10:02,160
vulnerabilities to this day. But and

243
00:10:00,160 --> 00:10:03,920
there are you know complexities that

244
00:10:02,160 --> 00:10:06,959
that are added to this sort of

245
00:10:03,920 --> 00:10:09,760
simplified uh view. Nevertheless, the

246
00:10:06,959 --> 00:10:12,720
point stands that this type of attack is

247
00:10:09,760 --> 00:10:14,560
very common to this day. It's being used

248
00:10:12,720 --> 00:10:17,120
uh to hijack control of important

249
00:10:14,560 --> 00:10:19,600
systems to modify them in malicious ways

250
00:10:17,120 --> 00:10:21,920
including AI systems and we need to do

251
00:10:19,600 --> 00:10:24,160
something about it. So what are the root

252
00:10:21,920 --> 00:10:26,399
causes that I mentioned that sort of we

253
00:10:24,160 --> 00:10:28,880
have inherited from early computer

254
00:10:26,399 --> 00:10:32,320
designs? Well, the root causes really go

255
00:10:28,880 --> 00:10:35,120
to essentially all layers of this stack.

256
00:10:32,320 --> 00:10:37,600
At the bottom layer, the processor does

257
00:10:35,120 --> 00:10:39,680
not have notions of different types of

258
00:10:37,600 --> 00:10:42,959
data, right? It's processing everything

259
00:10:39,680 --> 00:10:46,160
as strings of zeros and ones, right? So,

260
00:10:42,959 --> 00:10:47,920
it it cannot distinguish the fact that

261
00:10:46,160 --> 00:10:49,920
you know what I was trying to copy here

262
00:10:47,920 --> 00:10:51,760
was the data whereas you know what's

263
00:10:49,920 --> 00:10:53,360
underneath it is the model. It shouldn't

264
00:10:51,760 --> 00:10:55,519
overwrite the model with that data

265
00:10:53,360 --> 00:10:56,959
that's uh that the user is sending to

266
00:10:55,519 --> 00:10:58,959
the system. It doesn't have any notion

267
00:10:56,959 --> 00:11:01,279
of that, right?

268
00:10:58,959 --> 00:11:04,079
It treats everything as raw bits,

269
00:11:01,279 --> 00:11:07,040
essentially raw ones and zeros. The

270
00:11:04,079 --> 00:11:08,959
operating system is built as a monolith,

271
00:11:07,040 --> 00:11:10,640
meaning that it's a gigantic piece of

272
00:11:08,959 --> 00:11:13,360
code that's running at the highest

273
00:11:10,640 --> 00:11:15,200
privilege level in the system and every

274
00:11:13,360 --> 00:11:17,600
part of the OS has access to the other

275
00:11:15,200 --> 00:11:18,640
part of the OS. This is true to this

276
00:11:17,600 --> 00:11:21,040
day.

277
00:11:18,640 --> 00:11:22,880
uh and if a small part of the OS gets

278
00:11:21,040 --> 00:11:24,720
compromised the entire system gets

279
00:11:22,880 --> 00:11:26,880
compromised because there's no

280
00:11:24,720 --> 00:11:28,720
additional safeguards inside the OS to

281
00:11:26,880 --> 00:11:30,800
sort of contain the damage to limit the

282
00:11:28,720 --> 00:11:33,360
damage

283
00:11:30,800 --> 00:11:35,839
and also importantly applications and

284
00:11:33,360 --> 00:11:37,200
libraries are written in unsafe

285
00:11:35,839 --> 00:11:40,000
programming languages programming

286
00:11:37,200 --> 00:11:42,240
languages that don't have notions of

287
00:11:40,000 --> 00:11:44,480
size of the data right type of data

288
00:11:42,240 --> 00:11:48,079
right sort of temporal validity of the

289
00:11:44,480 --> 00:11:50,320
data uh and this is notably C and C++ ++

290
00:11:48,079 --> 00:11:52,959
again the idea here was that the reason

291
00:11:50,320 --> 00:11:55,360
is not that people who designed C and

292
00:11:52,959 --> 00:11:56,959
C++ didn't know about these issues they

293
00:11:55,360 --> 00:11:59,600
certainly know about knew about these

294
00:11:56,959 --> 00:12:01,360
issues the problem was at the time the

295
00:11:59,600 --> 00:12:04,240
machines were not resourceful enough to

296
00:12:01,360 --> 00:12:06,000
be able to perform complicated checks uh

297
00:12:04,240 --> 00:12:08,000
and they intentionally wanted to build

298
00:12:06,000 --> 00:12:09,519
these systems these languages to be

299
00:12:08,000 --> 00:12:10,959
close as close to the hardware as

300
00:12:09,519 --> 00:12:12,320
possible so they didn't want to add

301
00:12:10,959 --> 00:12:15,279
additional checks and additional

302
00:12:12,320 --> 00:12:17,279
safeguards into the language

303
00:12:15,279 --> 00:12:19,839
but we have lived with the consequences

304
00:12:17,279 --> 00:12:22,720
of those decisions ever since and this

305
00:12:19,839 --> 00:12:25,200
permeates to systems to this day. So the

306
00:12:22,720 --> 00:12:29,440
core issues are are those three core

307
00:12:25,200 --> 00:12:31,920
issues. The processors are sort of um

308
00:12:29,440 --> 00:12:33,839
are not in secure by design. They cannot

309
00:12:31,920 --> 00:12:35,440
perform security checks. Operating

310
00:12:33,839 --> 00:12:37,440
systems do not have enough safeguards

311
00:12:35,440 --> 00:12:40,160
inside them and we use unsafe

312
00:12:37,440 --> 00:12:42,959
programming languages. So what are the

313
00:12:40,160 --> 00:12:44,560
pillars of an inherently secure system?

314
00:12:42,959 --> 00:12:46,639
Well, essentially addressing those three

315
00:12:44,560 --> 00:12:50,079
root causes,

316
00:12:46,639 --> 00:12:52,560
we have in in fact created uh uh a

317
00:12:50,079 --> 00:12:55,200
vision for an inherently secure system.

318
00:12:52,560 --> 00:12:57,760
This was part of an initiative at MIT

319
00:12:55,200 --> 00:13:00,800
link lab called the moonshot initiative

320
00:12:57,760 --> 00:13:03,360
cyber moonshot initiative that sort of

321
00:13:00,800 --> 00:13:07,760
tried to address these core uh root

322
00:13:03,360 --> 00:13:09,440
causes and using these three new pillars

323
00:13:07,760 --> 00:13:11,360
and as I mentioned we have built some

324
00:13:09,440 --> 00:13:13,200
technologies to address some of these

325
00:13:11,360 --> 00:13:14,959
but there are many other places that

326
00:13:13,200 --> 00:13:16,720
work on these problems and they're

327
00:13:14,959 --> 00:13:19,040
building technologies to address them as

328
00:13:16,720 --> 00:13:21,920
well. So what are these pillars? The

329
00:13:19,040 --> 00:13:25,040
first one is hardware enforced security.

330
00:13:21,920 --> 00:13:27,680
Uh so more and more in modern uh

331
00:13:25,040 --> 00:13:30,000
hardware systems that are being uh sort

332
00:13:27,680 --> 00:13:32,320
of enriched with proper checks, proper

333
00:13:30,000 --> 00:13:34,639
types to enforce on data so that the

334
00:13:32,320 --> 00:13:37,360
type of attack that I showed uh would be

335
00:13:34,639 --> 00:13:40,560
prevented in the in the hardware itself.

336
00:13:37,360 --> 00:13:42,320
This has multiple advantages but one is

337
00:13:40,560 --> 00:13:44,160
that uh it's more efficient to enforce

338
00:13:42,320 --> 00:13:45,920
it in hardware than have to enforce it

339
00:13:44,160 --> 00:13:48,000
in the software. It doesn't make the

340
00:13:45,920 --> 00:13:50,560
software more complicated by additional

341
00:13:48,000 --> 00:13:55,760
sort of software to check other software

342
00:13:50,560 --> 00:13:57,600
right uh and uh and it sort of sol

343
00:13:55,760 --> 00:14:00,079
solves the problem at the layer that is

344
00:13:57,600 --> 00:14:03,360
appropriate uh for solving this includes

345
00:14:00,079 --> 00:14:06,720
sort of x86 architectures uh again Intel

346
00:14:03,360 --> 00:14:08,800
AMD processors ARM has uh has its own

347
00:14:06,720 --> 00:14:12,079
sort of type that's being added to newer

348
00:14:08,800 --> 00:14:14,560
processors uh but today I'm not going to

349
00:14:12,079 --> 00:14:17,519
talk uh get deeper into that I'm going

350
00:14:14,560 --> 00:14:20,160
to talk about the other two areas. Uh

351
00:14:17,519 --> 00:14:22,160
the sort of next pillar uh of a

352
00:14:20,160 --> 00:14:25,040
inherently secure system is uh what's

353
00:14:22,160 --> 00:14:28,079
called compartmentalization or another

354
00:14:25,040 --> 00:14:29,920
name for it is zero trust. We want to

355
00:14:28,079 --> 00:14:32,320
minimize the amount of privilege that

356
00:14:29,920 --> 00:14:35,360
each part of the system has so that when

357
00:14:32,320 --> 00:14:37,040
it it gets compromised it cannot impact

358
00:14:35,360 --> 00:14:38,800
the the rest of the system because

359
00:14:37,040 --> 00:14:40,240
inherently we're not going to be able to

360
00:14:38,800 --> 00:14:42,000
remove all vulnerabilities. These

361
00:14:40,240 --> 00:14:44,320
vulnerabilities are going to exist. So

362
00:14:42,000 --> 00:14:46,959
we want to minimize the damage when

363
00:14:44,320 --> 00:14:49,440
they're exploited in the system.

364
00:14:46,959 --> 00:14:51,120
Uh and then the last pillar is safe

365
00:14:49,440 --> 00:14:53,040
programming languages. Programming

366
00:14:51,120 --> 00:14:55,600
languages that have notions of safety

367
00:14:53,040 --> 00:14:58,160
built into them at compile time and at

368
00:14:55,600 --> 00:14:59,920
al at also runtime to be able to prevent

369
00:14:58,160 --> 00:15:01,360
these attacks. I'm going to talk about

370
00:14:59,920 --> 00:15:03,519
the first area first which is the

371
00:15:01,360 --> 00:15:07,440
compartmentalization and then briefly

372
00:15:03,519 --> 00:15:10,079
mention the safe programming languages.

373
00:15:07,440 --> 00:15:12,480
So what should we compartmentalize?

374
00:15:10,079 --> 00:15:15,440
Of course, the software system is very

375
00:15:12,480 --> 00:15:18,720
complex. There are various pieces to it.

376
00:15:15,440 --> 00:15:20,800
If we look at the targets of attacks, it

377
00:15:18,720 --> 00:15:23,839
turns out that a large chunk of them are

378
00:15:20,800 --> 00:15:26,240
the operating systems. Uh 28% in fact,

379
00:15:23,839 --> 00:15:28,720
it's the biggest chunk. Uh but the

380
00:15:26,240 --> 00:15:30,399
problem is even worse. We only have a

381
00:15:28,720 --> 00:15:31,839
handful of operating system whereas you

382
00:15:30,399 --> 00:15:34,079
know if you look at applications, there

383
00:15:31,839 --> 00:15:36,320
are millions of applications out there.

384
00:15:34,079 --> 00:15:37,760
So operating systems are a juicy target

385
00:15:36,320 --> 00:15:40,240
for attackers because there are a

386
00:15:37,760 --> 00:15:42,000
handful of them and they're sort of

387
00:15:40,240 --> 00:15:44,880
they're built as a monolith, right?

388
00:15:42,000 --> 00:15:47,279
They're easier to exploit than many

389
00:15:44,880 --> 00:15:50,720
different applications. And this shows

390
00:15:47,279 --> 00:15:53,279
up in the data. In fact, 28% of the

391
00:15:50,720 --> 00:15:55,279
attacks are uh target of attacks are

392
00:15:53,279 --> 00:15:58,079
operating systems.

393
00:15:55,279 --> 00:16:00,160
Uh and can we just fix this by better

394
00:15:58,079 --> 00:16:02,160
patching? Well, some part of the

395
00:16:00,160 --> 00:16:04,320
problem, but not really the majority of

396
00:16:02,160 --> 00:16:06,320
it. The majority of exploitation is

397
00:16:04,320 --> 00:16:08,240
exploitation of unknown vulnerabilities,

398
00:16:06,320 --> 00:16:10,160
vulnerabilities that are not that

399
00:16:08,240 --> 00:16:13,199
haven't been known to that up to that

400
00:16:10,160 --> 00:16:16,000
time. So patching can fix you know that

401
00:16:13,199 --> 00:16:18,639
pink part known vulnerabilities but it

402
00:16:16,000 --> 00:16:20,240
cannot really address the unknown part.

403
00:16:18,639 --> 00:16:23,040
So we need to do better. We need to put

404
00:16:20,240 --> 00:16:25,279
enough guard rails inside the OS so that

405
00:16:23,040 --> 00:16:27,360
when it is exploited one part of it gets

406
00:16:25,279 --> 00:16:29,680
exploited the entire mission system

407
00:16:27,360 --> 00:16:31,040
doesn't go down.

408
00:16:29,680 --> 00:16:33,040
In fact, that's uh one of the

409
00:16:31,040 --> 00:16:35,279
technologies that we have created in our

410
00:16:33,040 --> 00:16:38,480
lab. Uh we call it hardware assisted

411
00:16:35,279 --> 00:16:41,600
kernel compartmentalization or hacks.

412
00:16:38,480 --> 00:16:43,839
Um and sort of we take the Linux

413
00:16:41,600 --> 00:16:45,759
operating system. Why Linux? Again,

414
00:16:43,839 --> 00:16:48,480
that's the predominant operating system

415
00:16:45,759 --> 00:16:50,160
in many data centers. Uh Linux and its

416
00:16:48,480 --> 00:16:52,720
variants, right? So there are many of

417
00:16:50,160 --> 00:16:55,600
course variants to Linux. Uh but it also

418
00:16:52,720 --> 00:16:58,560
shares its internal design with similar

419
00:16:55,600 --> 00:17:01,600
operating systems as well. But as I

420
00:16:58,560 --> 00:17:04,240
mentioned, if you look at the in the

421
00:17:01,600 --> 00:17:06,319
internals of the Linux OS, everything

422
00:17:04,240 --> 00:17:08,400
has access to everything, right? So you

423
00:17:06,319 --> 00:17:10,720
have your Bluetooth module, your power

424
00:17:08,400 --> 00:17:12,480
management, your file system. Every part

425
00:17:10,720 --> 00:17:16,079
of the OS can access the other part of

426
00:17:12,480 --> 00:17:18,000
the OS, right? It's the highest it's the

427
00:17:16,079 --> 00:17:19,760
millions of lines of code running at the

428
00:17:18,000 --> 00:17:21,439
highest privilege level in the system,

429
00:17:19,760 --> 00:17:23,280
but there are no additional guard rails

430
00:17:21,439 --> 00:17:27,199
inside of it.

431
00:17:23,280 --> 00:17:29,440
So what we do um there are philosophies

432
00:17:27,199 --> 00:17:31,200
that people advocate for building new

433
00:17:29,440 --> 00:17:34,080
operating systems from scratch and those

434
00:17:31,200 --> 00:17:36,320
are sort of worthy goals. However, many

435
00:17:34,080 --> 00:17:38,799
existing systems use Linux right and

436
00:17:36,320 --> 00:17:41,840
it's very difficult to build everything

437
00:17:38,799 --> 00:17:44,400
from scratch. So what is said what we

438
00:17:41,840 --> 00:17:47,520
have done is to minimize the amount of

439
00:17:44,400 --> 00:17:49,520
privilege that exists inside the

440
00:17:47,520 --> 00:17:52,400
operating system kernel in this case

441
00:17:49,520 --> 00:17:54,000
Linux kernel. So we limit those to only

442
00:17:52,400 --> 00:17:56,559
the interactions that are absolutely

443
00:17:54,000 --> 00:17:58,400
necessary for the system to function. So

444
00:17:56,559 --> 00:18:00,559
meaning that we put additional guard

445
00:17:58,400 --> 00:18:02,160
rails in the system to say okay these

446
00:18:00,559 --> 00:18:04,640
modules may need to talk to each other

447
00:18:02,160 --> 00:18:07,280
and need certain types of access to

448
00:18:04,640 --> 00:18:10,320
other modules but those additional

449
00:18:07,280 --> 00:18:13,200
interactions are never necessary and

450
00:18:10,320 --> 00:18:15,120
should be explicitly disallowed. And by

451
00:18:13,200 --> 00:18:17,280
doing so we significantly reduce the

452
00:18:15,120 --> 00:18:20,799
amount of privilege that exist in the

453
00:18:17,280 --> 00:18:23,039
operating system kernel. uh and by the

454
00:18:20,799 --> 00:18:25,120
same token if there is a vulnerability

455
00:18:23,039 --> 00:18:27,600
in one of these modules and it is

456
00:18:25,120 --> 00:18:29,440
exploited then the attacker is only

457
00:18:27,600 --> 00:18:32,160
limited to that particular module and

458
00:18:29,440 --> 00:18:34,640
cannot own the entire mission system.

459
00:18:32,160 --> 00:18:37,440
This is again applying the principle of

460
00:18:34,640 --> 00:18:39,440
zero trust to the operating system. So

461
00:18:37,440 --> 00:18:41,360
we are minimizing the amount of

462
00:18:39,440 --> 00:18:43,919
privilege that exists in the operating

463
00:18:41,360 --> 00:18:46,080
system to what's absolutely necessary

464
00:18:43,919 --> 00:18:48,559
and limiting the damage uh from

465
00:18:46,080 --> 00:18:50,559
vulnerabilities. So again this is not

466
00:18:48,559 --> 00:18:52,240
trying to remove any vulnerability. I'll

467
00:18:50,559 --> 00:18:54,880
talk about safe programming languages in

468
00:18:52,240 --> 00:18:57,200
a second but this is to say

469
00:18:54,880 --> 00:18:59,440
vulnerabilities are going to exist. We

470
00:18:57,200 --> 00:19:01,360
have to somehow limit their damage and

471
00:18:59,440 --> 00:19:03,440
this is trying to limit uh damages from

472
00:19:01,360 --> 00:19:06,160
vulnerabilities.

473
00:19:03,440 --> 00:19:07,919
So this prototype is actually uh fairly

474
00:19:06,160 --> 00:19:10,960
mature at this point. We have built it

475
00:19:07,919 --> 00:19:12,400
over uh multiple years. Uh in fact I

476
00:19:10,960 --> 00:19:14,160
believe the slick sheet for the

477
00:19:12,400 --> 00:19:17,520
technology was included in your

478
00:19:14,160 --> 00:19:20,160
packages. uh but it can run on data

479
00:19:17,520 --> 00:19:21,919
center platforms. It can run on so all

480
00:19:20,160 --> 00:19:24,400
those platforms that are pictured here

481
00:19:21,919 --> 00:19:27,280
typical laptop. We have tested it and

482
00:19:24,400 --> 00:19:29,679
actually demonstrated on robots. Those

483
00:19:27,280 --> 00:19:32,080
Roomba like machines are uh what are

484
00:19:29,679 --> 00:19:34,320
called turtle bots. The robots that uh

485
00:19:32,080 --> 00:19:35,840
developer in robotics use for various

486
00:19:34,320 --> 00:19:38,480
applications. But we have actually

487
00:19:35,840 --> 00:19:40,320
showed that we can secure uh its

488
00:19:38,480 --> 00:19:42,880
operating system using this idea of

489
00:19:40,320 --> 00:19:46,240
compartmentalized Linux.

490
00:19:42,880 --> 00:19:48,799
And on the left side you see uh a secure

491
00:19:46,240 --> 00:19:51,440
processor developed by DARPA. So again

492
00:19:48,799 --> 00:19:54,320
going back to hardware for security.

493
00:19:51,440 --> 00:19:57,200
This type of processor has notions of

494
00:19:54,320 --> 00:20:00,160
capabilities right what certain parts of

495
00:19:57,200 --> 00:20:02,400
the software can do what they cannot do

496
00:20:00,160 --> 00:20:04,559
and through that they actually enforce a

497
00:20:02,400 --> 00:20:07,600
lot of the security checks for us. So it

498
00:20:04,559 --> 00:20:10,720
can run on commodity processors even

499
00:20:07,600 --> 00:20:14,080
sort of IoT like boards like you know

500
00:20:10,720 --> 00:20:17,520
those ARM boards uh robotic platforms

501
00:20:14,080 --> 00:20:20,400
data centers laptops as well as sort of

502
00:20:17,520 --> 00:20:22,080
security enhanced processors. Now the

503
00:20:20,400 --> 00:20:24,640
second area that I'm going to talk about

504
00:20:22,080 --> 00:20:26,799
is safe programming languages. As I

505
00:20:24,640 --> 00:20:29,520
mentioned, one of the main pain points

506
00:20:26,799 --> 00:20:32,000
in cyber today is that legacy

507
00:20:29,520 --> 00:20:34,720
programming languages like C and C++

508
00:20:32,000 --> 00:20:37,200
don't have notions of safety to check on

509
00:20:34,720 --> 00:20:39,440
to perform on the data. And because of

510
00:20:37,200 --> 00:20:41,520
that, this sort of safety check is

511
00:20:39,440 --> 00:20:42,880
delegated to the developer and

512
00:20:41,520 --> 00:20:44,799
developers are human. They make

513
00:20:42,880 --> 00:20:46,720
mistakes, right? They forget to perform

514
00:20:44,799 --> 00:20:48,480
certain checks and this leads to

515
00:20:46,720 --> 00:20:50,400
vulnerabilities.

516
00:20:48,480 --> 00:20:53,760
For decades, we didn't have good

517
00:20:50,400 --> 00:20:56,080
programming language options. uh sort of

518
00:20:53,760 --> 00:20:59,120
safe languages that existed let's say

519
00:20:56,080 --> 00:21:01,760
two decades ago where languages like

520
00:20:59,120 --> 00:21:03,600
Java which requires a language runtime

521
00:21:01,760 --> 00:21:05,679
it requires a heavy virtual machine to

522
00:21:03,600 --> 00:21:08,080
be able to run the code is not really

523
00:21:05,679 --> 00:21:10,799
appropriate for developing a system

524
00:21:08,080 --> 00:21:14,240
level software right a piece of uh

525
00:21:10,799 --> 00:21:17,120
system level software uh luckily in the

526
00:21:14,240 --> 00:21:19,200
past sort of decade or so uh programming

527
00:21:17,120 --> 00:21:22,080
languages have come up that actually

528
00:21:19,200 --> 00:21:25,200
have notions of safety built into

529
00:21:22,080 --> 00:21:28,159
Most prominently Rust and Go are two of

530
00:21:25,200 --> 00:21:30,880
those languages. Rust uh performs

531
00:21:28,159 --> 00:21:33,679
compile time checks many compile time

532
00:21:30,880 --> 00:21:35,360
checks uh to ensure sort of the type of

533
00:21:33,679 --> 00:21:38,960
data is correct, the size of data is

534
00:21:35,360 --> 00:21:40,320
correct uh and it performs bounce check

535
00:21:38,960 --> 00:21:42,799
what's called bounce check on the data.

536
00:21:40,320 --> 00:21:44,559
Bounds is just a fancy term for saying

537
00:21:42,799 --> 00:21:46,400
you know there are limits to how big

538
00:21:44,559 --> 00:21:50,080
this data could be and it could not lead

539
00:21:46,400 --> 00:21:53,200
into other areas in memory.

540
00:21:50,080 --> 00:21:55,200
It also has ownerships of uh concepts of

541
00:21:53,200 --> 00:21:57,520
ownership and lifetime to enforce

542
00:21:55,200 --> 00:22:00,400
temporal check. Uh more on that in a

543
00:21:57,520 --> 00:22:02,000
second. It performs some runtime checks

544
00:22:00,400 --> 00:22:05,039
as well. So as the code is running it

545
00:22:02,000 --> 00:22:06,960
performs runtime checks but luckily the

546
00:22:05,039 --> 00:22:09,120
speed that it performs is uh fairly

547
00:22:06,960 --> 00:22:13,039
optimized. So speed of Rust is

548
00:22:09,120 --> 00:22:16,000
comparable to C++ today. Uh which again

549
00:22:13,039 --> 00:22:18,320
something that we couldn't say 15 years

550
00:22:16,000 --> 00:22:20,640
ago, 20 years ago.

551
00:22:18,320 --> 00:22:22,640
Another language is Go. Again, Go is

552
00:22:20,640 --> 00:22:24,640
used heavily for data processing. It

553
00:22:22,640 --> 00:22:27,760
also has compile time checks and runtime

554
00:22:24,640 --> 00:22:30,159
checks. Uh I would say the only downside

555
00:22:27,760 --> 00:22:32,799
with Go is that its runtime checks are

556
00:22:30,159 --> 00:22:35,679
heavier um particularly for garbage

557
00:22:32,799 --> 00:22:37,840
collection. So it it has some slowdown

558
00:22:35,679 --> 00:22:42,400
when when compared to system languages

559
00:22:37,840 --> 00:22:45,200
like Rust. Um and as I said, Rust uh is

560
00:22:42,400 --> 00:22:48,000
applicable uh to because it has a very

561
00:22:45,200 --> 00:22:49,840
small runtime uh for system building for

562
00:22:48,000 --> 00:22:52,240
things that need to be high performance

563
00:22:49,840 --> 00:22:55,679
again applications, operating systems,

564
00:22:52,240 --> 00:22:58,000
things of that sort.

565
00:22:55,679 --> 00:23:00,320
I'm going to get a little deeper into

566
00:22:58,000 --> 00:23:04,240
how technically this is performed. I

567
00:23:00,320 --> 00:23:08,320
promise not too deep. Uh so again rust

568
00:23:04,240 --> 00:23:11,840
has notions of uh static and dynamic

569
00:23:08,320 --> 00:23:14,080
checks. Uh and it really provides two

570
00:23:11,840 --> 00:23:16,799
safety properties. One is called spatial

571
00:23:14,080 --> 00:23:18,960
safety meaning that if I have a piece of

572
00:23:16,799 --> 00:23:20,559
data it cannot bleed into something

573
00:23:18,960 --> 00:23:24,000
that's more critical in this case the

574
00:23:20,559 --> 00:23:27,039
model right. Uh so it performs those

575
00:23:24,000 --> 00:23:29,840
bounds check on the data so that it it

576
00:23:27,039 --> 00:23:33,039
is it contain it is contained within its

577
00:23:29,840 --> 00:23:35,440
sort of area of memory. Uh it does so

578
00:23:33,039 --> 00:23:37,600
for most of the checks are compile time

579
00:23:35,440 --> 00:23:40,240
but if the data is dynamic data it would

580
00:23:37,600 --> 00:23:42,480
uh perform runtime checks. It also

581
00:23:40,240 --> 00:23:44,720
performs uh the second type of check is

582
00:23:42,480 --> 00:23:46,960
called temporal safety. So meaning that

583
00:23:44,720 --> 00:23:49,520
if I store a piece of data in a part of

584
00:23:46,960 --> 00:23:51,200
memory and later on I free that data now

585
00:23:49,520 --> 00:23:53,440
and reuse that piece of memory for

586
00:23:51,200 --> 00:23:56,400
something more critical again model

587
00:23:53,440 --> 00:23:58,640
parameters or control logic. Nobody in

588
00:23:56,400 --> 00:24:01,200
the program has access remaining access

589
00:23:58,640 --> 00:24:03,600
to that data or residual access to that

590
00:24:01,200 --> 00:24:06,559
data and it does so by this notion of

591
00:24:03,600 --> 00:24:09,520
ownership meaning that you know in this

592
00:24:06,559 --> 00:24:11,600
case one owner exists to that object and

593
00:24:09,520 --> 00:24:13,840
if that object goes away the ownership

594
00:24:11,600 --> 00:24:16,080
is immediately revoked. So nobody has

595
00:24:13,840 --> 00:24:18,880
res will have residual access to a piece

596
00:24:16,080 --> 00:24:21,039
of memory that could contain uh crucial

597
00:24:18,880 --> 00:24:24,400
data.

598
00:24:21,039 --> 00:24:26,640
So you might say okay this is lovely but

599
00:24:24,400 --> 00:24:29,600
we have millions and billions of lines

600
00:24:26,640 --> 00:24:31,600
of code already developed in C C++ what

601
00:24:29,600 --> 00:24:34,159
should we do with that code right even

602
00:24:31,600 --> 00:24:36,880
if we adopt Rust for everything that we

603
00:24:34,159 --> 00:24:38,720
develop starting today we still have a

604
00:24:36,880 --> 00:24:40,559
lot of libraries a lot of code that's

605
00:24:38,720 --> 00:24:42,400
already written in those legacy

606
00:24:40,559 --> 00:24:45,880
languages what should we do what should

607
00:24:42,400 --> 00:24:45,880
we do with those

608
00:24:46,000 --> 00:24:51,200
luckily there's a DARPA program called

609
00:24:48,400 --> 00:24:53,919
DARPA tractor program that tackles this

610
00:24:51,200 --> 00:24:56,480
problem uh explicitly. So the idea of

611
00:24:53,919 --> 00:24:59,760
this program is to take a piece of C

612
00:24:56,480 --> 00:25:04,000
code and automatically translate it to

613
00:24:59,760 --> 00:25:06,480
safe ROS code. Uh it uses a combination

614
00:25:04,000 --> 00:25:10,480
of techniques static analysis, dynamic

615
00:25:06,480 --> 00:25:13,840
analysis and LLMs. So LMS have also a

616
00:25:10,480 --> 00:25:16,799
big role um in this program and the key

617
00:25:13,840 --> 00:25:20,159
sort of insight is or key hypothesis is

618
00:25:16,799 --> 00:25:24,159
to be able to take C code uh translated

619
00:25:20,159 --> 00:25:26,480
into safe ROS code not just sort of

620
00:25:24,159 --> 00:25:30,240
um you know mechanically ROS code but

621
00:25:26,480 --> 00:25:32,720
unsafe code but but to safe RS code in a

622
00:25:30,240 --> 00:25:35,200
way that's also idiomatic so in a way

623
00:25:32,720 --> 00:25:37,200
that's human readable that's sort of

624
00:25:35,200 --> 00:25:38,880
looks like a code that a human has

625
00:25:37,200 --> 00:25:40,960
written not a machine generated ated

626
00:25:38,880 --> 00:25:42,960
code. If you have ever seen machine

627
00:25:40,960 --> 00:25:45,120
generated code, it's just a mess, right?

628
00:25:42,960 --> 00:25:47,440
It's very difficult to make sense of it.

629
00:25:45,120 --> 00:25:49,760
The idea of of this program is to write

630
00:25:47,440 --> 00:25:54,799
idiomatic code that looks like human

631
00:25:49,760 --> 00:25:56,159
written code. And um the even today

632
00:25:54,799 --> 00:25:58,080
there are a lot of things that could be

633
00:25:56,159 --> 00:26:00,640
done. So this this is showing one

634
00:25:58,080 --> 00:26:02,480
example of a C code that's being

635
00:26:00,640 --> 00:26:05,520
translated into Rust code with Google

636
00:26:02,480 --> 00:26:09,200
Gemini. If you look at the left side,

637
00:26:05,520 --> 00:26:11,679
the C code takes an input from the user,

638
00:26:09,200 --> 00:26:14,640
compares it with a string given a string

639
00:26:11,679 --> 00:26:16,880
and if it matches, it prints welcome

640
00:26:14,640 --> 00:26:18,720
otherwise it terminates the program.

641
00:26:16,880 --> 00:26:21,840
What is this program? It's a password

642
00:26:18,720 --> 00:26:24,480
checker and if we feed it into uh

643
00:26:21,840 --> 00:26:26,559
Gemini, it is intelligent enough to

644
00:26:24,480 --> 00:26:28,480
actually rename this variable to

645
00:26:26,559 --> 00:26:30,320
password. So it recognized that it was

646
00:26:28,480 --> 00:26:32,080
actually a password checking program

647
00:26:30,320 --> 00:26:35,120
even though the name of the variable in

648
00:26:32,080 --> 00:26:37,919
the C program wasn't password and it

649
00:26:35,120 --> 00:26:40,559
could translate in into

650
00:26:37,919 --> 00:26:42,000
fairly decent Rust code. Uh but of

651
00:26:40,559 --> 00:26:43,919
course there's a lot of work to be done

652
00:26:42,000 --> 00:26:47,279
here to be able to translate larger

653
00:26:43,919 --> 00:26:50,240
amounts of code uh and uh preserve the

654
00:26:47,279 --> 00:26:53,679
quality and sort of um the functionality

655
00:26:50,240 --> 00:26:56,640
of the code as we do.

656
00:26:53,679 --> 00:26:58,799
To summarize, today's systems remain

657
00:26:56,640 --> 00:27:01,919
vulnerable to cyber attack mainly

658
00:26:58,799 --> 00:27:03,760
because of their legacy design. Uh, and

659
00:27:01,919 --> 00:27:06,400
in order to sort of break out of this

660
00:27:03,760 --> 00:27:08,320
cycle of more investment but also more

661
00:27:06,400 --> 00:27:10,480
vulnerabilities and more attacks, we

662
00:27:08,320 --> 00:27:12,799
really need to move into this era of

663
00:27:10,480 --> 00:27:16,080
inherently secure systems that can

664
00:27:12,799 --> 00:27:19,039
achieve resiliency by design. The really

665
00:27:16,080 --> 00:27:22,240
uh the three core pillars of building a

666
00:27:19,039 --> 00:27:24,080
inherently secure system are what the

667
00:27:22,240 --> 00:27:26,559
three main pain points are in existing

668
00:27:24,080 --> 00:27:28,480
systems. Safe programming languages,

669
00:27:26,559 --> 00:27:30,720
hardware enforced security and

670
00:27:28,480 --> 00:27:33,440
compartmentalization or zero trusts or

671
00:27:30,720 --> 00:27:36,000
these additional guard rails to uh to

672
00:27:33,440 --> 00:27:37,520
limit the damage that can be done by

673
00:27:36,000 --> 00:27:40,000
attacks.

674
00:27:37,520 --> 00:27:41,600
Future directions focus on enabling

675
00:27:40,000 --> 00:27:43,520
automation as I mentioned sort of

676
00:27:41,600 --> 00:27:46,720
automatically transitioning code from

677
00:27:43,520 --> 00:27:48,480
unsafe to safe code being able to do

678
00:27:46,720 --> 00:27:50,159
this at large scale. Of course we are

679
00:27:48,480 --> 00:27:51,919
dealing with large scale systems every

680
00:27:50,159 --> 00:27:55,520
day. So it's not enough to be able to do

681
00:27:51,919 --> 00:27:57,200
this on sort of simple uh strawman

682
00:27:55,520 --> 00:27:59,840
examples. We want to really do this on

683
00:27:57,200 --> 00:28:01,520
large scale code and being able to do so

684
00:27:59,840 --> 00:28:04,000
with minimal overhead. Right? Of course

685
00:28:01,520 --> 00:28:07,039
the functionality of the system is first

686
00:28:04,000 --> 00:28:08,399
and foremost right? we shouldn't have a

687
00:28:07,039 --> 00:28:10,720
lot of overhead that would sort of

688
00:28:08,399 --> 00:28:12,320
inhibit uh adoption of these

689
00:28:10,720 --> 00:28:14,559
technologies. So being able to achieve

690
00:28:12,320 --> 00:28:16,559
minimal overhead is also key that's

691
00:28:14,559 --> 00:28:18,880
captured in a lot of these including

692
00:28:16,559 --> 00:28:20,640
hardware and for security as well. With

693
00:28:18,880 --> 00:28:25,159
that I conclude my talk. I'll be happy

694
00:28:20,640 --> 00:28:25,159
to uh happy to take questions.

695
00:28:30,399 --> 00:28:33,880
Questions for Hamemed.

696
00:28:34,720 --> 00:28:38,760
>> Going once, going twice.

697
00:28:41,919 --> 00:28:44,640
>> You mentioned the hard word for

698
00:28:43,360 --> 00:28:47,039
security. How much are you guys looking

699
00:28:44,640 --> 00:28:49,039
at trusted execution environments? And

700
00:28:47,039 --> 00:28:51,760
>> that's a great question. So we have we

701
00:28:49,039 --> 00:28:53,360
have looked at it. We have looked at uh

702
00:28:51,760 --> 00:28:55,840
trusted execution technology. We have

703
00:28:53,360 --> 00:28:58,480
looked at sort of uh tagged

704
00:28:55,840 --> 00:28:59,679
architectures. uh so they help but they

705
00:28:58,480 --> 00:29:01,760
help with different parts of this

706
00:28:59,679 --> 00:29:04,240
problem right so if you're thinking

707
00:29:01,760 --> 00:29:06,559
about uh enforcing security checks on

708
00:29:04,240 --> 00:29:08,720
the data sort of tagged architectures

709
00:29:06,559 --> 00:29:10,480
are great for that uh if there are

710
00:29:08,720 --> 00:29:12,399
applications where a part of the

711
00:29:10,480 --> 00:29:14,240
application is really the crucial part

712
00:29:12,399 --> 00:29:15,919
and the rest of it is less important and

713
00:29:14,240 --> 00:29:17,919
that happens a lot right so the core

714
00:29:15,919 --> 00:29:20,480
logic is very important and you want to

715
00:29:17,919 --> 00:29:22,480
pro protect that against sort of um

716
00:29:20,480 --> 00:29:24,320
untrusted libraries untrusted code

717
00:29:22,480 --> 00:29:27,279
trusted execution technology helps with

718
00:29:24,320 --> 00:29:29,760
that so yeah it uh It's really a

719
00:29:27,279 --> 00:29:32,000
spectrum of solutions. I would say uh

720
00:29:29,760 --> 00:29:33,760
trusted execution technologies are a

721
00:29:32,000 --> 00:29:35,679
point in that spectrum and they're

722
00:29:33,760 --> 00:29:37,200
appropriate for some things, but there

723
00:29:35,679 --> 00:29:40,200
are also other technologies in that

724
00:29:37,200 --> 00:29:40,200
area.

725
00:29:43,120 --> 00:29:48,520
>> All right, then let's hear it for Jame.

726
00:29:45,360 --> 00:29:48,520
Thank you.


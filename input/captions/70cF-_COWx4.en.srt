1
00:00:05,319 --> 00:00:12,080
Our next we'll have Sandep from Fitch's

2
00:00:08,559 --> 00:00:13,519
lab will uh talk about tissue mosaic

3
00:00:12,080 --> 00:00:16,480
which uses self-supervised

4
00:00:13,519 --> 00:00:18,480
representation learning to um enable

5
00:00:16,480 --> 00:00:22,670
cross sample differential analysis of

6
00:00:18,480 --> 00:00:27,059
spatial transcripttoid data set.

7
00:00:22,670 --> 00:00:27,059
[Applause]

8
00:00:27,240 --> 00:00:32,719
Welcome. Okay. Hi, I'm Sundep. I'm a

9
00:00:30,480 --> 00:00:35,280
graduate student um advised by FA Chen

10
00:00:32,719 --> 00:00:37,360
and Marti. And I'll be talking to you

11
00:00:35,280 --> 00:00:40,239
today about our recent method tissue

12
00:00:37,360 --> 00:00:43,200
mosaic which stands for motif-based

13
00:00:40,239 --> 00:00:45,399
spatial inference across conditions. And

14
00:00:43,200 --> 00:00:47,920
so um this is a model that can learn

15
00:00:45,399 --> 00:00:50,239
representations of spatial transcrytoics

16
00:00:47,920 --> 00:00:52,719
data via self-supervision and then these

17
00:00:50,239 --> 00:00:56,239
representations enable cross sample

18
00:00:52,719 --> 00:00:58,239
differential analysis of ST data.

19
00:00:56,239 --> 00:01:00,719
So just to give an overview of what ESKI

20
00:00:58,239 --> 00:01:02,640
data is, this is a powerful experimental

21
00:01:00,719 --> 00:01:05,519
platform that can measure gene

22
00:01:02,640 --> 00:01:07,600
expression in native tissue context. And

23
00:01:05,519 --> 00:01:10,159
what this allows us to do is start to

24
00:01:07,600 --> 00:01:13,360
study how cell state is um sort of

25
00:01:10,159 --> 00:01:15,439
modulated by a cell's local environment.

26
00:01:13,360 --> 00:01:17,840
And so the way our data is structured is

27
00:01:15,439 --> 00:01:20,799
for a given sample we'll have a list of

28
00:01:17,840 --> 00:01:23,200
spots say 1 to n and for each spot we'll

29
00:01:20,799 --> 00:01:25,720
have its xycoordinate and the measured

30
00:01:23,200 --> 00:01:29,600
gene expression profile at that

31
00:01:25,720 --> 00:01:31,600
spot. And so one sort of common uh

32
00:01:29,600 --> 00:01:33,840
downstream task of interest with gene

33
00:01:31,600 --> 00:01:35,840
expression data is differential gene

34
00:01:33,840 --> 00:01:37,520
expression analysis. Let's say you have

35
00:01:35,840 --> 00:01:39,759
a set of samples from healthy and

36
00:01:37,520 --> 00:01:42,079
diseased tissue. um you can sequence

37
00:01:39,759 --> 00:01:43,840
mRNA and then you can identify genes

38
00:01:42,079 --> 00:01:46,159
that are more highly or more lowly

39
00:01:43,840 --> 00:01:47,680
expressed in your diseased samples and

40
00:01:46,159 --> 00:01:50,280
these are genes that are presumably

41
00:01:47,680 --> 00:01:52,960
implicated in the underlying disease

42
00:01:50,280 --> 00:01:55,040
process. And so we sort of set out to

43
00:01:52,960 --> 00:01:57,040
develop a similar method to enable

44
00:01:55,040 --> 00:01:59,680
differential analysis of our spatial

45
00:01:57,040 --> 00:02:01,920
data. And so more concretely, if you

46
00:01:59,680 --> 00:02:04,079
have a group of samples from control,

47
00:02:01,920 --> 00:02:06,560
another group of samples from case, how

48
00:02:04,079 --> 00:02:09,399
can we start to understand how tissue

49
00:02:06,560 --> 00:02:12,160
structure changes across these two

50
00:02:09,399 --> 00:02:14,239
conditions? And so one issue with sort

51
00:02:12,160 --> 00:02:16,800
of answering this question is that we

52
00:02:14,239 --> 00:02:20,160
need to define what the basic unit of

53
00:02:16,800 --> 00:02:22,480
tissue structure is, the way that genes

54
00:02:20,160 --> 00:02:24,800
are a unit of comparison for bulk RNA

55
00:02:22,480 --> 00:02:26,959
seek data. And so if we could define a

56
00:02:24,800 --> 00:02:29,360
similar unit for our spatial data, we

57
00:02:26,959 --> 00:02:32,000
can then start to compare samples across

58
00:02:29,360 --> 00:02:34,720
multiple conditions. And so in our work,

59
00:02:32,000 --> 00:02:37,200
we call these units tissue motifs. And

60
00:02:34,720 --> 00:02:39,360
our goal is to discover these motifs in

61
00:02:37,200 --> 00:02:40,879
an unbiased way. And we heard some

62
00:02:39,360 --> 00:02:43,040
really cool talks yesterday about the

63
00:02:40,879 --> 00:02:45,360
importance of learning unbiased niche

64
00:02:43,040 --> 00:02:47,120
representations and how these can enable

65
00:02:45,360 --> 00:02:49,440
um differential analysis across control

66
00:02:47,120 --> 00:02:52,239
and case samples. And so in a similar

67
00:02:49,440 --> 00:02:54,800
vein, what we want to enable is a common

68
00:02:52,239 --> 00:02:57,680
representational space that can unify

69
00:02:54,800 --> 00:03:00,959
our entire spatial data set such that if

70
00:02:57,680 --> 00:03:03,440
you extracted units or say patches from

71
00:03:00,959 --> 00:03:05,519
these samples, you can then embed them

72
00:03:03,440 --> 00:03:07,840
in a common latent space and you can

73
00:03:05,519 --> 00:03:10,239
start using that latent space to compare

74
00:03:07,840 --> 00:03:13,040
and contrast tissue structure across

75
00:03:10,239 --> 00:03:14,239
samples and conditions.

76
00:03:13,040 --> 00:03:17,120
And one thing I want to sort of

77
00:03:14,239 --> 00:03:19,360
highlight is the spatial heterogeneity

78
00:03:17,120 --> 00:03:21,280
that's inherent to tissues. So you can

79
00:03:19,360 --> 00:03:23,040
imagine in this latent space we might

80
00:03:21,280 --> 00:03:25,040
have so in this lane space like sort of

81
00:03:23,040 --> 00:03:27,360
a motif as we defined earlier sort of

82
00:03:25,040 --> 00:03:29,360
like a local organizational pattern that

83
00:03:27,360 --> 00:03:31,920
appears. And so you can imagine some

84
00:03:29,360 --> 00:03:34,239
motifs might be shared across control

85
00:03:31,920 --> 00:03:36,319
and case samples whereas other motifs

86
00:03:34,239 --> 00:03:38,480
are sort of enriched for control versus

87
00:03:36,319 --> 00:03:40,640
case samples. And so in our differential

88
00:03:38,480 --> 00:03:42,319
analysis procedure, what we want might

89
00:03:40,640 --> 00:03:44,799
want to do is sort of focus on the

90
00:03:42,319 --> 00:03:47,040
motifs that are over represented in our

91
00:03:44,799 --> 00:03:47,040
case

92
00:03:47,319 --> 00:03:52,400
samples. So this then introduces the

93
00:03:50,239 --> 00:03:55,040
next question of how do we learn these

94
00:03:52,400 --> 00:03:57,760
representations without any underlying

95
00:03:55,040 --> 00:03:59,519
labels for tissue structure. And so to

96
00:03:57,760 --> 00:04:01,360
do that we turn to self-supervised

97
00:03:59,519 --> 00:04:03,840
learning which is a sort of framework

98
00:04:01,360 --> 00:04:06,720
where you can define a proxy supervised

99
00:04:03,840 --> 00:04:08,239
task to train your model. And in solving

100
00:04:06,720 --> 00:04:10,080
that task, the model will learn

101
00:04:08,239 --> 00:04:12,879
meaningful features that can then

102
00:04:10,080 --> 00:04:14,720
generalize to other downstream tasks. So

103
00:04:12,879 --> 00:04:17,120
one um common framework in computer

104
00:04:14,720 --> 00:04:18,959
vision is contrastive learning. And um

105
00:04:17,120 --> 00:04:20,479
just to build some intuition, the idea

106
00:04:18,959 --> 00:04:22,960
here is that let's let you have an image

107
00:04:20,479 --> 00:04:24,720
data set without any class labels, but

108
00:04:22,960 --> 00:04:26,160
you still want to train a classifier.

109
00:04:24,720 --> 00:04:28,320
What you can do is you can take each

110
00:04:26,160 --> 00:04:31,040
image in your data set and then perform

111
00:04:28,320 --> 00:04:32,800
two random augmentations of that image

112
00:04:31,040 --> 00:04:35,440
and then you can instruct your model to

113
00:04:32,800 --> 00:04:37,759
produce representations that are similar

114
00:04:35,440 --> 00:04:40,000
to the two input augmentations then

115
00:04:37,759 --> 00:04:42,240
dissimilar to the other images in your

116
00:04:40,000 --> 00:04:43,680
data set. And so in solving this task,

117
00:04:42,240 --> 00:04:45,680
the model will sort of learn what it

118
00:04:43,680 --> 00:04:50,240
means for a dog to look like a dog and

119
00:04:45,680 --> 00:04:52,240
how a dog might differ from say a chair.

120
00:04:50,240 --> 00:04:54,320
So sort of inspired by the success of

121
00:04:52,240 --> 00:04:56,400
these class of approaches in um on

122
00:04:54,320 --> 00:04:58,320
natural images, we decided to take a

123
00:04:56,400 --> 00:05:00,880
similar approach for our spatial data

124
00:04:58,320 --> 00:05:02,880
and model them as cell type images. And

125
00:05:00,880 --> 00:05:05,040
so what we do is for each spot we take

126
00:05:02,880 --> 00:05:07,600
its XY coordinate and from the gene

127
00:05:05,040 --> 00:05:10,080
expression we can infer the cell type or

128
00:05:07,600 --> 00:05:12,320
cell type proportions at that spot and

129
00:05:10,080 --> 00:05:14,880
then we can rasterize that information

130
00:05:12,320 --> 00:05:16,960
into a multi-dimensional image where

131
00:05:14,880 --> 00:05:18,960
each channel of this image corresponds

132
00:05:16,960 --> 00:05:20,720
to a different cell type. And so on the

133
00:05:18,960 --> 00:05:22,320
right we have an example projection of

134
00:05:20,720 --> 00:05:24,639
what that image would look like for some

135
00:05:22,320 --> 00:05:26,639
mouse testus tissue. And we sort of see

136
00:05:24,639 --> 00:05:29,000
here the emergence of tissue structure

137
00:05:26,639 --> 00:05:31,600
in the form of these

138
00:05:29,000 --> 00:05:33,520
tubules. So once we have these cell type

139
00:05:31,600 --> 00:05:35,600
images we can then apply random

140
00:05:33,520 --> 00:05:37,919
augmentations to them. And so some of

141
00:05:35,600 --> 00:05:40,160
the augmentations that we choose are

142
00:05:37,919 --> 00:05:42,720
ones commonly applied in computer vision

143
00:05:40,160 --> 00:05:44,639
like resize cropping, flipping,

144
00:05:42,720 --> 00:05:46,400
rotations.

145
00:05:44,639 --> 00:05:47,919
But we also designed some augmentations

146
00:05:46,400 --> 00:05:50,080
that are tailored to our spatial

147
00:05:47,919 --> 00:05:52,479
transcrytoics data. So one example of

148
00:05:50,080 --> 00:05:54,320
this is channel or cell type dropout.

149
00:05:52,479 --> 00:05:56,320
And this sort of forces the model to pay

150
00:05:54,320 --> 00:05:58,400
attention to information that's present

151
00:05:56,320 --> 00:06:00,400
in all of the cell types in your data

152
00:05:58,400 --> 00:06:01,080
regardless of how rare or abundant they

153
00:06:00,400 --> 00:06:03,600
might

154
00:06:01,080 --> 00:06:06,000
be. Another augmentation, this straight

155
00:06:03,600 --> 00:06:07,919
cut augmentation, sort of desensitizes

156
00:06:06,000 --> 00:06:10,400
the model to any edge effects you might

157
00:06:07,919 --> 00:06:12,240
introduce by sort of sampling a square

158
00:06:10,400 --> 00:06:13,759
patch at the edge of a circular tissue

159
00:06:12,240 --> 00:06:16,319
sample.

160
00:06:13,759 --> 00:06:18,080
And so um we sort of have a set of 10 or

161
00:06:16,319 --> 00:06:20,319
11 different augmentations and some

162
00:06:18,080 --> 00:06:21,840
other augmentations can desensitize the

163
00:06:20,319 --> 00:06:23,840
model to different technical artifacts

164
00:06:21,840 --> 00:06:25,280
in your data which helps us overcome

165
00:06:23,840 --> 00:06:27,600
some of the batch effects when you want

166
00:06:25,280 --> 00:06:29,759
to integrate multiple samples together.

167
00:06:27,600 --> 00:06:32,240
And in each training pass, we can

168
00:06:29,759 --> 00:06:34,120
extract a patch from this image where

169
00:06:32,240 --> 00:06:36,319
the size of this patch is a user

170
00:06:34,120 --> 00:06:38,880
hyperparameter and sort of reflects your

171
00:06:36,319 --> 00:06:40,800
expected length scale of your tissue.

172
00:06:38,880 --> 00:06:42,800
And we can randomly select a set of

173
00:06:40,800 --> 00:06:45,360
augmentations and then compose them

174
00:06:42,800 --> 00:06:47,000
together to produce two augmented views

175
00:06:45,360 --> 00:06:49,759
of your input

176
00:06:47,000 --> 00:06:51,800
patch. And so then the way we train our

177
00:06:49,759 --> 00:06:53,919
model is like given these two input

178
00:06:51,800 --> 00:06:56,080
augmentations, we can pass them through

179
00:06:53,919 --> 00:06:58,160
two different branches of our network

180
00:06:56,080 --> 00:07:00,160
and then use this cross entropy loss

181
00:06:58,160 --> 00:07:02,000
that sort of encourages the model to

182
00:07:00,160 --> 00:07:03,479
produce representations that are similar

183
00:07:02,000 --> 00:07:05,680
for the two input

184
00:07:03,479 --> 00:07:07,360
augmentations. And so this um

185
00:07:05,680 --> 00:07:09,440
self-supervised learning framework is

186
00:07:07,360 --> 00:07:11,840
called Dino and has sort of shown great

187
00:07:09,440 --> 00:07:13,680
success on natural images.

188
00:07:11,840 --> 00:07:15,360
And once we've trained this model, we

189
00:07:13,680 --> 00:07:18,319
can take this trained ResNet, which is

190
00:07:15,360 --> 00:07:20,240
our feature extractor, and we can tile

191
00:07:18,319 --> 00:07:22,960
our sample, our data set with a large

192
00:07:20,240 --> 00:07:25,120
number of patches, pass each patch

193
00:07:22,960 --> 00:07:27,440
through our train model, and then

194
00:07:25,120 --> 00:07:29,520
produce a set of representations that

195
00:07:27,440 --> 00:07:31,599
then encapsulate the local tissue

196
00:07:29,520 --> 00:07:33,280
structure present in your data set. And

197
00:07:31,599 --> 00:07:37,039
so then we can start to discover tissue

198
00:07:33,280 --> 00:07:39,039
motifs that are present in our data.

199
00:07:37,039 --> 00:07:42,560
And so this approach that we call tissue

200
00:07:39,039 --> 00:07:44,319
mosaic enables several downstream tasks

201
00:07:42,560 --> 00:07:46,360
um including motif query, gene

202
00:07:44,319 --> 00:07:48,639
expression aggression and motif

203
00:07:46,360 --> 00:07:50,880
enrichment. And I'll briefly go through

204
00:07:48,639 --> 00:07:53,360
these um three tasks on two different

205
00:07:50,880 --> 00:07:55,520
spatial data sets. One is of the mouse

206
00:07:53,360 --> 00:07:57,919
testice and has three wild type and

207
00:07:55,520 --> 00:08:00,400
three diabetic samples. And the other is

208
00:07:57,919 --> 00:08:03,199
of the mouse is an um atlas of aging in

209
00:08:00,400 --> 00:08:04,960
the mouse thymus.

210
00:08:03,199 --> 00:08:06,960
So the the first task I'll talk about is

211
00:08:04,960 --> 00:08:09,599
motif query. And the idea here is that

212
00:08:06,960 --> 00:08:12,080
given an input patch, we want to find

213
00:08:09,599 --> 00:08:15,680
other regions in our samples that share

214
00:08:12,080 --> 00:08:17,680
the same motif as this query patch. So

215
00:08:15,680 --> 00:08:21,599
in the testice there are sort of two

216
00:08:17,680 --> 00:08:24,400
main motifs. We have these um RS tubules

217
00:08:21,599 --> 00:08:26,960
in orange and these SPC rich tubules in

218
00:08:24,400 --> 00:08:29,759
red. And so we can see that if we query

219
00:08:26,960 --> 00:08:31,919
the sample with an RSR rich tubule,

220
00:08:29,759 --> 00:08:34,159
we're able to retrieve other RSR rich

221
00:08:31,919 --> 00:08:35,719
tubules where here we're plotting the

222
00:08:34,159 --> 00:08:37,680
similarity of the retrieval

223
00:08:35,719 --> 00:08:39,760
representation to the query

224
00:08:37,680 --> 00:08:41,599
representation as an alpha transparency

225
00:08:39,760 --> 00:08:43,519
mask. So the more opaque the retrieval

226
00:08:41,599 --> 00:08:44,959
is, the more similar it is to the query.

227
00:08:43,519 --> 00:08:47,279
And so what's sort of notable here is

228
00:08:44,959 --> 00:08:49,440
that despite using square patches and no

229
00:08:47,279 --> 00:08:51,600
other segmentation input, the model

230
00:08:49,440 --> 00:08:54,640
starting to able to learn the circular

231
00:08:51,600 --> 00:08:56,640
boundaries of these tubules.

232
00:08:54,640 --> 00:08:58,399
We can do something similar with the SPC

233
00:08:56,640 --> 00:09:00,320
rich tubules. And so we see here with

234
00:08:58,399 --> 00:09:02,800
just a single example of each query

235
00:09:00,320 --> 00:09:06,200
motif, we're able to separate our sample

236
00:09:02,800 --> 00:09:09,120
into the two main motifs present in the

237
00:09:06,200 --> 00:09:10,880
data. And so another task that's very

238
00:09:09,120 --> 00:09:12,880
related to motif query is spatial

239
00:09:10,880 --> 00:09:14,640
clustering. We can discreetly group the

240
00:09:12,880 --> 00:09:16,640
learned laten representations to get

241
00:09:14,640 --> 00:09:18,800
spatial clusters. And so in the mouse

242
00:09:16,640 --> 00:09:20,800
thymus data, the two main anatomical

243
00:09:18,800 --> 00:09:22,880
regions are the cortex in blue and the

244
00:09:20,800 --> 00:09:24,240
medula in orange. And we can see that

245
00:09:22,880 --> 00:09:26,080
when you cluster the tissue mosaic

246
00:09:24,240 --> 00:09:27,760
representations, we get really good

247
00:09:26,080 --> 00:09:30,080
concordance with these ground truth

248
00:09:27,760 --> 00:09:31,360
manual annotations of the same samples.

249
00:09:30,080 --> 00:09:33,360
And then we can quantify this

250
00:09:31,360 --> 00:09:35,279
performance by a normalized mutual

251
00:09:33,360 --> 00:09:37,760
information metric. We can see that we

252
00:09:35,279 --> 00:09:39,440
can outperform um this baseline that's

253
00:09:37,760 --> 00:09:41,120
just based on the cell type compositions

254
00:09:39,440 --> 00:09:43,360
of the patches like treating each patch

255
00:09:41,120 --> 00:09:45,279
as a bag of cells. And we can also

256
00:09:43,360 --> 00:09:48,120
outperform several other existing

257
00:09:45,279 --> 00:09:50,480
representation learning um clustering

258
00:09:48,120 --> 00:09:52,240
methods. So sort of convinced we're able

259
00:09:50,480 --> 00:09:54,560
to learn some meaningful representations

260
00:09:52,240 --> 00:09:56,480
of tissue structure, we then wanted to

261
00:09:54,560 --> 00:09:58,160
connect these representations to the

262
00:09:56,480 --> 00:10:00,880
underlying gene expression through a

263
00:09:58,160 --> 00:10:02,720
downstream regression task. And so here

264
00:10:00,880 --> 00:10:04,640
I have this regression model for those

265
00:10:02,720 --> 00:10:06,720
who are interested, but I won't go into

266
00:10:04,640 --> 00:10:08,160
detail. Um, but just to build some

267
00:10:06,720 --> 00:10:10,320
intuition, what we're trying to do here

268
00:10:08,160 --> 00:10:12,279
is we want to identify genes that sort

269
00:10:10,320 --> 00:10:14,480
of co-vary with their tissue motif

270
00:10:12,279 --> 00:10:17,200
representations and essentially identify

271
00:10:14,480 --> 00:10:19,200
genes that have high mutual information

272
00:10:17,200 --> 00:10:21,839
with tissue structure which we sort of

273
00:10:19,200 --> 00:10:23,519
formalize with this motif information

274
00:10:21,839 --> 00:10:25,680
score.

275
00:10:23,519 --> 00:10:27,360
So if we run this framework on our

276
00:10:25,680 --> 00:10:29,040
testus data, we can get this

277
00:10:27,360 --> 00:10:31,519
distribution of information scores

278
00:10:29,040 --> 00:10:34,640
across genes and we can see that a gene

279
00:10:31,519 --> 00:10:36,480
with a low information score like FAP P9

280
00:10:34,640 --> 00:10:38,640
um we're also doing this conditioned on

281
00:10:36,480 --> 00:10:40,880
cell type. So within a specific cell

282
00:10:38,640 --> 00:10:42,240
type of interest. So conditioned on ES

283
00:10:40,880 --> 00:10:44,959
cells, we're going to see a gene like

284
00:10:42,240 --> 00:10:46,880
FAB P9 has a spatially random

285
00:10:44,959 --> 00:10:49,519
distribution of expression. whereas a

286
00:10:46,880 --> 00:10:51,839
gene like TNP1 that's at the tail end of

287
00:10:49,519 --> 00:10:53,839
this distribution has a much more um

288
00:10:51,839 --> 00:10:55,360
structured distribution of expression.

289
00:10:53,839 --> 00:10:57,519
And so what's cool here is that even

290
00:10:55,360 --> 00:10:59,600
though you can't easily parameterize

291
00:10:57,519 --> 00:11:01,360
this spatial pattern, the model is still

292
00:10:59,600 --> 00:11:04,200
able to pick it up as having high mutual

293
00:11:01,360 --> 00:11:06,720
information with tissue

294
00:11:04,200 --> 00:11:08,880
structure. And so we finally wanted to

295
00:11:06,720 --> 00:11:10,959
return to our sort of motivating task

296
00:11:08,880 --> 00:11:12,560
which was the differential analysis of

297
00:11:10,959 --> 00:11:15,040
spatial data. And this is a task that we

298
00:11:12,560 --> 00:11:17,279
call motif enrichment. And the idea is

299
00:11:15,040 --> 00:11:19,200
here is that given a training set of

300
00:11:17,279 --> 00:11:21,200
motif representations and their

301
00:11:19,200 --> 00:11:23,760
condition labels, we can train a

302
00:11:21,200 --> 00:11:26,800
classifier to predict condition label

303
00:11:23,760 --> 00:11:29,200
from motif representation. And then on a

304
00:11:26,800 --> 00:11:31,440
new held out sample, we can identify

305
00:11:29,200 --> 00:11:32,800
different motifs that are similar to the

306
00:11:31,440 --> 00:11:35,040
motifs in our training set that are

307
00:11:32,800 --> 00:11:36,720
enriched for different conditions in our

308
00:11:35,040 --> 00:11:38,640
training set. And then we can start to

309
00:11:36,720 --> 00:11:40,959
do differential expression analysis at

310
00:11:38,640 --> 00:11:43,040
this motif level rather than the sample

311
00:11:40,959 --> 00:11:45,120
level.

312
00:11:43,040 --> 00:11:48,000
So when we run this framework on our

313
00:11:45,120 --> 00:11:50,320
thymus data um one hallmark of aging in

314
00:11:48,000 --> 00:11:52,800
the thymus are the presence of these

315
00:11:50,320 --> 00:11:54,480
antigen presenting cell aggregates. We

316
00:11:52,800 --> 00:11:56,959
can see the model actually highlights

317
00:11:54,480 --> 00:11:59,279
these aggregated APCs as having high

318
00:11:56,959 --> 00:12:01,920
biological age. And so what this enables

319
00:11:59,279 --> 00:12:04,079
us to do is to then run differential

320
00:12:01,920 --> 00:12:07,760
expression specifically between the aged

321
00:12:04,079 --> 00:12:09,320
APCs and the non-aged APCs. And um one

322
00:12:07,760 --> 00:12:11,680
gene that this analysis highlights is

323
00:12:09,320 --> 00:12:14,040
CD74 which has been previously

324
00:12:11,680 --> 00:12:17,360
implicated malignancies of these

325
00:12:14,040 --> 00:12:19,040
cells. We can also go beyond just um

326
00:12:17,360 --> 00:12:20,720
magnitude of expression and we can also

327
00:12:19,040 --> 00:12:23,120
start to identify genes that are

328
00:12:20,720 --> 00:12:25,040
spatially disregulated across samples

329
00:12:23,120 --> 00:12:27,200
from different conditions. And so we

330
00:12:25,040 --> 00:12:30,160
demonstrate this in the testice where

331
00:12:27,200 --> 00:12:32,480
one hallmark of disease is um the

332
00:12:30,160 --> 00:12:34,399
presence of these disorganized tubules

333
00:12:32,480 --> 00:12:36,079
where you kind of see that the the

334
00:12:34,399 --> 00:12:37,920
periphery cells are orange or red sort

335
00:12:36,079 --> 00:12:40,000
of get mixed with the blue cells on the

336
00:12:37,920 --> 00:12:42,240
interior. And so we can quantify this

337
00:12:40,000 --> 00:12:44,480
disorganization with this ES purity

338
00:12:42,240 --> 00:12:47,600
metric. We can see the model is able to

339
00:12:44,480 --> 00:12:49,760
highlight the impure ES cells as having

340
00:12:47,600 --> 00:12:51,200
um a high diabetic scores which is we

341
00:12:49,760 --> 00:12:54,560
think is a fairly like subtle phenotype

342
00:12:51,200 --> 00:12:56,240
of disorganization in this data.

343
00:12:54,560 --> 00:12:58,880
And what's kind of cool is that we can

344
00:12:56,240 --> 00:13:01,600
then use our regression framework to

345
00:12:58,880 --> 00:13:03,760
define this differential tissue motif

346
00:13:01,600 --> 00:13:06,040
information score. And so this score is

347
00:13:03,760 --> 00:13:09,040
essentially sort of a metric of spatial

348
00:13:06,040 --> 00:13:11,760
disregulation across conditions. And so

349
00:13:09,040 --> 00:13:13,920
in blue in this is a distribution across

350
00:13:11,760 --> 00:13:15,519
genes. And in blue we have when we run

351
00:13:13,920 --> 00:13:18,320
this regression framework just using

352
00:13:15,519 --> 00:13:19,839
sample label. And then in um red we have

353
00:13:18,320 --> 00:13:22,000
this distribution when we run it using

354
00:13:19,839 --> 00:13:24,560
the enriched motifs. So kind of focusing

355
00:13:22,000 --> 00:13:26,800
in on the regions that are enriched in

356
00:13:24,560 --> 00:13:29,120
disease versus healthy samples. And we

357
00:13:26,800 --> 00:13:31,839
can see that a gene like SMCP that's

358
00:13:29,120 --> 00:13:34,560
known to be disregulated in the testice

359
00:13:31,839 --> 00:13:36,079
during diabetes has a small negative

360
00:13:34,560 --> 00:13:38,480
differential score. But by performing

361
00:13:36,079 --> 00:13:40,720
this motif enrichment procedure, we can

362
00:13:38,480 --> 00:13:43,440
detect a much greater effect size for

363
00:13:40,720 --> 00:13:45,040
this gene. And we also developed um a

364
00:13:43,440 --> 00:13:46,560
hypothesis testing framework that can

365
00:13:45,040 --> 00:13:48,399
allow you to assign statistical

366
00:13:46,560 --> 00:13:49,680
significance to these scores. And we

367
00:13:48,399 --> 00:13:51,200
think that this sort of result is kind

368
00:13:49,680 --> 00:13:53,760
of powerful in sort of ident starting to

369
00:13:51,200 --> 00:13:55,920
identify genes and gene programs that

370
00:13:53,760 --> 00:13:58,600
are sort of spatially disregulated

371
00:13:55,920 --> 00:14:01,519
within diseased

372
00:13:58,600 --> 00:14:03,680
samples. And so in conclusion here we

373
00:14:01,519 --> 00:14:06,079
have tissue mosaic, a method that learns

374
00:14:03,680 --> 00:14:08,240
representations of tissue structure and

375
00:14:06,079 --> 00:14:10,959
connects these representations back to

376
00:14:08,240 --> 00:14:13,120
the underlying gene expression. And then

377
00:14:10,959 --> 00:14:15,120
by doing this we're able to enable cross

378
00:14:13,120 --> 00:14:17,600
sample differential analysis. So we can

379
00:14:15,120 --> 00:14:19,519
identify motifs that vary across say

380
00:14:17,600 --> 00:14:21,680
healthy versus disease and then

381
00:14:19,519 --> 00:14:24,480
furthermore detect genes that covary

382
00:14:21,680 --> 00:14:26,399
with these motifs. And so by doing this

383
00:14:24,480 --> 00:14:29,040
we can then see how changes in tissue

384
00:14:26,399 --> 00:14:31,360
organization say due to disease start to

385
00:14:29,040 --> 00:14:33,360
impact transcriptional programs and

386
00:14:31,360 --> 00:14:35,800
start to sort of identify the functional

387
00:14:33,360 --> 00:14:38,639
organization of these

388
00:14:35,800 --> 00:14:41,600
tissues. And so um with that I'd like to

389
00:14:38,639 --> 00:14:42,880
thank my mentors FY and Mr. Um, if you

390
00:14:41,600 --> 00:14:45,279
want to learn more about our work, we

391
00:14:42,880 --> 00:14:46,560
have a pre-print out. Um, we demonstrate

392
00:14:45,279 --> 00:14:48,480
this in a variety of different

393
00:14:46,560 --> 00:14:50,560
technologies and tissues to show the

394
00:14:48,480 --> 00:14:52,959
model readily generalizes to different

395
00:14:50,560 --> 00:14:54,800
data sets. Um, I'd also like to thank my

396
00:14:52,959 --> 00:14:57,440
co-authors, particularly Luca, who made

397
00:14:54,800 --> 00:14:59,360
a lot of contributions to the codebase.

398
00:14:57,440 --> 00:15:00,800
And, um, yeah, I'd be happy to take any

399
00:14:59,360 --> 00:15:06,959
questions.

400
00:15:00,800 --> 00:15:09,519
[Applause]

401
00:15:06,959 --> 00:15:11,600
Great talk. Thanks, Andep. Uh, we have

402
00:15:09,519 --> 00:15:14,600
room for one question before our coffee

403
00:15:11,600 --> 00:15:14,600
break.

404
00:15:19,680 --> 00:15:24,160
So, when you do this dino like thing and

405
00:15:22,240 --> 00:15:26,000
you've got did you come from the same

406
00:15:24,160 --> 00:15:29,279
sample or were you the you know

407
00:15:26,000 --> 00:15:31,240
augmented versions? Are there other

408
00:15:29,279 --> 00:15:33,680
similarities so that you could take

409
00:15:31,240 --> 00:15:35,760
things from different regions of

410
00:15:33,680 --> 00:15:38,160
different images and still have like

411
00:15:35,760 --> 00:15:41,680
maybe an external label that would let

412
00:15:38,160 --> 00:15:43,760
you do that um cross entropy, right? So

413
00:15:41,680 --> 00:15:46,079
you're saying instead of taking the same

414
00:15:43,760 --> 00:15:47,519
like the the the you can contrast

415
00:15:46,079 --> 00:15:48,880
against patches from different images.

416
00:15:47,519 --> 00:15:50,959
Yeah. In the past we've done things

417
00:15:48,880 --> 00:15:52,639
where are you the same fold are you the

418
00:15:50,959 --> 00:15:54,079
same fold and function and of course you

419
00:15:52,639 --> 00:15:55,839
then end up doing a ton of work to

420
00:15:54,079 --> 00:15:57,360
figure out which of those relationships

421
00:15:55,839 --> 00:15:59,360
are reliable enough. Yeah. Yeah. Yeah.

422
00:15:57,360 --> 00:16:01,600
Yeah, but have you thought about that so

423
00:15:59,360 --> 00:16:03,360
that it's not just the are you two

424
00:16:01,600 --> 00:16:04,880
augmented versions of the the same

425
00:16:03,360 --> 00:16:06,399
patch, but you're actually two other

426
00:16:04,880 --> 00:16:08,320
things that are substantively similar

427
00:16:06,399 --> 00:16:09,519
across some other annotation. Yeah.

428
00:16:08,320 --> 00:16:11,040
Yeah. Yeah. So, we thought about that a

429
00:16:09,519 --> 00:16:12,959
little bit in the context of a different

430
00:16:11,040 --> 00:16:15,759
loss like Sinclair. So, here with this

431
00:16:12,959 --> 00:16:17,600
dino loss, you kind of um we thought

432
00:16:15,759 --> 00:16:18,880
Okay. So we thought about using the the

433
00:16:17,600 --> 00:16:20,560
frame custom flare where you have like

434
00:16:18,880 --> 00:16:22,079
negative samples you contrast against

435
00:16:20,560 --> 00:16:23,519
and then maybe try to use that to like

436
00:16:22,079 --> 00:16:26,000
overcome batch effects and things like

437
00:16:23,519 --> 00:16:28,079
that by contrasting against maybe like

438
00:16:26,000 --> 00:16:30,320
um patches from like um you can maybe

439
00:16:28,079 --> 00:16:31,759
like specifically only have patches from

440
00:16:30,320 --> 00:16:33,759
the same sample that you contrast

441
00:16:31,759 --> 00:16:35,839
against and maybe then try to overcome

442
00:16:33,759 --> 00:16:38,480
sample specific effects that way. But

443
00:16:35,839 --> 00:16:40,399
actually what we found was that just

444
00:16:38,480 --> 00:16:41,759
this not sort of we didn't need to worry

445
00:16:40,399 --> 00:16:43,440
about doing any of that. just this like

446
00:16:41,759 --> 00:16:44,880
straightforward implementation with

447
00:16:43,440 --> 00:16:46,880
taking the same patch actually worked

448
00:16:44,880 --> 00:16:48,800
pretty well at learning some integrated

449
00:16:46,880 --> 00:16:50,160
embedding space and we think one reason

450
00:16:48,800 --> 00:16:52,079
for that is that we're just modeling

451
00:16:50,160 --> 00:16:53,920
cell types and so those cell types are

452
00:16:52,079 --> 00:16:57,680
shared across all of the data and so

453
00:16:53,920 --> 00:16:59,600
that's kind of how we get get at that.

454
00:16:57,680 --> 00:17:02,140
Okay. So thank you to all the speakers

455
00:16:59,600 --> 00:17:07,670
of this morning's session.

456
00:17:02,140 --> 00:17:07,670
[Applause]


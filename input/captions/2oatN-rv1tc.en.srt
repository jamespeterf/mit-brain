1
00:00:00,000 --> 00:00:04,720
Our first session is about data

2
00:00:02,240 --> 00:00:08,320
analytics and digital twins to realtime

3
00:00:04,720 --> 00:00:10,800
control by Dr. Brian Anthony, principal

4
00:00:08,320 --> 00:00:13,280
research scientist at MI at MIT's

5
00:00:10,800 --> 00:00:16,160
department of mechanical engineering and

6
00:00:13,280 --> 00:00:19,520
associate director of MIT Nano. Please

7
00:00:16,160 --> 00:00:21,760
post your questions into the Q&A tab.

8
00:00:19,520 --> 00:00:23,119
Dr. Anthony, welcome. The floor is

9
00:00:21,760 --> 00:00:25,519
yours.

10
00:00:23,119 --> 00:00:26,560
>> Very good, Eduardo. Uh, thank you. And

11
00:00:25,519 --> 00:00:28,080
good morning, good evening, good

12
00:00:26,560 --> 00:00:30,080
afternoon, everybody. I know some people

13
00:00:28,080 --> 00:00:32,719
we have live and some people will be

14
00:00:30,080 --> 00:00:34,640
watching this after the fact. So um what

15
00:00:32,719 --> 00:00:36,960
I want to do today in the next say 30

16
00:00:34,640 --> 00:00:38,960
minutes is uh teach you a little bit uh

17
00:00:36,960 --> 00:00:41,760
and inspire you a little bit around the

18
00:00:38,960 --> 00:00:43,520
the art of possible and as Eduardo said

19
00:00:41,760 --> 00:00:46,800
sort of the intersection of of data

20
00:00:43,520 --> 00:00:48,960
science and operations uh but sort of

21
00:00:46,800 --> 00:00:50,960
digital twins machine learning all these

22
00:00:48,960 --> 00:00:53,680
concepts do come together in an

23
00:00:50,960 --> 00:00:55,280
interesting way. So the agenda some

24
00:00:53,680 --> 00:00:57,840
opportunities and needs I think they

25
00:00:55,280 --> 00:01:00,160
abound in mining. Why isn't mining fully

26
00:00:57,840 --> 00:01:02,239
data enhanced already? Question. Um

27
00:01:00,160 --> 00:01:03,600
share a little bit of the the art of the

28
00:01:02,239 --> 00:01:05,760
possible that are tools that you should

29
00:01:03,600 --> 00:01:07,680
be using already. Code automation as a

30
00:01:05,760 --> 00:01:10,320
sort of a a level setting of what you

31
00:01:07,680 --> 00:01:13,760
can do now. um sort of some motivation

32
00:01:10,320 --> 00:01:15,600
for how to take how to how to approach

33
00:01:13,760 --> 00:01:17,360
designing [snorts] in a ecosystem such

34
00:01:15,600 --> 00:01:19,520
as mining or manufacturing where you

35
00:01:17,360 --> 00:01:21,680
need to have both domain knowledge and

36
00:01:19,520 --> 00:01:23,200
take advantage of modern instrumentation

37
00:01:21,680 --> 00:01:25,680
tools whether it be data science or

38
00:01:23,200 --> 00:01:27,840
sensors and then close with some rapid

39
00:01:25,680 --> 00:01:29,680
dive examples. So we like to say

40
00:01:27,840 --> 00:01:31,600
education at MIT is like drinking from a

41
00:01:29,680 --> 00:01:34,720
fire hose. So I'm going to turn the the

42
00:01:31,600 --> 00:01:38,320
fire hose on uh and do please chat with

43
00:01:34,720 --> 00:01:40,560
questions. Um so there are many valuable

44
00:01:38,320 --> 00:01:42,240
data science digital twin which is a

45
00:01:40,560 --> 00:01:44,320
digital twin just a model that's updated

46
00:01:42,240 --> 00:01:46,799
over time but valuable opportunities in

47
00:01:44,320 --> 00:01:49,119
mining. So it's resource intelligence

48
00:01:46,799 --> 00:01:51,600
mind-to-mill optimization integrated

49
00:01:49,119 --> 00:01:54,079
autonomous operations overall improved

50
00:01:51,600 --> 00:01:56,479
reliability safety geotechnical risk and

51
00:01:54,079 --> 00:01:58,960
certainly energy and sustainability. So

52
00:01:56,479 --> 00:02:01,200
there's a lot of opportunities and you

53
00:01:58,960 --> 00:02:02,960
could ask well why why are we having

54
00:02:01,200 --> 00:02:06,479
this webinar? Why aren't mining

55
00:02:02,960 --> 00:02:09,119
operations smart and automated already?

56
00:02:06,479 --> 00:02:10,879
If you ask a chat GPT that question and

57
00:02:09,119 --> 00:02:12,239
tell it to generate an image, well,

58
00:02:10,879 --> 00:02:14,239
these are the two images that it'll

59
00:02:12,239 --> 00:02:16,720
generate for you. So, why aren't mining

60
00:02:14,239 --> 00:02:19,200
operations smart already? Um there's a

61
00:02:16,720 --> 00:02:22,400
nice survey put out by mining magazine a

62
00:02:19,200 --> 00:02:24,160
year ago um that emphasizes that very

63
00:02:22,400 --> 00:02:26,480
there aren't a large number of companies

64
00:02:24,160 --> 00:02:28,560
far less than majority of companies that

65
00:02:26,480 --> 00:02:32,720
are actually reporting machine learning

66
00:02:28,560 --> 00:02:35,280
AI deployments in the mining space and

67
00:02:32,720 --> 00:02:37,760
the biggest barrier reported in that

68
00:02:35,280 --> 00:02:39,840
survey to entry is the the lack of

69
00:02:37,760 --> 00:02:42,319
knowledge in the workforce to how to

70
00:02:39,840 --> 00:02:44,239
deploy skill how to deploy different

71
00:02:42,319 --> 00:02:46,239
technologies whether it be novel sensors

72
00:02:44,239 --> 00:02:48,720
or analytics and then certainly the

73
00:02:46,239 --> 00:02:51,280
availability of of sensors and and

74
00:02:48,720 --> 00:02:53,280
interoperability of of technologies that

75
00:02:51,280 --> 00:02:55,680
you can deploy into the harsh harsh

76
00:02:53,280 --> 00:02:57,280
environments of of mining and mining

77
00:02:55,680 --> 00:03:00,239
operations.

78
00:02:57,280 --> 00:03:02,560
So part of today is is making sure that

79
00:03:00,239 --> 00:03:05,200
you're aware of of what the new tools

80
00:03:02,560 --> 00:03:07,120
that are available can possibly do to

81
00:03:05,200 --> 00:03:08,720
help at least reduce some of the skills

82
00:03:07,120 --> 00:03:11,360
challenges. It hasn't solved the skills

83
00:03:08,720 --> 00:03:12,879
challenges, but um and then we'll take

84
00:03:11,360 --> 00:03:16,560
it from there.

85
00:03:12,879 --> 00:03:18,319
So I I know I imagine that all of you

86
00:03:16,560 --> 00:03:21,040
and if you have not had the chance to

87
00:03:18,319 --> 00:03:26,159
have a uh an interaction with with

88
00:03:21,040 --> 00:03:28,480
Gemini with chat GPT um um please do. So

89
00:03:26,159 --> 00:03:31,120
let me just level set everybody with

90
00:03:28,480 --> 00:03:32,640
what are the the new tools that are

91
00:03:31,120 --> 00:03:34,959
possible. So I wanted to start from

92
00:03:32,640 --> 00:03:37,599
scratch in in preparing my these slides

93
00:03:34,959 --> 00:03:40,400
for you. I wanted to say, well, how how

94
00:03:37,599 --> 00:03:42,640
fast could somebody that knows

95
00:03:40,400 --> 00:03:45,120
at least a little bit of the data that

96
00:03:42,640 --> 00:03:47,440
they have, how could you use machine

97
00:03:45,120 --> 00:03:50,879
learning tools, things like chat GPT and

98
00:03:47,440 --> 00:03:52,480
Gemini to augment

99
00:03:50,879 --> 00:03:54,640
your understanding of how to analyze

100
00:03:52,480 --> 00:03:57,439
data. So what do I mean mean by that? I

101
00:03:54,640 --> 00:03:59,120
I found this in in one day. Let me share

102
00:03:57,439 --> 00:04:00,720
with you what I did in one day in

103
00:03:59,120 --> 00:04:04,000
preparation at least this section of my

104
00:04:00,720 --> 00:04:07,200
talk. I found this open data set um data

105
00:04:04,000 --> 00:04:10,239
mining challenge from 2016 predicting

106
00:04:07,200 --> 00:04:13,200
dangerous seismic event events in active

107
00:04:10,239 --> 00:04:16,799
coal mines. So in this data set there

108
00:04:13,200 --> 00:04:20,000
are almost 80,000 records um with data

109
00:04:16,799 --> 00:04:22,079
on seismic activity different um sort of

110
00:04:20,000 --> 00:04:23,680
measurements of accelerometry

111
00:04:22,079 --> 00:04:25,520
of of

112
00:04:23,680 --> 00:04:28,000
number of different temperature sensors

113
00:04:25,520 --> 00:04:31,680
different site information and the data

114
00:04:28,000 --> 00:04:34,160
is labeled and in that it has a labeling

115
00:04:31,680 --> 00:04:36,320
as whether or not in the subsequent day

116
00:04:34,160 --> 00:04:39,360
it was a normal day of operation or

117
00:04:36,320 --> 00:04:41,280
there was actually seismic activity. Um

118
00:04:39,360 --> 00:04:43,120
so the data is labeled well and the

119
00:04:41,280 --> 00:04:45,120
prior day

120
00:04:43,120 --> 00:04:46,880
are we able to predict you know the the

121
00:04:45,120 --> 00:04:48,479
labeling of the data was the following

122
00:04:46,880 --> 00:04:50,479
day was a normal day or there was a

123
00:04:48,479 --> 00:04:52,639
heavy seismic activity that maybe we

124
00:04:50,479 --> 00:04:56,479
could have been alerted to. So we have

125
00:04:52,639 --> 00:04:58,479
80,000 data records and the question

126
00:04:56,479 --> 00:04:59,680
posed by this challenge and and the the

127
00:04:58,479 --> 00:05:02,560
question that you would often want to

128
00:04:59,680 --> 00:05:05,759
ask in a in a data science application

129
00:05:02,560 --> 00:05:07,840
of data is I have some historical data

130
00:05:05,759 --> 00:05:10,560
some observations that I have labelings

131
00:05:07,840 --> 00:05:12,400
for. You know I have the last three

132
00:05:10,560 --> 00:05:14,320
years of of data where I have seismic

133
00:05:12,400 --> 00:05:16,000
activity and I and I know whether the

134
00:05:14,320 --> 00:05:18,479
following day whether there was an

135
00:05:16,000 --> 00:05:20,800
active seismic event or not. So we would

136
00:05:18,479 --> 00:05:22,479
like to take that historical data, learn

137
00:05:20,800 --> 00:05:24,800
the mapping between an input and an

138
00:05:22,479 --> 00:05:27,039
output. The input in this case would be

139
00:05:24,800 --> 00:05:29,120
the seismic activity, different

140
00:05:27,039 --> 00:05:31,280
temperature sensors, sort of

141
00:05:29,120 --> 00:05:33,600
environmental conditions and then to

142
00:05:31,280 --> 00:05:35,199
predict whether the following day is

143
00:05:33,600 --> 00:05:37,280
going to be a normal day or there's

144
00:05:35,199 --> 00:05:39,360
going to be seismic activity. Right? So

145
00:05:37,280 --> 00:05:41,759
we want to learn a classifier. We want

146
00:05:39,360 --> 00:05:44,000
to learn a machine learning tool back in

147
00:05:41,759 --> 00:05:46,800
in the future. Observe what's happening

148
00:05:44,000 --> 00:05:48,639
today and predict what's going to happen

149
00:05:46,800 --> 00:05:50,639
tomorrow. Are we going to have a seismic

150
00:05:48,639 --> 00:05:52,960
event based on all the sensory data?

151
00:05:50,639 --> 00:05:54,479
Right? So this is a a classical very

152
00:05:52,960 --> 00:05:56,720
sort of classical machine learning

153
00:05:54,479 --> 00:05:58,400
problem where we have some some

154
00:05:56,720 --> 00:06:00,400
observations here. I've oversimplified.

155
00:05:58,400 --> 00:06:02,000
We have some observations, some

156
00:06:00,400 --> 00:06:03,919
historical observations that we have

157
00:06:02,000 --> 00:06:06,800
some labeling. We know that one side is

158
00:06:03,919 --> 00:06:08,479
normal, one side is warning. And we want

159
00:06:06,800 --> 00:06:11,520
to be able to learn what that boundary

160
00:06:08,479 --> 00:06:13,280
is. And that's what that's a it's a good

161
00:06:11,520 --> 00:06:14,800
machine learning problem. And we're

162
00:06:13,280 --> 00:06:17,919
doing this on seismic data. So So what

163
00:06:14,800 --> 00:06:20,800
did I do? I downloaded the data and I

164
00:06:17,919 --> 00:06:25,360
loaded it to big tables and I loaded

165
00:06:20,800 --> 00:06:28,880
that into uh Google cloud and then I

166
00:06:25,360 --> 00:06:31,440
spent two minutes typing the bold lines

167
00:06:28,880 --> 00:06:33,120
that you see here into chat GBT said

168
00:06:31,440 --> 00:06:35,360
well I'm I've loaded this data I have

169
00:06:33,120 --> 00:06:37,360
training data that's the t I had the

170
00:06:35,360 --> 00:06:39,440
labeling whether or not it was normal or

171
00:06:37,360 --> 00:06:42,080
warning the following day and then I

172
00:06:39,440 --> 00:06:45,280
have some validation data that I'm not

173
00:06:42,080 --> 00:06:47,680
going to use in the training and I also

174
00:06:45,280 --> 00:06:49,919
have labels associated with that. So I'm

175
00:06:47,680 --> 00:06:52,560
I'm I what I would like to do is is

176
00:06:49,919 --> 00:06:54,319
train a particular type of classifier.

177
00:06:52,560 --> 00:06:56,800
In this case, a random forest

178
00:06:54,319 --> 00:06:58,479
classifier. It's a it's a classifier

179
00:06:56,800 --> 00:06:59,599
that's a game of 20 questions, if you

180
00:06:58,479 --> 00:07:00,960
will. And that's not the important

181
00:06:59,599 --> 00:07:02,960
thing. I I know this thing. I've heard

182
00:07:00,960 --> 00:07:05,280
of this thing called a a random forest

183
00:07:02,960 --> 00:07:06,560
classifier. So I want to train a

184
00:07:05,280 --> 00:07:10,880
classifier that's going to be able to

185
00:07:06,560 --> 00:07:12,880
predict warning versus normal on the

186
00:07:10,880 --> 00:07:14,400
training data. And I would like to

187
00:07:12,880 --> 00:07:17,599
validate its performance on the

188
00:07:14,400 --> 00:07:19,199
validation data. So this is the coding

189
00:07:17,599 --> 00:07:22,240
that I'm going to tell you that I this

190
00:07:19,199 --> 00:07:24,880
is all that I did. I loaded the data and

191
00:07:22,240 --> 00:07:26,960
I typed this. I said improve I gave the

192
00:07:24,880 --> 00:07:28,880
instructions to chat GPT improve this

193
00:07:26,960 --> 00:07:31,599
coding prompt.

194
00:07:28,880 --> 00:07:34,000
Well, what did chat GPT give to me? Chat

195
00:07:31,599 --> 00:07:36,800
GPT improved my prompt. So I first like

196
00:07:34,000 --> 00:07:38,720
that's what I want to do. And chat GPT

197
00:07:36,800 --> 00:07:41,039
said, well, okay, well here's a a more

198
00:07:38,720 --> 00:07:43,759
expansive. I thought for 30 seconds and

199
00:07:41,039 --> 00:07:45,280
it gave me a little bit more nuance of

200
00:07:43,759 --> 00:07:47,360
the things that I might be wanting to

201
00:07:45,280 --> 00:07:49,360
think about. I didn't generate this. All

202
00:07:47,360 --> 00:07:51,680
I generated was the five lines of human

203
00:07:49,360 --> 00:07:53,440
text and it said, "Well, here's some

204
00:07:51,680 --> 00:07:55,599
inputs. Here's some more clarity on what

205
00:07:53,440 --> 00:07:59,840
we think are the tasks." So, I did not

206
00:07:55,599 --> 00:08:02,479
edit this at all. I took that and then I

207
00:07:59,840 --> 00:08:04,639
swapped over to a a different machine

208
00:08:02,479 --> 00:08:08,240
learning tool. I jump jumped over to

209
00:08:04,639 --> 00:08:11,120
Collab which is uh Google's online uh

210
00:08:08,240 --> 00:08:13,280
Python environment um that has its

211
00:08:11,120 --> 00:08:17,199
companion language model interpreter

212
00:08:13,280 --> 00:08:19,440
called Gemini and I dumped that prompt

213
00:08:17,199 --> 00:08:22,400
the prompt here that was generated by

214
00:08:19,440 --> 00:08:24,960
chat GPT I dumped that into Gemini and

215
00:08:22,400 --> 00:08:29,199
say hey create the code that will do

216
00:08:24,960 --> 00:08:31,280
this and run it.

217
00:08:29,199 --> 00:08:34,159
So this all that you're seeing on these

218
00:08:31,280 --> 00:08:36,959
following slides are code that was

219
00:08:34,159 --> 00:08:40,560
created by Gemini in response to that

220
00:08:36,959 --> 00:08:42,399
request. It's Python code. It's five

221
00:08:40,560 --> 00:08:44,399
slides of code that would have taken me,

222
00:08:42,399 --> 00:08:47,600
you know, a a day of solid day to make

223
00:08:44,399 --> 00:08:48,959
sure I debugged it. Um, it sort of looks

224
00:08:47,600 --> 00:08:51,760
at the data, make sure there's no

225
00:08:48,959 --> 00:08:55,440
missing data, make sure that it it

226
00:08:51,760 --> 00:08:57,839
converts text data uh to numeric data in

227
00:08:55,440 --> 00:09:00,480
a in a creative way called one hot

228
00:08:57,839 --> 00:09:02,399
encoding. that's not important. Um, and

229
00:09:00,480 --> 00:09:04,800
then it trained the model. This model

230
00:09:02,399 --> 00:09:06,560
training, well, there was about an hour

231
00:09:04,800 --> 00:09:07,920
of me debugging because Gemini didn't do

232
00:09:06,560 --> 00:09:11,440
a perfect thing. So, I did a little bit

233
00:09:07,920 --> 00:09:13,040
of debugging. Um, but it generated the

234
00:09:11,440 --> 00:09:15,360
after I did that debugging, the model

235
00:09:13,040 --> 00:09:17,920
took about two hours to train and and

236
00:09:15,360 --> 00:09:19,920
then it ran this code to well, how how

237
00:09:17,920 --> 00:09:22,640
well does it work on the on the

238
00:09:19,920 --> 00:09:25,440
validation set? And it has a really high

239
00:09:22,640 --> 00:09:28,480
accuracy, a really high precision. um

240
00:09:25,440 --> 00:09:30,480
generates some plots automatically and

241
00:09:28,480 --> 00:09:32,320
these are the plots of the final result.

242
00:09:30,480 --> 00:09:34,000
It it identified automatically for me

243
00:09:32,320 --> 00:09:36,240
the features in my data that were

244
00:09:34,000 --> 00:09:38,399
important. It gives me an ROC curve that

245
00:09:36,240 --> 00:09:39,839
tells me how well the classifier works.

246
00:09:38,399 --> 00:09:41,200
How often is it predicting the right

247
00:09:39,839 --> 00:09:44,399
thing? How is it predicting the wrong

248
00:09:41,200 --> 00:09:48,240
thing? And it's not perfect, but I I

249
00:09:44,399 --> 00:09:50,720
took two minutes to type and in a little

250
00:09:48,240 --> 00:09:52,480
bit of time to debug, two hours of the

251
00:09:50,720 --> 00:09:54,880
computer in the background running

252
00:09:52,480 --> 00:09:56,720
itself to develop one type of

253
00:09:54,880 --> 00:09:59,360
classifier. It's this the the the model

254
00:09:56,720 --> 00:10:01,920
here is a a decision tree which takes as

255
00:09:59,360 --> 00:10:03,920
input all this seismic data, tremors,

256
00:10:01,920 --> 00:10:05,680
energy, and it's now has a way to

257
00:10:03,920 --> 00:10:08,720
predict whether or not tomorrow is going

258
00:10:05,680 --> 00:10:10,640
to be a normal day uh or a warning day.

259
00:10:08,720 --> 00:10:12,399
So, this is truly amazing, right? These

260
00:10:10,640 --> 00:10:13,839
tools are amazing and I and I say this,

261
00:10:12,399 --> 00:10:16,800
I'm sure some of you are familiar with

262
00:10:13,839 --> 00:10:19,839
that. But I did so very very little. I

263
00:10:16,800 --> 00:10:21,760
wrote these five lines of text. I loaded

264
00:10:19,839 --> 00:10:23,360
the data. I knew the right things to ask

265
00:10:21,760 --> 00:10:26,959
for it. I I did have to do the

266
00:10:23,360 --> 00:10:28,800
debugging. So these new tools are going

267
00:10:26,959 --> 00:10:30,160
to help, right? They don't they don't

268
00:10:28,800 --> 00:10:32,000
solve all the world's problems, right?

269
00:10:30,160 --> 00:10:33,200
We're not replacing humans. We're going

270
00:10:32,000 --> 00:10:34,560
to need to do different things. We're

271
00:10:33,200 --> 00:10:35,680
going to need to be managers of these

272
00:10:34,560 --> 00:10:37,839
tools and know how to use them

273
00:10:35,680 --> 00:10:38,880
appropriately. The new tools are going

274
00:10:37,839 --> 00:10:40,959
to help with some of the training

275
00:10:38,880 --> 00:10:43,279
problem. There needs there remains a

276
00:10:40,959 --> 00:10:45,040
strong need for sensors. There remains a

277
00:10:43,279 --> 00:10:46,800
strong need for the context of how we

278
00:10:45,040 --> 00:10:48,399
collect data. And indeed, there's much

279
00:10:46,800 --> 00:10:51,040
to learn from manufacturing. And when

280
00:10:48,399 --> 00:10:53,839
we're designing ways to be smart, to be

281
00:10:51,040 --> 00:10:56,000
automated, we need to take into account

282
00:10:53,839 --> 00:10:58,959
both the physical context, domain

283
00:10:56,000 --> 00:11:00,720
knowledge, and what sensors can give us,

284
00:10:58,959 --> 00:11:02,720
the data, the information-rich data can

285
00:11:00,720 --> 00:11:04,880
tell us. And we don't want to put too

286
00:11:02,720 --> 00:11:06,320
much burden on our our algorithms. We

287
00:11:04,880 --> 00:11:08,399
would like to be as intelligent as

288
00:11:06,320 --> 00:11:09,920
possible in the deployment of our

289
00:11:08,399 --> 00:11:12,240
sensors.

290
00:11:09,920 --> 00:11:14,079
So, first, um, here are just five slides

291
00:11:12,240 --> 00:11:15,600
that I'm going to show up real quick.

292
00:11:14,079 --> 00:11:17,040
And there's you you'll there's some

293
00:11:15,600 --> 00:11:19,360
literature references on the bottom that

294
00:11:17,040 --> 00:11:22,079
you can go to, but I I show these these

295
00:11:19,360 --> 00:11:23,920
are areas now that are that are being

296
00:11:22,079 --> 00:11:26,240
addressed that are bringing to bear this

297
00:11:23,920 --> 00:11:28,160
concept of data science and automation.

298
00:11:26,240 --> 00:11:30,560
These are both academic and industry

299
00:11:28,160 --> 00:11:32,240
literature uh in the mining space,

300
00:11:30,560 --> 00:11:34,959
right? Just to motivate the deep dives

301
00:11:32,240 --> 00:11:36,800
that I'm going to tell you. So or body

302
00:11:34,959 --> 00:11:38,720
modeling and resource estimation under

303
00:11:36,800 --> 00:11:40,560
uncertainty you know you can sort of see

304
00:11:38,720 --> 00:11:42,640
why and like the references here are at

305
00:11:40,560 --> 00:11:44,560
the bottom and things like you know

306
00:11:42,640 --> 00:11:46,880
real-time control of machinery and

307
00:11:44,560 --> 00:11:49,519
operations and creating digital twins. A

308
00:11:46,880 --> 00:11:51,200
digital twin is a is a model that's

309
00:11:49,519 --> 00:11:53,279
updated with some data can be physics

310
00:11:51,200 --> 00:11:56,160
informed and data informed but allows us

311
00:11:53,279 --> 00:11:59,920
to predict the future. How do we choose

312
00:11:56,160 --> 00:12:03,040
to dispatch our trucks and do um the

313
00:11:59,920 --> 00:12:05,760
logistics of operations? How do we

314
00:12:03,040 --> 00:12:07,920
maintain our equipment? How do we

315
00:12:05,760 --> 00:12:10,720
monitor when machinery is starting to

316
00:12:07,920 --> 00:12:12,000
break down? Whether it be uh trucks out

317
00:12:10,720 --> 00:12:13,680
in the field or the maintenance

318
00:12:12,000 --> 00:12:17,279
equipments that is doing the sort of the

319
00:12:13,680 --> 00:12:19,200
separation and and and uh combination uh

320
00:12:17,279 --> 00:12:20,880
and then being able to control

321
00:12:19,200 --> 00:12:23,040
processes.

322
00:12:20,880 --> 00:12:24,639
So these are just sort of a laundry list

323
00:12:23,040 --> 00:12:26,320
of things that are you you're seeing in

324
00:12:24,639 --> 00:12:27,920
the academic and industry literature,

325
00:12:26,320 --> 00:12:30,240
but now we need to figure out how to

326
00:12:27,920 --> 00:12:32,079
bring these things to bear. So the key

327
00:12:30,240 --> 00:12:36,320
ideas that I want to make sure that you

328
00:12:32,079 --> 00:12:37,760
have is in in the mining space in the

329
00:12:36,320 --> 00:12:40,240
manufacturing space that I'm going to

330
00:12:37,760 --> 00:12:42,880
draw some analoges from you you want to

331
00:12:40,240 --> 00:12:44,399
take a a bilingual or a two axis

332
00:12:42,880 --> 00:12:47,440
approach right we're able to be

333
00:12:44,399 --> 00:12:49,920
successful because we have new AI tools

334
00:12:47,440 --> 00:12:52,240
better sensors but we can only be

335
00:12:49,920 --> 00:12:55,279
successful if we bring our domain

336
00:12:52,240 --> 00:12:56,560
knowledge to bear the physics the types

337
00:12:55,279 --> 00:12:58,959
of questions that we should ask and

338
00:12:56,560 --> 00:13:00,639
answer in the mining industry as domain

339
00:12:58,959 --> 00:13:02,880
experts, you know, the processes and the

340
00:13:00,639 --> 00:13:04,959
machines, what are the questions to ask,

341
00:13:02,880 --> 00:13:06,880
what the what information would you like

342
00:13:04,959 --> 00:13:08,800
to get out of your data and and data

343
00:13:06,880 --> 00:13:10,480
science experts can help us understand

344
00:13:08,800 --> 00:13:12,000
the the types of algorithms and how to

345
00:13:10,480 --> 00:13:13,760
use these tools and actually you don't

346
00:13:12,000 --> 00:13:15,760
need to be a data scientist anymore to

347
00:13:13,760 --> 00:13:17,920
do basic level of of coding as I tried

348
00:13:15,760 --> 00:13:20,959
to highlight at the beginning.

349
00:13:17,920 --> 00:13:24,639
So what I want to do now um in the next

350
00:13:20,959 --> 00:13:25,920
say 15 minutes is show you now some

351
00:13:24,639 --> 00:13:27,839
personal examples things that are

352
00:13:25,920 --> 00:13:30,959
happening at MIT uh that are in the

353
00:13:27,839 --> 00:13:33,839
space of of both manufacturing

354
00:13:30,959 --> 00:13:35,920
uh and automation and operations and in

355
00:13:33,839 --> 00:13:37,680
novel sensors that are applicable both

356
00:13:35,920 --> 00:13:39,600
in manufacturing and in healthcare and

357
00:13:37,680 --> 00:13:41,680
in mining as it turns out. Um but

358
00:13:39,600 --> 00:13:44,560
putting it into sort of two two

359
00:13:41,680 --> 00:13:46,079
contexts. So twins, digital twins are

360
00:13:44,560 --> 00:13:49,040
just models and they're we can have

361
00:13:46,079 --> 00:13:50,959
twins of many sorts. We can have um

362
00:13:49,040 --> 00:13:52,720
physics based twins, data twins, and we

363
00:13:50,959 --> 00:13:55,040
can have twins of an individual process

364
00:13:52,720 --> 00:13:56,800
or a machine. And we can develop twins

365
00:13:55,040 --> 00:13:58,639
of an entire operation. So I'll tell you

366
00:13:56,800 --> 00:14:00,639
a story about a twin of a machine. And

367
00:13:58,639 --> 00:14:03,680
then I'll tell you about tools of how

368
00:14:00,639 --> 00:14:06,639
you twin and model a complete operation,

369
00:14:03,680 --> 00:14:08,880
whether it be a factory or a mine, for

370
00:14:06,639 --> 00:14:10,639
example. And then don't forget that all

371
00:14:08,880 --> 00:14:12,560
of our data come from sensors. And so

372
00:14:10,639 --> 00:14:16,079
I'll tell you both about a a physical

373
00:14:12,560 --> 00:14:18,000
sensor um that is built on a new

374
00:14:16,079 --> 00:14:19,760
technology called integrated photonics.

375
00:14:18,000 --> 00:14:22,240
It's the miniaturization same way that

376
00:14:19,760 --> 00:14:25,600
we make micro electronics. We can now

377
00:14:22,240 --> 00:14:27,600
that miniaturaturize optical systems and

378
00:14:25,600 --> 00:14:29,440
make optical systems on in the form

379
00:14:27,600 --> 00:14:31,920
factor that fit onto sort of phone like

380
00:14:29,440 --> 00:14:35,440
devices um that allow us for example to

381
00:14:31,920 --> 00:14:36,959
do non-cont measurements in the field.

382
00:14:35,440 --> 00:14:38,560
And then talking a little bit about how

383
00:14:36,959 --> 00:14:40,560
machine learning tools can help us

384
00:14:38,560 --> 00:14:43,279
improve our our soft sensors, our

385
00:14:40,560 --> 00:14:45,839
virtual sensors and and being able to

386
00:14:43,279 --> 00:14:48,160
for example accelerate how we solve

387
00:14:45,839 --> 00:14:51,519
inverse problems and meaning how do we

388
00:14:48,160 --> 00:14:53,680
take our seismic data and and rapidly

389
00:14:51,519 --> 00:14:56,160
estimate well what is the domain what is

390
00:14:53,680 --> 00:14:58,480
the geography what is the landscape

391
00:14:56,160 --> 00:15:01,360
below the land that explains those

392
00:14:58,480 --> 00:15:03,920
seismic observations that we had. Okay.

393
00:15:01,360 --> 00:15:08,399
So first um first deep dive you know

394
00:15:03,920 --> 00:15:10,560
here is a an example just to motivate it

395
00:15:08,399 --> 00:15:13,600
um that we've done with a manufacturing

396
00:15:10,560 --> 00:15:15,600
company and they they have this this um

397
00:15:13,600 --> 00:15:18,560
machine and you know think of this

398
00:15:15,600 --> 00:15:20,880
machine as as as a as a vehicle as a

399
00:15:18,560 --> 00:15:23,279
mill as a in this case a packaging

400
00:15:20,880 --> 00:15:24,959
machine and we collect data from this

401
00:15:23,279 --> 00:15:27,760
machine. In this case, what this machine

402
00:15:24,959 --> 00:15:29,440
does is wraps packages. And there's a

403
00:15:27,760 --> 00:15:31,120
mech there's mechanical wear on this

404
00:15:29,440 --> 00:15:33,680
machine. And that mechanical wear is

405
00:15:31,120 --> 00:15:36,560
associated with the bearings. It's also

406
00:15:33,680 --> 00:15:38,639
associated with the the blade that's

407
00:15:36,560 --> 00:15:41,040
used to cut the plastic wrap that wraps

408
00:15:38,639 --> 00:15:43,279
around this package. And so the question

409
00:15:41,040 --> 00:15:44,800
is, well, how can we use the data? Take

410
00:15:43,279 --> 00:15:47,920
the data that we're already collecting

411
00:15:44,800 --> 00:15:49,600
for free in some sense and and monitor

412
00:15:47,920 --> 00:15:51,120
the health of the machine. This

413
00:15:49,600 --> 00:15:53,680
machine's doing a task. It's wrapping

414
00:15:51,120 --> 00:15:56,000
packages. But can we also extract

415
00:15:53,680 --> 00:15:59,360
additional information about from these

416
00:15:56,000 --> 00:16:01,519
data from these data? This is the data

417
00:15:59,360 --> 00:16:03,600
associated with one package coming

418
00:16:01,519 --> 00:16:06,560
through this machine. It's torque versus

419
00:16:03,600 --> 00:16:08,079
time. It's position of the blade that's

420
00:16:06,560 --> 00:16:10,720
cutting the plastic wrap. It's the

421
00:16:08,079 --> 00:16:14,000
velocity of the package. It's all the

422
00:16:10,720 --> 00:16:15,759
time series control system data that's

423
00:16:14,000 --> 00:16:17,519
dealing with one package as it passes

424
00:16:15,759 --> 00:16:20,720
through this machine. And the question

425
00:16:17,519 --> 00:16:22,399
is well can we can we extract not just

426
00:16:20,720 --> 00:16:24,000
well we're doing our job packaging but

427
00:16:22,399 --> 00:16:27,279
can we say something about well are the

428
00:16:24,000 --> 00:16:28,639
bearings wearing is the blade wearing so

429
00:16:27,279 --> 00:16:31,279
that was the question and the answer is

430
00:16:28,639 --> 00:16:32,720
indeed yes and the tool that we're going

431
00:16:31,279 --> 00:16:34,079
to use is this thing called a decision

432
00:16:32,720 --> 00:16:35,680
tree this thing that I sort of

433
00:16:34,079 --> 00:16:39,440
introduced at the very beginning with

434
00:16:35,680 --> 00:16:43,199
what GPT uh coded for me or Gemini coded

435
00:16:39,440 --> 00:16:45,120
for me um but we have this this this

436
00:16:43,199 --> 00:16:49,040
historical data for every package and

437
00:16:45,120 --> 00:16:50,560
then we also um have as our labeling,

438
00:16:49,040 --> 00:16:52,079
right? In in machine learning, we need

439
00:16:50,560 --> 00:16:54,399
to have historical data that has both an

440
00:16:52,079 --> 00:16:55,680
input output relationship where in the

441
00:16:54,399 --> 00:16:57,199
future we have an input, we're trying to

442
00:16:55,680 --> 00:16:59,040
predict the output. Here we're trying to

443
00:16:57,199 --> 00:17:00,720
predict the health of the machine. In

444
00:16:59,040 --> 00:17:02,399
this case, the health of the machine,

445
00:17:00,720 --> 00:17:05,280
we're going to use as a surrogate for

446
00:17:02,399 --> 00:17:07,600
health, the age of the machine since it

447
00:17:05,280 --> 00:17:09,360
was last maintained. So, the time since

448
00:17:07,600 --> 00:17:12,400
the last maintenance when we lubricated

449
00:17:09,360 --> 00:17:14,400
it, sharpened the blade, etc.

450
00:17:12,400 --> 00:17:17,280
I'm going to spare the details because

451
00:17:14,400 --> 00:17:20,079
that's not important for today. But the

452
00:17:17,280 --> 00:17:21,360
this decision trees and their sort of

453
00:17:20,079 --> 00:17:23,199
their collection of trees which is

454
00:17:21,360 --> 00:17:25,280
called a random forest is really just a

455
00:17:23,199 --> 00:17:28,160
series of questions that we ask on our

456
00:17:25,280 --> 00:17:30,160
data. And in this case here we're asking

457
00:17:28,160 --> 00:17:31,760
questions on the on the chat GPT example

458
00:17:30,160 --> 00:17:33,600
we were asking questions about seismic

459
00:17:31,760 --> 00:17:35,520
energy to detect whether or not there

460
00:17:33,600 --> 00:17:38,080
was going to be a seismic activity

461
00:17:35,520 --> 00:17:40,400
tomorrow. Here we're taking all this

462
00:17:38,080 --> 00:17:42,559
sensory data, the speeds, the positions,

463
00:17:40,400 --> 00:17:45,600
the torqus of this machine, and we

464
00:17:42,559 --> 00:17:47,440
predict the health, the age of the

465
00:17:45,600 --> 00:17:49,360
blade. Yeah. And we can have different

466
00:17:47,440 --> 00:17:51,840
different labeling in our historic data.

467
00:17:49,360 --> 00:17:54,000
We chose in this case to use the as a

468
00:17:51,840 --> 00:17:56,320
surrogate for where the age the time

469
00:17:54,000 --> 00:17:59,679
since it was last maintained. But we we

470
00:17:56,320 --> 00:18:01,840
have now a very easy tool that is taking

471
00:17:59,679 --> 00:18:03,520
as inputs this these data we're

472
00:18:01,840 --> 00:18:05,039
collecting for free and predicts well

473
00:18:03,520 --> 00:18:06,400
how healthy is the machine so that we

474
00:18:05,039 --> 00:18:09,120
can do condition monitoring and

475
00:18:06,400 --> 00:18:11,520
prediction well what we need to do is

476
00:18:09,120 --> 00:18:14,480
well how well does this model work and

477
00:18:11,520 --> 00:18:16,559
here what I'm plotting is comparing now

478
00:18:14,480 --> 00:18:18,960
we we use some of our historical data to

479
00:18:16,559 --> 00:18:20,320
train and then we're going to use some

480
00:18:18,960 --> 00:18:22,160
of our historical data to ask the

481
00:18:20,320 --> 00:18:24,559
question how well did the the training

482
00:18:22,160 --> 00:18:26,160
work how well is the model behaving what

483
00:18:24,559 --> 00:18:28,320
you would want in In a perfect model

484
00:18:26,160 --> 00:18:30,240
that would trained well on historic data

485
00:18:28,320 --> 00:18:32,160
that we use to do the training and

486
00:18:30,240 --> 00:18:35,280
generalizes well to our validation data,

487
00:18:32,160 --> 00:18:39,039
you would expect you want zero error

488
00:18:35,280 --> 00:18:42,160
between what the model predicts and what

489
00:18:39,039 --> 00:18:44,000
the truth is. So we split our data use

490
00:18:42,160 --> 00:18:45,600
some of it to train and here on the

491
00:18:44,000 --> 00:18:48,640
validation data we want to be able to

492
00:18:45,600 --> 00:18:51,039
predict what is the reality. And so what

493
00:18:48,640 --> 00:18:54,400
we would want on this plot is a bunch of

494
00:18:51,039 --> 00:18:56,799
zeros. we would want the error between

495
00:18:54,400 --> 00:18:58,640
the predicted age and the actual age to

496
00:18:56,799 --> 00:19:01,280
be zero. But we see here there's it's

497
00:18:58,640 --> 00:19:02,799
not we have a lot of zeros, but for each

498
00:19:01,280 --> 00:19:04,480
package that goes through sometimes

499
00:19:02,799 --> 00:19:06,000
we're we're 10 months off in the

500
00:19:04,480 --> 00:19:07,360
apparent age, the apparent wear, and

501
00:19:06,000 --> 00:19:09,840
we're eight months off in the other

502
00:19:07,360 --> 00:19:12,080
direction. But what do you do with a

503
00:19:09,840 --> 00:19:14,559
noisy sensor? Right? So I I I show this

504
00:19:12,080 --> 00:19:16,080
because I want to emphasize here is a

505
00:19:14,559 --> 00:19:17,679
great example where if you were just a

506
00:19:16,080 --> 00:19:19,360
machine learning expert, say I look at

507
00:19:17,679 --> 00:19:21,440
this and this is not a great model.

508
00:19:19,360 --> 00:19:23,360
Maybe I need to use a a neural net or

509
00:19:21,440 --> 00:19:26,320
support vector machine. But here I've

510
00:19:23,360 --> 00:19:28,720
I've made a a a decision tree which is a

511
00:19:26,320 --> 00:19:31,200
noisy sensor that takes as input the

512
00:19:28,720 --> 00:19:33,039
data I have and predicts a noisy output.

513
00:19:31,200 --> 00:19:34,799
And what do I do with noisy sensors? I

514
00:19:33,039 --> 00:19:36,320
filter them. I apply moving average. I

515
00:19:34,799 --> 00:19:38,799
use the things that I classically know

516
00:19:36,320 --> 00:19:41,120
how to do in analyzing data. And then

517
00:19:38,799 --> 00:19:43,840
doing that using that physical context

518
00:19:41,120 --> 00:19:45,919
now I can actually use this in a way

519
00:19:43,840 --> 00:19:48,160
that makes sense.

520
00:19:45,919 --> 00:19:51,440
So I guess my message there is sort of

521
00:19:48,160 --> 00:19:53,440
even bad models or sort of bad from a m

522
00:19:51,440 --> 00:19:56,160
purely machine learning perspective uh

523
00:19:53,440 --> 00:19:58,799
when used correctly uh can be very very

524
00:19:56,160 --> 00:20:00,960
very good. Okay, so that's what example

525
00:19:58,799 --> 00:20:03,840
one. So how do we use data in monitoring

526
00:20:00,960 --> 00:20:06,320
the health of the machine? So now this

527
00:20:03,840 --> 00:20:08,720
this next sort of example is um I know

528
00:20:06,320 --> 00:20:11,120
I'm sure some of you are using um what

529
00:20:08,720 --> 00:20:14,000
is called discrete event or discrete

530
00:20:11,120 --> 00:20:16,160
time simulation in the simulation of

531
00:20:14,000 --> 00:20:18,480
operations. But in my experience, I've

532
00:20:16,160 --> 00:20:20,480
found that many organizations both in

533
00:20:18,480 --> 00:20:23,919
the manufacturing domain and in the

534
00:20:20,480 --> 00:20:26,400
mining domain are not. So how do you

535
00:20:23,919 --> 00:20:28,240
model operations at at an appropriate

536
00:20:26,400 --> 00:20:30,559
level? I can drill down into individual

537
00:20:28,240 --> 00:20:32,880
machines, but how do I how do I model,

538
00:20:30,559 --> 00:20:36,480
for example, this factory or how do I

539
00:20:32,880 --> 00:20:39,200
model the flow of machines when machines

540
00:20:36,480 --> 00:20:40,559
can sometimes break down and sometimes

541
00:20:39,200 --> 00:20:42,320
they can be they take some time when

542
00:20:40,559 --> 00:20:45,520
they're broken down to be maintained and

543
00:20:42,320 --> 00:20:48,960
be repaired. At some aggregate level, we

544
00:20:45,520 --> 00:20:51,600
can think of every piece of equipment as

545
00:20:48,960 --> 00:20:53,280
being modeled as um how often when it's

546
00:20:51,600 --> 00:20:55,360
up, how long is it up? And when it's

547
00:20:53,280 --> 00:20:56,880
down, how long is it down? So to first

548
00:20:55,360 --> 00:20:58,880
order, I can look at my maintenance

549
00:20:56,880 --> 00:21:00,559
logs, understand the meanantime to

550
00:20:58,880 --> 00:21:04,320
repair, the meantime to fail, and

551
00:21:00,559 --> 00:21:07,440
mathematically I can think of a a a

552
00:21:04,320 --> 00:21:10,000
piece of equipment or a road as having

553
00:21:07,440 --> 00:21:12,000
as being in one of several states. It

554
00:21:10,000 --> 00:21:14,799
can be in an upstate or a down state. At

555
00:21:12,000 --> 00:21:16,640
any instance in time is informed by

556
00:21:14,799 --> 00:21:17,919
historical data of how often when

557
00:21:16,640 --> 00:21:19,520
something's operational, it stays

558
00:21:17,919 --> 00:21:22,480
operational or when it's down, how long

559
00:21:19,520 --> 00:21:25,520
it stays down. I can think of a machine

560
00:21:22,480 --> 00:21:28,159
as being up or down, healthy or good.

561
00:21:25,520 --> 00:21:30,000
And at any next interval in time

562
00:21:28,159 --> 00:21:32,400
tomorrow, if it's up, what's the

563
00:21:30,000 --> 00:21:34,240
likelihood of it still staying up, of it

564
00:21:32,400 --> 00:21:36,720
staying in a good state, or what's the

565
00:21:34,240 --> 00:21:38,960
likelihood of it transitioning? So, the

566
00:21:36,720 --> 00:21:41,280
data we collect, the the big data that

567
00:21:38,960 --> 00:21:43,679
we want to collect to model operations

568
00:21:41,280 --> 00:21:45,280
are are um things like this, the

569
00:21:43,679 --> 00:21:48,240
maintenance logs, how long is something

570
00:21:45,280 --> 00:21:51,039
up and down? Now, how do I then use that

571
00:21:48,240 --> 00:21:53,679
observational data to then create a

572
00:21:51,039 --> 00:21:56,240
model to create a twin that allows me to

573
00:21:53,679 --> 00:21:57,919
predict the future or to decide for

574
00:21:56,240 --> 00:22:00,640
example

575
00:21:57,919 --> 00:22:03,440
what would be the benefit of doubling my

576
00:22:00,640 --> 00:22:05,520
maintenance staff so that my the the

577
00:22:03,440 --> 00:22:08,480
likelihood the rate with which I came

578
00:22:05,520 --> 00:22:10,960
back from a a sick state a down state to

579
00:22:08,480 --> 00:22:14,480
a a healthy state was twice as fast. So,

580
00:22:10,960 --> 00:22:16,720
how do I play some what if scenarios in

581
00:22:14,480 --> 00:22:19,679
investing in different machinery or or

582
00:22:16,720 --> 00:22:22,000
or hiring more people? So, the modeling

583
00:22:19,679 --> 00:22:25,120
tool is nothing more than to

584
00:22:22,000 --> 00:22:27,600
oversimplify flipping a biased coin. So,

585
00:22:25,120 --> 00:22:29,840
I can use a biased coin if I if I know

586
00:22:27,600 --> 00:22:32,400
my machine is going to be up 90% of the

587
00:22:29,840 --> 00:22:33,760
time. Well, I can, you know,

588
00:22:32,400 --> 00:22:35,360
algorithmically, you know, here's

589
00:22:33,760 --> 00:22:38,080
graphically, but algorithmically, I can

590
00:22:35,360 --> 00:22:41,039
I can generate a random number that is

591
00:22:38,080 --> 00:22:44,320
not that's 90% that's that's heads 90%

592
00:22:41,039 --> 00:22:47,520
of the time. And so I can model all the

593
00:22:44,320 --> 00:22:50,720
all the equipment that has different

594
00:22:47,520 --> 00:22:52,400
healthy states. I can model capture the

595
00:22:50,720 --> 00:22:54,320
historical data when things are up, when

596
00:22:52,400 --> 00:22:56,480
things are down, and I can model that up

597
00:22:54,320 --> 00:22:59,120
down time by just flipping a bunch of

598
00:22:56,480 --> 00:23:00,960
random coins. Now, that is a notion.

599
00:22:59,120 --> 00:23:04,480
It's oversimplified, but that as a

600
00:23:00,960 --> 00:23:06,799
notion is what tools such as any logic

601
00:23:04,480 --> 00:23:09,919
or plant sim

602
00:23:06,799 --> 00:23:12,320
um use to monitor many types of domains.

603
00:23:09,919 --> 00:23:14,720
Here I I'll show you some results from a

604
00:23:12,320 --> 00:23:18,799
tool called any logic. And what any

605
00:23:14,720 --> 00:23:21,679
logic does is is allow you to simulate

606
00:23:18,799 --> 00:23:23,039
operations at the level of machines are

607
00:23:21,679 --> 00:23:24,960
up, machines are down, roads are

608
00:23:23,039 --> 00:23:27,600
blocked, roads are down. And it has

609
00:23:24,960 --> 00:23:30,960
under the hood basically this simple

610
00:23:27,600 --> 00:23:34,720
logic where I assign probabilities of

611
00:23:30,960 --> 00:23:37,440
things being up or down and and then

612
00:23:34,720 --> 00:23:39,280
letting my let my virtual world operate.

613
00:23:37,440 --> 00:23:42,320
Now the reason you will pay some dollars

614
00:23:39,280 --> 00:23:44,880
for a tool like this um if for this

615
00:23:42,320 --> 00:23:49,120
video play uh this is the the 3D

616
00:23:44,880 --> 00:23:50,880
rendering of a copper ore mine um where

617
00:23:49,120 --> 00:23:52,559
we have some trucks going around and

618
00:23:50,880 --> 00:23:54,720
they're they're sort of you know doing

619
00:23:52,559 --> 00:23:56,799
both inspection and sort of routing out

620
00:23:54,720 --> 00:23:59,919
and we have different camera views. So

621
00:23:56,799 --> 00:24:02,559
this gives you a nice graphical way to

622
00:23:59,919 --> 00:24:04,960
see sort of physically to map have a

623
00:24:02,559 --> 00:24:07,600
mental image of what's going on. But the

624
00:24:04,960 --> 00:24:09,760
reality is well under the hood it's

625
00:24:07,600 --> 00:24:12,000
actually I can look at it from 2D and

626
00:24:09,760 --> 00:24:14,320
understand what how in my simulation how

627
00:24:12,000 --> 00:24:16,320
things are moving around but then I can

628
00:24:14,320 --> 00:24:18,880
actually you see how resources are being

629
00:24:16,320 --> 00:24:21,039
used and I can play some scenarios well

630
00:24:18,880 --> 00:24:23,279
how do how do operations improve if I

631
00:24:21,039 --> 00:24:25,919
change the number of trucks or if I I

632
00:24:23,279 --> 00:24:28,640
change the number of resources available

633
00:24:25,919 --> 00:24:31,120
and so this gives me now a tool to then

634
00:24:28,640 --> 00:24:34,799
play what if like how does my throughput

635
00:24:31,120 --> 00:24:38,880
how does my utilization change um and to

636
00:24:34,799 --> 00:24:41,760
then be able to use this to take simple

637
00:24:38,880 --> 00:24:45,200
data of general availability of

638
00:24:41,760 --> 00:24:48,400
equipment, general flow, and be able to

639
00:24:45,200 --> 00:24:50,400
then ask what if questions. Um, and

640
00:24:48,400 --> 00:24:52,720
ultimately under the hood, what we're

641
00:24:50,400 --> 00:24:55,200
really doing is flipping some bias coins

642
00:24:52,720 --> 00:24:58,559
that allow us to simulate material flow,

643
00:24:55,200 --> 00:25:00,799
people flow through a complex operation.

644
00:24:58,559 --> 00:25:02,480
Now, I'm I'm dramatically simplifying

645
00:25:00,799 --> 00:25:04,080
and going very fast on that, but I I

646
00:25:02,480 --> 00:25:07,039
highlight it because as a tool, in my

647
00:25:04,080 --> 00:25:09,279
experience, it's an underutilized way to

648
00:25:07,039 --> 00:25:13,039
be able to represent physical operations

649
00:25:09,279 --> 00:25:14,480
both in in manufacturing and in mining.

650
00:25:13,039 --> 00:25:15,600
Okay. So, I think um we're getting a

651
00:25:14,480 --> 00:25:18,000
little bit close to time here, but let

652
00:25:15,600 --> 00:25:21,039
me let me show you um sort of two quick

653
00:25:18,000 --> 00:25:25,200
examples just to inspire you in the the

654
00:25:21,039 --> 00:25:27,679
art of what's possible. So um

655
00:25:25,200 --> 00:25:30,320
there is a um what's called the photo

656
00:25:27,679 --> 00:25:32,640
acoustic effect. If I take a laser beam

657
00:25:30,320 --> 00:25:34,400
and I shine it a pulse laser beam and I

658
00:25:32,640 --> 00:25:38,000
shine it on material whether that be

659
00:25:34,400 --> 00:25:40,320
rock, dirt, steel, aluminum or tissue at

660
00:25:38,000 --> 00:25:43,279
the right wavelength for that material.

661
00:25:40,320 --> 00:25:46,000
If I take a pulsed laser, the light will

662
00:25:43,279 --> 00:25:48,400
be absorbed by the material and it will

663
00:25:46,000 --> 00:25:49,919
slightly heat up and that heat up causes

664
00:25:48,400 --> 00:25:52,880
an expansion and that expansion

665
00:25:49,919 --> 00:25:56,320
dissipates as sound. And that sound will

666
00:25:52,880 --> 00:25:59,120
then propagate and I that sound will

667
00:25:56,320 --> 00:26:02,640
then propagate through a medium and and

668
00:25:59,120 --> 00:26:05,039
then I can also use another laser by

669
00:26:02,640 --> 00:26:08,080
want so I can use light to generate

670
00:26:05,039 --> 00:26:09,600
sound in a non-cont way. I can then use

671
00:26:08,080 --> 00:26:11,279
another laser acting as an

672
00:26:09,600 --> 00:26:13,120
interferometer

673
00:26:11,279 --> 00:26:16,159
monitoring at some point on the surface

674
00:26:13,120 --> 00:26:18,000
of the earth or of steel or of a person

675
00:26:16,159 --> 00:26:20,799
and monitor the sound wave as it goes

676
00:26:18,000 --> 00:26:23,520
by. So in this way I can use two light

677
00:26:20,799 --> 00:26:25,279
sources, two lasers, a pulse laser and a

678
00:26:23,520 --> 00:26:28,159
continuous wave laser to both generate

679
00:26:25,279 --> 00:26:30,880
sound in a medium from a distance and to

680
00:26:28,159 --> 00:26:32,640
detect and to detect sound.

681
00:26:30,880 --> 00:26:35,120
And I and I I highlight this more

682
00:26:32,640 --> 00:26:37,200
because I have a hypothesis. Um we're

683
00:26:35,120 --> 00:26:38,880
developing this technology. This is this

684
00:26:37,200 --> 00:26:42,080
image here is showing something that we

685
00:26:38,880 --> 00:26:44,880
developed 30 years ago and using fully

686
00:26:42,080 --> 00:26:47,039
non-cont measurement of silicon wafers

687
00:26:44,880 --> 00:26:51,120
undergoing rapid thermal processing.

688
00:26:47,039 --> 00:26:53,520
More recently, we've done that same type

689
00:26:51,120 --> 00:26:56,240
of phenomena on people where we can now

690
00:26:53,520 --> 00:26:59,360
at 2 meters away, shining two laser

691
00:26:56,240 --> 00:27:00,799
beams on a person, generate an

692
00:26:59,360 --> 00:27:02,880
ultrasound image of the sort that you

693
00:27:00,799 --> 00:27:05,039
would acquire at if you were putting a

694
00:27:02,880 --> 00:27:08,159
contact probe in in contact with the

695
00:27:05,039 --> 00:27:10,400
person. Um and again it's relying on

696
00:27:08,159 --> 00:27:12,880
sort of pulse lasers to generate sound

697
00:27:10,400 --> 00:27:15,039
and a continuous wave laser to detect

698
00:27:12,880 --> 00:27:17,279
the vibration of the surface scan that

699
00:27:15,039 --> 00:27:19,679
over the material surface to see

700
00:27:17,279 --> 00:27:22,080
subsurface to see in this case what a

701
00:27:19,679 --> 00:27:25,760
slice into the the human body would look

702
00:27:22,080 --> 00:27:28,400
like. Now this is the the macro scale

703
00:27:25,760 --> 00:27:30,880
optics that we used. I mentioned just

704
00:27:28,400 --> 00:27:32,400
briefly integrated photonix is a

705
00:27:30,880 --> 00:27:35,600
technology

706
00:27:32,400 --> 00:27:39,840
that is allowing us to miniaturaturize

707
00:27:35,600 --> 00:27:43,520
optical systems. So all of this sort of

708
00:27:39,840 --> 00:27:45,600
tabletop meter scale of technology now

709
00:27:43,520 --> 00:27:46,880
fits through the benefit of what is

710
00:27:45,600 --> 00:27:49,840
called integrated photonics. It's

711
00:27:46,880 --> 00:27:51,200
basically making small optical fibers on

712
00:27:49,840 --> 00:27:54,559
a substrate the same way that we can

713
00:27:51,200 --> 00:27:58,080
make small wires on a substrate. All of

714
00:27:54,559 --> 00:28:00,240
that technology is now on a chip that

715
00:27:58,080 --> 00:28:01,279
fits into a box. And my you can see my

716
00:28:00,240 --> 00:28:02,880
hand here. I know it's my hand because

717
00:28:01,279 --> 00:28:04,559
it has one of my rings on it, but is

718
00:28:02,880 --> 00:28:07,520
sort of a little bit bigger than an

719
00:28:04,559 --> 00:28:12,159
iPhone, but now this is now a system, a

720
00:28:07,520 --> 00:28:14,799
sensor that allows us to do non-cont

721
00:28:12,159 --> 00:28:17,840
ultrasound using light to generate sound

722
00:28:14,799 --> 00:28:20,399
and using light to detect sound. And I I

723
00:28:17,840 --> 00:28:21,760
I have to believe and this is more on

724
00:28:20,399 --> 00:28:23,520
the research side of things. I have a

725
00:28:21,760 --> 00:28:24,799
hypothesis but I I have to believe that

726
00:28:23,520 --> 00:28:26,799
there are some mining opportunities and

727
00:28:24,799 --> 00:28:28,240
would love to chat with folks on this.

728
00:28:26,799 --> 00:28:30,399
Now going back to sort of things that

729
00:28:28,240 --> 00:28:32,399
are are deployed already. So one one

730
00:28:30,399 --> 00:28:35,039
last case example I'll share with you.

731
00:28:32,399 --> 00:28:37,919
Um and this is more on the soft sensor

732
00:28:35,039 --> 00:28:39,200
side of the world and when you're trying

733
00:28:37,919 --> 00:28:40,640
to make sense of data and you'll hear

734
00:28:39,200 --> 00:28:42,399
more about this from the talks after

735
00:28:40,640 --> 00:28:45,520
mine um from the the different

736
00:28:42,399 --> 00:28:48,480
companies. Uh one of the problems, one

737
00:28:45,520 --> 00:28:50,960
of the common needs in in the mining

738
00:28:48,480 --> 00:28:52,640
world and seismic world is solving

739
00:28:50,960 --> 00:28:55,840
inverse problems. Meaning taking my

740
00:28:52,640 --> 00:28:57,600
observational data and figuring out well

741
00:28:55,840 --> 00:28:59,520
what was the world that explains that

742
00:28:57,600 --> 00:29:03,760
observational data. So if I had for

743
00:28:59,520 --> 00:29:05,840
example a domain on a seafloor and I I

744
00:29:03,760 --> 00:29:07,760
could I can write down physics and tell

745
00:29:05,840 --> 00:29:10,240
you if I if I generate a pulse of

746
00:29:07,760 --> 00:29:12,000
acoustic energy how that energy is going

747
00:29:10,240 --> 00:29:14,080
to propagate. That's the forward

748
00:29:12,000 --> 00:29:16,320
problem. But what I'm what I'm presented

749
00:29:14,080 --> 00:29:17,919
with the data that I collect this is the

750
00:29:16,320 --> 00:29:19,440
data that I collect and I need to solve

751
00:29:17,919 --> 00:29:22,720
the inverse problem. I need to collect

752
00:29:19,440 --> 00:29:25,120
that data say well what was the domain

753
00:29:22,720 --> 00:29:26,080
that explained that observation I'm

754
00:29:25,120 --> 00:29:27,279
trying to do imaging I'm trying to

755
00:29:26,080 --> 00:29:32,159
collect all this data and the way that

756
00:29:27,279 --> 00:29:35,360
we typically do that is by iteratively

757
00:29:32,159 --> 00:29:37,760
solving a forward problem but solving

758
00:29:35,360 --> 00:29:40,159
the inverse problem says okay I'm going

759
00:29:37,760 --> 00:29:42,320
to keep solving the forward problem

760
00:29:40,159 --> 00:29:44,640
changing the physical parameters of my

761
00:29:42,320 --> 00:29:48,720
world changing the the dimensions the

762
00:29:44,640 --> 00:29:51,360
elastic properties until I've over hours

763
00:29:48,720 --> 00:29:53,520
and hours and hours of iteration have

764
00:29:51,360 --> 00:29:55,120
figured out well what are the parameters

765
00:29:53,520 --> 00:29:56,799
what is the domain what is the layers

766
00:29:55,120 --> 00:29:58,960
what's the speed of sound in the layers

767
00:29:56,799 --> 00:30:00,559
that allows me to say hey yeah given

768
00:29:58,960 --> 00:30:02,159
those observations this is what my

769
00:30:00,559 --> 00:30:05,840
domain this is what my speed of sound

770
00:30:02,159 --> 00:30:08,159
map look like so what I want to um

771
00:30:05,840 --> 00:30:12,480
excite you about is something that we've

772
00:30:08,159 --> 00:30:15,679
done to accelerate that inverse model so

773
00:30:12,480 --> 00:30:17,520
what do we do we we take we we rely on

774
00:30:15,679 --> 00:30:19,440
the fact that physics we have really

775
00:30:17,520 --> 00:30:22,240
good physics that allow us to predict

776
00:30:19,440 --> 00:30:24,399
the forward problem. So let's instead of

777
00:30:22,240 --> 00:30:26,720
using the forward problem iteratively in

778
00:30:24,399 --> 00:30:29,279
an inverse solution, let's pre-generate

779
00:30:26,720 --> 00:30:30,960
synthetic data. Let's generate a bunch

780
00:30:29,279 --> 00:30:34,399
of domains,

781
00:30:30,960 --> 00:30:38,960
let's use the the wave equation to

782
00:30:34,399 --> 00:30:40,240
predict what our sensor input would be.

783
00:30:38,960 --> 00:30:41,360
So instead of doing this every time

784
00:30:40,240 --> 00:30:43,360
we're trying to solve an inverse

785
00:30:41,360 --> 00:30:46,799
problem, do it once. generate a massive

786
00:30:43,360 --> 00:30:51,279
quantity of inverse data and then train

787
00:30:46,799 --> 00:30:54,480
a network train a network on how to

788
00:30:51,279 --> 00:30:57,279
solve that inverse problem

789
00:30:54,480 --> 00:31:00,000
and I let's see there it goes so we

790
00:30:57,279 --> 00:31:01,440
train a network to take as as input you

791
00:31:00,000 --> 00:31:04,399
know we take our historical data our

792
00:31:01,440 --> 00:31:06,240
synthetic data pass all the time series

793
00:31:04,399 --> 00:31:08,799
data and say hey we want to learn how to

794
00:31:06,240 --> 00:31:10,960
directly map from that raw data to what

795
00:31:08,799 --> 00:31:13,360
the domain is

796
00:31:10,960 --> 00:31:15,360
and and so Here this is just uh some

797
00:31:13,360 --> 00:31:17,120
experimental results of showing all

798
00:31:15,360 --> 00:31:19,440
these different individual blocks or the

799
00:31:17,120 --> 00:31:21,840
different domains that we simulated and

800
00:31:19,440 --> 00:31:24,640
then um the reconstructed on synthetic

801
00:31:21,840 --> 00:31:27,200
data. But what we're able to do now is

802
00:31:24,640 --> 00:31:29,120
real time inversion.

803
00:31:27,200 --> 00:31:31,760
Real time where we pass the raw data and

804
00:31:29,120 --> 00:31:34,240
instead of iteratively running a physics

805
00:31:31,760 --> 00:31:36,240
informed loop at the time when we solve

806
00:31:34,240 --> 00:31:38,399
the problem, we generate our or we

807
00:31:36,240 --> 00:31:40,799
pre-generate that synthetic data and

808
00:31:38,399 --> 00:31:43,120
directly in real time can ingest the

809
00:31:40,799 --> 00:31:44,480
input and predict what is the domain,

810
00:31:43,120 --> 00:31:46,559
what's the speed of sound, what are the

811
00:31:44,480 --> 00:31:48,080
structures uh that we're seeing in that

812
00:31:46,559 --> 00:31:50,159
domain.

813
00:31:48,080 --> 00:31:52,000
Okay, so I know that was a lot. Um, what

814
00:31:50,159 --> 00:31:53,679
I really wanted to cover is is sort of

815
00:31:52,000 --> 00:31:56,000
it's critical. You know, the machine

816
00:31:53,679 --> 00:31:57,679
learning tools that are available are

817
00:31:56,000 --> 00:32:00,240
going to accelerate the way that we can

818
00:31:57,679 --> 00:32:01,760
collect and analyze data. It doesn't

819
00:32:00,240 --> 00:32:04,720
change the fact that we need sensors. We

820
00:32:01,760 --> 00:32:06,240
need our physical context when designing

821
00:32:04,720 --> 00:32:09,120
the systems that allow us to be

822
00:32:06,240 --> 00:32:11,120
impactful in this space. Um, and so with

823
00:32:09,120 --> 00:32:13,360
that, um, if we have time for questions,

824
00:32:11,120 --> 00:32:15,840
I'll I'll take one. Um, but also happy

825
00:32:13,360 --> 00:32:17,919
to follow up, uh, online.

826
00:32:15,840 --> 00:32:20,399
Yeah, we have time for a couple of quick

827
00:32:17,919 --> 00:32:24,880
uh answers to questions. One question

828
00:32:20,399 --> 00:32:26,720
from the audience is a hurdle is uh that

829
00:32:24,880 --> 00:32:29,200
the this

830
00:32:26,720 --> 00:32:31,519
keep facing is the lack of data or

831
00:32:29,200 --> 00:32:34,480
rather sparely a populated data and

832
00:32:31,519 --> 00:32:36,880
handling them especially labeled ones

833
00:32:34,480 --> 00:32:39,679
like description or type of failure

834
00:32:36,880 --> 00:32:42,000
observed in an equipment. Any particular

835
00:32:39,679 --> 00:32:43,919
helpful ways you have implemented to

836
00:32:42,000 --> 00:32:45,360
deal with this from a data science

837
00:32:43,919 --> 00:32:49,679
perspective?

838
00:32:45,360 --> 00:32:52,159
Right. So I mean if we we we need data

839
00:32:49,679 --> 00:32:55,279
um and

840
00:32:52,159 --> 00:32:57,200
but at the same time you know the being

841
00:32:55,279 --> 00:32:59,120
strategic I guess that it's not a data

842
00:32:57,200 --> 00:33:00,799
science solution. It's it's more of a a

843
00:32:59,120 --> 00:33:04,399
system solution. How do you how are you

844
00:33:00,799 --> 00:33:06,240
strategic in investing in the right

845
00:33:04,399 --> 00:33:07,760
places to get the targeted data? So

846
00:33:06,240 --> 00:33:09,760
that's where the domain knowledge comes

847
00:33:07,760 --> 00:33:12,320
in. That's sort of one part of the

848
00:33:09,760 --> 00:33:14,720
answer. And the other one is um in this

849
00:33:12,320 --> 00:33:16,480
era of soft sensors, well what what are

850
00:33:14,720 --> 00:33:18,080
the what are the data that we could

851
00:33:16,480 --> 00:33:19,760
collect that are correlated with

852
00:33:18,080 --> 00:33:22,799
something that we would like to measure

853
00:33:19,760 --> 00:33:25,279
and having physics informed and data

854
00:33:22,799 --> 00:33:27,279
enhanced ways to sort of predict the the

855
00:33:25,279 --> 00:33:28,880
the the

856
00:33:27,279 --> 00:33:30,159
hidden property that's not directly

857
00:33:28,880 --> 00:33:32,399
measured but it's correlated with thing

858
00:33:30,159 --> 00:33:34,480
that we can measure. So it's it's yeah

859
00:33:32,399 --> 00:33:36,720
it's it's a to to make sense of data.

860
00:33:34,480 --> 00:33:38,000
Yes, we need the data. But I I think

861
00:33:36,720 --> 00:33:40,000
where you're going to be most successful

862
00:33:38,000 --> 00:33:41,919
though is not re relying purely on the

863
00:33:40,000 --> 00:33:43,679
data. Sort of relying on what's called

864
00:33:41,919 --> 00:33:44,960
the sort of the gray box model where we

865
00:33:43,679 --> 00:33:46,480
have some physical knowledge that

866
00:33:44,960 --> 00:33:49,039
informs what type of sensors to

867
00:33:46,480 --> 00:33:50,960
strategically deploy and then how to

868
00:33:49,039 --> 00:33:53,360
make the most extract the most

869
00:33:50,960 --> 00:33:55,279
information out of the data as informed

870
00:33:53,360 --> 00:33:57,600
by physics as opposed to relying on just

871
00:33:55,279 --> 00:33:59,200
big data uh and not bringing any

872
00:33:57,600 --> 00:34:01,120
physical context.

873
00:33:59,200 --> 00:34:04,159
And Brian, the last question. How

874
00:34:01,120 --> 00:34:07,120
photonic sensors reacts to dust and fog

875
00:34:04,159 --> 00:34:09,200
and humidity often present in mines?

876
00:34:07,120 --> 00:34:12,399
>> No. Awesome question. I mean, like any

877
00:34:09,200 --> 00:34:13,679
any um we've not put a photonic sensor

878
00:34:12,399 --> 00:34:15,919
in a mine yet. So, just in full

879
00:34:13,679 --> 00:34:17,760
disclosure, um but like any electronic

880
00:34:15,919 --> 00:34:19,119
device, yes, you have to deal with the

881
00:34:17,760 --> 00:34:21,119
environmental issues. So, here the

882
00:34:19,119 --> 00:34:22,879
device that we're I showed you briefly,

883
00:34:21,119 --> 00:34:24,399
uh we're putting that into some clinical

884
00:34:22,879 --> 00:34:26,800
medical environments that are that are

885
00:34:24,399 --> 00:34:30,560
moist and and and need to be cleaned and

886
00:34:26,800 --> 00:34:32,159
sanitized. Um, but the any electronic

887
00:34:30,560 --> 00:34:33,919
device or optical device is going to

888
00:34:32,159 --> 00:34:37,119
have sort of ranges of both temperature

889
00:34:33,919 --> 00:34:38,800
and humidity and to make the r a rugged

890
00:34:37,119 --> 00:34:40,800
device. Yes, there's still work to be

891
00:34:38,800 --> 00:34:44,240
done on on that. Um, and we've not done

892
00:34:40,800 --> 00:34:46,720
that. Um, but I I would be very again,

893
00:34:44,240 --> 00:34:48,159
this is more of the I'm I'm being a

894
00:34:46,720 --> 00:34:49,919
little bit selfish here. I would love to

895
00:34:48,159 --> 00:34:51,679
talk with people that can tell me more

896
00:34:49,919 --> 00:34:53,119
about how to what might be the

897
00:34:51,679 --> 00:34:55,040
appropriate opportunities to deploy

898
00:34:53,119 --> 00:34:56,800
those types of sensors in the mining

899
00:34:55,040 --> 00:34:58,560
environment and would welcome the

900
00:34:56,800 --> 00:35:00,400
opportunity to sort of further the

901
00:34:58,560 --> 00:35:02,400
activities on our commercialization side

902
00:35:00,400 --> 00:35:04,480
that are getting those out into medical

903
00:35:02,400 --> 00:35:06,160
and manufacturing domains to understand

904
00:35:04,480 --> 00:35:09,200
well maybe we can also do this in the

905
00:35:06,160 --> 00:35:09,200
mining domain.


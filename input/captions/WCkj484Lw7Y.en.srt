1
00:00:00,000 --> 00:00:05,630

2
00:00:05,630 --> 00:00:07,280
Hello, everyone.

3
00:00:07,280 --> 00:00:09,530
My name is Asu Ozdaglar.

4
00:00:09,530 --> 00:00:12,300
I'm the head of
electrical engineering,

5
00:00:12,300 --> 00:00:14,210
computer science
department, also

6
00:00:14,210 --> 00:00:17,010
the Deputy Dean of the
Schwarzman College of Computing.

7
00:00:17,010 --> 00:00:23,630
I'm delighted to introduce the
session on AI and the health

8
00:00:23,630 --> 00:00:25,370
and life sciences.

9
00:00:25,370 --> 00:00:28,790
It's a very exciting
time for this initiative

10
00:00:28,790 --> 00:00:31,520
and its intersection with AI.

11
00:00:31,520 --> 00:00:33,560
Advances in AI and
machine learning

12
00:00:33,560 --> 00:00:37,470
are transforming not just
every aspect of our lives,

13
00:00:37,470 --> 00:00:40,740
but also the fundamentals
of academic inquiry.

14
00:00:40,740 --> 00:00:43,070
And life and
medical sciences are

15
00:00:43,070 --> 00:00:44,870
very much at the
forefront of this

16
00:00:44,870 --> 00:00:48,170
with the promise of accelerated
scientific discovery

17
00:00:48,170 --> 00:00:50,970
and personalized
treatments in medicine.

18
00:00:50,970 --> 00:00:53,700
While the opportunity
is clear and present,

19
00:00:53,700 --> 00:00:56,310
realizing it is
absolutely not trivial,

20
00:00:56,310 --> 00:01:00,780
it really requires a two way
exchange between biologists,

21
00:01:00,780 --> 00:01:04,050
chemists, chemical engineers
and health care professionals

22
00:01:04,050 --> 00:01:07,230
on one hand, and those at the
forefront of AI and machine

23
00:01:07,230 --> 00:01:08,260
learning on the other.

24
00:01:08,260 --> 00:01:11,070
And this session aims to
contribute to this exchange

25
00:01:11,070 --> 00:01:14,670
by highlighting early
innovative advances from MIT

26
00:01:14,670 --> 00:01:17,490
and how we can make this
aspiration a reality.

27
00:01:17,490 --> 00:01:21,280
I'm delighted to introduce
our four amazing speakers.

28
00:01:21,280 --> 00:01:25,450
First is Joey Davis, Associate
Professor of Biology.

29
00:01:25,450 --> 00:01:29,040
Joy will focus on
structural dynamics

30
00:01:29,040 --> 00:01:31,770
of multiple molecular
machines that

31
00:01:31,770 --> 00:01:34,840
are essential for performing
critical cellular functions,

32
00:01:34,840 --> 00:01:37,480
including synthesis and
degradation of proteins.

33
00:01:37,480 --> 00:01:40,020
He will present his
recent groundbreaking work

34
00:01:40,020 --> 00:01:43,140
that develops a novel
computational method called

35
00:01:43,140 --> 00:01:48,000
cryo DRGN and leveraging
deep learning to analyze data

36
00:01:48,000 --> 00:01:52,170
from cryogenic electronic
microscopy, which enables

37
00:01:52,170 --> 00:01:55,000
to image millions of
single molecules rapidly,

38
00:01:55,000 --> 00:01:57,270
but also extending this
method to determine

39
00:01:57,270 --> 00:02:01,250
dynamic structures of protein
complexes directly in cells.

40
00:02:01,250 --> 00:02:05,840
The second speaker is Caroline
Uhler, Andrew and Erna Viterbi,

41
00:02:05,840 --> 00:02:08,090
professor of Engineering
in the Department

42
00:02:08,090 --> 00:02:10,650
of Electrical Engineering
and Computer Science,

43
00:02:10,650 --> 00:02:13,400
also core member of
Institute for Data Systems

44
00:02:13,400 --> 00:02:17,120
and Society and Broad Institute,
and the director of Eric

45
00:02:17,120 --> 00:02:18,420
and Wendy Schmidt Center.

46
00:02:18,420 --> 00:02:22,100
Caroline will highlight
the big opportunity

47
00:02:22,100 --> 00:02:26,390
coming from rapidly growing data
sets in biomedical sciences.

48
00:02:26,390 --> 00:02:28,910
Of course, there's great
promise in understanding

49
00:02:28,910 --> 00:02:32,540
programs of life, but also a
phenomenal opportunity for AI

50
00:02:32,540 --> 00:02:36,140
and ML in creating
inspirations and problems

51
00:02:36,140 --> 00:02:38,210
for the foundational techniques.

52
00:02:38,210 --> 00:02:41,630
Of course, I think the
interesting part about her work

53
00:02:41,630 --> 00:02:44,870
is that she's going to
highlight that, AI applied

54
00:02:44,870 --> 00:02:48,650
to biomedical data
will require focusing

55
00:02:48,650 --> 00:02:52,370
on causal mechanisms rather
than simply correlations

56
00:02:52,370 --> 00:02:57,470
and forecasts, where-- which is
the focus of machine learning

57
00:02:57,470 --> 00:02:59,520
in several other domains.

58
00:02:59,520 --> 00:03:02,060
And she will actually talk
about the roadmap that

59
00:03:02,060 --> 00:03:04,310
combines causal inference
and machine learning

60
00:03:04,310 --> 00:03:07,320
to understand various key
questions in cell biology.

61
00:03:07,320 --> 00:03:10,310
Our third speaker
is Marzyeh Ghassemi,

62
00:03:10,310 --> 00:03:15,500
Germeshausen Development
Professor in MIT Electrical

63
00:03:15,500 --> 00:03:17,400
Engineering and Computer
Science Department,

64
00:03:17,400 --> 00:03:20,600
as well as Institute for
Medical Engineering and Science.

65
00:03:20,600 --> 00:03:25,350
Marzyeh focuses on decision
making in health care.

66
00:03:25,350 --> 00:03:28,640
And she's going to highlight
the importance of evaluating

67
00:03:28,640 --> 00:03:32,180
not only model
performance, but also

68
00:03:32,180 --> 00:03:34,800
the heterogeneous
performance of these models,

69
00:03:34,800 --> 00:03:38,030
including biases when
a model is applied

70
00:03:38,030 --> 00:03:39,980
to specific demographic groups.

71
00:03:39,980 --> 00:03:44,780
She will investigate whether
the AI models currently in use,

72
00:03:44,780 --> 00:03:47,370
use demographic
information as shortcuts,

73
00:03:47,370 --> 00:03:51,000
and whether biased decisions
follow from such shortcuts.

74
00:03:51,000 --> 00:03:52,830
But of course, with
a positive spin,

75
00:03:52,830 --> 00:03:55,860
she will also tell us
how to actually de-bias

76
00:03:55,860 --> 00:03:58,860
these outcomes in
a way that sort

77
00:03:58,860 --> 00:04:01,480
of calibrated to each
distinct input and query.

78
00:04:01,480 --> 00:04:04,230
And last but not least,
our fourth speaker

79
00:04:04,230 --> 00:04:08,250
is Dimitris Bertsimas, the
Boeing Leaders for Global

80
00:04:08,250 --> 00:04:10,650
Operations, Professor of
Management and Operations

81
00:04:10,650 --> 00:04:13,800
Research at Sloan School,
as well as the Vice Provost

82
00:04:13,800 --> 00:04:14,860
for Open Learning.

83
00:04:14,860 --> 00:04:16,800
Dimitris will
conclude the session

84
00:04:16,800 --> 00:04:20,529
focusing on precision medicine,
providing personalized care.

85
00:04:20,529 --> 00:04:23,430
How do we provide personalized
care to every patient?

86
00:04:23,430 --> 00:04:25,410
Of course, the key
here is to understand

87
00:04:25,410 --> 00:04:27,300
the variation of
treatment effects

88
00:04:27,300 --> 00:04:30,780
across patients, meaning how
the same treatment will affect

89
00:04:30,780 --> 00:04:32,290
different patients differently.

90
00:04:32,290 --> 00:04:36,430
Gold standard approach is to use
randomized controlled trials.

91
00:04:36,430 --> 00:04:38,290
But of course, this
is very costly.

92
00:04:38,290 --> 00:04:40,300
And we have tons of
observational data.

93
00:04:40,300 --> 00:04:44,100
So he's going to present
a terrific approach that

94
00:04:44,100 --> 00:04:47,280
enables the use of observational
data by removing unobserved

95
00:04:47,280 --> 00:04:49,720
confounding as if
they were randomized,

96
00:04:49,720 --> 00:04:53,530
thus opening really the road
to true personalized medicine.

97
00:04:53,530 --> 00:04:56,480
With that, I'm a very
delighted to invite you.

98
00:04:56,480 --> 00:04:59,378
[APPLAUSE]

99
00:04:59,378 --> 00:05:03,730

100
00:05:03,730 --> 00:05:04,250
All right.

101
00:05:04,250 --> 00:05:06,000
Thank you for that
wonderful introduction.

102
00:05:06,000 --> 00:05:10,130
So I thought I would
start with some slides.

103
00:05:10,130 --> 00:05:13,750
Oh, do I need to advance them?

104
00:05:13,750 --> 00:05:16,160
I wanted to start with a
historical perspective.

105
00:05:16,160 --> 00:05:18,895
This is a quote from renowned
physicist Richard Feynman.

106
00:05:18,895 --> 00:05:21,520
And he's sort of describing the
interesting biological problems

107
00:05:21,520 --> 00:05:22,280
of the day.

108
00:05:22,280 --> 00:05:25,408
Things like how do cells
deal with DNA mutations,

109
00:05:25,408 --> 00:05:26,950
how do they perform
translation, that

110
00:05:26,950 --> 00:05:29,030
is, how do they
synthesize proteins,

111
00:05:29,030 --> 00:05:30,770
how do things like
photosynthesis work.

112
00:05:30,770 --> 00:05:32,712
And he says, "It's
very easy to answer

113
00:05:32,712 --> 00:05:34,670
many of these fundamental
biological questions.

114
00:05:34,670 --> 00:05:36,252
You just look at the thing."

115
00:05:36,252 --> 00:05:37,460
And I really love this quote.

116
00:05:37,460 --> 00:05:40,280
It sort of captures the
promise of structural biology.

117
00:05:40,280 --> 00:05:42,050
That is, if we could
determine structures,

118
00:05:42,050 --> 00:05:43,480
we could inspect
those structures

119
00:05:43,480 --> 00:05:47,110
and use them to infer sort of
chemical mechanisms of action

120
00:05:47,110 --> 00:05:49,720
to really understand
how these machine works.

121
00:05:49,720 --> 00:05:52,130
He goes on to say, and
lament, unfortunately,

122
00:05:52,130 --> 00:05:54,770
"The present microscopes," and
here he's talking about electron

123
00:05:54,770 --> 00:05:58,790
microscopes, "they see that a
scale that is just a bit too

124
00:05:58,790 --> 00:05:59,330
crude.

125
00:05:59,330 --> 00:06:00,900
If we could make
them more powerful,

126
00:06:00,900 --> 00:06:02,877
many of these problems
would become easier."

127
00:06:02,877 --> 00:06:05,460
And so when we think about what
he was describing at the time,

128
00:06:05,460 --> 00:06:08,030
we can go and look at a
micrograph from around that era,

129
00:06:08,030 --> 00:06:09,660
this is a human cell.

130
00:06:09,660 --> 00:06:11,870
And it turns out all
these little black dots

131
00:06:11,870 --> 00:06:12,820
you see are ribosomes.

132
00:06:12,820 --> 00:06:14,570
These are the machines
that are performing

133
00:06:14,570 --> 00:06:15,487
synthesis in the cell.

134
00:06:15,487 --> 00:06:17,445
And when you look at
them, it's quite obviously

135
00:06:17,445 --> 00:06:19,930
it's very difficult to figure
out chemically how are they

136
00:06:19,930 --> 00:06:20,430
working.

137
00:06:20,430 --> 00:06:21,860
What are the atomic
contacts that allow

138
00:06:21,860 --> 00:06:23,160
them to perform translation?

139
00:06:23,160 --> 00:06:25,980
Because the microscope
was so crude.

140
00:06:25,980 --> 00:06:29,970
If we flash forward roughly 20
years, microscopes got better.

141
00:06:29,970 --> 00:06:32,720
People were able to infer sort
of low resolution structures

142
00:06:32,720 --> 00:06:34,200
of ribosomes shown here.

143
00:06:34,200 --> 00:06:35,790
They sort of look
like clay pottery.

144
00:06:35,790 --> 00:06:38,220
We got a general sense of
the shape of the molecules,

145
00:06:38,220 --> 00:06:40,940
but we really still couldn't
see the important details.

146
00:06:40,940 --> 00:06:44,060
So the subsequent 40
or so years of research

147
00:06:44,060 --> 00:06:47,100
led to huge advancements, both
in hardware and importantly,

148
00:06:47,100 --> 00:06:49,820
in software, that now allow
us to routinely determine

149
00:06:49,820 --> 00:06:53,140
structures to high resolution of
important biological molecules.

150
00:06:53,140 --> 00:06:55,377
And just sort of capstoning
Feynman's predictions,

151
00:06:55,377 --> 00:06:56,960
I've pulled a couple
of recent papers.

152
00:06:56,960 --> 00:07:00,670
Here's a complex that was solved
determining how this protein

153
00:07:00,670 --> 00:07:03,370
complex repairs DNA mutations.

154
00:07:03,370 --> 00:07:06,100
Our group and many others have
used cryo electron microscopy

155
00:07:06,100 --> 00:07:08,080
to look at the
process of translation

156
00:07:08,080 --> 00:07:11,810
and understand how these
ribosomes work in atomic detail.

157
00:07:11,810 --> 00:07:13,840
And there's a
recent study showing

158
00:07:13,840 --> 00:07:15,340
how one of the
photosystems involved

159
00:07:15,340 --> 00:07:17,200
in photosynthesis works.

160
00:07:17,200 --> 00:07:19,690
So how does this actually occur?

161
00:07:19,690 --> 00:07:21,500
When we perform cryo
electron microscopy,

162
00:07:21,500 --> 00:07:23,917
we're going to take a sample
of interest, typically highly

163
00:07:23,917 --> 00:07:26,360
purified in one state
that you're interested in.

164
00:07:26,360 --> 00:07:29,195
You'll apply that to an electron
microscope grid shown here.

165
00:07:29,195 --> 00:07:30,820
And then you're
rapidly going to freeze

166
00:07:30,820 --> 00:07:33,073
the sample in a thin
layer of vitreous ice

167
00:07:33,073 --> 00:07:34,990
that sort of freezes the
molecules in whatever

168
00:07:34,990 --> 00:07:36,175
conformation they were in.

169
00:07:36,175 --> 00:07:37,550
And then we're
going to image it.

170
00:07:37,550 --> 00:07:40,010
So this grid is about
3 millimeters across.

171
00:07:40,010 --> 00:07:43,710
An electron microscope allows
us to magnify it up to 100,000

172
00:07:43,710 --> 00:07:44,210
fold.

173
00:07:44,210 --> 00:07:46,640
Here I'll show you a
30,000 fold magnification.

174
00:07:46,640 --> 00:07:48,550
This is a copper grid.

175
00:07:48,550 --> 00:07:51,127
You can see the grid bar sort
of separate these into squares,

176
00:07:51,127 --> 00:07:53,710
and in these squares there's a
thin layer of carbon into which

177
00:07:53,710 --> 00:07:55,390
we've etched small holes.

178
00:07:55,390 --> 00:07:59,000
Suspended across these holes as
this thin layer of vitreous ice.

179
00:07:59,000 --> 00:08:00,830
And as you actually
look into the holes,

180
00:08:00,830 --> 00:08:03,170
you start to resolve,
miraculously,

181
00:08:03,170 --> 00:08:04,420
individual molecules.

182
00:08:04,420 --> 00:08:08,170
So these are single protein
molecules directly imaged.

183
00:08:08,170 --> 00:08:09,320
How do we use them?

184
00:08:09,320 --> 00:08:12,830
We're going to use very
typical machine learning tools,

185
00:08:12,830 --> 00:08:15,190
such as convolutional
neural networks to isolate

186
00:08:15,190 --> 00:08:16,760
the particles of interest.

187
00:08:16,760 --> 00:08:18,950
We can extract those
from the micrographs.

188
00:08:18,950 --> 00:08:20,590
And now we have this
sort of ensemble

189
00:08:20,590 --> 00:08:22,120
of data, which is
tens of thousands

190
00:08:22,120 --> 00:08:23,988
to millions of particle images.

191
00:08:23,988 --> 00:08:25,780
We're going to use
computational approaches

192
00:08:25,780 --> 00:08:27,860
to then align all these images.

193
00:08:27,860 --> 00:08:29,500
And once we align
them, we can average

194
00:08:29,500 --> 00:08:32,679
across them, which reduces
the sort of noise increasing

195
00:08:32,679 --> 00:08:33,892
the signal to noise ratio.

196
00:08:33,892 --> 00:08:36,100
And that allows us to now
solve these high resolution

197
00:08:36,100 --> 00:08:37,270
structures.

198
00:08:37,270 --> 00:08:39,340
Now inherent in this
notion of averaging

199
00:08:39,340 --> 00:08:41,780
is the basic assumption
that these molecules are,

200
00:08:41,780 --> 00:08:43,297
in fact homogeneous.

201
00:08:43,297 --> 00:08:45,380
That is that they're all
in the same conformation.

202
00:08:45,380 --> 00:08:47,710
They all have the
same composition.

203
00:08:47,710 --> 00:08:50,460
Anyone that has kids realizes
realize that biology is not,

204
00:08:50,460 --> 00:08:51,420
in fact, static.

205
00:08:51,420 --> 00:08:53,270
It is highly dynamic.

206
00:08:53,270 --> 00:08:55,740
And so we start to think
about, say, drug development,

207
00:08:55,740 --> 00:08:57,620
trying to understand
what types of pockets

208
00:08:57,620 --> 00:08:59,450
we might want to dock a ligand.

209
00:08:59,450 --> 00:09:00,450
We can think about kids.

210
00:09:00,450 --> 00:09:03,150
So here is a small
molecule docking problem.

211
00:09:03,150 --> 00:09:06,510
The task is to get the
ligand into the binding site.

212
00:09:06,510 --> 00:09:08,150
If you look at a
static structure,

213
00:09:08,150 --> 00:09:10,260
this looks like it
should be an easy task.

214
00:09:10,260 --> 00:09:12,420
And when you look at the
dynamic version of it,

215
00:09:12,420 --> 00:09:14,460
there are all sorts of motions.

216
00:09:14,460 --> 00:09:17,690
There are all sorts of dynamics
that complicate the problem.

217
00:09:17,690 --> 00:09:18,680
All right.

218
00:09:18,680 --> 00:09:22,635
So what we really want to do is
look at the dynamics of this.

219
00:09:22,635 --> 00:09:25,250
[APPLAUSE]

220
00:09:25,250 --> 00:09:26,900
So how are we going to do that?

221
00:09:26,900 --> 00:09:29,400
We began to think about
other ways to use this data.

222
00:09:29,400 --> 00:09:31,340
So typically you would
take your set of images

223
00:09:31,340 --> 00:09:33,210
and infer a single structure.

224
00:09:33,210 --> 00:09:35,990
We thought instead we could use
these images to learn a mapping

225
00:09:35,990 --> 00:09:36,960
function.

226
00:09:36,960 --> 00:09:39,200
So this mapping function
at its base level

227
00:09:39,200 --> 00:09:40,910
is going to take
these images and learn

228
00:09:40,910 --> 00:09:43,070
to map from some position
in Cartesian coordinates

229
00:09:43,070 --> 00:09:45,495
to some density at
that same position.

230
00:09:45,495 --> 00:09:47,370
We first showed that
one was able to do this.

231
00:09:47,370 --> 00:09:48,787
And then later,
we realized, well,

232
00:09:48,787 --> 00:09:51,000
we could modify this
function to now take

233
00:09:51,000 --> 00:09:53,020
as a second input
some condition.

234
00:09:53,020 --> 00:09:55,620
Say, where is this molecule
in a low dimensional energy

235
00:09:55,620 --> 00:09:56,640
landscape?

236
00:09:56,640 --> 00:09:58,350
How do we do this?

237
00:09:58,350 --> 00:10:00,595
So this is the work [INAUDIBLE]
that also introduced.

238
00:10:00,595 --> 00:10:02,970
This was done in collaboration
with Bonnie Berger's group

239
00:10:02,970 --> 00:10:05,860
in CSAIL, and led by my
first student, Ellen Zhang.

240
00:10:05,860 --> 00:10:07,590
We built a variational
autoencoder,

241
00:10:07,590 --> 00:10:08,688
consists of two parts.

242
00:10:08,688 --> 00:10:10,980
There's a decoder network
that does exactly what I just

243
00:10:10,980 --> 00:10:11,680
showed you.

244
00:10:11,680 --> 00:10:14,800
It's going to predict the
EM density at some position.

245
00:10:14,800 --> 00:10:17,740
The way it learns to do that is
it generates these model slices,

246
00:10:17,740 --> 00:10:19,630
compares them to
the input images.

247
00:10:19,630 --> 00:10:22,075
If they're the same, the neural
networks stay left alone.

248
00:10:22,075 --> 00:10:23,700
And if they're
different, that's a loss

249
00:10:23,700 --> 00:10:26,640
that we can backpropagate
to that decoder network.

250
00:10:26,640 --> 00:10:30,060
We couple that to
an encoder network.

251
00:10:30,060 --> 00:10:33,087
That will map these particles
into a low dimensional space,

252
00:10:33,087 --> 00:10:34,920
and you can think about
them as sorting them

253
00:10:34,920 --> 00:10:36,280
based on their structures.

254
00:10:36,280 --> 00:10:37,770
So the particles
get sorted based

255
00:10:37,770 --> 00:10:39,870
on what they're similar
to, and the decoder can

256
00:10:39,870 --> 00:10:41,880
generate structures from those.

257
00:10:41,880 --> 00:10:43,420
So how do we use this?

258
00:10:43,420 --> 00:10:45,190
Here's an exemplar
data set we analyzed.

259
00:10:45,190 --> 00:10:46,150
This is a spliceosome.

260
00:10:46,150 --> 00:10:49,190
So this is a machine involved
in splicing mRNA together.

261
00:10:49,190 --> 00:10:50,780
If you look at the
static structure,

262
00:10:50,780 --> 00:10:53,420
there's regions of it that are
highly resolved shown in blue.

263
00:10:53,420 --> 00:10:55,837
And there's other regions that
we weren't able to resolve.

264
00:10:55,837 --> 00:10:56,810
Those are shown in red.

265
00:10:56,810 --> 00:10:59,018
We hypothesize that those
are likely in motion, which

266
00:10:59,018 --> 00:11:00,470
made it hard to resolve them.

267
00:11:00,470 --> 00:11:02,420
When we pass this
through Cryo Dragon,

268
00:11:02,420 --> 00:11:04,460
we can now start to see
this molecule in motion.

269
00:11:04,460 --> 00:11:06,310
You see these
dancing motions that

270
00:11:06,310 --> 00:11:09,040
help you understand the
dynamics of the molecule.

271
00:11:09,040 --> 00:11:11,540
So with this in hand,
we began to think, well,

272
00:11:11,540 --> 00:11:14,520
if we can resolve sort of highly
purified molecules like this,

273
00:11:14,520 --> 00:11:16,270
perhaps we can push
this further and begin

274
00:11:16,270 --> 00:11:18,228
to resolve sort of
heterogeneous structures out

275
00:11:18,228 --> 00:11:19,600
of say, cell lysates.

276
00:11:19,600 --> 00:11:22,220
And we turn to translation
as a way to test this.

277
00:11:22,220 --> 00:11:23,812
It was well known
that ribosomes go

278
00:11:23,812 --> 00:11:26,020
through all sorts of
conformational and compositional

279
00:11:26,020 --> 00:11:28,160
changes as they perform
their functions.

280
00:11:28,160 --> 00:11:31,570
And about 20 years of work,
using primarily cryo-EM

281
00:11:31,570 --> 00:11:33,768
has resolved key
states within this.

282
00:11:33,768 --> 00:11:35,810
And we said, well, if
these states are important,

283
00:11:35,810 --> 00:11:37,580
they should be
populated in cells.

284
00:11:37,580 --> 00:11:39,050
And if they're
populated in cells,

285
00:11:39,050 --> 00:11:41,342
then we should be able to
just put sort of cell lysates

286
00:11:41,342 --> 00:11:44,270
directly onto grids,
image them by cryo-EM,

287
00:11:44,270 --> 00:11:46,760
sort the particles with
something like Cryo Dragon,

288
00:11:46,760 --> 00:11:49,110
to resolve each one of
these individual states.

289
00:11:49,110 --> 00:11:51,920
And so I had a series of really
wonderful students and postdocs

290
00:11:51,920 --> 00:11:53,760
that worked on the
technology to do this,

291
00:11:53,760 --> 00:11:55,710
and I'm excited to say this
actually worked quite well.

292
00:11:55,710 --> 00:11:58,100
So we can go through that
whole set of translation states

293
00:11:58,100 --> 00:11:59,250
that I just mentioned.

294
00:11:59,250 --> 00:12:01,070
We can see initiation
sort of building up

295
00:12:01,070 --> 00:12:03,600
more and more factors
joining to the particle.

296
00:12:03,600 --> 00:12:05,130
We can look at translation.

297
00:12:05,130 --> 00:12:08,010
We can see tRNAs in different
states within the ribosome.

298
00:12:08,010 --> 00:12:09,510
We can see these
ratcheting motions.

299
00:12:09,510 --> 00:12:10,670
And again the remarkable
thing about this

300
00:12:10,670 --> 00:12:12,720
is that there's no
purification upstream.

301
00:12:12,720 --> 00:12:15,030
We're just putting lysates
directly onto a grid.

302
00:12:15,030 --> 00:12:17,540
And we can fill out this
diagram and basically

303
00:12:17,540 --> 00:12:21,650
one or two weeks of work,
versus these decades of work.

304
00:12:21,650 --> 00:12:22,860
What do we really want to do?

305
00:12:22,860 --> 00:12:25,185
We want to understand how
these machines work in cells.

306
00:12:25,185 --> 00:12:26,310
So how do we go about that?

307
00:12:26,310 --> 00:12:29,210
There's a related technology
to electron microscopy called

308
00:12:29,210 --> 00:12:31,940
electron tomography that
allows us to look at structures

309
00:12:31,940 --> 00:12:33,450
directly in cells.

310
00:12:33,450 --> 00:12:35,337
And so Barrett Powell,
a student in my lab,

311
00:12:35,337 --> 00:12:36,920
applied some of the
similar approaches

312
00:12:36,920 --> 00:12:38,870
to Cryo Dragon and
particle picking

313
00:12:38,870 --> 00:12:40,940
using convolutional
neural networks to try

314
00:12:40,940 --> 00:12:42,167
to apply this to tomography.

315
00:12:42,167 --> 00:12:44,250
And so what I'm going to
show you here is a movie.

316
00:12:44,250 --> 00:12:46,965
This is a bacterial cell
imaged by tomography.

317
00:12:46,965 --> 00:12:49,590
As we slice through that cell,
you'll see the sort of membranes

318
00:12:49,590 --> 00:12:51,130
on the right side of the image.

319
00:12:51,130 --> 00:12:53,050
All these white
sort of speckles.

320
00:12:53,050 --> 00:12:54,430
Those are ribosomes.

321
00:12:54,430 --> 00:12:59,640
We can then segment all of those
out to populate the tomogram.

322
00:12:59,640 --> 00:13:01,860
We can then extract
all of these particles

323
00:13:01,860 --> 00:13:03,750
and use Tomo Dragon
to try to find those

324
00:13:03,750 --> 00:13:05,080
that are in similar states.

325
00:13:05,080 --> 00:13:06,190
And there was a
little trick here.

326
00:13:06,190 --> 00:13:07,565
We had actually
treated the cells

327
00:13:07,565 --> 00:13:09,540
with a small molecule
named chloramphenicol

328
00:13:09,540 --> 00:13:11,737
that binds to the
ribosome and inhibits it.

329
00:13:11,737 --> 00:13:13,320
And what we were
really excited to see

330
00:13:13,320 --> 00:13:15,180
is that the resolution of
the maps that came back

331
00:13:15,180 --> 00:13:17,472
were high enough for actually
to see the small molecule

332
00:13:17,472 --> 00:13:18,210
drug bound.

333
00:13:18,210 --> 00:13:20,220
Oops, jumped ahead there.

334
00:13:20,220 --> 00:13:22,020
So this is a small
molecule therapeutic

335
00:13:22,020 --> 00:13:25,098
bound to its functional target
image directly in cells.

336
00:13:25,098 --> 00:13:26,890
With that, thank you
so much for your time.

337
00:13:26,890 --> 00:13:29,360
[APPLAUSE]

338
00:13:29,360 --> 00:13:40,230

339
00:13:40,230 --> 00:13:43,930
I'm super excited to be here
and see this establishment

340
00:13:43,930 --> 00:13:45,800
of this HEALS Collaborative.

341
00:13:45,800 --> 00:13:48,820
I think it's really exciting to
see all this vibrant community

342
00:13:48,820 --> 00:13:51,160
come together here and see
all the collaborations that

343
00:13:51,160 --> 00:13:53,050
will actually come out of it.

344
00:13:53,050 --> 00:13:56,860
So I'm here to talk to you
about the unique opportunities

345
00:13:56,860 --> 00:13:59,980
that I see at building this
two way street between machine

346
00:13:59,980 --> 00:14:02,330
learning, AI, and the
biomedical sciences,

347
00:14:02,330 --> 00:14:06,190
and why I believe that the
life sciences are not only

348
00:14:06,190 --> 00:14:09,250
uniquely suited for
being one of the greatest

349
00:14:09,250 --> 00:14:12,580
beneficiaries of research
in AI, but actually also one

350
00:14:12,580 --> 00:14:14,800
of the greatest
sources of inspiration

351
00:14:14,800 --> 00:14:17,860
for foundational
developments in AI.

352
00:14:17,860 --> 00:14:21,500
So in the life sciences and
the biomedical sciences,

353
00:14:21,500 --> 00:14:24,430
we've seen a huge
data explosion where

354
00:14:24,430 --> 00:14:27,430
we're now able to
measure the same system

355
00:14:27,430 --> 00:14:29,330
in many different modalities.

356
00:14:29,330 --> 00:14:32,840
Think of single cells where
we can, in one experiment,

357
00:14:32,840 --> 00:14:34,600
measure the activity
of all genes

358
00:14:34,600 --> 00:14:38,180
at the single cell level in
a million cells at a time.

359
00:14:38,180 --> 00:14:40,450
Or all of the
imaging data where we

360
00:14:40,450 --> 00:14:44,310
can image at subcellular
resolution, cellular resolution,

361
00:14:44,310 --> 00:14:47,910
tissue scale, organ scale,
even whole body scale.

362
00:14:47,910 --> 00:14:50,210
And we have all
these biobanks where

363
00:14:50,210 --> 00:14:52,430
we have access to
health data of millions

364
00:14:52,430 --> 00:14:55,130
of individuals combined
with genetics data

365
00:14:55,130 --> 00:14:56,580
of these individuals.

366
00:14:56,580 --> 00:14:58,670
So I think the real
power here comes

367
00:14:58,670 --> 00:15:01,370
from thinking about
how to integrate

368
00:15:01,370 --> 00:15:03,860
these different views
of the same system

369
00:15:03,860 --> 00:15:06,210
into some joint space.

370
00:15:06,210 --> 00:15:08,810
And so that's really where
representation learning,

371
00:15:08,810 --> 00:15:10,790
the field of representation
learning in AI

372
00:15:10,790 --> 00:15:14,630
comes in, where you're trying
to identify information

373
00:15:14,630 --> 00:15:16,400
about all of these
different modalities

374
00:15:16,400 --> 00:15:19,490
and combine them into
one view that is most

375
00:15:19,490 --> 00:15:22,010
informative about the system.

376
00:15:22,010 --> 00:15:24,950
And so that has
unique opportunities.

377
00:15:24,950 --> 00:15:28,910
You can think of multimodal
biomarkers that better capture

378
00:15:28,910 --> 00:15:31,160
a disease, because
it can combine

379
00:15:31,160 --> 00:15:32,910
all these different views.

380
00:15:32,910 --> 00:15:34,910
Or you can think about
the opportunities

381
00:15:34,910 --> 00:15:37,940
for experimental
design to think about,

382
00:15:37,940 --> 00:15:39,870
what is information
that is actually

383
00:15:39,870 --> 00:15:43,300
captured by different
types of measurements?

384
00:15:43,300 --> 00:15:46,320
Say a cheaper measurement,
easier to obtain measurement

385
00:15:46,320 --> 00:15:50,370
like a heart ECG, or a
much harder to obtain

386
00:15:50,370 --> 00:15:53,170
and more expensive
measurement like a heart MRI.

387
00:15:53,170 --> 00:15:56,460
If you have shared information,
I could just translate from one

388
00:15:56,460 --> 00:15:57,400
to the other.

389
00:15:57,400 --> 00:16:00,000
Or what is information that
is really only contained

390
00:16:00,000 --> 00:16:02,850
in a particular measurement,
like a particular protein

391
00:16:02,850 --> 00:16:05,790
stain, where you really need to
get that measurement in order

392
00:16:05,790 --> 00:16:07,840
to get that information out?

393
00:16:07,840 --> 00:16:10,120
And maybe you can
go even further.

394
00:16:10,120 --> 00:16:12,540
In the life sciences,
generally, we

395
00:16:12,540 --> 00:16:16,080
care about getting at the
underlying mechanisms,

396
00:16:16,080 --> 00:16:19,420
moving from just
associations and biomarkers,

397
00:16:19,420 --> 00:16:23,380
actually moving on to
mechanisms and causality.

398
00:16:23,380 --> 00:16:26,740
So maybe multimodality can
actually help us there.

399
00:16:26,740 --> 00:16:29,760
And so that's the question
I want to talk to you about.

400
00:16:29,760 --> 00:16:31,325
But before-- let's
make the case.

401
00:16:31,325 --> 00:16:32,700
And I think I
probably don't even

402
00:16:32,700 --> 00:16:34,650
have to make it
here-- for why we

403
00:16:34,650 --> 00:16:37,180
need mechanisms and causality.

404
00:16:37,180 --> 00:16:42,340
So let's take a simple example
of fibrosis, where it's still

405
00:16:42,340 --> 00:16:45,830
a disease that actually has
a huge effect on mortality.

406
00:16:45,830 --> 00:16:50,180
And there is still no drug
that can revert fibrosis.

407
00:16:50,180 --> 00:16:53,080
Now, how do we think about
identifying drug targets

408
00:16:53,080 --> 00:16:54,050
in this setting?

409
00:16:54,050 --> 00:16:56,060
Well, we need to identify--

410
00:16:56,060 --> 00:17:00,020
and I should say, fibrosis
is when the tissue stiffens.

411
00:17:00,020 --> 00:17:03,220
And so what you want to
identify are genes proteins

412
00:17:03,220 --> 00:17:05,000
that are upstream.

413
00:17:05,000 --> 00:17:08,440
So causal of tissue stiffening.

414
00:17:08,440 --> 00:17:11,650
And not genes,
proteins, that are

415
00:17:11,650 --> 00:17:13,900
associated with
tissue stiffening,

416
00:17:13,900 --> 00:17:15,849
but are downstream of it.

417
00:17:15,849 --> 00:17:18,890
Because these would be
very bad drug targets.

418
00:17:18,890 --> 00:17:22,270
So it's really critical to
understand what is cause

419
00:17:22,270 --> 00:17:23,630
and what is effect.

420
00:17:23,630 --> 00:17:28,390
For example, for identifying
a drug candidate or protein

421
00:17:28,390 --> 00:17:30,310
candidates in this case.

422
00:17:30,310 --> 00:17:34,040
However, if we're thinking
about the current AI models,

423
00:17:34,040 --> 00:17:38,030
they generally fail
miserable in causal tasks.

424
00:17:38,030 --> 00:17:41,670
And so here I just want to give
you a very, very simple example.

425
00:17:41,670 --> 00:17:45,740
So we all know that good
warm weather and sunshine

426
00:17:45,740 --> 00:17:49,680
is a cause of increased
ice cream consumption.

427
00:17:49,680 --> 00:17:50,392
Right?

428
00:17:50,392 --> 00:17:54,080
But if you now go out and
you have a gloomy cold day

429
00:17:54,080 --> 00:17:57,090
and you give out a whole
lot of free ice cream,

430
00:17:57,090 --> 00:18:00,690
well, you're increasing ice
cream consumption artificially.

431
00:18:00,690 --> 00:18:02,870
That doesn't change the
weather, because weather

432
00:18:02,870 --> 00:18:04,410
is upstream of it.

433
00:18:04,410 --> 00:18:08,480
However, if you ask Dall-E so
OpenAI's model for generating

434
00:18:08,480 --> 00:18:11,640
images from text, and you
should all do this experiment,

435
00:18:11,640 --> 00:18:15,560
you ask it to draw an
image of an ice cream stand

436
00:18:15,560 --> 00:18:18,060
where they're giving
out ice cream for free.

437
00:18:18,060 --> 00:18:20,900
It always puts good
weather in the background,

438
00:18:20,900 --> 00:18:24,290
because there is a really
strong association between ice

439
00:18:24,290 --> 00:18:25,800
cream and good weather.

440
00:18:25,800 --> 00:18:30,270
And these models are trained on
learning based on associations.

441
00:18:30,270 --> 00:18:32,630
They are not trained on
trying to identify what

442
00:18:32,630 --> 00:18:34,410
are the causal relationships.

443
00:18:34,410 --> 00:18:36,170
But that's critical,
as I just showed you

444
00:18:36,170 --> 00:18:37,420
in the previous example.

445
00:18:37,420 --> 00:18:40,480
We need AI models that can
actually reason causally.

446
00:18:40,480 --> 00:18:42,330
And that's exactly
the types of questions

447
00:18:42,330 --> 00:18:44,760
that we're working on in my lab.

448
00:18:44,760 --> 00:18:46,360
So how do we?

449
00:18:46,360 --> 00:18:49,290
What does it mean to fully
understand the mechanisms

450
00:18:49,290 --> 00:18:50,735
in a biological system?

451
00:18:50,735 --> 00:18:52,110
So I guess
traditionally we would

452
00:18:52,110 --> 00:18:55,020
love to get to these pictures,
these amazing pictures here

453
00:18:55,020 --> 00:18:59,190
by Davidson, for example, of
really understanding fully

454
00:18:59,190 --> 00:19:02,950
how one gene protein turns
on another gene protein,

455
00:19:02,950 --> 00:19:06,120
maybe even knowing all the
differential equations above it,

456
00:19:06,120 --> 00:19:09,070
and really having this
full causal picture.

457
00:19:09,070 --> 00:19:13,140
Now, the framework for thinking
about these regulatory networks

458
00:19:13,140 --> 00:19:16,890
causally has been already
developed in 1920s by Sewall

459
00:19:16,890 --> 00:19:18,180
Wright.

460
00:19:18,180 --> 00:19:21,540
And so that has been like--
the field of causality has been

461
00:19:21,540 --> 00:19:26,140
a very, very vibrant field
basically since the 1920s.

462
00:19:26,140 --> 00:19:29,430
Now, in causality, actually,
until now, basically, there

463
00:19:29,430 --> 00:19:32,160
has always been one very
important assumption.

464
00:19:32,160 --> 00:19:36,310
That we know what the
nodes of the network are.

465
00:19:36,310 --> 00:19:40,870
So say we assume they are genes,
and we have data on the genes,

466
00:19:40,870 --> 00:19:42,740
like the activity of all genes.

467
00:19:42,740 --> 00:19:46,100
And we would like to infer
the regulatory relationships,

468
00:19:46,100 --> 00:19:49,360
these causal edges
between the genes.

469
00:19:49,360 --> 00:19:53,140
But I'd like to argue that in
all modern problems in the life

470
00:19:53,140 --> 00:19:55,660
sciences, we actually
don't even know what

471
00:19:55,660 --> 00:19:58,150
the nodes of the network are.

472
00:19:58,150 --> 00:20:01,790
Like let's take the example
of cholesterol, for example.

473
00:20:01,790 --> 00:20:05,710
Where for a long time we
thought that total cholesterol

474
00:20:05,710 --> 00:20:07,670
was one causal variable.

475
00:20:07,670 --> 00:20:09,740
Well, now we know
that's not the case.

476
00:20:09,740 --> 00:20:12,860
We actually have two causal
variables, LDL and HDL.

477
00:20:12,860 --> 00:20:15,050
And they have different
causal effects.

478
00:20:15,050 --> 00:20:16,700
So we don't actually know.

479
00:20:16,700 --> 00:20:19,160
We have to learn what
the causal variables are.

480
00:20:19,160 --> 00:20:23,270
Similarly in images, pixels
are not causal variables.

481
00:20:23,270 --> 00:20:25,660
We have to learn what
the causal variables are

482
00:20:25,660 --> 00:20:28,460
in any of the imaging data
sets that we're collecting.

483
00:20:28,460 --> 00:20:30,320
Is it the shape of
the cell nucleus?

484
00:20:30,320 --> 00:20:33,140
Is it a particular protein,
and where it is localized?

485
00:20:33,140 --> 00:20:36,540
Is it how much of it is
and where it is localized?

486
00:20:36,540 --> 00:20:39,860
So we have a really more
fundamental or really new

487
00:20:39,860 --> 00:20:41,780
foundational
question in AI, where

488
00:20:41,780 --> 00:20:45,270
we have to first learn what
even the causal variables are,

489
00:20:45,270 --> 00:20:47,330
and then from there go
on and actually learn

490
00:20:47,330 --> 00:20:50,450
the causal networks among them.

491
00:20:50,450 --> 00:20:54,860
So over the years, we've
taken on this problem

492
00:20:54,860 --> 00:20:57,980
and really thought
about how, or identified

493
00:20:57,980 --> 00:21:01,100
that actually having
access to multiple views

494
00:21:01,100 --> 00:21:03,620
of the same system, so
different measurements

495
00:21:03,620 --> 00:21:06,320
or different data modalities
on the same system

496
00:21:06,320 --> 00:21:10,070
can really help us understand
the underlying latent

497
00:21:10,070 --> 00:21:11,700
causal structures.

498
00:21:11,700 --> 00:21:13,290
So why is that?

499
00:21:13,290 --> 00:21:16,940
Well, so let's think about what
is hard about understanding what

500
00:21:16,940 --> 00:21:18,830
are causal relationships
is you need

501
00:21:18,830 --> 00:21:22,410
to sieve out all kinds
of spurious associations.

502
00:21:22,410 --> 00:21:24,650
So multimodality can
help you do that,

503
00:21:24,650 --> 00:21:26,300
because we're looking for--

504
00:21:26,300 --> 00:21:28,730
or a causal relationship
in the system

505
00:21:28,730 --> 00:21:31,320
as an intrinsic relationship
should be there,

506
00:21:31,320 --> 00:21:32,820
whether you're
looking at the system

507
00:21:32,820 --> 00:21:36,340
from the left, meaning
with measurement type 1,

508
00:21:36,340 --> 00:21:39,010
or from the right meaning
with measurement type 2,

509
00:21:39,010 --> 00:21:41,050
or from the top or
from the bottom.

510
00:21:41,050 --> 00:21:43,020
So in order to
really identify what

511
00:21:43,020 --> 00:21:45,700
are these causal relationships
or causal features,

512
00:21:45,700 --> 00:21:48,660
you should be looking for
what is invariant to how

513
00:21:48,660 --> 00:21:50,410
you're looking at the system.

514
00:21:50,410 --> 00:21:54,240
So trying to understand which
information or what information

515
00:21:54,240 --> 00:21:56,820
is really shared between
different modalities

516
00:21:56,820 --> 00:21:59,470
can actually help
you get at causality.

517
00:21:59,470 --> 00:22:01,410
And so that's really
exciting because we

518
00:22:01,410 --> 00:22:03,060
have all these
different measurements

519
00:22:03,060 --> 00:22:05,728
of the same biological system.

520
00:22:05,728 --> 00:22:07,770
And so we're always thinking
about, well, how can

521
00:22:07,770 --> 00:22:09,600
I identify what
is actually shared

522
00:22:09,600 --> 00:22:11,920
between these
different modalities?

523
00:22:11,920 --> 00:22:13,930
And then actually
learn from there.

524
00:22:13,930 --> 00:22:17,250
And so I just want to end with
one example that we're currently

525
00:22:17,250 --> 00:22:21,780
working on in ovarian cancer,
where we can, for example, think

526
00:22:21,780 --> 00:22:25,380
about, well, what is shared
among abundant pathology images

527
00:22:25,380 --> 00:22:28,710
that we have access to, and
newer and much more expensive

528
00:22:28,710 --> 00:22:31,480
spatial transcriptomics
data, and actually

529
00:22:31,480 --> 00:22:34,100
see that there is a lot
of shared information.

530
00:22:34,100 --> 00:22:36,610
It's actually possible to
translate between them pretty

531
00:22:36,610 --> 00:22:37,520
well.

532
00:22:37,520 --> 00:22:39,370
And you can not
only identify what

533
00:22:39,370 --> 00:22:41,600
is shared among
different modalities,

534
00:22:41,600 --> 00:22:45,610
but also what is shared
or specific to particular

535
00:22:45,610 --> 00:22:47,720
individuals or patients.

536
00:22:47,720 --> 00:22:50,020
Now, that's a really
important problem.

537
00:22:50,020 --> 00:22:52,960
Anyone here who has worked
with, say, transcriptomic data

538
00:22:52,960 --> 00:22:55,870
or basically any
patient data knows

539
00:22:55,870 --> 00:22:57,470
that if you look
at these data sets,

540
00:22:57,470 --> 00:23:00,670
you have such big batch effects
that basically every patient

541
00:23:00,670 --> 00:23:02,990
always looks its own Data Cloud.

542
00:23:02,990 --> 00:23:05,080
So it's very hard to see
what is actually shared

543
00:23:05,080 --> 00:23:07,490
and what is specific to
a particular patient.

544
00:23:07,490 --> 00:23:11,060
But if you just use these
multi-modal causal features,

545
00:23:11,060 --> 00:23:15,670
you can directly identify, in
this case, cancer niches which

546
00:23:15,670 --> 00:23:18,260
are specific to a
particular patient,

547
00:23:18,260 --> 00:23:21,040
and other cancer niches
that are actually shared

548
00:23:21,040 --> 00:23:22,730
between different individuals.

549
00:23:22,730 --> 00:23:25,240
And identifying these
cancer niches, as we know,

550
00:23:25,240 --> 00:23:28,990
is really critical for
informing therapeutic strategies

551
00:23:28,990 --> 00:23:30,350
down the road.

552
00:23:30,350 --> 00:23:34,040
So I hope I was able to give
you an example of showing why

553
00:23:34,040 --> 00:23:36,380
I think it is so important
to build this two way

554
00:23:36,380 --> 00:23:40,590
street between AI and
the life sciences.

555
00:23:40,590 --> 00:23:43,550
I think that like RA
Fisher, was motivated

556
00:23:43,550 --> 00:23:47,360
to develop modern statistics
based on applications

557
00:23:47,360 --> 00:23:50,730
to agriculture and to breeding,
I think here we have the life,

558
00:23:50,730 --> 00:23:52,760
the modern life
sciences is really

559
00:23:52,760 --> 00:23:57,170
going to be a driver for new
foundational questions in AI

560
00:23:57,170 --> 00:24:01,280
that will really inspire maybe
even deeper types of questions

561
00:24:01,280 --> 00:24:02,700
that we have seen so far.

562
00:24:02,700 --> 00:24:05,190
Certainly that's the case
in the field of causality.

563
00:24:05,190 --> 00:24:06,690
So thank you very much.

564
00:24:06,690 --> 00:24:09,684
[APPLAUSE]

565
00:24:09,684 --> 00:24:20,180

566
00:24:20,180 --> 00:24:21,860
Hi, everyone.

567
00:24:21,860 --> 00:24:23,900
I'm Marzyeh Ghassemi,
and I'm going

568
00:24:23,900 --> 00:24:29,250
to talk to you today about the
pulse of ethical AI and health.

569
00:24:29,250 --> 00:24:32,140
My lab is the Healthy
Machine Learning Lab at MIT,

570
00:24:32,140 --> 00:24:34,200
and we focus on
evaluating whether there's

571
00:24:34,200 --> 00:24:36,610
a need for machine learning
in a health care setting.

572
00:24:36,610 --> 00:24:39,730
Developing a robust private
and fair model if there is,

573
00:24:39,730 --> 00:24:41,590
and then potentially
deploying that model,

574
00:24:41,590 --> 00:24:45,450
understanding how people
might use that model for good.

575
00:24:45,450 --> 00:24:46,890
What I'd like to
start out with--

576
00:24:46,890 --> 00:24:49,450
and there will be a
quiz later, so remember.

577
00:24:49,450 --> 00:24:52,860
You're all going to--
its final season at MIT.

578
00:24:52,860 --> 00:24:55,740
What I'm going to start out with
is the first learning, which

579
00:24:55,740 --> 00:24:59,670
is at this point, maybe based on
the presentations you've already

580
00:24:59,670 --> 00:25:02,590
seen, you should know
that with some caveats,

581
00:25:02,590 --> 00:25:05,400
we can predict or
generate almost anything

582
00:25:05,400 --> 00:25:08,140
if we have the right data
and the right models.

583
00:25:08,140 --> 00:25:10,320
These are two really
fantastic examples

584
00:25:10,320 --> 00:25:12,990
of AlphaFold for
protein folding,

585
00:25:12,990 --> 00:25:16,420
and robust prediction
of breast cancer risk.

586
00:25:16,420 --> 00:25:17,910
And in both of
these cases, these

587
00:25:17,910 --> 00:25:20,290
were tasks that we
weren't very good at.

588
00:25:20,290 --> 00:25:22,420
And that machine
learning really improved,

589
00:25:22,420 --> 00:25:24,430
transformed the practice in.

590
00:25:24,430 --> 00:25:25,660
That's really exciting.

591
00:25:25,660 --> 00:25:26,650
How do we do that?

592
00:25:26,650 --> 00:25:28,480
Well, the way that
we do this now

593
00:25:28,480 --> 00:25:30,170
is by following this pipeline.

594
00:25:30,170 --> 00:25:31,910
This is pretty well established.

595
00:25:31,910 --> 00:25:35,330
We choose a problem, collect
some data, define an outcome,

596
00:25:35,330 --> 00:25:38,650
develop an algorithm, and then
potentially deploy that model.

597
00:25:38,650 --> 00:25:41,890
And if I walk you through
this for another prospective

598
00:25:41,890 --> 00:25:44,380
application, let's
say that I want to do

599
00:25:44,380 --> 00:25:46,400
X-ray triage at a hospital.

600
00:25:46,400 --> 00:25:48,560
So if you're healthy I
want to send you home.

601
00:25:48,560 --> 00:25:49,700
How would I do that?

602
00:25:49,700 --> 00:25:51,320
Well, I already
picked the problem.

603
00:25:51,320 --> 00:25:53,360
And so I would go out
and get some data.

604
00:25:53,360 --> 00:25:56,050
There's three really large,
publicly available chest X-ray

605
00:25:56,050 --> 00:25:57,500
data sets in the US.

606
00:25:57,500 --> 00:25:59,570
Over 700,000 images.

607
00:25:59,570 --> 00:26:00,550
I would train a model.

608
00:26:00,550 --> 00:26:03,160
Here I'm training a type of
convolutional neural network

609
00:26:03,160 --> 00:26:05,840
to predict no finding,
which means you're healthy.

610
00:26:05,840 --> 00:26:09,160
And then I would look at what
the performance of that model

611
00:26:09,160 --> 00:26:09,800
was.

612
00:26:09,800 --> 00:26:12,710
And here I get an AUC of 0.859.

613
00:26:12,710 --> 00:26:13,760
That's really high.

614
00:26:13,760 --> 00:26:16,340
Random is 0.5, 1 is perfect.

615
00:26:16,340 --> 00:26:18,140
So this is a really good score.

616
00:26:18,140 --> 00:26:21,110
And many people
don't just stop here.

617
00:26:21,110 --> 00:26:23,990
They go all the way
to FDA approval.

618
00:26:23,990 --> 00:26:27,440
And in fact, there's now many
hundreds of FDA approved devices

619
00:26:27,440 --> 00:26:29,570
with AI/ML in them
that are being

620
00:26:29,570 --> 00:26:32,460
deployed across a wide range
of clinical subspecialties.

621
00:26:32,460 --> 00:26:34,100
This is really exciting.

622
00:26:34,100 --> 00:26:38,810
But the second thing
to keep in mind

623
00:26:38,810 --> 00:26:41,630
is that predicting or
generating something,

624
00:26:41,630 --> 00:26:44,430
well, for the average,
especially in health,

625
00:26:44,430 --> 00:26:45,690
is not good enough.

626
00:26:45,690 --> 00:26:46,580
Why?

627
00:26:46,580 --> 00:26:49,260
Let's go back and
pick on my own work.

628
00:26:49,260 --> 00:26:52,098
That performance
right there, 0.859.

629
00:26:52,098 --> 00:26:52,890
That's really good.

630
00:26:52,890 --> 00:26:54,450
But that's one number.

631
00:26:54,450 --> 00:26:58,190
What happens when I see
the individual performance

632
00:26:58,190 --> 00:27:01,530
numbers for different
subgroups of patients?

633
00:27:01,530 --> 00:27:05,360
When I do that audit, I find
that this model underperforms

634
00:27:05,360 --> 00:27:09,290
in female patients, young
patients, Black patients

635
00:27:09,290 --> 00:27:11,370
and patients on
Medicaid insurance.

636
00:27:11,370 --> 00:27:14,160
And actually, if you exist in
an intersectional identity,

637
00:27:14,160 --> 00:27:16,168
if you're a Black or
Hispanic female patient,

638
00:27:16,168 --> 00:27:17,960
then you do significantly
worse than if you

639
00:27:17,960 --> 00:27:21,140
were a part of a larger
aggregated identity.

640
00:27:21,140 --> 00:27:26,580
And this is happening in part
because medical data is really

641
00:27:26,580 --> 00:27:29,880
complex, and you can
infer just by looking

642
00:27:29,880 --> 00:27:33,480
at somebody's medical note
or their medical image what

643
00:27:33,480 --> 00:27:34,900
their demographics are.

644
00:27:34,900 --> 00:27:38,820
What their biological sex is,
what their self-reported race

645
00:27:38,820 --> 00:27:39,550
would be.

646
00:27:39,550 --> 00:27:41,970
And this is even when you
don't give this information

647
00:27:41,970 --> 00:27:43,270
to the model.

648
00:27:43,270 --> 00:27:46,200
This is also in situations
where we've tested doctors

649
00:27:46,200 --> 00:27:48,870
and they can't tell based
on the medical image

650
00:27:48,870 --> 00:27:50,520
or the medical note.

651
00:27:50,520 --> 00:27:54,810
And so what this means is that
it's actually pretty complex

652
00:27:54,810 --> 00:27:58,180
to make a model optimal
in a high dimensional,

653
00:27:58,180 --> 00:27:59,850
multimodal setting.

654
00:27:59,850 --> 00:28:01,770
How hard could this be?

655
00:28:01,770 --> 00:28:03,490
Well, let's take a look.

656
00:28:03,490 --> 00:28:06,240
Medical imaging is one of the
spaces where AI is applied

657
00:28:06,240 --> 00:28:08,020
to most frequently in health.

658
00:28:08,020 --> 00:28:09,690
And so we looked at
a couple of settings

659
00:28:09,690 --> 00:28:10,940
where it's frequently applied.

660
00:28:10,940 --> 00:28:14,220
This would be for a chest X-ray
based diagnosis for dermatology

661
00:28:14,220 --> 00:28:15,580
and for ophthalmology.

662
00:28:15,580 --> 00:28:16,980
And in each of
these cases, we're

663
00:28:16,980 --> 00:28:19,300
trying to predict an
important clinical outcome.

664
00:28:19,300 --> 00:28:21,720
And we want to look at
how poorly these models do

665
00:28:21,720 --> 00:28:25,090
in different subgroups depending
on how we optimize the model.

666
00:28:25,090 --> 00:28:29,560
The first thing we found is that
the more that a model secretly

667
00:28:29,560 --> 00:28:34,010
learns in the layers to encode
your demographics, for example,

668
00:28:34,010 --> 00:28:36,100
that you are
female, the worse it

669
00:28:36,100 --> 00:28:40,270
does at predicting the clinical
target for that subgroup

670
00:28:40,270 --> 00:28:42,708
that is minoritized, in
this case, female patients.

671
00:28:42,708 --> 00:28:44,500
Put another way, if
you're training a model

672
00:28:44,500 --> 00:28:46,480
to predict pneumonia,
and it learns who is male

673
00:28:46,480 --> 00:28:48,910
and who is female, it will
predict pneumonia worse

674
00:28:48,910 --> 00:28:50,360
for female patients.

675
00:28:50,360 --> 00:28:52,690
We then tried to
fix this, and we

676
00:28:52,690 --> 00:28:55,790
found that if you take data
from hospitals in Massachusetts,

677
00:28:55,790 --> 00:28:58,880
train the model and
force it to be optimal,

678
00:28:58,880 --> 00:29:00,970
meaning all the way on
the bottom right hand

679
00:29:00,970 --> 00:29:05,350
part of that plot, very,
very performant on average,

680
00:29:05,350 --> 00:29:08,360
and on the bottom,
very low fairness gap.

681
00:29:08,360 --> 00:29:11,570
Then when you test the model
on patients from Massachusetts,

682
00:29:11,570 --> 00:29:12,633
it does really well.

683
00:29:12,633 --> 00:29:14,800
And so that means modern
machine learning strategies

684
00:29:14,800 --> 00:29:17,410
can be locally optimal,
if you deploy them

685
00:29:17,410 --> 00:29:19,190
in the settings at
their trained in.

686
00:29:19,190 --> 00:29:21,520
But that's not how we train
machine learning models

687
00:29:21,520 --> 00:29:24,090
right now, even when
they're approved by the FDA.

688
00:29:24,090 --> 00:29:25,740
We train them in Massachusetts.

689
00:29:25,740 --> 00:29:29,460
They get approved, and then we
invite the world to use them.

690
00:29:29,460 --> 00:29:33,770
And when we take this model and
we throw it over to California

691
00:29:33,770 --> 00:29:35,580
and ask them to
test on their data,

692
00:29:35,580 --> 00:29:40,250
we actually find that optimal
fairness doesn't transfer.

693
00:29:40,250 --> 00:29:42,560
And this has important
policy findings for the way

694
00:29:42,560 --> 00:29:44,960
that we audit models
and evaluate them

695
00:29:44,960 --> 00:29:47,660
before they're approved in a
local setting, for example,

696
00:29:47,660 --> 00:29:49,040
state to state.

697
00:29:49,040 --> 00:29:50,870
And this gets even
harder when we

698
00:29:50,870 --> 00:29:52,980
think not just about
deep learning models,

699
00:29:52,980 --> 00:29:54,600
but vision language models.

700
00:29:54,600 --> 00:29:56,550
Everybody's used a
vision language model,

701
00:29:56,550 --> 00:29:59,000
I would assume at
this point, for fun.

702
00:29:59,000 --> 00:30:02,580
As Carolyn said, they can give
you really interesting results.

703
00:30:02,580 --> 00:30:05,850
And they're really good, not
just at image generation,

704
00:30:05,850 --> 00:30:08,090
but they have been
used in medicine

705
00:30:08,090 --> 00:30:11,540
and clinically adjacent tasks
for zero shot classification

706
00:30:11,540 --> 00:30:13,098
and zero shot retrieval.

707
00:30:13,098 --> 00:30:14,640
And they're very
good at these tasks.

708
00:30:14,640 --> 00:30:16,400
But it's also been
pretty well established

709
00:30:16,400 --> 00:30:19,760
that they have these
problematic human biases in each

710
00:30:19,760 --> 00:30:20,820
of these settings.

711
00:30:20,820 --> 00:30:24,820
For example, they always tend
to generate male doctors.

712
00:30:24,820 --> 00:30:26,700
And one of the reasons
it's really hard

713
00:30:26,700 --> 00:30:28,830
to de-bias these
models is because we

714
00:30:28,830 --> 00:30:31,140
have a really simplistic
approach to thinking

715
00:30:31,140 --> 00:30:33,070
about their mind space.

716
00:30:33,070 --> 00:30:36,400
And so here, if I wanted to
de-bias a vision language model,

717
00:30:36,400 --> 00:30:38,580
much of the existing
work assumes

718
00:30:38,580 --> 00:30:42,460
there's a direction for male,
there's a direction for female.

719
00:30:42,460 --> 00:30:45,790
Draw a linear projection
and collapse that down.

720
00:30:45,790 --> 00:30:46,870
It's fair.

721
00:30:46,870 --> 00:30:49,560
But actually these
models are reasonably

722
00:30:49,560 --> 00:30:51,100
complex and non-linear.

723
00:30:51,100 --> 00:30:54,270
And so maybe the direction
for male and female doctors

724
00:30:54,270 --> 00:30:56,700
is very different than the
direction for male and female

725
00:30:56,700 --> 00:30:58,540
pilots or managers.

726
00:30:58,540 --> 00:31:00,100
And so in order
to get past this,

727
00:31:00,100 --> 00:31:02,820
we actually have to
think about doing a more

728
00:31:02,820 --> 00:31:04,510
complex, non-linear approach.

729
00:31:04,510 --> 00:31:06,330
And so in recent
work, what we did

730
00:31:06,330 --> 00:31:08,520
is looked at a zero
shot retrieval example

731
00:31:08,520 --> 00:31:10,600
where we want to get
a picture of a doctor,

732
00:31:10,600 --> 00:31:13,680
and we want that to be unbiased
between male and female image

733
00:31:13,680 --> 00:31:14,560
generation.

734
00:31:14,560 --> 00:31:17,250
So when I ask for a
doctor, maybe my query

735
00:31:17,250 --> 00:31:19,390
gets embedded right
there at the star.

736
00:31:19,390 --> 00:31:21,950
And if I did a
traditional de-biasing,

737
00:31:21,950 --> 00:31:25,210
I would just project a line,
find this middle point between

738
00:31:25,210 --> 00:31:28,280
these two spaces, and
say, "Now I'm fair."

739
00:31:28,280 --> 00:31:31,550
But you can see here, because
it's complex and non-linear,

740
00:31:31,550 --> 00:31:34,480
I'm still closer to all of
these pictures of male doctors

741
00:31:34,480 --> 00:31:35,780
than female doctors.

742
00:31:35,780 --> 00:31:38,750
So I would still just generate
a picture of a male doctor.

743
00:31:38,750 --> 00:31:43,030
Instead, we propose an
approach to bend your debiasing

744
00:31:43,030 --> 00:31:46,580
in the direction of the
complex non-linear space.

745
00:31:46,580 --> 00:31:48,380
And so don't stop here.

746
00:31:48,380 --> 00:31:50,230
Move along this
surface until you're

747
00:31:50,230 --> 00:31:52,780
at a place where you're
equidistant from male and female

748
00:31:52,780 --> 00:31:54,290
images, in this case.

749
00:31:54,290 --> 00:31:56,620
And this is nice because
approaches like this

750
00:31:56,620 --> 00:31:59,088
require no fine tuning of
your vision language models.

751
00:31:59,088 --> 00:32:00,880
So you can just use a
vision language model

752
00:32:00,880 --> 00:32:01,940
as it comes to you.

753
00:32:01,940 --> 00:32:03,700
And they can be
tailored to de-bias

754
00:32:03,700 --> 00:32:08,170
for existing or new
queries that come in.

755
00:32:08,170 --> 00:32:10,690
The last thing I
want you to remember

756
00:32:10,690 --> 00:32:14,000
is that good models,
even if we de-bias them,

757
00:32:14,000 --> 00:32:17,830
they don't necessarily guarantee
that we'll have good outcomes.

758
00:32:17,830 --> 00:32:20,000
And so we have a lot
of work in the past

759
00:32:20,000 --> 00:32:22,670
that's shown that the
losses from poor AI

760
00:32:22,670 --> 00:32:25,275
can be larger than the
gains from good AI.

761
00:32:25,275 --> 00:32:27,650
And so we have to be really
careful that these models are

762
00:32:27,650 --> 00:32:28,680
trained well.

763
00:32:28,680 --> 00:32:32,180
We know that doctors are
susceptible to poor advice,

764
00:32:32,180 --> 00:32:33,960
even when they have expertise.

765
00:32:33,960 --> 00:32:37,040
Here we showed radiologists
incorrect advice

766
00:32:37,040 --> 00:32:40,380
for X-ray images, and they
were still fooled by it.

767
00:32:40,380 --> 00:32:42,560
And finally, we
have work showing

768
00:32:42,560 --> 00:32:45,500
that the way that you
deliver bias content

769
00:32:45,500 --> 00:32:49,380
is more convincing sometimes
than the bias content itself.

770
00:32:49,380 --> 00:32:52,560
So if you tell somebody to call
the police on minority patients,

771
00:32:52,560 --> 00:32:54,890
they're much more likely
to listen to it than if you

772
00:32:54,890 --> 00:32:57,950
say there's a risk of violence
at an equal rate for minority

773
00:32:57,950 --> 00:32:58,592
patients.

774
00:32:58,592 --> 00:33:00,050
So we need to pay
careful attention

775
00:33:00,050 --> 00:33:01,920
to how we deliver
advice from models,

776
00:33:01,920 --> 00:33:04,160
not just the advice we give.

777
00:33:04,160 --> 00:33:07,610
And so the four things you need
to keep in mind as you build

778
00:33:07,610 --> 00:33:11,270
models along this pipeline
are, we can predict,

779
00:33:11,270 --> 00:33:12,690
or generate anything.

780
00:33:12,690 --> 00:33:15,270
But doing well on average
is not good enough.

781
00:33:15,270 --> 00:33:18,760
We need to know that making
models optimal as complex,

782
00:33:18,760 --> 00:33:20,580
otherwise they already
would be that way.

783
00:33:20,580 --> 00:33:22,383
And good models won't
improve outcomes.

784
00:33:22,383 --> 00:33:24,300
Instead, we need to move
forward with creating

785
00:33:24,300 --> 00:33:25,800
actionable insights
in human health.

786
00:33:25,800 --> 00:33:26,930
Thank you.

787
00:33:26,930 --> 00:33:29,870
[APPLAUSE]

788
00:33:29,870 --> 00:33:48,541

789
00:33:48,541 --> 00:33:52,170
Thank you and good afternoon.

790
00:33:52,170 --> 00:33:55,710
Very glad to be here.

791
00:33:55,710 --> 00:33:57,990
What I would like
to talk to you about

792
00:33:57,990 --> 00:34:02,500
is an area that occupied
my thinking for many years.

793
00:34:02,500 --> 00:34:06,720
And recently with
two of my colleagues,

794
00:34:06,720 --> 00:34:10,980
we have made some progress
that recently appeared,

795
00:34:10,980 --> 00:34:14,340
meaning recently in the
last month in nature

796
00:34:14,340 --> 00:34:16,179
digital medicine.

797
00:34:16,179 --> 00:34:18,820
So what is the story?

798
00:34:18,820 --> 00:34:20,739
As many of you
know, of course, is

799
00:34:20,739 --> 00:34:24,260
that the golden standard in
medicine and many other fields,

800
00:34:24,260 --> 00:34:27,320
of course, is to do
randomized clinical trials.

801
00:34:27,320 --> 00:34:31,040
For more than 100 years, this
has been the name of the game.

802
00:34:31,040 --> 00:34:38,230
However, RCTs are very expensive
and often last very long.

803
00:34:38,230 --> 00:34:42,489
Also, while RCTs,
the conclusions

804
00:34:42,489 --> 00:34:44,840
are suitable for
the average patient,

805
00:34:44,840 --> 00:34:54,949
they may be not appropriate
for not the average patient.

806
00:34:54,949 --> 00:34:58,540
So there is a need
to identify a way

807
00:34:58,540 --> 00:35:02,980
to understand what is
called heterogeneity

808
00:35:02,980 --> 00:35:07,220
of treatment effects,
namely more personalization.

809
00:35:07,220 --> 00:35:14,140
In contrast, observational
data are very widely available

810
00:35:14,140 --> 00:35:16,790
and inexpensive.

811
00:35:16,790 --> 00:35:23,640
One would argue that the cost
of developing a new drug,

812
00:35:23,640 --> 00:35:27,960
which currently is of the order
of between one or two billion,

813
00:35:27,960 --> 00:35:32,840
is definitely affected by the
fact that we have to do RCTs.

814
00:35:32,840 --> 00:35:35,280
So what is the
challenge on this idea?

815
00:35:35,280 --> 00:35:40,010
The presence of
confounding bias.

816
00:35:40,010 --> 00:35:44,520
Confounding exists, especially
in observational data.

817
00:35:44,520 --> 00:35:47,800
This is exactly the topic
that RCTs try to address.

818
00:35:47,800 --> 00:35:51,050

819
00:35:51,050 --> 00:35:55,550
At the same time,
RCTs, while strong

820
00:35:55,550 --> 00:35:58,280
in identifying whether a
treatment works or does not

821
00:35:58,280 --> 00:36:03,470
work, they do not define
effectively patient subgroups.

822
00:36:03,470 --> 00:36:04,970
In other words,
they don't typically

823
00:36:04,970 --> 00:36:06,840
personalize treatments.

824
00:36:06,840 --> 00:36:08,930
There has been some
progress of what

825
00:36:08,930 --> 00:36:10,410
is called one
variable at a time,

826
00:36:10,410 --> 00:36:12,800
but I would say quite limited.

827
00:36:12,800 --> 00:36:16,350
So what is the purpose
of this effort?

828
00:36:16,350 --> 00:36:20,490
That we propose and
demonstrate using

829
00:36:20,490 --> 00:36:24,130
one clinical example,
and later on many,

830
00:36:24,130 --> 00:36:25,660
but I only have time for one.

831
00:36:25,660 --> 00:36:31,110
A framework to reach
clinical conclusions

832
00:36:31,110 --> 00:36:33,760
based on observational data.

833
00:36:33,760 --> 00:36:37,050
And this is data that
we used in collaboration

834
00:36:37,050 --> 00:36:40,860
with Memorial Sloan Kettering
that one of my collaborators

835
00:36:40,860 --> 00:36:42,780
is from.

836
00:36:42,780 --> 00:36:45,810
So in other words, we
can now have an approach

837
00:36:45,810 --> 00:36:49,530
that can lead to medically
valid conclusions

838
00:36:49,530 --> 00:36:51,430
based on observational data.

839
00:36:51,430 --> 00:36:56,800
The second is that even
if we insist to use RCTs,

840
00:36:56,800 --> 00:36:59,770
we have a way of
personalizing the RCT.

841
00:36:59,770 --> 00:37:02,070
In other words, from an
RCT, you can actually

842
00:37:02,070 --> 00:37:07,020
get personalized information
of how treatment should

843
00:37:07,020 --> 00:37:09,030
be appropriately personalized.

844
00:37:09,030 --> 00:37:14,620
So in my view, this
leads to a way of--

845
00:37:14,620 --> 00:37:16,420
which is, in my
opinion, something

846
00:37:16,420 --> 00:37:19,540
I have tried for a long time
to utilize observational data

847
00:37:19,540 --> 00:37:23,560
than RCTs for
precision medicine.

848
00:37:23,560 --> 00:37:27,710
So let me tell you, get
you a sense of the story.

849
00:37:27,710 --> 00:37:32,920
We have some patients that
have a particular cancer,

850
00:37:32,920 --> 00:37:35,860
of a particular type
of tumor, what's

851
00:37:35,860 --> 00:37:39,790
called GIST,
Gastrointestinal Stromal

852
00:37:39,790 --> 00:37:44,980
Tumor, that MSK specializes
in the observational data set.

853
00:37:44,980 --> 00:37:48,440
So these patients have
already undergone surgery.

854
00:37:48,440 --> 00:37:50,200
And the question
is, are we going

855
00:37:50,200 --> 00:37:55,360
to give them a particular
chemotherapy called imatinib?

856
00:37:55,360 --> 00:37:58,420
By and large today
in the world, we

857
00:37:58,420 --> 00:38:01,520
offer imatinib as
a way of doing it,

858
00:38:01,520 --> 00:38:04,300
even though there has been some
studies that suggest that there

859
00:38:04,300 --> 00:38:08,350
are patients who don't need
it, and therefore would

860
00:38:08,350 --> 00:38:10,510
have benefit by avoiding it.

861
00:38:10,510 --> 00:38:12,720
So what is the data
that we do have?

862
00:38:12,720 --> 00:38:17,060
So for each patient we
have some covariates,

863
00:38:17,060 --> 00:38:18,980
or what is called
[INAUDIBLE] count

864
00:38:18,980 --> 00:38:23,510
the tumor site and the tumor
size potentially others.

865
00:38:23,510 --> 00:38:25,010
And for every one
of these patients,

866
00:38:25,010 --> 00:38:26,730
these are observational data.

867
00:38:26,730 --> 00:38:31,710
We also know whether the
treatment was applied,

868
00:38:31,710 --> 00:38:33,830
whether imatinib
was given or not,

869
00:38:33,830 --> 00:38:38,360
and whether or not
the patient recurred.

870
00:38:38,360 --> 00:38:42,330
So we have the
data, the treatment,

871
00:38:42,330 --> 00:38:48,620
whether the treatment was
given, and whether reoccurrence

872
00:38:48,620 --> 00:38:50,630
happened.

873
00:38:50,630 --> 00:38:52,275
Of course, there is confounding.

874
00:38:52,275 --> 00:38:53,900
What is the notion
of confounding here?

875
00:38:53,900 --> 00:38:57,720
That the treatment was
not randomly assigned.

876
00:38:57,720 --> 00:39:06,680
So patients who were predicted
to have worse outcomes typically

877
00:39:06,680 --> 00:39:10,600
tend to get the treatment.

878
00:39:10,600 --> 00:39:12,390
So these are not--

879
00:39:12,390 --> 00:39:14,050
this is not a randomized trial.

880
00:39:14,050 --> 00:39:19,770
So the very act of
having the treatment

881
00:39:19,770 --> 00:39:23,710
has a higher baseline
risk of recurrence.

882
00:39:23,710 --> 00:39:27,160
So which is the key difficulty.

883
00:39:27,160 --> 00:39:30,840
So what we try to
do, I will briefly

884
00:39:30,840 --> 00:39:34,448
tell you, the key idea
of how to overcome that.

885
00:39:34,448 --> 00:39:35,490
There are two components.

886
00:39:35,490 --> 00:39:37,180
I will only have
time for the first.

887
00:39:37,180 --> 00:39:39,640
But the key here
is to take a model,

888
00:39:39,640 --> 00:39:41,370
take a machine learning model.

889
00:39:41,370 --> 00:39:45,160
Take only people who did
not receive the treatment,

890
00:39:45,160 --> 00:39:49,710
and build a classification
model of whether they

891
00:39:49,710 --> 00:39:51,190
are recurring or not.

892
00:39:51,190 --> 00:39:53,670
Notice that this is
only based on people

893
00:39:53,670 --> 00:39:56,710
who did not get the treatment.

894
00:39:56,710 --> 00:40:02,560
Then apply the model for those
who did take the treatment.

895
00:40:02,560 --> 00:40:05,680
So now for every one
of these patients,

896
00:40:05,680 --> 00:40:10,160
we have a probability
of recurrence

897
00:40:10,160 --> 00:40:12,300
for both types of patients.

898
00:40:12,300 --> 00:40:16,250
But the patient was only
developed for those patients

899
00:40:16,250 --> 00:40:18,840
who did not--

900
00:40:18,840 --> 00:40:20,850
I'm sorry-- did not
get the treatment.

901
00:40:20,850 --> 00:40:22,550
Put them in buckets.

902
00:40:22,550 --> 00:40:26,730
So now let's say we put them
in 10 buckets between 10%.

903
00:40:26,730 --> 00:40:33,680
So within these buckets,
we have patients

904
00:40:33,680 --> 00:40:36,750
that have similar
probability of recurrence.

905
00:40:36,750 --> 00:40:38,670
Some of them got the treatment.

906
00:40:38,670 --> 00:40:40,560
Some of them did not.

907
00:40:40,560 --> 00:40:46,460
And then at the same
time, we try now to

908
00:40:46,460 --> 00:40:49,110
in each of these buckets,
there are say 10 of them,

909
00:40:49,110 --> 00:40:54,200
we try to make them in
each particular bucket

910
00:40:54,200 --> 00:40:57,480
so that they are as
if it were randomized.

911
00:40:57,480 --> 00:40:59,010
And how do we achieve that?

912
00:40:59,010 --> 00:41:00,840
We try to use optimization.

913
00:41:00,840 --> 00:41:03,860
We try to match the
characteristics from the data

914
00:41:03,860 --> 00:41:07,610
that we have so that
patients within every bucket,

915
00:41:07,610 --> 00:41:09,800
that includes both
treated and untreated,

916
00:41:09,800 --> 00:41:12,570
are similar in these
characteristics.

917
00:41:12,570 --> 00:41:14,280
And we use
optimization for that.

918
00:41:14,280 --> 00:41:16,478
The specifics that, you
would not follow it.

919
00:41:16,478 --> 00:41:18,270
I would not have followed
it if I were you.

920
00:41:18,270 --> 00:41:22,520
So key here is that we
have a methodology now

921
00:41:22,520 --> 00:41:25,760
that we, in each
of these buckets,

922
00:41:25,760 --> 00:41:29,990
we are able to match
their characteristics.

923
00:41:29,990 --> 00:41:34,220
Just to demonstrate the
process of confounding,

924
00:41:34,220 --> 00:41:35,970
the process of the left.

925
00:41:35,970 --> 00:41:39,320
The data on the left
shows the survival

926
00:41:39,320 --> 00:41:41,720
among those who took
the treatment and those

927
00:41:41,720 --> 00:41:43,080
who did not get the treatment.

928
00:41:43,080 --> 00:41:46,010
And you observe that people
who got the treatment

929
00:41:46,010 --> 00:41:50,990
are faring worse than the
people who did not get,

930
00:41:50,990 --> 00:41:52,190
because they are healthier.

931
00:41:52,190 --> 00:41:55,560
After the matching, after
this optimization process,

932
00:41:55,560 --> 00:41:59,250
there is still confounding
involved, but it has decreased.

933
00:41:59,250 --> 00:42:02,840
So there is remaining
confounding even

934
00:42:02,840 --> 00:42:04,410
after this optimization.

935
00:42:04,410 --> 00:42:07,510
So what we do as
a second step is--

936
00:42:07,510 --> 00:42:11,360
and to demonstrate
the effect is that,

937
00:42:11,360 --> 00:42:17,950
so this is the graph on the left
shows the percentages of people

938
00:42:17,950 --> 00:42:21,880
in each of these
buckets who have

939
00:42:21,880 --> 00:42:25,120
similar probability
of recurrence,

940
00:42:25,120 --> 00:42:28,720
but who took the treatment and
who did not take the treatment.

941
00:42:28,720 --> 00:42:32,500
What the optimization does
is on the right, in which we

942
00:42:32,500 --> 00:42:33,890
have the same number of people.

943
00:42:33,890 --> 00:42:37,790
So we actually delete patients
from the observational data,

944
00:42:37,790 --> 00:42:39,590
but we don't delete
random patients.

945
00:42:39,590 --> 00:42:42,700
We delete those patients so
that the remaining patients

946
00:42:42,700 --> 00:42:46,450
are very similar in their
characteristics, as well as

947
00:42:46,450 --> 00:42:48,530
the probability of recurrence.

948
00:42:48,530 --> 00:42:52,940
And then as a final step, we
also, because as I mentioned,

949
00:42:52,940 --> 00:42:56,830
there is a confounding
left, we actually

950
00:42:56,830 --> 00:43:01,900
train a model where
we artificially

951
00:43:01,900 --> 00:43:06,010
increase the weight
for those patients who

952
00:43:06,010 --> 00:43:09,500
received the treatment who
did not have recurrence.

953
00:43:09,500 --> 00:43:12,400
So the model tries to
make better predictions

954
00:43:12,400 --> 00:43:16,120
for those patients
with a larger weight,

955
00:43:16,120 --> 00:43:20,240
since this yields
greater improvement.

956
00:43:20,240 --> 00:43:25,690
And when we are-- so in a way,
we clean the data in such a way

957
00:43:25,690 --> 00:43:29,270
that we try to subtract
confounding from the data.

958
00:43:29,270 --> 00:43:32,620
And then as a final step, we
apply machine learning technique

959
00:43:32,620 --> 00:43:35,980
called optimal policy trees,
that was developed in my group,

960
00:43:35,980 --> 00:43:38,990
to be able to personalize
the treatment.

961
00:43:38,990 --> 00:43:43,270
And here's the effect
for patients from MSK.

962
00:43:43,270 --> 00:43:47,080
So you can see that
although you might not

963
00:43:47,080 --> 00:43:49,570
see the exact
personalization, you

964
00:43:49,570 --> 00:43:58,030
observe that when you
look at a particular,

965
00:43:58,030 --> 00:44:01,460
let's say the mitotic count,
if it's above a certain level,

966
00:44:01,460 --> 00:44:02,850
you prescribe the treatment.

967
00:44:02,850 --> 00:44:05,100
If it's is below a certain
level, you do other things.

968
00:44:05,100 --> 00:44:08,160
So this is definitely
a personalization story

969
00:44:08,160 --> 00:44:09,980
on the observational data.

970
00:44:09,980 --> 00:44:12,420
So how do we know that
it has some benefits?

971
00:44:12,420 --> 00:44:17,450
We actually took completely new
data, unseen data from Poland.

972
00:44:17,450 --> 00:44:21,470
And in that particular
data we have observed

973
00:44:21,470 --> 00:44:33,140
that while the sensitivity
of the trial data and ours

974
00:44:33,140 --> 00:44:37,110
is similar, we were able
to actually find 7%--

975
00:44:37,110 --> 00:44:39,200
the personalization
helped us spare

976
00:44:39,200 --> 00:44:42,620
7% of the patients who
would not have benefit

977
00:44:42,620 --> 00:44:44,370
from unnecessary treatment.

978
00:44:44,370 --> 00:44:46,770
While the result is
relatively modest,

979
00:44:46,770 --> 00:44:51,750
it shows that there is a
benefit by the personalization.

980
00:44:51,750 --> 00:44:56,220
This is just on-- and
this is unseen data.

981
00:44:56,220 --> 00:44:59,600
I mean, a completely
different study.

982
00:44:59,600 --> 00:45:04,420
My final point is how to
now personalize trials.

983
00:45:04,420 --> 00:45:10,680
So this has been so the benefit
of radiotherapy for patients

984
00:45:10,680 --> 00:45:14,220
with what is called
truncal sarcomas

985
00:45:14,220 --> 00:45:16,720
has been demonstrated
in two major trials.

986
00:45:16,720 --> 00:45:19,440
So MSK, as many
other institutions,

987
00:45:19,440 --> 00:45:27,660
utilize a radiation
therapy after surgery.

988
00:45:27,660 --> 00:45:33,400
So that's more or less
the key therapy today.

989
00:45:33,400 --> 00:45:36,780
However, it has been
reported that many patients--

990
00:45:36,780 --> 00:45:39,220
some patients might
not benefit for that.

991
00:45:39,220 --> 00:45:41,670
So applying a
similar story-- this

992
00:45:41,670 --> 00:45:43,090
is now not observational data.

993
00:45:43,090 --> 00:45:44,640
This is randomized
data for which we

994
00:45:44,640 --> 00:45:46,300
don't know how to personalize.

995
00:45:46,300 --> 00:45:51,570
So this data does not have
the effect of confounding

996
00:45:51,570 --> 00:45:53,260
because it's randomized trials.

997
00:45:53,260 --> 00:45:56,500
So we do the optimization
and this other part.

998
00:45:56,500 --> 00:45:59,820
And we also find a
personalized treatment

999
00:45:59,820 --> 00:46:01,460
on the randomization data.

1000
00:46:01,460 --> 00:46:05,680
So this is a general purpose
randomized clinical trial

1001
00:46:05,680 --> 00:46:08,000
that allows personalization.

1002
00:46:08,000 --> 00:46:12,520
And then we try this
approach for data from MSK

1003
00:46:12,520 --> 00:46:14,870
that are different from
the clinical trial.

1004
00:46:14,870 --> 00:46:20,020
The original-- the methodology
was trained by the randomized

1005
00:46:20,020 --> 00:46:26,270
clinical trial data in that
happened in the early 1980s.

1006
00:46:26,270 --> 00:46:31,510
And then we utilized the data
from MSK observational data

1007
00:46:31,510 --> 00:46:33,680
over 16, 17 years.

1008
00:46:33,680 --> 00:46:38,200
We have found that the
approach is equally

1009
00:46:38,200 --> 00:46:39,770
effective in
protecting patients,

1010
00:46:39,770 --> 00:46:45,670
but spares 15% of the
patients that need not--

1011
00:46:45,670 --> 00:46:47,960
they didn't need radiotherapy.

1012
00:46:47,960 --> 00:46:49,870
And therefore, the
personalization

1013
00:46:49,870 --> 00:46:52,430
helped in improving that effect.

1014
00:46:52,430 --> 00:46:55,130
So of course, since then
this was the original paper.

1015
00:46:55,130 --> 00:46:57,740
We have tried it in about
10 different studies,

1016
00:46:57,740 --> 00:47:05,790
from cardiology to oncology,
to other areas of medicine.

1017
00:47:05,790 --> 00:47:07,670
And we have found
across the board

1018
00:47:07,670 --> 00:47:12,140
that a benefit by the
personalization in studies

1019
00:47:12,140 --> 00:47:13,980
outside of the data we have.

1020
00:47:13,980 --> 00:47:17,330
So in summary, what I would
like you to remember from

1021
00:47:17,330 --> 00:47:23,810
this is that the area
of trying to find

1022
00:47:23,810 --> 00:47:28,430
an approach for personalization
just on observational data

1023
00:47:28,430 --> 00:47:32,960
is, in my opinion, a very
important aspect in medicine.

1024
00:47:32,960 --> 00:47:36,440
We hope that the approach is
definitely-- would definitely

1025
00:47:36,440 --> 00:47:40,520
help how to change
medical research,

1026
00:47:40,520 --> 00:47:45,830
and also perhaps improve and
decrease the cost of developing

1027
00:47:45,830 --> 00:47:50,060
therapies around the world
in a way that provides

1028
00:47:50,060 --> 00:47:52,410
a road to precision medicine.

1029
00:47:52,410 --> 00:47:54,500
Thank you.

1030
00:47:54,500 --> 00:47:57,250
[APPLAUSE]

1031
00:47:57,250 --> 00:47:59,000


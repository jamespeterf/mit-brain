1
00:00:04,400 --> 00:00:07,680
Kicking off the lightning talks today,

2
00:00:06,080 --> 00:00:10,320
I'd like to introduce our first

3
00:00:07,680 --> 00:00:12,400
presenter, Tim Carr of Ver. Vier

4
00:00:10,320 --> 00:00:14,880
develops highcapacity superconducting

5
00:00:12,400 --> 00:00:17,199
power transmission which is designed to

6
00:00:14,880 --> 00:00:19,359
meet the massive energy demands of the

7
00:00:17,199 --> 00:00:21,680
next generation data center

8
00:00:19,359 --> 00:00:23,359
infrastructure. Welcoming to the stage

9
00:00:21,680 --> 00:00:25,039
Tim Carr.

10
00:00:23,359 --> 00:00:27,199
>> Thank you so much Trisha. Uh very happy

11
00:00:25,039 --> 00:00:29,039
to be here today. Um my name is Tim

12
00:00:27,199 --> 00:00:31,439
Carr. I'm with Ver and I'm here to tell

13
00:00:29,039 --> 00:00:33,600
you about the superconducting technology

14
00:00:31,439 --> 00:00:37,040
that we're bringing to the data center

15
00:00:33,600 --> 00:00:40,040
uh AI data center market. And so our

16
00:00:37,040 --> 00:00:40,040
technology

17
00:00:40,239 --> 00:00:45,440
is built around a core reality of AI's

18
00:00:43,280 --> 00:00:48,320
growth, which is that power is at the

19
00:00:45,440 --> 00:00:50,079
center of it. Power is the backbone. As

20
00:00:48,320 --> 00:00:52,640
we continue to see the proliferation of

21
00:00:50,079 --> 00:00:54,879
AI models across inference, uh,

22
00:00:52,640 --> 00:00:57,440
reasoning, and training, we're seeing an

23
00:00:54,879 --> 00:00:59,920
explosion of power demand globally with

24
00:00:57,440 --> 00:01:01,760
gigawatt scale campuses now the norm.

25
00:00:59,920 --> 00:01:04,239
And frankly, this trend not expected to

26
00:01:01,760 --> 00:01:06,880
stop anytime soon. And what's becoming

27
00:01:04,239 --> 00:01:08,880
clear as this growth unfolds is that our

28
00:01:06,880 --> 00:01:11,360
conventional power distribution

29
00:01:08,880 --> 00:01:13,600
technology that we've used for decades

30
00:01:11,360 --> 00:01:15,760
is being brought to the brink, being

31
00:01:13,600 --> 00:01:18,880
outpaced and outrun by the power

32
00:01:15,760 --> 00:01:21,920
requirements of these AI workloads. And

33
00:01:18,880 --> 00:01:24,560
so the capability for our current power

34
00:01:21,920 --> 00:01:27,200
delivery equipment to move massive

35
00:01:24,560 --> 00:01:28,560
amounts of power to these campuses and

36
00:01:27,200 --> 00:01:30,799
ultimately into the data center

37
00:01:28,560 --> 00:01:33,600
buildings themselves is now becoming a

38
00:01:30,799 --> 00:01:36,640
bottleneck due to the size, the weight,

39
00:01:33,600 --> 00:01:38,799
electrical resistance, and the cost of

40
00:01:36,640 --> 00:01:41,200
conventional options such as copper bus

41
00:01:38,799 --> 00:01:42,880
bars and cables. And so data centers

42
00:01:41,200 --> 00:01:45,360
really need to start thinking about and

43
00:01:42,880 --> 00:01:47,040
finding new solutions to unlock the

44
00:01:45,360 --> 00:01:49,439
scale and performance that this growth

45
00:01:47,040 --> 00:01:51,600
requires. And this growth is tether

46
00:01:49,439 --> 00:01:53,360
tethered as we all know to the high

47
00:01:51,600 --> 00:01:55,759
performance chips that support these

48
00:01:53,360 --> 00:01:57,360
workloads GPUs and similar processors.

49
00:01:55,759 --> 00:02:00,159
And so I have on the screen a snapshot

50
00:01:57,360 --> 00:02:02,399
of GPUs of excuse me Nvidia's GPU road

51
00:02:00,159 --> 00:02:05,920
map. And you can see that in today's

52
00:02:02,399 --> 00:02:08,319
Blackwell family we're at 150 to 250

53
00:02:05,920 --> 00:02:10,319
kilowatts for a server rack. But within

54
00:02:08,319 --> 00:02:13,360
48 months we're going to be at a server

55
00:02:10,319 --> 00:02:16,879
rack of a,000 kilowatts a megawatt rack

56
00:02:13,360 --> 00:02:20,160
in a very short time. And so how do we

57
00:02:16,879 --> 00:02:23,360
solve this power delivery problem to

58
00:02:20,160 --> 00:02:25,120
unlock AI's promise? And so at VR, our

59
00:02:23,360 --> 00:02:27,840
solution is superconductors.

60
00:02:25,120 --> 00:02:30,400
Superconductors move 10 times the power

61
00:02:27,840 --> 00:02:33,360
of conventional options with nearly no

62
00:02:30,400 --> 00:02:36,000
resistance in a dramatically smaller and

63
00:02:33,360 --> 00:02:37,920
lighter conductor. These options can go

64
00:02:36,000 --> 00:02:40,720
much further than conventional uh

65
00:02:37,920 --> 00:02:42,879
conventional equipment and do so without

66
00:02:40,720 --> 00:02:45,519
the creation of of thermal resistance or

67
00:02:42,879 --> 00:02:47,680
heat ultimately enabling highly power

68
00:02:45,519 --> 00:02:50,239
dense efficient and high performance

69
00:02:47,680 --> 00:02:52,239
data centers that can support the most

70
00:02:50,239 --> 00:02:54,400
advanced AI chipsets without breaking a

71
00:02:52,239 --> 00:02:57,360
sweat. And so to do that today we have

72
00:02:54,400 --> 00:02:59,680
three products. Uh we have our SL series

73
00:02:57,360 --> 00:03:01,840
which is designed for low voltage indoor

74
00:02:59,680 --> 00:03:04,879
application to support the highest AI

75
00:03:01,840 --> 00:03:07,040
pod densities. We have our ST series

76
00:03:04,879 --> 00:03:10,080
which is designed for power distribution

77
00:03:07,040 --> 00:03:12,560
at medium voltage level in a form factor

78
00:03:10,080 --> 00:03:14,879
that's up to 140th the size of

79
00:03:12,560 --> 00:03:17,760
conventional options. Our ST series can

80
00:03:14,879 --> 00:03:21,200
move over 200 megawatts of power in a

81
00:03:17,760 --> 00:03:23,760
single cable. And finally our SE series

82
00:03:21,200 --> 00:03:25,599
which is V's uh flagship and early

83
00:03:23,760 --> 00:03:27,599
product innovation which moves

84
00:03:25,599 --> 00:03:30,720
transmission level power over long

85
00:03:27,599 --> 00:03:33,440
distance in an overhead superconductor.

86
00:03:30,720 --> 00:03:35,200
And so to help kind of put you know show

87
00:03:33,440 --> 00:03:37,040
where these products go in the campus

88
00:03:35,200 --> 00:03:39,280
and what their applications are I have

89
00:03:37,040 --> 00:03:42,239
on the screen you can you can see you

90
00:03:39,280 --> 00:03:44,959
moving high power connections uh to the

91
00:03:42,239 --> 00:03:46,959
campus at the grid and substation level

92
00:03:44,959 --> 00:03:48,879
moving that power throughout the campus

93
00:03:46,959 --> 00:03:51,040
between substation transformers and

94
00:03:48,879 --> 00:03:53,360
buildings and then finally delivering

95
00:03:51,040 --> 00:03:55,440
that power in low voltage form directly

96
00:03:53,360 --> 00:03:57,760
into the whites space of these data

97
00:03:55,440 --> 00:03:59,599
centers. And the unifying thing of all

98
00:03:57,760 --> 00:04:02,080
these applications is that they deliver

99
00:03:59,599 --> 00:04:04,080
10 times the power density with nearly

100
00:04:02,080 --> 00:04:06,159
no losses over dramatically longer

101
00:04:04,080 --> 00:04:08,400
distances. And what that results in is

102
00:04:06,159 --> 00:04:12,879
the ability for us to support multiple

103
00:04:08,400 --> 00:04:15,120
gigawatt scale campuses easily.

104
00:04:12,879 --> 00:04:16,959
This slide really hones in on our low

105
00:04:15,120 --> 00:04:19,600
voltage product and compares some of the

106
00:04:16,959 --> 00:04:22,000
physical attributes of us to a

107
00:04:19,600 --> 00:04:24,240
conventional 4,000 amp copper bus bar

108
00:04:22,000 --> 00:04:26,080
which is used frequently today. And as

109
00:04:24,240 --> 00:04:28,639
you can see, we can now move an

110
00:04:26,080 --> 00:04:31,040
equivalent amount of of current in a

111
00:04:28,639 --> 00:04:33,199
conductor that's 10 times smaller, 10

112
00:04:31,040 --> 00:04:36,400
times lighter, and can go 10 times

113
00:04:33,199 --> 00:04:38,560
further. And this benefit of re of of

114
00:04:36,400 --> 00:04:40,639
congestion reduction is a big deal for

115
00:04:38,560 --> 00:04:42,639
data centers as they continue to wrestle

116
00:04:40,639 --> 00:04:45,199
with larger and more complex server

117
00:04:42,639 --> 00:04:47,360
equipment, the services to support them,

118
00:04:45,199 --> 00:04:48,960
the introduction of liquid cooling, and

119
00:04:47,360 --> 00:04:50,960
balancing that with the need to get the

120
00:04:48,960 --> 00:04:53,360
most amount of compute in a given in in

121
00:04:50,960 --> 00:04:56,160
a given space. And lastly, on our low

122
00:04:53,360 --> 00:04:58,160
voltage product, because we're removing

123
00:04:56,160 --> 00:05:00,320
a large amount of thermal resistance out

124
00:04:58,160 --> 00:05:02,560
of the inside of these buildings, we

125
00:05:00,320 --> 00:05:04,320
encourage the compression of servers,

126
00:05:02,560 --> 00:05:07,759
which can help with latency performance

127
00:05:04,320 --> 00:05:09,440
and help to speed up uh model training.

128
00:05:07,759 --> 00:05:11,360
This next slide shows a similar

129
00:05:09,440 --> 00:05:13,280
comparison for our medium voltage

130
00:05:11,360 --> 00:05:15,360
underground product. And I I really

131
00:05:13,280 --> 00:05:17,280
think the visual speaks for itself. The

132
00:05:15,360 --> 00:05:19,680
takeaway is here we can move the same

133
00:05:17,280 --> 00:05:22,880
amount of power uh from a conventional

134
00:05:19,680 --> 00:05:24,639
option in a much smaller cross-section.

135
00:05:22,880 --> 00:05:26,560
And the reason for that is largely due

136
00:05:24,639 --> 00:05:29,039
to the fact that we can remove the need

137
00:05:26,560 --> 00:05:30,479
for concrete duct banks. And so you see

138
00:05:29,039 --> 00:05:32,880
on the lefth hand side this is a picture

139
00:05:30,479 --> 00:05:34,800
of a very common concrete duct bank

140
00:05:32,880 --> 00:05:36,560
installation. These are typically done

141
00:05:34,800 --> 00:05:39,280
to manage thermal dissipation and to

142
00:05:36,560 --> 00:05:40,960
house many conductors underground. So we

143
00:05:39,280 --> 00:05:43,680
can now take all of that power that you

144
00:05:40,960 --> 00:05:45,440
see on the left hand side and use it in

145
00:05:43,680 --> 00:05:47,440
what's represented on the right in a

146
00:05:45,440 --> 00:05:50,240
single superconductor. The big

147
00:05:47,440 --> 00:05:51,520
efficiency to note here is time. By

148
00:05:50,240 --> 00:05:54,000
doing this we're able to remove

149
00:05:51,520 --> 00:05:55,520
thousands of hours from uh labor hours

150
00:05:54,000 --> 00:05:57,280
from a construction project which

151
00:05:55,520 --> 00:05:58,960
ultimately allows our clients to get

152
00:05:57,280 --> 00:06:00,639
their facilities online faster. And

153
00:05:58,960 --> 00:06:02,639
speed to market is something that our

154
00:06:00,639 --> 00:06:04,720
clients care a lot about in uh in

155
00:06:02,639 --> 00:06:06,319
today's environment. And so we're

156
00:06:04,720 --> 00:06:08,639
looking to partner with data center

157
00:06:06,319 --> 00:06:12,000
operators, developers, engineers,

158
00:06:08,639 --> 00:06:14,160
designers um to solve these tough power

159
00:06:12,000 --> 00:06:15,520
delivery challenges with superconductors

160
00:06:14,160 --> 00:06:17,199
uh with early commercial scale

161
00:06:15,520 --> 00:06:21,960
deployments. And so reach out today to

162
00:06:17,199 --> 00:06:21,960
get started. Thank you very much.


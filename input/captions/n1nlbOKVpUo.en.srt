1
00:00:04,640 --> 00:00:10,480
Please join me in welcoming our first

2
00:00:06,879 --> 00:00:13,280
speaker, Jonathan Rosenfeld. Jonathan is

3
00:00:10,480 --> 00:00:15,839
the leader of the fundamental AI group

4
00:00:13,280 --> 00:00:16,960
at MIT Future Tech. Take it away,

5
00:00:15,839 --> 00:00:18,800
Jonathan.

6
00:00:16,960 --> 00:00:22,560
>> Good morning everyone. Let's try and

7
00:00:18,800 --> 00:00:25,439
make a sense at it all. So what we want

8
00:00:22,560 --> 00:00:27,760
to try to do is to answer the question

9
00:00:25,439 --> 00:00:29,439
of the life, universe, and everything,

10
00:00:27,760 --> 00:00:32,559
right? We're talking about AI in the

11
00:00:29,439 --> 00:00:34,559
context of data centers, its progress,

12
00:00:32,559 --> 00:00:38,719
what's driving it, and what I'll attempt

13
00:00:34,559 --> 00:00:40,960
to do is hopefully sort it all out in

14
00:00:38,719 --> 00:00:43,760
terms of what are the driving forces,

15
00:00:40,960 --> 00:00:47,039
how can we when we how can we answer

16
00:00:43,760 --> 00:00:49,280
basic questions like imagine tell me

17
00:00:47,039 --> 00:00:51,520
before you invest to the tune of tens of

18
00:00:49,280 --> 00:00:53,840
billions of dollars, what will be the

19
00:00:51,520 --> 00:00:56,399
end result and how performant it would

20
00:00:53,840 --> 00:00:58,160
be, what's going on today and how are

21
00:00:56,399 --> 00:01:01,359
economics fitting into

22
00:00:58,160 --> 00:01:04,400
So I've set here an agenda that I hope

23
00:01:01,359 --> 00:01:07,040
to cover in 30 minutes. Starting from

24
00:01:04,400 --> 00:01:09,360
where we are today. I assume this will

25
00:01:07,040 --> 00:01:11,280
be very very familiar. Try to tease out

26
00:01:09,360 --> 00:01:14,880
a bit of the hype and what's actually

27
00:01:11,280 --> 00:01:17,840
going on and then how we got here. What

28
00:01:14,880 --> 00:01:19,439
is the role of actually answering

29
00:01:17,840 --> 00:01:22,880
quantitatively

30
00:01:19,439 --> 00:01:24,400
this idea of predictive power of our

31
00:01:22,880 --> 00:01:26,799
performance

32
00:01:24,400 --> 00:01:29,200
and how all the components of that fit

33
00:01:26,799 --> 00:01:31,200
together? What are they with decisional

34
00:01:29,200 --> 00:01:32,960
technical laws the equivalent of Moore's

35
00:01:31,200 --> 00:01:34,720
law that we are seeing and what are

36
00:01:32,960 --> 00:01:36,560
their limits

37
00:01:34,720 --> 00:01:39,360
and how they interact briefly with

38
00:01:36,560 --> 00:01:40,960
market dynamics putting it all together

39
00:01:39,360 --> 00:01:43,840
in terms of how do we actually measure

40
00:01:40,960 --> 00:01:46,240
the things that we care about

41
00:01:43,840 --> 00:01:49,280
and then hopefully I'll I'll make it in

42
00:01:46,240 --> 00:01:51,439
time to have a unified view of that and

43
00:01:49,280 --> 00:01:53,119
if we have time we'll talk a bit about

44
00:01:51,439 --> 00:01:55,119
what is happening from the edge in the

45
00:01:53,119 --> 00:01:58,079
data center and what we can say about

46
00:01:55,119 --> 00:02:00,479
the edge from the data set. Okay, so we

47
00:01:58,079 --> 00:02:02,240
have a packed agenda.

48
00:02:00,479 --> 00:02:04,240
Let's start with where we are, right? So

49
00:02:02,240 --> 00:02:07,280
instead of talking about today, let's go

50
00:02:04,240 --> 00:02:11,200
exactly almost to the day, a year back,

51
00:02:07,280 --> 00:02:15,360
right? So a year back at Google, roughly

52
00:02:11,200 --> 00:02:18,400
a quarter of the code was generated,

53
00:02:15,360 --> 00:02:21,040
note generated. This doesn't say how

54
00:02:18,400 --> 00:02:24,000
good it was. This doesn't say how useful

55
00:02:21,040 --> 00:02:27,120
it is. So generated and then reviewed.

56
00:02:24,000 --> 00:02:30,239
If that is the case, we can ask okay in

57
00:02:27,120 --> 00:02:32,400
the software domain

58
00:02:30,239 --> 00:02:34,400
that was the case a year ago. What has h

59
00:02:32,400 --> 00:02:38,400
been happening across industry? And this

60
00:02:34,400 --> 00:02:40,640
is data from the US Bureau of Census.

61
00:02:38,400 --> 00:02:43,120
What you're seeing in orange is the

62
00:02:40,640 --> 00:02:46,160
actual reported usage. Again, not

63
00:02:43,120 --> 00:02:48,239
productivity, but actual usage and the

64
00:02:46,160 --> 00:02:50,720
prediction at the same moment in time

65
00:02:48,239 --> 00:02:52,560
shifted such that we can see how well do

66
00:02:50,720 --> 00:02:57,680
people actually predict. So this started

67
00:02:52,560 --> 00:03:00,000
at 4% around 2023 mid year. We're now

68
00:02:57,680 --> 00:03:02,800
predicting in half a year 14% and this

69
00:03:00,000 --> 00:03:07,280
is industrywide. This is general. So

70
00:03:02,800 --> 00:03:10,319
this was anecdotal usage in a Google. So

71
00:03:07,280 --> 00:03:13,680
you know a very very narrow this is

72
00:03:10,319 --> 00:03:16,080
industrywide. Okay. So so we have the

73
00:03:13,680 --> 00:03:19,120
view. Now we can ask the question of hey

74
00:03:16,080 --> 00:03:21,440
okay this is being used how much

75
00:03:19,120 --> 00:03:24,480
productivity is it driving? Okay. So

76
00:03:21,440 --> 00:03:26,159
again in the narrow view of software so

77
00:03:24,480 --> 00:03:28,000
you can see it's definitely saving time

78
00:03:26,159 --> 00:03:31,840
in generating code but it's creating

79
00:03:28,000 --> 00:03:34,000
many other categories of work

80
00:03:31,840 --> 00:03:37,120
in the sense of the tasks that need to

81
00:03:34,000 --> 00:03:40,319
be done by using this and today we are

82
00:03:37,120 --> 00:03:42,239
still at the you know working this out

83
00:03:40,319 --> 00:03:43,599
in terms of the net effect but we are

84
00:03:42,239 --> 00:03:45,280
definitely progressing and you can ask

85
00:03:43,599 --> 00:03:47,920
the same question this is very very

86
00:03:45,280 --> 00:03:51,519
recent a couple of days ago from open

87
00:03:47,920 --> 00:03:54,959
AAI where they released 44 four tasks

88
00:03:51,519 --> 00:03:58,000
and evaluated a question of

89
00:03:54,959 --> 00:04:00,879
for a different models. How do those

90
00:03:58,000 --> 00:04:04,319
models fare in their answers relative to

91
00:04:00,879 --> 00:04:05,920
a industry expert as judged by experts?

92
00:04:04,319 --> 00:04:09,360
And we're making different progress

93
00:04:05,920 --> 00:04:11,360
across broad areas there. Okay, let's

94
00:04:09,360 --> 00:04:14,560
talk about money a bit, right? And the

95
00:04:11,360 --> 00:04:16,400
numbers may seem detached or may seem

96
00:04:14,560 --> 00:04:18,880
very very

97
00:04:16,400 --> 00:04:20,880
logical depending on understanding what

98
00:04:18,880 --> 00:04:24,160
they are driving. Right? So this is a

99
00:04:20,880 --> 00:04:27,680
rough timeline to give you a sense

100
00:04:24,160 --> 00:04:31,199
of the scale. Right? So 65 billion

101
00:04:27,680 --> 00:04:34,960
dollars already this year commitment of

102
00:04:31,199 --> 00:04:39,759
hundreds of billion more. And this is

103
00:04:34,960 --> 00:04:43,280
driven by the voracious appetite of

104
00:04:39,759 --> 00:04:47,440
compute. You know, a single training run

105
00:04:43,280 --> 00:04:50,240
even without accounting uh to uh the

106
00:04:47,440 --> 00:04:53,040
overhead in organizing the data easily

107
00:04:50,240 --> 00:04:56,240
scaled from the hundreds of millions to

108
00:04:53,040 --> 00:04:59,120
the billion scale already.

109
00:04:56,240 --> 00:05:02,080
Okay. How did we get here?

110
00:04:59,120 --> 00:05:03,520
And how do we have this confidence of

111
00:05:02,080 --> 00:05:05,759
saying okay we're going to invest this

112
00:05:03,520 --> 00:05:07,600
and this will be a worthwhile investment

113
00:05:05,759 --> 00:05:11,680
right building data centers to the tune

114
00:05:07,600 --> 00:05:14,000
of you know things that are approaching

115
00:05:11,680 --> 00:05:15,759
the trillions of dollars in expected

116
00:05:14,000 --> 00:05:17,440
spending.

117
00:05:15,759 --> 00:05:20,479
So this might be the most important

118
00:05:17,440 --> 00:05:24,080
moment here. There were many but one of

119
00:05:20,479 --> 00:05:25,840
them was this idea of tell me again

120
00:05:24,080 --> 00:05:28,240
before you build something before you

121
00:05:25,840 --> 00:05:30,800
train these models before you you deploy

122
00:05:28,240 --> 00:05:32,080
a model what would be its performance as

123
00:05:30,800 --> 00:05:33,840
a function of the amount of capital

124
00:05:32,080 --> 00:05:36,320
amount of compute to invest and please

125
00:05:33,840 --> 00:05:38,320
do so before you train the model and to

126
00:05:36,320 --> 00:05:41,120
the tune of billions of dollars okay so

127
00:05:38,320 --> 00:05:43,759
if that sounds like a big ask in 2019

128
00:05:41,120 --> 00:05:45,440
here at MIT we answered that for the

129
00:05:43,759 --> 00:05:48,000
first time in a constructive fashion

130
00:05:45,440 --> 00:05:52,240
what you're seeing on the left side is

131
00:05:48,000 --> 00:05:55,520
the expected versus the actual loss of

132
00:05:52,240 --> 00:05:58,800
models as extrapolated

133
00:05:55,520 --> 00:06:01,039
100x into the future as it were into

134
00:05:58,800 --> 00:06:05,520
larger compute. So this these red dots

135
00:06:01,039 --> 00:06:07,199
here are models that were predicted to

136
00:06:05,520 --> 00:06:10,560
to have a certain performance before

137
00:06:07,199 --> 00:06:13,039
trained and uh indeed they had in both

138
00:06:10,560 --> 00:06:16,160
language domain and vision. This was

139
00:06:13,039 --> 00:06:20,960
scaled massively then by industry.

140
00:06:16,160 --> 00:06:24,080
If this was 2019 here at MIT, then by

141
00:06:20,960 --> 00:06:27,520
2023 extrapolation

142
00:06:24,080 --> 00:06:29,360
was done four orders of magnitude into

143
00:06:27,520 --> 00:06:31,360
the future

144
00:06:29,360 --> 00:06:33,039
and I won't go into all the details but

145
00:06:31,360 --> 00:06:37,280
this has been progressing very very

146
00:06:33,039 --> 00:06:39,360
quickly. So if in 2019 we had the first

147
00:06:37,280 --> 00:06:41,360
scaling laws for training and then they

148
00:06:39,360 --> 00:06:46,000
were expanded throughout the industry at

149
00:06:41,360 --> 00:06:49,199
very large scale. um by 2023 we're at

150
00:06:46,000 --> 00:06:51,360
the inference scaling regime. At 2024

151
00:06:49,199 --> 00:06:55,039
we're talking about data exhaustion.

152
00:06:51,360 --> 00:06:57,120
Today we are inching into

153
00:06:55,039 --> 00:06:59,919
the maturation or early inroads of

154
00:06:57,120 --> 00:07:04,800
agents but more quintessentially this

155
00:06:59,919 --> 00:07:06,479
idea of experiential or systems that

156
00:07:04,800 --> 00:07:08,800
learn through interaction with the real

157
00:07:06,479 --> 00:07:10,800
world and not necessarily by collecting

158
00:07:08,800 --> 00:07:12,319
the entirety of the internet or to the

159
00:07:10,800 --> 00:07:16,400
universe.

160
00:07:12,319 --> 00:07:17,759
What is a scaling law? What do we scale?

161
00:07:16,400 --> 00:07:20,240
There's the amount of data or

162
00:07:17,759 --> 00:07:23,199
experience. There's the size of the

163
00:07:20,240 --> 00:07:26,319
model. Together, they determine the

164
00:07:23,199 --> 00:07:28,319
error. And there is an optimal curve

165
00:07:26,319 --> 00:07:31,120
which is defines the amount of compute

166
00:07:28,319 --> 00:07:35,199
that we need. If you take that optimal C

167
00:07:31,120 --> 00:07:36,960
curve and you ask what how quickly does

168
00:07:35,199 --> 00:07:40,000
that

169
00:07:36,960 --> 00:07:42,720
actually reduce the loss what you're

170
00:07:40,000 --> 00:07:46,800
seeing here are different training runs

171
00:07:42,720 --> 00:07:48,960
smaller models with data you get this

172
00:07:46,800 --> 00:07:51,360
power law okay so that allows us to

173
00:07:48,960 --> 00:07:53,840
predict now this has been shown again

174
00:07:51,360 --> 00:07:56,400
and again to hold across different

175
00:07:53,840 --> 00:07:58,560
domains but different domains have very

176
00:07:56,400 --> 00:08:01,199
very different characteristics if in

177
00:07:58,560 --> 00:08:04,400
language you need to the tune of a

178
00:08:01,199 --> 00:08:07,280
million x in order to have the the loss

179
00:08:04,400 --> 00:08:10,240
in other domains it's less

180
00:08:07,280 --> 00:08:13,440
and not everything actually scales so

181
00:08:10,240 --> 00:08:16,960
nicely some things saturate before okay

182
00:08:13,440 --> 00:08:19,039
so from laws of the physics of what

183
00:08:16,960 --> 00:08:21,520
determines loss again I don't really

184
00:08:19,039 --> 00:08:23,120
care about loss right you can ask your

185
00:08:21,520 --> 00:08:25,039
latest

186
00:08:23,120 --> 00:08:27,599
AI assistant what is your loss and that

187
00:08:25,039 --> 00:08:29,280
might not be a very useful answer we

188
00:08:27,599 --> 00:08:30,879
want to talk about the underlying ing

189
00:08:29,280 --> 00:08:32,640
technical laws that are governing this

190
00:08:30,879 --> 00:08:35,519
industry. So think the equivalent of

191
00:08:32,640 --> 00:08:39,360
Moore's law but now in our context. So

192
00:08:35,519 --> 00:08:42,680
what I'm showing here is a top envelope

193
00:08:39,360 --> 00:08:42,680
in Nvidia

194
00:08:42,800 --> 00:08:48,640
GPUs from 2009 to

195
00:08:46,959 --> 00:08:50,560
2023.

196
00:08:48,640 --> 00:08:54,240
And what we have is actually an

197
00:08:50,560 --> 00:08:56,240
exponential increase in

198
00:08:54,240 --> 00:08:58,240
compute.

199
00:08:56,240 --> 00:08:59,600
And you see that's for a different

200
00:08:58,240 --> 00:09:03,200
precision. Well, I'll show in a second

201
00:08:59,600 --> 00:09:06,880
what that means. But also of the energy

202
00:09:03,200 --> 00:09:08,640
consumption, the price to an extent, but

203
00:09:06,880 --> 00:09:10,800
computer actually grows much much faster

204
00:09:08,640 --> 00:09:15,440
than everything else. Right? So with a a

205
00:09:10,800 --> 00:09:17,360
a very high clip and that is explained

206
00:09:15,440 --> 00:09:22,080
here. We can take a different look by a

207
00:09:17,360 --> 00:09:24,000
composite effect of both the actual um

208
00:09:22,080 --> 00:09:27,120
performance

209
00:09:24,000 --> 00:09:29,040
for a certain type of computation a

210
00:09:27,120 --> 00:09:31,440
floatingoint operation and then an

211
00:09:29,040 --> 00:09:34,480
advancement of what an operation

212
00:09:31,440 --> 00:09:37,760
operation actually means as we move to

213
00:09:34,480 --> 00:09:39,760
uh quantization methods and others.

214
00:09:37,760 --> 00:09:41,920
Okay, if that was the device, what is

215
00:09:39,760 --> 00:09:45,839
happening at the data center level? So

216
00:09:41,920 --> 00:09:49,920
what you're seeing here is training

217
00:09:45,839 --> 00:09:53,680
intensity. Okay, so think of this as the

218
00:09:49,920 --> 00:09:55,760
operations per second, right? So we have

219
00:09:53,680 --> 00:10:00,680
here

220
00:09:55,760 --> 00:10:00,680
over time and I'm showing two

221
00:10:01,760 --> 00:10:07,040
views of the same thing of the models

222
00:10:05,200 --> 00:10:08,640
and how much

223
00:10:07,040 --> 00:10:11,360
operations did they require in their

224
00:10:08,640 --> 00:10:13,360
training and correspondently how much

225
00:10:11,360 --> 00:10:16,480
energy

226
00:10:13,360 --> 00:10:19,120
did they sorry what was the peak power

227
00:10:16,480 --> 00:10:22,160
consumption corresponding to that and

228
00:10:19,120 --> 00:10:25,839
these handsomely fit on exponential

229
00:10:22,160 --> 00:10:29,279
curves and this gap between them is a

230
00:10:25,839 --> 00:10:34,160
efficiency gap or if you will a increase

231
00:10:29,279 --> 00:10:36,640
in efficiency over time okay so both

232
00:10:34,160 --> 00:10:38,800
energy is scaled as we well

233
00:10:36,640 --> 00:10:41,760
Right. This is at the watt. So here

234
00:10:38,800 --> 00:10:45,760
we're talking about

235
00:10:41,760 --> 00:10:48,480
many many megawws and the compute per

236
00:10:45,760 --> 00:10:51,440
watt also increases exponentially. Now

237
00:10:48,480 --> 00:10:53,360
you could ask okay if that is the inputs

238
00:10:51,440 --> 00:10:56,480
in terms of energy and then the useful

239
00:10:53,360 --> 00:10:58,160
computation relative to that energy what

240
00:10:56,480 --> 00:11:01,519
happens in terms of what we call

241
00:10:58,160 --> 00:11:06,240
algorithmic efficiency. How quickly does

242
00:11:01,519 --> 00:11:08,800
computation actually translate to a to a

243
00:11:06,240 --> 00:11:11,279
a performance improvement? So you can

244
00:11:08,800 --> 00:11:13,200
for example if we hold over in time the

245
00:11:11,279 --> 00:11:15,519
performance constant and ask how much

246
00:11:13,200 --> 00:11:18,320
compute did this require we discover

247
00:11:15,519 --> 00:11:21,200
that the required computation

248
00:11:18,320 --> 00:11:22,560
is also exponentially dropping. Okay. So

249
00:11:21,200 --> 00:11:26,800
both things are happening at the same

250
00:11:22,560 --> 00:11:29,360
time. both we have more energy with

251
00:11:26,800 --> 00:11:32,079
exponentially more compute per energy

252
00:11:29,360 --> 00:11:34,880
and exponentially decreasing compute

253
00:11:32,079 --> 00:11:38,320
needed for a given performance level. So

254
00:11:34,880 --> 00:11:40,959
this is a a dance of exponents. What

255
00:11:38,320 --> 00:11:42,959
happens as you increase the models? We

256
00:11:40,959 --> 00:11:44,959
move from loss to actual things that we

257
00:11:42,959 --> 00:11:48,240
care about here on different benchmarks

258
00:11:44,959 --> 00:11:50,160
in terms of completeness of tasks. You

259
00:11:48,240 --> 00:11:54,480
see that

260
00:11:50,160 --> 00:11:56,399
it takes a short while for the same

261
00:11:54,480 --> 00:11:59,200
level of benchmark. each one of these

262
00:11:56,399 --> 00:12:03,360
scenaries is a certain difficulty level

263
00:11:59,200 --> 00:12:05,440
within a benchmark to be solved by a

264
00:12:03,360 --> 00:12:07,760
smaller and smaller models. Okay, so

265
00:12:05,440 --> 00:12:09,920
over time this is the different view but

266
00:12:07,760 --> 00:12:12,480
now in the things that we care about

267
00:12:09,920 --> 00:12:15,600
demonstrating that smaller models become

268
00:12:12,480 --> 00:12:18,160
capable at solving what a moment ago was

269
00:12:15,600 --> 00:12:20,560
solved by larger models.

270
00:12:18,160 --> 00:12:22,560
Okay, so this is technical what is

271
00:12:20,560 --> 00:12:25,279
happening on the market side. We have a

272
00:12:22,560 --> 00:12:29,760
Pareto where we can trade off the

273
00:12:25,279 --> 00:12:33,519
performance versus a cost per token and

274
00:12:29,760 --> 00:12:36,959
we can ask for a given benchmark across

275
00:12:33,519 --> 00:12:38,720
all benchmarks or tasks. What would be

276
00:12:36,959 --> 00:12:41,680
the

277
00:12:38,720 --> 00:12:43,600
win rate of a model relative to a

278
00:12:41,680 --> 00:12:45,360
different model? So if we compare two

279
00:12:43,600 --> 00:12:47,760
models of the same size at the same

280
00:12:45,360 --> 00:12:50,800
moment in time, win rate will be by

281
00:12:47,760 --> 00:12:54,320
definition 50. If we take a model which

282
00:12:50,800 --> 00:12:57,519
is 10 times as large as its neighbor at

283
00:12:54,320 --> 00:13:02,160
the same time then win rate goes to 90

284
00:12:57,519 --> 00:13:05,680
79%. If we go all the way to 100x then

285
00:13:02,160 --> 00:13:08,000
we're at 94%. Not 100 but 94. That's in

286
00:13:05,680 --> 00:13:10,399
a moment in time. Does this mean that

287
00:13:08,000 --> 00:13:13,200
from a market perspective you can hold

288
00:13:10,399 --> 00:13:15,760
market share? Well, the answer is no

289
00:13:13,200 --> 00:13:17,920
because things become very very quickly

290
00:13:15,760 --> 00:13:20,480
abs obsolete.

291
00:13:17,920 --> 00:13:23,120
If you took the model today and compared

292
00:13:20,480 --> 00:13:28,800
it with a model of the same size in one

293
00:13:23,120 --> 00:13:31,920
year, you'd already be losing 90% of the

294
00:13:28,800 --> 00:13:34,880
time. Two years in, 7% of the time. Even

295
00:13:31,920 --> 00:13:38,720
if you compare a model today which is

296
00:13:34,880 --> 00:13:41,839
100x larger than a model in to in a year

297
00:13:38,720 --> 00:13:43,760
or two, you very very quickly lose

298
00:13:41,839 --> 00:13:46,639
market share.

299
00:13:43,760 --> 00:13:49,040
Okay.

300
00:13:46,639 --> 00:13:51,680
So what's actually explaining the final

301
00:13:49,040 --> 00:13:54,079
piece? The final piece is we talked in

302
00:13:51,680 --> 00:13:55,680
so so this might sound very familiar.

303
00:13:54,079 --> 00:13:59,279
There are benchmarks but we actually

304
00:13:55,680 --> 00:14:02,880
care about useful tasks and we want to

305
00:13:59,279 --> 00:14:06,079
quantify that. So imagine for a second

306
00:14:02,880 --> 00:14:08,880
the most simplistic

307
00:14:06,079 --> 00:14:10,800
explanation to what is governing the

308
00:14:08,880 --> 00:14:12,959
performance evolution of models. There

309
00:14:10,800 --> 00:14:16,480
are tasks in the world and let's uh for

310
00:14:12,959 --> 00:14:18,720
a second define a task by the

311
00:14:16,480 --> 00:14:21,199
the number of steps that it takes to

312
00:14:18,720 --> 00:14:24,000
complete it. and assume for a second the

313
00:14:21,199 --> 00:14:25,920
simplest version of the world where the

314
00:14:24,000 --> 00:14:28,639
probability of failure of a model or an

315
00:14:25,920 --> 00:14:32,320
AI system I should say at every given

316
00:14:28,639 --> 00:14:34,320
step or every unit interval is constant

317
00:14:32,320 --> 00:14:36,800
there's a failure rate that means that

318
00:14:34,320 --> 00:14:40,079
if it's a 5% failure rate if there's one

319
00:14:36,800 --> 00:14:44,320
step then the probability of success

320
00:14:40,079 --> 00:14:47,519
would be 95% if it involves two steps or

321
00:14:44,320 --> 00:14:50,000
two durations that compounds right we're

322
00:14:47,519 --> 00:14:54,000
already at 90% at three steps steps or

323
00:14:50,000 --> 00:14:56,320
at 86. This falls very very quickly

324
00:14:54,000 --> 00:15:00,480
and you can actually measure that if you

325
00:14:56,320 --> 00:15:04,959
take tasks and you annotate them by this

326
00:15:00,480 --> 00:15:06,320
is an amazing work by quiet takes real

327
00:15:04,959 --> 00:15:10,079
real tasks. this isn't the software

328
00:15:06,320 --> 00:15:12,240
domain and you bin them by the length it

329
00:15:10,079 --> 00:15:14,000
of time it would take a human to perform

330
00:15:12,240 --> 00:15:17,360
that task and then you ask for different

331
00:15:14,000 --> 00:15:21,440
models how well do they perform on

332
00:15:17,360 --> 00:15:24,720
different tasks length right and you get

333
00:15:21,440 --> 00:15:26,480
this uh very rapid decline with the task

334
00:15:24,720 --> 00:15:28,160
length

335
00:15:26,480 --> 00:15:30,720
which agrees quite well with our

336
00:15:28,160 --> 00:15:33,279
simplistic model before and then you can

337
00:15:30,720 --> 00:15:37,920
ask okay so for different models as they

338
00:15:33,279 --> 00:15:41,279
were released what Is this median?

339
00:15:37,920 --> 00:15:44,880
What is Let's say that we take the 50%

340
00:15:41,279 --> 00:15:50,079
success rate. What would be the how

341
00:15:44,880 --> 00:15:51,759
would this 50% success rate or the 90%

342
00:15:50,079 --> 00:15:54,720
choose a point here? Let's choose the

343
00:15:51,759 --> 00:15:55,920
the 80%. How does this evolve over time?

344
00:15:54,720 --> 00:15:58,160
Because that's the thing that we really

345
00:15:55,920 --> 00:16:00,320
care about. How long of a task and at

346
00:15:58,160 --> 00:16:03,279
what success rate can these systems

347
00:16:00,320 --> 00:16:05,120
actually solve? you find that that too

348
00:16:03,279 --> 00:16:07,440
amazingly

349
00:16:05,120 --> 00:16:10,480
grows exponentially. Again to explain

350
00:16:07,440 --> 00:16:13,759
the x-axis is time in years and we're

351
00:16:10,480 --> 00:16:17,440
looking at the 50%

352
00:16:13,759 --> 00:16:19,199
success rate and we ask what was the

353
00:16:17,440 --> 00:16:21,680
length of task for which a model

354
00:16:19,199 --> 00:16:23,920
succeeded half of the time that grows

355
00:16:21,680 --> 00:16:26,880
with a doubling time of roughly 7

356
00:16:23,920 --> 00:16:31,120
months. Okay, that means that if you

357
00:16:26,880 --> 00:16:35,519
have a model succeeding at 90% today for

358
00:16:31,120 --> 00:16:38,880
a task that takes half an hour in just

359
00:16:35,519 --> 00:16:40,720
over half a year it will be cap as

360
00:16:38,880 --> 00:16:44,000
capable in tasks which are twice as

361
00:16:40,720 --> 00:16:47,279
long. Okay, so that's what's empirically

362
00:16:44,000 --> 00:16:49,759
going on. And you can actually

363
00:16:47,279 --> 00:16:53,360
show that for it's a bit faint here, but

364
00:16:49,759 --> 00:16:55,120
for the 80% empirical success rate and

365
00:16:53,360 --> 00:16:58,959
you can ask how long does it take me to

366
00:16:55,120 --> 00:17:02,000
move from 90% to 99 to 99.19

367
00:16:58,959 --> 00:17:03,920
and at the current rate it's roughly uh

368
00:17:02,000 --> 00:17:06,720
two years

369
00:17:03,920 --> 00:17:09,120
and correspondingly also doubling the

370
00:17:06,720 --> 00:17:11,520
lengthing performance of the task that

371
00:17:09,120 --> 00:17:13,039
it can complete. This is very very quick

372
00:17:11,520 --> 00:17:16,720
and this is again the thing that we

373
00:17:13,039 --> 00:17:19,679
actually care about. Okay, I have 12

374
00:17:16,720 --> 00:17:22,000
minutes and I expect this will generate

375
00:17:19,679 --> 00:17:25,439
a lot of questions. So I'm going to try

376
00:17:22,000 --> 00:17:27,120
to put it all together. This is what we

377
00:17:25,439 --> 00:17:31,440
talked about up until now very very

378
00:17:27,120 --> 00:17:32,960
quantitatively. Okay, we know that for a

379
00:17:31,440 --> 00:17:34,559
given class category, right? We know

380
00:17:32,960 --> 00:17:36,720
that in different domains we have

381
00:17:34,559 --> 00:17:39,679
different learning efficiencies. We saw

382
00:17:36,720 --> 00:17:42,720
you know ranges between 40x to 100 to a

383
00:17:39,679 --> 00:17:45,840
million x in compute across domains. But

384
00:17:42,720 --> 00:17:49,200
in a domain we know

385
00:17:45,840 --> 00:17:52,400
this number. We know we just sh looked

386
00:17:49,200 --> 00:17:55,280
at the software doubling time and it was

387
00:17:52,400 --> 00:17:57,200
doubling every seven months.

388
00:17:55,280 --> 00:17:59,679
We also know what the algorithmic

389
00:17:57,200 --> 00:18:01,600
efficiency is because we can measure how

390
00:17:59,679 --> 00:18:04,480
quickly

391
00:18:01,600 --> 00:18:07,039
the same model sorry the same

392
00:18:04,480 --> 00:18:10,559
performance can be uh generated as a

393
00:18:07,039 --> 00:18:13,039
function of compute. We covered that

394
00:18:10,559 --> 00:18:16,240
power efficiency at the device and at

395
00:18:13,039 --> 00:18:19,200
the uh data center uh level. We know

396
00:18:16,240 --> 00:18:21,280
this and we control how much we build

397
00:18:19,200 --> 00:18:23,120
and currently we are building at an

398
00:18:21,280 --> 00:18:25,360
exponential rate. Okay. But this is a

399
00:18:23,120 --> 00:18:28,000
matter of choice. So we know all of

400
00:18:25,360 --> 00:18:29,600
these. This is a domain specific thing.

401
00:18:28,000 --> 00:18:32,000
We basically have everything that we

402
00:18:29,600 --> 00:18:34,720
need in order to put everything in the

403
00:18:32,000 --> 00:18:36,240
equivalent of a road map of how to

404
00:18:34,720 --> 00:18:38,400
navigate and make choices in this

405
00:18:36,240 --> 00:18:41,120
industry or in the data center. And it

406
00:18:38,400 --> 00:18:42,799
looks something like this. Okay. So on

407
00:18:41,120 --> 00:18:46,880
the

408
00:18:42,799 --> 00:18:50,720
y-axis we have the amount of compute.

409
00:18:46,880 --> 00:18:53,840
Okay. Um on the

410
00:18:50,720 --> 00:18:58,080
x-axis we have again time

411
00:18:53,840 --> 00:19:01,600
here is shown again the compute buildout

412
00:18:58,080 --> 00:19:04,480
for the models up to a bit earlier this

413
00:19:01,600 --> 00:19:07,039
year. Okay. So we're seeing the compute

414
00:19:04,480 --> 00:19:10,240
versus time with the actual uh models at

415
00:19:07,039 --> 00:19:13,600
the end here. I think is

416
00:19:10,240 --> 00:19:16,960
this is gro 3 probably uh in terms just

417
00:19:13,600 --> 00:19:19,360
to calibrate on the uh time. Okay. So

418
00:19:16,960 --> 00:19:20,960
this is actual compute buildout. Now we

419
00:19:19,360 --> 00:19:24,960
said two things are happening at the

420
00:19:20,960 --> 00:19:28,240
same time. We have an exponential

421
00:19:24,960 --> 00:19:31,760
increase in efficiency per watt. Okay.

422
00:19:28,240 --> 00:19:33,440
So if this is the ISO power contour

423
00:19:31,760 --> 00:19:37,679
meaning this is a buildout to the tune

424
00:19:33,440 --> 00:19:40,960
of 10 megaww then over time efficiency

425
00:19:37,679 --> 00:19:44,320
will drive the amount of computation on

426
00:19:40,960 --> 00:19:46,080
that uh energy contour. Okay. And at the

427
00:19:44,320 --> 00:19:49,120
same time we have the algorithmic

428
00:19:46,080 --> 00:19:52,240
efficiency which is four different task

429
00:19:49,120 --> 00:19:54,559
horizons. So this is 3.6 seconds. This

430
00:19:52,240 --> 00:19:57,360
is times 10, right? 36 seconds, 6

431
00:19:54,559 --> 00:20:01,120
minutes. So each one of these is a

432
00:19:57,360 --> 00:20:04,240
successful completion at a given rate of

433
00:20:01,120 --> 00:20:06,720
a task which takes 10 times as long.

434
00:20:04,240 --> 00:20:10,559
That too is dropping at an exponential

435
00:20:06,720 --> 00:20:14,240
rate. Meaning that if we hold everything

436
00:20:10,559 --> 00:20:16,640
constant, we will be able to that's the

437
00:20:14,240 --> 00:20:18,480
seven months doubling time that we saw

438
00:20:16,640 --> 00:20:21,360
before. Meaning that this is our design.

439
00:20:18,480 --> 00:20:23,760
If we want to say okay I want to know

440
00:20:21,360 --> 00:20:28,480
what my performance will be blue curve

441
00:20:23,760 --> 00:20:31,120
if I invest this amount of energy over

442
00:20:28,480 --> 00:20:33,360
for this horizon assuming that energy

443
00:20:31,120 --> 00:20:37,440
efficiency we will land here. Now the

444
00:20:33,360 --> 00:20:42,240
the slopes are pretty wild. You can look

445
00:20:37,440 --> 00:20:44,240
this is up to 20 35

446
00:20:42,240 --> 00:20:47,760
and these are two orders of magnitude

447
00:20:44,240 --> 00:20:51,360
between ISO power. Okay. So this is a

448
00:20:47,760 --> 00:20:55,679
single device level to

449
00:20:51,360 --> 00:20:58,400
100 of those to 10,000 terminal. So this

450
00:20:55,679 --> 00:21:01,520
is the gigawatt level

451
00:20:58,400 --> 00:21:03,440
and time is closing by virtue of the

452
00:21:01,520 --> 00:21:06,159
intersection of algorithmic efficiency

453
00:21:03,440 --> 00:21:11,120
and energy efficiency these gaps very

454
00:21:06,159 --> 00:21:13,360
quickly and you can say okay I I want to

455
00:21:11,120 --> 00:21:15,679
to win this and move over here and

456
00:21:13,360 --> 00:21:17,760
actually drive algorithmic efficiency

457
00:21:15,679 --> 00:21:19,840
with a buildout because I'll be able to

458
00:21:17,760 --> 00:21:22,000
make tasks

459
00:21:19,840 --> 00:21:25,039
with my systems that are much at much

460
00:21:22,000 --> 00:21:27,840
higher success rate and durations.

461
00:21:25,039 --> 00:21:30,880
Now there are limits to this thing and

462
00:21:27,840 --> 00:21:34,000
there are two fundamental limits. One is

463
00:21:30,880 --> 00:21:37,039
well you can't continue

464
00:21:34,000 --> 00:21:39,840
to get more computation out of the per

465
00:21:37,039 --> 00:21:42,400
watt at the infinitum right at some

466
00:21:39,840 --> 00:21:45,200
point there's a limit and the second one

467
00:21:42,400 --> 00:21:48,480
is well algorithmic efficiency also has

468
00:21:45,200 --> 00:21:51,840
a fundamental limit at some point I

469
00:21:48,480 --> 00:21:55,840
cannot complete the same task or task

470
00:21:51,840 --> 00:21:57,600
duration with a with less computation

471
00:21:55,840 --> 00:22:01,360
okay and it is the product of these two

472
00:21:57,600 --> 00:22:04,640
that determines or to try and

473
00:22:01,360 --> 00:22:07,280
show how to tackle just one of these. So

474
00:22:04,640 --> 00:22:10,320
let's talk a bit about the efficiency

475
00:22:07,280 --> 00:22:12,799
limits in the energetic domain. Okay, so

476
00:22:10,320 --> 00:22:16,320
again we're talking about here we have

477
00:22:12,799 --> 00:22:18,320
operations per second versus the power.

478
00:22:16,320 --> 00:22:22,480
Okay, so this is the idea of how many

479
00:22:18,320 --> 00:22:24,480
operations can we get per watt

480
00:22:22,480 --> 00:22:26,720
per second, right? Operations per second

481
00:22:24,480 --> 00:22:29,120
per watt or computations per unit

482
00:22:26,720 --> 00:22:30,640
energy. And what you're seeing here is

483
00:22:29,120 --> 00:22:35,960
the same data that we had before. So

484
00:22:30,640 --> 00:22:35,960
these are GPUs from 2008

485
00:22:36,559 --> 00:22:43,840
colored by time

486
00:22:39,039 --> 00:22:46,640
from 2000 uh sorry 2010 to 2025.

487
00:22:43,840 --> 00:22:50,000
And what you're seeing is these paral

488
00:22:46,640 --> 00:22:52,080
frontiers as we're adv advancing we can

489
00:22:50,000 --> 00:22:55,120
do more operations right this is a

490
00:22:52,080 --> 00:23:01,919
logarithmic again these are large large

491
00:22:55,120 --> 00:23:04,480
jumps every 100x per per octave here

492
00:23:01,919 --> 00:23:07,840
per grid line.

493
00:23:04,480 --> 00:23:10,480
So you're seeing this perro frontier

494
00:23:07,840 --> 00:23:13,760
where you can have very little

495
00:23:10,480 --> 00:23:15,679
operations at low energy, very many at

496
00:23:13,760 --> 00:23:17,679
high energy, but the efficiency is

497
00:23:15,679 --> 00:23:22,400
actually progressing through time. And

498
00:23:17,679 --> 00:23:26,400
these curves here are the fit of the

499
00:23:22,400 --> 00:23:28,559
of the of these frontiers. So this is up

500
00:23:26,400 --> 00:23:30,640
until where we are now. Now we can talk

501
00:23:28,559 --> 00:23:34,159
about the limit. There's a fundamental

502
00:23:30,640 --> 00:23:35,760
limit, a physical limit.

503
00:23:34,159 --> 00:23:39,120
You could question where it whether it

504
00:23:35,760 --> 00:23:41,039
is possible in principle or not. But uh

505
00:23:39,120 --> 00:23:44,880
somewhere over here there are different

506
00:23:41,039 --> 00:23:47,679
guesses of to how to account for human

507
00:23:44,880 --> 00:23:50,000
brain or other mleian brain operations

508
00:23:47,679 --> 00:23:52,400
per watt. I won't get into it. It's not

509
00:23:50,000 --> 00:23:54,720
my area of expertise. I chose here one

510
00:23:52,400 --> 00:23:57,120
such and I'll show error bars in a

511
00:23:54,720 --> 00:24:01,120
moment. But you see that assuming the

512
00:23:57,120 --> 00:24:06,720
current rate we have

513
00:24:01,120 --> 00:24:11,840
roughly. So if the last 15 years hold to

514
00:24:06,720 --> 00:24:14,559
the next 10 will close a a gap that

515
00:24:11,840 --> 00:24:16,559
might bring us comparable to some of the

516
00:24:14,559 --> 00:24:18,960
estimates of what our human brains are

517
00:24:16,559 --> 00:24:21,120
actually doing. And we're still very

518
00:24:18,960 --> 00:24:24,400
very far from the fundamental physical

519
00:24:21,120 --> 00:24:26,240
limit. So let's tie it together what we

520
00:24:24,400 --> 00:24:28,400
saw. Okay. By now this is very familiar.

521
00:24:26,240 --> 00:24:31,120
We're all singing it in our sleep

522
00:24:28,400 --> 00:24:33,840
hopefully. And now let's put the limits

523
00:24:31,120 --> 00:24:36,080
on it. So this is that limit for the 1

524
00:24:33,840 --> 00:24:38,080
kilowatt

525
00:24:36,080 --> 00:24:40,880
contour. Okay. So roughly at the scale

526
00:24:38,080 --> 00:24:43,360
of a single device. You can see here the

527
00:24:40,880 --> 00:24:45,440
single device scaling which has added

528
00:24:43,360 --> 00:24:48,240
some more power and that's why it's

529
00:24:45,440 --> 00:24:51,360
going over the efficient the net energy

530
00:24:48,240 --> 00:24:56,080
efficiency contour. You see that by

531
00:24:51,360 --> 00:24:59,279
roughly a decade from now we'll be at

532
00:24:56,080 --> 00:25:04,480
the vicinity of estimates of human brain

533
00:24:59,279 --> 00:25:06,240
efficiency and still several orders of

534
00:25:04,480 --> 00:25:10,240
magnitude from what is physically

535
00:25:06,240 --> 00:25:13,279
possible. So we have a ways to go.

536
00:25:10,240 --> 00:25:15,520
So there's room here significant room on

537
00:25:13,279 --> 00:25:18,880
the one side.

538
00:25:15,520 --> 00:25:20,480
I want to give a just a preview to I

539
00:25:18,880 --> 00:25:23,200
know that I promised five minutes. I'm

540
00:25:20,480 --> 00:25:25,520
at four for questions. I'll maybe just

541
00:25:23,200 --> 00:25:27,600
give a a short preview of how all this

542
00:25:25,520 --> 00:25:30,960
interacts between the data center and

543
00:25:27,600 --> 00:25:33,520
the edge because this is actually more

544
00:25:30,960 --> 00:25:36,000
nuanced than one might think. For

545
00:25:33,520 --> 00:25:38,320
example, if you think of we didn't talk

546
00:25:36,000 --> 00:25:41,600
about it, but the it's also the case

547
00:25:38,320 --> 00:25:43,600
that compute relative to bandwidth is is

548
00:25:41,600 --> 00:25:47,279
exploding. Now that might sound like a

549
00:25:43,600 --> 00:25:48,799
very big big challenge known as the the

550
00:25:47,279 --> 00:25:51,679
data wall, the communication wall, the

551
00:25:48,799 --> 00:25:54,640
memory wall in the data center. But you

552
00:25:51,679 --> 00:25:56,720
could ask a okay what actually happens

553
00:25:54,640 --> 00:25:59,360
when we have that to what extent

554
00:25:56,720 --> 00:26:01,279
algorithmic efficiency can drive task

555
00:25:59,360 --> 00:26:03,440
completion with less bandwidth between

556
00:26:01,279 --> 00:26:06,400
nodes. At the extreme this is what is

557
00:26:03,440 --> 00:26:09,840
happening at the at the edge. I have a

558
00:26:06,400 --> 00:26:12,880
single node with very very measly

559
00:26:09,840 --> 00:26:15,120
bandwidth to the rest of the world and I

560
00:26:12,880 --> 00:26:17,520
need to cope right

561
00:26:15,120 --> 00:26:19,919
so how does that look so one so there

562
00:26:17,520 --> 00:26:22,559
are two things to understand one let's

563
00:26:19,919 --> 00:26:27,360
take the let's extend our graph here to

564
00:26:22,559 --> 00:26:30,400
the 10 watt efficiency uh contour and in

565
00:26:27,360 --> 00:26:34,240
practice uh at the edge things have been

566
00:26:30,400 --> 00:26:35,840
moving slower uh in terms of the rate of

567
00:26:34,240 --> 00:26:38,400
exponential

568
00:26:35,840 --> 00:26:40,159
growth still exponential but that entire

569
00:26:38,400 --> 00:26:43,039
thing

570
00:26:40,159 --> 00:26:46,320
changes timelines somewhat but less than

571
00:26:43,039 --> 00:26:47,919
what one might think again because what

572
00:26:46,320 --> 00:26:49,840
we are interested in now is the

573
00:26:47,919 --> 00:26:52,159
intersection with algorithmic efficiency

574
00:26:49,840 --> 00:26:54,240
and the energetic efficiency again we

575
00:26:52,159 --> 00:26:56,640
can play this game and say okay if I

576
00:26:54,240 --> 00:27:00,159
want to have what would take on a

577
00:26:56,640 --> 00:27:03,159
gigawatt scale to reach performance in

578
00:27:00,159 --> 00:27:03,159
2020

579
00:27:03,360 --> 00:27:10,480
seven All right.

580
00:27:06,320 --> 00:27:13,440
When will that reach the 10 watt scale

581
00:27:10,480 --> 00:27:15,440
for the same level of performance?

582
00:27:13,440 --> 00:27:18,880
Okay. And we're talking things are

583
00:27:15,440 --> 00:27:22,799
progressing currently. If you

584
00:27:18,880 --> 00:27:25,840
if if what held for the last 15 years

585
00:27:22,799 --> 00:27:28,159
and accelerated actually lately would

586
00:27:25,840 --> 00:27:31,200
hold for the next

587
00:27:28,159 --> 00:27:35,440
five then we'll be at the 100 kilowatt

588
00:27:31,200 --> 00:27:37,520
or 10. will be at the uh 10 watt scale

589
00:27:35,440 --> 00:27:39,679
and at that point the difference in

590
00:27:37,520 --> 00:27:42,960
terms of energetic efficiency at the

591
00:27:39,679 --> 00:27:44,960
edge matters a lot but less again than

592
00:27:42,960 --> 00:27:47,200
what you may think so that's point one I

593
00:27:44,960 --> 00:27:49,840
wanted to make and the other one is okay

594
00:27:47,200 --> 00:27:52,159
this dynamic of having very capable

595
00:27:49,840 --> 00:27:53,840
nodes we call them the edge you can

596
00:27:52,159 --> 00:27:55,919
think of what happens in the data center

597
00:27:53,840 --> 00:27:59,039
once you reach those levels of

598
00:27:55,919 --> 00:28:02,159
performance per node okay and I left one

599
00:27:59,039 --> 00:28:05,159
minute and 30 seconds for questions Any

600
00:28:02,159 --> 00:28:05,159
questions?

601
00:28:09,200 --> 00:28:13,279
>> You mentioned uh model obsolescence, but

602
00:28:11,360 --> 00:28:14,880
any comment on hardware obsolescence and

603
00:28:13,279 --> 00:28:16,720
what kind of horizons you see in terms

604
00:28:14,880 --> 00:28:18,480
of like what's the useful life of a

605
00:28:16,720 --> 00:28:21,600
typical GPU or

606
00:28:18,480 --> 00:28:26,240
>> Yeah. So there's actually a very nice

607
00:28:21,600 --> 00:28:28,240
graph of a a

608
00:28:26,240 --> 00:28:29,760
you know generation over time in

609
00:28:28,240 --> 00:28:32,480
buildout

610
00:28:29,760 --> 00:28:36,240
and you could imagine to so so the short

611
00:28:32,480 --> 00:28:38,320
answer is in order to enjoy these energy

612
00:28:36,240 --> 00:28:40,880
efficiencies you actually need to drive

613
00:28:38,320 --> 00:28:42,640
them with novel architectures. That's a

614
00:28:40,880 --> 00:28:45,919
lot of what is happening there and the

615
00:28:42,640 --> 00:28:50,080
the clip is roughly

616
00:28:45,919 --> 00:28:53,600
is roughly doubling every 16 months at

617
00:28:50,080 --> 00:28:55,760
the aggregate uh when you include

618
00:28:53,600 --> 00:28:58,000
movement of floating pointer operations

619
00:28:55,760 --> 00:29:01,440
etc. So that gives you a sense of the

620
00:28:58,000 --> 00:29:04,080
the cycle time right call it a year and

621
00:29:01,440 --> 00:29:05,760
something and then the hardware

622
00:29:04,080 --> 00:29:09,120
efficiencies

623
00:29:05,760 --> 00:29:11,039
are at the scale of doubling every two

624
00:29:09,120 --> 00:29:13,679
or so years. So that gives you a sense

625
00:29:11,039 --> 00:29:16,000
of sort of technological node. Okay.

626
00:29:13,679 --> 00:29:17,679
However, if you look at buildout and I

627
00:29:16,000 --> 00:29:22,000
don't have it here, you actually see

628
00:29:17,679 --> 00:29:25,200
this titration. You have a you have sort

629
00:29:22,000 --> 00:29:27,039
of a the a

630
00:29:25,200 --> 00:29:29,840
an exponentially larger buildout with

631
00:29:27,039 --> 00:29:32,159
the new nodes, but still the nodes

632
00:29:29,840 --> 00:29:35,120
previously lingering on and making

633
00:29:32,159 --> 00:29:37,279
useful work. And that should not come as

634
00:29:35,120 --> 00:29:39,360
a surprise because again algorithmic

635
00:29:37,279 --> 00:29:42,159
efficiency is actually allowing us to

636
00:29:39,360 --> 00:29:44,000
get much more. Your phone currently can

637
00:29:42,159 --> 00:29:46,240
do things that you didn't imagine that

638
00:29:44,000 --> 00:29:47,760
it can would have been able to do a mere

639
00:29:46,240 --> 00:29:50,760
two years ago and you haven't switched

640
00:29:47,760 --> 00:29:50,760
it.

641
00:29:52,080 --> 00:29:56,279
>> All right, one more quick question.

642
00:29:56,640 --> 00:30:02,720
>> Hi. Um I find the uh benchmarking of the

643
00:30:00,080 --> 00:30:04,159
human brain uh against AI pretty

644
00:30:02,720 --> 00:30:06,320
interesting because there are things

645
00:30:04,159 --> 00:30:09,279
that a human brain can do that AI cannot

646
00:30:06,320 --> 00:30:11,440
and vice versa. So in a way my pocket

647
00:30:09,279 --> 00:30:14,880
calculator is smarter than the human

648
00:30:11,440 --> 00:30:16,640
brain in in terms of you know big number

649
00:30:14,880 --> 00:30:19,600
of multiplications or whatever. So so

650
00:30:16,640 --> 00:30:22,640
how do you quantify that comparison?

651
00:30:19,600 --> 00:30:25,279
>> That's a fantastic question and

652
00:30:22,640 --> 00:30:28,080
it's incredibly insightful. We are you

653
00:30:25,279 --> 00:30:31,840
know we are very very specialized

654
00:30:28,080 --> 00:30:36,399
hardware so comparing is very difficult

655
00:30:31,840 --> 00:30:39,600
I'm not claiming to I'm giving a a

656
00:30:36,399 --> 00:30:43,360
rough comparison which tries to bin or

657
00:30:39,600 --> 00:30:46,240
account for operations per second

658
00:30:43,360 --> 00:30:48,960
relative to power usage. Okay. And there

659
00:30:46,240 --> 00:30:51,919
there's a a lot of literature out there

660
00:30:48,960 --> 00:30:54,159
of how to do that bin counting.

661
00:30:51,919 --> 00:30:56,000
You're welcome to argue with it.

662
00:30:54,159 --> 00:30:57,520
But there is the the the takeaway is

663
00:30:56,000 --> 00:31:03,360
this

664
00:30:57,520 --> 00:31:05,919
basic idea of if a task is governed for

665
00:31:03,360 --> 00:31:09,120
a given architecture and we know that

666
00:31:05,919 --> 00:31:14,320
the by the amount of computation which

667
00:31:09,120 --> 00:31:19,360
in turn is governed by the amount of of

668
00:31:14,320 --> 00:31:22,399
energy per per operation or the power

669
00:31:19,360 --> 00:31:24,240
for that total uh instantaneous number

670
00:31:22,399 --> 00:31:27,200
of computations.

671
00:31:24,240 --> 00:31:29,520
then that itself is progressing

672
00:31:27,200 --> 00:31:31,279
exponentially for the class of problems

673
00:31:29,520 --> 00:31:33,120
that these things can solve. Okay,

674
00:31:31,279 --> 00:31:35,679
clearly our calculator are better at

675
00:31:33,120 --> 00:31:37,760
things. You know, models we build can

676
00:31:35,679 --> 00:31:39,840
read the genome. You know, I can't,

677
00:31:37,760 --> 00:31:41,519
maybe you can. So, it can do a lot of

678
00:31:39,840 --> 00:31:43,679
things that we can't, but there's no

679
00:31:41,519 --> 00:31:44,880
reason to think that fundamentally,

680
00:31:43,679 --> 00:31:47,600
maybe that's the thing you're alluding

681
00:31:44,880 --> 00:31:50,080
to. There's there are there's a class of

682
00:31:47,600 --> 00:31:52,960
things that we can do that we will not

683
00:31:50,080 --> 00:31:54,880
be able to reach. So that's the short

684
00:31:52,960 --> 00:31:56,640
answer is this is just bin counting as

685
00:31:54,880 --> 00:32:00,519
of operation

686
00:31:56,640 --> 00:32:00,519
per second per watt.

687
00:32:01,919 --> 00:32:06,039
Okay, let's hear it for Jonathan.


1
00:00:04,240 --> 00:00:08,720
Well, welcome back everyone. Um, like

2
00:00:06,480 --> 00:00:10,639
Nikki, I am a program director at the

3
00:00:08,720 --> 00:00:12,639
MIT office of corporate relations in the

4
00:00:10,639 --> 00:00:14,719
industrial liaison program. My name is

5
00:00:12,639 --> 00:00:16,560
Cheryl Greenberg. Um, I work with a

6
00:00:14,719 --> 00:00:20,160
number of the company people have that

7
00:00:16,560 --> 00:00:22,640
have attended today. Um, I'd like to

8
00:00:20,160 --> 00:00:25,519
introduce our next presenter, Professor

9
00:00:22,640 --> 00:00:27,519
Manolus Kellis. And if I were to ask you

10
00:00:25,519 --> 00:00:30,720
what you thought the primary research

11
00:00:27,519 --> 00:00:32,960
interest area of a professor like

12
00:00:30,720 --> 00:00:35,520
himself in the department of electrical

13
00:00:32,960 --> 00:00:36,760
engineering and computer science, you

14
00:00:35,520 --> 00:00:40,320
might guess

15
00:00:36,760 --> 00:00:42,800
wrong. So I will tell you professor

16
00:00:40,320 --> 00:00:45,280
Manolus Kellis his primary interest is

17
00:00:42,800 --> 00:00:47,120
in computational biology. So remember

18
00:00:45,280 --> 00:00:51,239
department of electrical engineering and

19
00:00:47,120 --> 00:00:53,520
computer science. In addition, he also

20
00:00:51,239 --> 00:00:54,480
develops new algorithms and machine

21
00:00:53,520 --> 00:00:56,800
learning techniques for the

22
00:00:54,480 --> 00:00:58,559
interpretation of complete genomes, the

23
00:00:56,800 --> 00:01:00,120
understanding of gene regulation and

24
00:00:58,559 --> 00:01:02,480
embryo

25
00:01:00,120 --> 00:01:05,119
development. This is along with research

26
00:01:02,480 --> 00:01:07,520
projects in machine learning, robotics,

27
00:01:05,119 --> 00:01:09,119
computational geometry, and much more.

28
00:01:07,520 --> 00:01:11,119
You can always check out his web page if

29
00:01:09,119 --> 00:01:13,439
you want to get a better sense of him.

30
00:01:11,119 --> 00:01:15,520
and today he will be speaking to you

31
00:01:13,439 --> 00:01:17,759
about AI foundation models for

32
00:01:15,520 --> 00:01:20,159
chemistry, protein structure and

33
00:01:17,759 --> 00:01:22,000
function and personalized therapeutics.

34
00:01:20,159 --> 00:01:23,759
Please join me in welcoming Professor

35
00:01:22,000 --> 00:01:26,320
Manolas Kellis. Thank you. Wonderful to

36
00:01:23,759 --> 00:01:28,159
be here.

37
00:01:26,320 --> 00:01:30,400
It's so nice to see so many familiar

38
00:01:28,159 --> 00:01:32,400
faces. So nice to see so many folks that

39
00:01:30,400 --> 00:01:34,799
we've interacted and collaborated with

40
00:01:32,400 --> 00:01:37,200
through the years. Um, what I'm going to

41
00:01:34,799 --> 00:01:40,280
tell you about today is how we use AI

42
00:01:37,200 --> 00:01:42,720
for understanding human health, for

43
00:01:40,280 --> 00:01:45,119
understanding biology and the

44
00:01:42,720 --> 00:01:47,840
foundations of biology, of chemistry, of

45
00:01:45,119 --> 00:01:52,000
protein structure, of protein function,

46
00:01:47,840 --> 00:01:54,079
and how we use that to guide both the

47
00:01:52,000 --> 00:01:56,159
what and where and how to target for

48
00:01:54,079 --> 00:01:58,200
whom, which is the genomic medicine

49
00:01:56,159 --> 00:02:00,320
part, and also how to develop new

50
00:01:58,200 --> 00:02:03,759
therapeutics, which is the therapeutic

51
00:02:00,320 --> 00:02:05,759
development part. So uh I'm a member of

52
00:02:03,759 --> 00:02:07,119
the uh computer science artificial

53
00:02:05,759 --> 00:02:10,080
intelligence lab but also a member of

54
00:02:07,119 --> 00:02:11,280
the broad institute and the first

55
00:02:10,080 --> 00:02:14,000
vertical that I'm going to be showing

56
00:02:11,280 --> 00:02:17,280
you is how to go from genomics to

57
00:02:14,000 --> 00:02:20,400
circuitry to targets to drug design and

58
00:02:17,280 --> 00:02:22,319
eventually animals and uh patients. And

59
00:02:20,400 --> 00:02:24,160
then the second one is how do we

60
00:02:22,319 --> 00:02:25,120
understand the diversity of patients?

61
00:02:24,160 --> 00:02:27,440
How do we understand patient

62
00:02:25,120 --> 00:02:30,160
trajectories? How do we understand in a

63
00:02:27,440 --> 00:02:32,560
multimodal way how to combine clinical

64
00:02:30,160 --> 00:02:34,959
notes and quantitative data and all of

65
00:02:32,560 --> 00:02:37,920
this information cutting across all of

66
00:02:34,959 --> 00:02:41,959
these different data streams to uh

67
00:02:37,920 --> 00:02:45,680
really deliver personalized precision

68
00:02:41,959 --> 00:02:50,319
medicine and the last part will be can

69
00:02:45,680 --> 00:02:54,879
we step back and see how is AI going how

70
00:02:50,319 --> 00:02:57,200
is it doing and how can we leverage AI

71
00:02:54,879 --> 00:02:59,040
as a partner ner not as a replacement.

72
00:02:57,200 --> 00:03:02,560
So a lot of people are freaked out about

73
00:02:59,040 --> 00:03:04,560
AI and that's because we've kind of

74
00:03:02,560 --> 00:03:06,800
developed an ecosystem where the humans

75
00:03:04,560 --> 00:03:10,000
are left out. So what I what I will show

76
00:03:06,800 --> 00:03:12,400
you is a new approach of visual AI that

77
00:03:10,000 --> 00:03:14,159
lifts humans up instead of replacing

78
00:03:12,400 --> 00:03:17,840
them. that basically puts you on the

79
00:03:14,159 --> 00:03:21,040
driver's seat by showing you directly

80
00:03:17,840 --> 00:03:22,959
how the AI is thinking of your data,

81
00:03:21,040 --> 00:03:24,720
making all that available and giving you

82
00:03:22,959 --> 00:03:27,200
access to sort of poke around the

83
00:03:24,720 --> 00:03:28,800
neurons and the latent representations

84
00:03:27,200 --> 00:03:31,840
which we're using for drug discovery,

85
00:03:28,800 --> 00:03:34,080
protein function and patient states.

86
00:03:31,840 --> 00:03:36,959
Medicine has really come a long way. So

87
00:03:34,080 --> 00:03:39,280
uh from treating the patients from the

88
00:03:36,959 --> 00:03:42,560
outside and you can see here an image of

89
00:03:39,280 --> 00:03:43,920
a god or maybe a temple physician. Um

90
00:03:42,560 --> 00:03:46,480
today things are very very different. No

91
00:03:43,920 --> 00:03:50,319
one will confuse a physician with god

92
00:03:46,480 --> 00:03:52,000
although you know reports might vary. Um

93
00:03:50,319 --> 00:03:53,680
and you basically have this peerreview

94
00:03:52,000 --> 00:03:55,840
committee these nurses. Actually not

95
00:03:53,680 --> 00:03:57,519
much has changed I have to say but what

96
00:03:55,840 --> 00:03:59,439
has changed is that we're treating

97
00:03:57,519 --> 00:04:01,040
patients not from the outside anymore.

98
00:03:59,439 --> 00:04:02,400
We're not simply making guesses anymore.

99
00:04:01,040 --> 00:04:04,840
It's not just about correlations

100
00:04:02,400 --> 00:04:06,480
anymore. It's not just about

101
00:04:04,840 --> 00:04:08,319
epidemiology. It's really about

102
00:04:06,480 --> 00:04:10,319
mechanism. And that changed, of course,

103
00:04:08,319 --> 00:04:13,120
with technology. What allowed us to

104
00:04:10,319 --> 00:04:15,519
change this is number one, the

105
00:04:13,120 --> 00:04:17,680
microscope, being able to actually peak

106
00:04:15,519 --> 00:04:20,400
inside the human body, look at

107
00:04:17,680 --> 00:04:23,199
individual cells, and even look inside

108
00:04:20,400 --> 00:04:26,720
those cells to recognize more than a 100

109
00:04:23,199 --> 00:04:28,160
years ago with the first diagnosis of

110
00:04:26,720 --> 00:04:30,639
Alzheimer's disease, the first

111
00:04:28,160 --> 00:04:32,560
Alzheimer's patient of Dr. Alzheimer,

112
00:04:30,639 --> 00:04:34,000
the recognition of amalloid plaques and

113
00:04:32,560 --> 00:04:37,280
tangles. And here I'm showing you at the

114
00:04:34,000 --> 00:04:39,360
bottom left two phenotypes in four

115
00:04:37,280 --> 00:04:42,560
cells. The phenotypes are amaloid

116
00:04:39,360 --> 00:04:44,080
plaques and neuropibrillary tangles. How

117
00:04:42,560 --> 00:04:49,000
far we've come. On the bottom right of

118
00:04:44,080 --> 00:04:52,560
the slide, I'm showing you 2.4 million

119
00:04:49,000 --> 00:04:55,199
cells. And every cell instead of having

120
00:04:52,560 --> 00:04:56,800
two measurements now has 20,000

121
00:04:55,199 --> 00:04:59,440
measurements. The expression of every

122
00:04:56,800 --> 00:05:01,280
single gene in the human genome. And I'm

123
00:04:59,440 --> 00:05:05,120
not showing you one or two patients. I'm

124
00:05:01,280 --> 00:05:08,360
showing you 430 patients in this

125
00:05:05,120 --> 00:05:11,000
particular slide. So every dot is a

126
00:05:08,360 --> 00:05:15,360
20,000dimensional vector which is

127
00:05:11,000 --> 00:05:17,360
projected into a two-dimensional space,

128
00:05:15,360 --> 00:05:18,639
an embedding space if you wish. And

129
00:05:17,360 --> 00:05:20,560
we're going to be using embeddings in

130
00:05:18,639 --> 00:05:23,360
the third part of the talk. So brace

131
00:05:20,560 --> 00:05:26,080
yourselves. Now, an embedding space is a

132
00:05:23,360 --> 00:05:29,280
space that preserves the pair-wise

133
00:05:26,080 --> 00:05:32,000
distances between elements in the 2D

134
00:05:29,280 --> 00:05:33,840
version, just like in the 20,000D

135
00:05:32,000 --> 00:05:36,160
version. Humans are not that great about

136
00:05:33,840 --> 00:05:37,600
visualizing 20,000 dimensional points.

137
00:05:36,160 --> 00:05:40,000
So, just for the benefit of the

138
00:05:37,600 --> 00:05:42,320
audience, we went down to 2D. Everybody

139
00:05:40,000 --> 00:05:44,520
with me here? So, what does that mean?

140
00:05:42,320 --> 00:05:48,080
It basically tells us the

141
00:05:44,520 --> 00:05:50,479
transcriptional position of every cell,

142
00:05:48,080 --> 00:05:53,039
i.e. where is that transcriptional state

143
00:05:50,479 --> 00:05:54,880
of that cell? And we can now study

144
00:05:53,039 --> 00:05:57,039
phenotypes. We can project phenotypes

145
00:05:54,880 --> 00:05:59,360
onto those cells and basically see how

146
00:05:57,039 --> 00:06:00,960
our Alzheimer's patients changing not

147
00:05:59,360 --> 00:06:02,880
just in one or two variables, not just

148
00:06:00,960 --> 00:06:05,080
in one or two genes, but in hundreds of

149
00:06:02,880 --> 00:06:08,240
genes, in all of these different

150
00:06:05,080 --> 00:06:11,160
pathways and hallmarks of the disease at

151
00:06:08,240 --> 00:06:14,319
a time. Everybody with me here? Who's

152
00:06:11,160 --> 00:06:16,720
excited? Come on. Who's excited? Yay.

153
00:06:14,319 --> 00:06:18,479
There you go. All right. So, how are we

154
00:06:16,720 --> 00:06:21,199
going to do this? We're going to do this

155
00:06:18,479 --> 00:06:22,960
using AI. And that's what I'm going to

156
00:06:21,199 --> 00:06:25,600
be telling you about. How AI can really

157
00:06:22,960 --> 00:06:26,880
help us transform both the understanding

158
00:06:25,600 --> 00:06:28,880
of disease, the understanding of

159
00:06:26,880 --> 00:06:30,319
biology, and the delivery of

160
00:06:28,880 --> 00:06:32,479
therapeutics and even the design of

161
00:06:30,319 --> 00:06:34,720
therapeutics. So, the tools are of

162
00:06:32,479 --> 00:06:37,520
course phenotypes, of course,

163
00:06:34,720 --> 00:06:39,479
transcriptional state, but also an ace

164
00:06:37,520 --> 00:06:41,360
up our sleeve is

165
00:06:39,479 --> 00:06:44,479
causality. And the quickest way to

166
00:06:41,360 --> 00:06:46,240
causality is genetics. In other words,

167
00:06:44,479 --> 00:06:48,160
if you have a genetic variant that

168
00:06:46,240 --> 00:06:50,479
correlates with the disease at 93 years

169
00:06:48,160 --> 00:06:52,400
of age and you inherited that variant

170
00:06:50,479 --> 00:06:54,240
before birth, it's unlikely to be that

171
00:06:52,400 --> 00:06:56,240
you have this variant because you ate

172
00:06:54,240 --> 00:06:59,120
more or you exercise less or you name

173
00:06:56,240 --> 00:07:01,280
it. Okay, that's the best closest

174
00:06:59,120 --> 00:07:03,599
approximation to causality that we have

175
00:07:01,280 --> 00:07:07,360
because we can find these correlations

176
00:07:03,599 --> 00:07:09,199
between genetic variation and disease.

177
00:07:07,360 --> 00:07:12,080
And because of the temporality of when I

178
00:07:09,199 --> 00:07:14,240
inherited that variant, I can now see

179
00:07:12,080 --> 00:07:16,880
what is the mechanism through which this

180
00:07:14,240 --> 00:07:19,880
genetic variant alters transcriptional

181
00:07:16,880 --> 00:07:22,400
and cellular function and then by

182
00:07:19,880 --> 00:07:25,360
extrapolation how that might actually be

183
00:07:22,400 --> 00:07:27,800
implicated in the disease mechanism and

184
00:07:25,360 --> 00:07:31,599
therefore how that can guide us to carry

185
00:07:27,800 --> 00:07:33,919
out a more mechanistic a more systematic

186
00:07:31,599 --> 00:07:35,759
a more rational approach to genomic

187
00:07:33,919 --> 00:07:39,880
medicine and therapeutic design. Who's

188
00:07:35,759 --> 00:07:43,759
with me so far? Yeah, good. Awesome.

189
00:07:39,880 --> 00:07:47,560
So, what are these new technologies?

190
00:07:43,759 --> 00:07:49,919
Number one, a major shift is going from

191
00:07:47,560 --> 00:07:51,520
hypothesisdriven research to datadriven

192
00:07:49,919 --> 00:07:52,880
research. That basically means that

193
00:07:51,520 --> 00:07:54,639
instead of just simply formulating

194
00:07:52,880 --> 00:07:56,319
hypothesis, gathering a bunch of data,

195
00:07:54,639 --> 00:07:58,400
doing all of the thinking before

196
00:07:56,319 --> 00:08:00,639
targeting the study, which basically

197
00:07:58,400 --> 00:08:03,120
gives us a highly biased with relatively

198
00:08:00,639 --> 00:08:04,960
little novelty and little ability to

199
00:08:03,120 --> 00:08:06,960
discover new things. We're instead

200
00:08:04,960 --> 00:08:09,280
seeing the shift to gather massive

201
00:08:06,960 --> 00:08:11,840
amounts of data, shoot first, ask

202
00:08:09,280 --> 00:08:13,599
questions later by building systematic

203
00:08:11,840 --> 00:08:15,199
data sets, building these resources, and

204
00:08:13,599 --> 00:08:17,759
massively sharing them in a

205
00:08:15,199 --> 00:08:20,000
comprehensive way across many different

206
00:08:17,759 --> 00:08:22,560
data modalities. The second dramatic

207
00:08:20,000 --> 00:08:24,440
shift that we're seeing is that we're

208
00:08:22,560 --> 00:08:27,120
going from correlation to

209
00:08:24,440 --> 00:08:28,879
causation. So throughout human history,

210
00:08:27,120 --> 00:08:31,199
epidemiology has been all about

211
00:08:28,879 --> 00:08:32,959
correlations. If you drink a $7

212
00:08:31,199 --> 00:08:36,399
Starbucks coffee every morning, you have

213
00:08:32,959 --> 00:08:38,399
better health outcomes. Is it because

214
00:08:36,399 --> 00:08:40,880
you probably can also afford a better

215
00:08:38,399 --> 00:08:42,479
health care, you know, more exercise,

216
00:08:40,880 --> 00:08:44,720
you know, a more steady job and you name

217
00:08:42,479 --> 00:08:46,800
it, or is it really that Starbucks is so

218
00:08:44,720 --> 00:08:49,040
awesome for you? I mean, could be both.

219
00:08:46,800 --> 00:08:50,240
Um, there's also a correlation. The

220
00:08:49,040 --> 00:08:52,560
countries that consume the most

221
00:08:50,240 --> 00:08:53,680
chocolate are also showing more Noble

222
00:08:52,560 --> 00:08:56,240
prices. We can again argue about

223
00:08:53,680 --> 00:08:59,000
correlation and causation. I'd rather

224
00:08:56,240 --> 00:09:02,480
postulate correlation.

225
00:08:59,000 --> 00:09:04,320
Um however uh with genetics we have the

226
00:09:02,480 --> 00:09:05,760
ability to now switch to causality to

227
00:09:04,320 --> 00:09:07,360
basically look at the correlation

228
00:09:05,760 --> 00:09:09,120
between genetic variance and disease

229
00:09:07,360 --> 00:09:11,519
outcomes and there's a unidirectional

230
00:09:09,120 --> 00:09:13,680
arrow there. Calculate polygenic risk

231
00:09:11,519 --> 00:09:15,200
scores for a diversity of latent

232
00:09:13,680 --> 00:09:17,360
factors. I don't need to look at

233
00:09:15,200 --> 00:09:20,560
individual variants. I can just say how

234
00:09:17,360 --> 00:09:23,360
am I predicting the complete burden on

235
00:09:20,560 --> 00:09:27,680
this particular pathway of genetic

236
00:09:23,360 --> 00:09:30,560
variance associated with a panoply of

237
00:09:27,680 --> 00:09:32,560
locations which are then converging on

238
00:09:30,560 --> 00:09:35,200
higher predicted uh I don't know

239
00:09:32,560 --> 00:09:37,120
neuronal activity which then we can

240
00:09:35,200 --> 00:09:40,080
correlate with I don't know chocolate

241
00:09:37,120 --> 00:09:41,680
and Nobel prizes and so forth. Um and

242
00:09:40,080 --> 00:09:43,760
then of course perturbation experiments

243
00:09:41,680 --> 00:09:46,240
are much easier in a cell than they are

244
00:09:43,760 --> 00:09:47,920
in a population. With I don't know

245
00:09:46,240 --> 00:09:49,760
social experiments it's very hard to say

246
00:09:47,920 --> 00:09:51,040
okay great let's put all of the kids out

247
00:09:49,760 --> 00:09:54,080
of school for two years and see what

248
00:09:51,040 --> 00:09:56,000
happens where whereas with cells it's

249
00:09:54,080 --> 00:09:58,880
much easier to sort of you know go and

250
00:09:56,000 --> 00:10:00,720
confirm this postulated causality. And

251
00:09:58,880 --> 00:10:02,880
then the third major shift which I will

252
00:10:00,720 --> 00:10:05,519
focus the last part of my talk on is

253
00:10:02,880 --> 00:10:07,120
we're going from classical data analysis

254
00:10:05,519 --> 00:10:09,120
namely where there's a new methodology

255
00:10:07,120 --> 00:10:11,120
for every problem where the human

256
00:10:09,120 --> 00:10:12,560
scientist does all the thinking and

257
00:10:11,120 --> 00:10:14,399
there's very few parameters we're trying

258
00:10:12,560 --> 00:10:17,760
to minimize the parameters and have very

259
00:10:14,399 --> 00:10:19,920
targeted models to a place where

260
00:10:17,760 --> 00:10:22,640
generative AI and deep learning and all

261
00:10:19,920 --> 00:10:25,120
of these foundation models live and

262
00:10:22,640 --> 00:10:27,360
that's the place of multimodality that's

263
00:10:25,120 --> 00:10:28,880
the place of representation learning

264
00:10:27,360 --> 00:10:31,760
that's the place of hier hierarchical

265
00:10:28,880 --> 00:10:34,000
abstractions on primary data, secondary

266
00:10:31,760 --> 00:10:36,720
abstractions, tertiary, etc. where the

267
00:10:34,000 --> 00:10:39,760
AI is actually truly understanding the

268
00:10:36,720 --> 00:10:42,320
concepts and can give us massive new

269
00:10:39,760 --> 00:10:44,240
insights. Okay, so combining all of this

270
00:10:42,320 --> 00:10:47,000
together, our team has basically taken

271
00:10:44,240 --> 00:10:51,040
on to understand first of all the

272
00:10:47,000 --> 00:10:52,959
causality underlying the most pronounced

273
00:10:51,040 --> 00:10:54,399
the strongest genetic associations with

274
00:10:52,959 --> 00:10:57,279
some of the biggest plagues in our

275
00:10:54,399 --> 00:10:58,640
society. The first is obesity. The

276
00:10:57,279 --> 00:11:02,880
strongest genetic association with

277
00:10:58,640 --> 00:11:07,680
obesity lies in the FTO locus in intron

278
00:11:02,880 --> 00:11:10,000
2 of this giant super long gene that

279
00:11:07,680 --> 00:11:14,160
turns out to be a complete red herring.

280
00:11:10,000 --> 00:11:16,600
So the FTO gene we showed is totally not

281
00:11:14,160 --> 00:11:19,519
involved in al in

282
00:11:16,600 --> 00:11:21,279
obesity even though the genetic variants

283
00:11:19,519 --> 00:11:23,680
that are truly causal sit in that gene.

284
00:11:21,279 --> 00:11:27,600
How is that possible? That's possible

285
00:11:23,680 --> 00:11:30,279
because 93% of genetic associations do

286
00:11:27,600 --> 00:11:33,480
not affect the proteins directly.

287
00:11:30,279 --> 00:11:35,920
Instead, they affect the non-coding

288
00:11:33,480 --> 00:11:38,880
regions and those non-coding regions are

289
00:11:35,920 --> 00:11:41,160
responsible for where and how and when

290
00:11:38,880 --> 00:11:44,240
the genes are actually

291
00:11:41,160 --> 00:11:46,640
active. Everybody with me here? So, what

292
00:11:44,240 --> 00:11:48,399
we found is that this genetic locus is

293
00:11:46,640 --> 00:11:51,200
in fact targeting two genes that are

294
00:11:48,399 --> 00:11:54,480
sitting 1.2 million nucleotides away.

295
00:11:51,200 --> 00:11:56,800
And those genes turned out to be newly

296
00:11:54,480 --> 00:11:59,360
discovered master regulators of a

297
00:11:56,800 --> 00:12:02,000
process known as thermogenesis. This is

298
00:11:59,360 --> 00:12:06,200
where your adipocytes instead of storing

299
00:12:02,000 --> 00:12:08,440
fat storing calories into these energy

300
00:12:06,200 --> 00:12:11,279
lies that we call

301
00:12:08,440 --> 00:12:13,839
lipids instead are depolarizing the

302
00:12:11,279 --> 00:12:16,560
mitochondrial membrane leading to a loss

303
00:12:13,839 --> 00:12:21,800
in the proton gradient and energy loss

304
00:12:16,560 --> 00:12:24,480
as heat. So by controlling the fate of

305
00:12:21,800 --> 00:12:26,040
padypiposytes into either energy burning

306
00:12:24,480 --> 00:12:29,519
or energy storing

307
00:12:26,040 --> 00:12:32,480
cells, this genetic locus causes people

308
00:12:29,519 --> 00:12:36,079
to have one standard deviation higher

309
00:12:32,480 --> 00:12:38,880
weight in adulthood. This is remarkable.

310
00:12:36,079 --> 00:12:41,920
So I'm I'm a homozygous risk carrier. So

311
00:12:38,880 --> 00:12:43,720
my entire family has been obese. I um

312
00:12:41,920 --> 00:12:45,760
you know I I haven't eaten since

313
00:12:43,720 --> 00:12:47,360
yesterday. I went to the gym this

314
00:12:45,760 --> 00:12:49,279
morning. I bike in every day. I go up

315
00:12:47,360 --> 00:12:51,200
the stairs. So yes, I you know, of

316
00:12:49,279 --> 00:12:52,560
course, environment matters. So if you

317
00:12:51,200 --> 00:12:53,920
know your genetics, you can, you know,

318
00:12:52,560 --> 00:12:55,120
either take a bunch of pills and, you

319
00:12:53,920 --> 00:12:56,480
know, that's fine. No, no problem with

320
00:12:55,120 --> 00:12:58,720
that. Or you can actually just live a

321
00:12:56,480 --> 00:13:01,519
healthier lifestyle. So anyway, I

322
00:12:58,720 --> 00:13:03,360
digress. So we were able to trace the

323
00:13:01,519 --> 00:13:05,639
strongest genetic association that spans

324
00:13:03,360 --> 00:13:09,680
50,000 nucleotides down to a single

325
00:13:05,639 --> 00:13:14,560
letter down to a T2C mutation that

326
00:13:09,680 --> 00:13:17,440
basically causes the ARID 5B repressor

327
00:13:14,560 --> 00:13:19,680
to no longer be able to repress the

328
00:13:17,440 --> 00:13:24,800
corresponding target genes that it

329
00:13:19,680 --> 00:13:28,079
normally binds and to therefore lead to

330
00:13:24,800 --> 00:13:30,320
this derression of Ryx3 and RX5. this

331
00:13:28,079 --> 00:13:33,440
derression of this master enhancer and

332
00:13:30,320 --> 00:13:34,720
the shut off of thermogenesis. So why

333
00:13:33,440 --> 00:13:36,240
are we excited about the circuitry?

334
00:13:34,720 --> 00:13:37,920
Because by understanding the circuitry,

335
00:13:36,240 --> 00:13:39,600
we can actually intervene. It's not just

336
00:13:37,920 --> 00:13:42,240
an academic exercise. Yeah, we figured

337
00:13:39,600 --> 00:13:44,959
out which is of course fun and cool. But

338
00:13:42,240 --> 00:13:46,480
uh we can actually know where to

339
00:13:44,959 --> 00:13:48,320
intervene. And I have to say a joke

340
00:13:46,480 --> 00:13:51,360
about this this MIT professor who is

341
00:13:48,320 --> 00:13:53,040
involved to uh uh to come to this

342
00:13:51,360 --> 00:13:54,880
factory that had just completely broken

343
00:13:53,040 --> 00:13:56,160
apart. Nothing was working. And then he

344
00:13:54,880 --> 00:13:59,760
spends a lot of time thinking and then

345
00:13:56,160 --> 00:14:01,760
he puts an X on the wall and then uh

346
00:13:59,760 --> 00:14:03,279
they ask him to, you know, they they

347
00:14:01,760 --> 00:14:04,399
check behind the X and indeed that's the

348
00:14:03,279 --> 00:14:05,760
that's the part that was missing. That's

349
00:14:04,399 --> 00:14:07,199
the part that was broken. They fixed it

350
00:14:05,760 --> 00:14:08,959
and then the factory that was spending

351
00:14:07,199 --> 00:14:11,279
millions of dollars in like a year was

352
00:14:08,959 --> 00:14:12,959
now back running. So then they asked for

353
00:14:11,279 --> 00:14:15,360
the itemized bill. They asked for the

354
00:14:12,959 --> 00:14:17,040
bill. He sent a $10,000 bill and they

355
00:14:15,360 --> 00:14:20,079
said, "Could you please itemize it?" And

356
00:14:17,040 --> 00:14:22,680
he said, you know, chalk $1. Knowing

357
00:14:20,079 --> 00:14:25,040
where to put the X,

358
00:14:22,680 --> 00:14:27,279
$9,999. So this is the knowing where to

359
00:14:25,040 --> 00:14:29,120
put the X part. Changing an equal side,

360
00:14:27,279 --> 00:14:30,880
no problemmo. But knowing what to where

361
00:14:29,120 --> 00:14:34,000
to put the X, that's that's where all

362
00:14:30,880 --> 00:14:35,680
the money is. Okay. So what we figured

363
00:14:34,000 --> 00:14:37,519
out is that by knowing where to put the

364
00:14:35,680 --> 00:14:40,000
X, we could change a single letter out

365
00:14:37,519 --> 00:14:41,360
of 3.2 billion letters in the genome. I

366
00:14:40,000 --> 00:14:43,360
mean, that's precision medicine right

367
00:14:41,360 --> 00:14:45,440
there, right? 3.2 billion letters. We

368
00:14:43,360 --> 00:14:47,440
choose one and we alter it. And what do

369
00:14:45,440 --> 00:14:50,399
we see? We see that we can completely

370
00:14:47,440 --> 00:14:53,680
restore thermogenesis in obesity risk

371
00:14:50,399 --> 00:14:55,360
patients by a factor of seven. and going

372
00:14:53,680 --> 00:14:57,680
into mice and changing the downstream

373
00:14:55,360 --> 00:15:01,959
target genes by deressing them. We

374
00:14:57,680 --> 00:15:04,959
basically see that these mice

375
00:15:01,959 --> 00:15:06,959
are unable to gain weight. You put them

376
00:15:04,959 --> 00:15:08,720
on a treadmill, you you know put them on

377
00:15:06,959 --> 00:15:10,720
a couch, you feed them whatever they

378
00:15:08,720 --> 00:15:12,320
want, they don't gain weight. They're

379
00:15:10,720 --> 00:15:14,880
unable to gain weight. All of their fat

380
00:15:12,320 --> 00:15:18,399
tissues are sort of gone. They're super

381
00:15:14,880 --> 00:15:21,839
healthy, super lean, red, juicy organs

382
00:15:18,399 --> 00:15:24,639
instead of like the Sorry, my appetite

383
00:15:21,839 --> 00:15:26,480
started. Um, all right. So, so we want

384
00:15:24,639 --> 00:15:28,720
to do this systematically. We want to do

385
00:15:26,480 --> 00:15:30,320
this for every gene, every disease,

386
00:15:28,720 --> 00:15:31,440
every genetic association of the genome.

387
00:15:30,320 --> 00:15:33,440
And of course, I have to show you more

388
00:15:31,440 --> 00:15:34,800
than one example. So, here's ApoE4. So,

389
00:15:33,440 --> 00:15:36,320
this was published in the New England

390
00:15:34,800 --> 00:15:39,040
Journal of Medicine. This was published

391
00:15:36,320 --> 00:15:40,720
in Nature. Uh, so here we have the

392
00:15:39,040 --> 00:15:43,519
strongest genetic association with

393
00:15:40,720 --> 00:15:45,680
Alzheimer's disease. And the ApoE4 alil

394
00:15:43,519 --> 00:15:47,680
that increases your risk tfold if you're

395
00:15:45,680 --> 00:15:50,560
homozygous carrier. What we found is

396
00:15:47,680 --> 00:15:52,240
that for both Alzheimer's and control

397
00:15:50,560 --> 00:15:53,639
individuals that were carriers of the

398
00:15:52,240 --> 00:15:57,959
risk alil

399
00:15:53,639 --> 00:16:01,279
apo4 we found increased cholesterol

400
00:15:57,959 --> 00:16:03,680
biogenesis but surprisingly decreased

401
00:16:01,279 --> 00:16:05,759
myelination. Milination is of course

402
00:16:03,680 --> 00:16:07,839
where the cholesterol ends up at the end

403
00:16:05,759 --> 00:16:11,759
end of oligodendrites that basically

404
00:16:07,839 --> 00:16:14,160
coat your axins with myelin with this

405
00:16:11,759 --> 00:16:16,240
lipid layer to basically protect them

406
00:16:14,160 --> 00:16:18,800
and to make the electrical signal flow

407
00:16:16,240 --> 00:16:20,240
faster. So you would expect that that

408
00:16:18,800 --> 00:16:22,000
would be associated with less

409
00:16:20,240 --> 00:16:24,000
cholesterol not more cholesterol because

410
00:16:22,000 --> 00:16:25,839
we're clearly upregulating cholesterol

411
00:16:24,000 --> 00:16:27,120
biosynthesis. So what's going on here?

412
00:16:25,839 --> 00:16:29,839
What's going on is that the cholesterol

413
00:16:27,120 --> 00:16:32,160
cannot be transported. instead it gets

414
00:16:29,839 --> 00:16:34,399
stuck in the endopplasmic reticulum of

415
00:16:32,160 --> 00:16:36,160
the oligodendrites and you see all these

416
00:16:34,399 --> 00:16:39,519
bubbles here instead of this nice sort

417
00:16:36,160 --> 00:16:41,839
of lean export. So what we reason is

418
00:16:39,519 --> 00:16:43,480
well maybe if we facilitate transport

419
00:16:41,839 --> 00:16:45,759
using

420
00:16:43,480 --> 00:16:48,639
cycllodextrine we can restore

421
00:16:45,759 --> 00:16:50,720
mileelination and restore cognition and

422
00:16:48,639 --> 00:16:52,480
indeed that's exactly what we found both

423
00:16:50,720 --> 00:16:54,480
in human cells and in an animal model

424
00:16:52,480 --> 00:16:58,000
and animal cells we're able to restore

425
00:16:54,480 --> 00:17:00,240
cognition by understanding the circuitry

426
00:16:58,000 --> 00:17:03,040
and being able to intervene third

427
00:17:00,240 --> 00:17:04,400
example cancer imotherapy and again I'm

428
00:17:03,040 --> 00:17:06,079
going through the big plagues of our

429
00:17:04,400 --> 00:17:09,120
society here so Alzheimer's cancer

430
00:17:06,079 --> 00:17:11,120
obesity so in cancer Iapy is

431
00:17:09,120 --> 00:17:13,360
magnificent. It cures 50% of the

432
00:17:11,120 --> 00:17:15,679
patients. Well, it's magnificent for for

433
00:17:13,360 --> 00:17:17,600
those 50%. For the other 50%, it's a

434
00:17:15,679 --> 00:17:19,199
waste of time. But what we were able to

435
00:17:17,600 --> 00:17:20,839
show is that the difference between

436
00:17:19,199 --> 00:17:23,520
responders and non-responders to

437
00:17:20,839 --> 00:17:24,959
imunotherapy was in fact a lot of genes

438
00:17:23,520 --> 00:17:27,039
downstream of a small number of

439
00:17:24,959 --> 00:17:28,960
regulators. So using a combination

440
00:17:27,039 --> 00:17:30,320
therapy by understanding again the

441
00:17:28,960 --> 00:17:33,200
circuitry, understanding the

442
00:17:30,320 --> 00:17:35,840
epigenomics, we were able to get 100%

443
00:17:33,200 --> 00:17:38,559
imunotherapy response.

444
00:17:35,840 --> 00:17:40,480
So we can now start taking on disease.

445
00:17:38,559 --> 00:17:42,080
But again, thinking about Alzheimer's as

446
00:17:40,480 --> 00:17:43,600
a single disease is a little weird

447
00:17:42,080 --> 00:17:45,600
because the manifestation of Alzheimer's

448
00:17:43,600 --> 00:17:47,919
is dramatically different from person to

449
00:17:45,600 --> 00:17:49,440
person. So what we can do now is scale

450
00:17:47,919 --> 00:17:51,520
up. Instead of just looking at one

451
00:17:49,440 --> 00:17:53,360
patient, we're looking at 400 patients.

452
00:17:51,520 --> 00:17:55,039
In this particular case, 427

453
00:17:53,360 --> 00:17:56,880
individuals, 2.4 million cells as I

454
00:17:55,039 --> 00:17:58,640
showed you in the first slide. And we

455
00:17:56,880 --> 00:18:01,039
can now look at the diversity of

456
00:17:58,640 --> 00:18:03,400
phenotypes across pathology, cognition,

457
00:18:01,039 --> 00:18:05,679
cognitive decline, amaloid plaques,

458
00:18:03,400 --> 00:18:07,760
neuropibrillers, neo inflammation. We

459
00:18:05,679 --> 00:18:10,880
can now start looking at the diversity

460
00:18:07,760 --> 00:18:12,640
of disease at the phenotypic level and

461
00:18:10,880 --> 00:18:15,280
start matching it with the diversity of

462
00:18:12,640 --> 00:18:17,600
disease at the cellular level and we can

463
00:18:15,280 --> 00:18:19,440
now discover these hallmarks of disease

464
00:18:17,600 --> 00:18:21,679
and start associating them with distinct

465
00:18:19,440 --> 00:18:23,520
combinations of phenotypes. For example,

466
00:18:21,679 --> 00:18:26,240
we found that resilience is associated

467
00:18:23,520 --> 00:18:28,480
with choline metabolism. And if you

468
00:18:26,240 --> 00:18:31,520
consume more choline, you know, chances

469
00:18:28,480 --> 00:18:33,120
are it's protective for or against

470
00:18:31,520 --> 00:18:34,640
Alzheimer disease. And we're able to

471
00:18:33,120 --> 00:18:37,760
understand this by building these

472
00:18:34,640 --> 00:18:39,520
networks of modules of hallmarks inside

473
00:18:37,760 --> 00:18:42,520
the cell and then associating with

474
00:18:39,520 --> 00:18:46,000
distinct regions in this cellular

475
00:18:42,520 --> 00:18:47,919
landscape. We can do the same thing with

476
00:18:46,000 --> 00:18:49,679
understanding the epigenome, not just

477
00:18:47,919 --> 00:18:50,960
the transcriptto. In this particular

478
00:18:49,679 --> 00:18:53,840
case, we're looking at how the

479
00:18:50,960 --> 00:18:58,000
epiggenome changes across again 3.5

480
00:18:53,840 --> 00:19:02,000
million cells across 400 donors where we

481
00:18:58,000 --> 00:19:05,919
now have matched DNA accessibility and

482
00:19:02,000 --> 00:19:08,160
gene expression and we can now find this

483
00:19:05,919 --> 00:19:10,240
very dramatic shift in epigenomic

484
00:19:08,160 --> 00:19:12,559
information. So we basically have this

485
00:19:10,240 --> 00:19:14,640
epigenome rewiring and this epigenome

486
00:19:12,559 --> 00:19:17,120
erosion that happens in the Alzheimer's

487
00:19:14,640 --> 00:19:19,559
individuals but then restoration in the

488
00:19:17,120 --> 00:19:22,400
control individuals and we can find the

489
00:19:19,559 --> 00:19:24,440
regulators the the the targets that we

490
00:19:22,400 --> 00:19:27,080
should be going after to restore

491
00:19:24,440 --> 00:19:30,640
homeogenesis. We can also use spatial

492
00:19:27,080 --> 00:19:33,120
transcodies to understand how the

493
00:19:30,640 --> 00:19:36,240
localization and the organization of

494
00:19:33,120 --> 00:19:38,320
these cells inside for example the

495
00:19:36,240 --> 00:19:40,640
arteries or the inima the lumen and the

496
00:19:38,320 --> 00:19:43,200
media of your coronary arteries in the

497
00:19:40,640 --> 00:19:44,799
context of again the fourth major killer

498
00:19:43,200 --> 00:19:47,039
coronary artery disease actually number

499
00:19:44,799 --> 00:19:49,679
one in developed nations where we

500
00:19:47,039 --> 00:19:52,160
actually find specific subsets of immune

501
00:19:49,679 --> 00:19:53,799
cells that are engulfing the lipids from

502
00:19:52,160 --> 00:19:57,280
your bloodstream are in fact

503
00:19:53,799 --> 00:20:00,679
disregulated in specific spatial regions

504
00:19:57,280 --> 00:20:04,000
that allows us to again now know how to

505
00:20:00,679 --> 00:20:06,520
intervene and going back to the concept

506
00:20:04,000 --> 00:20:08,960
of we don't want to treat Alzheimer's

507
00:20:06,520 --> 00:20:11,799
monolithically yes we can understand the

508
00:20:08,960 --> 00:20:14,400
hallmarks of Alzheimer's

509
00:20:11,799 --> 00:20:16,799
disease what are the pathways that are

510
00:20:14,400 --> 00:20:18,799
recurrently perturbed at the genetic

511
00:20:16,799 --> 00:20:20,320
level at the epigenomic level at the

512
00:20:18,799 --> 00:20:22,960
transcription level at the cellular

513
00:20:20,320 --> 00:20:25,120
level and ultimately manifesting in the

514
00:20:22,960 --> 00:20:26,799
endotypes the imaging

515
00:20:25,120 --> 00:20:29,520
the biomarkers and ultimately the

516
00:20:26,799 --> 00:20:33,240
disease phenotypes. But we can also go

517
00:20:29,520 --> 00:20:35,880
down to single cell

518
00:20:33,240 --> 00:20:38,960
resolution. Let me

519
00:20:35,880 --> 00:20:41,360
explain. Every cell in a differential

520
00:20:38,960 --> 00:20:45,120
expression analysis currently is thought

521
00:20:41,360 --> 00:20:46,880
of as 100% Alzheimer's or 100% control.

522
00:20:45,120 --> 00:20:49,120
We basically say what is the difference

523
00:20:46,880 --> 00:20:52,440
in expression between Alzheimer's cases

524
00:20:49,120 --> 00:20:52,440
and controls.

525
00:20:52,480 --> 00:20:57,640
But we have thousands of cells for each

526
00:20:54,799 --> 00:21:00,720
person. Not every cell is 100%

527
00:20:57,640 --> 00:21:03,360
Alzheimer's. So what we can do now is

528
00:21:00,720 --> 00:21:05,360
flip this around. We can basically say,

529
00:21:03,360 --> 00:21:08,080
let's look at the transcriptional

530
00:21:05,360 --> 00:21:10,640
landscape of the cells, this embedding

531
00:21:08,080 --> 00:21:13,760
landscape that I mentioned earlier. And

532
00:21:10,640 --> 00:21:18,120
we can now color every cell according to

533
00:21:13,760 --> 00:21:21,360
the color of the donor, 100% red or 100%

534
00:21:18,120 --> 00:21:24,400
blue, Alzheimer's or controls. And now

535
00:21:21,360 --> 00:21:26,840
we can basically say for every cellular

536
00:21:24,400 --> 00:21:29,520
neighborhood, for every transcriptional

537
00:21:26,840 --> 00:21:32,000
neighborhood, is there an enrichment for

538
00:21:29,520 --> 00:21:33,120
Alzheimer's, for control or for neither?

539
00:21:32,000 --> 00:21:35,760
And therefore, we can define

540
00:21:33,120 --> 00:21:39,320
neighborhoods that are very healthy in

541
00:21:35,760 --> 00:21:42,480
blue or very sick in red or

542
00:21:39,320 --> 00:21:44,159
intermediate. And every cell now, we can

543
00:21:42,480 --> 00:21:46,640
ignore the original phenotype that it

544
00:21:44,159 --> 00:21:49,760
had because we have 400 people telling

545
00:21:46,640 --> 00:21:51,919
us what those phenotypes are. And we can

546
00:21:49,760 --> 00:21:53,559
now color every cell according to the

547
00:21:51,919 --> 00:21:55,919
color of its

548
00:21:53,559 --> 00:21:57,600
neighborhood. Why is that exciting?

549
00:21:55,919 --> 00:21:59,760
Because we can now instead of finding

550
00:21:57,600 --> 00:22:01,440
five differentially expressed genes, we

551
00:21:59,760 --> 00:22:02,960
can find hundreds of differentially

552
00:22:01,440 --> 00:22:05,919
expressed genes. Because we're not

553
00:22:02,960 --> 00:22:08,080
looking at case control where every cell

554
00:22:05,919 --> 00:22:10,000
is colored either 100% red or 100% blue.

555
00:22:08,080 --> 00:22:11,280
We can now look at the gradients and say

556
00:22:10,000 --> 00:22:13,679
those cells that are in very sick

557
00:22:11,280 --> 00:22:15,200
neighborhoods have much more much

558
00:22:13,679 --> 00:22:16,880
stronger disregulation of these genes

559
00:22:15,200 --> 00:22:20,720
versus those genes. Who's with me so

560
00:22:16,880 --> 00:22:23,760
far? Yes. Awesome. Now we can go a step

561
00:22:20,720 --> 00:22:25,760
further and say well remember this red

562
00:22:23,760 --> 00:22:28,720
blue coloring of the individuals are

563
00:22:25,760 --> 00:22:32,080
sick or healthy. We don't have to do

564
00:22:28,720 --> 00:22:35,280
that anymore. We can now look at that

565
00:22:32,080 --> 00:22:36,799
person's microgal cells and say well

566
00:22:35,280 --> 00:22:38,400
their micro gleal cells were clearly in

567
00:22:36,799 --> 00:22:39,400
blue neighborhoods and theirodenderites

568
00:22:38,400 --> 00:22:41,760
were in red

569
00:22:39,400 --> 00:22:44,240
neighborhoods. So we can now start

570
00:22:41,760 --> 00:22:46,080
mapping phenotypes to the cellular level

571
00:22:44,240 --> 00:22:48,400
and from the cellular level map back to

572
00:22:46,080 --> 00:22:50,480
the individuals and start inferring

573
00:22:48,400 --> 00:22:52,240
transcriptional states for every person

574
00:22:50,480 --> 00:22:55,200
and for every phenotype in every cell

575
00:22:52,240 --> 00:22:56,880
type. This is completely transformative

576
00:22:55,200 --> 00:22:58,320
of the way that we use single cell data

577
00:22:56,880 --> 00:23:00,320
and of the way that we understand

578
00:22:58,320 --> 00:23:02,720
disease in the first place. We can now

579
00:23:00,320 --> 00:23:05,520
understand patient hogenity at

580
00:23:02,720 --> 00:23:07,240
unprecedented resolution. That allows us

581
00:23:05,520 --> 00:23:09,840
to now start looking back at the

582
00:23:07,240 --> 00:23:11,760
genetics and instead of just looking at

583
00:23:09,840 --> 00:23:14,640
the genetics in a completely blind way

584
00:23:11,760 --> 00:23:18,080
the way that it was done in 1905 by RA

585
00:23:14,640 --> 00:23:20,640
Fischer, we can now in 2025 say not

586
00:23:18,080 --> 00:23:22,559
every genetic variant is born the same.

587
00:23:20,640 --> 00:23:24,880
Some genetic variants are perturbing

588
00:23:22,559 --> 00:23:26,799
those hallmarks that we identified in

589
00:23:24,880 --> 00:23:28,640
the epigenomic regions in the genes in

590
00:23:26,799 --> 00:23:30,720
the pathways in the cell types in the

591
00:23:28,640 --> 00:23:33,120
cellular states that we uncovered as the

592
00:23:30,720 --> 00:23:35,840
hallmarks of disease. We can now just by

593
00:23:33,120 --> 00:23:37,679
looking at the genetics of a person say

594
00:23:35,840 --> 00:23:39,360
well that person's risk for

595
00:23:37,679 --> 00:23:41,840
neuroinflammation is much higher than

596
00:23:39,360 --> 00:23:44,960
for lipid dysregulation and for whole

597
00:23:41,840 --> 00:23:48,880
cholesterol homeostasis etc. So we can

598
00:23:44,960 --> 00:23:51,600
now start doing genetic predictions at

599
00:23:48,880 --> 00:23:54,000
extraordinary resolution and therefore

600
00:23:51,600 --> 00:23:55,919
start developing therapeutics and start

601
00:23:54,000 --> 00:23:58,880
targeting those therapeutics for each

602
00:23:55,919 --> 00:24:00,240
person in a different way. Which of

603
00:23:58,880 --> 00:24:02,640
course takes us to the last part of the

604
00:24:00,240 --> 00:24:05,280
talk about specific targets. How do we

605
00:24:02,640 --> 00:24:07,200
now develop these molecules? Well, we

606
00:24:05,280 --> 00:24:09,280
start of course with a protein target,

607
00:24:07,200 --> 00:24:11,679
but what we want to do is scan through

608
00:24:09,280 --> 00:24:13,520
thousands of known drugs and use a

609
00:24:11,679 --> 00:24:15,440
gradient ascent to basically understand

610
00:24:13,520 --> 00:24:17,919
again this latent embedding space of

611
00:24:15,440 --> 00:24:20,039
chemistry and walk up the chemical

612
00:24:17,919 --> 00:24:23,360
gradient of affinity towards that

613
00:24:20,039 --> 00:24:24,919
protein. And then when we find a region

614
00:24:23,360 --> 00:24:28,080
in that embedding

615
00:24:24,919 --> 00:24:29,520
space where those molecules are more

616
00:24:28,080 --> 00:24:32,640
promising, we can start generating

617
00:24:29,520 --> 00:24:35,039
outbdings. can start constructing

618
00:24:32,640 --> 00:24:36,799
molecules from those coordinates in that

619
00:24:35,039 --> 00:24:39,360
latent embedding space. So it's a very

620
00:24:36,799 --> 00:24:40,799
new paradigm for discovery where

621
00:24:39,360 --> 00:24:43,760
basically we understand the drug

622
00:24:40,799 --> 00:24:45,360
landscape that's feeding the AI. The AI

623
00:24:43,760 --> 00:24:49,039
is interacting with the human and we

624
00:24:45,360 --> 00:24:51,520
have complete control on how we we climb

625
00:24:49,039 --> 00:24:52,799
those gradients. So my student Safi

626
00:24:51,520 --> 00:24:54,320
who's going to be presenting a poster

627
00:24:52,799 --> 00:24:56,799
later, please go talk to him. He's the

628
00:24:54,320 --> 00:24:59,360
smartest person I have ever met. He is a

629
00:24:56,799 --> 00:25:01,679
freshman at MIT and he's beating the

630
00:24:59,360 --> 00:25:04,480
state-of-the-art in drug discovery in

631
00:25:01,679 --> 00:25:06,440
the world. He had seven publications

632
00:25:04,480 --> 00:25:09,200
before even coming to MIT as a high

633
00:25:06,440 --> 00:25:11,520
schooler and four patents. So this is

634
00:25:09,200 --> 00:25:13,520
like this kid is extraordinary. So so if

635
00:25:11,520 --> 00:25:15,520
you want to collaborate with him just

636
00:25:13,520 --> 00:25:17,600
don't steal him please, but work with

637
00:25:15,520 --> 00:25:21,039
him directly. You don't need me. Um so

638
00:25:17,600 --> 00:25:23,039
he developed affinity net 1 2 3 4 5 6 7.

639
00:25:21,039 --> 00:25:24,400
He's now at 10. At eight, he had already

640
00:25:23,039 --> 00:25:26,000
surpassed the state-of-the-art and he

641
00:25:24,400 --> 00:25:27,919
has continued just like blowing the

642
00:25:26,000 --> 00:25:30,000
competition out of the water. So, he's

643
00:25:27,919 --> 00:25:32,400
basically now building these native

644
00:25:30,000 --> 00:25:35,200
embeddings and outbeddings speaking a

645
00:25:32,400 --> 00:25:38,400
single language between chemistry and

646
00:25:35,200 --> 00:25:40,960
language and human language. How? By

647
00:25:38,400 --> 00:25:43,360
co-mbbedding the landscape of patents

648
00:25:40,960 --> 00:25:45,360
and the landscape of chemistry at the

649
00:25:43,360 --> 00:25:46,559
same time. So he can now look at

650
00:25:45,360 --> 00:25:48,559
different regions of the chemical

651
00:25:46,559 --> 00:25:49,840
landscape and say hey you know what

652
00:25:48,559 --> 00:25:52,080
should I be using for cardiovascular

653
00:25:49,840 --> 00:25:54,720
disease or Alzheimer's or cancer and so

654
00:25:52,080 --> 00:25:58,159
on so forth and he's developed in the

655
00:25:54,720 --> 00:26:00,080
last you know few days um these agents

656
00:25:58,159 --> 00:26:02,400
that are able to now go through the

657
00:26:00,080 --> 00:26:04,880
entire drug development process. So

658
00:26:02,400 --> 00:26:06,480
these agents are you know sort of first

659
00:26:04,880 --> 00:26:08,960
understanding what is the disease how

660
00:26:06,480 --> 00:26:10,880
should we be targeting it like then

661
00:26:08,960 --> 00:26:12,960
mining the entire literature and all of

662
00:26:10,880 --> 00:26:15,200
our transcriptional states to identify

663
00:26:12,960 --> 00:26:16,960
targets then validating these targets

664
00:26:15,200 --> 00:26:19,279
using our multimodal information across

665
00:26:16,960 --> 00:26:22,080
lipidomics transcrytoics epigenomics

666
00:26:19,279 --> 00:26:24,880
then climbing up that tree of

667
00:26:22,080 --> 00:26:27,679
therapeutic space and chemical space and

668
00:26:24,880 --> 00:26:29,679
in the end generating these reports and

669
00:26:27,679 --> 00:26:32,480
every few hours he has coded a new

670
00:26:29,679 --> 00:26:34,720
agent. So if you have collaborators that

671
00:26:32,480 --> 00:26:36,400
are invaluable in your company, talk to

672
00:26:34,720 --> 00:26:38,120
Safi, tell him what they do and he'll

673
00:26:36,400 --> 00:26:42,000
replace them very

674
00:26:38,120 --> 00:26:44,080
soon. So, so um that didn't quite come

675
00:26:42,000 --> 00:26:46,400
out the way that I was hoping, but but

676
00:26:44,080 --> 00:26:49,120
you can now construct a virtual team

677
00:26:46,400 --> 00:26:50,880
with every expertise, every data source,

678
00:26:49,120 --> 00:26:53,520
every approach, every angle that you

679
00:26:50,880 --> 00:26:56,960
would like to build using these um

680
00:26:53,520 --> 00:26:59,039
agents. And we can now start combining

681
00:26:56,960 --> 00:27:00,799
this geometric deep learning

682
00:26:59,039 --> 00:27:03,200
representation of the latent embeddings

683
00:27:00,799 --> 00:27:05,440
of the chemistry and the protein

684
00:27:03,200 --> 00:27:08,400
landscapes and the cellular landscape

685
00:27:05,440 --> 00:27:10,400
and the patient diversity landscape and

686
00:27:08,400 --> 00:27:13,039
the genetic landscape and then start

687
00:27:10,400 --> 00:27:16,960
optimizing jointly these molecules

688
00:27:13,039 --> 00:27:18,799
across both protein and chemical space.

689
00:27:16,960 --> 00:27:20,760
So that's the first part of the talk

690
00:27:18,799 --> 00:27:23,799
telling you about how we are

691
00:27:20,760 --> 00:27:26,760
transforming the space of biology,

692
00:27:23,799 --> 00:27:30,400
chemistry, healthcare

693
00:27:26,760 --> 00:27:32,480
and using this unified approach that

694
00:27:30,400 --> 00:27:34,559
cuts across all of these layers of

695
00:27:32,480 --> 00:27:35,880
genetics, circuitry, target genes,

696
00:27:34,559 --> 00:27:38,240
epigenomics,

697
00:27:35,880 --> 00:27:40,799
transcrytoics, protein targets, protein

698
00:27:38,240 --> 00:27:43,039
structure, chemical structure, and then

699
00:27:40,799 --> 00:27:45,679
eventually screening them in both

700
00:27:43,039 --> 00:27:47,840
organoids and optimizing the chemistry.

701
00:27:45,679 --> 00:27:50,240
So that's the first part. But I want to

702
00:27:47,840 --> 00:27:52,000
make a small parenthesis here and talk

703
00:27:50,240 --> 00:27:53,919
about that bottom right corner that

704
00:27:52,000 --> 00:27:55,679
everybody's asking me about. I heard a

705
00:27:53,919 --> 00:27:57,279
lot of you basically say, "Tell me about

706
00:27:55,679 --> 00:27:58,399
geni. Tell me about all of these

707
00:27:57,279 --> 00:28:00,159
representation learning. Tell me about

708
00:27:58,399 --> 00:28:02,080
these foundation models. Tell me about

709
00:28:00,159 --> 00:28:04,000
these agents." And I want to spend a

710
00:28:02,080 --> 00:28:07,039
little time on that and basically tell

711
00:28:04,000 --> 00:28:10,159
you how far we've come. The left part of

712
00:28:07,039 --> 00:28:12,799
the the slide is the good news.

713
00:28:10,159 --> 00:28:14,559
We now have deep representation learning

714
00:28:12,799 --> 00:28:17,120
across all of these different data

715
00:28:14,559 --> 00:28:18,559
modalities. We now have multimodel

716
00:28:17,120 --> 00:28:20,720
understanding that combines these

717
00:28:18,559 --> 00:28:22,960
modalities together. And we have an AI

718
00:28:20,720 --> 00:28:25,120
that is able to do intuitive reasoning.

719
00:28:22,960 --> 00:28:27,279
That's already really great news. The

720
00:28:25,120 --> 00:28:30,000
bad news is when I ask people, hey,

721
00:28:27,279 --> 00:28:33,120
what's the future? They say, oh, chat.

722
00:28:30,000 --> 00:28:34,880
Chat is the new search. Chat is the new

723
00:28:33,120 --> 00:28:39,279
um, you know, question answering. Chat

724
00:28:34,880 --> 00:28:42,600
is the new um, uh, everything. So, so we

725
00:28:39,279 --> 00:28:45,120
are effectively locking the humans in a

726
00:28:42,600 --> 00:28:47,200
box where they're able to interact with

727
00:28:45,120 --> 00:28:50,000
this magnificence of data only by

728
00:28:47,200 --> 00:28:53,480
sliding questions on a little note in a

729
00:28:50,000 --> 00:28:55,679
little hole in the box. The AI is the

730
00:28:53,480 --> 00:28:57,840
genie. Imagine yourself in the cave of

731
00:28:55,679 --> 00:28:59,760
wonders in Aladdin, the first one. I I

732
00:28:57,840 --> 00:29:01,679
haven't seen any of the other ones. So,

733
00:28:59,760 --> 00:29:03,120
uh I was 16 at the time. Just kidding.

734
00:29:01,679 --> 00:29:05,440
Maybe I was actually I don't know. Um,

735
00:29:03,120 --> 00:29:08,240
so anyway, so, so imagine Aladdin in the

736
00:29:05,440 --> 00:29:09,760
cave of wonders and the genie is flying

737
00:29:08,240 --> 00:29:12,240
around and seeing all the treasure.

738
00:29:09,760 --> 00:29:15,279
Aladdin blindfolded inside the box is

739
00:29:12,240 --> 00:29:17,360
able to only ask questions. The the the

740
00:29:15,279 --> 00:29:18,960
genie comes back and says, "I saw these

741
00:29:17,360 --> 00:29:20,559
mountains and these valleys and I saw

742
00:29:18,960 --> 00:29:22,320
these beautiful treasure and I saw this

743
00:29:20,559 --> 00:29:23,840
data set and that data set, etc. But

744
00:29:22,320 --> 00:29:25,440
here's the answer." And if you don't

745
00:29:23,840 --> 00:29:27,200
like the answer with a chat only

746
00:29:25,440 --> 00:29:28,399
interface, you're stuck. There's nothing

747
00:29:27,200 --> 00:29:30,559
you can do about it. You can just say,

748
00:29:28,399 --> 00:29:32,159
"Well, try again." That's it. You can't

749
00:29:30,559 --> 00:29:34,799
just say, "Oh, wait a minute. I have a

750
00:29:32,159 --> 00:29:37,440
new insight here which is unfortunately

751
00:29:34,799 --> 00:29:40,799
making humans dumber because you can't

752
00:29:37,440 --> 00:29:43,440
check the AI anymore. So I want to go

753
00:29:40,799 --> 00:29:45,480
and um show you this cartoon from the

754
00:29:43,440 --> 00:29:48,960
80s here of

755
00:29:45,480 --> 00:29:51,679
um Dilbert very um you know ahead of its

756
00:29:48,960 --> 00:29:52,880
time where Zimbu the monkey has the

757
00:29:51,679 --> 00:29:54,480
monkey has designed three commercial

758
00:29:52,880 --> 00:29:56,480
products this week. We better find out

759
00:29:54,480 --> 00:29:58,480
his secret. He's using his tail. He has

760
00:29:56,480 --> 00:30:00,080
a natural advantage. I feel the jaws of

761
00:29:58,480 --> 00:30:01,600
evolution on my throat. Good gravy. Did

762
00:30:00,080 --> 00:30:03,279
you see him cut and paste? Your big

763
00:30:01,600 --> 00:30:04,799
mistake evolution wise was inventing

764
00:30:03,279 --> 00:30:07,039
computers that are easier to use if you

765
00:30:04,799 --> 00:30:08,799
have a tail. In an ironic twist in the

766
00:30:07,039 --> 00:30:10,880
Darwinian saga, you've guaranteed the

767
00:30:08,799 --> 00:30:12,799
extinction of your own species, says the

768
00:30:10,880 --> 00:30:15,440
monkey as he's continuing to to code

769
00:30:12,799 --> 00:30:17,600
with his tail. Okay. So, so why am I

770
00:30:15,440 --> 00:30:20,000
showing you this? Because we made that

771
00:30:17,600 --> 00:30:21,360
mistake. We constructed that world. We

772
00:30:20,000 --> 00:30:23,120
constructed the world where we are

773
00:30:21,360 --> 00:30:26,880
blindfolded and we don't have access to

774
00:30:23,120 --> 00:30:29,760
the data. And again, what I want to do

775
00:30:26,880 --> 00:30:31,520
is create a cgraphy for data. a a

776
00:30:29,760 --> 00:30:33,279
landscape of chemistry, a landscape of

777
00:30:31,520 --> 00:30:35,200
proteins, a landscape of patients, and

778
00:30:33,279 --> 00:30:38,320
be able to navigate in that landscape,

779
00:30:35,200 --> 00:30:40,000
be able to understand the slopes and the

780
00:30:38,320 --> 00:30:41,360
land masses and the anchor points and

781
00:30:40,000 --> 00:30:42,960
the highway names and the street names

782
00:30:41,360 --> 00:30:44,799
and what it means to go up this gradient

783
00:30:42,960 --> 00:30:47,159
versus that gradient and so on so forth.

784
00:30:44,799 --> 00:30:50,320
That's what humans are best at. We

785
00:30:47,159 --> 00:30:52,960
evolved eyesight for millions of years

786
00:30:50,320 --> 00:30:55,120
to be able to understand landscapes, to

787
00:30:52,960 --> 00:30:57,039
understand topography, to to understand

788
00:30:55,120 --> 00:30:59,360
all of these things. And language is

789
00:30:57,039 --> 00:31:01,679
only like 70,000 years old. Language is

790
00:30:59,360 --> 00:31:04,880
very new by comparison. So what I want

791
00:31:01,679 --> 00:31:07,279
to do is transition where the AI is

792
00:31:04,880 --> 00:31:12,960
providing us landscapes of information.

793
00:31:07,279 --> 00:31:15,840
Imagine every patent, every memo, every

794
00:31:12,960 --> 00:31:18,880
email, every person in your corporation,

795
00:31:15,840 --> 00:31:22,320
every project, every love letter, every

796
00:31:18,880 --> 00:31:24,880
poem sitting somewhere in this latent

797
00:31:22,320 --> 00:31:28,080
landscape of all of knowledge and being

798
00:31:24,880 --> 00:31:30,240
able to directly navigate on it. Imagine

799
00:31:28,080 --> 00:31:32,240
you have to browse through three million

800
00:31:30,240 --> 00:31:34,000
patents or three million drugs or three

801
00:31:32,240 --> 00:31:35,600
million articles from the New York

802
00:31:34,000 --> 00:31:37,440
Times.

803
00:31:35,600 --> 00:31:38,559
instead of first putting them into

804
00:31:37,440 --> 00:31:39,919
buckets and then saying, "Hey, what's in

805
00:31:38,559 --> 00:31:41,679
the bucket and how many articles in

806
00:31:39,919 --> 00:31:43,919
every bucket?" Imagine being able to

807
00:31:41,679 --> 00:31:46,080
actually fly through the data. So, we're

808
00:31:43,919 --> 00:31:48,720
basically giving a lad in a magic carpet

809
00:31:46,080 --> 00:31:50,360
and you're now able to fly through three

810
00:31:48,720 --> 00:31:52,720
million articles from the New York

811
00:31:50,360 --> 00:31:55,279
Times. These are not buckets. This is a

812
00:31:52,720 --> 00:31:57,679
ctography. It's a map. And it allows you

813
00:31:55,279 --> 00:31:59,760
to now label these points according to

814
00:31:57,679 --> 00:32:01,919
the enrichment of the topics that are

815
00:31:59,760 --> 00:32:04,960
represented in every one of these

816
00:32:01,919 --> 00:32:06,640
places. And you can now ask questions

817
00:32:04,960 --> 00:32:07,840
directly. You can basically use a lasso

818
00:32:06,640 --> 00:32:10,000
tool to say, "Hey, what's happening

819
00:32:07,840 --> 00:32:11,559
here? Hey, if I go from here to there,

820
00:32:10,000 --> 00:32:13,760
what is happening?" So, we've

821
00:32:11,559 --> 00:32:16,000
constructed this tool that we call

822
00:32:13,760 --> 00:32:18,399
mantis. Mantis is not the animal. Mantis

823
00:32:16,000 --> 00:32:21,120
actually the animal is is named after

824
00:32:18,399 --> 00:32:22,480
the it's called preying mantis, right?

825
00:32:21,120 --> 00:32:24,000
And and and the reason why it's called

826
00:32:22,480 --> 00:32:26,640
mantis is because in Greek the word

827
00:32:24,000 --> 00:32:29,519
mantis is the seer, the one who sees

828
00:32:26,640 --> 00:32:32,000
beyond, the one who can see directly

829
00:32:29,519 --> 00:32:33,519
embedding landscapes. Okay? So we have

830
00:32:32,000 --> 00:32:35,200
basically constructed Mantis for

831
00:32:33,519 --> 00:32:38,240
navigating directly this embedding

832
00:32:35,200 --> 00:32:41,760
landscapes. This is an an a landscape of

833
00:32:38,240 --> 00:32:45,360
20,000 human genes and you can basically

834
00:32:41,760 --> 00:32:46,960
go into it and ask questions. You have

835
00:32:45,360 --> 00:32:48,320
cluster, you have the lasso tool, you

836
00:32:46,960 --> 00:32:50,880
have neighborhoods, you have this

837
00:32:48,320 --> 00:32:54,000
cognitive map, you have codes that that

838
00:32:50,880 --> 00:32:55,200
you write. For some questions, the AI

839
00:32:54,000 --> 00:32:56,399
will answer directly. For other

840
00:32:55,200 --> 00:32:58,080
questions, it will say, "Well, let me

841
00:32:56,399 --> 00:32:59,200
write a program for you and I'll run the

842
00:32:58,080 --> 00:33:00,880
program and find out the answer." And

843
00:32:59,200 --> 00:33:02,320
then you'll see the answers visually.

844
00:33:00,880 --> 00:33:04,080
You have these ontologies coming from

845
00:33:02,320 --> 00:33:06,279
scratch. You have the ability to search

846
00:33:04,080 --> 00:33:10,720
and we've constructed these

847
00:33:06,279 --> 00:33:12,640
landscapes by um through all kinds of

848
00:33:10,720 --> 00:33:15,200
ways. So in this particular way, we're

849
00:33:12,640 --> 00:33:18,960
basically looking at 20,000 genes from a

850
00:33:15,200 --> 00:33:21,200
knowledge graph that is able to um take

851
00:33:18,960 --> 00:33:23,039
care of understanding the relationship

852
00:33:21,200 --> 00:33:25,440
between genes and diseases and

853
00:33:23,039 --> 00:33:27,200
phenotypes and drugs and cellular

854
00:33:25,440 --> 00:33:30,240
components and pathways and so on so

855
00:33:27,200 --> 00:33:33,200
forth. And every one of these nodes

856
00:33:30,240 --> 00:33:34,799
starts out with its own meaning. The

857
00:33:33,200 --> 00:33:36,480
disease has a meaning, has a projection

858
00:33:34,799 --> 00:33:38,559
in the late embedding landscape. The

859
00:33:36,480 --> 00:33:40,960
gene has an initial meaning based on its

860
00:33:38,559 --> 00:33:43,200
description, its language. But then the

861
00:33:40,960 --> 00:33:44,960
connections between them are spreading

862
00:33:43,200 --> 00:33:48,000
activation. They're message passing

863
00:33:44,960 --> 00:33:50,080
information between them leading to a

864
00:33:48,000 --> 00:33:51,679
revised representation where every one

865
00:33:50,080 --> 00:33:53,360
of these genes and notice you might

866
00:33:51,679 --> 00:33:55,840
realize the picture is exactly the same.

867
00:33:53,360 --> 00:33:58,640
So I'm able to go and search for example

868
00:33:55,840 --> 00:34:01,360
for uh lipids and then I'm able to find

869
00:33:58,640 --> 00:34:04,159
every molecule that is associated with

870
00:34:01,360 --> 00:34:09,119
lipids and you know I can uh you know

871
00:34:04,159 --> 00:34:12,639
then ask to the AI um what are the major

872
00:34:09,119 --> 00:34:14,040
diseases uh that these genes are

873
00:34:12,639 --> 00:34:16,480
implicated

874
00:34:14,040 --> 00:34:20,839
in and I'm passing it the context for

875
00:34:16,480 --> 00:34:23,760
example I can just say um let's see

876
00:34:20,839 --> 00:34:26,800
lipids and then the AI I is able to now

877
00:34:23,760 --> 00:34:28,480
go and answer directly in that landscape

878
00:34:26,800 --> 00:34:30,720
and I can of course navigate this

879
00:34:28,480 --> 00:34:32,839
landscape and you know sort of go and

880
00:34:30,720 --> 00:34:35,520
you know create additional

881
00:34:32,839 --> 00:34:38,240
uh I mentioned the lasso tool earlier.

882
00:34:35,520 --> 00:34:40,960
So here I'm creating an additional bag

883
00:34:38,240 --> 00:34:42,679
and for every bag notice here it says

884
00:34:40,960 --> 00:34:44,800
mitochondrial genes and metabolic

885
00:34:42,679 --> 00:34:46,560
functions. Why is it saying that?

886
00:34:44,800 --> 00:34:49,520
Because this is not your grandmother's

887
00:34:46,560 --> 00:34:52,240
AI tool. This is like modern AI. It's

888
00:34:49,520 --> 00:34:54,320
basically using, you know, talk to your

889
00:34:52,240 --> 00:34:57,280
grandmother. You she'll be very excited.

890
00:34:54,320 --> 00:35:00,760
Um, so, so as soon as I select

891
00:34:57,280 --> 00:35:03,520
something, it tells me what it is.

892
00:35:00,760 --> 00:35:05,599
So, the way that I describe data science

893
00:35:03,520 --> 00:35:08,000
is imagine my three-year-old sitting on

894
00:35:05,599 --> 00:35:10,720
the carpet and then sorting little

895
00:35:08,000 --> 00:35:12,640
flashcards of, you know, squares

896
00:35:10,720 --> 00:35:14,800
together or all of the yellow triangles

897
00:35:12,640 --> 00:35:16,240
together and so on so forth. That's data

898
00:35:14,800 --> 00:35:18,480
science. Data science should be that

899
00:35:16,240 --> 00:35:20,079
easy. only dramatically augmented where

900
00:35:18,480 --> 00:35:22,160
the kid can say okay great summarize all

901
00:35:20,079 --> 00:35:24,640
of these books and you know like give me

902
00:35:22,160 --> 00:35:26,079
the cross cutting concepts across all of

903
00:35:24,640 --> 00:35:28,400
those books and that's what we have

904
00:35:26,079 --> 00:35:30,640
constructed so we are now able to go and

905
00:35:28,400 --> 00:35:33,200
directly navigate these latent embedding

906
00:35:30,640 --> 00:35:35,440
landscapes and we're not able to do that

907
00:35:33,200 --> 00:35:39,200
just with text we're able to do that

908
00:35:35,440 --> 00:35:41,280
with images with DNA sequences with

909
00:35:39,200 --> 00:35:43,119
chemistry with protein structures with

910
00:35:41,280 --> 00:35:44,640
patient records with cells with

911
00:35:43,119 --> 00:35:47,320
knowledge graphs with scientific papers

912
00:35:44,640 --> 00:35:49,200
with with free text and with multimodel

913
00:35:47,320 --> 00:35:50,960
representations. That's the major thing

914
00:35:49,200 --> 00:35:53,200
that has happened in AI in the last 12

915
00:35:50,960 --> 00:35:55,440
years. So if somebody says what happened

916
00:35:53,200 --> 00:35:58,480
the last 12 years in AI, you tell them

917
00:35:55,440 --> 00:36:00,800
latent spaces. It's the Z vector. It's

918
00:35:58,480 --> 00:36:03,119
not just the data and the labels. It's

919
00:36:00,800 --> 00:36:04,720
those latent representations. And what

920
00:36:03,119 --> 00:36:07,040
Mantis does is that it takes these

921
00:36:04,720 --> 00:36:09,119
latent representations and it makes them

922
00:36:07,040 --> 00:36:11,040
accessible so that you can trust your

923
00:36:09,119 --> 00:36:12,640
AI. You can say, "Hey, how are you

924
00:36:11,040 --> 00:36:14,320
thinking of this gene?" And the answer

925
00:36:12,640 --> 00:36:15,680
is, "Oh, well that gene sits there in

926
00:36:14,320 --> 00:36:18,000
the context of those other genes." and

927
00:36:15,680 --> 00:36:20,640
so on so forth. Okay, so we can do this

928
00:36:18,000 --> 00:36:22,240
with cellular and transcriptional

929
00:36:20,640 --> 00:36:23,680
landscapes. We can do this with

930
00:36:22,240 --> 00:36:25,760
chemistry. We can basically build these

931
00:36:23,680 --> 00:36:27,680
multimodal representations. We can do

932
00:36:25,760 --> 00:36:29,040
this with every patent and every grant

933
00:36:27,680 --> 00:36:31,280
and every paper that has been published

934
00:36:29,040 --> 00:36:32,599
by MIT. So we can basically build these

935
00:36:31,280 --> 00:36:35,119
multimodel

936
00:36:32,599 --> 00:36:37,040
representations and start mapping

937
00:36:35,119 --> 00:36:38,720
multiple cryptographies at once. If you

938
00:36:37,040 --> 00:36:40,160
notice at the top left here, I have

939
00:36:38,720 --> 00:36:41,680
connected the patents and the papers.

940
00:36:40,160 --> 00:36:43,839
And because we want to have fun, I've

941
00:36:41,680 --> 00:36:46,240
connected the cognitive landscape to the

942
00:36:43,839 --> 00:36:48,480
physical landscape of where at MIT those

943
00:36:46,240 --> 00:36:50,000
inventions were made. And I can do the

944
00:36:48,480 --> 00:36:51,760
same thing over time and basically see

945
00:36:50,000 --> 00:36:53,359
how knowledge changes over time. I can

946
00:36:51,760 --> 00:36:55,520
do things with quantitative data across

947
00:36:53,359 --> 00:36:57,920
100,000 loans. Or I can take every

948
00:36:55,520 --> 00:36:59,760
startup in AI and medicine and then

949
00:36:57,920 --> 00:37:01,200
start seeing what are the capabilities

950
00:36:59,760 --> 00:37:03,680
that they have and how do they compare

951
00:37:01,200 --> 00:37:05,680
to each other or take prerequisites

952
00:37:03,680 --> 00:37:07,920
between every class at MIT regardless of

953
00:37:05,680 --> 00:37:10,800
what department it's in and and I can

954
00:37:07,920 --> 00:37:13,119
take my own people and see how is a lua

955
00:37:10,800 --> 00:37:15,359
and how's Benjamin project progressing

956
00:37:13,119 --> 00:37:17,760
over time in their thinking in their

957
00:37:15,359 --> 00:37:19,880
code commits. So we have constructed

958
00:37:17,760 --> 00:37:21,839
these tools for auto ingestion, for

959
00:37:19,880 --> 00:37:23,240
summarization, for clustering, for

960
00:37:21,839 --> 00:37:24,960
search, for ontologies, for

961
00:37:23,240 --> 00:37:26,480
collaboration. We have these quick

962
00:37:24,960 --> 00:37:28,480
sheets that allow you to look at the t

963
00:37:26,480 --> 00:37:30,560
the tabular view or the embedding view

964
00:37:28,480 --> 00:37:32,119
of every region in this landscape. When

965
00:37:30,560 --> 00:37:35,040
you search, you see the results

966
00:37:32,119 --> 00:37:37,359
organized not in a single list, but

967
00:37:35,040 --> 00:37:38,800
instead organized by topic. So

968
00:37:37,359 --> 00:37:40,960
basically, when I search for lipids, you

969
00:37:38,800 --> 00:37:42,480
can see every single gene, but all of

970
00:37:40,960 --> 00:37:43,920
the different processes that they're

971
00:37:42,480 --> 00:37:46,079
involved in. We have these flash cards.

972
00:37:43,920 --> 00:37:49,280
We have these agents living together. We

973
00:37:46,079 --> 00:37:52,560
have u these macros that you're able to

974
00:37:49,280 --> 00:37:54,160
say okay watch me to the AI and you know

975
00:37:52,560 --> 00:37:57,599
it can follow you. It can learn from you

976
00:37:54,160 --> 00:37:59,359
and so on so forth. So um that's what we

977
00:37:57,599 --> 00:38:01,440
have and we are now able to sort of

978
00:37:59,359 --> 00:38:04,560
study the latent embeddings of proteins

979
00:38:01,440 --> 00:38:08,440
and of chemistry and of images and so on

980
00:38:04,560 --> 00:38:11,200
so forth and that allows us to now

981
00:38:08,440 --> 00:38:13,680
understand the chemical landscape at

982
00:38:11,200 --> 00:38:16,320
unprecedented resolution. map it to the

983
00:38:13,680 --> 00:38:18,480
protein landscape and use all of that to

984
00:38:16,320 --> 00:38:20,480
basically bring humans back in the loop

985
00:38:18,480 --> 00:38:22,880
to basically be able to discover

986
00:38:20,480 --> 00:38:24,960
alongside the AI. This is now looking at

987
00:38:22,880 --> 00:38:26,480
patients and from the mimic data set and

988
00:38:24,960 --> 00:38:28,400
sort of how they relate to each other

989
00:38:26,480 --> 00:38:30,480
and you can see the different types of

990
00:38:28,400 --> 00:38:32,560
phenotypes. You can ingest any type of

991
00:38:30,480 --> 00:38:34,160
information from your entire company.

992
00:38:32,560 --> 00:38:36,160
You can basically do this crosscutting

993
00:38:34,160 --> 00:38:38,640
search. You can, you know, study

994
00:38:36,160 --> 00:38:40,960
categories and trajectories and

995
00:38:38,640 --> 00:38:42,800
partitions and iterate over them. You

996
00:38:40,960 --> 00:38:45,680
have all of these quantitative tools for

997
00:38:42,800 --> 00:38:48,079
quant for for analysis across uh you

998
00:38:45,680 --> 00:38:51,200
know many different uh data types and

999
00:38:48,079 --> 00:38:54,640
and tools and most excitingly you have

1000
00:38:51,200 --> 00:38:56,480
now these multi-talented AI agents. Some

1001
00:38:54,640 --> 00:38:58,240
agents are able to write code and

1002
00:38:56,480 --> 00:39:00,560
execute it are other agents are able to

1003
00:38:58,240 --> 00:39:02,079
sort of reason about drug discovery and

1004
00:39:00,560 --> 00:39:03,920
other agents are able to sort of take

1005
00:39:02,079 --> 00:39:06,720
you all the way through the entire

1006
00:39:03,920 --> 00:39:08,560
discovery process. So we have also

1007
00:39:06,720 --> 00:39:10,079
integrated this with every tool you can

1008
00:39:08,560 --> 00:39:12,079
imagine. For example, you have this

1009
00:39:10,079 --> 00:39:13,920
Chrome extension that when you search in

1010
00:39:12,079 --> 00:39:15,920
Google, instead of just getting a list

1011
00:39:13,920 --> 00:39:19,839
of results, you can basically directly

1012
00:39:15,920 --> 00:39:22,160
see the latent representations of all of

1013
00:39:19,839 --> 00:39:26,079
your answers, you know, directly in a

1014
00:39:22,160 --> 00:39:28,160
Mantis um landscape. We're able to now

1015
00:39:26,079 --> 00:39:30,960
look at any article, for example, the

1016
00:39:28,160 --> 00:39:33,359
article in AI in Wikipedia, and now map

1017
00:39:30,960 --> 00:39:35,119
it into all of the concepts that are

1018
00:39:33,359 --> 00:39:37,520
being asked. And you can now do that

1019
00:39:35,119 --> 00:39:39,440
across all of the the documents in in in

1020
00:39:37,520 --> 00:39:41,040
your corporation. You can do that in

1021
00:39:39,440 --> 00:39:44,560
sales. You can do that in every single

1022
00:39:41,040 --> 00:39:46,560
aspect. And this is really peing inside

1023
00:39:44,560 --> 00:39:48,960
the brain of the machine. But it's also

1024
00:39:46,560 --> 00:39:50,560
peing inside of the brain of the human

1025
00:39:48,960 --> 00:39:52,480
because those latent embeddings that the

1026
00:39:50,560 --> 00:39:53,920
machine constructs are in fact the same

1027
00:39:52,480 --> 00:39:56,119
latent embedded that we construct

1028
00:39:53,920 --> 00:39:59,200
because the machines were trained

1029
00:39:56,119 --> 00:40:00,640
through self-supervision in the same way

1030
00:39:59,200 --> 00:40:02,720
that the humans were trained. So we can

1031
00:40:00,640 --> 00:40:05,040
now start peeking inside the brains of

1032
00:40:02,720 --> 00:40:06,880
the humans. So that's the road ahead. In

1033
00:40:05,040 --> 00:40:08,960
my view, the road ahead is being able to

1034
00:40:06,880 --> 00:40:10,480
construct these embeddings, these latent

1035
00:40:08,960 --> 00:40:12,640
representation across all of these

1036
00:40:10,480 --> 00:40:14,720
different data modalities and to use AI

1037
00:40:12,640 --> 00:40:16,640
as a Google maps that allows you to have

1038
00:40:14,720 --> 00:40:18,560
these extraordinarily capable agents,

1039
00:40:16,640 --> 00:40:20,960
but have full traceability where every

1040
00:40:18,560 --> 00:40:22,800
answer can be traced to individual lines

1041
00:40:20,960 --> 00:40:24,960
of evidence where we have these

1042
00:40:22,800 --> 00:40:26,720
extraordinary power and we're able to

1043
00:40:24,960 --> 00:40:29,280
navigate through the data landscapes.

1044
00:40:26,720 --> 00:40:31,440
Was excited about that? Good. Awesome.

1045
00:40:29,280 --> 00:40:34,440
Good. I'll stop there. Thank you so

1046
00:40:31,440 --> 00:40:34,440
much.

1047
00:40:35,280 --> 00:40:39,040
We have time for one question. By the

1048
00:40:37,359 --> 00:40:40,400
way, I know I know why you offer

1049
00:40:39,040 --> 00:40:42,800
chocolates to your guests when they come

1050
00:40:40,400 --> 00:40:44,880
to visit your lab. All the calories you

1051
00:40:42,800 --> 00:40:47,200
can get, all those Nobel prizes. The

1052
00:40:44,880 --> 00:40:49,280
brain spends a lot of energy, so you

1053
00:40:47,200 --> 00:40:51,359
should not feel bad about chocolate when

1054
00:40:49,280 --> 00:40:53,359
you're listening to lectures.

1055
00:40:51,359 --> 00:40:55,280
Quick question for anybody. I know

1056
00:40:53,359 --> 00:40:57,119
that's a lot. Okay, we have time for

1057
00:40:55,280 --> 00:40:58,640
one. How do you How do you get companies

1058
00:40:57,119 --> 00:41:01,040
to actually give you the data? What

1059
00:40:58,640 --> 00:41:02,160
you're doing is amazing. So, so but like

1060
00:41:01,040 --> 00:41:03,440
actually you know because that's a

1061
00:41:02,160 --> 00:41:05,920
fantastic question. That's a fantastic

1062
00:41:03,440 --> 00:41:07,599
question. Any tricks? So, so, so, so we

1063
00:41:05,920 --> 00:41:09,280
have constructed this in a completely

1064
00:41:07,599 --> 00:41:11,119
modular way. There's a front end,

1065
00:41:09,280 --> 00:41:13,359
there's a back end, there's a compute

1066
00:41:11,119 --> 00:41:15,359
farm and there's a broker where you can

1067
00:41:13,359 --> 00:41:17,040
register different compute farms. You

1068
00:41:15,359 --> 00:41:20,359
can basically project to the front and

1069
00:41:17,040 --> 00:41:22,400
the back end only the stuff that is

1070
00:41:20,359 --> 00:41:24,400
sharable. So, you can basically say

1071
00:41:22,400 --> 00:41:25,839
okay, I can compute in the compute farm

1072
00:41:24,400 --> 00:41:27,599
the later embedding representations and

1073
00:41:25,839 --> 00:41:29,760
then project them forward. You can also

1074
00:41:27,599 --> 00:41:32,160
have the entire thing living in one box

1075
00:41:29,760 --> 00:41:34,000
at your company. So we what we have a

1076
00:41:32,160 --> 00:41:35,520
partner right now in healthcare where

1077
00:41:34,000 --> 00:41:38,000
the data is not allowed to leave their

1078
00:41:35,520 --> 00:41:40,640
premises. So we have taken mantis and we

1079
00:41:38,000 --> 00:41:42,640
have installed it on their premises and

1080
00:41:40,640 --> 00:41:44,480
of course with AI you might be like oh

1081
00:41:42,640 --> 00:41:46,880
well what if I ask openAI something or

1082
00:41:44,480 --> 00:41:48,520
cloud something else will that leak? And

1083
00:41:46,880 --> 00:41:51,280
for this we have actually

1084
00:41:48,520 --> 00:41:53,359
implemented several tools locally. So

1085
00:41:51,280 --> 00:41:56,079
for example, DeepSeek and VLM that

1086
00:41:53,359 --> 00:41:58,480
allows you to now construct whatever you

1087
00:41:56,079 --> 00:42:00,880
would like completely locally within the

1088
00:41:58,480 --> 00:42:03,119
farm. So basically uh you can install

1089
00:42:00,880 --> 00:42:05,599
Mantis have completely private data and

1090
00:42:03,119 --> 00:42:08,480
nothing ever come out of the box except

1091
00:42:05,599 --> 00:42:10,560
for the people using it. Comput

1092
00:42:08,480 --> 00:42:12,720
you don't need that much compute power.

1093
00:42:10,560 --> 00:42:14,480
It's it's it's you know the training of

1094
00:42:12,720 --> 00:42:16,240
the model is very hard but once the

1095
00:42:14,480 --> 00:42:18,079
models are trained you can deploy them

1096
00:42:16,240 --> 00:42:19,440
very cheaply.

1097
00:42:18,079 --> 00:42:22,560
I'll take one more question while we're

1098
00:42:19,440 --> 00:42:26,599
switching. No, I think we're just sorry.

1099
00:42:22,560 --> 00:42:26,599
Thank you. Thank you so much.


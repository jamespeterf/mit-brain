1
00:00:00,440 --> 00:00:02,560
so it's going to take a couple of

2
00:00:01,400 --> 00:00:03,840
minutes just a couple of seconds just

3
00:00:02,560 --> 00:00:05,680
for us to bring everybody together into

4
00:00:03,840 --> 00:00:07,759
the panel session so I really just

5
00:00:05,680 --> 00:00:09,679
wanted to say thank you to all the

6
00:00:07,759 --> 00:00:11,840
speakers so far for some fantastic

7
00:00:09,679 --> 00:00:13,960
forward-looking very Broad and very

8
00:00:11,840 --> 00:00:15,679
challenging presentations touching on

9
00:00:13,960 --> 00:00:18,039
everything from jobs and skills and

10
00:00:15,679 --> 00:00:20,359
economics to biotech and synthetic

11
00:00:18,039 --> 00:00:21,720
biology and AI uh it's obviously clear

12
00:00:20,359 --> 00:00:23,560
that Manu Advanced design and

13
00:00:21,720 --> 00:00:25,359
Manufacturing are going to be you know

14
00:00:23,560 --> 00:00:27,359
kind of key foundational capabilities

15
00:00:25,359 --> 00:00:28,880
for the future of our economies and for

16
00:00:27,359 --> 00:00:30,279
tackling some of our our hardest

17
00:00:28,880 --> 00:00:32,360
problems including things like climate

18
00:00:30,279 --> 00:00:34,239
change and for the development of new

19
00:00:32,360 --> 00:00:36,200
Innovative products and services but

20
00:00:34,239 --> 00:00:37,280
also for like National competitiveness

21
00:00:36,200 --> 00:00:39,160
and Regional

22
00:00:37,280 --> 00:00:41,079
competitiveness so now everybody's back

23
00:00:39,160 --> 00:00:42,840
in I wanted to kind assert the

24
00:00:41,079 --> 00:00:45,440
moderator's privilege to maybe ask the

25
00:00:42,840 --> 00:00:46,879
first question while we uh um get other

26
00:00:45,440 --> 00:00:49,559
people's questions I really encourage

27
00:00:46,879 --> 00:00:52,320
Their audience to um add uh new

28
00:00:49,559 --> 00:00:56,719
questions to Q&A but a certain am amount

29
00:00:52,320 --> 00:00:57,760
of moderator privilege um you know one

30
00:00:56,719 --> 00:00:59,199
of the things I'd like to encourage the

31
00:00:57,760 --> 00:01:01,359
speakers we're not really aiming for

32
00:00:59,199 --> 00:01:03,160
consensus but you know the things we we

33
00:01:01,359 --> 00:01:04,680
don't agree on may be as interesting and

34
00:01:03,160 --> 00:01:08,080
and important as the ones that we the

35
00:01:04,680 --> 00:01:09,200
ones that we do um so you know given

36
00:01:08,080 --> 00:01:10,640
that we have an audience that's kind of

37
00:01:09,200 --> 00:01:13,040
drawn from multiple industries from

38
00:01:10,640 --> 00:01:16,360
multiple regions from government from

39
00:01:13,040 --> 00:01:19,360
industry um from non from nonprofits and

40
00:01:16,360 --> 00:01:23,119
from Civil Society you what would be the

41
00:01:19,360 --> 00:01:25,079
the you the one uh key action or Insight

42
00:01:23,119 --> 00:01:26,720
that you would each kind of really you

43
00:01:25,079 --> 00:01:28,119
suggest that people take away from our

44
00:01:26,720 --> 00:01:29,400
you know the discussion this morning and

45
00:01:28,119 --> 00:01:31,600
then we'll move into questions from the

46
00:01:29,400 --> 00:01:33,399
audience so I don't know Ben do you want

47
00:01:31,600 --> 00:01:39,119
to kick off on

48
00:01:33,399 --> 00:01:42,079
that sure uh I've been really I think so

49
00:01:39,119 --> 00:01:44,479
I hear the two clusters of

50
00:01:42,079 --> 00:01:46,560
presentations um talking about Workforce

51
00:01:44,479 --> 00:01:48,799
issues so how we develop new skills and

52
00:01:46,560 --> 00:01:51,159
how we learn to perform in a more

53
00:01:48,799 --> 00:01:53,320
digital manufacturing environment and

54
00:01:51,159 --> 00:01:55,040
then also there are these presentations

55
00:01:53,320 --> 00:01:57,159
about exciting new technological

56
00:01:55,040 --> 00:02:00,039
possibilities new products that we can

57
00:01:57,159 --> 00:02:02,399
produce new ways of producing them and

58
00:02:00,039 --> 00:02:05,640
then part of me thinks about

59
00:02:02,399 --> 00:02:07,719
organizational behavior and how um

60
00:02:05,640 --> 00:02:10,000
organizations you know both employers

61
00:02:07,719 --> 00:02:11,800
but also maybe regulatory organizations

62
00:02:10,000 --> 00:02:16,959
or government organizations that provide

63
00:02:11,800 --> 00:02:18,440
incentives can can um adapt to the these

64
00:02:16,959 --> 00:02:21,200
new technologies and new skill

65
00:02:18,440 --> 00:02:23,040
requirements and one of the pieces that

66
00:02:21,200 --> 00:02:24,720
I find so interesting is that

67
00:02:23,040 --> 00:02:26,599
organizations just like people aren't

68
00:02:24,720 --> 00:02:27,800
always rational they make decisions in

69
00:02:26,599 --> 00:02:30,120
the short term that are going to hurt

70
00:02:27,800 --> 00:02:32,800
them in the long term and in some cas

71
00:02:30,120 --> 00:02:35,160
they're predictably irrational so one of

72
00:02:32,800 --> 00:02:38,000
the uh areas that I emphasized that I

73
00:02:35,160 --> 00:02:39,760
want to bring back up is is risk is that

74
00:02:38,000 --> 00:02:42,000
we've evolved in the United States and

75
00:02:39,760 --> 00:02:43,959
to some extent in certain Western

76
00:02:42,000 --> 00:02:46,040
European markets to be extremely risk

77
00:02:43,959 --> 00:02:47,360
averse when it comes to manufacturing

78
00:02:46,040 --> 00:02:48,440
only to produce the things we know how

79
00:02:47,360 --> 00:02:50,599
to produce well where we have an

80
00:02:48,440 --> 00:02:53,239
existing comparative advantage and not

81
00:02:50,599 --> 00:02:56,239
to take chances to produce new things

82
00:02:53,239 --> 00:02:58,239
where essenti these organizations might

83
00:02:56,239 --> 00:02:59,680
fail at producing it competitively but

84
00:02:58,239 --> 00:03:03,080
still might learn something along the

85
00:02:59,680 --> 00:03:05,000
way way and I think the example from F's

86
00:03:03,080 --> 00:03:08,120
presentation earlier was you know this

87
00:03:05,000 --> 00:03:10,799
is for for employers to use or develop

88
00:03:08,120 --> 00:03:12,319
new designs um right now or to implement

89
00:03:10,799 --> 00:03:14,879
them in manufacturing it's highly costly

90
00:03:12,319 --> 00:03:18,400
and risky but new technologies can help

91
00:03:14,879 --> 00:03:21,480
drisk that experimentation and drisk

92
00:03:18,400 --> 00:03:24,040
exploration um of new possibilities so I

93
00:03:21,480 --> 00:03:26,920
think um the role for for government

94
00:03:24,040 --> 00:03:29,920
nonprofits is in many ways to to drisk

95
00:03:26,920 --> 00:03:31,000
experimentation and Innovation um and do

96
00:03:29,920 --> 00:03:32,879
manufacturing but it's also for

97
00:03:31,000 --> 00:03:36,239
technologists to help drisk that process

98
00:03:32,879 --> 00:03:38,159
as well um so I I I'd like to emphasize

99
00:03:36,239 --> 00:03:40,200
that thank you and that I think that's

100
00:03:38,159 --> 00:03:42,280
that's very incisive Bruce do you have

101
00:03:40,200 --> 00:03:44,400
any any thoughts on that I'm sorry could

102
00:03:42,280 --> 00:03:46,400
you repeat the question oh yeah so

103
00:03:44,400 --> 00:03:48,200
basically you know from the the range of

104
00:03:46,400 --> 00:03:50,120
of conversations we've been having is

105
00:03:48,200 --> 00:03:53,599
what would be the you know the one kind

106
00:03:50,120 --> 00:03:55,519
of action that you'd recommend for

107
00:03:53,599 --> 00:03:57,439
either leaders from industry or from

108
00:03:55,519 --> 00:03:58,640
kind of you know government or nonprofit

109
00:03:57,439 --> 00:04:00,640
they're engaged in the manufacturing

110
00:03:58,640 --> 00:04:03,120
space you know

111
00:04:00,640 --> 00:04:06,319
yeah so I I think that if you look at

112
00:04:03,120 --> 00:04:10,599
what we're doing at at rebuild um

113
00:04:06,319 --> 00:04:13,959
certainly implementing lean um so

114
00:04:10,599 --> 00:04:16,840
simplify and standardize really look at

115
00:04:13,959 --> 00:04:18,840
that hard before you do any automation

116
00:04:16,840 --> 00:04:21,000
so that's the first thing U second thing

117
00:04:18,840 --> 00:04:23,759
is just training your people I know you

118
00:04:21,000 --> 00:04:25,759
ask me for one thing but um training

119
00:04:23,759 --> 00:04:29,320
your people in datadriven decision

120
00:04:25,759 --> 00:04:31,600
making um that is machine learning AI is

121
00:04:29,320 --> 00:04:35,560
all about about learning from data and

122
00:04:31,600 --> 00:04:39,160
if we don't collect data uh store it and

123
00:04:35,560 --> 00:04:41,400
trust it none of this technology matters

124
00:04:39,160 --> 00:04:45,000
on top of it so if we we don't do the

125
00:04:41,400 --> 00:04:47,520
basics to make processes as simple as

126
00:04:45,000 --> 00:04:49,520
possible um and then if we don't do the

127
00:04:47,520 --> 00:04:51,520
basics of collecting and making

128
00:04:49,520 --> 00:04:54,520
decisions with data just with dashboards

129
00:04:51,520 --> 00:04:56,840
some basic analytics just some charts uh

130
00:04:54,520 --> 00:05:00,280
to start with statistical process

131
00:04:56,840 --> 00:05:02,800
control as an example um

132
00:05:00,280 --> 00:05:05,000
it that's the foundation for all of this

133
00:05:02,800 --> 00:05:07,360
and if we can't do those things for at

134
00:05:05,000 --> 00:05:10,800
least AI we if we don't do those things

135
00:05:07,360 --> 00:05:13,120
the rest of it it it won't it won't work

136
00:05:10,800 --> 00:05:15,000
so and I think people jump right over

137
00:05:13,120 --> 00:05:17,280
that they want to go to the latest model

138
00:05:15,000 --> 00:05:19,759
or the coolest thing and they forget

139
00:05:17,280 --> 00:05:22,160
those foundational elements of

140
00:05:19,759 --> 00:05:24,000
training and uh

141
00:05:22,160 --> 00:05:25,199
simplification no I think I think that's

142
00:05:24,000 --> 00:05:26,720
fantastic because that really does point

143
00:05:25,199 --> 00:05:29,120
to the kind of the the heavy lifting

144
00:05:26,720 --> 00:05:31,120
that's required in sustaining sustaining

145
00:05:29,120 --> 00:05:32,600
innovation within ex established

146
00:05:31,120 --> 00:05:34,800
Industries and those sorts things so so

147
00:05:32,600 --> 00:05:35,560
just move to Chris so Chris you're very

148
00:05:34,800 --> 00:05:38,720
much

149
00:05:35,560 --> 00:05:40,360
representing kind of an emerging new

150
00:05:38,720 --> 00:05:42,600
manufacturing field a whole new set of

151
00:05:40,360 --> 00:05:45,680
products a whole new set of processes

152
00:05:42,600 --> 00:05:47,080
you know you like your perspective other

153
00:05:45,680 --> 00:05:48,680
things that either reflected particular

154
00:05:47,080 --> 00:05:51,160
of the The Bu manufacturing space but

155
00:05:48,680 --> 00:05:53,880
more generally in terms of how we

156
00:05:51,160 --> 00:05:56,199
approach moving into these these nent

157
00:05:53,880 --> 00:05:58,680
spaces where there's as as Ben mentioned

158
00:05:56,199 --> 00:06:01,319
high risk um you know new Workforce

159
00:05:58,680 --> 00:06:02,960
challenges new technology challenges

160
00:06:01,319 --> 00:06:04,720
regulatory challenges you know what's

161
00:06:02,960 --> 00:06:06,080
the big moving question you know

162
00:06:04,720 --> 00:06:07,759
principle question that you would you'd

163
00:06:06,080 --> 00:06:10,759
recommend in that kind of

164
00:06:07,759 --> 00:06:12,960
space yeah I think kind of like to me

165
00:06:10,759 --> 00:06:14,240
how do we as the various stakeholders

166
00:06:12,960 --> 00:06:15,880
around these questions whether you're in

167
00:06:14,240 --> 00:06:18,800
BIO or traditional manufacturing is how

168
00:06:15,880 --> 00:06:21,280
do we make manufacturing cool again

169
00:06:18,800 --> 00:06:23,039
right people love to make things and

170
00:06:21,280 --> 00:06:24,520
they want to be able to make them for a

171
00:06:23,039 --> 00:06:27,120
variety of different

172
00:06:24,520 --> 00:06:29,000
purposes how do we embed the complexity

173
00:06:27,120 --> 00:06:30,759
of Technologies and all of the tools

174
00:06:29,000 --> 00:06:33,039
we've talked about here into the

175
00:06:30,759 --> 00:06:35,039
Manufacturing Systems such that people

176
00:06:33,039 --> 00:06:37,639
are free to do the things that they want

177
00:06:35,039 --> 00:06:40,120
to do with them and I think in some ways

178
00:06:37,639 --> 00:06:42,560
this is actually a little counter in

179
00:06:40,120 --> 00:06:44,400
maybe the lean ideas right lean lean

180
00:06:42,560 --> 00:06:46,520
doesn't like Innovation it only

181
00:06:44,400 --> 00:06:48,199
innovates through the practices of what

182
00:06:46,520 --> 00:06:51,720
it's already done but it doesn't leave

183
00:06:48,199 --> 00:06:53,319
room for truly transformative new ideas

184
00:06:51,720 --> 00:06:55,120
and so as we kind of think about how do

185
00:06:53,319 --> 00:06:57,520
we train workforces how do we bring new

186
00:06:55,120 --> 00:06:59,599
technologies online we have to kind of

187
00:06:57,520 --> 00:07:01,120
build a society where we embrace the

188
00:06:59,599 --> 00:07:02,280
manufacturing is going to look different

189
00:07:01,120 --> 00:07:03,960
given that we now have different

190
00:07:02,280 --> 00:07:05,319
Technologies right I mean why do we

191
00:07:03,960 --> 00:07:07,759
continue to make things the way that we

192
00:07:05,319 --> 00:07:09,639
did 50 years ago this is true and bio

193
00:07:07,759 --> 00:07:11,199
it's true and in mechanical systems when

194
00:07:09,639 --> 00:07:12,800
we have all of these new things that are

195
00:07:11,199 --> 00:07:15,160
advancing I appreciate it they're not

196
00:07:12,800 --> 00:07:17,360
fully advantaged yet to be able to roll

197
00:07:15,160 --> 00:07:18,520
out but that's where the kind of messy

198
00:07:17,360 --> 00:07:20,160
part comes in and I think where the

199
00:07:18,520 --> 00:07:21,599
opportunity lies how do we train

200
00:07:20,160 --> 00:07:22,919
students to be excited to work in these

201
00:07:21,599 --> 00:07:24,960
spaces how do we show them that it's

202
00:07:22,919 --> 00:07:26,960
going to be possible and how do we sort

203
00:07:24,960 --> 00:07:29,120
of as companies bring the parts together

204
00:07:26,960 --> 00:07:31,520
to show how it's going to be possible

205
00:07:29,120 --> 00:07:33,319
and really Dr risk as Ben was saying

206
00:07:31,520 --> 00:07:35,360
some of these newer

207
00:07:33,319 --> 00:07:37,680
ideas no I think that's fantastic I

208
00:07:35,360 --> 00:07:39,639
think that that kind of uh Echoes off

209
00:07:37,680 --> 00:07:41,120
this sense of this side of this lump

210
00:07:39,639 --> 00:07:43,160
labor fallacy there's only a certain

211
00:07:41,120 --> 00:07:44,520
amount of work to be done it's almost as

212
00:07:43,160 --> 00:07:46,000
if there's like there's not only a

213
00:07:44,520 --> 00:07:47,800
certain number of things to make there's

214
00:07:46,000 --> 00:07:49,440
always new things that we would you know

215
00:07:47,800 --> 00:07:51,520
we can imagine and we can make and so

216
00:07:49,440 --> 00:07:53,319
that that expanding Frontier I think

217
00:07:51,520 --> 00:07:55,800
that that brings us really to to fire

218
00:07:53,319 --> 00:07:58,080
it's like you how how do you think about

219
00:07:55,800 --> 00:07:59,599
this kind of not just the optimization

220
00:07:58,080 --> 00:08:01,720
of things we do at the moment but you

221
00:07:59,599 --> 00:08:03,360
know bring these sorts of approaches to

222
00:08:01,720 --> 00:08:05,080
the new things that we can create and

223
00:08:03,360 --> 00:08:07,919
the new ways that we can use them and

224
00:08:05,080 --> 00:08:09,440
the new ways that we can organize around

225
00:08:07,919 --> 00:08:11,520
kind of fabrication and use and those

226
00:08:09,440 --> 00:08:15,280
sorts things using techniques like

227
00:08:11,520 --> 00:08:17,800
gen yeah so I think um overall I've been

228
00:08:15,280 --> 00:08:20,080
very excited about the new possibilities

229
00:08:17,800 --> 00:08:23,240
that have opened up and a key thing that

230
00:08:20,080 --> 00:08:26,039
has changed is we have we have been

231
00:08:23,240 --> 00:08:28,720
looking at Ai and I think aiid driven

232
00:08:26,039 --> 00:08:33,080
Solutions but now what we are looking at

233
00:08:28,720 --> 00:08:35,320
is the start of the idea of General AI

234
00:08:33,080 --> 00:08:37,240
which is that the AI model is not just

235
00:08:35,320 --> 00:08:39,519
trained to do one thing but it can

236
00:08:37,240 --> 00:08:42,719
actually help with many different things

237
00:08:39,519 --> 00:08:44,600
and chat GPT type models are one example

238
00:08:42,719 --> 00:08:47,080
of it but this is the direction that I

239
00:08:44,600 --> 00:08:51,600
think is definitely the one of the key

240
00:08:47,080 --> 00:08:54,720
things that will drive um the many of

241
00:08:51,600 --> 00:08:59,279
the design and Manufacturing AED AI AED

242
00:08:54,720 --> 00:09:02,120
design and Manufacturing advances and um

243
00:08:59,279 --> 00:09:04,240
yeah yeah I I I think from from my

244
00:09:02,120 --> 00:09:06,519
perspective I always like to think how

245
00:09:04,240 --> 00:09:08,600
can we leverage all this amazing

246
00:09:06,519 --> 00:09:12,200
knowledge of optimization and

247
00:09:08,600 --> 00:09:14,440
simulations to help the AI models rather

248
00:09:12,200 --> 00:09:16,000
than just say we'll start from scratch

249
00:09:14,440 --> 00:09:17,920
because there is so much knowledge that

250
00:09:16,000 --> 00:09:20,360
has already been built and how can you

251
00:09:17,920 --> 00:09:21,399
create and combine these two to come up

252
00:09:20,360 --> 00:09:23,560
with better

253
00:09:21,399 --> 00:09:25,040
Solutions and so far we have seen a lot

254
00:09:23,560 --> 00:09:27,720
of promising

255
00:09:25,040 --> 00:09:30,480
results that sounds fantastic so just I

256
00:09:27,720 --> 00:09:33,600
want to give one example kind of to uh

257
00:09:30,480 --> 00:09:37,440
Chris's point on lean and Innovation and

258
00:09:33,600 --> 00:09:40,440
so what we've seen is we did a a project

259
00:09:37,440 --> 00:09:43,040
where uh we we bring the incoming part

260
00:09:40,440 --> 00:09:44,880
so we're not trying to design the final

261
00:09:43,040 --> 00:09:46,959
thing we're trying to design all the

262
00:09:44,880 --> 00:09:49,440
derivative works so we bring an incoming

263
00:09:46,959 --> 00:09:52,760
part we automatically generate the mold

264
00:09:49,440 --> 00:09:54,279
that makes the part and then we Auto and

265
00:09:52,760 --> 00:09:55,600
the the fixtures that are used to trim

266
00:09:54,279 --> 00:09:57,959
it these are actually Theros set

267
00:09:55,600 --> 00:10:02,200
composits and then we automatically

268
00:09:57,959 --> 00:10:04,800
generate the CNC cutter paths to cut

269
00:10:02,200 --> 00:10:06,279
that so we can bring the part in and do

270
00:10:04,800 --> 00:10:08,120
that whole workflow and it it's in a

271
00:10:06,279 --> 00:10:10,480
fairly constrained environment of a

272
00:10:08,120 --> 00:10:12,800
certain types of parts so it actually

273
00:10:10,480 --> 00:10:16,120
you know the generative AI Works quite

274
00:10:12,800 --> 00:10:18,040
well but one in order to do the tool

275
00:10:16,120 --> 00:10:19,800
paths we had to make some assumptions

276
00:10:18,040 --> 00:10:21,920
that essentially we're going to fill the

277
00:10:19,800 --> 00:10:24,560
tool holder with five tools and with

278
00:10:21,920 --> 00:10:28,160
those five tools we can machine

279
00:10:24,560 --> 00:10:30,720
anything we couldn't get the operators

280
00:10:28,160 --> 00:10:32,320
on the floor to put the five tools in

281
00:10:30,720 --> 00:10:34,959
the tool holder even though they could

282
00:10:32,320 --> 00:10:37,279
do everything with those five tools they

283
00:10:34,959 --> 00:10:38,839
had their own tools that they liked so

284
00:10:37,279 --> 00:10:40,839
we're actually in the process now of

285
00:10:38,839 --> 00:10:42,920
running a lean transformation of

286
00:10:40,839 --> 00:10:45,440
bringing everybody on board looking at

287
00:10:42,920 --> 00:10:47,440
the whole process and helping them to

288
00:10:45,440 --> 00:10:49,639
understand how this does change their

289
00:10:47,440 --> 00:10:52,720
job so this is where all this great Cool

290
00:10:49,639 --> 00:10:55,440
Tech kind of meets reality and we find

291
00:10:52,720 --> 00:10:57,120
that lean is a way to bring those two

292
00:10:55,440 --> 00:10:58,920
worlds together we call it you know

293
00:10:57,120 --> 00:11:01,480
digital lean how do we bring the Two

294
00:10:58,920 --> 00:11:03,200
Worlds together with the and it's the

295
00:11:01,480 --> 00:11:05,360
continuous Improvement respect for

296
00:11:03,200 --> 00:11:07,320
people kind of

297
00:11:05,360 --> 00:11:08,720
construct that's fantastic I just wanted

298
00:11:07,320 --> 00:11:10,720
to follow up one of the questions that's

299
00:11:08,720 --> 00:11:13,399
come in from from the audience on on

300
00:11:10,720 --> 00:11:14,440
lean U and it was a question Bruce the

301
00:11:13,399 --> 00:11:16,079
um said when working on lean

302
00:11:14,440 --> 00:11:17,200
implementations in small scale

303
00:11:16,079 --> 00:11:19,160
businesses and I know we had a lot of

304
00:11:17,200 --> 00:11:21,000
focus in the conversation around this

305
00:11:19,160 --> 00:11:22,399
kind of the the large bulk of us

306
00:11:21,000 --> 00:11:24,600
manufacturing being in smaller

307
00:11:22,399 --> 00:11:26,800
organizations so we often see businesses

308
00:11:24,600 --> 00:11:28,959
that have a relatively High degree of

309
00:11:26,800 --> 00:11:29,920
customization uh High mix low volume

310
00:11:28,959 --> 00:11:31,800
High

311
00:11:29,920 --> 00:11:33,519
customization um you know it's kind of

312
00:11:31,800 --> 00:11:35,560
an under researched area in how do you

313
00:11:33,519 --> 00:11:38,639
help these small organizations sustain

314
00:11:35,560 --> 00:11:41,040
lean in this kind of low volume custom

315
00:11:38,639 --> 00:11:43,320
small small manufacturer kind of

316
00:11:41,040 --> 00:11:45,959
environments uh it's it's really got to

317
00:11:43,320 --> 00:11:47,600
be driven by the top it has to be part

318
00:11:45,959 --> 00:11:52,839
of the the

319
00:11:47,600 --> 00:11:55,000
culture um and it it it takes a lot of

320
00:11:52,839 --> 00:11:58,000
work like for example at rebuild we have

321
00:11:55,000 --> 00:12:00,200
a chief a chief lean officer so a chief

322
00:11:58,000 --> 00:12:03,760
executive and the

323
00:12:00,200 --> 00:12:06,000
CEO pushes this as a concept the entire

324
00:12:03,760 --> 00:12:09,160
senior leadership team participates in

325
00:12:06,000 --> 00:12:12,480
lean events so it happens at all levels

326
00:12:09,160 --> 00:12:16,440
of the organization uh there are monthly

327
00:12:12,480 --> 00:12:20,240
goals for lean Improvement so it's it's

328
00:12:16,440 --> 00:12:22,839
a significant effort um but it has

329
00:12:20,240 --> 00:12:25,800
significant payoff so it's it's not a

330
00:12:22,839 --> 00:12:28,000
set of tools that you use it's not a 5S

331
00:12:25,800 --> 00:12:29,839
chart that you put up on the wall it

332
00:12:28,000 --> 00:12:31,360
really is in in order for it to be

333
00:12:29,839 --> 00:12:34,120
effective a cultural

334
00:12:31,360 --> 00:12:36,680
transformation and that's not 6 months

335
00:12:34,120 --> 00:12:39,720
and it didn't work it's multiple years

336
00:12:36,680 --> 00:12:42,000
of getting better better better and and

337
00:12:39,720 --> 00:12:44,120
Bruce if I could just follow up from

338
00:12:42,000 --> 00:12:46,320
some of what I've learned is that it it

339
00:12:44,120 --> 00:12:48,279
also seems to go into your hiring where

340
00:12:46,320 --> 00:12:50,279
I think some organizations use lean and

341
00:12:48,279 --> 00:12:51,519
they're essentially oh we'll hire people

342
00:12:50,279 --> 00:12:52,639
and they you know maybe we'll we'll

343
00:12:51,519 --> 00:12:54,839
teach them they'll go through a lean

344
00:12:52,639 --> 00:12:58,079
training with a third party but I think

345
00:12:54,839 --> 00:13:00,279
that the what a cultural transformation

346
00:12:58,079 --> 00:13:02,680
means is like you also hire people who

347
00:13:00,279 --> 00:13:05,000
are bought in that they're going to be

348
00:13:02,680 --> 00:13:07,560
responsible for making improvements in

349
00:13:05,000 --> 00:13:09,600
their own um station in the company and

350
00:13:07,560 --> 00:13:11,399
it's also higher skill expectations that

351
00:13:09,600 --> 00:13:14,000
I think you have for workers that you

352
00:13:11,399 --> 00:13:15,040
bring in do you think that's fair yes

353
00:13:14,000 --> 00:13:18,120
and

354
00:13:15,040 --> 00:13:20,800
specialized lean Engineers lean managers

355
00:13:18,120 --> 00:13:23,480
lean transformation coaches throughout

356
00:13:20,800 --> 00:13:27,160
the organization on site that is what

357
00:13:23,480 --> 00:13:29,880
they do so their additional staff 1 to

358
00:13:27,160 --> 00:13:32,920
3% of

359
00:13:29,880 --> 00:13:37,120
of people so it's actually adding people

360
00:13:32,920 --> 00:13:37,120
but you get more than that Improvement

361
00:13:38,079 --> 00:13:42,720
back no I think that that seems to play

362
00:13:40,959 --> 00:13:44,880
to one of the things that seem to be

363
00:13:42,720 --> 00:13:48,320
coming out around this kind of idea that

364
00:13:44,880 --> 00:13:50,320
the the knowledge environment that the

365
00:13:48,320 --> 00:13:52,440
uh all the people involved in

366
00:13:50,320 --> 00:13:54,920
manufacturing kind of are working in is

367
00:13:52,440 --> 00:13:57,160
is changing dramatically it's you know

368
00:13:54,920 --> 00:13:58,040
the with the kind of the ability to

369
00:13:57,160 --> 00:14:00,399
understand more about what's going on in

370
00:13:58,040 --> 00:14:02,639
the plant about the design about having

371
00:14:00,399 --> 00:14:04,360
much softer equipment that can be retas

372
00:14:02,639 --> 00:14:07,199
as you say five machines in a box kind

373
00:14:04,360 --> 00:14:08,839
of thing um you and one of the question

374
00:14:07,199 --> 00:14:10,880
that came in F was related to that and

375
00:14:08,839 --> 00:14:13,240
it's in terms of says um do you see the

376
00:14:10,880 --> 00:14:15,199
potential for using geni design

377
00:14:13,240 --> 00:14:17,440
co-pilots the means of generating

378
00:14:15,199 --> 00:14:19,160
Dynamic assembly methods for lean

379
00:14:17,440 --> 00:14:20,959
Fabrication in custom environments and I

380
00:14:19,160 --> 00:14:23,120
think it' be to give you all to comment

381
00:14:20,959 --> 00:14:26,600
on this question about you as we move

382
00:14:23,120 --> 00:14:28,639
forward into this environment where the

383
00:14:26,600 --> 00:14:30,839
production plants are more flexible the

384
00:14:28,639 --> 00:14:33,360
products are more varied the skills are

385
00:14:30,839 --> 00:14:35,199
at a higher level and we've got the AI

386
00:14:33,360 --> 00:14:37,480
tools to help us interpret that how does

387
00:14:35,199 --> 00:14:40,240
that all kind of play out so F do you

388
00:14:37,480 --> 00:14:43,000
want to you kick off on that sure yeah I

389
00:14:40,240 --> 00:14:45,320
think um the answer is I do definitely

390
00:14:43,000 --> 00:14:49,040
see a possibility of that happening

391
00:14:45,320 --> 00:14:52,079
there is uh thinking about the assembly

392
00:14:49,040 --> 00:14:53,880
methods U there are some early works

393
00:14:52,079 --> 00:14:57,199
that we have seen which uh which look

394
00:14:53,880 --> 00:14:58,880
promising having said that a like like a

395
00:14:57,199 --> 00:15:01,920
lot of other things that I mentioned in

396
00:14:58,880 --> 00:15:04,279
my I talk the key thing or kind of the

397
00:15:01,920 --> 00:15:08,160
top three things for the same problem is

398
00:15:04,279 --> 00:15:10,720
data data and data so if we can get data

399
00:15:08,160 --> 00:15:12,720
the generative AI models can solve much

400
00:15:10,720 --> 00:15:14,560
complex problems than Dynamic assembly

401
00:15:12,720 --> 00:15:17,920
and if you can collect data for it or if

402
00:15:14,560 --> 00:15:20,199
we can use Le leverage existing data I

403
00:15:17,920 --> 00:15:23,399
think this is U not a very complex

404
00:15:20,199 --> 00:15:26,040
problem from that perspective um but the

405
00:15:23,399 --> 00:15:28,040
quality of the data the bias in the data

406
00:15:26,040 --> 00:15:30,319
the extent of the data the modality of

407
00:15:28,040 --> 00:15:34,399
the data all of those things are things

408
00:15:30,319 --> 00:15:34,399
to think about when when looking at new

409
00:15:34,959 --> 00:15:38,959
applications so Ben I you you've been

410
00:15:37,279 --> 00:15:41,480
right in the middle of this kind of uh

411
00:15:38,959 --> 00:15:44,120
debate about how this kind of new new

412
00:15:41,480 --> 00:15:46,560
forms of knowledge is affecting the um

413
00:15:44,120 --> 00:15:48,279
you know the use of AI within

414
00:15:46,560 --> 00:15:50,839
organizations so I don't you any

415
00:15:48,279 --> 00:15:52,519
thoughts on this space well maybe if I

416
00:15:50,839 --> 00:15:55,480
could follow up what I find so

417
00:15:52,519 --> 00:15:57,560
interesting about your work as is the um

418
00:15:55,480 --> 00:15:59,480
a democratization of design and I think

419
00:15:57,560 --> 00:16:01,880
you're able to point out clear

420
00:15:59,480 --> 00:16:04,279
limitations in high stakes environments

421
00:16:01,880 --> 00:16:06,759
that these tools you need kind of an

422
00:16:04,279 --> 00:16:08,600
expert interpreter to know whether these

423
00:16:06,759 --> 00:16:10,519
designs are ready for prime time in

424
00:16:08,600 --> 00:16:12,519
manufacturing or what to what to be

425
00:16:10,519 --> 00:16:14,399
useful and what not to be useful and you

426
00:16:12,519 --> 00:16:16,319
see this in other manifestations with

427
00:16:14,399 --> 00:16:18,720
like GitHub co-pilot for coding for

428
00:16:16,319 --> 00:16:21,279
example that really you know excellent

429
00:16:18,720 --> 00:16:23,880
programmers who know what they want and

430
00:16:21,279 --> 00:16:26,160
can interpret code can use it to really

431
00:16:23,880 --> 00:16:27,920
you know become a superstar programmer

432
00:16:26,160 --> 00:16:29,360
highly improve their productivity but

433
00:16:27,920 --> 00:16:32,240
someone in the hands of someone who

434
00:16:29,360 --> 00:16:33,959
doesn't quite know what good programming

435
00:16:32,240 --> 00:16:35,880
looks like it could be maybe a dangerous

436
00:16:33,959 --> 00:16:37,800
tool or a tool that leads them astray

437
00:16:35,880 --> 00:16:39,920
and some of the researches has I think

438
00:16:37,800 --> 00:16:41,959
confirmed that for those interested you

439
00:16:39,920 --> 00:16:44,199
might look at this study of BCG

440
00:16:41,959 --> 00:16:45,560
Consultants that shows on on some tasks

441
00:16:44,199 --> 00:16:46,880
all the Consultants improve their

442
00:16:45,560 --> 00:16:48,920
performance when they use generative a

443
00:16:46,880 --> 00:16:51,959
but in other tasks you have Consultants

444
00:16:48,920 --> 00:16:53,959
that are persuaded to uh to you know

445
00:16:51,959 --> 00:16:55,120
essentially pick the wrong answer um

446
00:16:53,959 --> 00:16:56,600
when they're using generative AI but

447
00:16:55,120 --> 00:16:59,079
they get the right answer without that

448
00:16:56,600 --> 00:17:01,319
sort of assistance so I wonder when we

449
00:16:59,079 --> 00:17:03,439
talk about democratizing design are

450
00:17:01,319 --> 00:17:05,720
these tools only going to be useful for

451
00:17:03,439 --> 00:17:07,240
designers who already know how to design

452
00:17:05,720 --> 00:17:09,000
for manufacturing because they're able

453
00:17:07,240 --> 00:17:11,480
to point out they're able to pick out

454
00:17:09,000 --> 00:17:14,480
the designs that are already um

455
00:17:11,480 --> 00:17:16,839
applicable or is it really going to uh

456
00:17:14,480 --> 00:17:18,799
lower the barrier to entry for for

457
00:17:16,839 --> 00:17:20,799
design so I do wonder if if you know

458
00:17:18,799 --> 00:17:23,319
like what expertise is still required

459
00:17:20,799 --> 00:17:25,720
here I think and it depends on what

460
00:17:23,319 --> 00:17:28,960
stage of the new tool that we are in I

461
00:17:25,720 --> 00:17:31,520
want to kind of draw a a similarity to

462
00:17:28,960 --> 00:17:34,400
when finite element analysis software or

463
00:17:31,520 --> 00:17:37,120
cfd software came up initially people

464
00:17:34,400 --> 00:17:39,000
were hesitant to use them then people

465
00:17:37,120 --> 00:17:40,760
started using them but always verified

466
00:17:39,000 --> 00:17:43,600
it and at this point most of our

467
00:17:40,760 --> 00:17:46,000
students just use it blindly right but

468
00:17:43,600 --> 00:17:48,120
the expert students really know when the

469
00:17:46,000 --> 00:17:50,760
Tool gives a wrong answer or when it can

470
00:17:48,120 --> 00:17:53,080
have convergence issues similar to this

471
00:17:50,760 --> 00:17:55,320
I think there is the aspect of with any

472
00:17:53,080 --> 00:17:57,880
new tool there is a learning curve and

473
00:17:55,320 --> 00:17:59,480
there is a tech development curve the

474
00:17:57,880 --> 00:18:01,520
second part of your question is really

475
00:17:59,480 --> 00:18:03,200
interesting because I think the key

476
00:18:01,520 --> 00:18:04,880
value that we get with these type of

477
00:18:03,200 --> 00:18:08,039
tools is for a

478
00:18:04,880 --> 00:18:09,919
nonexpert and as the tools develop right

479
00:18:08,039 --> 00:18:12,280
right now we have some prototypes where

480
00:18:09,919 --> 00:18:14,120
you can go and ask it to generate a cad

481
00:18:12,280 --> 00:18:17,799
model in simple text language and it can

482
00:18:14,120 --> 00:18:20,039
generate simple CAD models now if you

483
00:18:17,799 --> 00:18:22,200
look at the current learning curve of C

484
00:18:20,039 --> 00:18:24,640
CAD software students have to come up in

485
00:18:22,200 --> 00:18:26,559
an engineering school learn how to do

486
00:18:24,640 --> 00:18:28,280
Cad and then they learn one software and

487
00:18:26,559 --> 00:18:30,720
they never switch because the cost of

488
00:18:28,280 --> 00:18:32,520
switching is very high right so there

489
00:18:30,720 --> 00:18:34,480
this is where I see there is

490
00:18:32,520 --> 00:18:37,039
democratization where you're not

491
00:18:34,480 --> 00:18:38,840
necessarily becoming experts in tools

492
00:18:37,039 --> 00:18:41,600
but you're thinking more around your

493
00:18:38,840 --> 00:18:43,760
ideas but you will of course learn to

494
00:18:41,600 --> 00:18:45,760
use the AI as a tool because AI is also

495
00:18:43,760 --> 00:18:48,039
a tool in

496
00:18:45,760 --> 00:18:49,840
itself D if I can jump in a little bit I

497
00:18:48,039 --> 00:18:51,400
think AI is kind of a huge wild card in

498
00:18:49,840 --> 00:18:52,960
the biotech space and I'm sure everyone

499
00:18:51,400 --> 00:18:55,400
saw yesterday the Nobel Prize was

500
00:18:52,960 --> 00:18:57,760
awarded for the ideation of proteins

501
00:18:55,400 --> 00:18:59,400
using AI tools it's now possible to

502
00:18:57,760 --> 00:19:00,960
think of entirely new proteins that

503
00:18:59,400 --> 00:19:03,080
didn't exist before the problem that

504
00:19:00,960 --> 00:19:05,080
still exists now is to how do you take

505
00:19:03,080 --> 00:19:07,039
those proteins that have been designed

506
00:19:05,080 --> 00:19:08,880
and actually manufacture them right the

507
00:19:07,039 --> 00:19:11,159
the models aren't good enough to account

508
00:19:08,880 --> 00:19:14,600
for all of the natural elements required

509
00:19:11,159 --> 00:19:15,880
to produce them at scale uh it seems to

510
00:19:14,600 --> 00:19:17,679
me right this is really how

511
00:19:15,880 --> 00:19:19,679
democratization might play in where

512
00:19:17,679 --> 00:19:21,880
biology because we can start to generate

513
00:19:19,679 --> 00:19:24,000
larger data sets and we need to do so in

514
00:19:21,880 --> 00:19:25,520
the manufacturing space you you could

515
00:19:24,000 --> 00:19:26,840
actually imagine design tools for

516
00:19:25,520 --> 00:19:28,400
biology now that don't really know

517
00:19:26,840 --> 00:19:30,200
anything about the underlying biology

518
00:19:28,400 --> 00:19:31,720
but say say I want to make this protein

519
00:19:30,200 --> 00:19:33,840
I need a host to do it and I need a

520
00:19:31,720 --> 00:19:35,080
process that will accommodate it you

521
00:19:33,840 --> 00:19:36,840
know I think this is really where the

522
00:19:35,080 --> 00:19:38,880
potential is at the intersection there

523
00:19:36,840 --> 00:19:40,200
that hasn't really been realized yet but

524
00:19:38,880 --> 00:19:42,120
uh you know I think like we've seen in

525
00:19:40,200 --> 00:19:44,240
these other fields will be quite

526
00:19:42,120 --> 00:19:45,520
exciting so Chris you want just to W the

527
00:19:44,240 --> 00:19:48,799
other side of that which is obviously

528
00:19:45,520 --> 00:19:50,400
the um biology is slightly different to

529
00:19:48,799 --> 00:19:54,080
many other manufacturing spaces in that

530
00:19:50,400 --> 00:19:56,520
we are biology um and the the idea that

531
00:19:54,080 --> 00:19:58,159
you know um we got used to the idea that

532
00:19:56,520 --> 00:20:00,240
everyone can write software and

533
00:19:58,159 --> 00:20:03,159
manufactur software that everybody can

534
00:20:00,240 --> 00:20:04,559
uh design screws and manufacture screws

535
00:20:03,159 --> 00:20:07,760
um but the idea that everybody can

536
00:20:04,559 --> 00:20:10,280
manufacture biology is kind of a um a

537
00:20:07,760 --> 00:20:11,880
fairly new idea and the implications

538
00:20:10,280 --> 00:20:13,600
that at scale and what kind of models we

539
00:20:11,880 --> 00:20:15,039
need to do to understand how the

540
00:20:13,600 --> 00:20:17,000
molecules we produce will actually

541
00:20:15,039 --> 00:20:18,320
impact on the human systems diversity of

542
00:20:17,000 --> 00:20:20,720
those

543
00:20:18,320 --> 00:20:23,200
so have you sense of how that may break

544
00:20:20,720 --> 00:20:24,520
open that manufacturing space yeah I

545
00:20:23,200 --> 00:20:26,440
mean I think if we already look at

546
00:20:24,520 --> 00:20:28,679
what's happening in you know a lot of

547
00:20:26,440 --> 00:20:30,600
large companies that have gotten spun up

548
00:20:28,679 --> 00:20:32,400
in the synthetic biology space we could

549
00:20:30,600 --> 00:20:34,600
look at genko or amoris or some of these

550
00:20:32,400 --> 00:20:37,120
others that have really automated much

551
00:20:34,600 --> 00:20:38,919
of the front end of I have a gene I want

552
00:20:37,120 --> 00:20:41,120
to be able to put in an organism I can

553
00:20:38,919 --> 00:20:42,840
make an organism that now does that so

554
00:20:41,120 --> 00:20:44,440
the front end is starting to show that

555
00:20:42,840 --> 00:20:45,960
it's going to be feasible to start and

556
00:20:44,440 --> 00:20:47,480
you start to layer in some of these AI

557
00:20:45,960 --> 00:20:49,919
tools I think it's going to become you

558
00:20:47,480 --> 00:20:51,400
know even more facile you know where the

559
00:20:49,919 --> 00:20:53,000
the challenges sort of as you pointed

560
00:20:51,400 --> 00:20:54,919
out which is thinking about how do we go

561
00:20:53,000 --> 00:20:57,440
from I built a strain that performs a

562
00:20:54,919 --> 00:20:59,039
task to that strain now has to operate

563
00:20:57,440 --> 00:21:00,760
in an environment that I've defined it

564
00:20:59,039 --> 00:21:02,720
in this could be a bioreactor in the

565
00:21:00,760 --> 00:21:04,600
context what we've talked about or it

566
00:21:02,720 --> 00:21:05,720
could be you know some type of harsh

567
00:21:04,600 --> 00:21:07,600
environment you know if we're thinking

568
00:21:05,720 --> 00:21:09,000
about terraforming or things like this

569
00:21:07,600 --> 00:21:10,799
and then of course what's the impact of

570
00:21:09,000 --> 00:21:13,120
the interaction of that system with that

571
00:21:10,799 --> 00:21:14,880
environment and ecosystem I think we can

572
00:21:13,120 --> 00:21:17,440
kind of break it into these three parts

573
00:21:14,880 --> 00:21:19,000
that we have to think a lot more about

574
00:21:17,440 --> 00:21:21,960
the front end I think is relatively

575
00:21:19,000 --> 00:21:23,400
straightforward today work to be done

576
00:21:21,960 --> 00:21:25,080
but it's a time and money question the

577
00:21:23,400 --> 00:21:27,520
other two I think really still require a

578
00:21:25,080 --> 00:21:29,440
lot of fundamental research one just in

579
00:21:27,520 --> 00:21:30,720
the manufacturing s sence itself and you

580
00:21:29,440 --> 00:21:32,320
know what's that relationship how do we

581
00:21:30,720 --> 00:21:33,799
start to build the data sets to support

582
00:21:32,320 --> 00:21:35,799
that and then on the back hand I think

583
00:21:33,799 --> 00:21:38,279
it's it's sort of the societal and and

584
00:21:35,799 --> 00:21:40,279
ethical questions of where should we be

585
00:21:38,279 --> 00:21:41,720
leveraging biology to do this it's very

586
00:21:40,279 --> 00:21:43,960
possible to do a wide number of things

587
00:21:41,720 --> 00:21:45,120
today should we is I think a very fair

588
00:21:43,960 --> 00:21:46,880
question that I think we all have to

589
00:21:45,120 --> 00:21:49,039
Grapple

590
00:21:46,880 --> 00:21:50,480
with that's great so we had a couple of

591
00:21:49,039 --> 00:21:52,840
questions coming in that kind of bridge

592
00:21:50,480 --> 00:21:56,559
two areas so one area is very much this

593
00:21:52,840 --> 00:21:58,080
kind of um kind of cultural aspects you

594
00:21:56,559 --> 00:22:01,360
basically the you know the management

595
00:21:58,080 --> 00:22:02,520
management culture and change inside of

596
00:22:01,360 --> 00:22:03,880
organizations manufacturing

597
00:22:02,520 --> 00:22:05,440
organizations that going through these

598
00:22:03,880 --> 00:22:07,960
Transitions and then the other one is

599
00:22:05,440 --> 00:22:10,279
around this question of kind of um

600
00:22:07,960 --> 00:22:11,240
ecosystems so these kind of broader like

601
00:22:10,279 --> 00:22:13,200
skills

602
00:22:11,240 --> 00:22:16,000
Workforce um technology development

603
00:22:13,200 --> 00:22:17,520
ecosystem so I don't know whether you um

604
00:22:16,000 --> 00:22:19,320
you know people had had thoughts on

605
00:22:17,520 --> 00:22:22,000
either those in those like internal

606
00:22:19,320 --> 00:22:24,960
cultural aspects and change methods and

607
00:22:22,000 --> 00:22:26,919
Bruce obvious V to lean but um and also

608
00:22:24,960 --> 00:22:28,520
these questions about kind of taking

609
00:22:26,919 --> 00:22:30,039
those outside into these broader system

610
00:22:28,520 --> 00:22:32,080
systems like Regional Workforce

611
00:22:30,039 --> 00:22:33,679
ecosystems how do we manage things like

612
00:22:32,080 --> 00:22:35,240
poaching and those sorts of half-life of

613
00:22:33,679 --> 00:22:36,919
skills and things like that so I know

614
00:22:35,240 --> 00:22:39,520
Ben don't whether you want to to kick

615
00:22:36,919 --> 00:22:41,559
off in that kind of space sure and I'll

616
00:22:39,520 --> 00:22:45,000
go back to one of the specific questions

617
00:22:41,559 --> 00:22:48,039
which Drew on some of Bruce's data about

618
00:22:45,000 --> 00:22:50,880
unfilled positions in in manufacturing

619
00:22:48,039 --> 00:22:52,720
how there is a higher demand for job

620
00:22:50,880 --> 00:22:55,120
than there is a supply of of skilled

621
00:22:52,720 --> 00:22:57,720
workers in manufacturing and that's been

622
00:22:55,120 --> 00:22:59,960
growing uh as a problem since 2018

623
00:22:57,720 --> 00:23:03,080
certainly acceler during the pandemic or

624
00:22:59,960 --> 00:23:04,799
sorry really since the early 2010s not

625
00:23:03,080 --> 00:23:05,480
and and then has been accelerating since

626
00:23:04,799 --> 00:23:08,360
the

627
00:23:05,480 --> 00:23:12,240
pandemic you know I I think there are a

628
00:23:08,360 --> 00:23:15,000
few Dimensions to this problem one is

629
00:23:12,240 --> 00:23:17,880
Cle clearly wages that companies that

630
00:23:15,000 --> 00:23:20,640
that we work with that pay high wages to

631
00:23:17,880 --> 00:23:23,240
their production Workforce have far less

632
00:23:20,640 --> 00:23:25,279
problem uh you know far reduced problem

633
00:23:23,240 --> 00:23:27,159
in recruiting that their workers more

634
00:23:25,279 --> 00:23:29,480
excited to to go to those firms I mean

635
00:23:27,159 --> 00:23:31,600
that's that's pretty straightforward how

636
00:23:29,480 --> 00:23:32,840
do you offer how do you justify offering

637
00:23:31,600 --> 00:23:34,760
higher wages well you become more

638
00:23:32,840 --> 00:23:36,360
productive you you know you adopt more

639
00:23:34,760 --> 00:23:38,240
Advanced Technologies and the practices

640
00:23:36,360 --> 00:23:39,840
like but Bruce was talking about so

641
00:23:38,240 --> 00:23:42,360
there is this really you know positive

642
00:23:39,840 --> 00:23:43,919
feedback loop I think between adopting

643
00:23:42,360 --> 00:23:46,159
really Advanced production practices and

644
00:23:43,919 --> 00:23:48,039
being able to recruit workers um one of

645
00:23:46,159 --> 00:23:50,640
the things that we've seen and this

646
00:23:48,039 --> 00:23:53,760
relates a bit to the culture question is

647
00:23:50,640 --> 00:23:55,799
that we've seen multiple very distinct

648
00:23:53,760 --> 00:23:58,600
models of organizing work so if you just

649
00:23:55,799 --> 00:23:59,640
think about how do you design a job so

650
00:23:58,600 --> 00:24:02,120
in manufacturing there's a lot of

651
00:23:59,640 --> 00:24:03,400
attention to designing processes on a

652
00:24:02,120 --> 00:24:05,799
factory floor there's attention to

653
00:24:03,400 --> 00:24:07,840
designing products but there's not

654
00:24:05,799 --> 00:24:10,720
really as much attention to designing

655
00:24:07,840 --> 00:24:12,960
individual jobs what workers do um the

656
00:24:10,720 --> 00:24:14,279
Japanese in in the introduction of cross

657
00:24:12,960 --> 00:24:17,400
training at companies like Toyota and

658
00:24:14,279 --> 00:24:20,240
Honda Nissan were were Pioneers in

659
00:24:17,400 --> 00:24:22,400
thinking about ergonomics and how do you

660
00:24:20,240 --> 00:24:24,679
you know not overwork people in in

661
00:24:22,400 --> 00:24:27,279
certain tasks but there what I mean by a

662
00:24:24,679 --> 00:24:29,440
job design is is a little different I

663
00:24:27,279 --> 00:24:30,919
would you know think about Job design

664
00:24:29,440 --> 00:24:33,559
similarly how do you design anything

665
00:24:30,919 --> 00:24:35,159
else you think about your your customer

666
00:24:33,559 --> 00:24:36,760
you think about what motivates them what

667
00:24:35,159 --> 00:24:38,399
they want and rarely do we really ask

668
00:24:36,760 --> 00:24:39,360
those questions about workers and

669
00:24:38,399 --> 00:24:41,279
particularly the workers that would

670
00:24:39,360 --> 00:24:42,760
thrive in a manufacturing environment

671
00:24:41,279 --> 00:24:44,080
instead we think okay well what is the

672
00:24:42,760 --> 00:24:46,679
process demand and I'm going to stick a

673
00:24:44,080 --> 00:24:47,960
person here so so one of the things that

674
00:24:46,679 --> 00:24:52,120
I see from the highest performing

675
00:24:47,960 --> 00:24:53,919
organizations we study is a much flatter

676
00:24:52,120 --> 00:24:55,919
organization of work and what I mean by

677
00:24:53,919 --> 00:24:58,000
that is traditionally you'll have kind

678
00:24:55,919 --> 00:24:59,480
of um what I hear from the community

679
00:24:58,000 --> 00:25:02,799
college folks is like they talk about

680
00:24:59,480 --> 00:25:04,480
721 how they train people SE seven folks

681
00:25:02,799 --> 00:25:07,360
on the front lines and kind of operator

682
00:25:04,480 --> 00:25:10,679
roles to two people in let's say setup

683
00:25:07,360 --> 00:25:12,039
or managerial roles to one engineer and

684
00:25:10,679 --> 00:25:13,960
that's very traditional you it varies a

685
00:25:12,039 --> 00:25:16,320
ton by industry but what It ultimately

686
00:25:13,960 --> 00:25:18,000
it is is it's pyramidal that you have uh

687
00:25:16,320 --> 00:25:20,399
a lot of people in these lower skill

688
00:25:18,000 --> 00:25:23,320
lower wage jobs and then fewer people in

689
00:25:20,399 --> 00:25:25,000
the higher skilled jobs and and what I I

690
00:25:23,320 --> 00:25:27,399
think you know at at rebuild they do

691
00:25:25,000 --> 00:25:28,960
this to some extent and and at other uh

692
00:25:27,399 --> 00:25:31,159
high-tech factories they do this where

693
00:25:28,960 --> 00:25:33,559
it's you expect every Frontline worker

694
00:25:31,159 --> 00:25:35,559
to have technical skills uh Bruce talked

695
00:25:33,559 --> 00:25:38,799
about this expectation at North American

696
00:25:35,559 --> 00:25:40,600
stainless where it it's not that you you

697
00:25:38,799 --> 00:25:42,240
just have the two people who do setup

698
00:25:40,600 --> 00:25:44,320
everyone is capable of doing setup and

699
00:25:42,240 --> 00:25:46,760
they can rotate through those positions

700
00:25:44,320 --> 00:25:48,720
everyone has the ability to

701
00:25:46,760 --> 00:25:50,640
troubleshoot uh machine programming

702
00:25:48,720 --> 00:25:53,000
issues or troubleshoot any issues with

703
00:25:50,640 --> 00:25:54,279
with robots um everyone has the

704
00:25:53,000 --> 00:25:56,159
opportunity you know everyone has the

705
00:25:54,279 --> 00:25:59,399
knowledge to run a CMM and and do kind

706
00:25:56,159 --> 00:26:01,600
of uh quality control so so that type of

707
00:25:59,399 --> 00:26:03,760
flattening of the manufacturing

708
00:26:01,600 --> 00:26:05,240
Workforce and designing jobs to require

709
00:26:03,760 --> 00:26:07,000
multiple different skills so people can

710
00:26:05,240 --> 00:26:08,080
slot in different parts and also can

711
00:26:07,000 --> 00:26:10,760
participate more in continuous

712
00:26:08,080 --> 00:26:13,120
Improvement I think is a big part of of

713
00:26:10,760 --> 00:26:14,600
a culture shift and like what John said

714
00:26:13,120 --> 00:26:17,120
at the beginning it's just you know you

715
00:26:14,600 --> 00:26:18,440
can expect more of people on the factory

716
00:26:17,120 --> 00:26:21,840
floor and I think they can they they

717
00:26:18,440 --> 00:26:24,600
rise to the occasion in these

718
00:26:21,840 --> 00:26:26,320
firms no I think that's I think that go

719
00:26:24,600 --> 00:26:30,240
back to I think some of the conclusions

720
00:26:26,320 --> 00:26:32,080
of the MIT uh work of the future report

721
00:26:30,240 --> 00:26:34,159
and I think there's this idea that the

722
00:26:32,080 --> 00:26:36,000
workforce has become by very bifurcated

723
00:26:34,159 --> 00:26:37,480
and the future has to be much more where

724
00:26:36,000 --> 00:26:41,120
there's no we don't have that Gap in the

725
00:26:37,480 --> 00:26:42,559
middle of the workforce um so I know

726
00:26:41,120 --> 00:26:45,799
we're coming close to time we had one

727
00:26:42,559 --> 00:26:47,080
last question come in um which is around

728
00:26:45,799 --> 00:26:50,080
this question really how do we get

729
00:26:47,080 --> 00:26:52,360
started on this AI stuff um so somebody

730
00:26:50,080 --> 00:26:55,840
was asking a question about are people

731
00:26:52,360 --> 00:26:57,640
using their own um AI models and tuning

732
00:26:55,840 --> 00:27:00,279
them are they you I guess that goes both

733
00:26:57,640 --> 00:27:02,000
to both the the general uh language

734
00:27:00,279 --> 00:27:04,559
processing for we doing textual stuff

735
00:27:02,000 --> 00:27:05,760
but also to manufacturing processes so

736
00:27:04,559 --> 00:27:07,480
you know how do you recommend that

737
00:27:05,760 --> 00:27:10,000
people kind of get started with this in

738
00:27:07,480 --> 00:27:11,399
terms of either using existing llms

739
00:27:10,000 --> 00:27:12,919
commercial ones or building Their Own

740
00:27:11,399 --> 00:27:15,520
Foundation models in some of these kind

741
00:27:12,919 --> 00:27:17,039
of spaces um I don't know who wants to

742
00:27:15,520 --> 00:27:19,559
who wants to take that well I can talk

743
00:27:17,039 --> 00:27:21,320
in general I won't go in necessarily to

744
00:27:19,559 --> 00:27:23,559
training Your Own Foundation models I

745
00:27:21,320 --> 00:27:26,039
would say most people should not try

746
00:27:23,559 --> 00:27:28,679
that in fact people who have have found

747
00:27:26,039 --> 00:27:31,159
that the the actual large line

748
00:27:28,679 --> 00:27:33,960
large language models works better but

749
00:27:31,159 --> 00:27:35,360
um than custom trained ones but um just

750
00:27:33,960 --> 00:27:37,559
because they train a much larger data

751
00:27:35,360 --> 00:27:40,200
set but in general the the whole reason

752
00:27:37,559 --> 00:27:42,679
we created the study the M the study

753
00:27:40,200 --> 00:27:45,320
that we collaborate with McKenzie on is

754
00:27:42,679 --> 00:27:49,320
to EXA answer that exact question first

755
00:27:45,320 --> 00:27:51,760
of all um think of it like Google Maps

756
00:27:49,320 --> 00:27:55,399
so first of all what we do is we lay out

757
00:27:51,760 --> 00:27:58,399
a map of of the different stages the the

758
00:27:55,399 --> 00:28:01,039
different routes you can go through um

759
00:27:58,399 --> 00:28:02,840
then we position you on that map we

760
00:28:01,039 --> 00:28:05,679
essentially Benchmark you show you where

761
00:28:02,840 --> 00:28:08,640
you fit and then we help you understand

762
00:28:05,679 --> 00:28:10,840
how do you go to the next level and so I

763
00:28:08,640 --> 00:28:13,679
will just tell you kind of the the

764
00:28:10,840 --> 00:28:15,919
general starting point is pick a problem

765
00:28:13,679 --> 00:28:18,600
that really matters to your business not

766
00:28:15,919 --> 00:28:20,840
one that's cool one that really matters

767
00:28:18,600 --> 00:28:24,159
to your business and that if you move

768
00:28:20,840 --> 00:28:26,600
the needle on it it will have a material

769
00:28:24,159 --> 00:28:27,919
bottom line impact to the business so

770
00:28:26,600 --> 00:28:29,360
that's the first thing makes it a whole

771
00:28:27,919 --> 00:28:33,480
lot EAS you to do your

772
00:28:29,360 --> 00:28:35,960
Roi collect data on it so put sensors in

773
00:28:33,480 --> 00:28:37,399
so you know I talked about we we had a

774
00:28:35,960 --> 00:28:39,960
situation where our scrap rate was

775
00:28:37,399 --> 00:28:42,840
really high on a very important part so

776
00:28:39,960 --> 00:28:44,760
we collected data on it now in our case

777
00:28:42,840 --> 00:28:46,799
we had enough skills that we did our own

778
00:28:44,760 --> 00:28:50,159
analytics but largely a lot of them can

779
00:28:46,799 --> 00:28:52,880
be done in powerbi but the the third

780
00:28:50,159 --> 00:28:55,600
step I would recommend is find a vendor

781
00:28:52,880 --> 00:28:57,840
who can solve that problem and help you

782
00:28:55,600 --> 00:28:59,600
do it because it's going to be very hard

783
00:28:57,840 --> 00:29:01,360
to typically for you to hire the data

784
00:28:59,600 --> 00:29:04,159
science skills that you need especially

785
00:29:01,360 --> 00:29:06,440
if you're smaller so um if these

786
00:29:04,159 --> 00:29:08,559
problems are in solution spaces where

787
00:29:06,440 --> 00:29:10,919
they exist you can get someone like a

788
00:29:08,559 --> 00:29:12,399
falconry or someone like an augury to do

789
00:29:10,919 --> 00:29:14,279
predictive maintenance they're they're

790
00:29:12,399 --> 00:29:17,200
out there and we're what we're even

791
00:29:14,279 --> 00:29:19,799
found in the last study is manufacturers

792
00:29:17,200 --> 00:29:23,120
and Rebuilders doing this as well are

793
00:29:19,799 --> 00:29:26,919
creating micr vertical Solutions so

794
00:29:23,120 --> 00:29:29,519
Titan cement is making AI for cement

795
00:29:26,919 --> 00:29:30,720
manufacturers they're Greek company so

796
00:29:29,519 --> 00:29:32,480
they know they're only going to operate

797
00:29:30,720 --> 00:29:35,279
in Greece but they can sell their

798
00:29:32,480 --> 00:29:38,760
software to cement manufacturers

799
00:29:35,279 --> 00:29:41,440
globally um so Cooper standard is doing

800
00:29:38,760 --> 00:29:42,960
that with H belts and hoses they're

801
00:29:41,440 --> 00:29:45,960
making

802
00:29:42,960 --> 00:29:47,679
a uh kind of a real-time process control

803
00:29:45,960 --> 00:29:51,200
using generative AI tool that they

804
00:29:47,679 --> 00:29:53,159
Market kind of live works so uh take

805
00:29:51,200 --> 00:29:55,679
advantage of those kinds of solutions so

806
00:29:53,159 --> 00:29:57,080
that's and I'll let FES or someone else

807
00:29:55,679 --> 00:30:00,279
answer to the really give a better

808
00:29:57,080 --> 00:30:04,000
answer to the Jered AI

809
00:30:00,279 --> 00:30:06,840
question great so uh I think I would uh

810
00:30:04,000 --> 00:30:09,320
like to start with first thing yes we do

811
00:30:06,840 --> 00:30:12,240
we do train our own generative llm

812
00:30:09,320 --> 00:30:14,000
models and BLM models having said that

813
00:30:12,240 --> 00:30:16,559
that's not something I would recommend

814
00:30:14,000 --> 00:30:19,600
to people who are starting it requires a

815
00:30:16,559 --> 00:30:21,840
lot of compute and a lot of data I would

816
00:30:19,600 --> 00:30:24,440
definitely I think the lucky thing right

817
00:30:21,840 --> 00:30:27,679
now is it's a problem of plenty if you

818
00:30:24,440 --> 00:30:28,519
go to any online resources is just like

819
00:30:27,679 --> 00:30:31,159
uh

820
00:30:28,519 --> 00:30:34,799
huge set of learning resources that are

821
00:30:31,159 --> 00:30:36,600
available on all of these topics for

822
00:30:34,799 --> 00:30:38,760
what I recommend to my students so I

823
00:30:36,600 --> 00:30:41,320
teach a AI for engineering design class

824
00:30:38,760 --> 00:30:44,120
and many of the students from mechi but

825
00:30:41,320 --> 00:30:46,360
other schools also like Sloan and

826
00:30:44,120 --> 00:30:48,919
architecture and other schools

827
00:30:46,360 --> 00:30:51,600
they one of the key things that students

828
00:30:48,919 --> 00:30:53,159
learn the most is by picking a project

829
00:30:51,600 --> 00:30:55,600
that they're excited about which is I

830
00:30:53,159 --> 00:30:58,240
think what Bruce was also mentioning is

831
00:30:55,600 --> 00:31:01,120
pick a project which may be relative

832
00:30:58,240 --> 00:31:03,240
simple and you can get access to data

833
00:31:01,120 --> 00:31:05,960
and try to go through that entire

834
00:31:03,240 --> 00:31:08,039
pipeline of how does it work and I think

835
00:31:05,960 --> 00:31:10,639
that really helps you incrementally

836
00:31:08,039 --> 00:31:14,600
build on more and more complex things as

837
00:31:10,639 --> 00:31:17,080
you learn about the process and yeah uh

838
00:31:14,600 --> 00:31:19,360
that's it's a fun

839
00:31:17,080 --> 00:31:21,440
Journey well thank you very much and I

840
00:31:19,360 --> 00:31:22,960
know we're at time so I'm I'm GNA draw

841
00:31:21,440 --> 00:31:26,000
to conclude so first I want to say thank

842
00:31:22,960 --> 00:31:27,480
you to to all of our speakers for some

843
00:31:26,000 --> 00:31:29,960
really fantastic questions and some

844
00:31:27,480 --> 00:31:32,880
fantastic interaction over over the over

845
00:31:29,960 --> 00:31:34,159
the panel um and then I wanted to you to

846
00:31:32,880 --> 00:31:35,559
thank the audience really and thank you

847
00:31:34,159 --> 00:31:37,240
for joining us I hope you enjoyed the

848
00:31:35,559 --> 00:31:40,880
presentations and the conversation I

849
00:31:37,240 --> 00:31:42,159
found it challenging and and useful um

850
00:31:40,880 --> 00:31:44,159
I'd also like to to thank the

851
00:31:42,159 --> 00:31:46,720
communications team here the help to

852
00:31:44,159 --> 00:31:48,559
organize the event and obviously a a

853
00:31:46,720 --> 00:31:50,120
special thank to our our speakers

854
00:31:48,559 --> 00:31:53,320
including my co conspirator on setting

855
00:31:50,120 --> 00:31:55,240
this up Ben um in a few days the

856
00:31:53,320 --> 00:31:57,000
recording of the uh the webinar will be

857
00:31:55,240 --> 00:32:00,240
available to our members on the website

858
00:31:57,000 --> 00:32:01,799
which is ILP mit.edu and I also want to

859
00:32:00,240 --> 00:32:04,320
just take a couple of seconds just to

860
00:32:01,799 --> 00:32:07,720
highlight a fewer upcoming events uh we

861
00:32:04,320 --> 00:32:09,159
have three upcoming uh oncampus events

862
00:32:07,720 --> 00:32:10,519
uh here at MIT we should also be

863
00:32:09,159 --> 00:32:12,159
streamed to members we have a

864
00:32:10,519 --> 00:32:14,840
sustainability conference coming up on

865
00:32:12,159 --> 00:32:18,039
the 22nd of October a nano Summit on the

866
00:32:14,840 --> 00:32:19,799
23rd of October and our Capstone R&D

867
00:32:18,039 --> 00:32:21,240
conference on the 19th and 20th of

868
00:32:19,799 --> 00:32:23,320
November which is a kind of a big

869
00:32:21,240 --> 00:32:25,320
multirack conference all those will be

870
00:32:23,320 --> 00:32:27,240
streamed uh We've also got Regional

871
00:32:25,320 --> 00:32:30,360
member conference in Paris on October

872
00:32:27,240 --> 00:32:32,720
the 17th Madrid on nov the 14th and

873
00:32:30,360 --> 00:32:34,120
Houston on December the 3D and we have

874
00:32:32,720 --> 00:32:36,760
two more webinars scheduled

875
00:32:34,120 --> 00:32:38,679
decarbonization on the 7th of November

876
00:32:36,760 --> 00:32:41,039
and a startup exchange demo day on the

877
00:32:38,679 --> 00:32:43,639
11th of December registation for all

878
00:32:41,039 --> 00:32:45,200
these events on our website uh the team

879
00:32:43,639 --> 00:32:47,200
here at MIT looks very much looks

880
00:32:45,200 --> 00:32:48,799
forward to seeing you all on on campus

881
00:32:47,200 --> 00:32:51,399
again or at some of our regional events

882
00:32:48,799 --> 00:32:53,519
or even online so thank you very much to

883
00:32:51,399 --> 00:32:56,360
both to our speakers and to all our

884
00:32:53,519 --> 00:33:00,519
attendees um and have a enjoyable rest

885
00:32:56,360 --> 00:33:00,519
of your days thank you right


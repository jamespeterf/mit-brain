1
00:00:01,120 --> 00:00:06,120
all right so let's get started let's

2
00:00:03,120 --> 00:00:08,160
welcome Henry vanen bam uh he is the

3
00:00:06,120 --> 00:00:10,759
senior vice president machine learning

4
00:00:08,160 --> 00:00:13,320
research chem informatics and atom wise

5
00:00:10,759 --> 00:00:16,600
Inc and also a professor in

6
00:00:13,320 --> 00:00:19,720
UCSF the stage is yours all

7
00:00:16,600 --> 00:00:21,320
right thank you and thank you for uh

8
00:00:19,720 --> 00:00:23,920
thank I want to thank the organizers for

9
00:00:21,320 --> 00:00:26,560
the opportunity uh to to speak here so

10
00:00:23,920 --> 00:00:30,480
developing and using generative AI for H

11
00:00:26,560 --> 00:00:35,440
identification and uh and optimization

12
00:00:30,480 --> 00:00:38,160
um I'm at Adam wise Adam wise is a um AI

13
00:00:35,440 --> 00:00:41,840
first preclinical small molecule drug

14
00:00:38,160 --> 00:00:43,640
Discovery uh company and you know when

15
00:00:41,840 --> 00:00:45,360
we're thinking about AI in drug

16
00:00:43,640 --> 00:00:47,520
Discovery especially for small molecules

17
00:00:45,360 --> 00:00:50,399
the conversation very quickly turns to

18
00:00:47,520 --> 00:00:53,359
faster and cheaper um but we believe

19
00:00:50,399 --> 00:00:55,120
that the the True Value uh for Pharma is

20
00:00:53,359 --> 00:00:57,239
delivered by either first-in-class or

21
00:00:55,120 --> 00:00:59,320
best-in-class uh medicine so

22
00:00:57,239 --> 00:01:01,000
first-in-class is there no known ligans

23
00:00:59,320 --> 00:01:03,079
for that particular particular Target

24
00:01:01,000 --> 00:01:06,320
and Best in Class is we try to escape

25
00:01:03,079 --> 00:01:08,720
limitations of uh of known

26
00:01:06,320 --> 00:01:11,360
chemotypes and so we develop technology

27
00:01:08,720 --> 00:01:14,479
to focus on either first in class or um

28
00:01:11,360 --> 00:01:17,479
or Best in Class um we have our uh

29
00:01:14,479 --> 00:01:19,880
internal pipeline um shown here um in

30
00:01:17,479 --> 00:01:22,880
particular I want to highlight tik2 CNS

31
00:01:19,880 --> 00:01:26,079
and i4r um both would be first-in-class

32
00:01:22,880 --> 00:01:30,439
uh uh medicines for us and in addition

33
00:01:26,079 --> 00:01:34,600
to these uh we also um have um uh

34
00:01:30,439 --> 00:01:37,119
programs with our external big PHA uh

35
00:01:34,600 --> 00:01:39,399
Partners all right we believe that uh

36
00:01:37,119 --> 00:01:41,680
that AI in particular can uh can add

37
00:01:39,399 --> 00:01:44,000
value to First in class and and and Best

38
00:01:41,680 --> 00:01:46,680
in Class by exploring designs that are

39
00:01:44,000 --> 00:01:49,280
Beyond human intuition and what I mean

40
00:01:46,680 --> 00:01:53,680
by that is in a more traditional sort of

41
00:01:49,280 --> 00:01:57,439
AI uh AI workflow in um in drug

42
00:01:53,680 --> 00:01:59,399
Discovery um the models score a lot of

43
00:01:57,439 --> 00:02:02,240
uh a lot of compounds and then the

44
00:01:59,399 --> 00:02:04,680
medicinal chemists look at it and decide

45
00:02:02,240 --> 00:02:06,920
which compounds we are going to make um

46
00:02:04,680 --> 00:02:09,280
an an essay and that's what you see in a

47
00:02:06,920 --> 00:02:11,280
more traditional sort of CAD workflow we

48
00:02:09,280 --> 00:02:13,440
had adom wise um and what you get is

49
00:02:11,280 --> 00:02:15,920
sort of the consensus between the

50
00:02:13,440 --> 00:02:18,280
machine learning uh models and the um

51
00:02:15,920 --> 00:02:20,360
and a medical chemist what we do at adom

52
00:02:18,280 --> 00:02:22,680
WISE is trying to build on the Synergy

53
00:02:20,360 --> 00:02:25,200
of uh of of these two and and really

54
00:02:22,680 --> 00:02:27,879
look at the union so our models

55
00:02:25,200 --> 00:02:31,280
typically evaluate millions or billions

56
00:02:27,879 --> 00:02:34,480
of of compounds especially in uh in hit

57
00:02:31,280 --> 00:02:36,640
Discovery um and uh and generate in a

58
00:02:34,480 --> 00:02:40,360
way an order list of let's say 400 or

59
00:02:36,640 --> 00:02:42,519
800 uh compounds and we order that uh

60
00:02:40,360 --> 00:02:44,640
that list no matter what even if our

61
00:02:42,519 --> 00:02:46,599
medicinal chemists don't recognize

62
00:02:44,640 --> 00:02:49,120
immediately that this is a compound that

63
00:02:46,599 --> 00:02:51,000
could be uh that could be successful in

64
00:02:49,120 --> 00:02:54,319
other words we don't build a human

65
00:02:51,000 --> 00:02:56,920
classifier on top of a a Ai and that's

66
00:02:54,319 --> 00:03:00,000
important because when I put on my AI

67
00:02:56,920 --> 00:03:01,680
hat I don't I want my models to learn

68
00:03:00,000 --> 00:03:04,760
from what they predict right and that's

69
00:03:01,680 --> 00:03:07,080
very critical to um in a in an active

70
00:03:04,760 --> 00:03:10,159
learning uh

71
00:03:07,080 --> 00:03:12,319
cycle all right when I say models um our

72
00:03:10,159 --> 00:03:13,920
our models are um are what we call

73
00:03:12,319 --> 00:03:16,080
Global models Global structure-based

74
00:03:13,920 --> 00:03:20,440
models what I mean by that is they are

75
00:03:16,080 --> 00:03:25,040
trained simultaneously on um on uh about

76
00:03:20,440 --> 00:03:28,000
7,000 uh uh targets um about 20 million

77
00:03:25,040 --> 00:03:30,519
uh bi biological data points that go uh

78
00:03:28,000 --> 00:03:32,799
that go into that and in a in a in a

79
00:03:30,519 --> 00:03:36,159
typical training run we generate about

80
00:03:32,799 --> 00:03:38,720
1.1 billion Co co- complexes now these

81
00:03:36,159 --> 00:03:41,360
sound like hug huge numbers of course

82
00:03:38,720 --> 00:03:44,519
but if you think about the universe of

83
00:03:41,360 --> 00:03:47,000
um um of possible compounds this is just

84
00:03:44,519 --> 00:03:50,720
a drop in the in the bucket right the

85
00:03:47,000 --> 00:03:54,200
reason we employ um Global models is

86
00:03:50,720 --> 00:03:56,840
that we want our models to learn the

87
00:03:54,200 --> 00:03:59,319
mechanisms of of molecular recognition

88
00:03:56,840 --> 00:04:02,200
because we feel that is transferable

89
00:03:59,319 --> 00:04:03,840
across the uh the entire uh the entire

90
00:04:02,200 --> 00:04:06,560
proteome and that's a little bit in

91
00:04:03,840 --> 00:04:08,079
contrast to um you know the more Target

92
00:04:06,560 --> 00:04:10,400
specific models where you have one

93
00:04:08,079 --> 00:04:12,519
target you look at the compounds that uh

94
00:04:10,400 --> 00:04:14,959
that are known for that Target um and

95
00:04:12,519 --> 00:04:17,239
you train a model uh based on that the

96
00:04:14,959 --> 00:04:20,400
limitation of that is it's often very

97
00:04:17,239 --> 00:04:22,280
difficult to um to generalize away from

98
00:04:20,400 --> 00:04:25,440
the from the chemotypes that are already

99
00:04:22,280 --> 00:04:29,280
known from that uh from that

100
00:04:25,440 --> 00:04:31,600
Target all right um we tested our our

101
00:04:29,280 --> 00:04:34,280
our model mod um actually we we do

102
00:04:31,600 --> 00:04:35,919
continuous testing but um but in in this

103
00:04:34,280 --> 00:04:38,960
particular case we went out to our

104
00:04:35,919 --> 00:04:41,800
partners and um and academic uh

105
00:04:38,960 --> 00:04:45,960
collaborators um to run a very very

106
00:04:41,800 --> 00:04:48,759
large hit Discovery campaign on 318 uh

107
00:04:45,960 --> 00:04:51,720
targets um Al together and we got quite

108
00:04:48,759 --> 00:04:55,160
good results we we found hits for about

109
00:04:51,720 --> 00:04:58,120
74% of uh of these targets and I want to

110
00:04:55,160 --> 00:05:00,560
in particular call your attention to uh

111
00:04:58,120 --> 00:05:03,160
uh this graph over here each dot

112
00:05:00,560 --> 00:05:05,800
represents a Target in this um in this

113
00:05:03,160 --> 00:05:07,639
plot on the horizontal axis you see the

114
00:05:05,800 --> 00:05:11,000
number of examples that we have in our

115
00:05:07,639 --> 00:05:14,160
training uh set for this particular uh

116
00:05:11,000 --> 00:05:16,560
uh Target and so what you should be

117
00:05:14,160 --> 00:05:18,720
particularly um devoting your attention

118
00:05:16,560 --> 00:05:22,120
to is this rectangle here these are

119
00:05:18,720 --> 00:05:24,160
targets for which we have no data in our

120
00:05:22,120 --> 00:05:25,960
um in our training set and so what that

121
00:05:24,160 --> 00:05:28,639
means is these are really the first

122
00:05:25,960 --> 00:05:30,759
in-class targets um that could be uh of

123
00:05:28,639 --> 00:05:33,720
interest and you see that we actually

124
00:05:30,759 --> 00:05:36,199
get um pretty pretty good hit rates for

125
00:05:33,720 --> 00:05:38,160
uh for those uh for those targets we

126
00:05:36,199 --> 00:05:40,720
published this study uh just earlier

127
00:05:38,160 --> 00:05:43,600
this year um AI is a viable alternative

128
00:05:40,720 --> 00:05:47,240
to high througho screening a 38 Target

129
00:05:43,600 --> 00:05:49,600
study the paper has 689 authors uh by

130
00:05:47,240 --> 00:05:54,120
far the longest list that I've ever been

131
00:05:49,600 --> 00:05:58,600
um uh uh uh part

132
00:05:54,120 --> 00:05:59,639
of all right so what is critical um what

133
00:05:58,600 --> 00:06:01,639
is critical if you're interested

134
00:05:59,639 --> 00:06:04,440
interested in first in-class uh Target

135
00:06:01,639 --> 00:06:07,599
is to to overcome a a covariant shift

136
00:06:04,440 --> 00:06:08,880
between your training data and and the

137
00:06:07,599 --> 00:06:11,479
data that you're uh that you're

138
00:06:08,880 --> 00:06:14,080
performing inference on so training data

139
00:06:11,479 --> 00:06:15,880
is often you know very very nice

140
00:06:14,080 --> 00:06:18,599
molecules often drugs that have been in

141
00:06:15,880 --> 00:06:20,400
a clinic and so they look very different

142
00:06:18,599 --> 00:06:23,039
than the kind of hit molecules that you

143
00:06:20,400 --> 00:06:24,560
typically get out of uh out of a screen

144
00:06:23,039 --> 00:06:27,120
and so machine learning models don't

145
00:06:24,560 --> 00:06:29,560
know very well how to um how to deal

146
00:06:27,120 --> 00:06:32,080
with that so there are two aspect

147
00:06:29,560 --> 00:06:34,000
effects to it first of all we so what

148
00:06:32,080 --> 00:06:36,240
they just talked about is is really the

149
00:06:34,000 --> 00:06:38,560
extrapolating to uh to new new

150
00:06:36,240 --> 00:06:40,440
chemotypes so want to understand want

151
00:06:38,560 --> 00:06:43,000
the model to understand like what could

152
00:06:40,440 --> 00:06:45,160
potential new chemotypes look like the

153
00:06:43,000 --> 00:06:48,759
other one of of course is extrapolating

154
00:06:45,160 --> 00:06:50,440
to new targets um so the vast majority

155
00:06:48,759 --> 00:06:53,319
of training data is available for

156
00:06:50,440 --> 00:06:55,360
Kinesis no surprise and so if you're

157
00:06:53,319 --> 00:06:57,120
interested in cytokines you need to

158
00:06:55,360 --> 00:07:01,039
think about how do we make the model

159
00:06:57,120 --> 00:07:03,759
aware of uh of of cyto so general

160
00:07:01,039 --> 00:07:05,919
generalizability of the models is really

161
00:07:03,759 --> 00:07:08,039
key to unlocking first inclass and

162
00:07:05,919 --> 00:07:10,720
best-in-class uh compounds at least

163
00:07:08,039 --> 00:07:14,199
that's the way uh we see

164
00:07:10,720 --> 00:07:16,960
it and so about a year ago we realized a

165
00:07:14,199 --> 00:07:21,440
way or we found a way

166
00:07:16,960 --> 00:07:23,720
um um to um help our models overcome

167
00:07:21,440 --> 00:07:25,840
that coari shift by self-supervised

168
00:07:23,720 --> 00:07:29,680
learning so we have these uh these big

169
00:07:25,840 --> 00:07:32,599
gnns and we we figured out a way to self

170
00:07:29,680 --> 00:07:35,720
to to pre-train these models on chemical

171
00:07:32,599 --> 00:07:37,919
data and Target data um for which there

172
00:07:35,720 --> 00:07:40,520
are no labels so for which there's no

173
00:07:37,919 --> 00:07:43,240
potency data for which there's no um

174
00:07:40,520 --> 00:07:45,879
activity data in a way taking a a page

175
00:07:43,240 --> 00:07:47,919
out of the book of uh of llms right

176
00:07:45,879 --> 00:07:50,400
large pre-trained models that we then

177
00:07:47,919 --> 00:07:52,639
sort of fine-tune based on uh on on

178
00:07:50,400 --> 00:07:54,879
label data and that has really changed

179
00:07:52,639 --> 00:07:58,520
the way we think about a model so we

180
00:07:54,879 --> 00:08:01,680
pre-train our models on on a large body

181
00:07:58,520 --> 00:08:03,960
of unlabeled data that gives us a base

182
00:08:01,680 --> 00:08:06,879
model and then we use the 20 million uh

183
00:08:03,960 --> 00:08:09,520
data points to in a way um develop a

184
00:08:06,879 --> 00:08:12,039
task specific model and task specific

185
00:08:09,520 --> 00:08:13,919
here means either an activity model so a

186
00:08:12,039 --> 00:08:16,120
classification model uh for our

187
00:08:13,919 --> 00:08:19,280
compounds or a regression model and this

188
00:08:16,120 --> 00:08:21,960
really goes to this Union of human

189
00:08:19,280 --> 00:08:25,360
design versus AI designed compounds

190
00:08:21,960 --> 00:08:27,520
because if you if you pre-train your

191
00:08:25,360 --> 00:08:30,080
models on unexplored chemical space it's

192
00:08:27,520 --> 00:08:32,240
these compounds that that human

193
00:08:30,080 --> 00:08:37,039
typically don't have a lot of intuition

194
00:08:32,240 --> 00:08:40,800
um about our models responded quite well

195
00:08:37,039 --> 00:08:43,599
um to this so this model here is the

196
00:08:40,800 --> 00:08:46,959
model that I just showed you for the 318

197
00:08:43,599 --> 00:08:49,519
targets and so for a long time we were

198
00:08:46,959 --> 00:08:51,920
having um a lot of difficulty building

199
00:08:49,519 --> 00:08:53,560
more expressive models because as soon

200
00:08:51,920 --> 00:08:56,279
as you added more parameters they

201
00:08:53,560 --> 00:08:58,360
started overfitting pre-training solved

202
00:08:56,279 --> 00:09:01,240
that for us so we see vastly more

203
00:08:58,360 --> 00:09:02,720
expressive models we've been able to um

204
00:09:01,240 --> 00:09:07,720
increase the number of parameters for

205
00:09:02,720 --> 00:09:10,200
our GNN uh 20 fold um we see huge um uh

206
00:09:07,720 --> 00:09:12,959
improvements in both classification and

207
00:09:10,200 --> 00:09:14,839
uh and regression performance by uh by

208
00:09:12,959 --> 00:09:17,320
by taking this

209
00:09:14,839 --> 00:09:19,200
approach all right so let me shift gears

210
00:09:17,320 --> 00:09:22,240
a little bit and and talk about what

211
00:09:19,200 --> 00:09:24,560
we're doing in um in generative AI in uh

212
00:09:22,240 --> 00:09:26,560
in hit Discovery and talk about our our

213
00:09:24,560 --> 00:09:30,800
latest model uh which we call

214
00:09:26,560 --> 00:09:34,240
neurogenesis ngt um for uh for

215
00:09:30,800 --> 00:09:37,040
short generative AI in drug Discovery is

216
00:09:34,240 --> 00:09:39,880
um there's a lot of Buzz um about it but

217
00:09:37,040 --> 00:09:41,720
the main problem in in generative AI in

218
00:09:39,880 --> 00:09:43,839
in drug Discovery is that it comes up

219
00:09:41,720 --> 00:09:46,560
with these fantastic compounds but you

220
00:09:43,839 --> 00:09:49,000
can't make them they're extremely

221
00:09:46,560 --> 00:09:51,399
difficult to make and and that is how

222
00:09:49,000 --> 00:09:54,160
hallucination manifests itself in

223
00:09:51,399 --> 00:09:56,519
generative AI in uh in drug Discovery

224
00:09:54,160 --> 00:09:59,720
and that was um sort of summarized very

225
00:09:56,519 --> 00:10:02,720
nicely um in a paper in Jacks uh just uh

226
00:09:59,720 --> 00:10:04,560
just last year it's a real problem um of

227
00:10:02,720 --> 00:10:06,959
course because you know what is key to

228
00:10:04,560 --> 00:10:09,000
driving a drug Discovery campaign is

229
00:10:06,959 --> 00:10:11,760
that you have access to to compounds

230
00:10:09,000 --> 00:10:14,480
that are readily synthesizable um you

231
00:10:11,760 --> 00:10:16,000
can't wait months for a compound to uh

232
00:10:14,480 --> 00:10:18,279
to be to be

233
00:10:16,000 --> 00:10:20,200
synthesizable so the flip side of this

234
00:10:18,279 --> 00:10:22,920
is that you have commercially available

235
00:10:20,200 --> 00:10:25,399
combinatorial synthesis libraries um and

236
00:10:22,920 --> 00:10:27,720
those are massive compound spaces of

237
00:10:25,399 --> 00:10:32,720
synthetically accessible compounds that

238
00:10:27,720 --> 00:10:34,480
you know cost maybe 100 or $150 um a pop

239
00:10:32,720 --> 00:10:37,120
and they have been growing very very

240
00:10:34,480 --> 00:10:40,200
rapidly over the over the last few years

241
00:10:37,120 --> 00:10:42,000
the latest um enamine is a is a very uh

242
00:10:40,200 --> 00:10:44,320
well-known provider of these kind of uh

243
00:10:42,000 --> 00:10:46,959
combine libraries their latest one is

244
00:10:44,320 --> 00:10:49,680
about 70 billion compounds um the

245
00:10:46,959 --> 00:10:51,839
largest we have in house is 16

246
00:10:49,680 --> 00:10:53,639
quadrillion compounds I want to point

247
00:10:51,839 --> 00:10:55,920
out that the scale here on the Left End

248
00:10:53,639 --> 00:10:58,360
side is in billions of uh of compounds

249
00:10:55,920 --> 00:11:00,639
so these spaces are huge and that comes

250
00:10:58,360 --> 00:11:03,200
with the problem of its own so how do

251
00:11:00,639 --> 00:11:08,040
you now search these vast compound

252
00:11:03,200 --> 00:11:11,480
spaces for um for uh for hits well we

253
00:11:08,040 --> 00:11:14,440
figured um we take um The Best of Both

254
00:11:11,480 --> 00:11:16,839
Worlds we use these Comin combinatorial

255
00:11:14,440 --> 00:11:19,360
synthesis libraries libraries as the

256
00:11:16,839 --> 00:11:22,240
universe from which we want to generate

257
00:11:19,360 --> 00:11:24,639
uh compounds so we use generative AI um

258
00:11:22,240 --> 00:11:26,920
to generate compounds out of these huge

259
00:11:24,639 --> 00:11:29,000
csls so let me walk you through very

260
00:11:26,920 --> 00:11:30,560
quickly on how we uh how we approach

261
00:11:29,000 --> 00:11:34,240
that for that you need to know a little

262
00:11:30,560 --> 00:11:36,120
bit how a CSL Works a CSL is nothing but

263
00:11:34,240 --> 00:11:38,519
um a large set of building blocks called

264
00:11:36,120 --> 00:11:40,920
synthons that you see here plus a set of

265
00:11:38,519 --> 00:11:43,600
rules on how put to put these syons

266
00:11:40,920 --> 00:11:45,880
together um so here this is an example

267
00:11:43,600 --> 00:11:50,720
from enamine three building blocks a

268
00:11:45,880 --> 00:11:53,920
rule and you get a compound out of it um

269
00:11:50,720 --> 00:11:56,000
so the way we approach the problem is we

270
00:11:53,920 --> 00:11:59,240
we frame retrieval of compounds out of

271
00:11:56,000 --> 00:12:01,680
the CSL as an autoencoding uh problem uh

272
00:11:59,240 --> 00:12:03,720
so nothing new here this is a

273
00:12:01,680 --> 00:12:06,160
variational auto encoder so we encode

274
00:12:03,720 --> 00:12:08,800
the library in a latent space and we

275
00:12:06,160 --> 00:12:11,079
design the encoder in such a way that if

276
00:12:08,800 --> 00:12:13,639
you sample latent space the compound

277
00:12:11,079 --> 00:12:17,199
that you get back is guaranteed to be in

278
00:12:13,639 --> 00:12:19,320
this uh in this CSL and that is um

279
00:12:17,199 --> 00:12:21,800
actually not that hard because what you

280
00:12:19,320 --> 00:12:24,760
need to learn is a synthesis Rule and

281
00:12:21,800 --> 00:12:26,440
then the ideas of the of the um of of

282
00:12:24,760 --> 00:12:28,839
the two R groups or three R groups or

283
00:12:26,440 --> 00:12:32,199
four R groups um depending on how many

284
00:12:28,839 --> 00:12:35,199
there are for uh for that particular

285
00:12:32,199 --> 00:12:37,399
um uh

286
00:12:35,199 --> 00:12:39,399
compound so that's all good and well and

287
00:12:37,399 --> 00:12:41,720
you can sample uh you can sample your

288
00:12:39,399 --> 00:12:44,600
latent space but how do you now get um

289
00:12:41,720 --> 00:12:46,560
compounds that are um uh that have

290
00:12:44,600 --> 00:12:48,720
desirable properties right like Pat

291
00:12:46,560 --> 00:12:50,959
earlier this uh talked about you know

292
00:12:48,720 --> 00:12:55,279
that we're not quite there yet um using

293
00:12:50,959 --> 00:12:58,839
Mo on um uh on on these kind of compound

294
00:12:55,279 --> 00:13:01,000
uh compound queries um and so how do we

295
00:12:58,839 --> 00:13:02,839
how do we go about that here is a very

296
00:13:01,000 --> 00:13:04,199
simple example of course lipinsky rule

297
00:13:02,839 --> 00:13:06,360
of five could be something that you're

298
00:13:04,199 --> 00:13:09,279
interested in in retrieving from the

299
00:13:06,360 --> 00:13:11,440
from the uh library and not not that we

300
00:13:09,279 --> 00:13:16,000
are very interested in liins R 5 but

301
00:13:11,440 --> 00:13:18,399
everybody uh knows this one of course um

302
00:13:16,000 --> 00:13:21,000
so to approach that problem we took our

303
00:13:18,399 --> 00:13:23,920
um our variational Auto encoder and then

304
00:13:21,000 --> 00:13:26,959
used reinforcement learning to train uh

305
00:13:23,920 --> 00:13:30,120
a policy to induce a distribution over

306
00:13:26,959 --> 00:13:33,160
uh over latent space um in such a way

307
00:13:30,120 --> 00:13:36,920
that compounds that satisfy these

308
00:13:33,160 --> 00:13:40,279
properties have a a High um uh a high

309
00:13:36,920 --> 00:13:44,720
probability of being sampled um in that

310
00:13:40,279 --> 00:13:47,240
um in in that space so I should add here

311
00:13:44,720 --> 00:13:50,399
we made um so typically when you do that

312
00:13:47,240 --> 00:13:52,480
when you typically when you train um a

313
00:13:50,399 --> 00:13:54,360
policy with reinforcement learning it's

314
00:13:52,480 --> 00:13:57,160
it's typically mod seeking so it focuses

315
00:13:54,360 --> 00:14:01,199
of on a very small part of uh of latent

316
00:13:57,160 --> 00:14:04,360
space and so we made um a a um a

317
00:14:01,199 --> 00:14:06,079
specific effort to to train this policy

318
00:14:04,360 --> 00:14:08,360
uh so that it's actually Mass covering

319
00:14:06,079 --> 00:14:10,600
so that you get a large variety of

320
00:14:08,360 --> 00:14:13,920
compounds um in latent space that

321
00:14:10,600 --> 00:14:16,720
satisfy um this uh this

322
00:14:13,920 --> 00:14:19,240
property okay we put this uh we put this

323
00:14:16,720 --> 00:14:21,399
through the test in a in a in a case

324
00:14:19,240 --> 00:14:23,839
study that was actually published just

325
00:14:21,399 --> 00:14:26,880
this week in the Journal of uh of

326
00:14:23,839 --> 00:14:29,560
medicinal uh chemistry where we used a

327
00:14:26,880 --> 00:14:32,800
uh a CSL of three trillion compounds

328
00:14:29,560 --> 00:14:37,959
uh to test our uh to test our method um

329
00:14:32,800 --> 00:14:40,440
very quickly um we we wanted to we

330
00:14:37,959 --> 00:14:43,519
wanted to try this on a on a challenging

331
00:14:40,440 --> 00:14:48,120
challenging example so we chose a

332
00:14:43,519 --> 00:14:51,480
gpcr um it's it's called mc2r um and

333
00:14:48,120 --> 00:14:55,000
it's um it's agonized by um by a by a

334
00:14:51,480 --> 00:14:57,120
hormone act it's a therapeutic Target

335
00:14:55,000 --> 00:15:00,320
for uh for Cushings Disease and actually

336
00:14:57,120 --> 00:15:04,480
kinetics uh a biotech is going into pH

337
00:15:00,320 --> 00:15:06,680
uh uh phase two clinical trials um with

338
00:15:04,480 --> 00:15:09,320
with an antagonist

339
00:15:06,680 --> 00:15:11,199
um and what is important to realize here

340
00:15:09,320 --> 00:15:13,040
is that selectivity is critical and

341
00:15:11,199 --> 00:15:15,800
challenging and that's why that's part

342
00:15:13,040 --> 00:15:20,120
of the reason why this uh Target is uh

343
00:15:15,800 --> 00:15:23,120
is is challenging um um this hormone

344
00:15:20,120 --> 00:15:24,639
activates all all of this uh gpcrs ISO

345
00:15:23,120 --> 00:15:27,240
forms so

346
00:15:24,639 --> 00:15:30,399
um it's a it's a hard

347
00:15:27,240 --> 00:15:32,800
problem um when we started this problem

348
00:15:30,399 --> 00:15:34,800
there were no mc2r antagonist in the

349
00:15:32,800 --> 00:15:37,639
literature so again this was an kind of

350
00:15:34,800 --> 00:15:40,360
an example for uh for a first in class

351
00:15:37,639 --> 00:15:42,040
uh application of our uh of our method

352
00:15:40,360 --> 00:15:44,519
when we do hit Discovery we typically

353
00:15:42,040 --> 00:15:47,519
screen against an uh an against a

354
00:15:44,519 --> 00:15:50,880
confirmation Ensemble of of receptors so

355
00:15:47,519 --> 00:15:53,000
we took an activated mc2r domain uh we

356
00:15:50,880 --> 00:15:55,480
typically include an alpha fold model

357
00:15:53,000 --> 00:15:57,399
even though those are often uh APO uh

358
00:15:55,480 --> 00:16:00,000
APO structures and then we took a

359
00:15:57,399 --> 00:16:02,279
homology model from an MC for our uh

360
00:16:00,000 --> 00:16:04,759
Crystal structures as I said we took a

361
00:16:02,279 --> 00:16:09,800
three trillion uh compound library that

362
00:16:04,759 --> 00:16:12,440
is uh called unreal um and um actually

363
00:16:09,800 --> 00:16:15,680
um it's now also available from uh from

364
00:16:12,440 --> 00:16:19,000
enamine and um we also of course wanted

365
00:16:15,680 --> 00:16:21,279
to um compare our methods to what we

366
00:16:19,000 --> 00:16:24,440
thought was a state-of-the-art method um

367
00:16:21,279 --> 00:16:26,240
to uh to search these large libraries um

368
00:16:24,440 --> 00:16:28,480
that was published I think two years ago

369
00:16:26,240 --> 00:16:30,000
it's called v v synthes really fragment

370
00:16:28,480 --> 00:16:33,800
growing up

371
00:16:30,000 --> 00:16:36,399
approach um yeah very quickly um our

372
00:16:33,800 --> 00:16:41,680
method actually did very well um we

373
00:16:36,399 --> 00:16:44,680
found um uh our hit rate was about uh

374
00:16:41,680 --> 00:16:48,720
12% um for our method slightly higher

375
00:16:44,680 --> 00:16:51,440
than um then v v synus um a hit we

376
00:16:48,720 --> 00:16:55,360
defined as more than 50% inhibition at

377
00:16:51,440 --> 00:16:57,759
uh at at at 30 micromolar um and then

378
00:16:55,360 --> 00:17:02,199
with the hits actually we selected a

379
00:16:57,759 --> 00:17:05,120
subset of of hits that um that uh

380
00:17:02,199 --> 00:17:09,120
actually had favorable um

381
00:17:05,120 --> 00:17:12,000
solubility um we took them into a dose

382
00:17:09,120 --> 00:17:15,319
response essay um we found micromolar

383
00:17:12,000 --> 00:17:17,760
hits um uh with our method as well as

384
00:17:15,319 --> 00:17:19,799
with uh with the vnus method they're

385
00:17:17,760 --> 00:17:23,240
pretty much indistinguishable in uh in

386
00:17:19,799 --> 00:17:25,400
terms of uh of of of potency our

387
00:17:23,240 --> 00:17:29,120
compound is slightly smaller so has a

388
00:17:25,400 --> 00:17:31,720
slightly better um liant deficiency um

389
00:17:29,120 --> 00:17:33,799
an important point to uh at least what

390
00:17:31,720 --> 00:17:36,640
we thought was important was if you look

391
00:17:33,799 --> 00:17:39,160
at this Disney plot um over here that

392
00:17:36,640 --> 00:17:41,840
the vynus compounds tended to Cluster

393
00:17:39,160 --> 00:17:44,440
together they're all um pretty similar

394
00:17:41,840 --> 00:17:47,360
what you see from our method is that uh

395
00:17:44,440 --> 00:17:49,799
our Mass covering um approach actually

396
00:17:47,360 --> 00:17:51,679
paid off you see a lot more diversity in

397
00:17:49,799 --> 00:17:54,200
the scaffolds that you uh that you get

398
00:17:51,679 --> 00:17:57,480
back and as every medicinal chemist will

399
00:17:54,200 --> 00:17:59,640
tell you if you have uh a couple of

400
00:17:57,480 --> 00:18:01,240
starting scaffolds in a drug Discovery

401
00:17:59,640 --> 00:18:03,400
campaign that will help you out uh

402
00:18:01,240 --> 00:18:05,520
tremendously so more diversity means

403
00:18:03,400 --> 00:18:08,960
more shots on goal

404
00:18:05,520 --> 00:18:12,080
um and um you know

405
00:18:08,960 --> 00:18:13,840
serendipitously maybe um our our

406
00:18:12,080 --> 00:18:17,480
compound actually uh turned out to be

407
00:18:13,840 --> 00:18:21,039
the most selective uh among isoforms uh

408
00:18:17,480 --> 00:18:25,039
as well um that brings me to the end of

409
00:18:21,039 --> 00:18:28,320
uh of my presentations um key takeaways

410
00:18:25,039 --> 00:18:29,679
key takeaways at least for me sure data

411
00:18:28,320 --> 00:18:32,320
is King

412
00:18:29,679 --> 00:18:35,840
but you know 20 million data points if

413
00:18:32,320 --> 00:18:39,159
we like we cannot add data fast enough

414
00:18:35,840 --> 00:18:41,600
to uh to train our um machine learning

415
00:18:39,159 --> 00:18:44,400
models um with better data right that

416
00:18:41,600 --> 00:18:45,960
would be enormously costly effort so I

417
00:18:44,400 --> 00:18:48,159
would say data is King but

418
00:18:45,960 --> 00:18:50,640
self-supervised uh learning rules for

419
00:18:48,159 --> 00:18:52,679
now um the key to better performance is

420
00:18:50,640 --> 00:18:54,559
upscaling the models um without

421
00:18:52,679 --> 00:18:56,280
overfitting I think again

422
00:18:54,559 --> 00:18:59,799
self-supervised learning can can help

423
00:18:56,280 --> 00:19:02,720
you there um just went over the uh the

424
00:18:59,799 --> 00:19:07,320
ngt generative AI so I'll just leave

425
00:19:02,720 --> 00:19:07,320
those uh slides up and uh and I'm taking

426
00:19:07,470 --> 00:19:11,640
[Applause]

427
00:19:11,760 --> 00:19:15,600
questions thank you

428
00:19:19,960 --> 00:19:24,080
questions hi thanks for the talk I had a

429
00:19:22,240 --> 00:19:26,440
question about the how you avoided mode

430
00:19:24,080 --> 00:19:28,480
seeking for the RL did you use anything

431
00:19:26,440 --> 00:19:30,640
like um recurrent experience repeats and

432
00:19:28,480 --> 00:19:32,200
stuff to help it maintain like a wide

433
00:19:30,640 --> 00:19:35,880
distribution or can you talk a little

434
00:19:32,200 --> 00:19:39,720
about that no we we developed a um a

435
00:19:35,880 --> 00:19:42,400
family of uh of what we call Alpha

436
00:19:39,720 --> 00:19:45,760
divergences so it's essentially um K

437
00:19:42,400 --> 00:19:48,919
divergences with a with a parameter that

438
00:19:45,760 --> 00:19:50,640
um that you can um that you can select

439
00:19:48,919 --> 00:19:53,919
so that it becomes either more mod

440
00:19:50,640 --> 00:19:55,960
seeking or um or more more mass covering

441
00:19:53,919 --> 00:19:59,240
and so you train the policy with that

442
00:19:55,960 --> 00:20:01,320
family of uh of K di virgin

443
00:19:59,240 --> 00:20:05,640
and that gives us the uh the mass

444
00:20:01,320 --> 00:20:08,480
covering um policy thank you sure

445
00:20:05,640 --> 00:20:11,240
details are in the paper go

446
00:20:08,480 --> 00:20:13,240
ahead uh hi next Ty I was wondering if

447
00:20:11,240 --> 00:20:15,559
you tried using conditional generation

448
00:20:13,240 --> 00:20:19,240
in place of the policy for a generation

449
00:20:15,559 --> 00:20:21,679
and and if so how it compared we didn't

450
00:20:19,240 --> 00:20:24,280
um and you know it's interesting like in

451
00:20:21,679 --> 00:20:27,559
machine learning I think nowadays

452
00:20:24,280 --> 00:20:29,200
methods commoditize so quickly that you

453
00:20:27,559 --> 00:20:31,679
know you put something out out and like

454
00:20:29,200 --> 00:20:33,919
a week later a grad student has made an

455
00:20:31,679 --> 00:20:36,400
improvement to your method that you you

456
00:20:33,919 --> 00:20:38,400
know spend like nine months developing

457
00:20:36,400 --> 00:20:41,840
and and so that's great about the field

458
00:20:38,400 --> 00:20:44,880
right um so you know there's many many

459
00:20:41,840 --> 00:20:47,159
ways to solve this problem so yeah I

460
00:20:44,880 --> 00:20:50,600
would say get behind your computer and

461
00:20:47,159 --> 00:20:55,600
uh thank you sure okay one quick

462
00:20:50,600 --> 00:20:59,840
question yes oh first as as in as in

463
00:20:55,600 --> 00:21:02,960
alumni information and to

464
00:20:59,840 --> 00:21:05,320
for for the variation of out quor have

465
00:21:02,960 --> 00:21:07,840
you tested how it Compares with

466
00:21:05,320 --> 00:21:10,000
so-called moleular molecular language

467
00:21:07,840 --> 00:21:13,000
modules like for example Mega mulber or

468
00:21:10,000 --> 00:21:15,240
M former where you also can sample

469
00:21:13,000 --> 00:21:18,720
Lattin space and potentially generate

470
00:21:15,240 --> 00:21:22,799
molecules this dat properties

471
00:21:18,720 --> 00:21:26,320
yeah so for us it was important to to

472
00:21:22,799 --> 00:21:28,640
solve the um synthetic accessibility

473
00:21:26,320 --> 00:21:32,120
problem it was really important that we

474
00:21:28,640 --> 00:21:34,559
generated compounds that were in the CSL

475
00:21:32,120 --> 00:21:38,799
and so if you look at more former or

476
00:21:34,559 --> 00:21:40,799
more former XL um you know it it's

477
00:21:38,799 --> 00:21:43,360
exactly the problem it creates great

478
00:21:40,799 --> 00:21:45,159
compounds and then we go to to enine or

479
00:21:43,360 --> 00:21:47,400
any vendor and they scratch their hats

480
00:21:45,159 --> 00:21:51,159
and they say yeah this is a list of 400

481
00:21:47,400 --> 00:21:54,720
we can maybe make two I was

482
00:21:51,159 --> 00:21:58,840
on receiving ends of of those requests

483
00:21:54,720 --> 00:22:01,960
so I fully understand I see yes

484
00:21:58,840 --> 00:22:03,960
um thank you all right one very quick

485
00:22:01,960 --> 00:22:07,240
question sure you have shown a heat rate

486
00:22:03,960 --> 00:22:10,480
of 12.5% there was a bar PL what's the

487
00:22:07,240 --> 00:22:12,640
range of heat rate across drugable

488
00:22:10,480 --> 00:22:13,840
versus undruggable targets what is your

489
00:22:12,640 --> 00:22:17,000
current

490
00:22:13,840 --> 00:22:19,760
observation well undruggable would be 0%

491
00:22:17,000 --> 00:22:21,880
almost by definition 0% then you had

492
00:22:19,760 --> 00:22:23,760
success you showed right so what what

493
00:22:21,880 --> 00:22:25,000
does the current heat rate Spectrum

494
00:22:23,760 --> 00:22:30,039
looks

495
00:22:25,000 --> 00:22:32,320
like um yeah I well my slides are gone I

496
00:22:30,039 --> 00:22:34,320
I think if you look at that that first

497
00:22:32,320 --> 00:22:37,400
rectangle that I showed on that that

498
00:22:34,320 --> 00:22:40,720
plot there um so these were targets for

499
00:22:37,400 --> 00:22:42,880
which we have no data in uh in in our in

500
00:22:40,720 --> 00:22:48,039
our training set the hit rate varied

501
00:22:42,880 --> 00:22:50,360
from 0% to uh to 25% so it really

502
00:22:48,039 --> 00:22:51,919
depends on on the targets you know

503
00:22:50,360 --> 00:22:54,240
interesting there too was if you looked

504
00:22:51,919 --> 00:22:56,120
at the horizontal axis there were also

505
00:22:54,240 --> 00:22:58,279
Targets in there for which we had

506
00:22:56,120 --> 00:23:00,600
thousands of compounds in our data set

507
00:22:58,279 --> 00:23:04,320
but we didn't find hits with uh with a

508
00:23:00,600 --> 00:23:06,799
model yeah so it the take away from that

509
00:23:04,320 --> 00:23:08,960
plot is there's almost no correlation

510
00:23:06,799 --> 00:23:12,120
between you know the amount of data that

511
00:23:08,960 --> 00:23:14,720
you have available uh for a Target and

512
00:23:12,120 --> 00:23:17,320
and the hit rate that you that you get

513
00:23:14,720 --> 00:23:19,290
yeah all right so let's thank the

514
00:23:17,320 --> 00:23:23,849
speaker one more time

515
00:23:19,290 --> 00:23:23,849
[Applause]


1
00:00:01,040 --> 00:00:08,440
Jim Flynn thanks for uh

2
00:00:04,040 --> 00:00:08,440
participating so you're all wired up I

3
00:00:09,160 --> 00:00:15,200
[Music]

4
00:00:12,200 --> 00:00:15,200
see

5
00:00:16,540 --> 00:00:25,320
[Music]

6
00:00:22,320 --> 00:00:25,320
yep

7
00:00:27,119 --> 00:00:30,320
yep yeah I have a couple students that

8
00:00:28,960 --> 00:00:33,039
are working to try to commercialize

9
00:00:30,320 --> 00:00:33,039
figure out the right

10
00:00:41,060 --> 00:00:48,929
[Music]

11
00:00:50,879 --> 00:00:55,840
Pathways okay they're trying to okay

12
00:00:52,879 --> 00:00:58,879
okay yeah would love the chat more good

13
00:00:55,840 --> 00:01:00,440
idea oh look at you you have my my sheet

14
00:00:58,879 --> 00:01:02,640
should have brought my sheet up yeah

15
00:01:00,440 --> 00:01:05,280
we're doing some work in um well as the

16
00:01:02,640 --> 00:01:07,360
standin I thought I should prepare a bit

17
00:01:05,280 --> 00:01:09,880
more T that's some of the things you're

18
00:01:07,360 --> 00:01:11,240
thinking about awesome supply chain so

19
00:01:09,880 --> 00:01:16,720
I'll have my resch happy to hand it off

20
00:01:11,240 --> 00:01:19,240
to you I some point we get right now all

21
00:01:16,720 --> 00:01:22,400
right she us what did I not talk about

22
00:01:19,240 --> 00:01:24,520
that's what I'm GNA talk about awesome

23
00:01:22,400 --> 00:01:25,560
okay all right we're going to go ahead

24
00:01:24,520 --> 00:01:30,200
and

25
00:01:25,560 --> 00:01:31,840
start so this is our last panel and like

26
00:01:30,200 --> 00:01:34,759
we did with the future of work we're

27
00:01:31,840 --> 00:01:38,079
going to talk about the future of

28
00:01:34,759 --> 00:01:42,600
operations so you heard

29
00:01:38,079 --> 00:01:45,280
from our two friends from MIT about

30
00:01:42,600 --> 00:01:48,840
cyber and digital

31
00:01:45,280 --> 00:01:51,439
twins um we have now some industry that

32
00:01:48,840 --> 00:01:54,159
have joined us so I'd like you to go

33
00:01:51,439 --> 00:01:57,399
ahead and start and tell us about

34
00:01:54,159 --> 00:01:59,560
yourself thanks uh name is Rob Scott I'm

35
00:01:57,399 --> 00:02:02,320
the managing director of Americas for

36
00:01:59,560 --> 00:02:07,000
Tech nip energies uh we're a

37
00:02:02,320 --> 00:02:09,319
company really in transition uh we spun

38
00:02:07,000 --> 00:02:13,879
out from Technip FMC about three and a

39
00:02:09,319 --> 00:02:17,200
half years ago and we're heavily focused

40
00:02:13,879 --> 00:02:20,959
uh with 177,000 colleagues in 34

41
00:02:17,200 --> 00:02:24,480
countries and executing energy energy

42
00:02:20,959 --> 00:02:28,440
transition circularity in terms of the

43
00:02:24,480 --> 00:02:32,160
chemistry around uh polyester and

44
00:02:28,440 --> 00:02:34,720
working extremely hard to uh remain

45
00:02:32,160 --> 00:02:37,599
positive through the pendulum as it

46
00:02:34,720 --> 00:02:41,319
swings back and forth with the markets

47
00:02:37,599 --> 00:02:43,360
uh and what owners do as a prime

48
00:02:41,319 --> 00:02:46,840
contractor in engineering procurement

49
00:02:43,360 --> 00:02:50,599
and construction you really are at the

50
00:02:46,840 --> 00:02:53,800
at what is able to go to market uh on

51
00:02:50,599 --> 00:02:55,640
Final investment decision so I'm pleased

52
00:02:53,800 --> 00:02:58,120
to be here it's an honor to represent

53
00:02:55,640 --> 00:02:59,840
Technip if you got any questions after

54
00:02:58,120 --> 00:03:03,040
this we'll be around and I'm here with a

55
00:02:59,840 --> 00:03:04,720
a couple of colleagues uh as well

56
00:03:03,040 --> 00:03:07,000
awesome all right Eric take it away yeah

57
00:03:04,720 --> 00:03:10,720
Eric Lee with halberton so work in the

58
00:03:07,000 --> 00:03:12,000
Upstream uh energy oil and gas um I've

59
00:03:10,720 --> 00:03:13,760
been in the industry for about 12 years

60
00:03:12,000 --> 00:03:15,440
at a couple different oil and gas

61
00:03:13,760 --> 00:03:17,040
companies prior to this was in the

62
00:03:15,440 --> 00:03:18,920
Aerospace business and somehow ventured

63
00:03:17,040 --> 00:03:21,319
my way out into oil and gas uh my role

64
00:03:18,920 --> 00:03:23,080
currently is a technology director and

65
00:03:21,319 --> 00:03:25,040
so I look after sort of everything

66
00:03:23,080 --> 00:03:26,519
digital building the technology and sort

67
00:03:25,040 --> 00:03:27,680
of building out our strategy the company

68
00:03:26,519 --> 00:03:30,200
on what we're going to do with digital

69
00:03:27,680 --> 00:03:31,799
so things like automation controls AI uh

70
00:03:30,200 --> 00:03:35,599
sort of anything in the digital space

71
00:03:31,799 --> 00:03:36,959
I'm working on Super Harry anything that

72
00:03:35,599 --> 00:03:39,799
you want to

73
00:03:36,959 --> 00:03:41,360
add so one project I didn't talk about

74
00:03:39,799 --> 00:03:43,720
because didn't have time to talk about

75
00:03:41,360 --> 00:03:46,319
everything is a project we're doing on

76
00:03:43,720 --> 00:03:48,200
supply chain cyber security our team's

77
00:03:46,319 --> 00:03:51,040
looking at how large companies are

78
00:03:48,200 --> 00:03:53,319
helping or can help small suppliers in

79
00:03:51,040 --> 00:03:55,120
the supply chain be more secure the

80
00:03:53,319 --> 00:03:57,200
issue being of course if you're a small

81
00:03:55,120 --> 00:04:00,040
and medium business you understand you

82
00:03:57,200 --> 00:04:02,360
have to be secure provider however when

83
00:04:00,040 --> 00:04:03,959
you have each customer asking you to

84
00:04:02,360 --> 00:04:05,680
prove to them that you're a secure

85
00:04:03,959 --> 00:04:07,959
supplier and you don't even have the

86
00:04:05,680 --> 00:04:10,360
resource to make sure you're a secure

87
00:04:07,959 --> 00:04:12,400
supplier it's quite a conundrum so we've

88
00:04:10,360 --> 00:04:15,079
been looking at how large companies can

89
00:04:12,400 --> 00:04:16,639
help small companies be more secure and

90
00:04:15,079 --> 00:04:18,440
I'd love to share that if that comes up

91
00:04:16,639 --> 00:04:20,479
as part of the operations discussion

92
00:04:18,440 --> 00:04:23,520
yeah okay we'll talk about that more and

93
00:04:20,479 --> 00:04:25,800
then our Emmy Award winner down there my

94
00:04:23,520 --> 00:04:28,759
brother one an M too so it's very

95
00:04:25,800 --> 00:04:31,479
awesome um throw in a new thing um how

96
00:04:28,759 --> 00:04:33,400
do I win the Nobel I'm not sure or the

97
00:04:31,479 --> 00:04:34,919
Oscar no so I think the one thing just

98
00:04:33,400 --> 00:04:37,080
on the cyber security and the thing I

99
00:04:34,919 --> 00:04:39,919
skipped over is as to keep your eyes

100
00:04:37,080 --> 00:04:42,320
open on a technology called homomorphic

101
00:04:39,919 --> 00:04:44,520
encryption um so as another tool in the

102
00:04:42,320 --> 00:04:47,000
Arsenal it allows you to do end to end

103
00:04:44,520 --> 00:04:48,120
mathematics on encrypted data so for

104
00:04:47,000 --> 00:04:49,919
example if you were to Outsource your

105
00:04:48,120 --> 00:04:51,759
data science you could share your data

106
00:04:49,919 --> 00:04:53,520
but nobody would have to decrypt it in

107
00:04:51,759 --> 00:04:56,560
order to do their learning or the

108
00:04:53,520 --> 00:04:58,560
mathematics on it and so as a tool Intel

109
00:04:56,560 --> 00:05:01,919
Microsoft Samsung are working on both

110
00:04:58,560 --> 00:05:03,800
accelerators um software to make these

111
00:05:01,919 --> 00:05:06,320
um that type of Technology available

112
00:05:03,800 --> 00:05:07,759
yeah I want to say so I think I might

113
00:05:06,320 --> 00:05:10,039
have mentioned I was the president of

114
00:05:07,759 --> 00:05:12,840
Technology review which is mit's Media

115
00:05:10,039 --> 00:05:13,759
company and every year there we do a top

116
00:05:12,840 --> 00:05:17,080
10

117
00:05:13,759 --> 00:05:19,080
Technologies and homomorphic encryption

118
00:05:17,080 --> 00:05:23,400
I think was

119
00:05:19,080 --> 00:05:25,120
2016 about 15 or 16 yeah so that it's

120
00:05:23,400 --> 00:05:26,840
interesting I feel like these things

121
00:05:25,120 --> 00:05:29,479
often when they're on the list they

122
00:05:26,840 --> 00:05:31,840
start to enter the vernacular about five

123
00:05:29,479 --> 00:05:33,720
to 10 years later so and and it's just

124
00:05:31,840 --> 00:05:36,280
starting to use it's been it's used in

125
00:05:33,720 --> 00:05:38,800
banking and it's used in at government

126
00:05:36,280 --> 00:05:40,039
levels and and the the accelerators that

127
00:05:38,800 --> 00:05:41,440
are happening from a technology

128
00:05:40,039 --> 00:05:42,759
perspective are making it more feasible

129
00:05:41,440 --> 00:05:44,560
to use it at the time skills that are

130
00:05:42,759 --> 00:05:45,880
necessary for manufacturing I guess the

131
00:05:44,560 --> 00:05:48,639
other thing I'll notice I had to I'll

132
00:05:45,880 --> 00:05:50,759
leave at 4:00 we'd had to catch a plane

133
00:05:48,639 --> 00:05:54,880
yes we we haven't figured out time

134
00:05:50,759 --> 00:05:58,479
travel yet we're working on that okay so

135
00:05:54,880 --> 00:06:00,919
then topic of the day is about

136
00:05:58,479 --> 00:06:03,120
transformation right right and so now

137
00:06:00,919 --> 00:06:05,639
we're talking about operational

138
00:06:03,120 --> 00:06:09,960
transformation and and with the panel

139
00:06:05,639 --> 00:06:12,680
the discussion uh with from Carrie and

140
00:06:09,960 --> 00:06:16,319
Brian you heard you know some basis of

141
00:06:12,680 --> 00:06:19,039
things so I want to take have each

142
00:06:16,319 --> 00:06:21,800
panelist talk about sort of what do they

143
00:06:19,039 --> 00:06:24,280
see as sort of the biggest Factor around

144
00:06:21,800 --> 00:06:27,000
transformation in operations what do you

145
00:06:24,280 --> 00:06:29,039
what is hitting you in industry and then

146
00:06:27,000 --> 00:06:31,080
maybe building on either a concept that

147
00:06:29,039 --> 00:06:33,360
you see in in your discussion or

148
00:06:31,080 --> 00:06:36,440
something new rob you want to go ahead

149
00:06:33,360 --> 00:06:39,560
and start I think first and foremost

150
00:06:36,440 --> 00:06:41,199
it's uh human in the loop and how do we

151
00:06:39,560 --> 00:06:44,520
take these

152
00:06:41,199 --> 00:06:48,759
Technologies uh and work to get them out

153
00:06:44,520 --> 00:06:51,319
at first of a kind and scale in a place

154
00:06:48,759 --> 00:06:52,880
that folks don't feel threatened by it

155
00:06:51,319 --> 00:06:55,599
and I understand that's been a large

156
00:06:52,880 --> 00:06:56,680
large part of the conversation today is

157
00:06:55,599 --> 00:06:59,240
you know the

158
00:06:56,680 --> 00:07:01,560
workforce it getting them to understand

159
00:06:59,240 --> 00:07:03,280
that it's human plus machine and that

160
00:07:01,560 --> 00:07:07,319
there's a human in the loop and that's

161
00:07:03,280 --> 00:07:10,400
the critical importance of of being able

162
00:07:07,319 --> 00:07:13,960
to do the Creative work with the tools

163
00:07:10,400 --> 00:07:15,639
that we have I think the second part of

164
00:07:13,960 --> 00:07:18,080
of that is

165
00:07:15,639 --> 00:07:22,440
affordability the the challenges you

166
00:07:18,080 --> 00:07:25,400
have at going to uh out of a Lab First

167
00:07:22,440 --> 00:07:29,000
of a kind to scale up and doing it

168
00:07:25,400 --> 00:07:31,039
affordably so that there can be uh the

169
00:07:29,000 --> 00:07:32,240
investment decisions that it takes to do

170
00:07:31,039 --> 00:07:35,440
this are

171
00:07:32,240 --> 00:07:38,879
also require a lot of stakeholder

172
00:07:35,440 --> 00:07:41,919
participation not just uh companies but

173
00:07:38,879 --> 00:07:43,599
also government local state federal to

174
00:07:41,919 --> 00:07:45,479
do these things so to me at the end of

175
00:07:43,599 --> 00:07:48,199
the day it continues to be about the

176
00:07:45,479 --> 00:07:50,599
human in the loop and how to do that

177
00:07:48,199 --> 00:07:53,840
efficiently uh so that you have a safer

178
00:07:50,599 --> 00:07:56,599
work environment that's more productive

179
00:07:53,840 --> 00:07:58,360
yep really

180
00:07:56,599 --> 00:08:00,360
important I think one of the biggest

181
00:07:58,360 --> 00:08:01,879
things we run into is honestly the

182
00:08:00,360 --> 00:08:03,800
change management so I think you know

183
00:08:01,879 --> 00:08:06,560
the technology is hard and coming from

184
00:08:03,800 --> 00:08:07,919
the technology side uh you know we we we

185
00:08:06,560 --> 00:08:10,599
fight that battle every day and it it's

186
00:08:07,919 --> 00:08:11,919
not easy but uh I'll say I've worked for

187
00:08:10,599 --> 00:08:13,639
many years on the product management

188
00:08:11,919 --> 00:08:15,039
side as well rolling the stuff out and

189
00:08:13,639 --> 00:08:17,319
uh it's fascinating because I think you

190
00:08:15,039 --> 00:08:19,319
can sort of bought the math and physics

191
00:08:17,319 --> 00:08:20,840
as much as we can with engineering but

192
00:08:19,319 --> 00:08:23,120
it's almost getting the people to buy

193
00:08:20,840 --> 00:08:25,400
into it in operations which is super

194
00:08:23,120 --> 00:08:26,680
hard and so I think often times that's

195
00:08:25,400 --> 00:08:28,599
overlooked and I would even go further

196
00:08:26,680 --> 00:08:31,000
and say you know product management is

197
00:08:28,599 --> 00:08:33,080
is a hard role I'm not even sure that we

198
00:08:31,000 --> 00:08:34,440
train our folks well to be ready to be a

199
00:08:33,080 --> 00:08:35,839
product manager and roll out digital

200
00:08:34,440 --> 00:08:36,760
technology so I think to me that's one

201
00:08:35,839 --> 00:08:39,159
of the hardest parts of getting

202
00:08:36,760 --> 00:08:41,919
transformation happen in a business yeah

203
00:08:39,159 --> 00:08:44,839
yeah the change for sure yeah to add on

204
00:08:41,919 --> 00:08:48,360
to that I think that we underestimate

205
00:08:44,839 --> 00:08:52,600
just how hard changes on our

206
00:08:48,360 --> 00:08:55,920
Workforce uh things happen so fast now

207
00:08:52,600 --> 00:08:58,640
that you know for example in in 10 we

208
00:08:55,920 --> 00:09:00,120
have 75 different corporate initiatives

209
00:08:58,640 --> 00:09:03,560
around digitization

210
00:09:00,120 --> 00:09:06,399
75 75 around

211
00:09:03,560 --> 00:09:09,600
digitization enhancing project

212
00:09:06,399 --> 00:09:12,680
management uh tracking the numbers

213
00:09:09,600 --> 00:09:14,120
safety uh environmental and I don't

214
00:09:12,680 --> 00:09:16,560
think I'm any diff I don't think

215
00:09:14,120 --> 00:09:21,880
technique is any different than

216
00:09:16,560 --> 00:09:25,880
halberton or Exxon or shell but 70% of

217
00:09:21,880 --> 00:09:28,079
major change initiatives fail yeah and

218
00:09:25,880 --> 00:09:31,000
this is in companies that are doing it

219
00:09:28,079 --> 00:09:32,880
you know one or two at a year in the

220
00:09:31,000 --> 00:09:35,079
environment that we're in the ecosystem

221
00:09:32,880 --> 00:09:38,399
that we're in you either have to do it

222
00:09:35,079 --> 00:09:41,640
at that pace and at that scale or else

223
00:09:38,399 --> 00:09:43,839
you're out uh I think that's part of the

224
00:09:41,640 --> 00:09:46,839
human in the loop change management

225
00:09:43,839 --> 00:09:48,880
discussion is how do we take it from the

226
00:09:46,839 --> 00:09:50,959
theoretical or in a room where people

227
00:09:48,880 --> 00:09:54,240
are very comfortable talking about what

228
00:09:50,959 --> 00:09:56,040
if and making it real to somebody by

229
00:09:54,240 --> 00:09:58,839
demonstrated that it's going to make a

230
00:09:56,040 --> 00:10:01,600
value ad to their life yeah I think the

231
00:09:58,839 --> 00:10:04,279
culture change topic has been a theme

232
00:10:01,600 --> 00:10:07,079
throughout this right I would expect

233
00:10:04,279 --> 00:10:08,920
yeah Carri you want to build on that or

234
00:10:07,079 --> 00:10:10,959
top I want to build build on that but

235
00:10:08,920 --> 00:10:12,680
also add another top another area I

236
00:10:10,959 --> 00:10:15,079
think this um human in the loop is

237
00:10:12,680 --> 00:10:18,240
really important back in the 90s I did

238
00:10:15,079 --> 00:10:20,200
some research on uh we were just we had

239
00:10:18,240 --> 00:10:22,079
PCS you might remember PCS the big

240
00:10:20,200 --> 00:10:24,360
luggable things or things on your desk

241
00:10:22,079 --> 00:10:27,200
and at that time we were all asking the

242
00:10:24,360 --> 00:10:29,200
question um how do we build our

243
00:10:27,200 --> 00:10:31,160
organizations so that we took advantage

244
00:10:29,200 --> 00:10:33,640
of are the best of people and the best

245
00:10:31,160 --> 00:10:36,079
of technology and I think along the way

246
00:10:33,640 --> 00:10:38,000
we've kind of lost this joint piece of

247
00:10:36,079 --> 00:10:39,600
people do some things really well and

248
00:10:38,000 --> 00:10:41,079
computers do some things really well and

249
00:10:39,600 --> 00:10:42,920
computers are doing more and more things

250
00:10:41,079 --> 00:10:44,519
really well but people still do things

251
00:10:42,920 --> 00:10:47,160
really well we notice things that

252
00:10:44,519 --> 00:10:49,200
computerss will never notice we we can

253
00:10:47,160 --> 00:10:51,160
design the next application that

254
00:10:49,200 --> 00:10:52,639
computers can't maybe AI someday will do

255
00:10:51,160 --> 00:10:54,600
it that's the Hollywood version maybe

256
00:10:52,639 --> 00:10:56,399
I'll get an me for this it's a Hollywood

257
00:10:54,600 --> 00:10:58,880
version of of the how the where these

258
00:10:56,399 --> 00:11:01,480
Technologies are going but the truth is

259
00:10:58,880 --> 00:11:03,120
today and I think for the next few years

260
00:11:01,480 --> 00:11:04,839
it's all about marrying what people do

261
00:11:03,120 --> 00:11:06,320
really well with what technologies do

262
00:11:04,839 --> 00:11:08,360
really well not trying to move one of

263
00:11:06,320 --> 00:11:10,079
them in or out of the loop and that kind

264
00:11:08,360 --> 00:11:13,200
of speaks to my second point I brought

265
00:11:10,079 --> 00:11:15,920
it up briefly in my talk but um we need

266
00:11:13,200 --> 00:11:17,720
to build for and design for security and

267
00:11:15,920 --> 00:11:19,279
I think that's gets lost when we start

268
00:11:17,720 --> 00:11:21,279
looking at transformation we start

269
00:11:19,279 --> 00:11:23,279
thinking about how do we design for

270
00:11:21,279 --> 00:11:25,639
efficiency how do we assign for

271
00:11:23,279 --> 00:11:28,200
Effectiveness for competitiveness for

272
00:11:25,639 --> 00:11:30,120
lower costs we have a lot of uh criteria

273
00:11:28,200 --> 00:11:33,120
for our design but we rarely see

274
00:11:30,120 --> 00:11:34,760
designed for security built in um is

275
00:11:33,120 --> 00:11:36,200
becoming more popular it's certainly

276
00:11:34,760 --> 00:11:38,600
something the White House has been

277
00:11:36,200 --> 00:11:40,600
promoting through uh cisa the cyber

278
00:11:38,600 --> 00:11:42,600
security Center there and many other

279
00:11:40,600 --> 00:11:45,279
organizations are talking about design

280
00:11:42,600 --> 00:11:47,480
for security but as we transform our

281
00:11:45,279 --> 00:11:50,760
operations we want to transform it not

282
00:11:47,480 --> 00:11:52,880
only including Concepts like safety but

283
00:11:50,760 --> 00:11:54,480
including Concepts like security and

284
00:11:52,880 --> 00:11:56,200
resilience because we aren't thinking

285
00:11:54,480 --> 00:11:57,880
that that's just not we're not rewarded

286
00:11:56,200 --> 00:12:00,160
for that we're rewarded for Elegance in

287
00:11:57,880 --> 00:12:02,320
design not for more secure design and we

288
00:12:00,160 --> 00:12:06,200
need to be thinking about more secure

289
00:12:02,320 --> 00:12:07,800
design super Brian I guess in in this

290
00:12:06,200 --> 00:12:10,800
context I guess it would add sort of

291
00:12:07,800 --> 00:12:13,720
design for AI and what I mean by that is

292
00:12:10,800 --> 00:12:15,519
even just the simple thing of having

293
00:12:13,720 --> 00:12:20,440
your maintenance

294
00:12:15,519 --> 00:12:22,399
data logged alongside your process data

295
00:12:20,440 --> 00:12:23,800
it's impossible to get companies

296
00:12:22,399 --> 00:12:26,120
currently they that's where all the

297
00:12:23,800 --> 00:12:27,560
problems like the the tools exist the AI

298
00:12:26,120 --> 00:12:30,040
machine learning tools exist it's

299
00:12:27,560 --> 00:12:32,160
actually getting the clean data and

300
00:12:30,040 --> 00:12:34,480
getting the data in a singular database

301
00:12:32,160 --> 00:12:36,160
where time is known across like hey we

302
00:12:34,480 --> 00:12:38,320
did this to this machine at this time

303
00:12:36,160 --> 00:12:40,880
and that's important event in contextual

304
00:12:38,320 --> 00:12:42,440
knowledge to be able to understand why

305
00:12:40,880 --> 00:12:44,560
your process data is varying so even

306
00:12:42,440 --> 00:12:46,000
that simple thing designing your how you

307
00:12:44,560 --> 00:12:47,639
collect your data like the simple

308
00:12:46,000 --> 00:12:49,240
instrumentation to make sure that

309
00:12:47,639 --> 00:12:50,880
there's a common time base saved

310
00:12:49,240 --> 00:12:53,519
throughout the organization if you were

311
00:12:50,880 --> 00:12:56,160
able to do that you the the amount of

312
00:12:53,519 --> 00:12:57,639
potential in just that that that

313
00:12:56,160 --> 00:12:59,440
solution that problem solving that

314
00:12:57,639 --> 00:13:02,880
problem would be huge you wouldn't need

315
00:12:59,440 --> 00:13:05,880
tools but your point on models I think

316
00:13:02,880 --> 00:13:08,399
is critical there because when you start

317
00:13:05,880 --> 00:13:11,839
the design and you're putting the

318
00:13:08,399 --> 00:13:15,760
attributes of the data into the model

319
00:13:11,839 --> 00:13:18,360
you have to think from Project to

320
00:13:15,760 --> 00:13:20,560
production uh procurement construction

321
00:13:18,360 --> 00:13:23,279
operations and it's hard to get the

322
00:13:20,560 --> 00:13:26,920
capex people and the project people and

323
00:13:23,279 --> 00:13:29,440
the Ops people and in a room and agree

324
00:13:26,920 --> 00:13:32,160
if we could get to what the men standard

325
00:13:29,440 --> 00:13:34,639
is of what those attributes are that

326
00:13:32,160 --> 00:13:37,320
we're going to do this with then you can

327
00:13:34,639 --> 00:13:39,639
also start designing in for security and

328
00:13:37,320 --> 00:13:42,199
a couple of other you know holy Grails

329
00:13:39,639 --> 00:13:43,880
that we're after reason we're here and

330
00:13:42,199 --> 00:13:47,279
we're talking about it is it sounds

331
00:13:43,880 --> 00:13:49,000
really easy but it's super hard and

332
00:13:47,279 --> 00:13:51,079
everybody has a different view of what

333
00:13:49,000 --> 00:13:54,320
they want based on the 40 Years of

334
00:13:51,079 --> 00:13:58,040
operating a plant or a floor

335
00:13:54,320 --> 00:14:00,320
and comes like a discussion on

336
00:13:58,040 --> 00:14:05,800
religion let's double click on this I

337
00:14:00,320 --> 00:14:11,040
like this so um the idea of I mean a lot

338
00:14:05,800 --> 00:14:11,040
who here is running an AI pilot in your

339
00:14:11,519 --> 00:14:17,880
organization one two three you're sort

340
00:14:14,360 --> 00:14:22,480
of hesitantly holding up your

341
00:14:17,880 --> 00:14:24,240
hands okay so a few AI Pilots are does

342
00:14:22,480 --> 00:14:26,920
that mean everyone else has fully

343
00:14:24,240 --> 00:14:29,240
integrated into your

344
00:14:26,920 --> 00:14:32,880
organization you haven't started yet

345
00:14:29,240 --> 00:14:35,920
okay great so this is hard so the

346
00:14:32,880 --> 00:14:37,440
question is how do we basically take

347
00:14:35,920 --> 00:14:41,160
something that's a

348
00:14:37,440 --> 00:14:43,440
pilot and go to sort of full scale

349
00:14:41,160 --> 00:14:45,519
operation like let's let's talk about

350
00:14:43,440 --> 00:14:47,600
that in industry and then let's bring in

351
00:14:45,519 --> 00:14:49,959
like what what we're seeing in

352
00:14:47,600 --> 00:14:53,600
Academia on the horizon so you want to

353
00:14:49,959 --> 00:14:56,519
take that Rob first or Eric yeah that's

354
00:14:53,600 --> 00:14:59,120
more his baileywick I break his

355
00:14:56,519 --> 00:15:00,160
thing I think um maybe one of the big

356
00:14:59,120 --> 00:15:02,000
pieces about and I think maybe I'll

357
00:15:00,160 --> 00:15:03,480
speak broadly to AI there's geni kind of

358
00:15:02,000 --> 00:15:05,160
the new Hot Topic but I think you know

359
00:15:03,480 --> 00:15:07,360
broadly algorithms that do things are

360
00:15:05,160 --> 00:15:09,240
some form of AI uh and I've got so many

361
00:15:07,360 --> 00:15:11,440
War Stories from doing this in our

362
00:15:09,240 --> 00:15:13,800
business I'll say the last five years of

363
00:15:11,440 --> 00:15:15,759
my life maybe prior to this past year

364
00:15:13,800 --> 00:15:17,759
was in our hydraulic fracturing business

365
00:15:15,759 --> 00:15:19,880
so a really you know you talk about hard

366
00:15:17,759 --> 00:15:21,519
tech I mean it's a harsh environment it

367
00:15:19,880 --> 00:15:22,920
reminds me of sort of the military type

368
00:15:21,519 --> 00:15:24,600
application where you're out in the

369
00:15:22,920 --> 00:15:28,040
middle of nowhere there's no internet

370
00:15:24,600 --> 00:15:29,319
it's 24/7 Ops it's I won't say low skill

371
00:15:28,040 --> 00:15:30,880
people I'll say they're very skilled

372
00:15:29,319 --> 00:15:32,600
people but they are very low digitally

373
00:15:30,880 --> 00:15:34,319
Savvy people and so when you take things

374
00:15:32,600 --> 00:15:35,600
out there you know most of the times I

375
00:15:34,319 --> 00:15:36,680
brought back my hardware and it was

376
00:15:35,600 --> 00:15:37,839
smashed with a hammer this is really

377
00:15:36,680 --> 00:15:39,920
what happens every day in the field They

378
00:15:37,839 --> 00:15:42,600
smash my sensors They smash my cables

379
00:15:39,920 --> 00:15:44,160
they break everything so and so you know

380
00:15:42,600 --> 00:15:46,079
this is just to set the context this is

381
00:15:44,160 --> 00:15:48,440
what we're taking our digital Tech out

382
00:15:46,079 --> 00:15:49,639
into and and what I'll share so I think

383
00:15:48,440 --> 00:15:52,079
the answer to your question to me is

384
00:15:49,639 --> 00:15:53,720
transparency I think making the digital

385
00:15:52,079 --> 00:15:56,720
solution is transparent about what it's

386
00:15:53,720 --> 00:15:58,279
doing is possible drives the change

387
00:15:56,720 --> 00:15:59,639
management and makes it easier and I'll

388
00:15:58,279 --> 00:16:01,800
give you an example when I would go out

389
00:15:59,639 --> 00:16:04,040
into operations in the middle of Saudi

390
00:16:01,800 --> 00:16:05,639
Arabia or which if you go to West Texas

391
00:16:04,040 --> 00:16:08,680
it's bot lock Saudi Arabia in some

392
00:16:05,639 --> 00:16:10,079
places um get a beer but you can get a

393
00:16:08,680 --> 00:16:12,000
beer yeah maybe no self service but a

394
00:16:10,079 --> 00:16:13,600
beer but but you get out there and you

395
00:16:12,000 --> 00:16:15,399
know these guys are running just to put

396
00:16:13,600 --> 00:16:18,040
it in perspective they've got 40,000

397
00:16:15,399 --> 00:16:19,959
horsepower about 100 million assets and

398
00:16:18,040 --> 00:16:21,639
super high pressure and and huge safety

399
00:16:19,959 --> 00:16:23,000
risks and so you know these guys are

400
00:16:21,639 --> 00:16:24,000
making two or three decisions every

401
00:16:23,000 --> 00:16:25,480
minute about how they're going to run

402
00:16:24,000 --> 00:16:28,199
this basically a mobile manufacturing

403
00:16:25,480 --> 00:16:29,240
plant to manufacture it well um and so

404
00:16:28,199 --> 00:16:30,680
we roll out there with the piece of

405
00:16:29,240 --> 00:16:32,519
technology says you can click one button

406
00:16:30,680 --> 00:16:33,519
and run the entire thing autonomously

407
00:16:32,519 --> 00:16:34,680
and I'll tell you we went out cuz we

408
00:16:33,519 --> 00:16:36,360
want to get first to Market and get

409
00:16:34,680 --> 00:16:38,560
these things out the door and went out

410
00:16:36,360 --> 00:16:40,199
with PC's that didn't have transparency

411
00:16:38,560 --> 00:16:41,800
like it's making decisions every minute

412
00:16:40,199 --> 00:16:43,000
and these guys are literally freaking

413
00:16:41,800 --> 00:16:44,600
out because they're saying I don't what

414
00:16:43,000 --> 00:16:46,800
this thing's doing and you're commanding

415
00:16:44,600 --> 00:16:47,959
you know a million dollar asset so I

416
00:16:46,800 --> 00:16:49,880
think the lesson learned there is you

417
00:16:47,959 --> 00:16:51,120
know I think and what these guys wanted

418
00:16:49,880 --> 00:16:52,720
was really simple every time it makes a

419
00:16:51,120 --> 00:16:53,639
decision write it out on the screen for

420
00:16:52,720 --> 00:16:55,160
me and tell me what it's doing every

421
00:16:53,639 --> 00:16:56,880
minute so I can evaluate it and give me

422
00:16:55,160 --> 00:16:59,319
the ability to take control if I want to

423
00:16:56,880 --> 00:17:00,959
back and in this case like a a fra crew

424
00:16:59,319 --> 00:17:03,079
may have the manufacturing plan may have

425
00:17:00,959 --> 00:17:04,559
20 machines so we did some things to

426
00:17:03,079 --> 00:17:06,559
give them control of individual machines

427
00:17:04,559 --> 00:17:08,480
but automate as much as possible and so

428
00:17:06,559 --> 00:17:09,720
in that context I think transparency is

429
00:17:08,480 --> 00:17:10,760
they want to know exactly what's

430
00:17:09,720 --> 00:17:12,480
happening every time and why the

431
00:17:10,760 --> 00:17:14,760
decision is being made I think you move

432
00:17:12,480 --> 00:17:16,280
to kind of The Office application you

433
00:17:14,760 --> 00:17:18,039
know and so by the way that would be if

434
00:17:16,280 --> 00:17:19,880
I went to my ux team they would say

435
00:17:18,039 --> 00:17:21,240
that's an absolutely horrible ux Eric

436
00:17:19,880 --> 00:17:22,400
you shouldn't report all this stuff we

437
00:17:21,240 --> 00:17:23,480
make it clean and simple but this is

438
00:17:22,400 --> 00:17:25,000
what these guys need in the field

439
00:17:23,480 --> 00:17:27,039
because they have a you know business

440
00:17:25,000 --> 00:17:28,400
critical application it's high risk I

441
00:17:27,039 --> 00:17:30,559
think when I go to the office it's still

442
00:17:28,400 --> 00:17:32,200
transparent but it's you know gen

443
00:17:30,559 --> 00:17:34,280
hallucinations are a big problem I mean

444
00:17:32,200 --> 00:17:35,559
fundamentally the algorithm is lying to

445
00:17:34,280 --> 00:17:37,080
us this is what it's doing we can use

446
00:17:35,559 --> 00:17:39,880
hallucination these words but it's in

447
00:17:37,080 --> 00:17:41,440
essence telling us uh a non- truth and I

448
00:17:39,880 --> 00:17:43,000
think there it's you know how do we

449
00:17:41,440 --> 00:17:44,200
Shield against just just tell me you

450
00:17:43,000 --> 00:17:46,000
don't know the answer this is really I

451
00:17:44,200 --> 00:17:47,480
think what gen needs to do to work well

452
00:17:46,000 --> 00:17:49,440
in the business and this is what we're

453
00:17:47,480 --> 00:17:50,720
working on every day is trying to detect

454
00:17:49,440 --> 00:17:52,799
hallucinations if you will various

455
00:17:50,720 --> 00:17:54,280
metrics and algorithms and just say we

456
00:17:52,799 --> 00:17:55,240
don't know we know the answer I think

457
00:17:54,280 --> 00:17:57,520
you know it's it's a level of

458
00:17:55,240 --> 00:17:59,039
transparency too to allowing us to scale

459
00:17:57,520 --> 00:18:00,760
AI I think this is the biggest challeng

460
00:17:59,039 --> 00:18:03,640
got today though is I think transparency

461
00:18:00,760 --> 00:18:04,880
is one of the main um things you need to

462
00:18:03,640 --> 00:18:05,799
implement to to make it work and what

463
00:18:04,880 --> 00:18:08,880
we're working

464
00:18:05,799 --> 00:18:11,320
on Super Carrie Brian you want to build

465
00:18:08,880 --> 00:18:13,559
on that in thinking about some

466
00:18:11,320 --> 00:18:16,080
experiments you've been doing or

467
00:18:13,559 --> 00:18:19,600
things want to take it first sure I I

468
00:18:16,080 --> 00:18:21,760
guess the the thing that we recommend

469
00:18:19,600 --> 00:18:24,280
and best practice is that it's never

470
00:18:21,760 --> 00:18:26,760
about a singular tool like I presented a

471
00:18:24,280 --> 00:18:28,919
decision tree a neuronet but you should

472
00:18:26,760 --> 00:18:30,440
be using all the tools and if they I'll

473
00:18:28,919 --> 00:18:31,840
give you the same answer that's great

474
00:18:30,440 --> 00:18:33,320
and if they're telling you if one of

475
00:18:31,840 --> 00:18:34,679
them is telling you something different

476
00:18:33,320 --> 00:18:36,400
if it's hallucinating if it's giving you

477
00:18:34,679 --> 00:18:38,880
an incorrect answer it's a little more

478
00:18:36,400 --> 00:18:40,640
obvious if you're getting answer one

479
00:18:38,880 --> 00:18:41,960
from a decision tree answer two from a

480
00:18:40,640 --> 00:18:44,679
support Vector machine answer three from

481
00:18:41,960 --> 00:18:46,600
a neural net and so in terms of practice

482
00:18:44,679 --> 00:18:48,320
you it's not just say hey I have the

483
00:18:46,600 --> 00:18:49,600
hammer that I'm going to hit everything

484
00:18:48,320 --> 00:18:50,760
with I have the hammer the wrench the

485
00:18:49,600 --> 00:18:52,120
screwdriver I'm going to use all those

486
00:18:50,760 --> 00:18:53,640
tools and all of them are going to give

487
00:18:52,120 --> 00:18:55,039
me a different answer and if I believe

488
00:18:53,640 --> 00:18:57,000
if they all are giv me the same answer I

489
00:18:55,039 --> 00:18:58,960
have a lot more confidence that it's the

490
00:18:57,000 --> 00:19:01,440
right thing I was going to add a little

491
00:18:58,960 --> 00:19:03,120
bit different angle there um I I think

492
00:19:01,440 --> 00:19:06,760
part of the issue we're seeing as we

493
00:19:03,120 --> 00:19:09,600
transition to more AI is a concern that

494
00:19:06,760 --> 00:19:12,120
we're going to lose the skills of the

495
00:19:09,600 --> 00:19:14,120
people whose jobs are being supplemented

496
00:19:12,120 --> 00:19:16,159
with AI and that's what I heard in your

497
00:19:14,120 --> 00:19:17,400
example too the guys in the field they

498
00:19:16,159 --> 00:19:19,360
need to know what's happening they need

499
00:19:17,400 --> 00:19:22,280
to see the million dooll machine being

500
00:19:19,360 --> 00:19:23,720
transformed with AI or with the tool in

501
00:19:22,280 --> 00:19:25,480
a way that they understand what's

502
00:19:23,720 --> 00:19:28,320
happening but there's another piece of

503
00:19:25,480 --> 00:19:30,480
that for me which is we have skill sets

504
00:19:28,320 --> 00:19:32,320
that once we automate them the people

505
00:19:30,480 --> 00:19:34,520
who are doing the work either never had

506
00:19:32,320 --> 00:19:36,880
the skill in the first place or stop

507
00:19:34,520 --> 00:19:39,120
keeping that skill current and that's a

508
00:19:36,880 --> 00:19:41,400
big problem especially where for

509
00:19:39,120 --> 00:19:43,280
something as as sensitive I guess is the

510
00:19:41,400 --> 00:19:45,120
right word in the field where something

511
00:19:43,280 --> 00:19:46,799
could go Ary I mean a little something

512
00:19:45,120 --> 00:19:48,440
electronically this is my big fear of

513
00:19:46,799 --> 00:19:50,799
anything that we digitize whether it's a

514
00:19:48,440 --> 00:19:52,600
digital twin or something in the field

515
00:19:50,799 --> 00:19:54,640
the minute it goes a little Ary if the

516
00:19:52,600 --> 00:19:57,520
people in the system don't have the

517
00:19:54,640 --> 00:19:59,919
skill set or the experience to from

518
00:19:57,520 --> 00:20:01,600
before we autom everything how are they

519
00:19:59,919 --> 00:20:04,039
going to know that it's going a whether

520
00:20:01,600 --> 00:20:05,520
it's a hallucination or whether it's a

521
00:20:04,039 --> 00:20:08,000
process that goes AR and I think that's

522
00:20:05,520 --> 00:20:11,600
a big fear that we haven't really

523
00:20:08,000 --> 00:20:13,520
addressed um in in the implementation of

524
00:20:11,600 --> 00:20:14,840
a transformation transformed system and

525
00:20:13,520 --> 00:20:16,600
we want to think about that as part of

526
00:20:14,840 --> 00:20:17,760
the design we don't we want to make are

527
00:20:16,600 --> 00:20:20,120
part of the buildout we want to make

528
00:20:17,760 --> 00:20:21,360
sure that we don't lose the skills we

529
00:20:20,120 --> 00:20:22,799
we've already lost a lot of skills

530
00:20:21,360 --> 00:20:25,720
because of things we've automated along

531
00:20:22,799 --> 00:20:29,080
the way I I remember um work done by one

532
00:20:25,720 --> 00:20:31,720
of my colleagues many years ago 30 years

533
00:20:29,080 --> 00:20:34,200
ago about automating paper the paper

534
00:20:31,720 --> 00:20:37,320
process and the people paper you know to

535
00:20:34,200 --> 00:20:39,280
make paper making paper paper used to be

536
00:20:37,320 --> 00:20:40,640
you know you boil all the components and

537
00:20:39,280 --> 00:20:42,520
the people that made the paper could

538
00:20:40,640 --> 00:20:43,760
tell by the smell and the the

539
00:20:42,520 --> 00:20:45,520
consistency and the feeling they

540
00:20:43,760 --> 00:20:47,320
automated it all and all of a sudden

541
00:20:45,520 --> 00:20:48,960
those people weren't the experts anymore

542
00:20:47,320 --> 00:20:51,600
because the system automated it but then

543
00:20:48,960 --> 00:20:53,559
nobody ever really had that expertise to

544
00:20:51,600 --> 00:20:56,600
make the paper anymore they was all done

545
00:20:53,559 --> 00:20:58,240
through electronic controls uh the the

546
00:20:56,600 --> 00:21:00,840
the person who did that research her

547
00:20:58,240 --> 00:21:03,039
name was shos zubo and she wrote some

548
00:21:00,840 --> 00:21:05,640
work called automate or infomate and it

549
00:21:03,039 --> 00:21:07,720
was about adding information to A system

550
00:21:05,640 --> 00:21:09,679
that then um changes the way that the

551
00:21:07,720 --> 00:21:11,400
systems done and I I see the same kind

552
00:21:09,679 --> 00:21:14,039
of thing happening with AI the problem

553
00:21:11,400 --> 00:21:16,360
is people start to trust the AI and it

554
00:21:14,039 --> 00:21:17,799
might be wrong and we don't know yet I

555
00:21:16,360 --> 00:21:19,600
mean maybe we'll get to a point where

556
00:21:17,799 --> 00:21:20,720
it's not wrong and we as scientists

557
00:21:19,600 --> 00:21:22,679
would like to think that it's never

558
00:21:20,720 --> 00:21:24,559
wrong but it it is it does hallucinate

559
00:21:22,679 --> 00:21:25,919
does tell us the wrong answer it may not

560
00:21:24,559 --> 00:21:27,880
even be smart enough to tell us that

561
00:21:25,919 --> 00:21:29,960
it's telling us the wrong answer but the

562
00:21:27,880 --> 00:21:32,559
point is that we can't lose the skills

563
00:21:29,960 --> 00:21:34,960
in the interim while we transition to

564
00:21:32,559 --> 00:21:36,960
our new operational um environment

565
00:21:34,960 --> 00:21:38,640
because we need that skill to be able to

566
00:21:36,960 --> 00:21:40,279
make sure that we're doing our processes

567
00:21:38,640 --> 00:21:41,480
correctly I don't know the answer to

568
00:21:40,279 --> 00:21:42,960
that right now but that's that's what

569
00:21:41,480 --> 00:21:45,039
it's sparked in my head is this work we

570
00:21:42,960 --> 00:21:48,320
did many years ago about automating

571
00:21:45,039 --> 00:21:49,679
processes and infom mating processes

572
00:21:48,320 --> 00:21:51,880
isn't it funny that we've picked the

573
00:21:49,679 --> 00:21:54,200
word hallucination that it's

574
00:21:51,880 --> 00:21:56,200
hallucinating and that I I like that

575
00:21:54,200 --> 00:22:00,520
sounds like it's having

576
00:21:56,200 --> 00:22:00,520
fun we know what you were doing back in

577
00:22:01,520 --> 00:22:04,600
it's another example of just giving a

578
00:22:02,679 --> 00:22:08,240
new name to something it makes a mistake

579
00:22:04,600 --> 00:22:10,279
it's giving you the wrong answer it's a

580
00:22:08,240 --> 00:22:12,520
hallucination that's a good one okay so

581
00:22:10,279 --> 00:22:14,400
Rob you got out of that one but I'm I'm

582
00:22:12,520 --> 00:22:16,919
you're not done with me yet so I'm gonna

583
00:22:14,400 --> 00:22:22,080
give you a different question um this

584
00:22:16,919 --> 00:22:24,039
morning Liz talked about uh climate and

585
00:22:22,080 --> 00:22:27,279
that you know we're seeing a lot of

586
00:22:24,039 --> 00:22:29,440
weather issues and different things um

587
00:22:27,279 --> 00:22:31,880
that's also need needs to be imp

588
00:22:29,440 --> 00:22:33,440
impacting how we think about operations

589
00:22:31,880 --> 00:22:34,880
so why don't you talk that a little bit

590
00:22:33,440 --> 00:22:38,120
about

591
00:22:34,880 --> 00:22:40,760
that um so I'll I'll give you an example

592
00:22:38,120 --> 00:22:43,039
okay uh let's start with how you

593
00:22:40,760 --> 00:22:47,080
engineer it right and where the engineer

594
00:22:43,039 --> 00:22:49,600
sits when I was on uh the Keystone XL

595
00:22:47,080 --> 00:22:52,039
pipeline the bulk of the engineering for

596
00:22:49,600 --> 00:22:54,320
the pump stations was being done by

597
00:22:52,039 --> 00:22:57,360
engineering teams out of

598
00:22:54,320 --> 00:22:59,240
Calgary now they're designing for what

599
00:22:57,360 --> 00:23:02,600
they understand to be their weather

600
00:22:59,240 --> 00:23:04,760
impacts long Winters Etc but you're

601
00:23:02,600 --> 00:23:07,840
putting pump stations down here on the

602
00:23:04,760 --> 00:23:09,880
Gulf Coast and it's a much different

603
00:23:07,840 --> 00:23:12,880
environment then when you're trying to

604
00:23:09,880 --> 00:23:15,440
get it signed off by a PE or get it into

605
00:23:12,880 --> 00:23:18,760
operation you're the person is used to

606
00:23:15,440 --> 00:23:22,919
looking at a very specific set of code

607
00:23:18,760 --> 00:23:27,039
as it is applied to weather Etc where I

608
00:23:22,919 --> 00:23:30,840
think we are today more and more is your

609
00:23:27,039 --> 00:23:33,400
plants uh your assets have to be able to

610
00:23:30,840 --> 00:23:36,200
operate at the low end to the very high

611
00:23:33,400 --> 00:23:38,559
end of the temperature sphere so it take

612
00:23:36,200 --> 00:23:40,520
what was it four years ago we had three

613
00:23:38,559 --> 00:23:44,279
days of freezing here in

614
00:23:40,520 --> 00:23:47,039
Texas um plants because they you don't

615
00:23:44,279 --> 00:23:49,039
put heat tracing on the pipes all the

616
00:23:47,039 --> 00:23:51,159
plants stopped operating and we froze

617
00:23:49,039 --> 00:23:53,200
our tail off for three days there's a

618
00:23:51,159 --> 00:23:55,200
whole other set of reasons around that

619
00:23:53,200 --> 00:23:58,559
but at the end of the day it was a

620
00:23:55,200 --> 00:24:02,039
design decision based on cost that that

621
00:23:58,559 --> 00:24:04,159
I wouldn't have as long ax period that I

622
00:24:02,039 --> 00:24:07,320
would have to do this so I'm not doing

623
00:24:04,159 --> 00:24:09,720
it and I think those days are over so

624
00:24:07,320 --> 00:24:11,640
we're going to have to start either

625
00:24:09,720 --> 00:24:15,960
accepting those

626
00:24:11,640 --> 00:24:18,440
costs and Andor being ready to be cold

627
00:24:15,960 --> 00:24:20,400
and freezing for three days or four days

628
00:24:18,440 --> 00:24:24,240
as that works through because it's

629
00:24:20,400 --> 00:24:26,600
happening uh you lose uh it's it's

630
00:24:24,240 --> 00:24:29,120
hotter and wetter on the Gulf Coast

631
00:24:26,600 --> 00:24:31,080
every year where folks are out there

632
00:24:29,120 --> 00:24:33,840
operating and you Eric's talking about

633
00:24:31,080 --> 00:24:36,960
the desert I I don't think that people

634
00:24:33,840 --> 00:24:39,399
are really want you know it's not that

635
00:24:36,960 --> 00:24:41,279
they want to see every decision they

636
00:24:39,399 --> 00:24:43,640
just want to be in the loop with the

637
00:24:41,279 --> 00:24:47,120
decisions that are being made and being

638
00:24:43,640 --> 00:24:49,760
able to say a go noo on an asset that's

639
00:24:47,120 --> 00:24:52,360
multi-millions of dollars and ultimately

640
00:24:49,760 --> 00:24:54,039
they're responsible for that also comes

641
00:24:52,360 --> 00:24:56,679
down to when you stand it up when you

642
00:24:54,039 --> 00:24:59,399
shut it down how you shutter for a

643
00:24:56,679 --> 00:25:00,840
weather event long answer to a short

644
00:24:59,399 --> 00:25:03,559
question but I think we have to start

645
00:25:00,840 --> 00:25:06,399
designing for both ends of the Spectrum

646
00:25:03,559 --> 00:25:06,399
in the in the

647
00:25:07,200 --> 00:25:12,600
Americas good okay so we're gonna now

648
00:25:09,799 --> 00:25:15,840
move to a speed round Brian I'm going to

649
00:25:12,600 --> 00:25:19,440
start with you uh first question and

650
00:25:15,840 --> 00:25:21,840
sort of do a 15 20 second sort of just

651
00:25:19,440 --> 00:25:25,679
response and we'll go down the line what

652
00:25:21,840 --> 00:25:30,200
is the most impactful technology driving

653
00:25:25,679 --> 00:25:30,200
operational transformation today

654
00:25:31,520 --> 00:25:36,240
I I I guess actually what I'm seeing is

655
00:25:34,840 --> 00:25:38,200
an

656
00:25:36,240 --> 00:25:39,679
underutilized tool that's commercially

657
00:25:38,200 --> 00:25:41,799
available whether it be from seens or

658
00:25:39,679 --> 00:25:44,720
any logic things like discrete event and

659
00:25:41,799 --> 00:25:46,159
discret time simulation as tools that

660
00:25:44,720 --> 00:25:47,760
allows you to simulate sort of at the

661
00:25:46,159 --> 00:25:48,880
factory level and and those are things

662
00:25:47,760 --> 00:25:49,960
that are underutilized like they're

663
00:25:48,880 --> 00:25:51,880
commercially available they're well

664
00:25:49,960 --> 00:25:53,240
practiced in some Industries but you

665
00:25:51,880 --> 00:25:54,559
know when small medium companies are

666
00:25:53,240 --> 00:25:56,320
sort of getting exposed to these tools

667
00:25:54,559 --> 00:25:59,159
it's it's it's transformational in in

668
00:25:56,320 --> 00:26:00,960
how they think about their operations

669
00:25:59,159 --> 00:26:02,799
so I told Kathleen I was going to change

670
00:26:00,960 --> 00:26:05,200
questions to what I wanted to answer I'm

671
00:26:02,799 --> 00:26:07,000
not a tool expert so I would my first

672
00:26:05,200 --> 00:26:09,320
thought is AI but we already talked a

673
00:26:07,000 --> 00:26:11,120
lot about AI so I'm going to talk about

674
00:26:09,320 --> 00:26:13,520
what I think is a more transformational

675
00:26:11,120 --> 00:26:16,279
idea and I think the idea here is

676
00:26:13,520 --> 00:26:19,159
designing for resilience I think um as

677
00:26:16,279 --> 00:26:21,760
we're thinking about um uh driving

678
00:26:19,159 --> 00:26:23,039
opportunities for transformation uh we

679
00:26:21,760 --> 00:26:24,880
want to make sure that we're building

680
00:26:23,039 --> 00:26:27,080
something that that can be around for

681
00:26:24,880 --> 00:26:29,200
the world we're expecting with all of

682
00:26:27,080 --> 00:26:30,760
the new um threat and vulnerabilities

683
00:26:29,200 --> 00:26:33,120
that are coming our

684
00:26:30,760 --> 00:26:35,360
Direction I'll go with an old Tech kind

685
00:26:33,120 --> 00:26:37,039
of but containers uh I mean containers

686
00:26:35,360 --> 00:26:38,440
are a simple idea but when you look

687
00:26:37,039 --> 00:26:40,320
across a lot of these Legacy businesses

688
00:26:38,440 --> 00:26:41,480
they're not deployed everywhere and I

689
00:26:40,320 --> 00:26:43,240
I'll use this in the context of

690
00:26:41,480 --> 00:26:44,679
operations I mean the ability for a

691
00:26:43,240 --> 00:26:46,679
piece of software to go down and spin

692
00:26:44,679 --> 00:26:48,200
back up instantaneously is huge I mean

693
00:26:46,679 --> 00:26:50,399
we can't afford downtime I think the

694
00:26:48,200 --> 00:26:52,919
other thing is the ability to push small

695
00:26:50,399 --> 00:26:54,600
updates in low bandwidth environments is

696
00:26:52,919 --> 00:26:56,039
huge I think these these are very simple

697
00:26:54,600 --> 00:26:57,559
foundational things but once again it's

698
00:26:56,039 --> 00:27:00,200
the foundation that kind of we build Ai

699
00:26:57,559 --> 00:27:03,520
and other things on top

700
00:27:00,200 --> 00:27:06,279
of to me it's uh because I'm on a theme

701
00:27:03,520 --> 00:27:09,440
Here human in the loop that's affordable

702
00:27:06,279 --> 00:27:12,039
to me it's uh back to wearables and what

703
00:27:09,440 --> 00:27:14,240
you can do with uh technology Brian

704
00:27:12,039 --> 00:27:16,640
touched on this a little bit earlier I

705
00:27:14,240 --> 00:27:19,000
think that is severely underutilized

706
00:27:16,640 --> 00:27:22,200
when we're trying to figure out uh Time

707
00:27:19,000 --> 00:27:24,559
On Tools how can we get uh equipment or

708
00:27:22,200 --> 00:27:26,919
materials to the craft so that they can

709
00:27:24,559 --> 00:27:28,960
work their magic uh in a much more

710
00:27:26,919 --> 00:27:32,039
efficient manner

711
00:27:28,960 --> 00:27:34,440
what their bodies are doing in these hot

712
00:27:32,039 --> 00:27:36,640
cold humid temperatures and how we can

713
00:27:34,440 --> 00:27:39,520
do things to regulate help them regulate

714
00:27:36,640 --> 00:27:42,200
that so that they can be more productive

715
00:27:39,520 --> 00:27:44,640
uh and safer in the environment to me I

716
00:27:42,200 --> 00:27:47,159
think that's the underutilized tool all

717
00:27:44,640 --> 00:27:49,320
of us have uh most of us in this room I

718
00:27:47,159 --> 00:27:51,240
would say will have some form of

719
00:27:49,320 --> 00:27:54,200
Smartwatch uh you know now you can get

720
00:27:51,240 --> 00:27:56,399
them for 15200 bucks but you know when

721
00:27:54,200 --> 00:27:59,080
you say you have a work site of 5,000

722
00:27:56,399 --> 00:28:01,679
people the construction man maner says

723
00:27:59,080 --> 00:28:04,000
no way am I doing that but I I think as

724
00:28:01,679 --> 00:28:06,320
that becomes more commoditized we'll

725
00:28:04,000 --> 00:28:09,120
find Opportunities and the data that

726
00:28:06,320 --> 00:28:10,679
we'll get from it will reinforce some

727
00:28:09,120 --> 00:28:13,000
things but we'll also learn some things

728
00:28:10,679 --> 00:28:15,200
that we haven't really thought

729
00:28:13,000 --> 00:28:17,399
about okay just just add on that for a

730
00:28:15,200 --> 00:28:18,760
moment like as an intellectual field

731
00:28:17,399 --> 00:28:21,039
people are introducing the concept of

732
00:28:18,760 --> 00:28:23,679
Industry 5 which is actually just this I

733
00:28:21,039 --> 00:28:25,960
actually like also instrument the person

734
00:28:23,679 --> 00:28:28,240
um and having both ergonomic awareness

735
00:28:25,960 --> 00:28:30,120
health awareness of the of the worker as

736
00:28:28,240 --> 00:28:33,120
a part of the the of the overall

737
00:28:30,120 --> 00:28:35,200
operations so that it is a exiting a lot

738
00:28:33,120 --> 00:28:36,840
of academic attention and there are some

739
00:28:35,200 --> 00:28:38,320
some companies that you know BMW they

740
00:28:36,840 --> 00:28:40,000
can think of one in particular that's

741
00:28:38,320 --> 00:28:42,919
trying to use that to accelerate the

742
00:28:40,000 --> 00:28:45,919
rate with which they train do training

743
00:28:42,919 --> 00:28:48,320
uh for manual operations yeah I just

744
00:28:45,919 --> 00:28:50,360
invested in an MIT found a company

745
00:28:48,320 --> 00:28:52,519
that's doing augmentation I think

746
00:28:50,360 --> 00:28:56,840
there's a lot of really interesting

747
00:28:52,519 --> 00:28:58,760
stuff there uh Brian back to you for our

748
00:28:56,840 --> 00:29:00,120
speed round second question question

749
00:28:58,760 --> 00:29:03,880
biggest

750
00:29:00,120 --> 00:29:06,559
misconception about Ai and

751
00:29:03,880 --> 00:29:08,799
operations biggest misconception um I

752
00:29:06,559 --> 00:29:11,640
guess I'll map it as maybe sort of going

753
00:29:08,799 --> 00:29:13,440
back to sort of the point of of the user

754
00:29:11,640 --> 00:29:16,039
interface and how how do we help the

755
00:29:13,440 --> 00:29:18,960
operator know what's going on AI tools

756
00:29:16,039 --> 00:29:21,200
are really good at interpolating like if

757
00:29:18,960 --> 00:29:23,760
whatever your data set is okay I can I

758
00:29:21,200 --> 00:29:25,519
can learn how to predict and what's

759
00:29:23,760 --> 00:29:29,120
happening in the data within the space

760
00:29:25,519 --> 00:29:30,640
that I've observed and the to improve

761
00:29:29,120 --> 00:29:33,960
operations to improve how we understand

762
00:29:30,640 --> 00:29:35,480
the tools to make aware to the person

763
00:29:33,960 --> 00:29:36,720
when a data point that we're trying to

764
00:29:35,480 --> 00:29:39,679
understand is outside of the things that

765
00:29:36,720 --> 00:29:41,279
we've seen in the past um and and have

766
00:29:39,679 --> 00:29:43,000
the tools be able to convey that

767
00:29:41,279 --> 00:29:43,960
information I think that's not exactly

768
00:29:43,000 --> 00:29:46,039
the question you asked but sort of being

769
00:29:43,960 --> 00:29:47,519
able to like flag like yeah we don't we

770
00:29:46,039 --> 00:29:48,760
haven't seen this type of data before so

771
00:29:47,519 --> 00:29:51,120
anything any answer we're going to give

772
00:29:48,760 --> 00:29:52,679
is wrong and this is a prime place where

773
00:29:51,120 --> 00:29:54,600
human context understanding could be

774
00:29:52,679 --> 00:29:55,840
really helpful to make sense of of this

775
00:29:54,600 --> 00:29:58,440
aberant thing that we're trying to use

776
00:29:55,840 --> 00:30:01,320
to predict yes the questions are me to

777
00:29:58,440 --> 00:30:03,399
prompt discussion and interesting ideas

778
00:30:01,320 --> 00:30:07,760
so it's okay if you change them Carrie

779
00:30:03,399 --> 00:30:07,760
go ahead this one I think I'm going to

780
00:30:07,799 --> 00:30:11,320
answer uh I think the biggest

781
00:30:09,720 --> 00:30:13,559
misconception we've already addressed

782
00:30:11,320 --> 00:30:16,080
number one which is that you can replace

783
00:30:13,559 --> 00:30:18,600
people with AI but I think we also have

784
00:30:16,080 --> 00:30:20,440
to remember that um people aren't

785
00:30:18,600 --> 00:30:22,399
perfect either and we've seen lots of

786
00:30:20,440 --> 00:30:25,080
instances where people have introduced

787
00:30:22,399 --> 00:30:27,360
information into an AI system that has

788
00:30:25,080 --> 00:30:29,919
had unintended in this case security

789
00:30:27,360 --> 00:30:32,399
consequences where um people think that

790
00:30:29,919 --> 00:30:34,360
they're entering a schematic just to

791
00:30:32,399 --> 00:30:35,600
make it better into some geni product

792
00:30:34,360 --> 00:30:38,200
and it ends up being part of the

793
00:30:35,600 --> 00:30:40,559
learning to the learning tools that

794
00:30:38,200 --> 00:30:43,279
train a publicly available AI so I think

795
00:30:40,559 --> 00:30:45,840
the biggest misconception is AI has the

796
00:30:43,279 --> 00:30:47,679
answers uh because I think sometimes we

797
00:30:45,840 --> 00:30:50,279
we've got to make sure those guard rails

798
00:30:47,679 --> 00:30:53,000
are in place for the people using our

799
00:30:50,279 --> 00:30:54,960
AIS uh and they understand the risk of

800
00:30:53,000 --> 00:30:56,840
putting something into an AI system that

801
00:30:54,960 --> 00:30:58,399
might unint have unintentional

802
00:30:56,840 --> 00:31:00,200
consequences

803
00:30:58,399 --> 00:31:03,399
I want to Bild on this one I think the

804
00:31:00,200 --> 00:31:05,080
misconception is AI is be is better than

805
00:31:03,399 --> 00:31:07,200
people I think it's absolutely false

806
00:31:05,080 --> 00:31:09,399
maybe in a narrow context in some cases

807
00:31:07,200 --> 00:31:11,120
yes uh and I don't know the why but I'll

808
00:31:09,399 --> 00:31:13,120
I'll hypothesize I think one why might

809
00:31:11,120 --> 00:31:14,639
be that we've got a lot of sensors on us

810
00:31:13,120 --> 00:31:16,480
every day and I'll tell you if you go

811
00:31:14,639 --> 00:31:18,760
out into operations and watch people and

812
00:31:16,480 --> 00:31:20,639
sit there they are seeing smelling

813
00:31:18,760 --> 00:31:22,120
hearing getting input that the AI

814
00:31:20,639 --> 00:31:23,639
doesn't get fundamentally so I think we

815
00:31:22,120 --> 00:31:25,320
have an advantage because we have a new

816
00:31:23,639 --> 00:31:26,880
data stream lots of data streams that AI

817
00:31:25,320 --> 00:31:28,200
doesn't have I think two there's still

818
00:31:26,880 --> 00:31:30,080
something special about humans maybe

819
00:31:28,200 --> 00:31:31,639
this is just my desire to have humans

820
00:31:30,080 --> 00:31:33,559
not get beat by AI here but you know I

821
00:31:31,639 --> 00:31:35,240
think in a broad context of doing really

822
00:31:33,559 --> 00:31:37,399
Dynamic things it's still super hard to

823
00:31:35,240 --> 00:31:40,320
beat humans I I don't foresee AI beating

824
00:31:37,399 --> 00:31:41,919
us in 10 years the humans are still

825
00:31:40,320 --> 00:31:45,679
winning

826
00:31:41,919 --> 00:31:49,240
excellent II I think

827
00:31:45,679 --> 00:31:52,760
that humans have to realize that uh

828
00:31:49,240 --> 00:31:55,399
virtual presence is physical absence and

829
00:31:52,760 --> 00:31:57,159
why do I say that uh I think we've all

830
00:31:55,399 --> 00:32:00,639
been around for quite some time we've

831
00:31:57,159 --> 00:32:03,919
seen different revolutions Evolutions

832
00:32:00,639 --> 00:32:08,360
changes the one constant in all of that

833
00:32:03,919 --> 00:32:10,240
at any site in any lab is the human so

834
00:32:08,360 --> 00:32:14,039
the misconception that I keep working

835
00:32:10,240 --> 00:32:15,519
with with the team on is it's not about

836
00:32:14,039 --> 00:32:18,799
that the human is going to become

837
00:32:15,519 --> 00:32:21,200
replaced or or irrelevant it's about how

838
00:32:18,799 --> 00:32:24,480
do we upscale the human so that they can

839
00:32:21,200 --> 00:32:27,360
use the Technologies in a collaborative

840
00:32:24,480 --> 00:32:29,120
way to get a better outcome than the

841
00:32:27,360 --> 00:32:31,200
outcome we have

842
00:32:29,120 --> 00:32:35,159
today that's what that's what we talk a

843
00:32:31,200 --> 00:32:38,760
lot about at MIT Horizon um okay so

844
00:32:35,159 --> 00:32:41,039
Brian you've got five minutes so I'm

845
00:32:38,760 --> 00:32:42,880
going to let you drive the next this

846
00:32:41,039 --> 00:32:44,919
next portion of conversation and then

847
00:32:42,880 --> 00:32:47,639
we're going to have the mics and and

848
00:32:44,919 --> 00:32:50,960
open up for questions um what would you

849
00:32:47,639 --> 00:32:54,559
like to talk about what have we

850
00:32:50,960 --> 00:32:57,880
missed um so I think the just top of

851
00:32:54,559 --> 00:33:02,159
mind because of a what we do at MIT and

852
00:32:57,880 --> 00:33:08,880
what's sort of what I'm hearing is the

853
00:33:02,159 --> 00:33:10,320
AI as a tool um is a little scary and I

854
00:33:08,880 --> 00:33:14,720
guess the thing that I would like to

855
00:33:10,320 --> 00:33:16,799
hear from the audience is how you how

856
00:33:14,720 --> 00:33:17,519
you demystify and what what are the

857
00:33:16,799 --> 00:33:19,320
things that you do within your

858
00:33:17,519 --> 00:33:20,960
organization say listen okay it's it's

859
00:33:19,320 --> 00:33:23,279
may sound new we give new terms to

860
00:33:20,960 --> 00:33:25,480
things you know I have a hypothesis that

861
00:33:23,279 --> 00:33:28,240
we we we we call it all these other

862
00:33:25,480 --> 00:33:29,559
things and it's we can ground it and the

863
00:33:28,240 --> 00:33:31,200
things that we're already doing so i'

864
00:33:29,559 --> 00:33:33,799
would love to hear like from the

865
00:33:31,200 --> 00:33:35,840
audience in terms of like are there

866
00:33:33,799 --> 00:33:38,840
within your organizations like how are

867
00:33:35,840 --> 00:33:40,880
you socializing and say is there are we

868
00:33:38,840 --> 00:33:43,000
missing the message in how we

869
00:33:40,880 --> 00:33:44,600
communicate what these tools are doing

870
00:33:43,000 --> 00:33:46,159
for us and are we sort of trying to say

871
00:33:44,600 --> 00:33:49,240
that there's something very different

872
00:33:46,159 --> 00:33:51,760
and new when in reality we've been using

873
00:33:49,240 --> 00:33:54,440
them called different things for a long

874
00:33:51,760 --> 00:33:56,039
time um calling it process control

875
00:33:54,440 --> 00:33:58,840
calling it physical process feedback

876
00:33:56,039 --> 00:34:00,519
control I guess that's my bias I see

877
00:33:58,840 --> 00:34:04,360
like there's a lot of just sort

878
00:34:00,519 --> 00:34:06,720
of dictionary creation uh that scares

879
00:34:04,360 --> 00:34:08,440
people and grounding it and things that

880
00:34:06,720 --> 00:34:10,320
they already know I think is the way is

881
00:34:08,440 --> 00:34:12,280
one of the paths forward so right okay

882
00:34:10,320 --> 00:34:16,399
so I did a poll earlier and asked

883
00:34:12,280 --> 00:34:19,760
everyone who was using generative AI uh

884
00:34:16,399 --> 00:34:20,960
and it seemed like most people were

885
00:34:19,760 --> 00:34:24,119
using it

886
00:34:20,960 --> 00:34:26,079
personally but a lot of a very few

887
00:34:24,119 --> 00:34:30,520
people were actually working it using in

888
00:34:26,079 --> 00:34:32,599
their daytoday as an office tool um so

889
00:34:30,520 --> 00:34:35,720
is that was is that right on like who

890
00:34:32,599 --> 00:34:35,720
uses it for

891
00:34:38,760 --> 00:34:43,079
work there's a Nuance to it

892
00:34:52,639 --> 00:34:59,760
yeah so instead of Google you're using

893
00:34:56,480 --> 00:35:03,040
TPT yeah so and and another thing I

894
00:34:59,760 --> 00:35:06,160
wanted to convey before was lot of

895
00:35:03,040 --> 00:35:09,000
generative AI that we see that is been

896
00:35:06,160 --> 00:35:13,000
commoditized is based on generic

897
00:35:09,000 --> 00:35:14,680
knowledge yeah that's why I think uh the

898
00:35:13,000 --> 00:35:17,680
the presenter in the in the morning

899
00:35:14,680 --> 00:35:21,400
session was showing it at the low level

900
00:35:17,680 --> 00:35:23,880
um the of Effectiveness and and easy to

901
00:35:21,400 --> 00:35:25,160
use but there are some gen AIS which are

902
00:35:23,880 --> 00:35:29,200
specific to

903
00:35:25,160 --> 00:35:31,599
Industry that are deployed in a special

904
00:35:29,200 --> 00:35:35,040
circumstances it depends on the industry

905
00:35:31,599 --> 00:35:38,880
specific data and and that has totally

906
00:35:35,040 --> 00:35:41,160
different uh you know the the Nu around

907
00:35:38,880 --> 00:35:43,320
it so I think the question would be

908
00:35:41,160 --> 00:35:45,000
whose organization has built like a rag

909
00:35:43,320 --> 00:35:46,960
system thank

910
00:35:45,000 --> 00:35:49,079
you

911
00:35:46,960 --> 00:35:50,319
yeah okay just a couple that's

912
00:35:49,079 --> 00:35:51,920
interesting that's coming that's what

913
00:35:50,319 --> 00:35:53,400
you're going to do next well can sh I

914
00:35:51,920 --> 00:35:54,640
can share the journey that my company's

915
00:35:53,400 --> 00:35:56,000
going through right now at the moment

916
00:35:54,640 --> 00:35:58,319
with adoption right so I work for a

917
00:35:56,000 --> 00:36:00,640
company called BMC Software and at the

918
00:35:58,319 --> 00:36:03,000
moment we have ai obviously in our

919
00:36:00,640 --> 00:36:04,839
products but for the uh for the general

920
00:36:03,000 --> 00:36:05,920
population what's happening is uh we're

921
00:36:04,839 --> 00:36:08,640
noticing that people were just kind of

922
00:36:05,920 --> 00:36:10,319
like doing chat GPT and stuff like that

923
00:36:08,640 --> 00:36:11,720
and we were really concerned about our

924
00:36:10,319 --> 00:36:13,760
data being out there on those different

925
00:36:11,720 --> 00:36:14,920
models so what we ended up doing is that

926
00:36:13,760 --> 00:36:16,160
at the moment we're doing this thing

927
00:36:14,920 --> 00:36:18,000
called the flight of AI which is

928
00:36:16,160 --> 00:36:20,400
basically we have a series of trainings

929
00:36:18,000 --> 00:36:21,880
for the general population on how to

930
00:36:20,400 --> 00:36:23,960
actually you know what is AI how do we

931
00:36:21,880 --> 00:36:26,319
use it internally externally Etc so you

932
00:36:23,960 --> 00:36:28,280
have to take that no matter who you are

933
00:36:26,319 --> 00:36:30,160
uh we're also doing p we're piloting

934
00:36:28,280 --> 00:36:32,680
just a standard utilization from a

935
00:36:30,160 --> 00:36:36,520
productivity standpoint like with um

936
00:36:32,680 --> 00:36:38,119
Office 360 U co-pilot and also with uh

937
00:36:36,520 --> 00:36:40,480
with Ms teams Pro and you know

938
00:36:38,119 --> 00:36:42,000
summarizing and stuff like that uh and

939
00:36:40,480 --> 00:36:44,359
then we did a pilot just to make sure

940
00:36:42,000 --> 00:36:45,400
that people know how to use it uh the

941
00:36:44,359 --> 00:36:47,079
one thing that we understand at the

942
00:36:45,400 --> 00:36:49,200
moment is now we have every single

943
00:36:47,079 --> 00:36:52,119
organization uh within the company is

944
00:36:49,200 --> 00:36:53,040
now actually uh kind of like trying to

945
00:36:52,119 --> 00:36:55,160
understand who's going to be able to use

946
00:36:53,040 --> 00:36:56,440
it and the use cases the problem is when

947
00:36:55,160 --> 00:36:57,680
you ask people hey you going to use it

948
00:36:56,440 --> 00:36:59,880
they don't know how to use it right I'm

949
00:36:57,680 --> 00:37:01,920
I'm going to use uh gen in Excel for

950
00:36:59,880 --> 00:37:03,000
instance or co-pilot in Excel so there's

951
00:37:01,920 --> 00:37:04,119
a lot of the adoption that's not

952
00:37:03,000 --> 00:37:06,520
happening so now we're going to go ahead

953
00:37:04,119 --> 00:37:08,440
and actually uh enable everybody to

954
00:37:06,520 --> 00:37:09,839
understand with it it subf function and

955
00:37:08,440 --> 00:37:12,880
create our own use cases so we can

956
00:37:09,839 --> 00:37:14,359
actually Target the usability of it um

957
00:37:12,880 --> 00:37:16,760
and then we also looking at elements

958
00:37:14,359 --> 00:37:18,200
like for instance uh the uh agent force

959
00:37:16,760 --> 00:37:20,119
from Salesforce at the moment that we

960
00:37:18,200 --> 00:37:21,720
just looked at dreamforce uh to look at

961
00:37:20,119 --> 00:37:23,480
the uh the next uh you know the the

962
00:37:21,720 --> 00:37:25,560
virtual agents at the moment so work in

963
00:37:23,480 --> 00:37:26,920
use cases with that as well so the

964
00:37:25,560 --> 00:37:29,680
problem is if we just kind of like let

965
00:37:26,920 --> 00:37:31,280
everybody use it it there isn't really a

966
00:37:29,680 --> 00:37:34,359
full productivity that we can actually

967
00:37:31,280 --> 00:37:36,280
measure companywide and we also uh did

968
00:37:34,359 --> 00:37:37,520
uh manage to work with a third party to

969
00:37:36,280 --> 00:37:40,960
try to understand how to actually set

970
00:37:37,520 --> 00:37:44,119
governance around it and and guard rails

971
00:37:40,960 --> 00:37:46,480
and uh if you actually do want to uh do

972
00:37:44,119 --> 00:37:49,079
uh a provision AI tool whether it's

973
00:37:46,480 --> 00:37:50,760
cloud-based or whatever uh you have to

974
00:37:49,079 --> 00:37:52,760
actually go through a system through it

975
00:37:50,760 --> 00:37:54,319
to make sure first of all do we have

976
00:37:52,760 --> 00:37:56,160
anything of this of the matter of the

977
00:37:54,319 --> 00:37:58,160
sort you know obviously their budget if

978
00:37:56,160 --> 00:38:00,000
there's it's actually on our policies as

979
00:37:58,160 --> 00:38:01,560
well uh but also they're looking at if

980
00:38:00,000 --> 00:38:02,760
they do their own models uh for instance

981
00:38:01,560 --> 00:38:04,160
there was one that we we wanted to

982
00:38:02,760 --> 00:38:05,880
provision and the it said no we'll build

983
00:38:04,160 --> 00:38:07,200
it for you so they build it they built

984
00:38:05,880 --> 00:38:08,280
it internal so I think a lot of that is

985
00:38:07,200 --> 00:38:10,240
going on in there but they're trying to

986
00:38:08,280 --> 00:38:11,599
kind of like a ring fence yeah so it's

987
00:38:10,240 --> 00:38:15,280
not a freefor so that's kind of how we

988
00:38:11,599 --> 00:38:18,839
approaching it I run I do want a parting

989
00:38:15,280 --> 00:38:21,520
comment is a as a fear we're lumping in

990
00:38:18,839 --> 00:38:24,599
we're calling AI gen Ai and there's so

991
00:38:21,520 --> 00:38:26,480
much diversity in what AI tools are like

992
00:38:24,599 --> 00:38:28,079
and so like it's great you know gen is

993
00:38:26,480 --> 00:38:31,160
solving some real problems but there's

994
00:38:28,079 --> 00:38:33,880
so much more than to AI as a set of

995
00:38:31,160 --> 00:38:36,800
tools than than what gen AI is so okay

996
00:38:33,880 --> 00:38:38,319
thank you all right stay quiet All Right

997
00:38:36,800 --> 00:38:41,319
audience

998
00:38:38,319 --> 00:38:41,319
questions

999
00:38:41,359 --> 00:38:47,720
there so just on j i you know I'm a True

1000
00:38:44,800 --> 00:38:50,200
Believer that it's transformational uh

1001
00:38:47,720 --> 00:38:53,240
but if we were here three years ago

1002
00:38:50,200 --> 00:38:54,839
probably the main technology Trend that

1003
00:38:53,240 --> 00:38:57,079
we would have been talking about was

1004
00:38:54,839 --> 00:38:59,839
blockchain blockchain yeah and two years

1005
00:38:57,079 --> 00:39:02,400
ago yeah probably the one that we would

1006
00:38:59,839 --> 00:39:04,839
have been talking more was the metaverse

1007
00:39:02,400 --> 00:39:08,920
none of those two has been mentioned at

1008
00:39:04,839 --> 00:39:12,760
least once today so what's the future of

1009
00:39:08,920 --> 00:39:15,480
blockchain and metaverse from your

1010
00:39:12,760 --> 00:39:18,520
view ah I'm reading I'm reading the book

1011
00:39:15,480 --> 00:39:20,079
about Sam bman freed right now that I

1012
00:39:18,520 --> 00:39:24,200
highly recommend very interesting he's

1013
00:39:20,079 --> 00:39:26,560
also an MIT grage but uh what are your

1014
00:39:24,200 --> 00:39:28,880
thoughts on on blockchain Andor

1015
00:39:26,560 --> 00:39:31,359
metaverse I I think the reason you don't

1016
00:39:28,880 --> 00:39:33,560
hear about it is because it's already

1017
00:39:31,359 --> 00:39:36,240
ingrained and incorporated into what we

1018
00:39:33,560 --> 00:39:38,839
do and that's goes back to the rate of

1019
00:39:36,240 --> 00:39:41,599
change and what we were talking about

1020
00:39:38,839 --> 00:39:43,599
earlier about there's so much change and

1021
00:39:41,599 --> 00:39:46,800
it's coming at such a rapid pace and

1022
00:39:43,599 --> 00:39:49,400
even faster you talk blockchain

1023
00:39:46,800 --> 00:39:52,079
underpins Financial transactions at

1024
00:39:49,400 --> 00:39:55,000
every stage now it's a large part of

1025
00:39:52,079 --> 00:39:56,960
supply chain uh nobody's excited about

1026
00:39:55,000 --> 00:39:58,079
it anymore now it's about how do I use

1027
00:39:56,960 --> 00:40:00,560
AI

1028
00:39:58,079 --> 00:40:03,280
to predict where my next supply chain

1029
00:40:00,560 --> 00:40:06,440
Log Jam is going to be or how the

1030
00:40:03,280 --> 00:40:08,599
Straits are horuse or XYZ is going to

1031
00:40:06,440 --> 00:40:10,839
affect it and you know as for the

1032
00:40:08,599 --> 00:40:13,880
metaverse that's something my kids play

1033
00:40:10,839 --> 00:40:15,400
in not me so I can really can't speak

1034
00:40:13,880 --> 00:40:18,160
much to that but I think it's because

1035
00:40:15,400 --> 00:40:22,920
it's ubiquitous now it it is just part

1036
00:40:18,160 --> 00:40:25,599
of doing uh work in today's

1037
00:40:22,920 --> 00:40:28,560
world I was going to change your

1038
00:40:25,599 --> 00:40:31,520
question no

1039
00:40:28,560 --> 00:40:33,040
uh actually uh I don't have a comment on

1040
00:40:31,520 --> 00:40:34,839
an additional comment on blockchain or

1041
00:40:33,040 --> 00:40:37,119
metaverse but we're also not talking

1042
00:40:34,839 --> 00:40:38,480
about Quantum and I think Quantum is the

1043
00:40:37,119 --> 00:40:40,240
next thing we're going to talk about a

1044
00:40:38,480 --> 00:40:43,079
few years from now because right now

1045
00:40:40,240 --> 00:40:45,040
we're getting our arms around AI um but

1046
00:40:43,079 --> 00:40:47,040
we're at MIT at least in our group we're

1047
00:40:45,040 --> 00:40:48,640
also looking at Quantum and we're saying

1048
00:40:47,040 --> 00:40:49,920
you know AI is here today and here's all

1049
00:40:48,640 --> 00:40:51,920
the risk and here's how we're seeing it

1050
00:40:49,920 --> 00:40:53,680
used for cyber and there's all sorts of

1051
00:40:51,920 --> 00:40:55,760
applications and there's news technology

1052
00:40:53,680 --> 00:40:57,960
implications and Brian's not wrong it's

1053
00:40:55,760 --> 00:41:01,440
not all about gen AI there are all sorts

1054
00:40:57,960 --> 00:41:03,400
of new AI tools and old AI tools but I

1055
00:41:01,440 --> 00:41:05,160
think the next one for cyber for the

1056
00:41:03,400 --> 00:41:07,280
cyber world the threats and the get our

1057
00:41:05,160 --> 00:41:08,920
arms around is quantum and if you

1058
00:41:07,280 --> 00:41:11,319
haven't even looked into Quantum you

1059
00:41:08,920 --> 00:41:13,640
should uh it's not here today it's not

1060
00:41:11,319 --> 00:41:16,000
ready for prime time it is here but it's

1061
00:41:13,640 --> 00:41:17,160
not ready for prime time but I think in

1062
00:41:16,000 --> 00:41:20,839
five years that's what we're going to be

1063
00:41:17,160 --> 00:41:23,599
talking about we have a whole segment on

1064
00:41:20,839 --> 00:41:25,359
on Quantum and basically what are the

1065
00:41:23,599 --> 00:41:26,800
basics that you need to understand just

1066
00:41:25,359 --> 00:41:28,560
like the gentleman here was talking

1067
00:41:26,800 --> 00:41:30,359
about that he had has the whole

1068
00:41:28,560 --> 00:41:33,040
organization doing what are the basics

1069
00:41:30,359 --> 00:41:36,119
around generative Ai and AI we have that

1070
00:41:33,040 --> 00:41:38,000
on 17 different topics and quantum's a

1071
00:41:36,119 --> 00:41:40,560
real popular one because that's what

1072
00:41:38,000 --> 00:41:42,560
people need to understand the key things

1073
00:41:40,560 --> 00:41:44,640
yeah and maybe we're not talking about

1074
00:41:42,560 --> 00:41:47,280
blockchain metaverse in the same way as

1075
00:41:44,640 --> 00:41:49,000
we are AI because when you were talking

1076
00:41:47,280 --> 00:41:51,680
about them two or three years ago you

1077
00:41:49,000 --> 00:41:54,240
didn't talk about them taking over the

1078
00:41:51,680 --> 00:41:56,200
world or making us irrelevant I think

1079
00:41:54,240 --> 00:41:58,680
there's also part of what Brian was

1080
00:41:56,200 --> 00:42:01,200
talking about the the lingo that comes

1081
00:41:58,680 --> 00:42:05,200
out uh the buzzword Bingo that gets

1082
00:42:01,200 --> 00:42:08,119
played as these things roll out it AI is

1083
00:42:05,200 --> 00:42:10,000
been much scarier if if you just sit

1084
00:42:08,119 --> 00:42:12,119
back and read it and you're not

1085
00:42:10,000 --> 00:42:14,800
technologically oriented than blockchain

1086
00:42:12,119 --> 00:42:16,960
or metaverse ever were I think maybe

1087
00:42:14,800 --> 00:42:19,119
that's also another angle to view it

1088
00:42:16,960 --> 00:42:20,880
from and maybe a different take on on

1089
00:42:19,119 --> 00:42:24,520
your comment there I I'll speak to upw

1090
00:42:20,880 --> 00:42:26,480
and gas broadly um I mean I think my

1091
00:42:24,520 --> 00:42:28,640
view on this is those two technologies

1092
00:42:26,480 --> 00:42:30,559
are sort of solution looking for a

1093
00:42:28,640 --> 00:42:32,160
problem maybe in oil and gas and I mean

1094
00:42:30,559 --> 00:42:33,520
there's some scenarios around smart

1095
00:42:32,160 --> 00:42:34,920
contracts I think some companies will

1096
00:42:33,520 --> 00:42:37,280
try to make it work and it's really gone

1097
00:42:34,920 --> 00:42:39,160
nowhere from what I can tell uh and in

1098
00:42:37,280 --> 00:42:41,000
metaverse I mean we've worked with a

1099
00:42:39,160 --> 00:42:42,800
number of companies trying to sort of

1100
00:42:41,000 --> 00:42:45,280
create immersive environments to look at

1101
00:42:42,800 --> 00:42:47,640
well trajectories and things I mean it's

1102
00:42:45,280 --> 00:42:49,160
like my kids sort of VR device cool but

1103
00:42:47,640 --> 00:42:51,280
uh we get back to our desktop computer

1104
00:42:49,160 --> 00:42:53,760
and go back to work every day so it

1105
00:42:51,280 --> 00:42:55,440
feels it's cool Tech I just don't think

1106
00:42:53,760 --> 00:42:56,920
I think it hasn't solved a real problem

1107
00:42:55,440 --> 00:42:58,880
for us yet at least in in the oil and

1108
00:42:56,920 --> 00:43:01,680
gas space that I can see well but isn't

1109
00:42:58,880 --> 00:43:06,359
that right so I mean thinking about like

1110
00:43:01,680 --> 00:43:09,800
meterse um in 2010 we called it second

1111
00:43:06,359 --> 00:43:13,400
second life so and then VR goggles have

1112
00:43:09,800 --> 00:43:14,920
been around for 30 years yeah so we've

1113
00:43:13,400 --> 00:43:16,839
had these things and they I feel like

1114
00:43:14,920 --> 00:43:20,319
they have a hype cycle and then you know

1115
00:43:16,839 --> 00:43:25,000
someone tries to make it big but so in

1116
00:43:20,319 --> 00:43:26,960
200 what 21 we were using gpt3 and I

1117
00:43:25,000 --> 00:43:29,480
would go on stage and talk to people

1118
00:43:26,960 --> 00:43:31,119
about about we're using gpt3 and

1119
00:43:29,480 --> 00:43:34,400
everyone would look at me and blink and

1120
00:43:31,119 --> 00:43:37,760
say oh that's nice MIT person and then

1121
00:43:34,400 --> 00:43:39,760
in you know and then chat gbt came out

1122
00:43:37,760 --> 00:43:41,559
and then everyone understood what it was

1123
00:43:39,760 --> 00:43:44,680
so it's sort of like something has to

1124
00:43:41,559 --> 00:43:48,160
hit that massive inflection point where

1125
00:43:44,680 --> 00:43:50,720
Mark Zuckerberg tried to do it with meta

1126
00:43:48,160 --> 00:43:53,800
Chang the name of the company but it was

1127
00:43:50,720 --> 00:43:56,400
exactly that it was still trying it's a

1128
00:43:53,800 --> 00:43:58,520
technology looking to solve a problem

1129
00:43:56,400 --> 00:44:01,200
and it was just sort of gaming still you

1130
00:43:58,520 --> 00:44:05,240
could almost look at digital twin yes as

1131
00:44:01,200 --> 00:44:06,319
a a a smaller version of metaverse

1132
00:44:05,240 --> 00:44:09,079
because what you're doing is you're

1133
00:44:06,319 --> 00:44:10,760
digitizing something that's physical

1134
00:44:09,079 --> 00:44:13,839
same idea and then you're manipulating

1135
00:44:10,760 --> 00:44:15,680
it in a digital space to see what the uh

1136
00:44:13,839 --> 00:44:17,960
impacts could be what the changes might

1137
00:44:15,680 --> 00:44:20,079
be uh and then potentially going back

1138
00:44:17,960 --> 00:44:22,240
over to the physical side to make a

1139
00:44:20,079 --> 00:44:24,240
non-digital twin back out of it but so

1140
00:44:22,240 --> 00:44:26,160
it's almost like that concept is still

1141
00:44:24,240 --> 00:44:27,680
around it's just kind of morphed into

1142
00:44:26,160 --> 00:44:29,760
something a little different maybe a

1143
00:44:27,680 --> 00:44:33,280
little more useful in the in the

1144
00:44:29,760 --> 00:44:36,839
operation space I think you hit on the

1145
00:44:33,280 --> 00:44:40,400
key part of it is if it doesn't help the

1146
00:44:36,839 --> 00:44:45,240
person do their job more efficiently or

1147
00:44:40,400 --> 00:44:47,319
save the organization cost it it it'll

1148
00:44:45,240 --> 00:44:50,160
no matter how much you push it from on

1149
00:44:47,319 --> 00:44:51,720
top it'll go away well I think there's a

1150
00:44:50,160 --> 00:44:53,599
piece if it's a competitive advantage

1151
00:44:51,720 --> 00:44:55,319
and I think that's where Meta Meta was

1152
00:44:53,599 --> 00:44:57,240
going in the first place yeah you know

1153
00:44:55,319 --> 00:44:59,079
you can make money on the metaverse you

1154
00:44:57,240 --> 00:45:00,359
can set up shops you can do all these

1155
00:44:59,079 --> 00:45:03,000
other I mean I don't think we ever found

1156
00:45:00,359 --> 00:45:04,559
a solution But Eric and I can't I think

1157
00:45:03,000 --> 00:45:07,839
is what we're trying to say from an

1158
00:45:04,559 --> 00:45:10,640
operational standpoint physical world

1159
00:45:07,839 --> 00:45:12,400
where you're cracking molecules or

1160
00:45:10,640 --> 00:45:14,680
you're doing things that you know 20

1161
00:45:12,400 --> 00:45:18,240
years ago only a guy up in the Woodlands

1162
00:45:14,680 --> 00:45:21,640
thought we were going to do um it's

1163
00:45:18,240 --> 00:45:23,839
where the conceptual academic meets the

1164
00:45:21,640 --> 00:45:27,599
real world and all all I'm just trying

1165
00:45:23,839 --> 00:45:30,520
to say is it's a harsh reality and you

1166
00:45:27,599 --> 00:45:33,079
can get opportunities to let it to work

1167
00:45:30,520 --> 00:45:35,119
it but even the companies with the

1168
00:45:33,079 --> 00:45:37,280
deepest Pockets aren't going to let it

1169
00:45:35,119 --> 00:45:41,359
go more than one or two years without

1170
00:45:37,280 --> 00:45:42,839
being able to see the the benefit and

1171
00:45:41,359 --> 00:45:44,920
that's where I think really for me if

1172
00:45:42,839 --> 00:45:48,800
you could get AI to help you get through

1173
00:45:44,920 --> 00:45:51,160
the trls faster with some confidence

1174
00:45:48,800 --> 00:45:53,000
then we'd really be talking about

1175
00:45:51,160 --> 00:45:56,760
differentiators of where we can help

1176
00:45:53,000 --> 00:45:57,800
societies and get more things done uh

1177
00:45:56,760 --> 00:45:59,800
back

1178
00:45:57,800 --> 00:46:02,079
yeah I I don't disagree with the the

1179
00:45:59,800 --> 00:46:04,040
application of AI I was just saying that

1180
00:46:02,079 --> 00:46:06,200
part of the and maybe it doesn't apply

1181
00:46:04,040 --> 00:46:08,319
in your particular industry but the

1182
00:46:06,200 --> 00:46:10,000
promise was basically the same thing as

1183
00:46:08,319 --> 00:46:11,160
digital twin you make something digital

1184
00:46:10,000 --> 00:46:14,160
and then you can manipulate it

1185
00:46:11,160 --> 00:46:16,559
differently and and test out things it's

1186
00:46:14,160 --> 00:46:18,720
the old you know testing and beta

1187
00:46:16,559 --> 00:46:20,160
testing without actually building and

1188
00:46:18,720 --> 00:46:21,640
that was where I thought the promise of

1189
00:46:20,160 --> 00:46:23,160
metaverse was but it never really

1190
00:46:21,640 --> 00:46:24,599
materialized it maybe because it was too

1191
00:46:23,160 --> 00:46:28,480
hard to do it the tools just weren't

1192
00:46:24,599 --> 00:46:30,800
there to make it easy like ja chat G

1193
00:46:28,480 --> 00:46:34,040
BT

1194
00:46:30,800 --> 00:46:34,040
yeah yeah

1195
00:46:34,960 --> 00:46:41,520
yeah yeah training people to do what the

1196
00:46:39,839 --> 00:46:43,520
training yeah so that's an environment

1197
00:46:41,520 --> 00:46:45,680
where the simulation is really we saw

1198
00:46:43,520 --> 00:46:47,880
the same thing with was that airplane

1199
00:46:45,680 --> 00:46:49,160
you know thing we all saw back in 30

1200
00:46:47,880 --> 00:46:53,880
years ago where people learned how to

1201
00:46:49,160 --> 00:46:53,880
fly airplanes with a simulation

1202
00:46:59,400 --> 00:47:03,920
oh that'll be interesting to watch yes

1203
00:47:01,480 --> 00:47:07,599
question over here so I I did want to

1204
00:47:03,920 --> 00:47:10,920
ask a soft tissue question around trust

1205
00:47:07,599 --> 00:47:12,160
particularly around um cyber resilience

1206
00:47:10,920 --> 00:47:13,839
um we've been talking a lot about the

1207
00:47:12,160 --> 00:47:16,559
human in the loop but I talk about the

1208
00:47:13,839 --> 00:47:20,520
machine in the loop now and what happens

1209
00:47:16,559 --> 00:47:23,160
if a machine does make a mistake does

1210
00:47:20,520 --> 00:47:26,599
create a cyber incident how do we start

1211
00:47:23,160 --> 00:47:28,880
rebuilding trust ah good question for

1212
00:47:26,599 --> 00:47:31,119
those who are interfacing for the humans

1213
00:47:28,880 --> 00:47:33,480
in the loop with the machine how do you

1214
00:47:31,119 --> 00:47:35,680
start rebuilding trust how do you start

1215
00:47:33,480 --> 00:47:37,240
recovering from it how does the

1216
00:47:35,680 --> 00:47:40,040
communication plan that you talked about

1217
00:47:37,240 --> 00:47:42,400
does it have an aspect of that it is

1218
00:47:40,040 --> 00:47:44,880
things things like that that keep people

1219
00:47:42,400 --> 00:47:48,040
concerned I'm I'm I didn't I didn't pay

1220
00:47:44,880 --> 00:47:50,079
you to say that right so um two weeks

1221
00:47:48,040 --> 00:47:51,800
ago I was fortunate enough to be invited

1222
00:47:50,079 --> 00:47:53,720
to the world economic Forum cyber

1223
00:47:51,800 --> 00:47:56,280
security meeting and they asked me to

1224
00:47:53,720 --> 00:47:58,760
chair a session on building trust post

1225
00:47:56,280 --> 00:48:00,280
incident so I happen to know a few

1226
00:47:58,760 --> 00:48:02,079
things about that right now in addition

1227
00:48:00,280 --> 00:48:04,079
I'm working on a paper right now with

1228
00:48:02,079 --> 00:48:06,160
one of our companies one of our cons

1229
00:48:04,079 --> 00:48:08,960
Consortium companies about the same

1230
00:48:06,160 --> 00:48:11,839
thing so the angle we're looking at is

1231
00:48:08,960 --> 00:48:13,599
building trust post incident so and the

1232
00:48:11,839 --> 00:48:15,559
question is how do you rebuild trust and

1233
00:48:13,599 --> 00:48:18,040
right now the the research we're looking

1234
00:48:15,559 --> 00:48:19,480
at is build trust with your customers

1235
00:48:18,040 --> 00:48:21,680
and with your employees so it's a

1236
00:48:19,480 --> 00:48:23,200
broader stakeholder question but my

1237
00:48:21,680 --> 00:48:24,640
research has really been been on

1238
00:48:23,200 --> 00:48:26,599
customers and what we're what we're

1239
00:48:24,640 --> 00:48:28,520
seeing of course I'm a you probably got

1240
00:48:26,599 --> 00:48:30,280
this already I'm a behavioralist person

1241
00:48:28,520 --> 00:48:32,079
I look at the people's side and what

1242
00:48:30,280 --> 00:48:35,119
we're seeing are mechanisms companies

1243
00:48:32,079 --> 00:48:37,760
have been putting in place uh to rebuild

1244
00:48:35,119 --> 00:48:41,640
trust things like Chief trust officer

1245
00:48:37,760 --> 00:48:44,960
things like um uh trust uh advisory

1246
00:48:41,640 --> 00:48:46,720
boards things like um the same kind of

1247
00:48:44,960 --> 00:48:49,240
thing we talked about with building

1248
00:48:46,720 --> 00:48:50,920
resilience in your process doing that

1249
00:48:49,240 --> 00:48:53,280
ahead of time if you've identified that

1250
00:48:50,920 --> 00:48:54,640
Trust might be an issue post incident

1251
00:48:53,280 --> 00:48:56,400
you should be starting now to build

1252
00:48:54,640 --> 00:48:57,760
those trust mechanisms so if there's an

1253
00:48:56,400 --> 00:48:59,680
incident you've already got the

1254
00:48:57,760 --> 00:49:01,119
groundwork for the trust it's a little

1255
00:48:59,680 --> 00:49:02,920
hard to come back after an incident and

1256
00:49:01,119 --> 00:49:04,680
say oh sorry now we want to build trust

1257
00:49:02,920 --> 00:49:06,359
with you it's a little bit better if you

1258
00:49:04,680 --> 00:49:08,160
start up front and say you know we're

1259
00:49:06,359 --> 00:49:10,599
trying to build resilience we all know

1260
00:49:08,160 --> 00:49:12,200
that cyber attacks can come we know that

1261
00:49:10,599 --> 00:49:14,000
the Cyber vulnerabilities are out there

1262
00:49:12,200 --> 00:49:15,440
we're doing the best we can we know

1263
00:49:14,000 --> 00:49:17,680
you're doing the best you can and let's

1264
00:49:15,440 --> 00:49:19,720
build some trust mechanisms now so that

1265
00:49:17,680 --> 00:49:22,079
we're transparent transparent is a big

1266
00:49:19,720 --> 00:49:23,680
word in trust and we're um we're

1267
00:49:22,079 --> 00:49:25,760
building those mechanisms for those

1268
00:49:23,680 --> 00:49:27,760
conversations and so if and when

1269
00:49:25,760 --> 00:49:30,000
something happens we have those

1270
00:49:27,760 --> 00:49:33,359
processes and we have those guide rails

1271
00:49:30,000 --> 00:49:35,040
in place to recover the trust or maybe

1272
00:49:33,359 --> 00:49:36,640
it doesn't even erode if you've built

1273
00:49:35,040 --> 00:49:38,480
those mechanisms in place before an

1274
00:49:36,640 --> 00:49:39,680
incident after an incident a little bit

1275
00:49:38,480 --> 00:49:41,960
harder to do but that's what we're

1276
00:49:39,680 --> 00:49:41,960
looking

1277
00:49:43,760 --> 00:49:50,240
at um uh I I have a question and um

1278
00:49:48,319 --> 00:49:52,839
actually um this thing whole thing about

1279
00:49:50,240 --> 00:49:55,359
the metaverse right so iq3 connect I

1280
00:49:52,839 --> 00:49:56,799
mean we're I wouldn't call our solution

1281
00:49:55,359 --> 00:49:59,839
metaverse but we've been through the

1282
00:49:56,799 --> 00:50:02,799
that and we've been U working with

1283
00:49:59,839 --> 00:50:06,359
industrial companies that have

1284
00:50:02,799 --> 00:50:08,319
tried and spent millions of dollars and

1285
00:50:06,359 --> 00:50:10,920
there are so many carcasses lying around

1286
00:50:08,319 --> 00:50:12,520
because they do a pilot and it fails uh

1287
00:50:10,920 --> 00:50:15,520
and nobody's been able to scale this

1288
00:50:12,520 --> 00:50:17,559
technology or the metaverse or these 3D

1289
00:50:15,520 --> 00:50:19,760
environments uh to a level where it

1290
00:50:17,559 --> 00:50:21,480
starts delivering you know real uh

1291
00:50:19,760 --> 00:50:23,319
business value and I wanted to ask if

1292
00:50:21,480 --> 00:50:25,680
that's I think I came late to this

1293
00:50:23,319 --> 00:50:27,400
conversation but is is that kind of what

1294
00:50:25,680 --> 00:50:29,119
you are seeing

1295
00:50:27,400 --> 00:50:32,079
at maybe halberton has played around

1296
00:50:29,119 --> 00:50:33,799
with this technology or I know Technip

1297
00:50:32,079 --> 00:50:36,960
uh because we worked in the we have

1298
00:50:33,799 --> 00:50:39,960
customers in the oil and gas space as

1299
00:50:36,960 --> 00:50:41,480
well yeah I think that's it I mean and

1300
00:50:39,960 --> 00:50:43,559
yeah I think there's some training on

1301
00:50:41,480 --> 00:50:44,640
drilling so there it is being used in

1302
00:50:43,559 --> 00:50:46,880
Pockets I shouldn't say it's not being

1303
00:50:44,640 --> 00:50:49,680
used but is it transformed to Industry

1304
00:50:46,880 --> 00:50:51,040
by no means I mean maybe if you break it

1305
00:50:49,680 --> 00:50:53,119
down if I break it down mentally why is

1306
00:50:51,040 --> 00:50:55,359
it not worked out maybe it's the cost to

1307
00:50:53,119 --> 00:50:57,440
build these things is so high yes and

1308
00:50:55,359 --> 00:50:59,559
the value is

1309
00:50:57,440 --> 00:51:00,480
not barely there it just doesn't make

1310
00:50:59,559 --> 00:51:01,520
sense to do it from a business

1311
00:51:00,480 --> 00:51:02,799
standpoint so I think that's why it

1312
00:51:01,520 --> 00:51:04,200
hasn't scaled honestly I don't think

1313
00:51:02,799 --> 00:51:05,920
that it's useless by any means but I

1314
00:51:04,200 --> 00:51:07,960
think it's really I mean so if you can

1315
00:51:05,920 --> 00:51:09,640
make it really cheap to build it's free

1316
00:51:07,960 --> 00:51:11,240
we probably use it because it's it is

1317
00:51:09,640 --> 00:51:13,440
adding some value but it's not big

1318
00:51:11,240 --> 00:51:14,480
enough to Warrant the investment yes I

1319
00:51:13,440 --> 00:51:15,440
mean that's just an observation I think

1320
00:51:14,480 --> 00:51:16,799
that's probably the reason it hasn't

1321
00:51:15,440 --> 00:51:18,480
taken off yeah I mean there's just too

1322
00:51:16,799 --> 00:51:20,720
many friction points the hardware is

1323
00:51:18,480 --> 00:51:22,280
very expensive you know you you put it

1324
00:51:20,720 --> 00:51:23,920
out in the on the manufacturing floor it

1325
00:51:22,280 --> 00:51:26,920
breaks and people just throw it aside

1326
00:51:23,920 --> 00:51:28,599
nobody has a patience to you know say uh

1327
00:51:26,920 --> 00:51:29,760
you know and and Microsoft has pushed

1328
00:51:28,599 --> 00:51:32,359
this very hard and you know they've

1329
00:51:29,760 --> 00:51:34,200
moved away like Hollow lens and all

1330
00:51:32,359 --> 00:51:37,240
these big Investments are just complete

1331
00:51:34,200 --> 00:51:38,680
failures but I I think the so I'll and

1332
00:51:37,240 --> 00:51:41,319
there's a question over here that wants

1333
00:51:38,680 --> 00:51:44,880
to bounce on what Eric said but what I

1334
00:51:41,319 --> 00:51:47,720
would say look at Technique we take 1%

1335
00:51:44,880 --> 00:51:51,200
of our profit and we bake it back into

1336
00:51:47,720 --> 00:51:53,000
R&D every year that's pretty phenomenal

1337
00:51:51,200 --> 00:51:55,839
for what is really at the end of the day

1338
00:51:53,000 --> 00:51:59,920
a company that does technology products

1339
00:51:55,839 --> 00:52:01,880
and services is an EPC project delivery

1340
00:51:59,920 --> 00:52:04,839
um I don't know of anyone else that does

1341
00:52:01,880 --> 00:52:07,599
it at that level now you have to choose

1342
00:52:04,839 --> 00:52:10,160
where you're going to put that amount of

1343
00:52:07,599 --> 00:52:12,680
money now if I'm a company that's

1344
00:52:10,160 --> 00:52:15,520
working in trying to pull through

1345
00:52:12,680 --> 00:52:18,200
technologies that deliver a product or a

1346
00:52:15,520 --> 00:52:21,440
service to a customer I'm probably going

1347
00:52:18,200 --> 00:52:23,280
to do that or I'm doing that today in

1348
00:52:21,440 --> 00:52:25,520
the space where I can take somebody to a

1349
00:52:23,280 --> 00:52:28,559
lab and I can show them the next

1350
00:52:25,520 --> 00:52:31,760
hydrogen or the next ammonia or some way

1351
00:52:28,559 --> 00:52:34,799
to do it get more with less energy

1352
00:52:31,760 --> 00:52:37,880
versus the metaverse which there's a ton

1353
00:52:34,799 --> 00:52:40,359
of other folks out there mining or

1354
00:52:37,880 --> 00:52:43,160
pioneering in that space and I'll stick

1355
00:52:40,359 --> 00:52:45,520
to what at the end of the day underpins

1356
00:52:43,160 --> 00:52:49,079
the two areas that I'm able to create

1357
00:52:45,520 --> 00:52:51,640
value internally and externally I think

1358
00:52:49,079 --> 00:52:54,240
that's ultimately the challenge uh

1359
00:52:51,640 --> 00:52:56,119
around it and we also hype it up a lot

1360
00:52:54,240 --> 00:52:58,599
it gets hyped up that it's going to have

1361
00:52:56,119 --> 00:53:01,440
this big cycle and you said it was you

1362
00:52:58,599 --> 00:53:04,000
know 2016 you were talking about X and

1363
00:53:01,440 --> 00:53:05,960
today we're talking about it you know 8

1364
00:53:04,000 --> 00:53:08,640
years later I think that's the other

1365
00:53:05,960 --> 00:53:11,200
part we're humans and our flash to bang

1366
00:53:08,640 --> 00:53:13,480
is near instantaneous you know we're not

1367
00:53:11,200 --> 00:53:16,240
looking at this over uh long

1368
00:53:13,480 --> 00:53:17,799
generational periods and and that's

1369
00:53:16,240 --> 00:53:20,040
really at the end of the day what

1370
00:53:17,799 --> 00:53:23,160
organizations are doing whether you call

1371
00:53:20,040 --> 00:53:25,960
it R&D or digitization we're all working

1372
00:53:23,160 --> 00:53:27,960
in the same space trying to find a more

1373
00:53:25,960 --> 00:53:30,400
efficient way of

1374
00:53:27,960 --> 00:53:32,799
delivering okay I mean um I'd love to

1375
00:53:30,400 --> 00:53:35,400
talk some more after with the yeah if

1376
00:53:32,799 --> 00:53:37,599
you're buying the beer for Eric I'm

1377
00:53:35,400 --> 00:53:40,280
there I think we had one question over

1378
00:53:37,599 --> 00:53:44,559
here so so continue on the same theme of

1379
00:53:40,280 --> 00:53:46,520
um metaverse style environments the one

1380
00:53:44,559 --> 00:53:49,160
really sound application area that I've

1381
00:53:46,520 --> 00:53:51,760
seen in in an industrial environment is

1382
00:53:49,160 --> 00:53:53,000
safety so safety training it's it's a

1383
00:53:51,760 --> 00:53:54,799
bit bit of the same problem as with

1384
00:53:53,000 --> 00:53:56,000
cyber security which is there's annual

1385
00:53:54,799 --> 00:53:58,400
training and there's books and there's

1386
00:53:56,000 --> 00:54:00,720
exams and people pass all the exams but

1387
00:53:58,400 --> 00:54:02,839
in an actual incident they don't behave

1388
00:54:00,720 --> 00:54:05,359
the way uh that they did when they

1389
00:54:02,839 --> 00:54:07,839
passed all the exams and trainings and

1390
00:54:05,359 --> 00:54:09,280
in practice the only way to in the real

1391
00:54:07,839 --> 00:54:11,240
world the only way you know that someone

1392
00:54:09,280 --> 00:54:13,599
actually has internalized information is

1393
00:54:11,240 --> 00:54:15,400
how they function in actual disaster the

1394
00:54:13,599 --> 00:54:17,920
problem is we cannot create actual

1395
00:54:15,400 --> 00:54:19,920
disasters to figure that out so in a in

1396
00:54:17,920 --> 00:54:22,240
a metaverse environment you can sort of

1397
00:54:19,920 --> 00:54:23,799
say okay there's you hear a fire alarm

1398
00:54:22,240 --> 00:54:26,599
go off are you following the prescribed

1399
00:54:23,799 --> 00:54:29,160
routes now a staircase collapses do what

1400
00:54:26,599 --> 00:54:30,880
the fall back plan is in real time you

1401
00:54:29,160 --> 00:54:32,880
don't have the time to think and reflect

1402
00:54:30,880 --> 00:54:34,559
you know your fire blocks your Escape

1403
00:54:32,880 --> 00:54:36,880
Route do you know what your alternate

1404
00:54:34,559 --> 00:54:38,760
course of action is so these things are

1405
00:54:36,880 --> 00:54:40,720
absolutely infeasible to create in the

1406
00:54:38,760 --> 00:54:45,119
real world you know short of blowing up

1407
00:54:40,720 --> 00:54:47,240
a plant to do it so it it is it is

1408
00:54:45,119 --> 00:54:50,000
obviously it's a fringe application but

1409
00:54:47,240 --> 00:54:52,160
in that Fringe space it has tremendous

1410
00:54:50,000 --> 00:54:53,760
value the in the environment I looked at

1411
00:54:52,160 --> 00:54:55,559
which was very very

1412
00:54:53,760 --> 00:54:57,559
dangerous the problem is it's very

1413
00:54:55,559 --> 00:54:59,440
dangerous and kind of like the I worked

1414
00:54:57,559 --> 00:55:02,480
on the BP Monda incident the problem is

1415
00:54:59,440 --> 00:55:04,319
they happen once in 50 years uh so no

1416
00:55:02,480 --> 00:55:05,040
one has actual real world experience of

1417
00:55:04,319 --> 00:55:08,160
it

1418
00:55:05,040 --> 00:55:10,480
nobody and but but when it happens that

1419
00:55:08,160 --> 00:55:13,520
instant decision making in real time is

1420
00:55:10,480 --> 00:55:16,760
critical so that's but I think Carrie

1421
00:55:13,520 --> 00:55:20,040
talked about that you know it's uh you

1422
00:55:16,760 --> 00:55:21,760
know there's there's a lot of tools to

1423
00:55:20,040 --> 00:55:24,319
do it whether you're talking about trust

1424
00:55:21,760 --> 00:55:26,880
or transparency Etc you have to walk the

1425
00:55:24,319 --> 00:55:28,599
walk every day you're when your people

1426
00:55:26,880 --> 00:55:31,559
ask you hard questions you got to give

1427
00:55:28,599 --> 00:55:33,039
them the hard answers and and build that

1428
00:55:31,559 --> 00:55:36,000
level of trust and then there's

1429
00:55:33,039 --> 00:55:38,319
tabletops exercises there scenarios

1430
00:55:36,000 --> 00:55:41,520
those things I think apply we're not

1431
00:55:38,319 --> 00:55:44,000
arguing or stating that there's not an

1432
00:55:41,520 --> 00:55:46,760
application what we're what

1433
00:55:44,000 --> 00:55:48,319
we're trying at least I'll speak for Rob

1434
00:55:46,760 --> 00:55:51,119
Scott not for anyone else what I'm

1435
00:55:48,319 --> 00:55:54,440
trying to say is those applications to

1436
00:55:51,119 --> 00:55:56,760
deliver large value either internally or

1437
00:55:54,440 --> 00:55:57,559
externally are difficult to find with

1438
00:55:56,760 --> 00:56:01,839
the

1439
00:55:57,559 --> 00:56:04,160
metaverse and and and the hype around it

1440
00:56:01,839 --> 00:56:06,760
uh has put it in in where people are

1441
00:56:04,160 --> 00:56:09,559
skeptical and they're now there's other

1442
00:56:06,760 --> 00:56:11,160
things that could help us deliver uh

1443
00:56:09,559 --> 00:56:15,839
safer more

1444
00:56:11,160 --> 00:56:18,440
efficiently uh with less carbon Etc than

1445
00:56:15,839 --> 00:56:20,039
than those that's what we're what I'm

1446
00:56:18,440 --> 00:56:23,640
trying to say and that's where we're

1447
00:56:20,039 --> 00:56:25,839
investing is around circularity

1448
00:56:23,640 --> 00:56:28,240
sustainability uh that's where we're

1449
00:56:25,839 --> 00:56:30,200
putting Investments today and I I would

1450
00:56:28,240 --> 00:56:34,280
just add one thing I think again back to

1451
00:56:30,200 --> 00:56:36,720
this question about um uh the cost as we

1452
00:56:34,280 --> 00:56:38,520
see Quantum Computing coming in we may

1453
00:56:36,720 --> 00:56:40,680
be revisiting the metaverse it might

1454
00:56:38,520 --> 00:56:42,119
really bring down the cost of computing

1455
00:56:40,680 --> 00:56:45,039
which might really bring down the cost

1456
00:56:42,119 --> 00:56:46,520
of simulations like metaverse so maybe

1457
00:56:45,039 --> 00:56:48,599
we'll start to see when the costs come

1458
00:56:46,520 --> 00:56:50,400
down and the technology advances a

1459
00:56:48,599 --> 00:56:52,000
Resurgence of this question but right

1460
00:56:50,400 --> 00:56:54,480
now it's just not costeffective from

1461
00:56:52,000 --> 00:56:56,720
what I'm hearing for for the major plays

1462
00:56:54,480 --> 00:57:00,760
in the organizations

1463
00:56:56,720 --> 00:57:04,000
back to you yeah well so I think we'll

1464
00:57:00,760 --> 00:57:05,839
do a very fast last question and then

1465
00:57:04,000 --> 00:57:08,160
I'm going to go back to the audience for

1466
00:57:05,839 --> 00:57:10,960
something else

1467
00:57:08,160 --> 00:57:14,640
um Rob let's start with you so we're

1468
00:57:10,960 --> 00:57:16,920
back together in five years sitting uh I

1469
00:57:14,640 --> 00:57:19,599
think maybe I'd like lower comfortable

1470
00:57:16,920 --> 00:57:21,319
chairs and yes this does feel a little

1471
00:57:19,599 --> 00:57:23,799
bit like I'm outside the principal's

1472
00:57:21,319 --> 00:57:28,839
office in grade school not that I was

1473
00:57:23,799 --> 00:57:30,760
ever there just saying okay and uh so I

1474
00:57:28,839 --> 00:57:31,760
I I think I heard loud and clear that

1475
00:57:30,760 --> 00:57:34,440
you don't think we're going to be

1476
00:57:31,760 --> 00:57:36,240
talking about the metaverse um what do

1477
00:57:34,440 --> 00:57:39,559
you hope to be talking

1478
00:57:36,240 --> 00:57:43,559
about I touched on it earlier the the

1479
00:57:39,559 --> 00:57:47,039
use of scalable technology with our

1480
00:57:43,559 --> 00:57:49,920
craft in order to make it uh safer and

1481
00:57:47,039 --> 00:57:52,000
more efficient uh on the work sites

1482
00:57:49,920 --> 00:57:55,559
because those places are extremely

1483
00:57:52,000 --> 00:57:57,720
dangerous um and as people get tired and

1484
00:57:55,559 --> 00:58:00,200
they're exposed to those stresses you

1485
00:57:57,720 --> 00:58:03,119
can start to make suboptimal decisions

1486
00:58:00,200 --> 00:58:06,520
that ultimately will result in a loss of

1487
00:58:03,119 --> 00:58:09,559
life life changing accidents or uh

1488
00:58:06,520 --> 00:58:11,880
catastrophic events around the plant so

1489
00:58:09,559 --> 00:58:14,039
to me what I'd like to be back in five

1490
00:58:11,880 --> 00:58:16,359
years is we've cracked the code on what

1491
00:58:14,039 --> 00:58:19,559
the wearable technology is how we

1492
00:58:16,359 --> 00:58:22,359
leverage cameras and drones in order to

1493
00:58:19,559 --> 00:58:25,240
be more efficient and safer for the

1494
00:58:22,359 --> 00:58:27,200
craft because if we can do that then

1495
00:58:25,240 --> 00:58:29,559
we'll be more more sustainable more

1496
00:58:27,200 --> 00:58:33,839
affordable to me it just starts with the

1497
00:58:29,559 --> 00:58:35,240
folks doing the work super all right and

1498
00:58:33,839 --> 00:58:37,280
maybe I'll play off the question earlier

1499
00:58:35,240 --> 00:58:38,880
from the gentleman so maybe I My Hope Is

1500
00:58:37,280 --> 00:58:40,400
this I hope that gen has played out to

1501
00:58:38,880 --> 00:58:42,559
be everything it's it's cooked up to be

1502
00:58:40,400 --> 00:58:45,160
and isn't another metaverse uh I think

1503
00:58:42,559 --> 00:58:46,480
this happens in in I think there's

1504
00:58:45,160 --> 00:58:47,680
Fringe or I think there's use cases

1505
00:58:46,480 --> 00:58:49,319
where it will work for sort of in

1506
00:58:47,680 --> 00:58:51,079
documents and things like this it it's

1507
00:58:49,319 --> 00:58:52,880
probably going to play out well if you

1508
00:58:51,079 --> 00:58:54,720
fast forward that and may maybe five

1509
00:58:52,880 --> 00:58:56,640
years is May five years is about right

1510
00:58:54,720 --> 00:58:58,400
actually for us to adopt these things if

1511
00:58:56,640 --> 00:59:00,280
you've got thousands of Agents let's

1512
00:58:58,400 --> 00:59:01,559
just call it running your business today

1513
00:59:00,280 --> 00:59:03,000
at least in terms of filling forms out

1514
00:59:01,559 --> 00:59:04,680
and doing documents how do you manage

1515
00:59:03,000 --> 00:59:06,720
this I mean we aren't prepared to manage

1516
00:59:04,680 --> 00:59:07,920
it what are all these people today who

1517
00:59:06,720 --> 00:59:09,880
are actually really skilled Engineers

1518
00:59:07,920 --> 00:59:11,680
that used to design jobs now what are

1519
00:59:09,880 --> 00:59:13,240
they doing I you know I hope we're here

1520
00:59:11,680 --> 00:59:15,000
in five years say seeing that have

1521
00:59:13,240 --> 00:59:16,440
worked and asking those questions on how

1522
00:59:15,000 --> 00:59:17,520
do we manage this stuff at scale and and

1523
00:59:16,440 --> 00:59:19,079
what are these people that we had in

1524
00:59:17,520 --> 00:59:21,960
place doing and now what are they doing

1525
00:59:19,079 --> 00:59:23,240
yeah super how we transitioned that's

1526
00:59:21,960 --> 00:59:25,280
the other yeah yeah I'm assuming you've

1527
00:59:23,240 --> 00:59:27,039
transition yeah how do we pull how we

1528
00:59:25,280 --> 00:59:28,559
did it and lessons learned that we're

1529
00:59:27,039 --> 00:59:29,880
sharing amongst each other and the way

1530
00:59:28,559 --> 00:59:32,200
that we share

1531
00:59:29,880 --> 00:59:34,359
safy I think is going to be critical for

1532
00:59:32,200 --> 00:59:36,520
the work

1533
00:59:34,359 --> 00:59:38,200
yeah okay so what do I think we're going

1534
00:59:36,520 --> 00:59:40,680
to talk about in five years I hope we're

1535
00:59:38,200 --> 00:59:42,599
not talking about cyber security I hope

1536
00:59:40,680 --> 00:59:45,160
we've cracked that nut I hope it's all

1537
00:59:42,599 --> 00:59:47,079
ether for everybody's work I hope it's

1538
00:59:45,160 --> 00:59:49,039
as ubiquitous as safety and all the

1539
00:59:47,079 --> 00:59:51,359
other things that are important and

1540
00:59:49,039 --> 00:59:53,200
Baseline in our organization I hope we

1541
00:59:51,359 --> 00:59:54,880
are talking about strategic Advantage

1542
00:59:53,200 --> 00:59:57,680
from whatever the next technology might

1543
00:59:54,880 --> 01:00:00,760
be whether it's um uh Quantum or the

1544
00:59:57,680 --> 01:00:02,559
next uh applications of AI uh I hope

1545
01:00:00,760 --> 01:00:05,000
we're talking more about how we can do

1546
01:00:02,559 --> 01:00:06,920
things new and different uh and create

1547
01:00:05,000 --> 01:00:08,799
strategic and competitive advantages for

1548
01:00:06,920 --> 01:00:09,799
our companies with whatever the next

1549
01:00:08,799 --> 01:00:13,079
thing

1550
01:00:09,799 --> 01:00:15,720
is awesome all right Applause for the

1551
01:00:13,079 --> 01:00:18,880
panel

1552
01:00:15,720 --> 01:00:18,880
[Applause]


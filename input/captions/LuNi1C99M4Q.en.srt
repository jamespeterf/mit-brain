1
00:00:05,759 --> 00:00:12,000
My name is Jim Flynn. I am a program

2
00:00:08,720 --> 00:00:14,320
director at MIT corporate relations and

3
00:00:12,000 --> 00:00:17,119
I want to welcome you back from lunch.

4
00:00:14,320 --> 00:00:19,680
Uh hopefully everyone is fed and have

5
00:00:17,119 --> 00:00:20,880
enough energy to uh power through this

6
00:00:19,680 --> 00:00:24,720
afternoon.

7
00:00:20,880 --> 00:00:28,160
uh we'll kick off our next session is uh

8
00:00:24,720 --> 00:00:32,160
called chips code and people essentially

9
00:00:28,160 --> 00:00:35,200
AI hardware AI software as well as AI

10
00:00:32,160 --> 00:00:38,559
training. So handling our first segment,

11
00:00:35,200 --> 00:00:41,280
it is my pleasure to introduce Jesus Del

12
00:00:38,559 --> 00:00:44,399
Alamo who is a professor of electrical

13
00:00:41,280 --> 00:00:47,120
engineering and computer science at MIT

14
00:00:44,399 --> 00:00:49,360
and has also in the past served as the

15
00:00:47,120 --> 00:00:52,000
director of the micros systemystems

16
00:00:49,360 --> 00:00:54,840
technology lab at MIT and he will talk

17
00:00:52,000 --> 00:00:57,199
to you about the current state of AI

18
00:00:54,840 --> 00:01:00,199
hardware. Let's give a warm welcome for

19
00:00:57,199 --> 00:01:00,199
Jesus.

20
00:01:02,800 --> 00:01:05,519
Thank you. Good afternoon. Thank you for

21
00:01:04,159 --> 00:01:07,119
inviting me. What an audience. This is

22
00:01:05,519 --> 00:01:09,520
really this is really fantastic. I'm

23
00:01:07,119 --> 00:01:10,880
delighted to be here. So yes, today I

24
00:01:09,520 --> 00:01:12,479
want to share some thoughts about the

25
00:01:10,880 --> 00:01:14,240
future of a hardware. Of course, it's a

26
00:01:12,479 --> 00:01:16,000
it's a it's a very large topic. So I

27
00:01:14,240 --> 00:01:17,799
will only be able to touch on a on a few

28
00:01:16,000 --> 00:01:20,720
on a few

29
00:01:17,799 --> 00:01:23,040
issues. So uh this conference is about

30
00:01:20,720 --> 00:01:24,640
AI and so therefore the four key pillars

31
00:01:23,040 --> 00:01:27,200
of AI are going to be discussed which

32
00:01:24,640 --> 00:01:29,280
are algorithms, data sets, human talent

33
00:01:27,200 --> 00:01:31,600
of course and and hardware. And this

34
00:01:29,280 --> 00:01:34,240
talks this talk is about hardware and

35
00:01:31,600 --> 00:01:36,799
hardware today is being is seen as the

36
00:01:34,240 --> 00:01:38,159
key to enable the long-term progress in

37
00:01:36,799 --> 00:01:40,000
AI that we have seen in the last few

38
00:01:38,159 --> 00:01:41,600
years to continue for years to come

39
00:01:40,000 --> 00:01:45,360
without burning the planet along the

40
00:01:41,600 --> 00:01:47,759
way. In fact, you can see the the uh

41
00:01:45,360 --> 00:01:49,119
importance of AI hardware in this chart.

42
00:01:47,759 --> 00:01:50,159
It's a little bit busy, but let let me

43
00:01:49,119 --> 00:01:52,240
go through it. What this chart

44
00:01:50,159 --> 00:01:54,640
represents in a semi-logarithmic scale

45
00:01:52,240 --> 00:01:56,640
on the y-axis is the computational

46
00:01:54,640 --> 00:01:58,399
performance of the computing the

47
00:01:56,640 --> 00:02:01,040
computers that have been used to train

48
00:01:58,399 --> 00:02:03,600
the various models in the last uh you

49
00:02:01,040 --> 00:02:04,960
know 20 years or so uh as a function of

50
00:02:03,600 --> 00:02:06,399
time. So notice it's a it's a

51
00:02:04,960 --> 00:02:08,000
semi-ogarithmic scale, a logarithmic

52
00:02:06,399 --> 00:02:10,000
scale on the y- axis, a linear scale on

53
00:02:08,000 --> 00:02:11,599
the x axis. And you can see that for the

54
00:02:10,000 --> 00:02:14,480
first few years in this chart up to

55
00:02:11,599 --> 00:02:18,400
about 2012, there was progress that went

56
00:02:14,480 --> 00:02:20,080
about uh 2x doubling of uh twice uh

57
00:02:18,400 --> 00:02:21,840
doubling every two years or so, which is

58
00:02:20,080 --> 00:02:24,640
the rate of progress of mors law.

59
00:02:21,840 --> 00:02:26,640
However, something happened in 2012, an

60
00:02:24,640 --> 00:02:29,200
inflation point that really resulted in

61
00:02:26,640 --> 00:02:30,879
a massive increase in in the progress

62
00:02:29,200 --> 00:02:33,120
that went from doubling every two years

63
00:02:30,879 --> 00:02:36,400
to doubling every two months. Now what

64
00:02:33,120 --> 00:02:38,800
happened there was the advent of the

65
00:02:36,400 --> 00:02:41,280
GPU, the graphical processing unit as

66
00:02:38,800 --> 00:02:45,200
the engine to implement these algorithms

67
00:02:41,280 --> 00:02:47,760
as opposed to CPU standard uh processing

68
00:02:45,200 --> 00:02:51,360
units before that uh that were used uh

69
00:02:47,760 --> 00:02:53,280
in the past and is this new hardware the

70
00:02:51,360 --> 00:02:55,120
GPU and the massive parallelism that it

71
00:02:53,280 --> 00:02:56,879
allows that resulted in this tremendous

72
00:02:55,120 --> 00:02:58,879
improvement in the productivity in the

73
00:02:56,879 --> 00:03:00,879
growth in the computing capabilities

74
00:02:58,879 --> 00:03:03,200
that were used to train these models. So

75
00:03:00,879 --> 00:03:05,360
this is to make the point that a

76
00:03:03,200 --> 00:03:06,800
specialized hardware makes a huge

77
00:03:05,360 --> 00:03:09,200
difference and as a result we should be

78
00:03:06,800 --> 00:03:11,440
thinking into the future of AI hardware

79
00:03:09,200 --> 00:03:13,360
innovating in terms of new hardware to

80
00:03:11,440 --> 00:03:15,599
continue to uh introduce inflation

81
00:03:13,360 --> 00:03:17,120
points of this type. Now you get a

82
00:03:15,599 --> 00:03:19,200
picture of what is going on today in

83
00:03:17,120 --> 00:03:22,319
this chart. It's a little bit busy

84
00:03:19,200 --> 00:03:25,599
again, but this is a chart that uh maps

85
00:03:22,319 --> 00:03:27,599
in this two-dimensional space of peak

86
00:03:25,599 --> 00:03:31,040
performance in giga operations per

87
00:03:27,599 --> 00:03:33,440
second as a function of peak power of

88
00:03:31,040 --> 00:03:35,040
many AI processors and accelerators that

89
00:03:33,440 --> 00:03:36,879
have been demonstrated out there. These

90
00:03:35,040 --> 00:03:39,040
are also logarithmic scale. So they span

91
00:03:36,879 --> 00:03:42,959
many orders of magnitude. On the bottom

92
00:03:39,040 --> 00:03:45,200
left you see small um edge type uh

93
00:03:42,959 --> 00:03:47,040
machines and moving towards the top

94
00:03:45,200 --> 00:03:48,799
right edge you see the very big data

95
00:03:47,040 --> 00:03:50,879
centers with the big engines that are

96
00:03:48,799 --> 00:03:52,159
implementing the large language models

97
00:03:50,879 --> 00:03:54,640
and you can see how there is a very

98
00:03:52,159 --> 00:03:56,480
fundamental trade-off uh between power

99
00:03:54,640 --> 00:03:58,159
and performance. If you want more

100
00:03:56,480 --> 00:04:00,720
performance you really need to be

101
00:03:58,159 --> 00:04:03,519
willing to to uh burn more power. It

102
00:04:00,720 --> 00:04:05,519
seems it seems uh inevitable to do that.

103
00:04:03,519 --> 00:04:07,680
But in fact, if you look in more detail,

104
00:04:05,519 --> 00:04:10,560
you will actually see that there is a

105
00:04:07,680 --> 00:04:13,200
fundamental barrier there that

106
00:04:10,560 --> 00:04:15,599
essentially no demonstration has ever

107
00:04:13,200 --> 00:04:18,400
crossed in terms of this trade-off of

108
00:04:15,599 --> 00:04:21,519
power and u and performance which is

109
00:04:18,400 --> 00:04:23,280
given by 10 terops per watt. And the

110
00:04:21,519 --> 00:04:25,199
reason for that fundamental limit is

111
00:04:23,280 --> 00:04:27,520
because the underlying technology that

112
00:04:25,199 --> 00:04:29,680
is being used in all these accelerators

113
00:04:27,520 --> 00:04:32,400
and processors is the same. It is

114
00:04:29,680 --> 00:04:34,080
conventional SMOS, the mainstream micro

115
00:04:32,400 --> 00:04:36,400
electronics technology which is making

116
00:04:34,080 --> 00:04:38,639
progress along the way but is making

117
00:04:36,400 --> 00:04:41,120
relatively slow progress. And so we are

118
00:04:38,639 --> 00:04:43,080
facing this fundamental limit that we

119
00:04:41,120 --> 00:04:45,440
need to find a way to

120
00:04:43,080 --> 00:04:47,720
cross. And in fact if you look in more

121
00:04:45,440 --> 00:04:50,080
detail you will see that we are in a

122
00:04:47,720 --> 00:04:52,080
trajectory which is start which is

123
00:04:50,080 --> 00:04:54,560
starting to bend over which means that

124
00:04:52,080 --> 00:04:56,479
if you want much more performance as is

125
00:04:54,560 --> 00:04:58,639
desirable for these very large language

126
00:04:56,479 --> 00:05:00,840
models that are being introduced. you

127
00:04:58,639 --> 00:05:04,400
can see that you need to burn a super

128
00:05:00,840 --> 00:05:07,280
linearly more power in order to in order

129
00:05:04,400 --> 00:05:09,120
to enable this. So we are truly in an

130
00:05:07,280 --> 00:05:12,080
unsustainable trajectory that needs to

131
00:05:09,120 --> 00:05:14,000
be corrected right and and so that is

132
00:05:12,080 --> 00:05:17,039
why you have seen how in the last few

133
00:05:14,000 --> 00:05:19,759
months we are hearing uh the major uh

134
00:05:17,039 --> 00:05:21,919
data server companies uh talking about

135
00:05:19,759 --> 00:05:23,840
you know using nuclear energy to to feed

136
00:05:21,919 --> 00:05:25,280
the data centers because the amount of

137
00:05:23,840 --> 00:05:26,560
energy that is going to be required to

138
00:05:25,280 --> 00:05:28,400
implement all these models is really

139
00:05:26,560 --> 00:05:30,560
going to be gigantic. So clearly this is

140
00:05:28,400 --> 00:05:32,800
something that needs some uh some

141
00:05:30,560 --> 00:05:35,199
drastic new approach. We need as

142
00:05:32,800 --> 00:05:37,199
indicated in the red arrow on the on the

143
00:05:35,199 --> 00:05:38,800
top left. We need a new trajectory in

144
00:05:37,199 --> 00:05:40,240
which we can continue to improve the

145
00:05:38,800 --> 00:05:42,960
performance and the capabilities of

146
00:05:40,240 --> 00:05:47,280
computing but to do that at much modest

147
00:05:42,960 --> 00:05:49,120
increases in uh in power. Now Joe Hinton

148
00:05:47,280 --> 00:05:50,960
u has been telling us now for for quite

149
00:05:49,120 --> 00:05:52,880
some time. He he won the Nobel Prize in

150
00:05:50,960 --> 00:05:55,360
physics as you know just last year that

151
00:05:52,880 --> 00:05:58,320
there is a complete new way of doing AI

152
00:05:55,360 --> 00:06:00,320
computation that promises much great

153
00:05:58,320 --> 00:06:02,800
efficient uh increases in the energy

154
00:06:00,320 --> 00:06:05,120
efficiency and that is analog computing.

155
00:06:02,800 --> 00:06:07,560
In fact he says we can use very low

156
00:06:05,120 --> 00:06:10,400
power analog computation. You can have

157
00:06:07,560 --> 00:06:12,880
trillion way parallelism using things

158
00:06:10,400 --> 00:06:15,039
like meristers. This is the kilobytes uh

159
00:06:12,880 --> 00:06:16,720
for the weights. So analog computing

160
00:06:15,039 --> 00:06:18,479
based on this new approach which I'm

161
00:06:16,720 --> 00:06:20,880
going to tell you a little bit about

162
00:06:18,479 --> 00:06:24,319
really promises great enhancements in

163
00:06:20,880 --> 00:06:26,080
energy efficiency in uh in in AI

164
00:06:24,319 --> 00:06:27,759
computation. And in fact in in this

165
00:06:26,080 --> 00:06:30,160
other talk this is a slide from a talk

166
00:06:27,759 --> 00:06:32,280
that he gave in Cambridge uh titled two

167
00:06:30,160 --> 00:06:35,759
paths to intelligence. He actually talks

168
00:06:32,280 --> 00:06:38,080
specifically about the core mathematical

169
00:06:35,759 --> 00:06:40,160
function that underlies uh neural

170
00:06:38,080 --> 00:06:42,960
networks and deep learning which is the

171
00:06:40,160 --> 00:06:45,199
vector uh matrix multiplication. And he

172
00:06:42,960 --> 00:06:47,039
says that if you implement the vector

173
00:06:45,199 --> 00:06:49,680
matrix multiplication in the analog

174
00:06:47,039 --> 00:06:51,600
domain using a network of resistors as

175
00:06:49,680 --> 00:06:53,759
it's as you can see in the diagram

176
00:06:51,600 --> 00:06:55,759
resistors which conductance can be

177
00:06:53,759 --> 00:06:57,600
programmed to have the weights of a

178
00:06:55,759 --> 00:06:59,840
neural network then you can use the

179
00:06:57,600 --> 00:07:01,520
combination of ohms law and kickoff's

180
00:06:59,840 --> 00:07:03,919
law to perform the vector matrix

181
00:07:01,520 --> 00:07:06,080
multiplication in the analog domain with

182
00:07:03,919 --> 00:07:08,000
much greater savings in in energy as

183
00:07:06,080 --> 00:07:09,639
opposed to the conventional digital

184
00:07:08,000 --> 00:07:13,199
domain which is how it's being done

185
00:07:09,639 --> 00:07:16,800
today. and and so so the key is is this

186
00:07:13,199 --> 00:07:18,400
network of resistors with a with a value

187
00:07:16,800 --> 00:07:20,800
of the resistance or a value of the

188
00:07:18,400 --> 00:07:22,800
conductance which can be programmed and

189
00:07:20,800 --> 00:07:25,039
can be held in memory. It is this key

190
00:07:22,800 --> 00:07:27,120
device which he calls meters sometimes

191
00:07:25,039 --> 00:07:30,400
is also called a synapse which is in

192
00:07:27,120 --> 00:07:32,160
effect a programmable nonvolatile

193
00:07:30,400 --> 00:07:34,240
resistor meaning that you can program a

194
00:07:32,160 --> 00:07:36,880
value of the resistance and it will be

195
00:07:34,240 --> 00:07:39,520
held in memory until a new value is

196
00:07:36,880 --> 00:07:42,479
programmed. And this is the key in this

197
00:07:39,520 --> 00:07:44,080
in these two dimensional arrays to um to

198
00:07:42,479 --> 00:07:45,280
implement analog neural networks that

199
00:07:44,080 --> 00:07:46,880
perform the vector matrix

200
00:07:45,280 --> 00:07:48,639
multiplication. Now essentially the way

201
00:07:46,880 --> 00:07:50,400
this works is as the diagram in the

202
00:07:48,639 --> 00:07:51,759
middle shows if we look at the

203
00:07:50,400 --> 00:07:54,319
conductance which is the inverse of the

204
00:07:51,759 --> 00:07:57,599
resistance of the resistor. If we apply

205
00:07:54,319 --> 00:07:59,840
positive voltages positive pulses uh

206
00:07:57,599 --> 00:08:01,759
across the device or to a third terminal

207
00:07:59,840 --> 00:08:03,440
that is acting on the device then the

208
00:08:01,759 --> 00:08:04,960
conductance increases in a programmable

209
00:08:03,440 --> 00:08:06,960
way as you can see in the staircase on

210
00:08:04,960 --> 00:08:08,400
the right. And if you apply a series of

211
00:08:06,960 --> 00:08:11,520
negative pulses then the conductance

212
00:08:08,400 --> 00:08:13,199
drops again in a staircase way um as

213
00:08:11,520 --> 00:08:14,800
more negative pulses arrive and and when

214
00:08:13,199 --> 00:08:16,479
you stop the pulses the value of the

215
00:08:14,800 --> 00:08:19,039
conductance will remain in memory until

216
00:08:16,479 --> 00:08:22,160
you change it again. Now the specs that

217
00:08:19,039 --> 00:08:25,199
we need for a for a device like this to

218
00:08:22,160 --> 00:08:26,800
really result in the great savings in

219
00:08:25,199 --> 00:08:28,240
energy efficiency of analog neural

220
00:08:26,800 --> 00:08:30,560
networks are fairly well understood and

221
00:08:28,240 --> 00:08:33,519
I have a summary of them in in the table

222
00:08:30,560 --> 00:08:37,120
here. So we know what we want. The

223
00:08:33,519 --> 00:08:38,800
problem is that today in spite of having

224
00:08:37,120 --> 00:08:40,880
quite a wide range of options there

225
00:08:38,800 --> 00:08:43,120
based on new materials and based on new

226
00:08:40,880 --> 00:08:44,880
physical principles, there is no one

227
00:08:43,120 --> 00:08:46,480
device technology that has been found

228
00:08:44,880 --> 00:08:48,720
that meets all the specs that are

229
00:08:46,480 --> 00:08:51,360
required to to implement these neuron

230
00:08:48,720 --> 00:08:52,480
networks which is which is why folks

231
00:08:51,360 --> 00:08:54,160
like me which are interested in

232
00:08:52,480 --> 00:08:56,000
materials and transistors and devices

233
00:08:54,160 --> 00:08:58,959
are really interested in in this

234
00:08:56,000 --> 00:09:00,880
problem. And so a number of us at MIT

235
00:08:58,959 --> 00:09:03,760
are working on a number of concepts. How

236
00:09:00,880 --> 00:09:06,480
can we implement these membrrisers or

237
00:09:03,760 --> 00:09:08,399
synaptic devices or AI transistors

238
00:09:06,480 --> 00:09:11,279
however you want to call them uh with

239
00:09:08,399 --> 00:09:13,200
the right uh portfolio of properties are

240
00:09:11,279 --> 00:09:14,240
required to implement neural networks.

241
00:09:13,200 --> 00:09:16,560
So I'm going to tell you about two

242
00:09:14,240 --> 00:09:18,880
projects uh that are going on in my lab.

243
00:09:16,560 --> 00:09:21,120
On the left is a project uh that is

244
00:09:18,880 --> 00:09:23,440
based on devices that are based on

245
00:09:21,120 --> 00:09:25,600
proton intercolation onto a

246
00:09:23,440 --> 00:09:27,200
semiconductor. On the right uh devices

247
00:09:25,600 --> 00:09:28,880
that are based on the federal effect

248
00:09:27,200 --> 00:09:30,320
these are ongoing research projects in

249
00:09:28,880 --> 00:09:32,240
my lab. So on the right I'll give you

250
00:09:30,320 --> 00:09:34,880
some more details on that. There is if I

251
00:09:32,240 --> 00:09:37,120
may point here there is a a thin layer

252
00:09:34,880 --> 00:09:39,279
of tungsten oxide here. Tungsten oxide

253
00:09:37,120 --> 00:09:41,360
is actually a semiconductor. So you can

254
00:09:39,279 --> 00:09:43,120
think of it as a as a transistor channel

255
00:09:41,360 --> 00:09:45,120
except that it's very easy to to

256
00:09:43,120 --> 00:09:47,120
introduce ions into the tungsten oxide

257
00:09:45,120 --> 00:09:48,720
and the ions will the right ion will

258
00:09:47,120 --> 00:09:50,640
dope the tungsten oxide enhancing the

259
00:09:48,720 --> 00:09:52,720
conductivity. If you take the ions away

260
00:09:50,640 --> 00:09:55,040
then you can reduce the conductivity. So

261
00:09:52,720 --> 00:09:56,560
we have two contacts uh uh on both sides

262
00:09:55,040 --> 00:09:57,920
of a tungxen oxide to measure the

263
00:09:56,560 --> 00:09:59,600
conductivity of the conductance of a

264
00:09:57,920 --> 00:10:03,120
tungxen oxide and we are going to

265
00:09:59,600 --> 00:10:05,200
introduce ions in in our case protons

266
00:10:03,120 --> 00:10:07,360
from a reservoir which is this paladium

267
00:10:05,200 --> 00:10:11,200
gate here through an electrolyte which

268
00:10:07,360 --> 00:10:12,320
in our case is uh ph uh phosphocilicate

269
00:10:11,200 --> 00:10:15,040
glass and that is one of the key

270
00:10:12,320 --> 00:10:17,200
innovations of of my research group. So

271
00:10:15,040 --> 00:10:20,079
essentially what you have here is a tiny

272
00:10:17,200 --> 00:10:22,000
nano battery that injects protons from

273
00:10:20,079 --> 00:10:23,600
this reservoir into the tungsten oxide

274
00:10:22,000 --> 00:10:25,760
on demand. If we apply a positive

275
00:10:23,600 --> 00:10:27,600
voltage we get protons in. If we apply a

276
00:10:25,760 --> 00:10:29,440
negative voltage we get the protons out.

277
00:10:27,600 --> 00:10:31,600
And if we remove the voltage the protons

278
00:10:29,440 --> 00:10:34,000
will remain in place so that the device

279
00:10:31,600 --> 00:10:36,640
holds the memory of the conductance that

280
00:10:34,000 --> 00:10:38,079
has been set by the proton concentration

281
00:10:36,640 --> 00:10:40,000
that has been introducing here.

282
00:10:38,079 --> 00:10:41,760
Essentially, we can control the doping

283
00:10:40,000 --> 00:10:44,000
level of a semiconductor at room

284
00:10:41,760 --> 00:10:45,760
temperature simply by uh using these

285
00:10:44,000 --> 00:10:47,920
tiny nano batteries. Something that we

286
00:10:45,760 --> 00:10:50,079
cannot possibly do with silicon. And on

287
00:10:47,920 --> 00:10:52,240
the right is a different device concept

288
00:10:50,079 --> 00:10:54,560
uh where we have essentially it's a thin

289
00:10:52,240 --> 00:10:56,720
transistor. If for those of you that uh

290
00:10:54,560 --> 00:10:58,640
know about transistors that are used on

291
00:10:56,720 --> 00:11:00,320
for displays for example, it's sort of

292
00:10:58,640 --> 00:11:01,839
upside down. This is the gate. This is

293
00:11:00,320 --> 00:11:03,440
the dialectric. This is the

294
00:11:01,839 --> 00:11:05,440
semiconductor channel which in our case

295
00:11:03,440 --> 00:11:06,800
is indium gallium zinc oxide. And then

296
00:11:05,440 --> 00:11:08,720
the two contacts for the source and

297
00:11:06,800 --> 00:11:11,440
drain. So we can measure the conductance

298
00:11:08,720 --> 00:11:13,120
of this channel uh by putting a voltage

299
00:11:11,440 --> 00:11:14,720
across the source and drain. What's

300
00:11:13,120 --> 00:11:16,800
unique about this device is that this

301
00:11:14,720 --> 00:11:19,120
dialectric is actually a ferroelectric

302
00:11:16,800 --> 00:11:21,440
is half new siliconium oxide a material

303
00:11:19,120 --> 00:11:23,279
that has been found recently to have uh

304
00:11:21,440 --> 00:11:25,839
prominent ferctric characteristics and

305
00:11:23,279 --> 00:11:28,560
that is also silicon compatible. And so

306
00:11:25,839 --> 00:11:30,800
applying a a suitable voltage across the

307
00:11:28,560 --> 00:11:33,200
havoc silicon oxide, you can program the

308
00:11:30,800 --> 00:11:34,959
polarization state and that changes the

309
00:11:33,200 --> 00:11:36,240
threshold voltage of the semiconductor

310
00:11:34,959 --> 00:11:38,399
channel and that changes the current

311
00:11:36,240 --> 00:11:40,880
through it. And once you remove that

312
00:11:38,399 --> 00:11:44,560
voltage, the fer the polarization state

313
00:11:40,880 --> 00:11:47,040
is held in memory in this in uh in this

314
00:11:44,560 --> 00:11:48,720
ferctic material and it only can be

315
00:11:47,040 --> 00:11:51,040
changed by applying the the reverse

316
00:11:48,720 --> 00:11:53,200
voltage. So again we have a device in

317
00:11:51,040 --> 00:11:54,800
which we can program a conductance that

318
00:11:53,200 --> 00:11:56,640
is read through a semiconductor channel

319
00:11:54,800 --> 00:11:58,480
and is held in memory until we change it

320
00:11:56,640 --> 00:12:01,760
again. So these are two types of devices

321
00:11:58,480 --> 00:12:04,000
that we are working in my lab. Now a key

322
00:12:01,760 --> 00:12:07,920
requirement for any technology of this

323
00:12:04,000 --> 00:12:10,320
kind is that it has to be integrated on

324
00:12:07,920 --> 00:12:12,480
top of a SMOS platform because it has to

325
00:12:10,320 --> 00:12:13,920
leverage the SMOS backbone that is going

326
00:12:12,480 --> 00:12:15,760
to continue to make a lot of progress

327
00:12:13,920 --> 00:12:17,120
along the way for years to come. Right?

328
00:12:15,760 --> 00:12:19,600
So the way the technology is going to

329
00:12:17,120 --> 00:12:21,360
look like this is a a cartoon schematic

330
00:12:19,600 --> 00:12:23,760
is we'll have a silicon wafer with the

331
00:12:21,360 --> 00:12:26,000
silicon transistors at the at the w at

332
00:12:23,760 --> 00:12:27,519
the uh silicon level and then we'll have

333
00:12:26,000 --> 00:12:29,680
many layers of interconnects and

334
00:12:27,519 --> 00:12:32,959
somewhere in this tall interconnect

335
00:12:29,680 --> 00:12:35,760
stack of uh of a modern chip there will

336
00:12:32,959 --> 00:12:38,399
be a layer where the AI accelerator will

337
00:12:35,760 --> 00:12:41,040
sit with these synapi synaptic devices

338
00:12:38,399 --> 00:12:42,480
or memoristic devices and so it has to

339
00:12:41,040 --> 00:12:45,680
be built in there in the middle of the

340
00:12:42,480 --> 00:12:47,680
cos process on the back end which is the

341
00:12:45,680 --> 00:12:49,600
ation that we use for to refer to these

342
00:12:47,680 --> 00:12:51,279
where all the interconnects are. And as

343
00:12:49,600 --> 00:12:53,440
a result, it has to be fully SIMOS

344
00:12:51,279 --> 00:12:55,519
compatible. It has to be done in a SIMOS

345
00:12:53,440 --> 00:12:58,160
fab. It has to use SIMOS compatible

346
00:12:55,519 --> 00:13:00,160
materials, SIMO compatible processes. It

347
00:12:58,160 --> 00:13:01,839
has to be able to withstand 400 degrees

348
00:13:00,160 --> 00:13:03,360
centiggrades, which is the temperature

349
00:13:01,839 --> 00:13:05,920
required for the rest of interconnects

350
00:13:03,360 --> 00:13:09,040
that are going to come on top. And also

351
00:13:05,920 --> 00:13:10,399
it has to u be able to uh to be done

352
00:13:09,040 --> 00:13:12,399
everything has to be done at temperature

353
00:13:10,399 --> 00:13:13,680
less than 400 degrees because you don't

354
00:13:12,399 --> 00:13:15,839
want to damage anything that has been

355
00:13:13,680 --> 00:13:17,680
fabricated before. So there are many

356
00:13:15,839 --> 00:13:19,920
constraints that a technology of this

357
00:13:17,680 --> 00:13:22,320
kind has to fulfill which we are

358
00:13:19,920 --> 00:13:24,240
incorporating in in our research in in

359
00:13:22,320 --> 00:13:28,000
our lab. So let me give you some more

360
00:13:24,240 --> 00:13:29,680
details of this um this uh uh proton

361
00:13:28,000 --> 00:13:31,600
intercalation device that we have been

362
00:13:29,680 --> 00:13:34,480
investigating in my group. Here you see

363
00:13:31,600 --> 00:13:37,200
a top view of one of our experimental

364
00:13:34,480 --> 00:13:39,120
devices. You see the uh the source and

365
00:13:37,200 --> 00:13:41,519
drain are here. This is these golden

366
00:13:39,120 --> 00:13:43,440
regions. The gate is coming like this.

367
00:13:41,519 --> 00:13:45,040
The active area of the device is right

368
00:13:43,440 --> 00:13:46,560
there. This is the tungsten oxide

369
00:13:45,040 --> 00:13:48,000
channel. So the active area is right

370
00:13:46,560 --> 00:13:49,760
there where the overlap of all these

371
00:13:48,000 --> 00:13:52,480
regions takes place which is in the

372
00:13:49,760 --> 00:13:55,200
nanometer scale 30 nanometers long and

373
00:13:52,480 --> 00:13:57,440
60 nanometers wide. So we are

374
00:13:55,200 --> 00:13:58,959
emphasizing extremely uh extreme scaling

375
00:13:57,440 --> 00:14:00,959
for for our transistors or for our

376
00:13:58,959 --> 00:14:02,240
devices to achieve very high density.

377
00:14:00,959 --> 00:14:04,079
This is a transmission electron

378
00:14:02,240 --> 00:14:05,920
microraph cross-section. You can see

379
00:14:04,079 --> 00:14:08,399
here the tungsten oxide channel very

380
00:14:05,920 --> 00:14:09,800
very thin layer with two contacts at

381
00:14:08,399 --> 00:14:11,839
both ends. You can see here the

382
00:14:09,800 --> 00:14:14,160
phosphocosilic phosphocyic glass

383
00:14:11,839 --> 00:14:16,480
electrolyte and the paladium gate and

384
00:14:14,160 --> 00:14:18,959
also reservoir. So the protons come from

385
00:14:16,480 --> 00:14:21,279
the paladium through the PSG into the

386
00:14:18,959 --> 00:14:22,959
tungsten oxide and then back and we read

387
00:14:21,279 --> 00:14:24,639
the conductance of the tungsten oxide by

388
00:14:22,959 --> 00:14:26,279
putting a voltage between these two gold

389
00:14:24,639 --> 00:14:28,800
electrons and passing current through

390
00:14:26,279 --> 00:14:30,000
it. Now this device actually works quite

391
00:14:28,800 --> 00:14:31,440
well. Here is some electrical

392
00:14:30,000 --> 00:14:34,000
characteristics similar to what I show

393
00:14:31,440 --> 00:14:38,240
you earlier that we desire. Here we are

394
00:14:34,000 --> 00:14:39,519
applying uh five nancond pulses uh uh

395
00:14:38,240 --> 00:14:41,519
positive and you can see how the

396
00:14:39,519 --> 00:14:43,199
conductance of the device increases and

397
00:14:41,519 --> 00:14:45,440
when we switch to negative pulses the

398
00:14:43,199 --> 00:14:47,680
conductance of the device decreases. We

399
00:14:45,440 --> 00:14:50,959
span a very large dynamic range about

400
00:14:47,680 --> 00:14:52,480
20x or so in conductance. the uh the

401
00:14:50,959 --> 00:14:54,480
trajectory is fairly linear and

402
00:14:52,480 --> 00:14:57,040
symmetric on the way up and on the way

403
00:14:54,480 --> 00:14:58,800
down and as I said it responds to uh

404
00:14:57,040 --> 00:15:00,639
very very short pulses which means that

405
00:14:58,800 --> 00:15:03,360
this is a technology that could really

406
00:15:00,639 --> 00:15:04,800
operate at very high uh speeds something

407
00:15:03,360 --> 00:15:06,720
that's important is to show that you

408
00:15:04,800 --> 00:15:09,040
have retention in the end this must have

409
00:15:06,720 --> 00:15:11,279
memory through the uh to withstand the

410
00:15:09,040 --> 00:15:14,000
training process in a in a in a deep

411
00:15:11,279 --> 00:15:16,160
learning uh system and so you can see

412
00:15:14,000 --> 00:15:18,000
here how the device has been programmed

413
00:15:16,160 --> 00:15:21,199
here's again conductance as a as a

414
00:15:18,000 --> 00:15:23,600
function of uh pulse number we have uh

415
00:15:21,199 --> 00:15:25,680
apply a pulse to program the conductance

416
00:15:23,600 --> 00:15:28,160
to the next level and then we read that

417
00:15:25,680 --> 00:15:29,680
conductance 100 times one per second and

418
00:15:28,160 --> 00:15:31,120
you can see how the value is held in

419
00:15:29,680 --> 00:15:33,279
memory quite well. This is still a

420
00:15:31,120 --> 00:15:36,240
little bit of a a little bit of a drift

421
00:15:33,279 --> 00:15:38,639
but uh quite limited. Uh so to show you

422
00:15:36,240 --> 00:15:40,560
that this really holds uh memory quite

423
00:15:38,639 --> 00:15:42,320
well and of course the device shows very

424
00:15:40,560 --> 00:15:44,720
high endurance and repeatability. Here

425
00:15:42,320 --> 00:15:46,959
are 10 to the five pulses over 30 hours.

426
00:15:44,720 --> 00:15:48,839
You can see the device has a very very

427
00:15:46,959 --> 00:15:52,079
reproducible um

428
00:15:48,839 --> 00:15:53,920
characteristics and this is a benchmark

429
00:15:52,079 --> 00:15:55,839
with some work that has been done uh in

430
00:15:53,920 --> 00:15:58,720
industry by uh other by other

431
00:15:55,839 --> 00:16:01,120
colleagues. uh the metric that we are

432
00:15:58,720 --> 00:16:02,480
using here is this is all about energy

433
00:16:01,120 --> 00:16:04,959
from the very beginning I've emphasized

434
00:16:02,480 --> 00:16:06,880
that right so the the metric that we

435
00:16:04,959 --> 00:16:08,639
using here is the energy that is

436
00:16:06,880 --> 00:16:10,480
required to change the conductance of

437
00:16:08,639 --> 00:16:12,959
this device by a certain amount so that

438
00:16:10,480 --> 00:16:14,800
ratio is a reasonable measure of energy

439
00:16:12,959 --> 00:16:16,320
efficiency that we can use different

440
00:16:14,800 --> 00:16:18,000
investigators to compare different

441
00:16:16,320 --> 00:16:20,240
device technologies so here I'm showing

442
00:16:18,000 --> 00:16:22,800
you two designs from other folks this is

443
00:16:20,240 --> 00:16:24,959
based on oxygen ions this is based on

444
00:16:22,800 --> 00:16:27,519
lithium ions our work I remind you is

445
00:16:24,959 --> 00:16:29,600
based on protons And we chose protons

446
00:16:27,519 --> 00:16:32,240
because well the proton is the lightest

447
00:16:29,600 --> 00:16:35,040
ion that exists and as a result is going

448
00:16:32,240 --> 00:16:36,480
to be able to move fast. It's very small

449
00:16:35,040 --> 00:16:38,079
and so it's going to be able to move

450
00:16:36,480 --> 00:16:39,920
fast and responds to a very small

451
00:16:38,079 --> 00:16:42,160
voltage which again is what we want to

452
00:16:39,920 --> 00:16:45,360
achieve very high energy efficiency. So

453
00:16:42,160 --> 00:16:47,519
you can see how by uh using a much

454
00:16:45,360 --> 00:16:49,600
lighter ion that these folks and by

455
00:16:47,519 --> 00:16:52,000
scaling this is the area of the device

456
00:16:49,600 --> 00:16:53,680
to to nanoscale dimensions we have been

457
00:16:52,000 --> 00:16:55,920
able to enhance this measure of energy

458
00:16:53,680 --> 00:16:58,079
efficiency by many orders of magnitude

459
00:16:55,920 --> 00:17:00,800
that that gives you a sense of of the

460
00:16:58,079 --> 00:17:04,480
promise of of this technology and in

461
00:17:00,800 --> 00:17:06,559
fact the um PhD student that carried out

462
00:17:04,480 --> 00:17:08,880
this research then when he graduated he

463
00:17:06,559 --> 00:17:10,720
went on to set up a company to try to

464
00:17:08,880 --> 00:17:12,720
commercialize to commercialize this

465
00:17:10,720 --> 00:17:14,160
technology which I I I found really

466
00:17:12,720 --> 00:17:16,079
fantastic and in fact he was I

467
00:17:14,160 --> 00:17:19,520
understand speaking earlier today and I

468
00:17:16,079 --> 00:17:23,039
saw that he has a booth or uh displaying

469
00:17:19,520 --> 00:17:25,199
there with some some of u some of the

470
00:17:23,039 --> 00:17:28,720
ideas and and the uh where where the

471
00:17:25,199 --> 00:17:30,559
company sits corporation and um and so

472
00:17:28,720 --> 00:17:32,640
he's in the process of you know bringing

473
00:17:30,559 --> 00:17:34,080
this technology to a maturity level that

474
00:17:32,640 --> 00:17:36,600
eventually can be implemented in the

475
00:17:34,080 --> 00:17:39,039
real world. So I I find that extremely

476
00:17:36,600 --> 00:17:41,039
exciting. All right. So we've talked

477
00:17:39,039 --> 00:17:43,039
about new devices and new based on new

478
00:17:41,039 --> 00:17:45,039
materials and in some cases new physical

479
00:17:43,039 --> 00:17:46,640
principles to implement anal analog

480
00:17:45,039 --> 00:17:48,960
neural networks which which George

481
00:17:46,640 --> 00:17:52,160
Hinton has told us is the way to achieve

482
00:17:48,960 --> 00:17:54,000
greater uh efficiency enhancements. It

483
00:17:52,160 --> 00:17:55,840
turns out that you can also do analog

484
00:17:54,000 --> 00:17:57,919
neural networks without requiring new

485
00:17:55,840 --> 00:18:00,080
devices or new materials just using

486
00:17:57,919 --> 00:18:01,200
SIMOS. And so here is the work and I'm

487
00:18:00,080 --> 00:18:03,120
now going to be talking about the

488
00:18:01,200 --> 00:18:04,960
research of other colleagues at MIT.

489
00:18:03,120 --> 00:18:07,520
This is the work of professor Anatha

490
00:18:04,960 --> 00:18:09,760
Chandra Kasan and his postoc Aya Ammer

491
00:18:07,520 --> 00:18:12,000
who are using SRAMM which is a static

492
00:18:09,760 --> 00:18:14,960
random access memory. It's a standard

493
00:18:12,000 --> 00:18:17,600
memory design uses using SIMOS to

494
00:18:14,960 --> 00:18:19,840
implement analog neural networks in in a

495
00:18:17,600 --> 00:18:21,440
similar way. So so now instead of a

496
00:18:19,840 --> 00:18:24,080
device you've got an SRAM cell which

497
00:18:21,440 --> 00:18:25,919
will contain six seven nine transistors.

498
00:18:24,080 --> 00:18:27,280
So it's a much bigger creature which is

499
00:18:25,919 --> 00:18:29,120
why in the end we really are going to

500
00:18:27,280 --> 00:18:31,120
need new devices and new materials. But

501
00:18:29,120 --> 00:18:33,360
you can really make a lot of progress uh

502
00:18:31,120 --> 00:18:36,080
using SIMOS and in particular they have

503
00:18:33,360 --> 00:18:38,160
demonstrated an all analog voice

504
00:18:36,080 --> 00:18:40,320
activity detection with a neural network

505
00:18:38,160 --> 00:18:42,960
here that contains uh three levels and

506
00:18:40,320 --> 00:18:45,280
here is a chip implementation in a four

507
00:18:42,960 --> 00:18:47,360
14 nanometer fined process that really

508
00:18:45,280 --> 00:18:49,200
shows that this is real and that they

509
00:18:47,360 --> 00:18:51,120
can make all these work with great

510
00:18:49,200 --> 00:18:52,559
energy efficiency.

511
00:18:51,120 --> 00:18:54,559
Some more examples on the left here I'm

512
00:18:52,559 --> 00:18:55,760
showing you the work of VBNZ and Joel

513
00:18:54,559 --> 00:18:57,559
Emmer other colleagues also in

514
00:18:55,760 --> 00:19:00,080
electrical engineering who are also

515
00:18:57,559 --> 00:19:02,240
investigating analog neural networks in

516
00:19:00,080 --> 00:19:04,160
this case they are developing tools to

517
00:19:02,240 --> 00:19:06,559
design these networks depending on what

518
00:19:04,160 --> 00:19:08,799
specific technology you have meristers

519
00:19:06,559 --> 00:19:11,840
or SRAMs or whatever it is that you have

520
00:19:08,799 --> 00:19:13,679
and and other system level parameters to

521
00:19:11,840 --> 00:19:15,760
optimize for throughput and to optimize

522
00:19:13,679 --> 00:19:17,840
for energy efficiency. the parameter

523
00:19:15,760 --> 00:19:19,440
space is vast and so therefore you need

524
00:19:17,840 --> 00:19:21,600
new design tools that are going to be

525
00:19:19,440 --> 00:19:24,000
able to analyze all these and find an

526
00:19:21,600 --> 00:19:25,520
optimum design and on the right is a

527
00:19:24,000 --> 00:19:27,440
colleague dear Kenlon who's using

528
00:19:25,520 --> 00:19:30,000
photonics to do deep learning and as he

529
00:19:27,440 --> 00:19:32,799
likes to say we process AI algorithms at

530
00:19:30,000 --> 00:19:33,640
the speed of light so a very a very uh

531
00:19:32,799 --> 00:19:36,880
cool

532
00:19:33,640 --> 00:19:39,440
technology a couple more examples uh

533
00:19:36,880 --> 00:19:41,600
also castan is is already examining

534
00:19:39,440 --> 00:19:43,000
issues of security on these new types of

535
00:19:41,600 --> 00:19:45,520
neural

536
00:19:43,000 --> 00:19:47,679
networks is investing investigating what

537
00:19:45,520 --> 00:19:53,200
he calls tiny ML, tiny machine learning,

538
00:19:47,679 --> 00:19:55,760
essentially tiny um um inference uh

539
00:19:53,200 --> 00:19:57,600
engines to be used on the edge that are

540
00:19:55,760 --> 00:19:59,679
have very little memory that have used

541
00:19:57,600 --> 00:20:01,120
that have very little energy and that

542
00:19:59,679 --> 00:20:03,200
have very little processing capability

543
00:20:01,120 --> 00:20:06,080
and yet that they can do smart things as

544
00:20:03,200 --> 00:20:08,160
as a way to bring efficient AI to the to

545
00:20:06,080 --> 00:20:09,520
the edge. And then at the bottom here is

546
00:20:08,160 --> 00:20:12,320
also a cool project from another

547
00:20:09,520 --> 00:20:14,720
colleague Ronan Han who is using uh

548
00:20:12,320 --> 00:20:17,240
large language models to help on the

549
00:20:14,720 --> 00:20:19,520
design of uh analog

550
00:20:17,240 --> 00:20:20,880
circuits. All of this is taking place in

551
00:20:19,520 --> 00:20:23,600
the context and I will finish with this

552
00:20:20,880 --> 00:20:25,679
at MIT which is the MIT AI hardware

553
00:20:23,600 --> 00:20:27,679
program. This is a collaboration between

554
00:20:25,679 --> 00:20:30,080
the MIT school of engineering and the

555
00:20:27,679 --> 00:20:32,559
Schwartzman College of Computing to

556
00:20:30,080 --> 00:20:34,480
essentially explore new concepts of AI

557
00:20:32,559 --> 00:20:36,799
hardware to drastically enhance the

558
00:20:34,480 --> 00:20:39,120
energy efficiency of implementation of

559
00:20:36,799 --> 00:20:41,360
AI in the in the future. So let me share

560
00:20:39,120 --> 00:20:43,039
with you very briefly our vision which I

561
00:20:41,360 --> 00:20:45,280
have already mentioned in this talk.

562
00:20:43,039 --> 00:20:47,919
Essentially our vision is that sustained

563
00:20:45,280 --> 00:20:49,440
progress in AI is going to demand a

564
00:20:47,919 --> 00:20:50,640
specialized hardware. I show you the

565
00:20:49,440 --> 00:20:52,240
difference that it made already a few

566
00:20:50,640 --> 00:20:54,080
years ago and that's what we need to

567
00:20:52,240 --> 00:20:55,760
continue to do forward. Energy

568
00:20:54,080 --> 00:20:58,000
efficiency should be should be our

569
00:20:55,760 --> 00:20:59,919
paramount goal and that is going to

570
00:20:58,000 --> 00:21:01,840
require new devices, new materials,

571
00:20:59,919 --> 00:21:04,320
perhaps new physical principles. I show

572
00:21:01,840 --> 00:21:05,559
you some nano battery based uh devices

573
00:21:04,320 --> 00:21:07,760
very different from conventional

574
00:21:05,559 --> 00:21:09,760
transistors. But all of this has to

575
00:21:07,760 --> 00:21:12,159
leverage the SIMOS backbone. Simos is

576
00:21:09,760 --> 00:21:13,919
going to continue to be this amazing

577
00:21:12,159 --> 00:21:15,440
technology extremely versatile and

578
00:21:13,919 --> 00:21:17,039
powerful that is going to continue to

579
00:21:15,440 --> 00:21:19,360
make progress for many years to come. We

580
00:21:17,039 --> 00:21:20,880
must leverage it to the max. So this is

581
00:21:19,360 --> 00:21:22,640
going to require a vertical integrated

582
00:21:20,880 --> 00:21:24,240
effort. there there are no well-

583
00:21:22,640 --> 00:21:26,159
definfined boundaries between the

584
00:21:24,240 --> 00:21:28,080
various various levels of abstraction as

585
00:21:26,159 --> 00:21:29,679
we have in conversional electronics. So

586
00:21:28,080 --> 00:21:31,679
we need to be able to work up and down

587
00:21:29,679 --> 00:21:33,679
the entire stack from materials all the

588
00:21:31,679 --> 00:21:35,039
way to algorithms and we need to be able

589
00:21:33,679 --> 00:21:37,200
to do hardware and algorithmic

590
00:21:35,039 --> 00:21:39,200
co-design. And finally for this to be

591
00:21:37,200 --> 00:21:40,559
successful we are convinced that we need

592
00:21:39,200 --> 00:21:42,320
to do this in collaboration in close

593
00:21:40,559 --> 00:21:45,039
collaboration with industry. You know in

594
00:21:42,320 --> 00:21:46,720
academia we can select problems that are

595
00:21:45,039 --> 00:21:48,480
fun that are interesting and we could

596
00:21:46,720 --> 00:21:51,280
just immerse ourselves and and enjoy

597
00:21:48,480 --> 00:21:53,679
solving them. But we at MIT also like to

598
00:21:51,280 --> 00:21:55,120
work on relevant problems that if we can

599
00:21:53,679 --> 00:21:56,960
fix them, if we can solve them, we can

600
00:21:55,120 --> 00:21:58,960
make a contribution to humanity. And

601
00:21:56,960 --> 00:22:00,080
that's what industry brings to us. If we

602
00:21:58,960 --> 00:22:01,760
are in close collaboration with

603
00:22:00,080 --> 00:22:04,640
industry, that awareness of what are the

604
00:22:01,760 --> 00:22:06,159
problems that if we if we can uh make

605
00:22:04,640 --> 00:22:08,400
progress on can really make a difference

606
00:22:06,159 --> 00:22:10,720
in the world. The value proposition that

607
00:22:08,400 --> 00:22:13,760
we offer to the companies that join in

608
00:22:10,720 --> 00:22:15,919
this program is the ability to define

609
00:22:13,760 --> 00:22:17,919
together with a principal investigator a

610
00:22:15,919 --> 00:22:20,080
research project that is tailored to the

611
00:22:17,919 --> 00:22:22,080
interest of your company to follow the

612
00:22:20,080 --> 00:22:24,400
progress of that pro of that project

613
00:22:22,080 --> 00:22:27,120
very closely over the years and at the

614
00:22:24,400 --> 00:22:28,880
same time to gain awareness on all the

615
00:22:27,120 --> 00:22:30,320
other projects that all companies that

616
00:22:28,880 --> 00:22:32,960
participate in the program are funding

617
00:22:30,320 --> 00:22:36,240
so that you get a much broader vision of

618
00:22:32,960 --> 00:22:37,760
as I gave you very briefly here on on

619
00:22:36,240 --> 00:22:39,840
the broader range of AI hardware

620
00:22:37,760 --> 00:22:41,760
research that's going on at MIT. We do

621
00:22:39,840 --> 00:22:43,760
that through an annual symposium which

622
00:22:41,760 --> 00:22:47,120
actually took place yesterday and we

623
00:22:43,760 --> 00:22:50,159
also do that through a full online um

624
00:22:47,120 --> 00:22:52,080
update that takes place online uh in the

625
00:22:50,159 --> 00:22:53,440
fall and there you see the entire the

626
00:22:52,080 --> 00:22:55,360
entire portfolio and of course there are

627
00:22:53,440 --> 00:22:57,919
many other many other benefits in the

628
00:22:55,360 --> 00:22:59,679
program. And I finish by showing you a

629
00:22:57,919 --> 00:23:02,559
picture of our secret weapon in AI

630
00:22:59,679 --> 00:23:06,000
hardware, which is our beautiful uh

631
00:23:02,559 --> 00:23:09,039
still very new MIT nano facility in the

632
00:23:06,000 --> 00:23:10,799
Lisa Tissu building, which is this

633
00:23:09,039 --> 00:23:12,559
extraordinary facility for nanop

634
00:23:10,799 --> 00:23:14,960
fabrication and nanotechnology that

635
00:23:12,559 --> 00:23:17,280
allows us to prototype all kinds of

636
00:23:14,960 --> 00:23:19,120
novel concept based on new materials

637
00:23:17,280 --> 00:23:20,320
such as I show you a few examples today.

638
00:23:19,120 --> 00:23:23,960
Thank you for your interest and I'll be

639
00:23:20,320 --> 00:23:23,960
happy to take some questions.

640
00:23:34,400 --> 00:23:37,600
Oh, there are questions

641
00:23:40,200 --> 00:23:44,480
here. I am not so knowledgeable of some

642
00:23:43,039 --> 00:23:46,559
of these some of these issues that are

643
00:23:44,480 --> 00:23:51,400
being asked here as as as you saw I work

644
00:23:46,559 --> 00:23:51,400
at a at the materials and device level.

645
00:23:52,320 --> 00:23:55,039
There is a lot of interest on quantum

646
00:23:53,600 --> 00:23:57,120
hardware. In fact, yesterday at the

647
00:23:55,039 --> 00:24:00,080
symposium, Dear Kangloo, who is working

648
00:23:57,120 --> 00:24:02,080
on photonics was presenting a number of

649
00:24:00,080 --> 00:24:04,000
concepts that were really spanning the

650
00:24:02,080 --> 00:24:06,240
intersection between photonics and and

651
00:24:04,000 --> 00:24:09,520
quantum computing as an area that is

652
00:24:06,240 --> 00:24:11,120
really uh uh incredibly fertile for

653
00:24:09,520 --> 00:24:13,440
computing but also for for

654
00:24:11,120 --> 00:24:16,400
communications. So definitely that is an

655
00:24:13,440 --> 00:24:19,039
area that overlaps strongly with with

656
00:24:16,400 --> 00:24:20,400
the area of photonics uh AI that I think

657
00:24:19,039 --> 00:24:23,279
is very worthwhile to explore and the

658
00:24:20,400 --> 00:24:23,279
key person at MIT is

659
00:24:28,120 --> 00:24:34,400
develop so can quantum hardware give us

660
00:24:31,200 --> 00:24:37,120
that another inflection inflection point

661
00:24:34,400 --> 00:24:39,760
to the progress of uh of AI well that is

662
00:24:37,120 --> 00:24:40,960
that is definitely the hope uh it's

663
00:24:39,760 --> 00:24:42,720
going to take a while according to what

664
00:24:40,960 --> 00:24:43,919
Dangru told yesterday. But that is the

665
00:24:42,720 --> 00:24:46,799
hope. We need something that will bend

666
00:24:43,919 --> 00:24:48,880
the curve and also essentially increase

667
00:24:46,799 --> 00:24:51,760
the rate of progress by a factor of 10

668
00:24:48,880 --> 00:24:51,760
in in a

669
00:24:51,880 --> 00:24:57,640
hardware. That seems to be it. Thank you

670
00:24:54,640 --> 00:24:57,640
again.

671
00:24:59,710 --> 00:25:03,700
[Applause]


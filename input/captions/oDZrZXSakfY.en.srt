1
00:00:00,240 --> 00:00:05,640
um thank you for the introduction and

2
00:00:02,000 --> 00:00:09,480
great to be back at MIT um and excited

3
00:00:05,640 --> 00:00:11,840
to talk to you all about my research and

4
00:00:09,480 --> 00:00:14,280
um kind of my vision for where I think a

5
00:00:11,840 --> 00:00:17,439
lot of cool research can be done in a

6
00:00:14,280 --> 00:00:18,800
for Earth very broadly um yeah I'm a

7
00:00:17,439 --> 00:00:20,600
senior applied research scientist at

8
00:00:18,800 --> 00:00:22,160
Microsoft research I did my post talk

9
00:00:20,600 --> 00:00:24,480
here at Microsoft research New England

10
00:00:22,160 --> 00:00:26,000
and now I'm technically at a Redman team

11
00:00:24,480 --> 00:00:29,599
just haven't moved yet so it was a very

12
00:00:26,000 --> 00:00:30,800
short commute for me um I want to start

13
00:00:29,599 --> 00:00:33,360
my

14
00:00:30,800 --> 00:00:35,680
by this little um oh it even has the

15
00:00:33,360 --> 00:00:38,320
sound nice by this little um time lapse

16
00:00:35,680 --> 00:00:40,600
so what you what you see here is a time

17
00:00:38,320 --> 00:00:41,960
lapse of objects in lower Earth orbit

18
00:00:40,600 --> 00:00:45,960
since the

19
00:00:41,960 --> 00:00:47,680
1960s up until all the way to today and

20
00:00:45,960 --> 00:00:50,520
what you can see is this kind of steady

21
00:00:47,680 --> 00:00:51,640
growth of more and more objects over the

22
00:00:50,520 --> 00:00:54,879
last six

23
00:00:51,640 --> 00:00:56,239
decades now many of these objects you

24
00:00:54,879 --> 00:00:59,280
see here are Earth observation

25
00:00:56,239 --> 00:01:00,519
satellites so satellites that sense some

26
00:00:59,280 --> 00:01:02,600
aspect of our plan

27
00:01:00,519 --> 00:01:04,960
it

28
00:01:02,600 --> 00:01:06,920
and the question for me since a long

29
00:01:04,960 --> 00:01:08,880
time has been you know with all of this

30
00:01:06,920 --> 00:01:10,840
sense sense state of our planet what

31
00:01:08,880 --> 00:01:12,200
what can we do with it um and what do

32
00:01:10,840 --> 00:01:16,000
these satellites

33
00:01:12,200 --> 00:01:18,759
observe and yeah we're about 10 years um

34
00:01:16,000 --> 00:01:20,680
off from today bit more but you see it's

35
00:01:18,759 --> 00:01:22,920
getting really cluttered up there and I

36
00:01:20,680 --> 00:01:24,159
don't know if you you've noticed but

37
00:01:22,920 --> 00:01:26,840
sometimes you look up you can for

38
00:01:24,159 --> 00:01:29,240
example see the Starling satellites uh

39
00:01:26,840 --> 00:01:30,960
in this like little neat lines traveling

40
00:01:29,240 --> 00:01:33,360
through the sky so it's looking very

41
00:01:30,960 --> 00:01:34,920
different to even when I was a

42
00:01:33,360 --> 00:01:37,320
child

43
00:01:34,920 --> 00:01:39,479
now as I said there's more and more

44
00:01:37,320 --> 00:01:41,479
satellites being launched almost every

45
00:01:39,479 --> 00:01:43,399
day what you see here is just kind of

46
00:01:41,479 --> 00:01:47,280
the expansion of the esa Mission so the

47
00:01:43,399 --> 00:01:50,320
European Space Agency um up until the

48
00:01:47,280 --> 00:01:52,799
2030s um obviously these satellites

49
00:01:50,320 --> 00:01:56,439
produce a massive absolutely massive

50
00:01:52,799 --> 00:01:58,520
amounts of data and um I think to kind

51
00:01:56,439 --> 00:02:01,520
of put that a bit into perspective if

52
00:01:58,520 --> 00:02:04,280
you think about the latest Generation Um

53
00:02:01,520 --> 00:02:05,960
large language model something like gp4

54
00:02:04,280 --> 00:02:07,600
we don't exactly know how big the

55
00:02:05,960 --> 00:02:09,640
training set for those models were but

56
00:02:07,600 --> 00:02:12,000
it's hypothesized or estimated that was

57
00:02:09,640 --> 00:02:14,319
around one petabyte of tokens we

58
00:02:12,000 --> 00:02:16,160
training data and keep in mind that for

59
00:02:14,319 --> 00:02:18,040
for this data to be generated open I

60
00:02:16,160 --> 00:02:20,599
basically scraped every single existing

61
00:02:18,040 --> 00:02:22,720
text that exists and um some people you

62
00:02:20,599 --> 00:02:24,599
know think also they kind of translated

63
00:02:22,720 --> 00:02:27,239
YouTube videos and made that into text

64
00:02:24,599 --> 00:02:29,560
so we don't know exactly right um to

65
00:02:27,239 --> 00:02:31,239
compare Earth observation data with that

66
00:02:29,560 --> 00:02:32,800
the kind of current estimate of all of

67
00:02:31,239 --> 00:02:36,120
the earth observation data out there is

68
00:02:32,800 --> 00:02:38,040
800 petabytes with another 100 petabytes

69
00:02:36,120 --> 00:02:39,599
being generated every year so we're kind

70
00:02:38,040 --> 00:02:42,560
of working on completely different

71
00:02:39,599 --> 00:02:45,360
orders of magnitude

72
00:02:42,560 --> 00:02:48,239
here and it isn't really just um

73
00:02:45,360 --> 00:02:50,120
satellites uh a large portions of all of

74
00:02:48,239 --> 00:02:51,840
the world's data have Geographic meta

75
00:02:50,120 --> 00:02:53,440
metadata attached to them right so

76
00:02:51,840 --> 00:02:55,879
beyond the satellites we might have

77
00:02:53,440 --> 00:02:57,400
something like a a Geotech tweet so

78
00:02:55,879 --> 00:02:59,560
social media post that has been sent

79
00:02:57,400 --> 00:03:01,159
from a specific location and then we

80
00:02:59,560 --> 00:03:04,200
have also Al like derived products like

81
00:03:01,159 --> 00:03:06,440
elevation or species range Maps um at a

82
00:03:04,200 --> 00:03:06,440
given

83
00:03:06,720 --> 00:03:12,760
location now I really believe that

84
00:03:10,519 --> 00:03:15,000
there's lots of potential in combining

85
00:03:12,760 --> 00:03:16,599
these uh geospatial data sources from

86
00:03:15,000 --> 00:03:19,879
different ground and remote sensors

87
00:03:16,599 --> 00:03:22,200
together to support decision- making and

88
00:03:19,879 --> 00:03:24,959
for this we can leverage their joint

89
00:03:22,200 --> 00:03:26,480
geography their joint um yeah geometry

90
00:03:24,959 --> 00:03:29,280
being being able to map them on the

91
00:03:26,480 --> 00:03:30,760
sphere of our planet um and I'll show

92
00:03:29,280 --> 00:03:32,640
you a little example of what I what I

93
00:03:30,760 --> 00:03:35,040
mean with that for example we could

94
00:03:32,640 --> 00:03:36,840
combine this Geotech tweet which is from

95
00:03:35,040 --> 00:03:39,799
Annapolis it's about a flooding event oh

96
00:03:36,840 --> 00:03:42,280
no that was too fast I wanted to do this

97
00:03:39,799 --> 00:03:44,760
right so this is a a tweet about a a a

98
00:03:42,280 --> 00:03:46,200
flooding event in Anapolis we can

99
00:03:44,760 --> 00:03:47,799
combine that with real-time

100
00:03:46,200 --> 00:03:50,519
meteorological data that comes from a

101
00:03:47,799 --> 00:03:53,000
satellite for example to make some

102
00:03:50,519 --> 00:03:55,720
informed decision for example should an

103
00:03:53,000 --> 00:03:58,280
evacuation um order be issued or

104
00:03:55,720 --> 00:04:00,280
not so this seems very intuitive right

105
00:03:58,280 --> 00:04:01,879
this combination and support decision

106
00:04:00,280 --> 00:04:05,560
making so why isn't this being

107
00:04:01,879 --> 00:04:08,120
operationalized at large scale and I'm

108
00:04:05,560 --> 00:04:09,560
breaking this down very very roughly but

109
00:04:08,120 --> 00:04:11,599
um I think there's kind of three

110
00:04:09,560 --> 00:04:14,159
overarching problems that currently

111
00:04:11,599 --> 00:04:16,799
exist the first one I got to already is

112
00:04:14,159 --> 00:04:18,440
the sheer scale of this data the second

113
00:04:16,799 --> 00:04:20,320
one is that this data is very

114
00:04:18,440 --> 00:04:23,080
unstructured and multimodel right so we

115
00:04:20,320 --> 00:04:24,800
working with you know images video very

116
00:04:23,080 --> 00:04:26,680
very different data modalities

117
00:04:24,800 --> 00:04:28,800
unstructured is they're like in

118
00:04:26,680 --> 00:04:30,000
different archives um different from

119
00:04:28,800 --> 00:04:31,360
different providers some some of them

120
00:04:30,000 --> 00:04:32,800
are behind pay wall some of them you

121
00:04:31,360 --> 00:04:35,280
have public access

122
00:04:32,800 --> 00:04:37,560
to and the latest big problem is that a

123
00:04:35,280 --> 00:04:39,199
lot of this data is unlabeled right so

124
00:04:37,560 --> 00:04:40,800
um while we have satellite imagery for

125
00:04:39,199 --> 00:04:43,240
the whole world we only have kind of

126
00:04:40,800 --> 00:04:44,759
limited labels that tell us what exactly

127
00:04:43,240 --> 00:04:48,360
is in this satellite image at this

128
00:04:44,759 --> 00:04:51,280
location at this point of time and with

129
00:04:48,360 --> 00:04:54,199
uh my research um I'm kind of trying to

130
00:04:51,280 --> 00:04:57,199
tackle all of these problems at once

131
00:04:54,199 --> 00:04:59,800
very ambitious but I think um there's

132
00:04:57,199 --> 00:05:03,680
some interesting Solutions here um for

133
00:04:59,800 --> 00:05:06,560
the large scale problem very kind of uh

134
00:05:03,680 --> 00:05:08,759
yeah invoke uh solution is to use nor

135
00:05:06,560 --> 00:05:10,240
networks kind of the best scaling method

136
00:05:08,759 --> 00:05:11,280
that we have to deal with large amounts

137
00:05:10,240 --> 00:05:14,039
of

138
00:05:11,280 --> 00:05:17,160
data to tackle the kind of unstructured

139
00:05:14,039 --> 00:05:19,319
multimodal um nature like I said I

140
00:05:17,160 --> 00:05:21,240
believe we can fuse different modalities

141
00:05:19,319 --> 00:05:23,720
different information of of our planet

142
00:05:21,240 --> 00:05:26,880
together in their joint um locations in

143
00:05:23,720 --> 00:05:28,400
space and time and then lastly to tackle

144
00:05:26,880 --> 00:05:31,199
this problem of of the largely

145
00:05:28,400 --> 00:05:33,680
unscalable uh UNL data I think we can

146
00:05:31,199 --> 00:05:37,560
leverage advances in self-supervised

147
00:05:33,680 --> 00:05:37,560
learning so learning um without

148
00:05:38,919 --> 00:05:43,400
labels and the type of models I want to

149
00:05:41,759 --> 00:05:45,160
talk about today and that I believe have

150
00:05:43,400 --> 00:05:48,000
the potential to fulfill all of these

151
00:05:45,160 --> 00:05:52,440
parameters are geographic location

152
00:05:48,000 --> 00:05:55,039
encoders um and these are highly

153
00:05:52,440 --> 00:05:57,440
scalable neural network models that use

154
00:05:55,039 --> 00:05:59,680
self-supervision to learn semantically

155
00:05:57,440 --> 00:06:01,039
meaningful representations of our planet

156
00:05:59,680 --> 00:06:04,000
from these large amounts of Earth

157
00:06:01,039 --> 00:06:06,360
observation data and throughout this

158
00:06:04,000 --> 00:06:07,960
talk I'll kind of show how we built the

159
00:06:06,360 --> 00:06:09,759
first generation of these models and

160
00:06:07,960 --> 00:06:12,599
then where we go from

161
00:06:09,759 --> 00:06:14,199
there and um the way I want to structure

162
00:06:12,599 --> 00:06:16,280
this is first I want to talk a bit about

163
00:06:14,199 --> 00:06:18,680
the origins of the spatial modeling

164
00:06:16,280 --> 00:06:20,960
problem then I'll outline location

165
00:06:18,680 --> 00:06:23,479
encoders and how they currently look in

166
00:06:20,960 --> 00:06:24,919
part three I will talk about how to S

167
00:06:23,479 --> 00:06:27,280
train them with s supervision and in

168
00:06:24,919 --> 00:06:30,319
part four I will talk about the kind of

169
00:06:27,280 --> 00:06:31,680
looking ahead what is up next

170
00:06:30,319 --> 00:06:34,360
all right so let's start with um

171
00:06:31,680 --> 00:06:37,039
learning from Geographic data so the

172
00:06:34,360 --> 00:06:38,599
classic um uh description of this

173
00:06:37,039 --> 00:06:41,919
Geographic modeling problem is that for

174
00:06:38,599 --> 00:06:44,960
a given location let and long we want

175
00:06:41,919 --> 00:06:47,599
some output and what we can leverage

176
00:06:44,960 --> 00:06:49,360
here is the first law of geography all

177
00:06:47,599 --> 00:06:52,199
things are related but near things are

178
00:06:49,360 --> 00:06:54,240
more related for example for a good

179
00:06:52,199 --> 00:06:56,440
temperature estimate at our current

180
00:06:54,240 --> 00:06:58,000
location the best thing we can do is we

181
00:06:56,440 --> 00:07:01,240
can look up the closest available

182
00:06:58,000 --> 00:07:02,800
temperature sensor and and then weigh

183
00:07:01,240 --> 00:07:05,520
our estimate somewhat on the distance

184
00:07:02,800 --> 00:07:07,280
between us and that sensor and so we can

185
00:07:05,520 --> 00:07:09,440
get from few spus observations we can

186
00:07:07,280 --> 00:07:11,160
kind of build a dense map that exploits

187
00:07:09,440 --> 00:07:13,759
this spatial

188
00:07:11,160 --> 00:07:16,199
smoothness um classic interpolation

189
00:07:13,759 --> 00:07:18,560
problem traditionally in Du uh

190
00:07:16,199 --> 00:07:21,360
statistics we would use a g gion process

191
00:07:18,560 --> 00:07:24,680
for this um in in in geography it's also

192
00:07:21,360 --> 00:07:26,759
often called cing so we would basically

193
00:07:24,680 --> 00:07:28,240
learn a continuous function over space

194
00:07:26,759 --> 00:07:31,120
using using

195
00:07:28,240 --> 00:07:34,440
kernels one problem with these kind of

196
00:07:31,120 --> 00:07:36,080
traditional uh methods is uh that they

197
00:07:34,440 --> 00:07:38,599
scale pretty poorly right so gion

198
00:07:36,080 --> 00:07:41,160
processes and kernel methods have cubic

199
00:07:38,599 --> 00:07:42,720
complexity and um while there is some

200
00:07:41,160 --> 00:07:44,639
work on for example deep caution

201
00:07:42,720 --> 00:07:46,199
processes that help that a little bit we

202
00:07:44,639 --> 00:07:48,560
kind of still struggle with the pure

203
00:07:46,199 --> 00:07:50,199
scale of that data Gan processes are

204
00:07:48,560 --> 00:07:52,280
also not the best models to work with

205
00:07:50,199 --> 00:07:53,639
kind of very complex data types like

206
00:07:52,280 --> 00:07:57,319
images or

207
00:07:53,639 --> 00:07:59,199
so and lastly at least vanilla gion

208
00:07:57,319 --> 00:08:01,479
processes are also not able to deal with

209
00:07:59,199 --> 00:08:03,000
the kind of spherical nature of latitude

210
00:08:01,479 --> 00:08:04,360
longitude coordinates you can use

211
00:08:03,000 --> 00:08:07,039
something like a spherical kernel but

212
00:08:04,360 --> 00:08:09,919
again there's some some

213
00:08:07,039 --> 00:08:12,039
shortcomings so uh we are machine

214
00:08:09,919 --> 00:08:13,720
learning people right so why don't we

215
00:08:12,039 --> 00:08:16,120
just replace the Gan process with a

216
00:08:13,720 --> 00:08:19,879
neural network and uh solve all of these

217
00:08:16,120 --> 00:08:22,280
problems unfortunately that's not uh not

218
00:08:19,879 --> 00:08:23,879
so simple either because um new networks

219
00:08:22,280 --> 00:08:26,120
also have some problems sure they scale

220
00:08:23,879 --> 00:08:28,759
better but they also for example don't

221
00:08:26,120 --> 00:08:30,680
necessarily work on um spherical

222
00:08:28,759 --> 00:08:34,399
coordinates and can deal with the kind

223
00:08:30,680 --> 00:08:37,680
of non-clear nature of geographic

224
00:08:34,399 --> 00:08:39,240
coordinates so what we do here is then

225
00:08:37,680 --> 00:08:40,959
we want to kind of build the best of

226
00:08:39,240 --> 00:08:44,120
both worlds uh neural network

227
00:08:40,959 --> 00:08:45,640
architecture that is able to deal with

228
00:08:44,120 --> 00:08:47,560
the spherical nature of the coordinates

229
00:08:45,640 --> 00:08:50,279
and that is the geographic location

230
00:08:47,560 --> 00:08:53,600
encoder and the idea here is

231
00:08:50,279 --> 00:08:55,320
to First embed our location coordinates

232
00:08:53,600 --> 00:08:57,040
or latitude longitude using some

233
00:08:55,320 --> 00:08:58,440
positional encoding this is if you're

234
00:08:57,040 --> 00:09:00,120
familiar with Transformer architectures

235
00:08:58,440 --> 00:09:02,360
is basically very similar to our

236
00:09:00,120 --> 00:09:04,200
Transformers to positional encodings and

237
00:09:02,360 --> 00:09:06,279
then we put a neural network on top that

238
00:09:04,200 --> 00:09:08,279
learns a weighted function of these

239
00:09:06,279 --> 00:09:10,399
positional encodings to solve our task

240
00:09:08,279 --> 00:09:12,760
at

241
00:09:10,399 --> 00:09:15,000
hand and hopefully this can then scale

242
00:09:12,760 --> 00:09:16,480
to really high dimensional data and

243
00:09:15,000 --> 00:09:18,240
again we kind of do the same thing we

244
00:09:16,480 --> 00:09:21,160
would do in a GP and learn this

245
00:09:18,240 --> 00:09:23,320
continuous function over

246
00:09:21,160 --> 00:09:26,160
space the other thing we can do with

247
00:09:23,320 --> 00:09:28,399
this is um that location encoders also

248
00:09:26,160 --> 00:09:30,040
give us the flexibility to integrate

249
00:09:28,399 --> 00:09:32,519
them with other neuron Network models

250
00:09:30,040 --> 00:09:35,480
specialized for different inputs for

251
00:09:32,519 --> 00:09:38,920
example images and this is the idea that

252
00:09:35,480 --> 00:09:41,200
um behind Geographic priors so for

253
00:09:38,920 --> 00:09:42,600
example here we have a image

254
00:09:41,200 --> 00:09:45,760
classification task where we want to

255
00:09:42,600 --> 00:09:48,399
classify the image of this uh this fox

256
00:09:45,760 --> 00:09:50,240
this this is an arctic fox if you think

257
00:09:48,399 --> 00:09:52,800
about this task kind of location

258
00:09:50,240 --> 00:09:54,360
agnostically um it might be a bit

259
00:09:52,800 --> 00:09:56,880
difficult to exactly place as animals

260
00:09:54,360 --> 00:09:59,399
foxes are all around the world but

261
00:09:56,880 --> 00:10:01,600
knowing the location of the fox will

262
00:09:59,399 --> 00:10:03,320
allow a model to learn uh internally

263
00:10:01,600 --> 00:10:05,760
some some sort of species distribution

264
00:10:03,320 --> 00:10:07,360
model and will um have the model learn

265
00:10:05,760 --> 00:10:09,360
that you can only find the species in

266
00:10:07,360 --> 00:10:11,560
certain um

267
00:10:09,360 --> 00:10:13,440
latitudes and so Geographic priors are

268
00:10:11,560 --> 00:10:15,760
relevant for for many different um

269
00:10:13,440 --> 00:10:17,880
applications not just kind of species

270
00:10:15,760 --> 00:10:22,240
classification but for example also for

271
00:10:17,880 --> 00:10:22,240
building segmentation or soil carbon

272
00:10:22,399 --> 00:10:27,399
estimation all right so done with part

273
00:10:25,760 --> 00:10:29,880
one the kind of description of the

274
00:10:27,399 --> 00:10:34,079
spatial modeling problem let's let's go

275
00:10:29,880 --> 00:10:37,880
into part two um the location encoding

276
00:10:34,079 --> 00:10:42,800
uh uh yeah Basics and this is mostly

277
00:10:37,880 --> 00:10:44,320
based on our iar 24 Spotlight paper um

278
00:10:42,800 --> 00:10:47,440
which you can all check

279
00:10:44,320 --> 00:10:50,680
out so here I briefly describe how uh

280
00:10:47,440 --> 00:10:52,000
location coders should be designed um

281
00:10:50,680 --> 00:10:55,040
how they were designed in the past and

282
00:10:52,000 --> 00:10:55,040
what the current stateof the art

283
00:10:55,440 --> 00:11:00,240
is all right so let's start with a few

284
00:10:58,320 --> 00:11:03,320
formalities about encoders I'm not going

285
00:11:00,240 --> 00:11:05,560
to go into all too much detail um but

286
00:11:03,320 --> 00:11:09,120
basically this is the very simple form

287
00:11:05,560 --> 00:11:11,440
they take you have your locations C so

288
00:11:09,120 --> 00:11:14,839
these are latitude longitude coordinate

289
00:11:11,440 --> 00:11:16,399
pairs um that are fed through a

290
00:11:14,839 --> 00:11:18,440
positional encoding this is purely

291
00:11:16,399 --> 00:11:21,519
functional transform right so there's no

292
00:11:18,440 --> 00:11:23,320
learnable parameters there and then the

293
00:11:21,519 --> 00:11:25,440
output from this positional encoding is

294
00:11:23,320 --> 00:11:27,120
going to be fed into our neural network

295
00:11:25,440 --> 00:11:30,040
which has learnable parameters and that

296
00:11:27,120 --> 00:11:32,040
is our location inorder quite simple but

297
00:11:30,040 --> 00:11:34,480
of course we can do a few different uh

298
00:11:32,040 --> 00:11:38,440
modifications here and the first one I

299
00:11:34,480 --> 00:11:39,920
want to talk about is the history of the

300
00:11:38,440 --> 00:11:41,880
different positional encodings that were

301
00:11:39,920 --> 00:11:43,120
used the kind of first positional en

302
00:11:41,880 --> 00:11:46,440
coding we can look at in the machine

303
00:11:43,120 --> 00:11:49,120
learning literature is from a 2015 cvpr

304
00:11:46,440 --> 00:11:51,320
paper that does very very simple one hot

305
00:11:49,120 --> 00:11:52,760
encoding of the coordinates so the idea

306
00:11:51,320 --> 00:11:55,519
is that you split your whole world into

307
00:11:52,760 --> 00:11:57,600
grid cells um each of the grid cells is

308
00:11:55,519 --> 00:11:59,440
um yeah one value in your tensor let's

309
00:11:57,600 --> 00:12:00,920
say and all of them are zero value

310
00:11:59,440 --> 00:12:04,399
except the one grid cell that your

311
00:12:00,920 --> 00:12:06,480
location Falls in that's a one so very

312
00:12:04,399 --> 00:12:09,320
simple similar to other one encoding

313
00:12:06,480 --> 00:12:10,760
methods in in other areas obviously not

314
00:12:09,320 --> 00:12:15,199
the most sophisticated positional

315
00:12:10,760 --> 00:12:16,959
encoding and so in 2019 allet cvpr um we

316
00:12:15,199 --> 00:12:19,519
saw kind of the first bit more

317
00:12:16,959 --> 00:12:20,800
sophisticated version of uh positional

318
00:12:19,519 --> 00:12:23,839
encodings and that was the first

319
00:12:20,800 --> 00:12:25,560
sinusoidal one um same paper as the

320
00:12:23,839 --> 00:12:27,600
paper I talked about before with

321
00:12:25,560 --> 00:12:29,680
Geographic priors and image

322
00:12:27,600 --> 00:12:33,440
classification of um an

323
00:12:29,680 --> 00:12:36,399
images and so here the idea is to um use

324
00:12:33,440 --> 00:12:38,880
S cosine activations very much again the

325
00:12:36,399 --> 00:12:40,399
same attrition as for Transformers um

326
00:12:38,880 --> 00:12:42,120
and so here you project your latitude

327
00:12:40,399 --> 00:12:43,800
longitude coordinates in from two

328
00:12:42,120 --> 00:12:46,920
dimensional space into four dimensional

329
00:12:43,800 --> 00:12:49,000
space doing cosine lat cosine long and S

330
00:12:46,920 --> 00:12:51,360
lat sign

331
00:12:49,000 --> 00:12:52,720
long and over the recent years the kind

332
00:12:51,360 --> 00:12:55,000
of state of the art has been to make

333
00:12:52,720 --> 00:12:56,600
more sophisticated versions of this for

334
00:12:55,000 --> 00:12:59,639
example the multiscale sinusoidal

335
00:12:56,600 --> 00:13:01,920
encoding where you basically do the same

336
00:12:59,639 --> 00:13:04,360
s cosine functions but you do it at

337
00:13:01,920 --> 00:13:08,320
different frequencies um basically by

338
00:13:04,360 --> 00:13:09,880
dividing um dividing the um values by

339
00:13:08,320 --> 00:13:12,120
this Alpha here which is your scaling

340
00:13:09,880 --> 00:13:14,600
factor and you can do that at arbitrary

341
00:13:12,120 --> 00:13:18,079
intervals to get more and more F fine

342
00:13:14,600 --> 00:13:18,079
grained um uh

343
00:13:19,720 --> 00:13:25,320
embeddings all right so this is kind of

344
00:13:22,000 --> 00:13:26,959
the work up until maybe 24 um but there

345
00:13:25,320 --> 00:13:28,360
has not really been a fundamental shift

346
00:13:26,959 --> 00:13:30,880
in the way these positional encodings

347
00:13:28,360 --> 00:13:32,920
were done in in this kind of sign coign

348
00:13:30,880 --> 00:13:34,600
formation and the work that we're doing

349
00:13:32,920 --> 00:13:35,360
is changing this and I'll get to that in

350
00:13:34,600 --> 00:13:37,959
a

351
00:13:35,360 --> 00:13:40,040
second the other part of the position of

352
00:13:37,959 --> 00:13:41,880
the location encoder has remained vastly

353
00:13:40,040 --> 00:13:45,160
unchanged over the last years and that

354
00:13:41,880 --> 00:13:46,959
is the neural network component so

355
00:13:45,160 --> 00:13:49,839
basically what people have been used

356
00:13:46,959 --> 00:13:52,720
here is simple um fully connected layers

357
00:13:49,839 --> 00:13:54,839
or simple MLPs um this is also something

358
00:13:52,720 --> 00:13:57,320
we're going to change in our

359
00:13:54,839 --> 00:13:59,440
paper and the reason why we adapt this a

360
00:13:57,320 --> 00:14:03,040
little bit is that existing location

361
00:13:59,440 --> 00:14:05,079
encoders um up until us had two major

362
00:14:03,040 --> 00:14:06,759
shortcomings first performance of these

363
00:14:05,079 --> 00:14:09,120
location encoders falls off drastically

364
00:14:06,759 --> 00:14:11,000
around the poles and the reason for that

365
00:14:09,120 --> 00:14:13,800
is that these location encoders use sign

366
00:14:11,000 --> 00:14:16,600
cosine um positional encodings um that

367
00:14:13,800 --> 00:14:17,880
isum in space and around the poles this

368
00:14:16,600 --> 00:14:20,199
diverges the most from the true

369
00:14:17,880 --> 00:14:22,480
spherical space of of our planet and so

370
00:14:20,199 --> 00:14:25,600
we should probably replace them the

371
00:14:22,480 --> 00:14:27,800
other problem is that simple uh fully

372
00:14:25,600 --> 00:14:30,040
connected networks are not necessarily

373
00:14:27,800 --> 00:14:31,959
equipped to learn these kind of smooth

374
00:14:30,040 --> 00:14:34,600
spatial functions that we want uh smooth

375
00:14:31,959 --> 00:14:36,079
functions over space that we want and so

376
00:14:34,600 --> 00:14:39,519
we want to tackle both of these problems

377
00:14:36,079 --> 00:14:41,920
at once in our uh work and the solution

378
00:14:39,519 --> 00:14:44,279
for the kind of first problem uh in the

379
00:14:41,920 --> 00:14:45,800
positional encoding is that we using

380
00:14:44,279 --> 00:14:49,399
spherical harmonics functions in setad

381
00:14:45,800 --> 00:14:51,240
of simple s cosine activations and the

382
00:14:49,399 --> 00:14:53,199
um the answer for the second problem is

383
00:14:51,240 --> 00:14:54,839
that we don't just use a fully connect

384
00:14:53,199 --> 00:14:56,959
networks but we use sinos soidal

385
00:14:54,839 --> 00:14:59,759
representation networks so s activation

386
00:14:56,959 --> 00:15:01,600
functions

387
00:14:59,759 --> 00:15:03,199
um yeah let me get a little bit into

388
00:15:01,600 --> 00:15:05,399
into the first component the spherical

389
00:15:03,199 --> 00:15:07,480
harmonics positional encoding so

390
00:15:05,399 --> 00:15:10,240
spherical harmonics are widely used in

391
00:15:07,480 --> 00:15:12,800
ge6 fluid dynamics to model our planet

392
00:15:10,240 --> 00:15:13,480
so this is kind of the St status quo in

393
00:15:12,800 --> 00:15:17,480
in

394
00:15:13,480 --> 00:15:19,160
geophysics um and I'm not going to um go

395
00:15:17,480 --> 00:15:21,639
much into the math here but basically

396
00:15:19,160 --> 00:15:23,000
spheric LM monics are um orthogonal

397
00:15:21,639 --> 00:15:24,480
basis functions that are natively

398
00:15:23,000 --> 00:15:27,959
defined on the

399
00:15:24,480 --> 00:15:31,560
sphere and um they come in different um

400
00:15:27,959 --> 00:15:33,199
numbers of degrees L and uh or as M um

401
00:15:31,560 --> 00:15:35,079
this is kind of the full function here

402
00:15:33,199 --> 00:15:37,440
but I guess in the interest of time also

403
00:15:35,079 --> 00:15:38,839
not going to go too much into this um

404
00:15:37,440 --> 00:15:41,040
and while there is a closed form

405
00:15:38,839 --> 00:15:43,240
solution for um for the spheric

406
00:15:41,040 --> 00:15:45,480
harmonics uh we can also analytically

407
00:15:43,240 --> 00:15:48,120
pre-compute them which is really nice

408
00:15:45,480 --> 00:15:51,839
later on in our neural network training

409
00:15:48,120 --> 00:15:54,160
because that makes everything much

410
00:15:51,839 --> 00:15:56,000
faster now there is a really cool

411
00:15:54,160 --> 00:15:58,000
theorem that says that any function on

412
00:15:56,000 --> 00:16:00,040
this sphere can be approximated by a

413
00:15:58,000 --> 00:16:01,959
weighted sum of spherical armonics

414
00:16:00,040 --> 00:16:04,199
functions and so the question now

415
00:16:01,959 --> 00:16:05,279
becomes how do we get these weights for

416
00:16:04,199 --> 00:16:07,600
the weighted spherical armonics

417
00:16:05,279 --> 00:16:09,240
functions and our answer is that we use

418
00:16:07,600 --> 00:16:11,120
a neural network to get these weights so

419
00:16:09,240 --> 00:16:13,440
we use a neural network on top of our

420
00:16:11,120 --> 00:16:15,720
spherical harmonics positional encodings

421
00:16:13,440 --> 00:16:18,680
to yeah hopefully approximate any

422
00:16:15,720 --> 00:16:20,959
function on the sphere and to better

423
00:16:18,680 --> 00:16:23,360
learn smooth spatial patterns we use a

424
00:16:20,959 --> 00:16:25,360
neural network uh architecture that

425
00:16:23,360 --> 00:16:26,920
comes out of vision especially 3D Vision

426
00:16:25,360 --> 00:16:28,920
and that is the sinusoidal

427
00:16:26,920 --> 00:16:30,839
representation Network that was actually

428
00:16:28,920 --> 00:16:33,800
proposed by Vincent sitzman who is right

429
00:16:30,839 --> 00:16:35,319
here at MIT um and yeah they've been

430
00:16:33,800 --> 00:16:37,440
shown to be extremely effective at

431
00:16:35,319 --> 00:16:39,079
learning neural implicit representation

432
00:16:37,440 --> 00:16:41,199
which are again these functions that are

433
00:16:39,079 --> 00:16:43,279
continuous in space and you can think

434
00:16:41,199 --> 00:16:45,920
about this from a kind of 3D Vision

435
00:16:43,279 --> 00:16:47,800
perspective uh as a point Cloud problem

436
00:16:45,920 --> 00:16:50,639
we have Point clouds in 3D space and you

437
00:16:47,800 --> 00:16:53,199
want to build some um continuous mesh or

438
00:16:50,639 --> 00:16:55,680
map out of them and basically we have

439
00:16:53,199 --> 00:16:58,480
the exactly same problem uh on the

440
00:16:55,680 --> 00:17:00,800
sphere of our planet and the trick with

441
00:16:58,480 --> 00:17:02,639
s sinal representation networks is

442
00:17:00,800 --> 00:17:03,920
really really really really simple and

443
00:17:02,639 --> 00:17:06,199
it's just changing the activation

444
00:17:03,920 --> 00:17:07,959
function in network to sign activation

445
00:17:06,199 --> 00:17:10,319
function that leads to some

446
00:17:07,959 --> 00:17:11,679
computational issues um if if you stack

447
00:17:10,319 --> 00:17:14,439
a lot of these layers because

448
00:17:11,679 --> 00:17:16,760
computation gets gets more important uh

449
00:17:14,439 --> 00:17:19,079
gets more expensive but we're not really

450
00:17:16,760 --> 00:17:22,280
dealing with large neural networks

451
00:17:19,079 --> 00:17:24,640
here all right and then again we

452
00:17:22,280 --> 00:17:26,679
hopefully can um learn this kind of

453
00:17:24,640 --> 00:17:29,880
weighted sperical harmonics to solve

454
00:17:26,679 --> 00:17:33,000
functions on the sphere and um let's put

455
00:17:29,880 --> 00:17:35,760
things together um we can use location

456
00:17:33,000 --> 00:17:37,880
encoders just like we would use caution

457
00:17:35,760 --> 00:17:39,799
processes or other interpolation methods

458
00:17:37,880 --> 00:17:41,720
and learn from kind of sparse

459
00:17:39,799 --> 00:17:44,600
observation a continuous map in

460
00:17:41,720 --> 00:17:47,480
spherical space for example we can use

461
00:17:44,600 --> 00:17:49,919
them to learn a map of land mass

462
00:17:47,480 --> 00:17:52,400
globally right so here we sample let's

463
00:17:49,919 --> 00:17:54,400
say 5,000 locations on the planet we

464
00:17:52,400 --> 00:17:56,280
give them each a zero value if it's

465
00:17:54,400 --> 00:17:59,600
water not land mass or one if it's land

466
00:17:56,280 --> 00:18:01,720
mass and then using our um spheric

467
00:17:59,600 --> 00:18:05,039
harmonics location encoder we built like

468
00:18:01,720 --> 00:18:06,960
a dense map and you see depending on how

469
00:18:05,039 --> 00:18:09,440
you set your scale this works quite

470
00:18:06,960 --> 00:18:12,360
well let's look at the two components of

471
00:18:09,440 --> 00:18:15,320
our uh new location encoder separately

472
00:18:12,360 --> 00:18:17,240
um so first siren neural Nets are better

473
00:18:15,320 --> 00:18:20,159
than existing linear or fully connected

474
00:18:17,240 --> 00:18:21,520
backbones for learning spatial patterns

475
00:18:20,159 --> 00:18:23,159
which you can see here right so on the

476
00:18:21,520 --> 00:18:25,080
top we have kind of the exact same

477
00:18:23,159 --> 00:18:27,039
positional and quarter backbone or

478
00:18:25,080 --> 00:18:29,120
monics but on the top you see a linear

479
00:18:27,039 --> 00:18:32,159
neural network and on the bottom you see

480
00:18:29,120 --> 00:18:34,440
a siren neural network um the L5

481
00:18:32,159 --> 00:18:36,640
hyperparameter here um that's basically

482
00:18:34,440 --> 00:18:38,760
the number of lra polinomial we use in

483
00:18:36,640 --> 00:18:40,640
our sperical harmonic so the higher the

484
00:18:38,760 --> 00:18:42,880
more fine grain our spatial resolution

485
00:18:40,640 --> 00:18:44,559
is which you can also see and you see

486
00:18:42,880 --> 00:18:47,240
that the the S neural network just gets

487
00:18:44,559 --> 00:18:47,240
much better

488
00:18:47,320 --> 00:18:51,400
resolution now let's look at the other

489
00:18:49,640 --> 00:18:53,400
component the spherical harmonics

490
00:18:51,400 --> 00:18:55,440
positional encoding and here we want to

491
00:18:53,400 --> 00:18:57,039
specifically focus on the polls areas

492
00:18:55,440 --> 00:18:59,000
remember there I said that existing

493
00:18:57,039 --> 00:19:01,320
methods often fall short on the poll

494
00:18:59,000 --> 00:19:03,600
because the assumed ucan space of kind

495
00:19:01,320 --> 00:19:06,880
of Foria transforms diverges the most

496
00:19:03,600 --> 00:19:08,760
from the actual spherical space um let's

497
00:19:06,880 --> 00:19:11,240
look again at our arctic fox so here we

498
00:19:08,760 --> 00:19:13,679
do arctic fox image classification and

499
00:19:11,240 --> 00:19:15,919
you can see that a model that uses one

500
00:19:13,679 --> 00:19:18,360
of the existing positional encodings

501
00:19:15,919 --> 00:19:20,559
that is not um spherical harmonics based

502
00:19:18,360 --> 00:19:22,799
um has much more artifacts that are

503
00:19:20,559 --> 00:19:26,360
completely far from the poles compared

504
00:19:22,799 --> 00:19:28,000
to our method um another example here

505
00:19:26,360 --> 00:19:29,280
this this a different um this is

506
00:19:28,000 --> 00:19:31,880
synthetic task

507
00:19:29,280 --> 00:19:33,520
Fibonacci checker board prediction um

508
00:19:31,880 --> 00:19:35,400
here you can see in the figure the red

509
00:19:33,520 --> 00:19:37,320
line is our spec harmonics method and

510
00:19:35,400 --> 00:19:39,919
you see that it remains quite accurate

511
00:19:37,320 --> 00:19:42,240
around the polls whereas other s cosine

512
00:19:39,919 --> 00:19:45,559
base methods fall a bit off

513
00:19:42,240 --> 00:19:47,799
here all right so that's it for part two

514
00:19:45,559 --> 00:19:49,200
to recap so far we've discussed how to

515
00:19:47,799 --> 00:19:51,520
design state-of-the-art location

516
00:19:49,200 --> 00:19:53,640
encoders and how to train them directly

517
00:19:51,520 --> 00:19:56,320
right so here the input was L long and

518
00:19:53,640 --> 00:19:59,559
the output was some value right landm

519
00:19:56,320 --> 00:20:02,159
yes yes no or um some climate variable

520
00:19:59,559 --> 00:20:04,720
right so we have like a direct um

521
00:20:02,159 --> 00:20:06,679
classification or prediction problem the

522
00:20:04,720 --> 00:20:08,120
next part of the talk will focus on

523
00:20:06,679 --> 00:20:10,520
pre-training location in quars with

524
00:20:08,120 --> 00:20:13,600
unlabeled Earth observation data and how

525
00:20:10,520 --> 00:20:16,120
this can help us improve modeling

526
00:20:13,600 --> 00:20:17,880
Downstream and this I should have

527
00:20:16,120 --> 00:20:19,679
updated that slide so this work is based

528
00:20:17,880 --> 00:20:22,039
on our paper sack clip which is not

529
00:20:19,679 --> 00:20:24,320
under submission anymore but a tria AI

530
00:20:22,039 --> 00:20:26,360
paper uh next week in Philadelphia if

531
00:20:24,320 --> 00:20:30,440
you're

532
00:20:26,360 --> 00:20:32,679
on and why do need the step um so far

533
00:20:30,440 --> 00:20:33,760
we've basic basically only talked about

534
00:20:32,679 --> 00:20:36,080
spatial

535
00:20:33,760 --> 00:20:38,120
interpolation but a big question in

536
00:20:36,080 --> 00:20:41,200
geospatial modeling is of course also

537
00:20:38,120 --> 00:20:43,440
can we do extrapolation and um spatial

538
00:20:41,200 --> 00:20:44,880
extrapolation describes the problem when

539
00:20:43,440 --> 00:20:47,840
we want to make a prediction

540
00:20:44,880 --> 00:20:50,440
geographically far from our training set

541
00:20:47,840 --> 00:20:51,880
and we cannot rely on the first law of

542
00:20:50,440 --> 00:20:54,200
geography or just kind of looking at

543
00:20:51,880 --> 00:20:57,120
nearby um observations because we just

544
00:20:54,200 --> 00:20:59,159
don't have any nearby observations and I

545
00:20:57,120 --> 00:21:01,760
believe that using this globally

546
00:20:59,159 --> 00:21:03,600
available Earth observation data and our

547
00:21:01,760 --> 00:21:05,760
um location and quoda models that we can

548
00:21:03,600 --> 00:21:08,039
actually make a big step towards kind of

549
00:21:05,760 --> 00:21:10,760
more General approaches for uh

550
00:21:08,039 --> 00:21:12,520
Geographic extrapolation which is one of

551
00:21:10,760 --> 00:21:15,840
the kind of big long-standing problems

552
00:21:12,520 --> 00:21:15,840
in uh geospatial

553
00:21:16,400 --> 00:21:22,919
modeling and to kind of outline the

554
00:21:19,320 --> 00:21:25,360
intuition for that a little bit um I

555
00:21:22,919 --> 00:21:27,640
want you to think about the Earth as a

556
00:21:25,360 --> 00:21:29,480
bounded space right it's a completely

557
00:21:27,640 --> 00:21:32,000
bounded space we can kind of capture all

558
00:21:29,480 --> 00:21:33,679
of the planet with satellites and sure

559
00:21:32,000 --> 00:21:35,200
some areas might have more or less cloud

560
00:21:33,679 --> 00:21:36,840
coverage but in the end we can kind of

561
00:21:35,200 --> 00:21:39,640
observe everything plus there are

562
00:21:36,840 --> 00:21:43,760
sensors that see through clouds like

563
00:21:39,640 --> 00:21:46,320
radar um and now if we assume that Earth

564
00:21:43,760 --> 00:21:49,480
observation data is roughly relevant to

565
00:21:46,320 --> 00:21:51,640
a lot of tasks we can hopefully leverage

566
00:21:49,480 --> 00:21:53,400
this kind of data to capture ground

567
00:21:51,640 --> 00:21:55,840
conditions that are relevant to our

568
00:21:53,400 --> 00:21:57,440
tasks um and Infuse them in our location

569
00:21:55,840 --> 00:22:00,520
and quarters and have them available for

570
00:21:57,440 --> 00:22:00,520
the whole world

571
00:22:00,960 --> 00:22:05,080
but the question is how do we go about

572
00:22:02,760 --> 00:22:07,320
this pre-training all right so again the

573
00:22:05,080 --> 00:22:09,000
intuition is location encoders fail when

574
00:22:07,320 --> 00:22:11,360
deployed in unseen

575
00:22:09,000 --> 00:22:13,039
areas question is can we pre-train them

576
00:22:11,360 --> 00:22:16,279
on globally available Earth observation

577
00:22:13,039 --> 00:22:18,919
data so no error remains

578
00:22:16,279 --> 00:22:22,320
unseen and to revisit our kind of Arctic

579
00:22:18,919 --> 00:22:24,520
fox um prediction task instead of doing

580
00:22:22,320 --> 00:22:27,159
this conditioning on the geographic

581
00:22:24,520 --> 00:22:28,960
location um like from scratch basically

582
00:22:27,159 --> 00:22:30,760
just feeding in the coordinates can we

583
00:22:28,960 --> 00:22:33,279
instead of just the coordinates feed in

584
00:22:30,760 --> 00:22:35,960
some semantically meaningful Vector

585
00:22:33,279 --> 00:22:39,640
embedding that represents this

586
00:22:35,960 --> 00:22:40,919
location and to get to this embedding um

587
00:22:39,640 --> 00:22:43,039
and to explain the intrution for how

588
00:22:40,919 --> 00:22:45,720
this pre-training works um I have a

589
00:22:43,039 --> 00:22:47,480
little game that we can play and the

590
00:22:45,720 --> 00:22:51,039
game is called uh where is this

591
00:22:47,480 --> 00:22:53,440
satellite image so um hopefully you can

592
00:22:51,039 --> 00:22:55,360
yeah basically geog guesser but geaser

593
00:22:53,440 --> 00:22:58,559
is like with street view imagery now you

594
00:22:55,360 --> 00:23:01,559
have the satellite view right so um yeah

595
00:22:58,559 --> 00:23:05,240
anyone have any idea where this image is

596
00:23:01,559 --> 00:23:06,799
Sara Sahara okay any other guesses we

597
00:23:05,240 --> 00:23:11,279
have

598
00:23:06,799 --> 00:23:13,600
Sahara that's uh Northern Africa e

599
00:23:11,279 --> 00:23:15,320
Eastern what Eastern Africa Eastern

600
00:23:13,600 --> 00:23:18,600
Africa

601
00:23:15,320 --> 00:23:22,720
okay any other guesses Boston

602
00:23:18,600 --> 00:23:24,679
har Boston Harbor Boston Harbor okay I

603
00:23:22,720 --> 00:23:26,120
think so I actually need to see because

604
00:23:24,679 --> 00:23:28,799
I don't think you can see it so well

605
00:23:26,120 --> 00:23:31,320
scale like what is this oh oh yeah yeah

606
00:23:28,799 --> 00:23:35,840
yeah so this is

607
00:23:31,320 --> 00:23:35,840
um 2.5 by 2.5

608
00:23:37,559 --> 00:23:41,919
km I think it's a bit hard with the Bea

609
00:23:40,080 --> 00:23:43,559
view this is always a bit the tricky bit

610
00:23:41,919 --> 00:23:45,080
of the the talk because it kind of

611
00:23:43,559 --> 00:23:49,320
always depends like at least the screen

612
00:23:45,080 --> 00:23:50,679
is very big okay so everyone's guess was

613
00:23:49,320 --> 00:23:53,880
very

614
00:23:50,679 --> 00:23:55,279
wrong this is a picture in the in the

615
00:23:53,880 --> 00:23:59,200
Arctic somewhere in

616
00:23:55,279 --> 00:24:01,159
Canada and um so this now we know where

617
00:23:59,200 --> 00:24:04,080
this picture is what I want you to do

618
00:24:01,159 --> 00:24:06,360
next is I want you to think about if you

619
00:24:04,080 --> 00:24:08,640
now know this location think about what

620
00:24:06,360 --> 00:24:11,760
characteristics in this image might make

621
00:24:08,640 --> 00:24:13,799
you think of that location and um again

622
00:24:11,760 --> 00:24:16,520
so I have I I happen to know where this

623
00:24:13,799 --> 00:24:18,400
is um and so I can walk you a little bit

624
00:24:16,520 --> 00:24:21,080
through what I think are kind of

625
00:24:18,400 --> 00:24:22,799
relevant characteristics so in the top

626
00:24:21,080 --> 00:24:23,960
here we have this little little white

627
00:24:22,799 --> 00:24:26,760
patch I don't know if you can see it

628
00:24:23,960 --> 00:24:29,760
well which could be snow then we have

629
00:24:26,760 --> 00:24:32,120
this rugged kind of

630
00:24:29,760 --> 00:24:34,200
maybe glacial morine and then down here

631
00:24:32,120 --> 00:24:35,440
and this is the bit you can't really see

632
00:24:34,200 --> 00:24:37,159
because of the contrast but there's the

633
00:24:35,440 --> 00:24:40,760
coastline here right so there's some

634
00:24:37,159 --> 00:24:42,399
water here and all in all these three

635
00:24:40,760 --> 00:24:43,960
features might give you some indication

636
00:24:42,399 --> 00:24:47,799
that this is kind of in the in the

637
00:24:43,960 --> 00:24:49,320
Arctic Circle and the true location um

638
00:24:47,799 --> 00:24:50,799
can actually be predicted quite well

639
00:24:49,320 --> 00:24:52,240
with the neural network and this is

640
00:24:50,799 --> 00:24:53,320
exactly how we're going to pre-train our

641
00:24:52,240 --> 00:24:57,360
location

642
00:24:53,320 --> 00:25:01,240
encoder and the way we do this is very

643
00:24:57,360 --> 00:25:02,960
much similar to clip clip is a model by

644
00:25:01,240 --> 00:25:06,840
open air that matches text and image

645
00:25:02,960 --> 00:25:08,919
pairs only in our model we we match um

646
00:25:06,840 --> 00:25:10,559
image and location pairs right so we

647
00:25:08,919 --> 00:25:13,080
take a bunch of globally distributed

648
00:25:10,559 --> 00:25:15,279
Sentinel to images with their

649
00:25:13,080 --> 00:25:17,240
corresponding locations and then we have

650
00:25:15,279 --> 00:25:18,520
a contrastive learning objective where

651
00:25:17,240 --> 00:25:20,640
we feed our images through an image

652
00:25:18,520 --> 00:25:23,080
encoder locations through an location

653
00:25:20,640 --> 00:25:26,679
encoder and then we match the correct

654
00:25:23,080 --> 00:25:28,960
images with the correct locations in a

655
00:25:26,679 --> 00:25:32,039
batch and the idea is understand that if

656
00:25:28,960 --> 00:25:34,200
this training succeeds we can take

657
00:25:32,039 --> 00:25:36,039
forward this location encoder and obtain

658
00:25:34,200 --> 00:25:38,559
semantically meaningful embeddings for

659
00:25:36,039 --> 00:25:41,120
every single location on the planet and

660
00:25:38,559 --> 00:25:43,279
if we train this on enough data this

661
00:25:41,120 --> 00:25:45,640
model should learn to interpolate and

662
00:25:43,279 --> 00:25:47,000
even work for unseen locations because

663
00:25:45,640 --> 00:25:49,240
because it will interpolate from the

664
00:25:47,000 --> 00:25:51,120
nearest seen observations leveraging the

665
00:25:49,240 --> 00:25:53,880
first law of geography and learn this

666
00:25:51,120 --> 00:25:57,640
kind of smooth embedding map so to

667
00:25:53,880 --> 00:25:59,399
say and yeah so the way this works um is

668
00:25:57,640 --> 00:26:01,039
that you have like a bunch of different

669
00:25:59,399 --> 00:26:02,120
um image embeddings you get of course

670
00:26:01,039 --> 00:26:03,679
and you have a bunch of different

671
00:26:02,120 --> 00:26:05,600
location embeddings you get but

672
00:26:03,679 --> 00:26:09,279
throughout this matching process you

673
00:26:05,600 --> 00:26:11,080
learn to align them and to transfer the

674
00:26:09,279 --> 00:26:13,799
features that make an image look unique

675
00:26:11,080 --> 00:26:15,480
to a location into the location encoder

676
00:26:13,799 --> 00:26:17,279
and so now Downstream you don't need

677
00:26:15,480 --> 00:26:18,919
images at all anymore because you assume

678
00:26:17,279 --> 00:26:20,720
that the most important image features

679
00:26:18,919 --> 00:26:22,480
are now part of the weights of your

680
00:26:20,720 --> 00:26:24,120
location encoder and you just have a

681
00:26:22,480 --> 00:26:26,120
model that takes in latitude longitude

682
00:26:24,120 --> 00:26:29,120
and returns these embeddings the

683
00:26:26,120 --> 00:26:30,679
embeddings in our case are um 256

684
00:26:29,120 --> 00:26:32,960
characters long so they're not really

685
00:26:30,679 --> 00:26:34,600
able to capture super super granular

686
00:26:32,960 --> 00:26:36,880
structure like how many cars are in this

687
00:26:34,600 --> 00:26:38,000
picture or so they only capture very

688
00:26:36,880 --> 00:26:40,360
high level

689
00:26:38,000 --> 00:26:42,039
features and one of the high level

690
00:26:40,360 --> 00:26:44,399
features that they capture that we can

691
00:26:42,039 --> 00:26:48,080
show is biomes right so here you have a

692
00:26:44,399 --> 00:26:50,159
dense biom map of the whole world um and

693
00:26:48,080 --> 00:26:52,880
now again think of a interpolation task

694
00:26:50,159 --> 00:26:54,559
right so you take 5,000 uh random

695
00:26:52,880 --> 00:26:56,679
locations and try to build this map from

696
00:26:54,559 --> 00:26:58,919
scratch again from these 5,000 locations

697
00:26:56,679 --> 00:27:01,559
sparse location uh sparse location build

698
00:26:58,919 --> 00:27:03,120
a dense map if you do this just using

699
00:27:01,559 --> 00:27:05,919
the location encoder trained from

700
00:27:03,120 --> 00:27:09,159
scratch no pre-training with our sa clip

701
00:27:05,919 --> 00:27:12,440
method you get to this map so you get um

702
00:27:09,159 --> 00:27:14,960
not a very good um accurate map of

703
00:27:12,440 --> 00:27:17,720
biomes now if you do this using our

704
00:27:14,960 --> 00:27:22,399
pre-trained um location encoder instead

705
00:27:17,720 --> 00:27:24,240
you get to very accurate biomap so we um

706
00:27:22,399 --> 00:27:26,000
basically see through this that our our

707
00:27:24,240 --> 00:27:28,279
sack clip

708
00:27:26,000 --> 00:27:30,799
embeddings excuse me capture at least

709
00:27:28,279 --> 00:27:32,960
some degree the conditions that make out

710
00:27:30,799 --> 00:27:32,960
a

711
00:27:33,159 --> 00:27:38,080
biome now this is an interpolation

712
00:27:36,279 --> 00:27:39,880
problem and uh when I started this

713
00:27:38,080 --> 00:27:41,720
section of the talk I said that sap can

714
00:27:39,880 --> 00:27:43,799
be really useful for extrapolation right

715
00:27:41,720 --> 00:27:46,679
so what am I doing with interpolation

716
00:27:43,799 --> 00:27:48,240
and to explain that a little bit I will

717
00:27:46,679 --> 00:27:51,360
we play a second round of the game and

718
00:27:48,240 --> 00:27:53,679
the second run of uh of the game um has

719
00:27:51,360 --> 00:27:54,720
now this image and again question is

720
00:27:53,679 --> 00:28:00,519
where is

721
00:27:54,720 --> 00:28:00,519
this can I again have some some

722
00:28:06,080 --> 00:28:11,279
thoughts yeah same size 2.5 by 2.5

723
00:28:13,960 --> 00:28:19,559
kilom any thoughts Australia Australia

724
00:28:20,440 --> 00:28:26,279
okay South Africa nice okay so I assume

725
00:28:24,159 --> 00:28:29,080
you see some it's it's like reddish you

726
00:28:26,279 --> 00:28:33,279
think it's in the desert

727
00:28:29,080 --> 00:28:35,559
okay turns out it's not at all in South

728
00:28:33,279 --> 00:28:39,080
Africa or in Australia but it is a

729
00:28:35,559 --> 00:28:40,840
desert right it's in Arizona now

730
00:28:39,080 --> 00:28:43,480
obviously sa will get that right right

731
00:28:40,840 --> 00:28:45,600
because you know it's big big AI model

732
00:28:43,480 --> 00:28:47,039
it knows everything turns out sa also

733
00:28:45,600 --> 00:28:49,159
gets there completely wrong right it

734
00:28:47,039 --> 00:28:50,440
thinks also that it's is a desert but

735
00:28:49,159 --> 00:28:52,880
just like you it just thinks it's a

736
00:28:50,440 --> 00:28:55,240
different desert and it turns out that a

737
00:28:52,880 --> 00:28:57,600
lot of places in around the world

738
00:28:55,240 --> 00:28:59,360
actually look very similar and if you

739
00:28:57,600 --> 00:29:01,679
just look at satellite imagery alone

740
00:28:59,360 --> 00:29:02,559
there's no like features that actually

741
00:29:01,679 --> 00:29:05,559
make it

742
00:29:02,559 --> 00:29:07,760
distinguishable um now you might think

743
00:29:05,559 --> 00:29:09,799
that this is a failure mode of the model

744
00:29:07,760 --> 00:29:12,200
but it's actually not at all the case

745
00:29:09,799 --> 00:29:14,120
because S Clip predicts a different

746
00:29:12,200 --> 00:29:16,399
location because both locations again

747
00:29:14,120 --> 00:29:19,240
have the same features and what this can

748
00:29:16,399 --> 00:29:22,120
tell us is which areas around the world

749
00:29:19,240 --> 00:29:25,440
are visually similar and this inside we

750
00:29:22,120 --> 00:29:27,279
can then leverage to train models for

751
00:29:25,440 --> 00:29:28,679
one area where we don't have labels on

752
00:29:27,279 --> 00:29:30,039
another area of the the world where we

753
00:29:28,679 --> 00:29:32,120
have labels that is visually very

754
00:29:30,039 --> 00:29:35,960
similar that is the

755
00:29:32,120 --> 00:29:38,200
idea and to kind of H out on that

756
00:29:35,960 --> 00:29:40,559
intuition a little bit here's a

757
00:29:38,200 --> 00:29:42,080
similarity map of sa embeddings with

758
00:29:40,559 --> 00:29:44,080
different anchor locations around the

759
00:29:42,080 --> 00:29:46,799
world right so on the left side we have

760
00:29:44,080 --> 00:29:48,760
a location in the Congo Basin we take

761
00:29:46,799 --> 00:29:50,279
that location and we compare it to every

762
00:29:48,760 --> 00:29:52,679
single other location on the planet and

763
00:29:50,279 --> 00:29:54,360
see how similar is that location and

764
00:29:52,679 --> 00:29:56,039
obviously the most similar locations are

765
00:29:54,360 --> 00:29:58,559
going to be other locations in the Congo

766
00:29:56,039 --> 00:30:01,200
Basin super high similarities score the

767
00:29:58,559 --> 00:30:03,000
rder the more similar but we also see

768
00:30:01,200 --> 00:30:05,080
that very geographically distant

769
00:30:03,000 --> 00:30:07,039
locations like in the Amazon or in

770
00:30:05,080 --> 00:30:08,240
Indonesia also have high similarity

771
00:30:07,039 --> 00:30:09,720
scores even though they're very

772
00:30:08,240 --> 00:30:12,679
geographically

773
00:30:09,720 --> 00:30:14,760
far same with the on the right side a

774
00:30:12,679 --> 00:30:17,039
map of the US East Coast again the most

775
00:30:14,760 --> 00:30:19,760
similar locations are also in the um

776
00:30:17,039 --> 00:30:21,399
Northeastern us but there's also a lot

777
00:30:19,760 --> 00:30:24,440
of similar locations in Europe or in

778
00:30:21,399 --> 00:30:26,799
South uh uh sorry in East Asia like

779
00:30:24,440 --> 00:30:29,840
China Japan kind of built very built-in

780
00:30:26,799 --> 00:30:31,120
areas and again the intuition is we

781
00:30:29,840 --> 00:30:32,640
might want to train a model for the

782
00:30:31,120 --> 00:30:34,799
Congo Basin but we don't have any

783
00:30:32,640 --> 00:30:36,120
training data available there but we

784
00:30:34,799 --> 00:30:37,760
might have training data available in

785
00:30:36,120 --> 00:30:40,080
the Amazon or in Indonesia so if we

786
00:30:37,760 --> 00:30:42,360
train a model on that sort of data it

787
00:30:40,080 --> 00:30:43,679
should transfer quite well to that new

788
00:30:42,360 --> 00:30:46,440
unseen

789
00:30:43,679 --> 00:30:48,840
area and we can test that intuition to

790
00:30:46,440 --> 00:30:51,200
some degree by doing um Geographic

791
00:30:48,840 --> 00:30:53,000
domain adaptation experiments so here we

792
00:30:51,200 --> 00:30:55,720
basically hold out the whole continent

793
00:30:53,000 --> 00:30:58,320
as a test set and only train on all

794
00:30:55,720 --> 00:30:59,919
other continents as training set this is

795
00:30:58,320 --> 00:31:01,679
a few shot setting so we actually give

796
00:30:59,919 --> 00:31:04,480
it very limited number I think it's

797
00:31:01,679 --> 00:31:07,080
about 100 of points in the in the test

798
00:31:04,480 --> 00:31:08,799
continent just because um in this

799
00:31:07,080 --> 00:31:10,600
example we try to predict Eco regions

800
00:31:08,799 --> 00:31:13,440
and Eco regions can be unique to a

801
00:31:10,600 --> 00:31:15,559
continent and slip gets that much better

802
00:31:13,440 --> 00:31:17,519
than some existing location in quarter

803
00:31:15,559 --> 00:31:19,320
models there is some that exist already

804
00:31:17,519 --> 00:31:21,320
for example geoclip is trained on

805
00:31:19,320 --> 00:31:23,720
flicker images so these are social media

806
00:31:21,320 --> 00:31:25,159
images um mosaics is not a location

807
00:31:23,720 --> 00:31:26,600
encoder but like a direct feature

808
00:31:25,159 --> 00:31:29,279
extractor from a satellite image

809
00:31:26,600 --> 00:31:32,399
database and CP is also location and

810
00:31:29,279 --> 00:31:35,000
quarter trained on I naturalist

811
00:31:32,399 --> 00:31:38,919
imagery yeah yeah I even have this in

812
00:31:35,000 --> 00:31:40,919
here um yeah so location quars exist

813
00:31:38,919 --> 00:31:43,039
already but none of them has really been

814
00:31:40,919 --> 00:31:44,679
trained with this idea of kind of broad

815
00:31:43,039 --> 00:31:48,440
Geographic generalization and

816
00:31:44,679 --> 00:31:48,440
generalization across tasks in

817
00:31:48,720 --> 00:31:54,320
mind um another thing um that I

818
00:31:51,760 --> 00:31:55,559
unfortunately um can talk about too much

819
00:31:54,320 --> 00:31:56,799
because we did this internally at

820
00:31:55,559 --> 00:31:58,720
Microsoft but I can give you a little

821
00:31:56,799 --> 00:32:01,960
bit of the intuition it's kind of my

822
00:31:58,720 --> 00:32:04,760
favorite application of s clip is in um

823
00:32:01,960 --> 00:32:06,960
yeah building Mass prediction um so

824
00:32:04,760 --> 00:32:09,120
often models that are trained on Western

825
00:32:06,960 --> 00:32:10,600
data fail when they're deployed in in

826
00:32:09,120 --> 00:32:12,799
other countries around the world in low

827
00:32:10,600 --> 00:32:14,720
income countries especially and building

828
00:32:12,799 --> 00:32:17,639
segmentation is a classic example for

829
00:32:14,720 --> 00:32:19,519
this here we have a satellite image of

830
00:32:17,639 --> 00:32:21,120
buildings in the US where you can see

831
00:32:19,519 --> 00:32:22,840
that buildings are on the left side

832
00:32:21,120 --> 00:32:25,360
where you see buildings are very

833
00:32:22,840 --> 00:32:28,120
rectangular they're arranged in a in a

834
00:32:25,360 --> 00:32:29,600
grid and they're kind of spaced out on

835
00:32:28,120 --> 00:32:31,600
the right side we have the same kind of

836
00:32:29,600 --> 00:32:33,720
resolution satellite image for Somalia

837
00:32:31,600 --> 00:32:36,320
and still kind of a residential area but

838
00:32:33,720 --> 00:32:37,760
you see that buildings are smaller

839
00:32:36,320 --> 00:32:40,519
they're in all sorts of shapes and

840
00:32:37,760 --> 00:32:42,279
they're kind of irregular um arranged

841
00:32:40,519 --> 00:32:45,080
and so a model that would be trained on

842
00:32:42,279 --> 00:32:47,880
us data might do pretty poorly at this

843
00:32:45,080 --> 00:32:49,799
um data in Somalia now the cool thing

844
00:32:47,880 --> 00:32:52,159
with slip is that it has seen both of

845
00:32:49,799 --> 00:32:53,679
these areas right it hasn't learned to

846
00:32:52,159 --> 00:32:55,279
do building segmentation in both of

847
00:32:53,679 --> 00:32:56,919
these areas but it has learned something

848
00:32:55,279 --> 00:32:59,799
about the unique characteristics of both

849
00:32:56,919 --> 00:33:03,559
of these areas and it turns out that if

850
00:32:59,799 --> 00:33:06,159
we do um a model transfer and add S Clip

851
00:33:03,559 --> 00:33:09,440
into the mix that this actually helps

852
00:33:06,159 --> 00:33:12,760
improve these uh these modeling

853
00:33:09,440 --> 00:33:14,480
efforts a similar idea um is something

854
00:33:12,760 --> 00:33:17,000
that some other researchers have done so

855
00:33:14,480 --> 00:33:19,880
this from Nathan Jacobs group at washu

856
00:33:17,000 --> 00:33:22,240
um here people have used um S clip to

857
00:33:19,880 --> 00:33:25,120
condition um image diffusion model for

858
00:33:22,240 --> 00:33:27,399
satellite imagery so diffusion models a

859
00:33:25,120 --> 00:33:31,080
generative model for satellite images

860
00:33:27,399 --> 00:33:33,440
and the authors here condition um

861
00:33:31,080 --> 00:33:35,840
condition the model on a open street map

862
00:33:33,440 --> 00:33:37,320
mask so that kind of produces an image

863
00:33:35,840 --> 00:33:39,720
that has the same kind of buildings and

864
00:33:37,320 --> 00:33:41,279
streets as in the open street map mask

865
00:33:39,720 --> 00:33:44,039
and then they also condition it on set

866
00:33:41,279 --> 00:33:46,919
clip and the the best way you can kind

867
00:33:44,039 --> 00:33:49,840
of see the effect that slip has here is

868
00:33:46,919 --> 00:33:51,840
that um keep in mind slip captures kind

869
00:33:49,840 --> 00:33:54,399
of very high level features of a

870
00:33:51,840 --> 00:33:57,799
location like climate zone um humidity

871
00:33:54,399 --> 00:33:59,919
and so on and if you compare images just

872
00:33:57,799 --> 00:34:03,080
generated at for in for example de Mo

873
00:33:59,919 --> 00:34:05,799
Iowa to bould Colorado you will see that

874
00:34:03,080 --> 00:34:07,919
the um satellite images generated for de

875
00:34:05,799 --> 00:34:10,000
Mo are much Greener and the reason for

876
00:34:07,919 --> 00:34:12,639
that is that de MO is much more humid

877
00:34:10,000 --> 00:34:14,200
right there's much more um um yeah

878
00:34:12,639 --> 00:34:16,159
humidity there's much more vegetation

879
00:34:14,200 --> 00:34:17,839
there and this is exactly one of these

880
00:34:16,159 --> 00:34:20,000
big high level features that slip

881
00:34:17,839 --> 00:34:23,159
captures and so it helps to kind of

882
00:34:20,000 --> 00:34:23,159
ground this model a bit

883
00:34:23,599 --> 00:34:28,359
geographically all right so um this is

884
00:34:26,760 --> 00:34:30,000
kind of where we stand but with STP this

885
00:34:28,359 --> 00:34:31,520
is kind of the experiments we've done

886
00:34:30,000 --> 00:34:33,679
Where Do We Go From Here with this kind

887
00:34:31,520 --> 00:34:33,679
of

888
00:34:35,119 --> 00:34:40,000
research and what I really want to posit

889
00:34:37,839 --> 00:34:42,520
is that geographical encoders are a

890
00:34:40,000 --> 00:34:45,000
whole new class of geospatial foundation

891
00:34:42,520 --> 00:34:47,119
models that have Global coverage and are

892
00:34:45,000 --> 00:34:49,000
designed for general purpose they might

893
00:34:47,119 --> 00:34:50,200
not be the biggest models right the ones

894
00:34:49,000 --> 00:34:52,200
that we've trained so far are actually

895
00:34:50,200 --> 00:34:55,960
quite small but they fulfill this kind

896
00:34:52,200 --> 00:34:58,000
of globality aspect of the foundation of

897
00:34:55,960 --> 00:35:01,520
the foundation model

898
00:34:58,000 --> 00:35:03,280
and I've kind of broadly outlined what I

899
00:35:01,520 --> 00:35:05,280
believe are going to be the the main

900
00:35:03,280 --> 00:35:07,839
thrusts of research in this area in the

901
00:35:05,280 --> 00:35:11,680
next six is

902
00:35:07,839 --> 00:35:14,640
years five is years and um I think the

903
00:35:11,680 --> 00:35:16,520
kind of first uh immediate impact of of

904
00:35:14,640 --> 00:35:19,240
such models um that we're already seeing

905
00:35:16,520 --> 00:35:21,359
today is that they are a great way for

906
00:35:19,240 --> 00:35:23,480
providing cheap and Global location

907
00:35:21,359 --> 00:35:24,960
embeddings in especially in settings

908
00:35:23,480 --> 00:35:27,359
that are quite resource constrained

909
00:35:24,960 --> 00:35:29,000
right not everyone can kind of afford to

910
00:35:27,359 --> 00:35:30,920
train a big computer vision model that

911
00:35:29,000 --> 00:35:32,280
takes in satellite imagery that everyone

912
00:35:30,920 --> 00:35:34,320
might have access to satellite imagery

913
00:35:32,280 --> 00:35:36,720
or be able to store it instead you can

914
00:35:34,320 --> 00:35:39,359
just download our cyop model which is a

915
00:35:36,720 --> 00:35:40,680
few hundred megabytes if you remove uh

916
00:35:39,359 --> 00:35:42,960
the image encod and just take the

917
00:35:40,680 --> 00:35:44,400
location encod it's even smaller and

918
00:35:42,960 --> 00:35:46,000
then you can for any location on the

919
00:35:44,400 --> 00:35:47,520
world you can just query the

920
00:35:46,000 --> 00:35:49,760
corresponding location embedding and

921
00:35:47,520 --> 00:35:51,680
replace your image for some tasks that

922
00:35:49,760 --> 00:35:54,280
might be enough for some tasks it might

923
00:35:51,680 --> 00:35:57,640
not be um and in fact we're seeing

924
00:35:54,280 --> 00:35:59,920
already um uh quite a few kind of new

925
00:35:57,640 --> 00:36:01,640
papers on this I think bunch of the kind

926
00:35:59,920 --> 00:36:04,520
of big tech companies have have caught

927
00:36:01,640 --> 00:36:06,560
up on this I think the latest uh uh

928
00:36:04,520 --> 00:36:07,880
institution to release one is Deep Mind

929
00:36:06,560 --> 00:36:10,200
they have one that is more based on

930
00:36:07,880 --> 00:36:12,200
socio economic data and census data but

931
00:36:10,200 --> 00:36:15,960
also really cool

932
00:36:12,200 --> 00:36:18,319
research in the medium term uh I think

933
00:36:15,960 --> 00:36:19,839
uh sorry also in the short term I think

934
00:36:18,319 --> 00:36:22,000
the next steps for expanding these

935
00:36:19,839 --> 00:36:23,720
models are also very clear so far we

936
00:36:22,000 --> 00:36:25,800
only use sentinel 2 imagery which is

937
00:36:23,720 --> 00:36:28,040
Optical satellite imagery there's many

938
00:36:25,800 --> 00:36:30,640
many more um remotes sensing data

939
00:36:28,040 --> 00:36:33,280
sources we can adapt like radar like

940
00:36:30,640 --> 00:36:34,960
yourve products like vegetation indices

941
00:36:33,280 --> 00:36:37,040
we can also work with data at different

942
00:36:34,960 --> 00:36:39,280
spatial resolutions and of course

943
00:36:37,040 --> 00:36:41,839
integrate the time component right now

944
00:36:39,280 --> 00:36:44,680
sap only takes an latitude longitude we

945
00:36:41,839 --> 00:36:47,200
do sample data from two and a half years

946
00:36:44,680 --> 00:36:49,079
I think so we basically implicitly

947
00:36:47,200 --> 00:36:50,920
average over time or marginalize over

948
00:36:49,079 --> 00:36:54,079
the time component we still represent

949
00:36:50,920 --> 00:36:56,560
all seasonalities but having that time

950
00:36:54,079 --> 00:36:58,359
be like a free floating parameter um

951
00:36:56,560 --> 00:37:00,480
that you can manipulate yourself would

952
00:36:58,359 --> 00:37:04,640
obviously be really

953
00:37:00,480 --> 00:37:09,079
cool now um in the medium term I think

954
00:37:04,640 --> 00:37:10,680
location encoders can be very useful for

955
00:37:09,079 --> 00:37:14,720
augmenting some sort of je spatial

956
00:37:10,680 --> 00:37:17,880
intelligence in llms um I haven't looked

957
00:37:14,720 --> 00:37:19,359
this up super recently but the last time

958
00:37:17,880 --> 00:37:21,720
I did it kind of still held true and

959
00:37:19,359 --> 00:37:24,079
that is that kind of llms are not

960
00:37:21,720 --> 00:37:26,599
excellent at kind of geographic question

961
00:37:24,079 --> 00:37:28,720
answering so here I kind of just dropped

962
00:37:26,599 --> 00:37:32,640
a pin in the Pacific and asked uh this

963
00:37:28,720 --> 00:37:35,480
is gp4 to get me the annual mean

964
00:37:32,640 --> 00:37:39,480
temperature of the closest uh location

965
00:37:35,480 --> 00:37:41,280
that it has access to um and this

966
00:37:39,480 --> 00:37:42,720
location is somewhat close to Hawaii so

967
00:37:41,280 --> 00:37:44,680
I would expect it to give me the annual

968
00:37:42,720 --> 00:37:46,319
mean uh temperature for Hawaii but it

969
00:37:44,680 --> 00:37:47,920
kind of gets that distance calculation

970
00:37:46,319 --> 00:37:51,000
completely wrong and instead drops me

971
00:37:47,920 --> 00:37:53,079
somewhere in the Philippines um and so

972
00:37:51,000 --> 00:37:55,119
hopefully these kind of models uh

973
00:37:53,079 --> 00:37:57,800
location embeddings might again be able

974
00:37:55,119 --> 00:38:00,680
to condition bigger Foundation models

975
00:37:57,800 --> 00:38:02,200
geographically and help with answering

976
00:38:00,680 --> 00:38:04,720
questions like

977
00:38:02,200 --> 00:38:06,680
this I think generally this kind of

978
00:38:04,720 --> 00:38:09,680
alignment of embeddings from different

979
00:38:06,680 --> 00:38:11,560
modalities is super interesting here um

980
00:38:09,680 --> 00:38:14,040
because it can really help with this

981
00:38:11,560 --> 00:38:18,640
translation between um modalities so

982
00:38:14,040 --> 00:38:21,560
from image uh to location to text to

983
00:38:18,640 --> 00:38:23,200
video and um I think we already see kind

984
00:38:21,560 --> 00:38:28,200
of first schol examples of this so this

985
00:38:23,200 --> 00:38:31,760
is from um a a python package um Sigma

986
00:38:28,200 --> 00:38:35,640
Geo that um or Sam Geo that basically

987
00:38:31,760 --> 00:38:38,560
already integrate some sort of um llm

988
00:38:35,640 --> 00:38:41,560
component in in like a GIS tool you can

989
00:38:38,560 --> 00:38:44,520
basically type in a prompt like tree and

990
00:38:41,560 --> 00:38:46,720
the model will kind of translate that

991
00:38:44,520 --> 00:38:48,200
into Vision embedding space and then

992
00:38:46,720 --> 00:38:49,119
segment all of the trees in that image

993
00:38:48,200 --> 00:38:51,960
for

994
00:38:49,119 --> 00:38:53,079
you it's like a more like a gimmick at

995
00:38:51,960 --> 00:38:55,599
this point but I think we're going to

996
00:38:53,079 --> 00:38:58,119
see a lot more of this in the in the in

997
00:38:55,599 --> 00:39:01,079
the future

998
00:38:58,119 --> 00:39:04,040
now um looking kind of further ahead I

999
00:39:01,079 --> 00:39:06,359
think we are eventually arriving at a

1000
00:39:04,040 --> 00:39:08,880
very big question and that is can we

1001
00:39:06,359 --> 00:39:11,680
learn physical environmental and even

1002
00:39:08,880 --> 00:39:15,280
social processes of our planet from data

1003
00:39:11,680 --> 00:39:17,119
alone using neural networks and can this

1004
00:39:15,280 --> 00:39:19,480
help us identify and track changes in

1005
00:39:17,119 --> 00:39:21,599
our planet H might this even help with

1006
00:39:19,480 --> 00:39:24,160
scientific discovery and extrapolation

1007
00:39:21,599 --> 00:39:26,160
right if we learn like a good Laten

1008
00:39:24,160 --> 00:39:28,160
space representation of our planet that

1009
00:39:26,160 --> 00:39:30,720
is dynamic from his hisorical data can

1010
00:39:28,160 --> 00:39:33,440
we play these effects forward and um

1011
00:39:30,720 --> 00:39:37,760
analyze Trends such as climate change

1012
00:39:33,440 --> 00:39:41,000
the answer to this um I think is very

1013
00:39:37,760 --> 00:39:43,480
unclear um but I think these kind of

1014
00:39:41,000 --> 00:39:46,920
intermediate steps on the way are very

1015
00:39:43,480 --> 00:39:49,160
useful in and of themselves and um I

1016
00:39:46,920 --> 00:39:51,599
yeah I myself am very curious about this

1017
00:39:49,160 --> 00:39:53,319
questions um I'm actually more

1018
00:39:51,599 --> 00:39:54,920
optimistic than I was maybe a year ago

1019
00:39:53,319 --> 00:39:56,440
we're seeing great progress not

1020
00:39:54,920 --> 00:39:58,720
necessarily in remote sensing but in

1021
00:39:56,440 --> 00:40:00,400
other kind of adjacent areas of Earth

1022
00:39:58,720 --> 00:40:02,160
Systems modeling especially in climate

1023
00:40:00,400 --> 00:40:04,200
and weather modeling I think we're

1024
00:40:02,160 --> 00:40:05,960
seeing nor networks actually being

1025
00:40:04,200 --> 00:40:08,280
really really good that makes me also

1026
00:40:05,960 --> 00:40:12,920
more optimistic for this line of work

1027
00:40:08,280 --> 00:40:16,720
and um yeah maybe to to end the talk uh

1028
00:40:12,920 --> 00:40:19,560
I'd like to direct you to um our um icml

1029
00:40:16,720 --> 00:40:22,160
position paper on this whole topic where

1030
00:40:19,560 --> 00:40:25,560
um especially as Ro who the first author

1031
00:40:22,160 --> 00:40:27,319
on this paper and and us we argue that

1032
00:40:25,560 --> 00:40:29,200
we believe that it's kind of time for

1033
00:40:27,319 --> 00:40:30,920
for people to treat Earth observation

1034
00:40:29,200 --> 00:40:32,960
and remote sensing data as it's a

1035
00:40:30,920 --> 00:40:35,480
distinct kind of application area with

1036
00:40:32,960 --> 00:40:37,079
within machine learning rather than

1037
00:40:35,480 --> 00:40:39,119
having it like you know at a workshop

1038
00:40:37,079 --> 00:40:40,680
here and there but I think really it is

1039
00:40:39,119 --> 00:40:43,480
unique enough and is potentially

1040
00:40:40,680 --> 00:40:45,119
impactful enough to have its own kind of

1041
00:40:43,480 --> 00:40:48,440
yeah sub area just like we treat

1042
00:40:45,119 --> 00:40:49,800
biomedical um imagery or so and yeah

1043
00:40:48,440 --> 00:40:52,480
with that these are the two papers I

1044
00:40:49,800 --> 00:40:54,160
talked about today um thank you to my

1045
00:40:52,480 --> 00:40:56,800
amazing co-authors whove worked with me

1046
00:40:54,160 --> 00:40:58,800
on this and thanks everyone for coming

1047
00:40:56,800 --> 00:41:00,450
and for interest in this topic and I'm

1048
00:40:58,800 --> 00:41:07,110
excited to hear questions

1049
00:41:00,450 --> 00:41:07,110
[Applause]


1
00:00:05,520 --> 00:00:14,639
He is a uh principal investigator in MIT

2
00:00:10,240 --> 00:00:16,960
pro probabilistic computing project. He

3
00:00:14,639 --> 00:00:20,800
is going to explore

4
00:00:16,960 --> 00:00:23,960
uh probabilistic computing approach

5
00:00:20,800 --> 00:00:28,640
alternative to deep learning to build

6
00:00:23,960 --> 00:00:32,440
machines that can learn and think with

7
00:00:28,640 --> 00:00:35,440
people. Let's welcome

8
00:00:32,440 --> 00:00:37,800
uh Minka. I'm sorry. It's okay. Thank

9
00:00:35,440 --> 00:00:41,200
you. Hi

10
00:00:37,800 --> 00:00:44,160
everybody. Very happy to be here. Now,

11
00:00:41,200 --> 00:00:45,600
maybe like some of you, I grew up loving

12
00:00:44,160 --> 00:00:48,800
science fiction that prominently

13
00:00:45,600 --> 00:00:51,879
featured AI. There was a vision that we

14
00:00:48,800 --> 00:00:55,120
could somehow have artificial

15
00:00:51,879 --> 00:00:57,520
agents who were embodying some of the

16
00:00:55,120 --> 00:00:58,960
highest human ideals. you know, not just

17
00:00:57,520 --> 00:01:02,239
that they were rational, but

18
00:00:58,960 --> 00:01:04,559
superhumanly informed and helpful. And

19
00:01:02,239 --> 00:01:06,320
even AI villains, uh, like here I'm

20
00:01:04,559 --> 00:01:09,119
showing Lieutenant Commander Data's evil

21
00:01:06,320 --> 00:01:13,240
twin lore, could at least be counted on

22
00:01:09,119 --> 00:01:13,240
to be rationally self-interested.

23
00:01:13,280 --> 00:01:18,640
But the place we are today in this early

24
00:01:16,720 --> 00:01:21,759
emergence of probabistic computing and

25
00:01:18,640 --> 00:01:24,080
AI, still very much the beginning, is we

26
00:01:21,759 --> 00:01:26,720
have systems that fail to live up to the

27
00:01:24,080 --> 00:01:28,799
basic norms of rationality that science

28
00:01:26,720 --> 00:01:31,079
fiction and also cognitive science have

29
00:01:28,799 --> 00:01:34,240
been exploring for a long

30
00:01:31,079 --> 00:01:36,079
time. In highstakes deployments from

31
00:01:34,240 --> 00:01:37,920
some of the world's best AI companies,

32
00:01:36,079 --> 00:01:39,840
where engineers have worked hard to

33
00:01:37,920 --> 00:01:42,840
prevent failure, it so far hasn't been

34
00:01:39,840 --> 00:01:42,840
possible.

35
00:01:43,520 --> 00:01:48,079
I think it's helpful to reflect on the

36
00:01:45,840 --> 00:01:50,680
quality of the failure modes that we're

37
00:01:48,079 --> 00:01:53,040
seeing from machine learning

38
00:01:50,680 --> 00:01:55,200
systems. Some of you may have

39
00:01:53,040 --> 00:01:56,360
experienced failure modes like this in

40
00:01:55,200 --> 00:01:59,840
your own

41
00:01:56,360 --> 00:02:03,479
vehicle, but I think it's important to

42
00:01:59,840 --> 00:02:05,600
reflect on the analogy to human

43
00:02:03,479 --> 00:02:10,520
intelligence that's causing us to

44
00:02:05,600 --> 00:02:14,440
chuckle here. If a human driver was

45
00:02:10,520 --> 00:02:16,800
seeing a sequence of fluctuating

46
00:02:14,440 --> 00:02:19,440
hallucinations, we might not want them

47
00:02:16,800 --> 00:02:22,239
behind the wheel, especially if they

48
00:02:19,440 --> 00:02:24,319
didn't think anything was wrong. Right?

49
00:02:22,239 --> 00:02:27,200
There's no alarm bells going off in the

50
00:02:24,319 --> 00:02:30,560
Tesla's cabin.

51
00:02:27,200 --> 00:02:32,160
And in fact uh this has led to uh this

52
00:02:30,560 --> 00:02:34,640
kind of failure mode has led to both

53
00:02:32,160 --> 00:02:37,000
significant fatalities and as one of the

54
00:02:34,640 --> 00:02:39,280
cost drivers in the autonomous vehicle

55
00:02:37,000 --> 00:02:40,959
industry. You know the the mistakes that

56
00:02:39,280 --> 00:02:43,120
these systems make are mistakes that

57
00:02:40,959 --> 00:02:44,879
would not be made by uh even a human

58
00:02:43,120 --> 00:02:46,680
child behind the wheel if they were

59
00:02:44,879 --> 00:02:48,519
sober and paying

60
00:02:46,680 --> 00:02:51,360
attention.

61
00:02:48,519 --> 00:02:53,200
Um so let's dig a little bit deeper.

62
00:02:51,360 --> 00:02:54,959
What's really going on with these kinds

63
00:02:53,200 --> 00:02:56,800
of failure modes of machine learning? In

64
00:02:54,959 --> 00:02:59,360
fact, you can see the same kinds of

65
00:02:56,800 --> 00:03:01,120
errors in classic games of strategy. So,

66
00:02:59,360 --> 00:03:03,599
many of you may know that the world's

67
00:03:01,120 --> 00:03:05,360
best go players today are AI systems.

68
00:03:03,599 --> 00:03:07,599
But you may not know that there's simple

69
00:03:05,360 --> 00:03:09,519
camouflage that you can teach a human

70
00:03:07,599 --> 00:03:11,760
amateur, an amateur who's beaten by

71
00:03:09,519 --> 00:03:14,640
human pros and soundly beaten by Go AI

72
00:03:11,760 --> 00:03:16,480
players normally. But the go the go AIs

73
00:03:14,640 --> 00:03:18,159
cannot see through that camouflage. So,

74
00:03:16,480 --> 00:03:20,000
an amateur like me, having learned the

75
00:03:18,159 --> 00:03:23,120
camouflage, will beat superhuman Go

76
00:03:20,000 --> 00:03:24,879
players. The Go AI can't see the

77
00:03:23,120 --> 00:03:27,280
configuration in front of its face, much

78
00:03:24,879 --> 00:03:29,920
like the Tesla can't see the overturned

79
00:03:27,280 --> 00:03:32,080
bus. So, what's really going on? What's

80
00:03:29,920 --> 00:03:34,200
the gap between rationality at the core

81
00:03:32,080 --> 00:03:36,640
of intelligence and today's

82
00:03:34,200 --> 00:03:38,799
AI? The roots are in the discipline of

83
00:03:36,640 --> 00:03:41,200
machine learning and the enormous power

84
00:03:38,799 --> 00:03:44,400
it's brought to scaling AI, but also the

85
00:03:41,200 --> 00:03:46,319
cracks in that theory. So we've been

86
00:03:44,400 --> 00:03:49,440
building larger and larger end toend

87
00:03:46,319 --> 00:03:53,319
train neural networks using enormous

88
00:03:49,440 --> 00:03:56,400
advances in parallel compute uh GPUs,

89
00:03:53,319 --> 00:03:58,319
TPUs, deep learning stacks like PyTorch,

90
00:03:56,400 --> 00:04:00,799
Jacks and TensorFlow which automate the

91
00:03:58,319 --> 00:04:03,040
math of deep learning and massive data

92
00:04:00,799 --> 00:04:05,120
sets including the common crawl, large

93
00:04:03,040 --> 00:04:06,959
simulations and sticky product loops

94
00:04:05,120 --> 00:04:08,560
designed us to keep us feeding the

95
00:04:06,959 --> 00:04:10,959
machine learning systems the data they

96
00:04:08,560 --> 00:04:13,239
need. then training them end to end to

97
00:04:10,959 --> 00:04:15,479
try to produce these

98
00:04:13,239 --> 00:04:18,000
systems. But I have to

99
00:04:15,479 --> 00:04:19,720
acknowledge as someone who uh teaches

100
00:04:18,000 --> 00:04:22,960
machine learning methods on occasion

101
00:04:19,720 --> 00:04:25,000
here that we don't entirely understand

102
00:04:22,960 --> 00:04:27,440
how these machine learning systems are

103
00:04:25,000 --> 00:04:29,400
working. There's something alchemical

104
00:04:27,440 --> 00:04:32,400
about

105
00:04:29,400 --> 00:04:34,320
it and that raises the question, what

106
00:04:32,400 --> 00:04:36,320
better technological foundations are

107
00:04:34,320 --> 00:04:39,759
needed to deliver on the dreams of

108
00:04:36,320 --> 00:04:42,080
rationality and AI?

109
00:04:39,759 --> 00:04:43,680
At MIT and especially at the Seagull

110
00:04:42,080 --> 00:04:45,759
family quest for intelligence, we've

111
00:04:43,680 --> 00:04:48,000
been pursuing a different approach.

112
00:04:45,759 --> 00:04:50,720
We're building engineered rational by

113
00:04:48,000 --> 00:04:53,960
design AI that constructs world models

114
00:04:50,720 --> 00:04:56,960
that are coherent and used rationally by

115
00:04:53,960 --> 00:04:59,040
construction where let's say the sensory

116
00:04:56,960 --> 00:05:01,360
information about a room like this is

117
00:04:59,040 --> 00:05:03,919
parsed into a hierarchical multiscale

118
00:05:01,360 --> 00:05:06,720
symbolic model that coheres with both

119
00:05:03,919 --> 00:05:09,280
our common sense unlike the entangled

120
00:05:06,720 --> 00:05:11,199
representations inside a neural network

121
00:05:09,280 --> 00:05:12,960
and also with the world is revealed by

122
00:05:11,199 --> 00:05:15,520
science which validates the intuitive

123
00:05:12,960 --> 00:05:18,320
perception that at some level there are

124
00:05:15,520 --> 00:05:21,880
objects in space out there, not just

125
00:05:18,320 --> 00:05:24,720
activations uh in some

126
00:05:21,880 --> 00:05:27,360
transformer. Now, in fact, even human

127
00:05:24,720 --> 00:05:29,919
children robustly develop generalizable

128
00:05:27,360 --> 00:05:33,440
world models. There's a slightly

129
00:05:29,919 --> 00:05:36,560
troubling genre on YouTube of uh

130
00:05:33,440 --> 00:05:39,600
children and non-human primates, it

131
00:05:36,560 --> 00:05:41,520
turns out, uh driving golf carts. And

132
00:05:39,600 --> 00:05:44,000
while one might question the judgment

133
00:05:41,520 --> 00:05:47,280
calls of all of the primates involved in

134
00:05:44,000 --> 00:05:49,120
making these videos, um, we would be

135
00:05:47,280 --> 00:05:50,639
shocked if they couldn't see the road in

136
00:05:49,120 --> 00:05:53,680
front of them, right? If they failed the

137
00:05:50,639 --> 00:05:55,520
way that the Teslas did. And of course,

138
00:05:53,680 --> 00:05:58,720
there's deep biological reasons for

139
00:05:55,520 --> 00:06:00,680
this. The ability to construct robust,

140
00:05:58,720 --> 00:06:04,000
rational models of the world is an

141
00:06:00,680 --> 00:06:06,880
evolutionarily ancient necessity.

142
00:06:04,000 --> 00:06:09,120
Even small fish swimming around needed

143
00:06:06,880 --> 00:06:10,600
to see their prey and accurately locate

144
00:06:09,120 --> 00:06:12,479
them in three dimensions without

145
00:06:10,600 --> 00:06:14,360
hallucination so that they could eat

146
00:06:12,479 --> 00:06:16,960
enough to survive and

147
00:06:14,360 --> 00:06:18,960
reproduce. You know, without robust

148
00:06:16,960 --> 00:06:20,720
rational perception, it's unclear that

149
00:06:18,960 --> 00:06:22,880
the evolutionary ratchet could even have

150
00:06:20,720 --> 00:06:24,240
gotten started. Now, when you hear the

151
00:06:22,880 --> 00:06:26,240
narrative that what deep learning is

152
00:06:24,240 --> 00:06:27,759
doing is evolutionary scale compute, I

153
00:06:26,240 --> 00:06:29,520
think it's actually worth considering

154
00:06:27,759 --> 00:06:32,160
how much less efficient and effective

155
00:06:29,520 --> 00:06:33,360
than evolution it actually is. Now,

156
00:06:32,160 --> 00:06:35,039
that's not to say that deep learning

157
00:06:33,360 --> 00:06:37,600
methods don't have a role to play, a

158
00:06:35,039 --> 00:06:40,240
crucial tool in the broader probabistic

159
00:06:37,600 --> 00:06:42,400
computing toolkit for scaling software

160
00:06:40,240 --> 00:06:45,600
and inference far beyond the scales

161
00:06:42,400 --> 00:06:48,400
we're used to today. But at MIT, we see

162
00:06:45,600 --> 00:06:50,319
it located within a broader framework of

163
00:06:48,400 --> 00:06:53,039
toolkits for engineering rational by

164
00:06:50,319 --> 00:06:55,199
design AI that crucially have to exploit

165
00:06:53,039 --> 00:06:56,800
scale parallel compute in many of the

166
00:06:55,199 --> 00:06:59,039
same ways deep learning did, but to go

167
00:06:56,800 --> 00:07:00,560
beyond it by applying it to modular,

168
00:06:59,039 --> 00:07:03,039
interpretable, and in some cases

169
00:07:00,560 --> 00:07:04,800
symbolic and engineered representations.

170
00:07:03,039 --> 00:07:06,400
And our research moonshots at the Quest

171
00:07:04,800 --> 00:07:08,160
for intelligence are pursuing that

172
00:07:06,400 --> 00:07:10,319
program using modular learning from

173
00:07:08,160 --> 00:07:12,639
human scale data. So learning much more

174
00:07:10,319 --> 00:07:14,720
like the efficiency that you and I learn

175
00:07:12,639 --> 00:07:16,639
and using comparisons, quantitative

176
00:07:14,720 --> 00:07:19,240
comparisons between AI systems and human

177
00:07:16,639 --> 00:07:22,160
behavior in comparable

178
00:07:19,240 --> 00:07:24,800
worlds. And the key technical innovation

179
00:07:22,160 --> 00:07:26,759
enabling us to scale this approach is an

180
00:07:24,800 --> 00:07:30,080
emerging field called proistic

181
00:07:26,759 --> 00:07:31,680
programming which unifies the symbolic,

182
00:07:30,080 --> 00:07:32,800
probabilistic and neural or

183
00:07:31,680 --> 00:07:35,039
differentiable approaches to

184
00:07:32,800 --> 00:07:36,880
computation.

185
00:07:35,039 --> 00:07:38,560
So many of us may be familiar with the

186
00:07:36,880 --> 00:07:40,560
power of the symbolic and neural

187
00:07:38,560 --> 00:07:43,039
components. In fact, compilers like

188
00:07:40,560 --> 00:07:44,400
TensorFlow and PyTorch and Jax are

189
00:07:43,039 --> 00:07:46,960
really paralyzing symbolic

190
00:07:44,400 --> 00:07:48,960
representation frameworks for

191
00:07:46,960 --> 00:07:50,880
differentiable or neural computation.

192
00:07:48,960 --> 00:07:52,160
Right? You don't train neural nets using

193
00:07:50,880 --> 00:07:54,160
neural nets. You train them using

194
00:07:52,160 --> 00:07:57,440
symbolic programs that manage the

195
00:07:54,160 --> 00:07:59,599
parallelism. Um, but of course there's a

196
00:07:57,440 --> 00:08:01,280
much broader sphere of methods that are

197
00:07:59,599 --> 00:08:02,879
needed for rationality, including

198
00:08:01,280 --> 00:08:04,720
decision theory, the ability to weigh

199
00:08:02,879 --> 00:08:07,120
risk and reward, to make guesses given

200
00:08:04,720 --> 00:08:08,479
incomplete information. And it turns out

201
00:08:07,120 --> 00:08:09,879
those can be integrated with the

202
00:08:08,479 --> 00:08:12,960
symbolic and the

203
00:08:09,879 --> 00:08:14,560
differentiable. And over the years, uh,

204
00:08:12,960 --> 00:08:17,199
we've sort of been climbing up the

205
00:08:14,560 --> 00:08:18,720
ladders of scale with this approach. Um,

206
00:08:17,199 --> 00:08:20,960
so I've been working in this area for

207
00:08:18,720 --> 00:08:22,479
about 20 years. uh but it's really only

208
00:08:20,960 --> 00:08:24,400
in the last few years we turned an

209
00:08:22,479 --> 00:08:26,240
inflection point and started early

210
00:08:24,400 --> 00:08:28,879
projects with Google to demonstrate

211
00:08:26,240 --> 00:08:31,360
scale time series forecasting and 3D

212
00:08:28,879 --> 00:08:33,039
scene perception using this approach uh

213
00:08:31,360 --> 00:08:34,959
dduplicating and linking and cleaning

214
00:08:33,039 --> 00:08:37,599
databases with millions of records like

215
00:08:34,959 --> 00:08:39,039
the US Medicare physicians registry um

216
00:08:37,599 --> 00:08:40,399
and there have been a number of startup

217
00:08:39,039 --> 00:08:42,159
companies that have become part of the

218
00:08:40,399 --> 00:08:44,159
business intelligence industry so far

219
00:08:42,159 --> 00:08:45,680
and then a new one in gaming uh started

220
00:08:44,159 --> 00:08:47,760
recently uh that have been

221
00:08:45,680 --> 00:08:50,080
commercializing this approach and so

222
00:08:47,760 --> 00:08:51,839
feel free to talk to me about uh the

223
00:08:50,080 --> 00:08:53,000
spectrum of industry applications for

224
00:08:51,839 --> 00:08:55,200
people who are

225
00:08:53,000 --> 00:08:57,760
interested. Just to make sure we have a

226
00:08:55,200 --> 00:08:58,959
concrete view of probabistic programming

227
00:08:57,760 --> 00:09:01,120
here, what you're seeing is data

228
00:08:58,959 --> 00:09:02,399
streaming in one point at a time. And on

229
00:09:01,120 --> 00:09:03,839
the right, you're seeing the symbolic

230
00:09:02,399 --> 00:09:05,680
source code for a probabistic model

231
00:09:03,839 --> 00:09:07,920
that's being edited by two probabistic

232
00:09:05,680 --> 00:09:09,839
programs working together. One that

233
00:09:07,920 --> 00:09:11,360
defines a space of possible models and

234
00:09:09,839 --> 00:09:13,279
then the other one that explores that

235
00:09:11,360 --> 00:09:16,320
space guessing and testing against each

236
00:09:13,279 --> 00:09:18,640
data point incrementally. Here is

237
00:09:16,320 --> 00:09:20,480
probabic program building a map in real

238
00:09:18,640 --> 00:09:21,920
time of one of uh from data from one of

239
00:09:20,480 --> 00:09:24,200
the floors in the computer science and

240
00:09:21,920 --> 00:09:27,040
AI lab at

241
00:09:24,200 --> 00:09:28,959
MIT. Probleistic programs can detect and

242
00:09:27,040 --> 00:09:31,200
correct errors and hallucinations in

243
00:09:28,959 --> 00:09:34,320
neural net object detectors like you're

244
00:09:31,200 --> 00:09:35,920
seeing here. Uh so for example, you

245
00:09:34,320 --> 00:09:37,519
know, we know that it's unphysical to

246
00:09:35,920 --> 00:09:40,080
have a bottle floating sideways in

247
00:09:37,519 --> 00:09:42,160
midair and that fails to explain the

248
00:09:40,080 --> 00:09:43,440
actual image of the bottle. The neural

249
00:09:42,160 --> 00:09:45,880
net can't handle that, but the

250
00:09:43,440 --> 00:09:49,200
probabistic program

251
00:09:45,880 --> 00:09:51,200
can. And inside the box, crucially, are

252
00:09:49,200 --> 00:09:53,279
representations and inference processes,

253
00:09:51,200 --> 00:09:55,800
which unlike the entangled weights of

254
00:09:53,279 --> 00:09:59,360
transformers, we understand and can

255
00:09:55,800 --> 00:10:01,279
engineer. Now, the pendulum swings often

256
00:09:59,360 --> 00:10:02,959
by decade in computer science. And in

257
00:10:01,279 --> 00:10:04,800
this moment, this approach might seem to

258
00:10:02,959 --> 00:10:06,000
be out of favor. But for people who were

259
00:10:04,800 --> 00:10:07,440
around at the beginning of deep

260
00:10:06,000 --> 00:10:09,600
learning, I just want to invite you to

261
00:10:07,440 --> 00:10:12,399
consider how foreign the idea of

262
00:10:09,600 --> 00:10:14,240
learning representations was at scale

263
00:10:12,399 --> 00:10:15,920
just 10 or 15 years ago. And then what

264
00:10:14,240 --> 00:10:18,480
happened as parallel compute was

265
00:10:15,920 --> 00:10:19,920
unlocked in service of that hypothesis.

266
00:10:18,480 --> 00:10:21,440
Well, I think we may be at a similar

267
00:10:19,920 --> 00:10:23,440
moment for representations that have

268
00:10:21,440 --> 00:10:25,440
been rationally engineered. Here you can

269
00:10:23,440 --> 00:10:27,839
see there's a graphics model inside the

270
00:10:25,440 --> 00:10:29,360
system and the system's exploring small

271
00:10:27,839 --> 00:10:31,279
edits that you could imagine making

272
00:10:29,360 --> 00:10:33,160
yourself with a graphics engine editor

273
00:10:31,279 --> 00:10:35,279
just way faster than you could do by

274
00:10:33,160 --> 00:10:38,160
hand. And ultimately that's how the

275
00:10:35,279 --> 00:10:40,160
system's fitting 3D models to data. And

276
00:10:38,160 --> 00:10:42,079
in fact it turns out this approach is

277
00:10:40,160 --> 00:10:44,800
just beginning to scale to open world

278
00:10:42,079 --> 00:10:47,440
video. So here I'm showing real RGB

279
00:10:44,800 --> 00:10:49,360
in-depth video captured from an iPad uh

280
00:10:47,440 --> 00:10:50,959
by my wonderful student George who did a

281
00:10:49,360 --> 00:10:53,399
lot of this research most recently along

282
00:10:50,959 --> 00:10:55,200
with Nashad and a stochastic

283
00:10:53,399 --> 00:10:57,360
reconstruction in terms of an

284
00:10:55,200 --> 00:10:58,880
explainable Gausian representation where

285
00:10:57,360 --> 00:11:00,880
the resolution is automatically

286
00:10:58,880 --> 00:11:04,120
adjusting as the objects move closer or

287
00:11:00,880 --> 00:11:06,640
farther from the camera.

288
00:11:04,120 --> 00:11:08,160
Uh and at the Quest for intelligence

289
00:11:06,640 --> 00:11:09,680
we've been building larger scale models

290
00:11:08,160 --> 00:11:12,000
of human perception based on

291
00:11:09,680 --> 00:11:13,600
representations like this. So consider

292
00:11:12,000 --> 00:11:16,240
the fact that our eyes and perceptual

293
00:11:13,600 --> 00:11:18,720
systems can connect the dots from sparse

294
00:11:16,240 --> 00:11:19,959
patterns where neural nets can may not

295
00:11:18,720 --> 00:11:21,760
be able to see

296
00:11:19,959 --> 00:11:23,120
anything. These are some of the

297
00:11:21,760 --> 00:11:24,720
capacities we think rationally

298
00:11:23,120 --> 00:11:25,480
engineered representations will unlock

299
00:11:24,720 --> 00:11:27,680
in

300
00:11:25,480 --> 00:11:30,240
perception. But what about expert

301
00:11:27,680 --> 00:11:32,320
systems and databases? Maybe that's a

302
00:11:30,240 --> 00:11:34,000
topic of interest to some of you here

303
00:11:32,320 --> 00:11:36,399
from industry. A couple of my startups

304
00:11:34,000 --> 00:11:38,200
over the years have worked in this area.

305
00:11:36,399 --> 00:11:40,560
Well, here I'm showing four different

306
00:11:38,200 --> 00:11:42,160
databases and I'm showing real data in

307
00:11:40,560 --> 00:11:43,680
one color and synthetic data from

308
00:11:42,160 --> 00:11:45,600
learned probabistic programs in another

309
00:11:43,680 --> 00:11:47,279
color. And so what you can see is we can

310
00:11:45,600 --> 00:11:48,800
learn probabistic models from data that

311
00:11:47,279 --> 00:11:50,399
accurately capture not just the main

312
00:11:48,800 --> 00:11:52,320
effects but the heterogeneity in the

313
00:11:50,399 --> 00:11:54,240
tails but also the error bars and the

314
00:11:52,320 --> 00:11:57,240
inferial uncertainty that's associated

315
00:11:54,240 --> 00:12:00,200
with rigorous reasoning from

316
00:11:57,240 --> 00:12:03,399
data. And this leads to an interesting

317
00:12:00,200 --> 00:12:06,560
project. Would it be possible to build a

318
00:12:03,399 --> 00:12:08,720
model of the global human population

319
00:12:06,560 --> 00:12:11,040
that uses probabistic inference to join

320
00:12:08,720 --> 00:12:13,600
across massive disperate data sources

321
00:12:11,040 --> 00:12:15,200
that don't share primary keys? A common

322
00:12:13,600 --> 00:12:16,200
asset to accelerate research and

323
00:12:15,200 --> 00:12:18,320
clinical

324
00:12:16,200 --> 00:12:19,680
trials. This kind of thing can't really

325
00:12:18,320 --> 00:12:20,959
be done with deep learning because we

326
00:12:19,680 --> 00:12:22,320
need to be able to audit what

327
00:12:20,959 --> 00:12:24,000
information flows through different

328
00:12:22,320 --> 00:12:25,680
parts of the model and we need to be

329
00:12:24,000 --> 00:12:27,680
able to quantify uncertainty where data

330
00:12:25,680 --> 00:12:28,880
is sparse. But with probabistic

331
00:12:27,680 --> 00:12:31,600
programs, we have the technical

332
00:12:28,880 --> 00:12:33,120
foundations that are needed to do that.

333
00:12:31,600 --> 00:12:34,880
And if you think about the sparity of

334
00:12:33,120 --> 00:12:36,880
this kind of data where there aren't

335
00:12:34,880 --> 00:12:40,079
primary keys, that's what I'm showing

336
00:12:36,880 --> 00:12:42,000
here on the slide, you can see that LLMs

337
00:12:40,079 --> 00:12:44,639
and tool use don't solve the problem.

338
00:12:42,000 --> 00:12:46,639
You somehow need a model that fills in

339
00:12:44,639 --> 00:12:48,800
all the gaps in the actual data we have

340
00:12:46,639 --> 00:12:52,279
and reasons in a coherent, rigorously

341
00:12:48,800 --> 00:12:54,560
grounded, probabilistically calibrated

342
00:12:52,279 --> 00:12:57,120
way. And we need to be able to talk to

343
00:12:54,560 --> 00:13:00,639
it in English. So one of the systems we

344
00:12:57,120 --> 00:13:02,720
built recently maps from English claims

345
00:13:00,639 --> 00:13:06,680
or queries like show age and gender for

346
00:13:02,720 --> 00:13:08,959
people who are Democrat voters to parse

347
00:13:06,680 --> 00:13:11,279
trees which can parse out different

348
00:13:08,959 --> 00:13:13,279
meanings of the phrase right does

349
00:13:11,279 --> 00:13:15,360
democrat voter mean registered democrats

350
00:13:13,279 --> 00:13:17,440
or people who identify as Democrats just

351
00:13:15,360 --> 00:13:17,440
for

352
00:13:17,959 --> 00:13:23,360
example or let's take an application

353
00:13:20,720 --> 00:13:26,079
that many of us may have uh some family

354
00:13:23,360 --> 00:13:28,720
experience for a family member just gets

355
00:13:26,079 --> 00:13:30,480
an unfortunate diagnosis and now we want

356
00:13:28,720 --> 00:13:32,440
to know okay what are what what's the

357
00:13:30,480 --> 00:13:34,639
person's likely

358
00:13:32,440 --> 00:13:36,160
prognosis. Well, with this kind of

359
00:13:34,639 --> 00:13:38,639
approach, we can get automated

360
00:13:36,160 --> 00:13:41,040
uncertainty calibrated prognosis even in

361
00:13:38,639 --> 00:13:42,800
realms where the data is sparse. Like

362
00:13:41,040 --> 00:13:44,800
for example, many cancer patients are

363
00:13:42,800 --> 00:13:46,880
older than most clinical trial

364
00:13:44,800 --> 00:13:48,560
populations in cancer. So there's a

365
00:13:46,880 --> 00:13:50,639
challenging statistical inference to do

366
00:13:48,560 --> 00:13:52,440
off sample to be able to deliver a

367
00:13:50,639 --> 00:13:55,040
capability like

368
00:13:52,440 --> 00:13:56,639
this. And at the Quest for Intelligence,

369
00:13:55,040 --> 00:13:58,079
we're also using the same approach to

370
00:13:56,639 --> 00:14:00,000
try to reverse engineer much more

371
00:13:58,079 --> 00:14:02,560
foundational aspects of human common

372
00:14:00,000 --> 00:14:05,839
sense. Our ability to ground language

373
00:14:02,560 --> 00:14:07,920
and models of the world or um as in work

374
00:14:05,839 --> 00:14:09,760
by my wonderful student Shen, our

375
00:14:07,920 --> 00:14:12,560
ability to generate behavior that helps

376
00:14:09,760 --> 00:14:15,519
other people, machines that really learn

377
00:14:12,560 --> 00:14:17,120
and think with us. So here you can see a

378
00:14:15,519 --> 00:14:19,199
famous video from developmental

379
00:14:17,120 --> 00:14:21,800
psychology where this adult is doing

380
00:14:19,199 --> 00:14:24,399
some kind of puzzling thing and this

381
00:14:21,800 --> 00:14:25,399
toddler spontaneously generates very

382
00:14:24,399 --> 00:14:27,440
helpful

383
00:14:25,399 --> 00:14:30,800
behavior even though the adult was

384
00:14:27,440 --> 00:14:30,800
clearly failing to achieve their

385
00:14:32,120 --> 00:14:36,800
goals. And uh my student Shen and others

386
00:14:35,199 --> 00:14:39,199
have been working on applying this kind

387
00:14:36,800 --> 00:14:41,519
of approach to make much better natural

388
00:14:39,199 --> 00:14:43,199
language assistance and to resolve some

389
00:14:41,519 --> 00:14:45,360
of the safety challenges we're starting

390
00:14:43,199 --> 00:14:47,760
to encounter uh with increasingly common

391
00:14:45,360 --> 00:14:48,880
agents that we might not want to entrust

392
00:14:47,760 --> 00:14:50,760
let's say to make credit card

393
00:14:48,880 --> 00:14:54,000
transactions on our

394
00:14:50,760 --> 00:14:56,000
behalf. So Shen has done work that's

395
00:14:54,000 --> 00:14:57,680
already been tested in virtual worlds

396
00:14:56,000 --> 00:14:59,160
and one of the next phases is to try to

397
00:14:57,680 --> 00:15:02,639
bring it into the real

398
00:14:59,160 --> 00:15:06,160
one. Okay. So zooming out over the last

399
00:15:02,639 --> 00:15:08,880
many decades actually all scale compute

400
00:15:06,160 --> 00:15:11,040
has been increasingly probabilistic from

401
00:15:08,880 --> 00:15:15,440
networks to the early web and data

402
00:15:11,040 --> 00:15:15,440
science to modern neural network

403
00:15:15,959 --> 00:15:21,760
systems. But what if we could start to

404
00:15:18,480 --> 00:15:23,839
pursue aworked modular rational scaling

405
00:15:21,760 --> 00:15:25,920
route for AI where the components were

406
00:15:23,839 --> 00:15:27,920
designed rather than relying entirely on

407
00:15:25,920 --> 00:15:30,000
learning? Maybe there would there would

408
00:15:27,920 --> 00:15:32,320
be a way to do it without necessarily

409
00:15:30,000 --> 00:15:34,040
centralizing so much uh within just a

410
00:15:32,320 --> 00:15:38,240
few AI

411
00:15:34,040 --> 00:15:40,000
labs. Okay. Um uh thank you. Um all this

412
00:15:38,240 --> 00:15:43,120
work was done in collaboration with many

413
00:15:40,000 --> 00:15:44,639
wonderful students and engineers. Um uh

414
00:15:43,120 --> 00:15:46,040
anyway I'm happy to take some is is

415
00:15:44,639 --> 00:15:50,399
there time for

416
00:15:46,040 --> 00:15:50,399
questions? Maybe not. Okay. Thank

417
00:15:53,079 --> 00:15:59,360
you question. Okay. Great.

418
00:15:57,440 --> 00:16:01,279
Great. So, one question, can we truly

419
00:15:59,360 --> 00:16:03,440
achieve predicting position and velocity

420
00:16:01,279 --> 00:16:05,199
simultaneously using a single camera

421
00:16:03,440 --> 00:16:07,600
akin to having stereoscopic vision?

422
00:16:05,199 --> 00:16:09,279
Yeah, it's a beautiful question. Um,

423
00:16:07,600 --> 00:16:10,639
yeah, so the quest for intelligence is

424
00:16:09,279 --> 00:16:12,320
working on this in its perceptual

425
00:16:10,639 --> 00:16:14,560
intelligence mission, both trying to

426
00:16:12,320 --> 00:16:16,560
build models of humans ability to do

427
00:16:14,560 --> 00:16:19,120
this and also use that as the basis for

428
00:16:16,560 --> 00:16:21,279
more capable machine perception systems.

429
00:16:19,120 --> 00:16:22,639
And one of the hypotheses we're testing

430
00:16:21,279 --> 00:16:24,800
which I showed you some early results

431
00:16:22,639 --> 00:16:26,959
from is engineered representations as

432
00:16:24,800 --> 00:16:28,800
compared to learn transformers. Um so

433
00:16:26,959 --> 00:16:30,160
yeah that's exactly the one of the types

434
00:16:28,800 --> 00:16:31,680
of questions we think is current. And

435
00:16:30,160 --> 00:16:33,600
I'll say more generally by the way since

436
00:16:31,680 --> 00:16:35,040
this is an industry audience. The quest

437
00:16:33,600 --> 00:16:37,279
for intelligence is engaging with

438
00:16:35,040 --> 00:16:38,639
corporate member companies. My lab has

439
00:16:37,279 --> 00:16:40,959
done that quite frequently over the

440
00:16:38,639 --> 00:16:42,800
years to field test early versions of

441
00:16:40,959 --> 00:16:44,560
these capabilities and help to discover

442
00:16:42,800 --> 00:16:46,240
where the differential edges really are

443
00:16:44,560 --> 00:16:48,480
with pure deep learning systems versus

444
00:16:46,240 --> 00:16:50,639
what are the cases like in our language

445
00:16:48,480 --> 00:16:52,240
understanding work where we use hybrids

446
00:16:50,639 --> 00:16:53,199
of probabistic programming and deep

447
00:16:52,240 --> 00:16:55,759
learning and we're actually

448
00:16:53,199 --> 00:16:56,959
experimenting with both um using open

449
00:16:55,759 --> 00:16:59,279
source platforms that have been

450
00:16:56,959 --> 00:17:00,959
developed here at MIT. So that's a way

451
00:16:59,279 --> 00:17:03,120
where some of your questions could get

452
00:17:00,959 --> 00:17:04,880
tested maybe with a little more vigor uh

453
00:17:03,120 --> 00:17:06,919
than uh just the discussion we can have

454
00:17:04,880 --> 00:17:09,199
here.

455
00:17:06,919 --> 00:17:10,559
Okay. World models are said to be

456
00:17:09,199 --> 00:17:12,160
essential for the practical use of

457
00:17:10,559 --> 00:17:13,760
humanoid robots. What do you see as the

458
00:17:12,160 --> 00:17:15,199
main possibilities and challenges in

459
00:17:13,760 --> 00:17:17,160
their real world implementation? Yeah,

460
00:17:15,199 --> 00:17:18,919
great question.

461
00:17:17,160 --> 00:17:21,280
Um,

462
00:17:18,919 --> 00:17:23,360
well, okay, I think the possibilities

463
00:17:21,280 --> 00:17:24,880
are fairly easy to imagine in broad

464
00:17:23,360 --> 00:17:26,079
terms if we could really have robots

465
00:17:24,880 --> 00:17:28,000
that had world models with the

466
00:17:26,079 --> 00:17:29,919
incredible scale and flexibility of our

467
00:17:28,000 --> 00:17:32,720
own world models.

468
00:17:29,919 --> 00:17:34,799
So I think one challenge, one question

469
00:17:32,720 --> 00:17:36,960
is will deep learning really be able to

470
00:17:34,799 --> 00:17:40,000
produce such world models merely by

471
00:17:36,960 --> 00:17:43,039
adding more data and compute or maybe

472
00:17:40,000 --> 00:17:44,280
even also inference time compute or will

473
00:17:43,039 --> 00:17:48,480
those scaling

474
00:17:44,280 --> 00:17:50,480
curves prove economically prohibitive.

475
00:17:48,480 --> 00:17:52,400
Second challenge for the thesis we're

476
00:17:50,480 --> 00:17:54,400
presenting is how will we scale up

477
00:17:52,400 --> 00:17:57,120
engineered rational representations that

478
00:17:54,400 --> 00:17:58,200
can be much more data efficient to have

479
00:17:57,120 --> 00:18:00,400
broad

480
00:17:58,200 --> 00:18:01,919
coverage. So we have some interesting

481
00:18:00,400 --> 00:18:03,120
early evidence that it's possible to

482
00:18:01,919 --> 00:18:04,960
scale engineered rational

483
00:18:03,120 --> 00:18:07,440
representations much farther than people

484
00:18:04,960 --> 00:18:09,200
thought even just a couple years ago and

485
00:18:07,440 --> 00:18:10,559
I think testing that out will be one of

486
00:18:09,200 --> 00:18:12,320
the main activities of the quest for

487
00:18:10,559 --> 00:18:14,640
intelligence and also industry partners

488
00:18:12,320 --> 00:18:18,360
over the coming years.

489
00:18:14,640 --> 00:18:18,360
Thank you very much.


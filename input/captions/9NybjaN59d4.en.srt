1
00:00:05,839 --> 00:00:11,840
Hello. Um, my name is Sasha Servin

2
00:00:08,760 --> 00:00:14,400
Shriber. I finished my PhD here at MIT

3
00:00:11,840 --> 00:00:16,480
about four months ago and I'm now the

4
00:00:14,400 --> 00:00:18,920
co-founder of Tinfoil where we're

5
00:00:16,480 --> 00:00:21,119
building confidential AI in the

6
00:00:18,920 --> 00:00:24,960
cloud. Uh, we're actually a team of

7
00:00:21,119 --> 00:00:27,920
four. Uh, two of us are PhDs from MIT in

8
00:00:24,960 --> 00:00:30,400
computer security and cryptography. Um

9
00:00:27,920 --> 00:00:32,320
and we're really excited to join uh Y

10
00:00:30,400 --> 00:00:34,079
Combinator for the spring batch starting

11
00:00:32,320 --> 00:00:36,360
in a week and we're also part of the

12
00:00:34,079 --> 00:00:40,079
NVIDIA inception

13
00:00:36,360 --> 00:00:41,960
program. So data privacy uh slowing is

14
00:00:40,079 --> 00:00:44,160
slowing down AI adoption across the

15
00:00:41,960 --> 00:00:47,440
enterprise. Um and the reason for this

16
00:00:44,160 --> 00:00:50,000
is if you're using AI today, you have to

17
00:00:47,440 --> 00:00:52,399
send all your potentially proprietary or

18
00:00:50,000 --> 00:00:56,160
um sensitive information to the AI

19
00:00:52,399 --> 00:00:58,079
provider or the AI application.

20
00:00:56,160 --> 00:01:00,559
Um and then this means that the

21
00:00:58,079 --> 00:01:02,520
application and provider can access and

22
00:01:00,559 --> 00:01:04,920
train on all your

23
00:01:02,520 --> 00:01:09,200
data. Indeed,

24
00:01:04,920 --> 00:01:10,720
57% of IT professionals site uh data

25
00:01:09,200 --> 00:01:13,400
privacy as being the number one

26
00:01:10,720 --> 00:01:15,760
inhibitor for Gen AI

27
00:01:13,400 --> 00:01:17,759
adoption. Um and this is not that much

28
00:01:15,760 --> 00:01:19,280
of a surprise because 48% of

29
00:01:17,759 --> 00:01:23,200
organizations

30
00:01:19,280 --> 00:01:26,880
uh put p um private company data into AI

31
00:01:23,200 --> 00:01:30,240
systems. And in fact, 4% of employees

32
00:01:26,880 --> 00:01:32,560
put uh sensitive data into AI systems on

33
00:01:30,240 --> 00:01:35,720
a weekly basis, which makes this problem

34
00:01:32,560 --> 00:01:38,159
only compounding over

35
00:01:35,720 --> 00:01:41,200
time. Um, unfortunately, existing

36
00:01:38,159 --> 00:01:44,479
solutions for data privacy are not a

37
00:01:41,200 --> 00:01:46,320
great fit for the AI age. data privacy

38
00:01:44,479 --> 00:01:47,680
agreements are difficult to enforce

39
00:01:46,320 --> 00:01:50,880
especially if you're dealing with small

40
00:01:47,680 --> 00:01:53,520
c um smaller companies building AI and

41
00:01:50,880 --> 00:01:56,560
traditional cyber security uh best

42
00:01:53,520 --> 00:01:59,280
practices do not really fit well with um

43
00:01:56,560 --> 00:02:02,240
AI deployments and so a lot of

44
00:01:59,280 --> 00:02:04,880
enterprises are now forced to shift to

45
00:02:02,240 --> 00:02:07,840
on-prem uh deployments of their AI

46
00:02:04,880 --> 00:02:10,080
systems which uh creates a a demand for

47
00:02:07,840 --> 00:02:13,760
or requires a lot of engineering effort

48
00:02:10,080 --> 00:02:13,760
to uh deploy and manage

49
00:02:14,080 --> 00:02:20,319
Um and so Tinfoil is providing a way to

50
00:02:17,760 --> 00:02:22,239
um get confidential AI in the cloud. So

51
00:02:20,319 --> 00:02:25,440
what this means is that you get the

52
00:02:22,239 --> 00:02:28,080
convenience of the cloud uh but the

53
00:02:25,440 --> 00:02:32,160
security of an on-prem deployment. Your

54
00:02:28,080 --> 00:02:34,319
data is always encrypted uh from the uh

55
00:02:32,160 --> 00:02:36,640
source all the way through the inference

56
00:02:34,319 --> 00:02:38,879
process. So even Tinfoil cannot see your

57
00:02:36,640 --> 00:02:41,680
data.

58
00:02:38,879 --> 00:02:43,440
Um, Tinfoil provides several guarantees.

59
00:02:41,680 --> 00:02:45,200
The first is that you have data

60
00:02:43,440 --> 00:02:48,160
confidentiality, meaning that everything

61
00:02:45,200 --> 00:02:51,319
you put into the AI system is going to

62
00:02:48,160 --> 00:02:53,680
be hidden even from the cloud or

63
00:02:51,319 --> 00:02:55,200
tinfoil. Uh, we also provide model

64
00:02:53,680 --> 00:02:57,920
confidentiality. So if you put a

65
00:02:55,200 --> 00:03:00,239
proprietary model into tinfoil, uh, no

66
00:02:57,920 --> 00:03:01,840
one can access the model weights uh,

67
00:03:00,239 --> 00:03:03,920
directly.

68
00:03:01,840 --> 00:03:05,680
and our infrastructure is transparent

69
00:03:03,920 --> 00:03:07,599
and verifiable, meaning that you can

70
00:03:05,680 --> 00:03:09,879
check for yourself that these two

71
00:03:07,599 --> 00:03:12,560
properties are

72
00:03:09,879 --> 00:03:15,680
enforced. The way we achieve this is by

73
00:03:12,560 --> 00:03:18,640
building on top of Nvidia GPUs with

74
00:03:15,680 --> 00:03:20,959
confidential compute mode. So this we

75
00:03:18,640 --> 00:03:25,040
create a secure enclave on an untrusted

76
00:03:20,959 --> 00:03:28,720
server that we uh run and all the data

77
00:03:25,040 --> 00:03:30,799
from uh your end user is encrypted

78
00:03:28,720 --> 00:03:33,599
directly to this secure enclave where

79
00:03:30,799 --> 00:03:34,879
it's then processed and sent back.

80
00:03:33,599 --> 00:03:36,959
Because we're building on top of

81
00:03:34,879 --> 00:03:40,080
state-of-the-art GPUs, there's no

82
00:03:36,959 --> 00:03:43,519
performance overhead relative to um

83
00:03:40,080 --> 00:03:45,840
traditional inference.

84
00:03:43,519 --> 00:03:49,760
We made it really easy to integrate

85
00:03:45,840 --> 00:03:52,720
tinfoil into existing deployments of um

86
00:03:49,760 --> 00:03:55,200
AI. So if you uh are running open source

87
00:03:52,720 --> 00:03:57,519
models like deepse llama with one line

88
00:03:55,200 --> 00:04:00,840
of code change you can uh start using

89
00:03:57,519 --> 00:04:03,040
tinfoil and secure your AI

90
00:04:00,840 --> 00:04:05,439
inference. Uh we're currently working

91
00:04:03,040 --> 00:04:07,920
closely with NeoCloud and inference

92
00:04:05,439 --> 00:04:10,879
providers who are looking to secure the

93
00:04:07,920 --> 00:04:13,760
their AI offerings. We're also building

94
00:04:10,879 --> 00:04:16,239
private rag and AI agents uh for

95
00:04:13,760 --> 00:04:18,400
user-facing applications and we work

96
00:04:16,239 --> 00:04:20,959
closely with an encrypted messaging

97
00:04:18,400 --> 00:04:22,800
application uh to build uh content

98
00:04:20,959 --> 00:04:25,160
moderation and spam filtering in a

99
00:04:22,800 --> 00:04:29,120
privacy preserving

100
00:04:25,160 --> 00:04:30,800
way. As the CTO of uh Microsoft Azure

101
00:04:29,120 --> 00:04:32,320
said the future of the cloud and the

102
00:04:30,800 --> 00:04:35,680
future of computing is going to be

103
00:04:32,320 --> 00:04:37,919
confidential. So if you're interested in

104
00:04:35,680 --> 00:04:40,000
uh deploying confidential AI inside your

105
00:04:37,919 --> 00:04:42,800
enterprise, we're interested in finding

106
00:04:40,000 --> 00:04:45,040
design partners uh across uh several

107
00:04:42,800 --> 00:04:47,360
verticals in the biotech space, finance

108
00:04:45,040 --> 00:04:49,840
or healthcare. So come talk to us. We

109
00:04:47,360 --> 00:04:52,400
have a booth um and really looking

110
00:04:49,840 --> 00:04:54,479
forward to talking with you all. Thank

111
00:04:52,400 --> 00:04:57,960
you.

112
00:04:54,479 --> 00:04:57,960
Thank you Sasha.


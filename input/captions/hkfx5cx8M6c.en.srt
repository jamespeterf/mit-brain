1
00:00:06,000 --> 00:00:10,480
My name's Lindseay Edwards. I'm the CTO

2
00:00:08,720 --> 00:00:13,280
of a company in London called Relation

3
00:00:10,480 --> 00:00:16,160
that does a lot of single cell and

4
00:00:13,280 --> 00:00:19,039
machine learning for drug discovery. Um,

5
00:00:16,160 --> 00:00:21,199
and it's a real treat to be here

6
00:00:19,039 --> 00:00:23,680
wherever Caroline is. Thank you for the

7
00:00:21,199 --> 00:00:26,800
for the invite and thank you for asking

8
00:00:23,680 --> 00:00:29,279
me to put together a committee to judge

9
00:00:26,800 --> 00:00:30,880
the posters. I spend way too much of my

10
00:00:29,279 --> 00:00:32,239
time thinking about raising money and

11
00:00:30,880 --> 00:00:34,800
whether our compute cluster is going to

12
00:00:32,239 --> 00:00:36,800
fall over or not. So, it's really nice

13
00:00:34,800 --> 00:00:39,600
to spend several days thinking about

14
00:00:36,800 --> 00:00:41,600
nothing but science. Um, and a couple of

15
00:00:39,600 --> 00:00:43,760
quick comments before we get right to

16
00:00:41,600 --> 00:00:45,600
the business. Uh, the first thing I

17
00:00:43,760 --> 00:00:47,039
would say is the level of science over

18
00:00:45,600 --> 00:00:49,920
the last couple of days has been

19
00:00:47,039 --> 00:00:52,640
absolutely phenomenal. So just to

20
00:00:49,920 --> 00:00:54,239
everyone that's here and and to all of

21
00:00:52,640 --> 00:00:56,719
the students that have presented the

22
00:00:54,239 --> 00:00:59,760
last couple of days um you're doing

23
00:00:56,719 --> 00:01:03,680
amazing work so feel very good about uh

24
00:00:59,760 --> 00:01:05,280
about yourselves. Um we tried to choose

25
00:01:03,680 --> 00:01:07,280
on the basis of three different things.

26
00:01:05,280 --> 00:01:09,680
So the first thing is originality. So

27
00:01:07,280 --> 00:01:13,040
how original is is the work that's being

28
00:01:09,680 --> 00:01:14,560
done. Second thing is scientific quality

29
00:01:13,040 --> 00:01:16,640
and then the third one is a slightly

30
00:01:14,560 --> 00:01:18,560
looser one that I would call something

31
00:01:16,640 --> 00:01:20,000
like scientific communication. And so

32
00:01:18,560 --> 00:01:22,000
the way that you were able to speak

33
00:01:20,000 --> 00:01:23,439
about your work at the poster or just

34
00:01:22,000 --> 00:01:25,119
the presentation of the poster, the

35
00:01:23,439 --> 00:01:29,040
clarity of the language, the clarity of

36
00:01:25,119 --> 00:01:30,720
the narrative, um, all really important.

37
00:01:29,040 --> 00:01:32,720
And one thing I would just add to that

38
00:01:30,720 --> 00:01:34,560
last thing is it feels like it's not

39
00:01:32,720 --> 00:01:36,320
science and we shouldn't care about it,

40
00:01:34,560 --> 00:01:38,400
but my god, it's important. Like if

41
00:01:36,320 --> 00:01:40,720
you're good at speaking, you'll get

42
00:01:38,400 --> 00:01:42,400
asked to speak. And the more you speak,

43
00:01:40,720 --> 00:01:44,799
the broader audience there is for your

44
00:01:42,400 --> 00:01:46,960
science. So please, you know, people who

45
00:01:44,799 --> 00:01:48,799
you see who are really good presenters

46
00:01:46,960 --> 00:01:50,560
almost never got that way by accident.

47
00:01:48,799 --> 00:01:53,439
They worked on it. It's worth spending a

48
00:01:50,560 --> 00:02:01,640
little bit of time on. Okay. So we have

49
00:01:53,439 --> 00:02:06,799
three prizes. Uh we have um £300. Sorry,

50
00:02:01,640 --> 00:02:06,799
dollars. You you might prefer £300.

51
00:02:07,160 --> 00:02:16,160
Um sorry, I couldn't help it. Uh three

52
00:02:11,720 --> 00:02:18,400
$300. Uh so in third place we have I'm

53
00:02:16,160 --> 00:02:20,640
getting so old I can't decide whether I

54
00:02:18,400 --> 00:02:25,840
need my glasses on or my glasses off. So

55
00:02:20,640 --> 00:02:27,920
in third place is um poster 21, an AI

56
00:02:25,840 --> 00:02:30,560
cyborg system for adaptive intelligent

57
00:02:27,920 --> 00:02:34,560
modulation of organoid maturation. And I

58
00:02:30,560 --> 00:02:39,959
think we have Xinhi Jang to to collect

59
00:02:34,560 --> 00:02:39,959
the prize. Amazing. Come on.

60
00:02:42,160 --> 00:02:47,640
Brilliant. Thank you very much indeed.

61
00:02:44,480 --> 00:02:47,640
Thank you.

62
00:02:49,160 --> 00:02:52,379
[Applause]

63
00:02:54,760 --> 00:02:59,160
Okay. In second place and with a prize

64
00:02:58,080 --> 00:03:04,080
of

65
00:02:59,160 --> 00:03:06,400
$400, uh it is poster 31, whisper

66
00:03:04,080 --> 00:03:08,000
inference of contact mediated cell

67
00:03:06,400 --> 00:03:10,310
signaling. And this is for

68
00:03:08,000 --> 00:03:15,699
Annarandrakumar.

69
00:03:10,310 --> 00:03:15,699
[Applause]

70
00:03:16,000 --> 00:03:20,760
Great stuff. Thank you. Thank you.

71
00:03:30,560 --> 00:03:34,120
And then in first place, we're hoping

72
00:03:32,959 --> 00:03:36,879
that

73
00:03:34,120 --> 00:03:40,680
the that the first authors uh made it

74
00:03:36,879 --> 00:03:43,200
back um by unanimous decision is poster

75
00:03:40,680 --> 00:03:44,959
25 mapping the topography of spatial

76
00:03:43,200 --> 00:03:48,720
gene expression with interpretable deep

77
00:03:44,959 --> 00:03:52,200
learning and it's Utsaf Chitra.

78
00:03:48,720 --> 00:03:52,200
Do we have

79
00:03:56,720 --> 00:03:58,879
is

80
00:03:59,400 --> 00:04:05,920
he now? Now I sing. No. Um, okay. What

81
00:04:04,159 --> 00:04:07,519
should we do? Should we we could we can

82
00:04:05,920 --> 00:04:10,560
have a little clap later maybe and move

83
00:04:07,519 --> 00:04:12,159
forward. Okay. Anyway, thank you to

84
00:04:10,560 --> 00:04:15,799
everybody. It's been a brilliant couple

85
00:04:12,159 --> 00:04:15,799
of days. Thank you, Caroline.

86
00:04:18,560 --> 00:04:23,079
Thank you so much for this.

87
00:04:23,080 --> 00:04:28,560
Okay, thank you Lindsay again and thank

88
00:04:26,320 --> 00:04:30,800
you to all the poster presenters for all

89
00:04:28,560 --> 00:04:33,040
of their work that they put into it and

90
00:04:30,800 --> 00:04:35,840
to you know enriching this uh conference

91
00:04:33,040 --> 00:04:38,600
with their amazing science. Um so now

92
00:04:35,840 --> 00:04:41,280
we're getting to the final um panel

93
00:04:38,600 --> 00:04:43,440
discussion. Um so this panel discussion

94
00:04:41,280 --> 00:04:46,000
is going to be on foundation models in

95
00:04:43,440 --> 00:04:48,240
biology. So kind of the computational

96
00:04:46,000 --> 00:04:50,639
counterpart to what we've um seen

97
00:04:48,240 --> 00:04:53,440
yesterday and again going all the way

98
00:04:50,639 --> 00:04:57,759
from all levels from DNA to protein to

99
00:04:53,440 --> 00:05:01,360
cells, tissues and organisms. And um we

100
00:04:57,759 --> 00:05:04,639
have a treat here for you um this uh

101
00:05:01,360 --> 00:05:06,320
afternoon. So I think I will reorganize

102
00:05:04,639 --> 00:05:08,479
the talks a little bit so that we start

103
00:05:06,320 --> 00:05:10,479
with proteins and then we'll go on to

104
00:05:08,479 --> 00:05:13,440
tissues, we'll go on to drug discovery

105
00:05:10,479 --> 00:05:16,479
and we'll go on to organisms and and

106
00:05:13,440 --> 00:05:19,039
hospitals and biases etc. um all the way

107
00:05:16,479 --> 00:05:21,520
at the end. So we'll start with Sergey

108
00:05:19,039 --> 00:05:24,800
of Chinikov um assistant professor in

109
00:05:21,520 --> 00:05:27,039
the department of biology um at MIT. um

110
00:05:24,800 --> 00:05:30,080
his lab studies protein structure and

111
00:05:27,039 --> 00:05:32,560
evolution in all levels. So

112
00:05:30,080 --> 00:05:35,919
environmental, organismal, genomic,

113
00:05:32,560 --> 00:05:39,280
structural and molecular um scales. And

114
00:05:35,919 --> 00:05:40,800
so welcome. And um we'll have your talk

115
00:05:39,280 --> 00:05:42,320
first and then we'll follow up with a

116
00:05:40,800 --> 00:05:45,320
panel discussion with everyone at the

117
00:05:42,320 --> 00:05:45,320
end.

118
00:05:51,680 --> 00:05:55,600
I wasn't planning to be first. Thought

119
00:05:53,919 --> 00:05:57,880
I'd still have a chance to change some

120
00:05:55,600 --> 00:06:00,880
slides, but too late

121
00:05:57,880 --> 00:06:00,880
now. All

122
00:06:06,280 --> 00:06:11,120
right. Right. So, yeah, thank you so

123
00:06:08,960 --> 00:06:13,440
much for inviting me to be here today.

124
00:06:11,120 --> 00:06:14,960
Um yeah so I'll tell you guys about some

125
00:06:13,440 --> 00:06:16,240
of the work we've been doing in uh

126
00:06:14,960 --> 00:06:18,160
trying to understand what protein and

127
00:06:16,240 --> 00:06:19,919
genomic language models are doing. uh

128
00:06:18,160 --> 00:06:22,720
depending how much time we have, we may

129
00:06:19,919 --> 00:06:25,440
or may not skip the genomics. But uh in

130
00:06:22,720 --> 00:06:27,360
big pictures, uh my group uh wonders a

131
00:06:25,440 --> 00:06:29,360
lot like what are big models learning?

132
00:06:27,360 --> 00:06:30,960
Like we we heard today about like the

133
00:06:29,360 --> 00:06:32,720
genome language models, protein language

134
00:06:30,960 --> 00:06:34,319
models. Um but what are they actually

135
00:06:32,720 --> 00:06:36,080
doing? Like what's this blackbox

136
00:06:34,319 --> 00:06:37,520
learning? And part of the reason we do

137
00:06:36,080 --> 00:06:39,360
this is because my lab we don't have

138
00:06:37,520 --> 00:06:41,440
that many GPUs. That's why I'm wearing

139
00:06:39,360 --> 00:06:42,960
this hat. Hopefully somebody would give

140
00:06:41,440 --> 00:06:45,440
us some. But because we don't have that

141
00:06:42,960 --> 00:06:48,960
many GPUs, we try to say, well, what

142
00:06:45,440 --> 00:06:50,639
could we as biologists or a scientist uh

143
00:06:48,960 --> 00:06:52,240
contribute to maybe maybe this giant

144
00:06:50,639 --> 00:06:53,840
field where companies are training these

145
00:06:52,240 --> 00:06:55,280
giant models like maybe we could look at

146
00:06:53,840 --> 00:06:56,800
these models and see are they learning

147
00:06:55,280 --> 00:06:58,240
new biology? Are they learning

148
00:06:56,800 --> 00:06:59,360
statistics? Like what how can we

149
00:06:58,240 --> 00:07:03,039
interpret them? What can we contribute

150
00:06:59,360 --> 00:07:05,280
in that perspective? Um so we all know

151
00:07:03,039 --> 00:07:06,720
proteins, DNA, RNA. Uh this is

152
00:07:05,280 --> 00:07:08,400
essentially a little cartoon picture of

153
00:07:06,720 --> 00:07:10,240
a of a sequence. But when you only have

154
00:07:08,400 --> 00:07:11,520
a single sequence, there's not much you

155
00:07:10,240 --> 00:07:12,720
can say about it. like maybe you know

156
00:07:11,520 --> 00:07:14,160
some physics, maybe you know some

157
00:07:12,720 --> 00:07:16,160
chemistry, but you're kind of stuck

158
00:07:14,160 --> 00:07:17,680
there. Uh but where things become really

159
00:07:16,160 --> 00:07:18,960
really powerful is if you can collect a

160
00:07:17,680 --> 00:07:20,880
bunch of sequences from many many

161
00:07:18,960 --> 00:07:23,240
different organisms. All of these

162
00:07:20,880 --> 00:07:25,680
sequences here uh all share common

163
00:07:23,240 --> 00:07:27,919
ancestry. Um and there's some positions

164
00:07:25,680 --> 00:07:30,080
that are conserved. Um some positions

165
00:07:27,919 --> 00:07:31,919
that are co uh maybe related to each

166
00:07:30,080 --> 00:07:33,120
other due to fogyny. For example, these

167
00:07:31,919 --> 00:07:34,880
two positions are due because of

168
00:07:33,120 --> 00:07:36,400
connections here and some positions are

169
00:07:34,880 --> 00:07:38,319
coaring with each other which maybe tell

170
00:07:36,400 --> 00:07:40,400
you something about structure. Uh and

171
00:07:38,319 --> 00:07:42,080
one thing we always wonder is how do we

172
00:07:40,400 --> 00:07:43,360
capture these constraints and more

173
00:07:42,080 --> 00:07:44,800
importantly maybe how do these

174
00:07:43,360 --> 00:07:46,479
foundational models that we learned

175
00:07:44,800 --> 00:07:49,280
about today are they capturing any of

176
00:07:46,479 --> 00:07:51,280
these constraints at all? Um and so how

177
00:07:49,280 --> 00:07:53,599
do we model these constraints? A very

178
00:07:51,280 --> 00:07:55,199
very simple model is to say well let's

179
00:07:53,599 --> 00:07:56,960
look look at look at these sequences and

180
00:07:55,199 --> 00:07:59,440
just pretend that there's only three

181
00:07:56,960 --> 00:08:01,360
positions three possible characters. Um

182
00:07:59,440 --> 00:08:02,879
and you could try to really model a very

183
00:08:01,360 --> 00:08:05,280
very simple model where you take the

184
00:08:02,879 --> 00:08:07,440
sequence uh one hot encode it because

185
00:08:05,280 --> 00:08:10,000
you need to somehow express blue yellow

186
00:08:07,440 --> 00:08:11,360
green so a computer would understand. Um

187
00:08:10,000 --> 00:08:12,879
then you could say well I'm going to try

188
00:08:11,360 --> 00:08:14,000
to model how the first position connects

189
00:08:12,879 --> 00:08:15,599
the second position how the second

190
00:08:14,000 --> 00:08:17,440
position connects the first position. So

191
00:08:15,599 --> 00:08:19,680
you have like a fully connected matrix.

192
00:08:17,440 --> 00:08:21,360
So imagine like a very simple linear

193
00:08:19,680 --> 00:08:22,479
layer. Uh and then of course there's

194
00:08:21,360 --> 00:08:23,840
some positions that may be completely

195
00:08:22,479 --> 00:08:25,680
conserved. They're not connected to

196
00:08:23,840 --> 00:08:28,479
anything. And so you have some parameter

197
00:08:25,680 --> 00:08:29,759
that models conservation. Um and then

198
00:08:28,479 --> 00:08:31,840
finally all the probabilities that the

199
00:08:29,759 --> 00:08:34,159
end should sum up to one. So imagine we

200
00:08:31,840 --> 00:08:35,839
have a very very simple uh linear layer

201
00:08:34,159 --> 00:08:38,080
where you have activations at the very

202
00:08:35,839 --> 00:08:39,519
end. Uh and then you try to minimize the

203
00:08:38,080 --> 00:08:41,599
inputs and the outputs. Say the inputs

204
00:08:39,519 --> 00:08:43,519
should match the outputs. Um if you

205
00:08:41,599 --> 00:08:45,279
train such a model on all the data that

206
00:08:43,519 --> 00:08:46,880
I showed a little earlier like train a

207
00:08:45,279 --> 00:08:48,240
model on all this data here you might

208
00:08:46,880 --> 00:08:50,080
imagine it will learn a very very

209
00:08:48,240 --> 00:08:51,360
trivial function of just saying I'm

210
00:08:50,080 --> 00:08:53,200
going to learn an identity matrix of

211
00:08:51,360 --> 00:08:54,160
anything mapping to outputs. And so it

212
00:08:53,200 --> 00:08:55,760
doesn't really learn anything

213
00:08:54,160 --> 00:08:57,920
meaningful. Where things become really

214
00:08:55,760 --> 00:08:59,760
really powerful if you say, "Hey, let me

215
00:08:57,920 --> 00:09:01,120
remove self connections." So I'm going

216
00:08:59,760 --> 00:09:02,320
to make sure like the first position is

217
00:09:01,120 --> 00:09:04,240
only connected to all the other

218
00:09:02,320 --> 00:09:05,519
positions but not to itself. And then

219
00:09:04,240 --> 00:09:07,920
you might imagine the model actually

220
00:09:05,519 --> 00:09:09,519
start to pick up on covolution like the

221
00:09:07,920 --> 00:09:11,480
fact that this position depends on this

222
00:09:09,519 --> 00:09:13,839
one and these edges might have that

223
00:09:11,480 --> 00:09:15,519
interpretation. Uh this model that

224
00:09:13,839 --> 00:09:17,360
actually does this uh one of these

225
00:09:15,519 --> 00:09:18,880
models is called gremlin. uh and this is

226
00:09:17,360 --> 00:09:21,120
the model that I'll be comparing to

227
00:09:18,880 --> 00:09:22,399
where I'm comparing the uh these genome

228
00:09:21,120 --> 00:09:24,160
language models and these protein

229
00:09:22,399 --> 00:09:25,440
language models too. Um and so this

230
00:09:24,160 --> 00:09:27,360
model essentially is very very simple.

231
00:09:25,440 --> 00:09:29,440
It just has a a weights and and a bias

232
00:09:27,360 --> 00:09:31,360
parameter. That's all it has. Um but

233
00:09:29,440 --> 00:09:34,000
this model is very very much

234
00:09:31,360 --> 00:09:35,600
interpretable unlike that block black

235
00:09:34,000 --> 00:09:36,880
box I showed at the very beginning. This

236
00:09:35,600 --> 00:09:39,839
one you could actually say hey these

237
00:09:36,880 --> 00:09:41,519
weights you could actually extract them

238
00:09:39,839 --> 00:09:42,959
uh and then maybe take some L2 norm of

239
00:09:41,519 --> 00:09:45,279
those weights to compress each of these

240
00:09:42,959 --> 00:09:47,279
3x3 matrices to one and now you have

241
00:09:45,279 --> 00:09:48,800
essentially a contact map and just to

242
00:09:47,279 --> 00:09:50,160
give you a big picture here you

243
00:09:48,800 --> 00:09:51,680
essentially these two connections these

244
00:09:50,160 --> 00:09:53,360
two residues are connected to each other

245
00:09:51,680 --> 00:09:54,720
and you can extract from the weights the

246
00:09:53,360 --> 00:09:56,560
fact that they are actually connected to

247
00:09:54,720 --> 00:09:57,839
each other and so it's very very easy to

248
00:09:56,560 --> 00:10:00,800
interpret we know exactly what those

249
00:09:57,839 --> 00:10:03,440
parameters mean um but and just to give

250
00:10:00,800 --> 00:10:05,279
you a real example uh here is a protein

251
00:10:03,440 --> 00:10:07,279
contact map um stretching out this

252
00:10:05,279 --> 00:10:09,440
protein from N terminus to C terminus,

253
00:10:07,279 --> 00:10:10,560
blue to red, blue to red. All of these

254
00:10:09,440 --> 00:10:12,640
contacts you see here are coming from

255
00:10:10,560 --> 00:10:14,320
the crystal structure. Um, and if I want

256
00:10:12,640 --> 00:10:16,560
to show how like the cyan part interacts

257
00:10:14,320 --> 00:10:19,519
with the orange part, cyan orange, I can

258
00:10:16,560 --> 00:10:21,279
look up on this matrix here. Um, now if

259
00:10:19,519 --> 00:10:22,880
I overlay these contacts that were

260
00:10:21,279 --> 00:10:25,279
extracted from just this very very

261
00:10:22,880 --> 00:10:26,480
simple model training, I can extract all

262
00:10:25,279 --> 00:10:28,000
these dependencies and the really

263
00:10:26,480 --> 00:10:30,240
exciting part is they overlap on the

264
00:10:28,000 --> 00:10:32,320
gray dots. So this is around 2011 people

265
00:10:30,240 --> 00:10:34,320
got really really excited because now we

266
00:10:32,320 --> 00:10:36,160
without any deep learning this is a very

267
00:10:34,320 --> 00:10:38,000
simple I guess you say simple machine

268
00:10:36,160 --> 00:10:39,360
learning we can extract these contacts

269
00:10:38,000 --> 00:10:40,640
from there and this can mean that we

270
00:10:39,360 --> 00:10:43,440
could start to predict protein

271
00:10:40,640 --> 00:10:45,440
structures um and so we know how to do

272
00:10:43,440 --> 00:10:47,040
it with very very simple models but how

273
00:10:45,440 --> 00:10:49,360
about more complex model like a protein

274
00:10:47,040 --> 00:10:51,440
language model that has maybe many many

275
00:10:49,360 --> 00:10:53,680
layers of transformers as we heard today

276
00:10:51,440 --> 00:10:55,839
from Patrick like maybe some kind of

277
00:10:53,680 --> 00:10:57,360
stripe hyena layers like how do we like

278
00:10:55,839 --> 00:10:59,680
interpret these things like how do we

279
00:10:57,360 --> 00:11:01,519
look inside this model. Um, turns out

280
00:10:59,680 --> 00:11:03,360
there's a relatively simple trick you

281
00:11:01,519 --> 00:11:05,200
can do because essentially the the input

282
00:11:03,360 --> 00:11:06,720
and the outputs are the same. Like you

283
00:11:05,200 --> 00:11:07,839
still have one hot encoded sequence,

284
00:11:06,720 --> 00:11:09,519
you're trying to recreate the sequence

285
00:11:07,839 --> 00:11:11,120
on the other side. Maybe you could do

286
00:11:09,519 --> 00:11:12,720
something much simpler where you just

287
00:11:11,120 --> 00:11:14,959
try to perturb the inputs and see how

288
00:11:12,720 --> 00:11:16,720
the outputs change. Um, but before I go

289
00:11:14,959 --> 00:11:18,560
into that detail just to give you a big

290
00:11:16,720 --> 00:11:20,399
comparison. So these are traditional

291
00:11:18,560 --> 00:11:23,200
models we used to fit. So for every

292
00:11:20,399 --> 00:11:24,880
protein family, we fit one model for

293
00:11:23,200 --> 00:11:26,480
every family. One of the things exciting

294
00:11:24,880 --> 00:11:29,920
about these protein language models like

295
00:11:26,480 --> 00:11:32,560
ESM uh other other I guess related

296
00:11:29,920 --> 00:11:35,120
models uh is that they are trained one

297
00:11:32,560 --> 00:11:36,640
model for all sequences. Um and they're

298
00:11:35,120 --> 00:11:38,480
trained the exact same way. The only

299
00:11:36,640 --> 00:11:40,000
difference is for for a single protein

300
00:11:38,480 --> 00:11:41,120
family you train one model or you say

301
00:11:40,000 --> 00:11:42,160
I'm going to train all the model. I'm

302
00:11:41,120 --> 00:11:43,519
going to put the sequence in. I'm going

303
00:11:42,160 --> 00:11:45,680
to try to recreate the sequence on the

304
00:11:43,519 --> 00:11:47,440
other side. And so one thing we've been

305
00:11:45,680 --> 00:11:49,040
wondering is like are these two models

306
00:11:47,440 --> 00:11:51,200
learning the same thing? Like is there

307
00:11:49,040 --> 00:11:53,200
somewhere inside these parameters these

308
00:11:51,200 --> 00:11:54,959
parameters? Um, and so how do we

309
00:11:53,200 --> 00:11:56,800
actually check if that's actually true?

310
00:11:54,959 --> 00:11:58,360
Um, and so these protein language

311
00:11:56,800 --> 00:12:01,040
models, as I said, train on all

312
00:11:58,360 --> 00:12:02,640
sequences. Um, and so the way we try to

313
00:12:01,040 --> 00:12:04,320
do this is say, well, could we try to

314
00:12:02,640 --> 00:12:06,160
map the inputs to the outputs? Because

315
00:12:04,320 --> 00:12:08,399
essentially this W matrix or this

316
00:12:06,160 --> 00:12:09,440
coution matrix is essentially just a

317
00:12:08,399 --> 00:12:10,880
mapping between the inputs and the

318
00:12:09,440 --> 00:12:12,639
outputs, which is a linear layer. And

319
00:12:10,880 --> 00:12:14,480
and the way we could do that is perturb

320
00:12:12,639 --> 00:12:16,399
the inputs. And here's a quick

321
00:12:14,480 --> 00:12:19,519
illustration here. So I can go to every

322
00:12:16,399 --> 00:12:22,079
single position um and try to mutate it

323
00:12:19,519 --> 00:12:23,600
to some other character and see how the

324
00:12:22,079 --> 00:12:26,399
logits change. So I can compute this

325
00:12:23,600 --> 00:12:28,160
delta logits and I can compute a matrix

326
00:12:26,399 --> 00:12:30,160
of every possible input to every

327
00:12:28,160 --> 00:12:31,600
possible output and then the exact same

328
00:12:30,160 --> 00:12:34,000
way as I did with my really really

329
00:12:31,600 --> 00:12:36,399
simple model convert that into a contact

330
00:12:34,000 --> 00:12:38,560
map. Um and one thing that we found that

331
00:12:36,399 --> 00:12:40,560
quite remarkable was that if you extract

332
00:12:38,560 --> 00:12:41,760
these contact maps or these covolution

333
00:12:40,560 --> 00:12:44,000
matrices from these very very simple

334
00:12:41,760 --> 00:12:45,760
model like Gremlin models uh and then do

335
00:12:44,000 --> 00:12:47,760
the same thing to a protein language

336
00:12:45,760 --> 00:12:50,079
models the the pair parameters that you

337
00:12:47,760 --> 00:12:51,680
extract are very closely similar and

338
00:12:50,079 --> 00:12:53,360
actually very well correlated to each

339
00:12:51,680 --> 00:12:56,000
other. So the parameters actually look

340
00:12:53,360 --> 00:12:59,519
very much similar uh between the two

341
00:12:56,000 --> 00:13:00,880
kinds of models. Um and so this sort of

342
00:12:59,519 --> 00:13:02,160
gives us this hypothesis that

343
00:13:00,880 --> 00:13:04,399
essentially what protein language models

344
00:13:02,160 --> 00:13:06,079
are doing are essentially uh learning

345
00:13:04,399 --> 00:13:08,240
like a library of Gremlin models and

346
00:13:06,079 --> 00:13:11,760
effectively acting as a a very very nice

347
00:13:08,240 --> 00:13:14,399
or cool uh lookup and compression

348
00:13:11,760 --> 00:13:16,480
algorithm. Uh so this could be both a

349
00:13:14,399 --> 00:13:18,959
pro and a con. I guess a pro is like

350
00:13:16,480 --> 00:13:20,560
well now you don't need to make MSAs. Uh

351
00:13:18,959 --> 00:13:22,079
maybe there's some shared parameters

352
00:13:20,560 --> 00:13:24,079
between families maybe it could do a

353
00:13:22,079 --> 00:13:25,600
better job. maybe a con if you were

354
00:13:24,079 --> 00:13:27,040
thought maybe this this model solved the

355
00:13:25,600 --> 00:13:29,600
protein folding problem then you're like

356
00:13:27,040 --> 00:13:30,639
well maybe it didn't um but but still we

357
00:13:29,600 --> 00:13:32,240
were kind of wondering is this actually

358
00:13:30,639 --> 00:13:33,600
what it's doing is it actually taking

359
00:13:32,240 --> 00:13:35,680
the sequence looking up some model

360
00:13:33,600 --> 00:13:37,839
internally and returning the sequence um

361
00:13:35,680 --> 00:13:39,839
and so we tried to design a quick

362
00:13:37,839 --> 00:13:41,920
experiment where we said okay is it

363
00:13:39,839 --> 00:13:43,519
looking up the entire structure or maybe

364
00:13:41,920 --> 00:13:45,440
it's just looking at motifs because

365
00:13:43,519 --> 00:13:47,600
there's proteins have little motifs that

366
00:13:45,440 --> 00:13:49,440
are shared across all proteins so maybe

367
00:13:47,600 --> 00:13:50,800
it's not actually just look storing

368
00:13:49,440 --> 00:13:53,519
entire protein families maybe just

369
00:13:50,800 --> 00:13:55,360
storing motifs Um and so Ziti and my

370
00:13:53,519 --> 00:13:56,720
group uh decided to do some experiments

371
00:13:55,360 --> 00:13:58,959
for this. Uh she's sitting around here

372
00:13:56,720 --> 00:14:00,560
somewhere. Try to find her later. But

373
00:13:58,959 --> 00:14:02,959
essentially we said well well let's take

374
00:14:00,560 --> 00:14:04,560
the protein for example and find a motif

375
00:14:02,959 --> 00:14:06,480
here. So in this case there's these two

376
00:14:04,560 --> 00:14:08,720
helix interacting with the with the beta

377
00:14:06,480 --> 00:14:10,560
strand. Um and then we try to add more

378
00:14:08,720 --> 00:14:12,639
contacts or remove contacts and see how

379
00:14:10,560 --> 00:14:14,480
much of the context needs to be able to

380
00:14:12,639 --> 00:14:16,639
recover these interactions. And the same

381
00:14:14,480 --> 00:14:18,160
thing for let's say two very distantly

382
00:14:16,639 --> 00:14:19,839
related motifs like this motif and this

383
00:14:18,160 --> 00:14:21,920
motif far away and sequence space.

384
00:14:19,839 --> 00:14:24,079
Sorry. I mean uh and if you add or more

385
00:14:21,920 --> 00:14:25,920
remove or remove contacts what happens

386
00:14:24,079 --> 00:14:28,959
uh and so what we find is that as you

387
00:14:25,920 --> 00:14:30,880
start to remove more and more contacts

388
00:14:28,959 --> 00:14:32,480
interestingly this motif is still there

389
00:14:30,880 --> 00:14:34,240
until you essentially remove so much of

390
00:14:32,480 --> 00:14:36,240
the protein that it's no longer able to

391
00:14:34,240 --> 00:14:38,240
so essentially we're literally just

392
00:14:36,240 --> 00:14:40,000
masking out everything around the

393
00:14:38,240 --> 00:14:42,000
sequence and the only thing the model

394
00:14:40,000 --> 00:14:43,839
sees this little motif and what we see

395
00:14:42,000 --> 00:14:45,920
is essentially we can mask almost the

396
00:14:43,839 --> 00:14:47,920
whole sequence and still see that motif.

397
00:14:45,920 --> 00:14:49,839
Um, same thing with the pair like these

398
00:14:47,920 --> 00:14:51,120
two helyses. We could essentially remove

399
00:14:49,839 --> 00:14:53,199
everything except for those two

400
00:14:51,120 --> 00:14:55,680
sequences of those T helyses and we

401
00:14:53,199 --> 00:14:57,839
still see the contacts. Um, and so what

402
00:14:55,680 --> 00:14:59,839
this suggests to us is that the model is

403
00:14:57,839 --> 00:15:01,440
not doing like a full fold lookup but

404
00:14:59,839 --> 00:15:04,240
maybe is doing some kind of motif lookup

405
00:15:01,440 --> 00:15:05,440
instead. Um, and so we we we wrote um a

406
00:15:04,240 --> 00:15:07,120
paper about this. If you guys want to

407
00:15:05,440 --> 00:15:09,600
check it out at some point you could.

408
00:15:07,120 --> 00:15:12,240
Um, uh, so in summary for at least this

409
00:15:09,600 --> 00:15:14,079
part is that um, we we do have a way of

410
00:15:12,240 --> 00:15:15,440
extracting contacts and it's very very

411
00:15:14,079 --> 00:15:17,199
powerful. you could apply it to any

412
00:15:15,440 --> 00:15:19,199
model where maybe you don't necessarily

413
00:15:17,199 --> 00:15:20,320
care about what the inputs are like,

414
00:15:19,199 --> 00:15:22,560
what exactly is in the middle of the

415
00:15:20,320 --> 00:15:24,639
model. Um, and so since then we've been

416
00:15:22,560 --> 00:15:26,880
now applying this model to other models

417
00:15:24,639 --> 00:15:29,600
like EVO, EVO 2 and asking similar kind

418
00:15:26,880 --> 00:15:31,279
of questions. Um, and so maybe looks

419
00:15:29,600 --> 00:15:32,480
like I still have three minutes. Okay.

420
00:15:31,279 --> 00:15:33,839
So, so since we have a little three

421
00:15:32,480 --> 00:15:35,600
minutes, I'll get into genomic language

422
00:15:33,839 --> 00:15:37,920
models. So, as you guys heard about

423
00:15:35,600 --> 00:15:39,440
today from Patrick is this really cool

424
00:15:37,920 --> 00:15:40,800
new model came out where you say, well,

425
00:15:39,440 --> 00:15:42,800
instead of training on protein

426
00:15:40,800 --> 00:15:44,240
sequences, what if we train on genomic

427
00:15:42,800 --> 00:15:46,480
sequences? So the the essentially the

428
00:15:44,240 --> 00:15:48,320
the task is very much the same. You have

429
00:15:46,480 --> 00:15:50,720
an input sequence. You mask part some of

430
00:15:48,320 --> 00:15:52,240
your uh nucleotides. In this case, you

431
00:15:50,720 --> 00:15:54,000
could do it in an auto reggressive way.

432
00:15:52,240 --> 00:15:55,680
Uh and then you recreate the amino acid,

433
00:15:54,000 --> 00:15:57,279
sorry, nucleotides on the other side. Um

434
00:15:55,680 --> 00:15:58,720
and there's lots of cool stuff happening

435
00:15:57,279 --> 00:15:59,839
in the middle, but for our purposes,

436
00:15:58,720 --> 00:16:00,959
like we said, we don't care what's

437
00:15:59,839 --> 00:16:02,720
actually happening in the middle. We

438
00:16:00,959 --> 00:16:05,279
wanted to see does it learn the correct

439
00:16:02,720 --> 00:16:07,279
uh input output mappings. Um and one

440
00:16:05,279 --> 00:16:09,199
thing that was quite exciting, we s we

441
00:16:07,279 --> 00:16:10,560
looks like it's capturing RNA contexts.

442
00:16:09,199 --> 00:16:12,720
like you could actually see if you

443
00:16:10,560 --> 00:16:13,839
perturb the inputs the output logs

444
00:16:12,720 --> 00:16:15,600
change and you could see that for

445
00:16:13,839 --> 00:16:18,079
example in this tRNA structure it is

446
00:16:15,600 --> 00:16:20,160
indeed capturing contacts. Um but when

447
00:16:18,079 --> 00:16:22,720
we applied it to protein structure we

448
00:16:20,160 --> 00:16:24,399
noticed that there were no contacts. Um

449
00:16:22,720 --> 00:16:26,480
so I mean it learned some kind of

450
00:16:24,399 --> 00:16:29,120
interesting patterns that kind of look

451
00:16:26,480 --> 00:16:31,120
like checkerboards. Um but the contacts

452
00:16:29,120 --> 00:16:32,959
for the most part appear to be missing.

453
00:16:31,120 --> 00:16:35,279
uh and so we were kind of wondering why

454
00:16:32,959 --> 00:16:37,440
are they missing for RNA it looks to be

455
00:16:35,279 --> 00:16:39,440
fine but from for protein like this is

456
00:16:37,440 --> 00:16:41,199
an example from a ESM the protein

457
00:16:39,440 --> 00:16:42,720
language model and this is an example

458
00:16:41,199 --> 00:16:44,560
from EVO where we did the same exact

459
00:16:42,720 --> 00:16:46,000
analysis the reason why this is half

460
00:16:44,560 --> 00:16:48,079
blank is because it is an auto

461
00:16:46,000 --> 00:16:50,079
reggressive model uh so you if you

462
00:16:48,079 --> 00:16:52,000
perturb something at the input only

463
00:16:50,079 --> 00:16:53,680
things after get changed but then later

464
00:16:52,000 --> 00:16:55,759
on don't don't really change so that's

465
00:16:53,680 --> 00:16:57,839
why it's only half um and so some

466
00:16:55,759 --> 00:17:00,160
hypothesis we had was maybe the model's

467
00:16:57,839 --> 00:17:02,160
just not large enough um and so we did

468
00:17:00,160 --> 00:17:04,000
look at EVO O2 and it still seems to be

469
00:17:02,160 --> 00:17:06,160
missing contact. So we think maybe

470
00:17:04,000 --> 00:17:08,240
that's not quite the only reason. Uh

471
00:17:06,160 --> 00:17:10,319
another hypothes well maybe there are

472
00:17:08,240 --> 00:17:11,760
other constraints that are overpowering

473
00:17:10,319 --> 00:17:13,520
like maybe there are protein contacts

474
00:17:11,760 --> 00:17:16,480
here. It's just that maybe there's other

475
00:17:13,520 --> 00:17:18,400
more stronger constraints coming from

476
00:17:16,480 --> 00:17:20,959
other genomic constraints that are sort

477
00:17:18,400 --> 00:17:22,959
of overpowering the signal. Um and

478
00:17:20,959 --> 00:17:24,480
finally maybe this we're just doing the

479
00:17:22,959 --> 00:17:26,480
analysis wrong. So that's always a

480
00:17:24,480 --> 00:17:28,480
possibility. Um, one hypothesis that

481
00:17:26,480 --> 00:17:30,480
we're kind of exploring now is maybe it

482
00:17:28,480 --> 00:17:32,240
has to do more with the fact that what

483
00:17:30,480 --> 00:17:34,160
does it mean to encode the nucleotide

484
00:17:32,240 --> 00:17:35,679
sequence for proteins. And so you

485
00:17:34,160 --> 00:17:37,360
probably all familiar, but if you like

486
00:17:35,679 --> 00:17:38,960
change the last codon, the last letter

487
00:17:37,360 --> 00:17:40,720
of a codon, you essentially stay the

488
00:17:38,960 --> 00:17:42,080
same amino acid. But even if you change

489
00:17:40,720 --> 00:17:43,679
the middle codon, like the letter of

490
00:17:42,080 --> 00:17:45,679
this middle codon, you have to either

491
00:17:43,679 --> 00:17:47,520
stay hydrophobic or hydrophilic based on

492
00:17:45,679 --> 00:17:49,440
transitions versus transversions. So you

493
00:17:47,520 --> 00:17:51,520
can maybe already recreate a lot of the

494
00:17:49,440 --> 00:17:52,640
sequence just based on your local uh

495
00:17:51,520 --> 00:17:55,760
signal. Like maybe you don't need to

496
00:17:52,640 --> 00:17:58,799
learn contacts. Um and so one analysis

497
00:17:55,760 --> 00:18:00,320
by Yunha uh who actually is joining MIT

498
00:17:58,799 --> 00:18:02,640
later. So if you guys want to talk to

499
00:18:00,320 --> 00:18:04,320
Yha, she'll be here in June. Um so she's

500
00:18:02,640 --> 00:18:06,720
a new assistant professor in MIT

501
00:18:04,320 --> 00:18:09,520
biology. Uh so one thing she tried say

502
00:18:06,720 --> 00:18:11,039
well instead of using uh nucleotide

503
00:18:09,520 --> 00:18:12,880
encoding could we just use amino acid

504
00:18:11,039 --> 00:18:14,559
encoding? And when you do that you

505
00:18:12,880 --> 00:18:16,640
actually see so this is just showing

506
00:18:14,559 --> 00:18:18,400
control two proteins contacts between

507
00:18:16,640 --> 00:18:20,320
the two proteins. Uh and then when you

508
00:18:18,400 --> 00:18:22,720
look at GLM2 you actually see really

509
00:18:20,320 --> 00:18:24,400
really strong contacts recovered. And

510
00:18:22,720 --> 00:18:26,640
just to contrast that to like EVO and

511
00:18:24,400 --> 00:18:28,000
ESM2, there are no contacts recovered.

512
00:18:26,640 --> 00:18:29,360
And so we think part of the reason might

513
00:18:28,000 --> 00:18:30,799
be because that reason. Okay, I think

514
00:18:29,360 --> 00:18:34,360
I'm out of time. So I'll stop there.

515
00:18:30,799 --> 00:18:34,360
Thank you very much.

516
00:18:36,799 --> 00:18:40,080
Thank you very much Sergey. We'll do

517
00:18:38,400 --> 00:18:42,000
discussion afterwards with everyone.

518
00:18:40,080 --> 00:18:44,320
Yep, that would be awesome. Perfect.

519
00:18:42,000 --> 00:18:46,400
Okay, so I think we'll move to Fasil

520
00:18:44,320 --> 00:18:48,000
next. Fasil Mahmud um assistant

521
00:18:46,400 --> 00:18:50,480
professor at Harvard Medical School and

522
00:18:48,000 --> 00:18:52,960
Dana Farber. his lab uh develops

523
00:18:50,480 --> 00:18:55,679
multimodal foundation models of going

524
00:18:52,960 --> 00:18:58,080
from diagnosis, prognosis, biomarker

525
00:18:55,679 --> 00:19:00,480
discovery and all of that particularly

526
00:18:58,080 --> 00:19:02,400
in the in the context of cancer but also

527
00:19:00,480 --> 00:19:05,400
in many other contexts as well. So

528
00:19:02,400 --> 00:19:05,400
welcome.

529
00:19:06,590 --> 00:19:10,490
[Applause]

530
00:19:16,320 --> 00:19:19,760
Um, thank you so much Caroline for the

531
00:19:18,400 --> 00:19:21,840
introduction and for inviting me to

532
00:19:19,760 --> 00:19:23,360
speak. Um, I'll be talking really

533
00:19:21,840 --> 00:19:25,840
quickly about some of the work that my

534
00:19:23,360 --> 00:19:27,840
group has done over the past past few

535
00:19:25,840 --> 00:19:30,240
years and uh, more more recently what

536
00:19:27,840 --> 00:19:32,080
we've done in in self-supervised models,

537
00:19:30,240 --> 00:19:33,600
foundation models to try some to address

538
00:19:32,080 --> 00:19:35,559
some of these questions from a clinical

539
00:19:33,600 --> 00:19:38,000
point of view. Here are my

540
00:19:35,559 --> 00:19:39,520
disclosures. Um, so what my group does

541
00:19:38,000 --> 00:19:41,919
is that we predominantly try to work

542
00:19:39,520 --> 00:19:44,559
with pathology images when glass slides

543
00:19:41,919 --> 00:19:46,400
are digitized. So, so pathology blast

544
00:19:44,559 --> 00:19:47,679
lies really the backbone of of biio

545
00:19:46,400 --> 00:19:49,039
medicine whether it's diagnostic,

546
00:19:47,679 --> 00:19:50,720
prognostic, therapeutic response

547
00:19:49,039 --> 00:19:53,039
related, but it also has lots of

548
00:19:50,720 --> 00:19:55,440
applications in uh in pre-clinical drug

549
00:19:53,039 --> 00:19:57,440
screening um trying to identify

550
00:19:55,440 --> 00:19:59,679
toxicology and so forth for for for drug

551
00:19:57,440 --> 00:20:01,440
discovery. So, a lot of tools we develop

552
00:19:59,679 --> 00:20:02,960
are are more generic and can be applied

553
00:20:01,440 --> 00:20:04,240
to applied to both. But today, I'll be

554
00:20:02,960 --> 00:20:06,160
talking specifically about some of the

555
00:20:04,240 --> 00:20:08,480
work we do in uh in in the diagnostic

556
00:20:06,160 --> 00:20:10,799
prognostic space. So, once these images

557
00:20:08,480 --> 00:20:12,320
are digitized, they are hierarchical.

558
00:20:10,799 --> 00:20:13,679
They harbor informations at many

559
00:20:12,320 --> 00:20:16,240
different scales and they look more like

560
00:20:13,679 --> 00:20:18,000
satellite satellite images and and it's

561
00:20:16,240 --> 00:20:20,799
a it's a very old diagnostic modality.

562
00:20:18,000 --> 00:20:22,240
It's been around for about 125 years but

563
00:20:20,799 --> 00:20:24,320
it's computational analysis is

564
00:20:22,240 --> 00:20:26,559
relatively recent. So there's been

565
00:20:24,320 --> 00:20:27,840
computational analysis for the past 3540

566
00:20:26,559 --> 00:20:30,320
years but really large scale

567
00:20:27,840 --> 00:20:32,480
computational analysis is is relatively

568
00:20:30,320 --> 00:20:34,080
very very recent and it's just recently

569
00:20:32,480 --> 00:20:35,919
begin to be digitized in in in

570
00:20:34,080 --> 00:20:37,760
hospitals. So when we when we're looking

571
00:20:35,919 --> 00:20:39,440
at these large images for some from a

572
00:20:37,760 --> 00:20:40,799
machine learning perspective, what comes

573
00:20:39,440 --> 00:20:42,400
to mind is multiple instance learning.

574
00:20:40,799 --> 00:20:44,039
So we can split them into smaller

575
00:20:42,400 --> 00:20:46,640
patches and then

576
00:20:44,039 --> 00:20:47,840
u use multiple instance learning uh on

577
00:20:46,640 --> 00:20:49,919
top of them. And there's there's a lot

578
00:20:47,840 --> 00:20:52,000
of work that was that was done training

579
00:20:49,919 --> 00:20:53,520
these models end to end which was

580
00:20:52,000 --> 00:20:55,200
computationally tedious and and over

581
00:20:53,520 --> 00:20:57,200
time we started to use these feature

582
00:20:55,200 --> 00:20:59,120
extractors where where we could could

583
00:20:57,200 --> 00:21:00,320
extract rich feature representations

584
00:20:59,120 --> 00:21:01,919
aggregate into slide level

585
00:21:00,320 --> 00:21:03,679
representations and then do whatever

586
00:21:01,919 --> 00:21:05,760
form of prediction we want to do on top

587
00:21:03,679 --> 00:21:07,440
of it. whether it's you know diagnostic

588
00:21:05,760 --> 00:21:10,559
which means you you can you could be

589
00:21:07,440 --> 00:21:13,840
looking at um detection of disease

590
00:21:10,559 --> 00:21:15,919
subtyping grading staging or if you pose

591
00:21:13,840 --> 00:21:18,640
it as a ranking problem it could become

592
00:21:15,919 --> 00:21:20,000
prognostic uh or related rel related to

593
00:21:18,640 --> 00:21:22,400
therapeutic response prediction and so

594
00:21:20,000 --> 00:21:23,840
forth and we sort of used this idea in a

595
00:21:22,400 --> 00:21:25,360
number of different studies over the

596
00:21:23,840 --> 00:21:27,200
years. We we you know tinkered with this

597
00:21:25,360 --> 00:21:28,480
method adding in attention and other

598
00:21:27,200 --> 00:21:30,159
bells and whistles that were being

599
00:21:28,480 --> 00:21:31,600
developed in the in the machine learning

600
00:21:30,159 --> 00:21:33,520
community but then also applying it to

601
00:21:31,600 --> 00:21:34,880
to to more challenging problems like

602
00:21:33,520 --> 00:21:37,120
predicting religions for cancers of

603
00:21:34,880 --> 00:21:41,039
unknown primary and mioardial biopsy

604
00:21:37,120 --> 00:21:43,120
detection uh in or or for for heart

605
00:21:41,039 --> 00:21:44,640
heart biopsies and also build building

606
00:21:43,120 --> 00:21:46,080
large scale prognostic models by

607
00:21:44,640 --> 00:21:47,760
including histologology and and

608
00:21:46,080 --> 00:21:49,520
molecular information. So coming back to

609
00:21:47,760 --> 00:21:50,880
this paradigm so more recently there's

610
00:21:49,520 --> 00:21:52,240
been a lot of work uh using

611
00:21:50,880 --> 00:21:53,840
self-supervised learning to extract

612
00:21:52,240 --> 00:21:55,600
vector feature representations. A lot of

613
00:21:53,840 --> 00:21:57,919
the previous work I showed was all done

614
00:21:55,600 --> 00:22:00,080
using ResNets trained on imageet and

615
00:21:57,919 --> 00:22:02,480
using those features for for training

616
00:22:00,080 --> 00:22:04,799
these models. So, so in this in this

617
00:22:02,480 --> 00:22:06,559
case we we we try to develop some some

618
00:22:04,799 --> 00:22:08,240
of those self-supervised models back

619
00:22:06,559 --> 00:22:10,400
dating back to 2021 and there are a

620
00:22:08,240 --> 00:22:11,520
bunch of conference articles we we we

621
00:22:10,400 --> 00:22:13,200
published just showing how

622
00:22:11,520 --> 00:22:15,280
self-supervised models can be used in in

623
00:22:13,200 --> 00:22:16,799
pathology and then last year we built

624
00:22:15,280 --> 00:22:19,919
you know these these foundation models.

625
00:22:16,799 --> 00:22:21,520
Uh, one of them was really just a Dinov2

626
00:22:19,919 --> 00:22:23,120
using lots of hospital data. And we

627
00:22:21,520 --> 00:22:24,960
learned from Dino V2 that diversity of

628
00:22:23,120 --> 00:22:27,600
data is way more important than than the

629
00:22:24,960 --> 00:22:29,200
quantity of data. And and we we went out

630
00:22:27,600 --> 00:22:31,200
looking at Brigham and MGH what are the

631
00:22:29,200 --> 00:22:32,799
most diverse cases and built those built

632
00:22:31,200 --> 00:22:34,480
those models and and at the at the same

633
00:22:32,799 --> 00:22:36,400
time we also built a visual vision

634
00:22:34,480 --> 00:22:38,559
language model. So just by using the

635
00:22:36,400 --> 00:22:40,240
Koka framework and contrasting with the

636
00:22:38,559 --> 00:22:41,679
corresponding text information to see if

637
00:22:40,240 --> 00:22:43,679
representation would improve. And these

638
00:22:41,679 --> 00:22:44,799
models, we we made these models publicly

639
00:22:43,679 --> 00:22:46,320
available and they've really been

640
00:22:44,799 --> 00:22:48,320
downloaded quite a lot around the world

641
00:22:46,320 --> 00:22:50,480
and have been used in over 400 different

642
00:22:48,320 --> 00:22:52,000
studies over the over the past past

643
00:22:50,480 --> 00:22:53,520
year. And I think one reason for this is

644
00:22:52,000 --> 00:22:54,960
that mythology data is becoming

645
00:22:53,520 --> 00:22:57,039
increasingly more available. And it's

646
00:22:54,960 --> 00:22:58,960
easy to just incorporate this data if

647
00:22:57,039 --> 00:23:01,360
you have rich rich representations

648
00:22:58,960 --> 00:23:03,039
representations available. But if you if

649
00:23:01,360 --> 00:23:05,280
we think about this, we also have lots

650
00:23:03,039 --> 00:23:06,640
of other multimodal data corresponding

651
00:23:05,280 --> 00:23:08,320
these patients. So histologology really

652
00:23:06,640 --> 00:23:10,159
acts as a diagnostic backbone. But

653
00:23:08,320 --> 00:23:12,480
there's also molecular data which has

654
00:23:10,159 --> 00:23:14,880
been collected over the past past 20 20

655
00:23:12,480 --> 00:23:16,960
years and we also do minister chemistry

656
00:23:14,880 --> 00:23:18,640
special stains um other kinds of

657
00:23:16,960 --> 00:23:21,840
ancillary testing corresponding these

658
00:23:18,640 --> 00:23:23,440
these uh these hisystologology the these

659
00:23:21,840 --> 00:23:25,520
patients and and we have that available

660
00:23:23,440 --> 00:23:27,520
corresponding to histologology and we

661
00:23:25,520 --> 00:23:29,120
have seen this from conventional

662
00:23:27,520 --> 00:23:31,360
computer vision and machine learning

663
00:23:29,120 --> 00:23:32,720
that that contrasting against modalities

664
00:23:31,360 --> 00:23:33,919
improves representation for all the

665
00:23:32,720 --> 00:23:35,200
modalities. So that's what we tried to

666
00:23:33,919 --> 00:23:37,120
explore in a bunch of these studies.

667
00:23:35,200 --> 00:23:40,000
This is from ECCV last year where we

668
00:23:37,120 --> 00:23:42,559
where we're contrasting with the uh uh

669
00:23:40,000 --> 00:23:44,320
with with IC stains uh molecular markers

670
00:23:42,559 --> 00:23:45,840
to see if we if by contrasting across

671
00:23:44,320 --> 00:23:47,440
these these stains we can improve

672
00:23:45,840 --> 00:23:49,440
representation and we then we apply it

673
00:23:47,440 --> 00:23:51,280
to a bunch of downstream tasks including

674
00:23:49,440 --> 00:23:54,320
survival outcome prediction as well as

675
00:23:51,280 --> 00:23:56,400
uh just just grading these these IoT IC

676
00:23:54,320 --> 00:23:59,919
slides and then same concept but instead

677
00:23:56,400 --> 00:24:01,520
of using um IC's we use transcrytoic

678
00:23:59,919 --> 00:24:03,120
data. This was sort of a toy example

679
00:24:01,520 --> 00:24:04,960
just done on the TCGA trying to see if

680
00:24:03,120 --> 00:24:08,559
in a few shot setting the representation

681
00:24:04,960 --> 00:24:09,840
would uh would would improve. Um so so

682
00:24:08,559 --> 00:24:11,440
we're essentially had it headed in this

683
00:24:09,840 --> 00:24:13,120
direction where by using more and more

684
00:24:11,440 --> 00:24:14,960
multimodel data we're able to improve

685
00:24:13,120 --> 00:24:17,679
image representation in itself by using

686
00:24:14,960 --> 00:24:20,080
fewer and fewer samples. So this was

687
00:24:17,679 --> 00:24:22,880
first sort of an indication where where

688
00:24:20,080 --> 00:24:24,400
we really we saw a few shot improvement

689
00:24:22,880 --> 00:24:25,600
on some of these more difficult tasks.

690
00:24:24,400 --> 00:24:28,159
This was the first indication that we

691
00:24:25,600 --> 00:24:29,679
should scale this idea. And we used

692
00:24:28,159 --> 00:24:31,840
basically all the molecular data that

693
00:24:29,679 --> 00:24:33,679
was available to us at Brigham and MGH

694
00:24:31,840 --> 00:24:35,679
together with paired hisystologology to

695
00:24:33,679 --> 00:24:36,880
see if we can contrast against them. And

696
00:24:35,679 --> 00:24:38,400
because we're not fusing here, we're

697
00:24:36,880 --> 00:24:40,159
contrasting against them, we could use

698
00:24:38,400 --> 00:24:41,520
molecular data that was collected using

699
00:24:40,159 --> 00:24:44,640
a variety of different mechanisms

700
00:24:41,520 --> 00:24:46,880
including uh the the NGS assay that we

701
00:24:44,640 --> 00:24:48,640
have at the Dana Farber uh Bigham Cancer

702
00:24:46,880 --> 00:24:51,919
Center as well as the transcripttoic

703
00:24:48,640 --> 00:24:53,760
assay that's frequently used at at MGH.

704
00:24:51,919 --> 00:24:55,360
um and then applying it to a bunch of

705
00:24:53,760 --> 00:24:56,880
different downstream tasks, we we we

706
00:24:55,360 --> 00:24:57,919
found that it it improved performance

707
00:24:56,880 --> 00:24:59,279
particularly for some of these more

708
00:24:57,919 --> 00:25:01,440
difficult tasks like treatment response

709
00:24:59,279 --> 00:25:03,200
prediction where it's difficult to get

710
00:25:01,440 --> 00:25:06,080
get these samples. So we have very few

711
00:25:03,200 --> 00:25:07,760
samples available. Um and these are just

712
00:25:06,080 --> 00:25:08,960
you know very very challenging

713
00:25:07,760 --> 00:25:10,320
challenging problems. Predicting

714
00:25:08,960 --> 00:25:12,080
treatment directly from histologology is

715
00:25:10,320 --> 00:25:13,279
is is a challenging problem but for the

716
00:25:12,080 --> 00:25:14,960
first time we we saw a jump in

717
00:25:13,279 --> 00:25:16,799
performance. We've we've basically been

718
00:25:14,960 --> 00:25:18,640
scaling this working together with other

719
00:25:16,799 --> 00:25:20,559
institutions to to get more

720
00:25:18,640 --> 00:25:23,679
corresponding molecular data to to scale

721
00:25:20,559 --> 00:25:25,120
this idea in in general. Um so once we

722
00:25:23,679 --> 00:25:27,039
had these rich representations an

723
00:25:25,120 --> 00:25:29,120
obvious next step for us was to see if

724
00:25:27,039 --> 00:25:30,480
we could build a build a co-pilot or or

725
00:25:29,120 --> 00:25:32,159
a generative model which can synthesize

726
00:25:30,480 --> 00:25:34,400
text corresponding this corresponding

727
00:25:32,159 --> 00:25:36,159
this this this information. Uh so to do

728
00:25:34,400 --> 00:25:38,400
that you need a large instruction set.

729
00:25:36,159 --> 00:25:39,360
So uh the philosophy behind this is that

730
00:25:38,400 --> 00:25:40,960
you know the these images are

731
00:25:39,360 --> 00:25:42,559
hierarchical harboring information at

732
00:25:40,960 --> 00:25:44,559
many different many different scales.

733
00:25:42,559 --> 00:25:46,080
But but the but the the the

734
00:25:44,559 --> 00:25:48,559
corresponding label that we have just

735
00:25:46,080 --> 00:25:50,960
resides in in pathology reports and the

736
00:25:48,559 --> 00:25:53,919
label is often corresponding just the

737
00:25:50,960 --> 00:25:55,440
slide or the all the cases that are oh

738
00:25:53,919 --> 00:25:57,360
sorry all the slides that are in that in

739
00:25:55,440 --> 00:26:00,320
that particular case. But to build a

740
00:25:57,360 --> 00:26:02,400
good useful co-pilot or a chatbot or you

741
00:26:00,320 --> 00:26:04,960
know multimodal large language model uh

742
00:26:02,400 --> 00:26:06,480
we need u instructions corresponding

743
00:26:04,960 --> 00:26:08,080
every level of abstraction whether it's

744
00:26:06,480 --> 00:26:10,720
at the region level at the patch level

745
00:26:08,080 --> 00:26:12,720
slide level or the case level. So we we

746
00:26:10,720 --> 00:26:14,159
started by curating those manually but

747
00:26:12,720 --> 00:26:16,559
quickly realized that this was just not

748
00:26:14,159 --> 00:26:17,760
scalable despite asking so many so many

749
00:26:16,559 --> 00:26:19,200
pathologists to contribute to this

750
00:26:17,760 --> 00:26:21,200
across multiple institutions and

751
00:26:19,200 --> 00:26:22,640
eventually we figured out that that the

752
00:26:21,200 --> 00:26:24,159
best thing we could do was to use

753
00:26:22,640 --> 00:26:27,039
teaching and training materials that we

754
00:26:24,159 --> 00:26:29,039
had at Bigham and MGH essentially using

755
00:26:27,039 --> 00:26:31,360
what's used to teach residents to teach

756
00:26:29,039 --> 00:26:33,279
the multimodal large language model uh

757
00:26:31,360 --> 00:26:35,200
to to be able to build this bu build

758
00:26:33,279 --> 00:26:36,960
this chatbot but this is a a study from

759
00:26:35,200 --> 00:26:38,559
June of last year where we're able to

760
00:26:36,960 --> 00:26:41,120
build a chatbot where you can go in and

761
00:26:38,559 --> 00:26:42,400
ask different questions about um about

762
00:26:41,120 --> 00:26:44,320
the image. In the beginning, this was

763
00:26:42,400 --> 00:26:46,720
just based on 500,000 instructions. We

764
00:26:44,320 --> 00:26:48,400
did try to maximize for diversity trying

765
00:26:46,720 --> 00:26:51,679
to represent every indication that exist

766
00:26:48,400 --> 00:26:54,159
existed in uh at within our Bigham and

767
00:26:51,679 --> 00:26:56,559
MGH databases. Uh but but since then

768
00:26:54,159 --> 00:26:59,760
it's been really expanded to around 5

769
00:26:56,559 --> 00:27:01,960
million cases and it also got FDA

770
00:26:59,760 --> 00:27:04,480
breakthrough device designation uh

771
00:27:01,960 --> 00:27:06,799
recently. Um there are better demos for

772
00:27:04,480 --> 00:27:08,400
this available publicly. We we're also

773
00:27:06,799 --> 00:27:09,760
very interested in building agents

774
00:27:08,400 --> 00:27:10,799
particularly for computational biology

775
00:27:09,760 --> 00:27:12,320
but you know I think this is something

776
00:27:10,799 --> 00:27:13,679
that everyone's interested in because

777
00:27:12,320 --> 00:27:15,279
generative models are getting better and

778
00:27:13,679 --> 00:27:16,400
better and they can make good scientific

779
00:27:15,279 --> 00:27:18,080
plans for what to do and in

780
00:27:16,400 --> 00:27:19,840
computational biology what we're doing

781
00:27:18,080 --> 00:27:22,320
very frequently is bringing new kinds of

782
00:27:19,840 --> 00:27:23,679
data to to existing tools. We we develop

783
00:27:22,320 --> 00:27:25,360
a lot of new tools but a lot of

784
00:27:23,679 --> 00:27:27,200
discovery can take place by bringing new

785
00:27:25,360 --> 00:27:28,799
kinds of data to to existing tools. So

786
00:27:27,200 --> 00:27:33,600
the question is that can you start with

787
00:27:28,799 --> 00:27:35,679
like a good um um just a prompt from a

788
00:27:33,600 --> 00:27:37,279
from a user break it down have a plan

789
00:27:35,679 --> 00:27:39,279
planning agent that breaks it down into

790
00:27:37,279 --> 00:27:40,559
into a schedule and then and a DAC

791
00:27:39,279 --> 00:27:43,200
scheduling unit that schedules which

792
00:27:40,559 --> 00:27:45,440
tools to use when and where and then uh

793
00:27:43,200 --> 00:27:47,360
essentially have a uh have a language

794
00:27:45,440 --> 00:27:49,279
agent uh and a coding agent that

795
00:27:47,360 --> 00:27:52,559
interfaces with this to to eventually

796
00:27:49,279 --> 00:27:54,640
create uh uh create an overall uh

797
00:27:52,559 --> 00:27:57,279
agentic agentic workflow. So this is

798
00:27:54,640 --> 00:27:59,200
what we have done in just for these

799
00:27:57,279 --> 00:28:01,440
tools right here. And this is just a

800
00:27:59,200 --> 00:28:03,520
just a demo of that where we can where

801
00:28:01,440 --> 00:28:05,919
the user comes in and says that well

802
00:28:03,520 --> 00:28:08,000
here I have a cohort of responders

803
00:28:05,919 --> 00:28:10,000
versus non-responders

804
00:28:08,000 --> 00:28:11,360
um and can you go train a model that

805
00:28:10,000 --> 00:28:13,279
would distinguish between between the

806
00:28:11,360 --> 00:28:15,279
two and it can go make a make a plan and

807
00:28:13,279 --> 00:28:17,360
then and then then go and execute it.

808
00:28:15,279 --> 00:28:18,720
This is uh surprisingly very easy to

809
00:28:17,360 --> 00:28:20,799
build technically because now we have

810
00:28:18,720 --> 00:28:23,679
all these uh models that generate very

811
00:28:20,799 --> 00:28:25,360
good uh very good plans. More recently

812
00:28:23,679 --> 00:28:27,840
we have updated this to where you can go

813
00:28:25,360 --> 00:28:30,159
back and sort of edit what the plan plan

814
00:28:27,840 --> 00:28:31,840
should be and we have deployed this at

815
00:28:30,159 --> 00:28:33,520
MGH and given it to all our pathology

816
00:28:31,840 --> 00:28:36,320
colleagues so they don't come to us when

817
00:28:33,520 --> 00:28:38,000
they need to train and train a model and

818
00:28:36,320 --> 00:28:41,919
uh they can just use this this kind of a

819
00:28:38,000 --> 00:28:43,120
setup to uh to do so. Um so once the

820
00:28:41,919 --> 00:28:45,520
model is trained it would you know you

821
00:28:43,120 --> 00:28:47,679
can you can can look at um how well the

822
00:28:45,520 --> 00:28:49,760
model is doing just by looking at the

823
00:28:47,679 --> 00:28:52,480
the AC curve and then you can go forward

824
00:28:49,760 --> 00:28:54,640
by looking at things like uh uh the the

825
00:28:52,480 --> 00:28:56,240
interpretability at the level of the of

826
00:28:54,640 --> 00:28:59,200
the heat map and you know maybe that's

827
00:28:56,240 --> 00:29:01,840
not good enough and and and you can then

828
00:28:59,200 --> 00:29:03,279
ask it to describe what it sees uh

829
00:29:01,840 --> 00:29:05,360
within the high tension regions across

830
00:29:03,279 --> 00:29:07,120
your entire entire test set and and it

831
00:29:05,360 --> 00:29:09,360
can use our our generative model to

832
00:29:07,120 --> 00:29:10,880
describe that. Um so yeah we're we're

833
00:29:09,360 --> 00:29:12,080
continuing to work in this direction and

834
00:29:10,880 --> 00:29:14,240
then there are a lot of interesting

835
00:29:12,080 --> 00:29:16,480
questions when you you know give them

836
00:29:14,240 --> 00:29:18,640
tasks and we're we're trying to assess

837
00:29:16,480 --> 00:29:20,159
how well these models do in achieving

838
00:29:18,640 --> 00:29:23,200
certain tasks and we're realizing that

839
00:29:20,159 --> 00:29:25,200
the models are good but they don't they

840
00:29:23,200 --> 00:29:26,799
don't quite match a graduate student and

841
00:29:25,200 --> 00:29:28,559
the reason is that graduate students are

842
00:29:26,799 --> 00:29:30,799
more hungry and we're we're we're trying

843
00:29:28,559 --> 00:29:33,840
to assess that how do you build in this

844
00:29:30,799 --> 00:29:36,080
uh this ambition hunger into the uh in

845
00:29:33,840 --> 00:29:37,279
into the model and this is like a open

846
00:29:36,080 --> 00:29:41,279
open question other people are working

847
00:29:37,279 --> 00:29:43,440
on on this too. Um uh but I I do want to

848
00:29:41,279 --> 00:29:44,960
touch upon Apollo. This is a new model

849
00:29:43,440 --> 00:29:48,960
that we recently built and would be

850
00:29:44,960 --> 00:29:50,399
coming out uh uh very very very soon uh

851
00:29:48,960 --> 00:29:52,880
where we have used data corresponding

852
00:29:50,399 --> 00:29:55,120
10.1 million patients from Brigham and

853
00:29:52,880 --> 00:29:56,799
and NMGH and really have tried to used

854
00:29:55,120 --> 00:29:58,720
all of the patient record that was uh

855
00:29:56,799 --> 00:30:00,720
that was available to us. This includes

856
00:29:58,720 --> 00:30:03,200
pathology, diagnostic reports, clinical

857
00:30:00,720 --> 00:30:04,960
and laboratory tests and uh uh all the

858
00:30:03,200 --> 00:30:06,559
EMRs. And we spent about two and a half

859
00:30:04,960 --> 00:30:08,159
years cleaning this cleaning this data

860
00:30:06,559 --> 00:30:09,600
made was definitely made easier once all

861
00:30:08,159 --> 00:30:11,760
these LLMs were available and could be

862
00:30:09,600 --> 00:30:13,279
locally locally served. But the idea is

863
00:30:11,760 --> 00:30:16,000
and this is just a distribution for all

864
00:30:13,279 --> 00:30:19,279
the all the uh diagnoses that were used

865
00:30:16,000 --> 00:30:20,559
and then we have the um the oral

866
00:30:19,279 --> 00:30:22,000
architecture where we have built lots of

867
00:30:20,559 --> 00:30:24,000
unimodal models corresponding these

868
00:30:22,000 --> 00:30:25,520
modalities and then we integrate them

869
00:30:24,000 --> 00:30:27,200
together and also have a temporal

870
00:30:25,520 --> 00:30:28,799
component to this where this there's an

871
00:30:27,200 --> 00:30:33,039
essentially essentially a representation

872
00:30:28,799 --> 00:30:35,279
which gets updated from uh uh based off

873
00:30:33,039 --> 00:30:37,440
of more and more information that comes

874
00:30:35,279 --> 00:30:38,880
in corresponding these uh these patients

875
00:30:37,440 --> 00:30:39,919
and there's a temporal trajectory to it

876
00:30:38,880 --> 00:30:42,559
and then we apply it to lots of

877
00:30:39,919 --> 00:30:43,840
downstream tasks. including for early

878
00:30:42,559 --> 00:30:45,360
diagnosis, treatment response

879
00:30:43,840 --> 00:30:46,799
prediction, biomarker discovery,

880
00:30:45,360 --> 00:30:48,799
clinical trial matching, and we're

881
00:30:46,799 --> 00:30:50,320
working with several pharma to to try to

882
00:30:48,799 --> 00:30:52,159
see how well it can work on clinical

883
00:30:50,320 --> 00:30:54,480
trial trial matching and population

884
00:30:52,159 --> 00:30:56,960
health in general. But really the scale

885
00:30:54,480 --> 00:30:58,240
of the data that we have makes this uh

886
00:30:56,960 --> 00:30:59,679
quite quite interesting because we have

887
00:30:58,240 --> 00:31:02,240
accumulated data not only from Brigham

888
00:30:59,679 --> 00:31:04,399
and MGH but we also have data from other

889
00:31:02,240 --> 00:31:07,840
uh institutions around uh around the

890
00:31:04,399 --> 00:31:09,600
country uh to to really in integrate u

891
00:31:07,840 --> 00:31:10,799
these these data sets and build a single

892
00:31:09,600 --> 00:31:12,559
model that can do patient level

893
00:31:10,799 --> 00:31:14,559
representation. So I want to thank

894
00:31:12,559 --> 00:31:17,200
everyone who I mean there are a lot of

895
00:31:14,559 --> 00:31:18,880
MIT students who worked on this over the

896
00:31:17,200 --> 00:31:21,520
uh over the years as well as all the

897
00:31:18,880 --> 00:31:23,440
funding that you know is probably going

898
00:31:21,520 --> 00:31:25,260
to be stopped very soon. So, thank you.

899
00:31:23,440 --> 00:31:29,760
Thank you so much.

900
00:31:25,260 --> 00:31:31,600
[Applause]

901
00:31:29,760 --> 00:31:35,760
Thank you. Thanks for ending on such a

902
00:31:31,600 --> 00:31:37,440
positive note. Um, okay. So, uh, now

903
00:31:35,760 --> 00:31:40,159
we'll talk take it to uh, drug

904
00:31:37,440 --> 00:31:42,320
discovery. Um, Shirley Leu, I'm very

905
00:31:40,159 --> 00:31:43,840
excited to have her here. She was a

906
00:31:42,320 --> 00:31:45,840
professor of bioatistics and

907
00:31:43,840 --> 00:31:47,519
computational biology at Dana Farber and

908
00:31:45,840 --> 00:31:49,919
Harvard School of Public of Public

909
00:31:47,519 --> 00:31:51,840
Health. um where she developed a lot of

910
00:31:49,919 --> 00:31:53,919
statistical and machine learning models

911
00:31:51,840 --> 00:31:55,440
for many important biological problems

912
00:31:53,919 --> 00:31:57,760
and also actually one of the first

913
00:31:55,440 --> 00:32:01,279
single cell RNA seek foundation models.

914
00:31:57,760 --> 00:32:04,480
Um and then in 2016 she co-founded uh

915
00:32:01,279 --> 00:32:09,480
GV20 therapeutics and has been at CEO

916
00:32:04,480 --> 00:32:13,549
since 2022. So welcome Shirley.

917
00:32:09,480 --> 00:32:13,549
[Music]

918
00:32:23,039 --> 00:32:29,200
Great. Thank you, Caroline, for the kind

919
00:32:26,200 --> 00:32:29,200
invitation.

920
00:32:30,039 --> 00:32:34,279
Um, I

921
00:32:31,960 --> 00:32:37,760
think I don't

922
00:32:34,279 --> 00:32:41,279
need Okay, great. Yeah. So, as Carla

923
00:32:37,760 --> 00:32:43,919
mentioned, I've been at GV20 for uh just

924
00:32:41,279 --> 00:32:45,960
over three years now. Um if you look at

925
00:32:43,919 --> 00:32:49,360
the last decade I would say cancer

926
00:32:45,960 --> 00:32:52,240
imunotherapy crisper and AI are the most

927
00:32:49,360 --> 00:32:55,200
exciting uh scientific breakthroughs and

928
00:32:52,240 --> 00:32:58,080
at GB20 our mission is to cure cancer by

929
00:32:55,200 --> 00:32:59,760
integrating cancer imunology crisper or

930
00:32:58,080 --> 00:33:03,440
other kind of high throughput technology

931
00:32:59,760 --> 00:33:06,640
and data and AI or computation. Um and

932
00:33:03,440 --> 00:33:08,799
so we focused on cancer imunotherapy

933
00:33:06,640 --> 00:33:11,679
because it is the only treatment to a

934
00:33:08,799 --> 00:33:14,480
true achieve true cure in metastatic

935
00:33:11,679 --> 00:33:16,960
tumors and if you look at the last year

936
00:33:14,480 --> 00:33:20,480
the highest selling cancer drug are the

937
00:33:16,960 --> 00:33:23,840
two cancer uh the antiPD1 therapeutics

938
00:33:20,480 --> 00:33:25,440
and uh antip1 is approved in over 40

939
00:33:23,840 --> 00:33:27,919
indications because they don't just

940
00:33:25,440 --> 00:33:30,080
specifically target cancer they try to

941
00:33:27,919 --> 00:33:32,799
boost the patient own immune system to

942
00:33:30,080 --> 00:33:36,080
indirectly cure the cancers but Even for

943
00:33:32,799 --> 00:33:38,080
a drug that's like a the most you know

944
00:33:36,080 --> 00:33:40,320
highest sold cancer drug, it only

945
00:33:38,080 --> 00:33:43,039
benefits about 20% of the cancer

946
00:33:40,320 --> 00:33:45,360
patients. So 80% of the cancer patient

947
00:33:43,039 --> 00:33:47,919
still needs better treatment. The

948
00:33:45,360 --> 00:33:50,279
conventional approach for a drug uh

949
00:33:47,919 --> 00:33:53,600
research and development process like

950
00:33:50,279 --> 00:33:56,960
antip antibbody is like this. Uh it's

951
00:33:53,600 --> 00:33:59,519
from gene uh to function to target or to

952
00:33:56,960 --> 00:34:01,679
uh to drug. So first scientists need to

953
00:33:59,519 --> 00:34:04,240
know that there is a PD1 gene or

954
00:34:01,679 --> 00:34:07,200
protein. It interacts with PDL1 to

955
00:34:04,240 --> 00:34:09,159
induce a T- cell dysfunction. Then they

956
00:34:07,200 --> 00:34:12,560
can develop an antibbody to block this

957
00:34:09,159 --> 00:34:14,960
interaction to um uh stimulate the T-

958
00:34:12,560 --> 00:34:16,879
cells for cancer killing. And the drug

959
00:34:14,960 --> 00:34:18,879
discovery, the target discovery is like

960
00:34:16,879 --> 00:34:20,399
three and 10 years. Drug discovery is

961
00:34:18,879 --> 00:34:22,399
another many years and clinical

962
00:34:20,399 --> 00:34:24,240
development just overall very long and

963
00:34:22,399 --> 00:34:26,320
expensive.

964
00:34:24,240 --> 00:34:29,359
So what I tell you what if I tell you

965
00:34:26,320 --> 00:34:32,119
that humans own immune system actually

966
00:34:29,359 --> 00:34:35,359
already produce and optimize anti-tumor

967
00:34:32,119 --> 00:34:37,440
antibodies in their tumors and in fact

968
00:34:35,359 --> 00:34:39,359
over millions of years of evolution

969
00:34:37,440 --> 00:34:42,159
enable the human immune system to

970
00:34:39,359 --> 00:34:44,960
recognize the tumor targets and optimize

971
00:34:42,159 --> 00:34:47,200
antibodies against them um and so they

972
00:34:44,960 --> 00:34:49,440
are usually made within the tumors in

973
00:34:47,200 --> 00:34:51,679
these tertiary lymphoid structures or

974
00:34:49,440 --> 00:34:54,240
bell aggregates

975
00:34:51,679 --> 00:34:56,159
um and it's it's been widely reported

976
00:34:54,240 --> 00:34:58,640
that the presence of these bell

977
00:34:56,159 --> 00:35:00,560
aggregates or tertiary lymph structures

978
00:34:58,640 --> 00:35:04,720
are associated with better patient

979
00:35:00,560 --> 00:35:06,560
response and antiPD1 um uh response and

980
00:35:04,720 --> 00:35:08,800
so you wonder if they already have

981
00:35:06,560 --> 00:35:11,680
anti-tumor antibodies why do patients

982
00:35:08,800 --> 00:35:14,400
still develop cancer um you can imagine

983
00:35:11,680 --> 00:35:16,720
in the lost territory in the war like a

984
00:35:14,400 --> 00:35:19,040
tumor there are still guerilla warriors

985
00:35:16,720 --> 00:35:21,280
that there are still fighting and if we

986
00:35:19,040 --> 00:35:23,839
can have tens of thousands of tumors to

987
00:35:21,280 --> 00:35:26,480
look at even if we don't know why they

988
00:35:23,839 --> 00:35:28,320
are uh they are still persisters. We

989
00:35:26,480 --> 00:35:30,560
know we need to train more soldiers like

990
00:35:28,320 --> 00:35:33,280
this to really win the war and that's

991
00:35:30,560 --> 00:35:36,320
the kind of approach we're taking. Um we

992
00:35:33,280 --> 00:35:38,880
have a proprietary AI platform that can

993
00:35:36,320 --> 00:35:42,920
identify novel cancer drug candidate

994
00:35:38,880 --> 00:35:45,440
directly from these tumor infiltrating

995
00:35:42,920 --> 00:35:47,839
antibodies. Um we actually don't have to

996
00:35:45,440 --> 00:35:50,560
do the tumor sequencing ourselves. There

997
00:35:47,839 --> 00:35:53,200
are a lot of um published the tumor RNA

998
00:35:50,560 --> 00:35:55,920
seek data available out there and when

999
00:35:53,200 --> 00:35:58,400
people sequence the RNA of a tumor, the

1000
00:35:55,920 --> 00:36:01,359
B cells infiltrating that tumor are also

1001
00:35:58,400 --> 00:36:03,119
making the antibbody RNA. And so we have

1002
00:36:01,359 --> 00:36:05,760
a computational approach called the

1003
00:36:03,119 --> 00:36:09,280
trust that can assemble antibodies from

1004
00:36:05,760 --> 00:36:11,599
these tumor RNA seek. And so at GV20 we

1005
00:36:09,280 --> 00:36:13,839
have assembled over a 100 million of

1006
00:36:11,599 --> 00:36:16,800
these tumor infiltrating antibodies from

1007
00:36:13,839 --> 00:36:19,200
tens of thousands of tumors. um they are

1008
00:36:16,800 --> 00:36:21,599
usually coming from the clonal expanded

1009
00:36:19,200 --> 00:36:24,480
B cells that are more likely to be

1010
00:36:21,599 --> 00:36:26,800
recognizing some tumor antigens. Turns

1011
00:36:24,480 --> 00:36:29,200
out we could use AI to predict the

1012
00:36:26,800 --> 00:36:31,920
targets of these antibodies and from

1013
00:36:29,200 --> 00:36:34,160
there we get to the drug. So intuitively

1014
00:36:31,920 --> 00:36:36,400
how do we make predictions? We don't

1015
00:36:34,160 --> 00:36:38,720
actually train on a known antigen

1016
00:36:36,400 --> 00:36:41,280
antibbody database. Instead we learn all

1017
00:36:38,720 --> 00:36:44,000
the features directly from our tumor

1018
00:36:41,280 --> 00:36:46,480
antibodies. For example, from the tumor

1019
00:36:44,000 --> 00:36:48,480
RNA seek expression, you can tell which

1020
00:36:46,480 --> 00:36:51,040
are her to positive tumors and which are

1021
00:36:48,480 --> 00:36:53,599
her to negative tumors. And if you see

1022
00:36:51,040 --> 00:36:56,079
any antibbody features, these are, you

1023
00:36:53,599 --> 00:36:57,920
know, peptide short peptide features

1024
00:36:56,079 --> 00:37:00,240
that are enriched in the hero to

1025
00:36:57,920 --> 00:37:02,800
positive tumors but depleted in the hero

1026
00:37:00,240 --> 00:37:04,560
negative tumors. That's a potential

1027
00:37:02,800 --> 00:37:06,320
herto binder. And if you have a

1028
00:37:04,560 --> 00:37:08,480
antibbody sequence that have all the

1029
00:37:06,320 --> 00:37:10,640
right features, then you know it's a

1030
00:37:08,480 --> 00:37:13,359
potential herto binder. And we don't

1031
00:37:10,640 --> 00:37:15,440
just do this for her too. Um we have

1032
00:37:13,359 --> 00:37:17,599
first of all a huge tumor collection and

1033
00:37:15,440 --> 00:37:19,440
we test it on every gene in the genome

1034
00:37:17,599 --> 00:37:21,680
and every mutation that's recurrently

1035
00:37:19,440 --> 00:37:24,320
occurring in the tumor. And so at the

1036
00:37:21,680 --> 00:37:26,560
end for every antibbody we have a

1037
00:37:24,320 --> 00:37:30,040
probabilistic assignment of this

1038
00:37:26,560 --> 00:37:32,720
antibbody to the protein or genes or

1039
00:37:30,040 --> 00:37:34,079
mutations. And so I hope this kind of

1040
00:37:32,720 --> 00:37:36,240
convinced you that we can get a

1041
00:37:34,079 --> 00:37:38,880
potentially interesting antibbody. Um

1042
00:37:36,240 --> 00:37:40,640
but how do we get to the target? Um the

1043
00:37:38,880 --> 00:37:42,960
first thing we you know with this AI

1044
00:37:40,640 --> 00:37:46,000
approach we we tested was that do do

1045
00:37:42,960 --> 00:37:48,720
patient make antiPD1 sorry make a her

1046
00:37:46,000 --> 00:37:50,720
two or EGFR antibodies these are drugs

1047
00:37:48,720 --> 00:37:52,960
that sell for about a billion dollars a

1048
00:37:50,720 --> 00:37:55,359
year and indeed we can make predictions

1049
00:37:52,960 --> 00:37:58,560
and experimentally validate that and

1050
00:37:55,359 --> 00:38:00,800
then we ask how about the PD1 PD1 we can

1051
00:37:58,560 --> 00:38:03,599
also um actually inhouse we have very

1052
00:38:00,800 --> 00:38:05,680
very good PD1 PD1 antibody that the PD1

1053
00:38:03,599 --> 00:38:08,160
we get we don't even need to optimize it

1054
00:38:05,680 --> 00:38:11,280
works from the bat and then we asked ask

1055
00:38:08,160 --> 00:38:13,280
how about the CD47 or SIGLA like 15

1056
00:38:11,280 --> 00:38:15,440
these are antibodies that have failed in

1057
00:38:13,280 --> 00:38:17,520
clinical trials interestingly we don't

1058
00:38:15,440 --> 00:38:20,079
see any patient antibbody signals in

1059
00:38:17,520 --> 00:38:22,160
them and so we thought oh maybe we can

1060
00:38:20,079 --> 00:38:25,119
use antibbody signal to tell us which

1061
00:38:22,160 --> 00:38:27,680
targets are promising um and which ones

1062
00:38:25,119 --> 00:38:29,920
are not going to make it and so we use

1063
00:38:27,680 --> 00:38:32,400
the antibbody signal to help us rank the

1064
00:38:29,920 --> 00:38:34,640
targets in addition once we have the

1065
00:38:32,400 --> 00:38:37,440
targets we can also use AI to directly

1066
00:38:34,640 --> 00:38:41,359
get to the antibbody drugs and so that's

1067
00:38:37,440 --> 00:38:43,920
why we call our approach this um uh stat

1068
00:38:41,359 --> 00:38:46,480
or simultaneous target evaluation and

1069
00:38:43,920 --> 00:38:48,320
antibbody discovery. And so then we said

1070
00:38:46,480 --> 00:38:51,240
okay let's try to predict something new

1071
00:38:48,320 --> 00:38:53,680
that nobody knows. And we focus on this

1072
00:38:51,240 --> 00:38:56,240
immunoglobin super family protein

1073
00:38:53,680 --> 00:38:58,400
because currently um all the immune

1074
00:38:56,240 --> 00:39:00,280
checkpoint genes belong to this family.

1075
00:38:58,400 --> 00:39:02,920
They are known to mediate cell

1076
00:39:00,280 --> 00:39:06,000
interaction and we found that this um

1077
00:39:02,920 --> 00:39:08,160
IGSF8 gene is interesting. many many

1078
00:39:06,000 --> 00:39:11,119
patients made a little bit of antibbody

1079
00:39:08,160 --> 00:39:14,160
against it. Um and we also looked at our

1080
00:39:11,119 --> 00:39:16,000
in-house crisper screen data. Um GV20

1081
00:39:14,160 --> 00:39:17,839
when we started was based on the crisper

1082
00:39:16,000 --> 00:39:19,599
screen technology. My lab were also

1083
00:39:17,839 --> 00:39:21,960
among the earliest to use crisper

1084
00:39:19,599 --> 00:39:25,119
screens for oncology and immunoncology

1085
00:39:21,960 --> 00:39:27,760
studies and we found that this IGSF8

1086
00:39:25,119 --> 00:39:30,240
gene normally does not influence cancer

1087
00:39:27,760 --> 00:39:32,400
cell growth unless the cancer cell is

1088
00:39:30,240 --> 00:39:34,160
under immune pressure. for example when

1089
00:39:32,400 --> 00:39:36,720
we co-culture the cancer cell with an

1090
00:39:34,160 --> 00:39:40,000
ENK cell or when we implant the cancer

1091
00:39:36,720 --> 00:39:41,680
cell in a fully immune mice and um so

1092
00:39:40,000 --> 00:39:44,560
without understanding the function of

1093
00:39:41,680 --> 00:39:46,720
this gene um we just said let's use AI

1094
00:39:44,560 --> 00:39:49,920
to pull out the antibbody that patient

1095
00:39:46,720 --> 00:39:52,000
made against IGSF8 and fortunately this

1096
00:39:49,920 --> 00:39:54,400
target is conserved between human and

1097
00:39:52,000 --> 00:39:57,520
mouse so the antibbody we got combined

1098
00:39:54,400 --> 00:39:59,920
to the mouse IGSF8 as well so we tried

1099
00:39:57,520 --> 00:40:02,640
on mouse tumors right away first in

1100
00:39:59,920 --> 00:40:04,400
melanoma but also in lung cancer, colon

1101
00:40:02,640 --> 00:40:06,880
cancer, breast cancer and prostate

1102
00:40:04,400 --> 00:40:08,800
cancer. And we consistently see the same

1103
00:40:06,880 --> 00:40:10,800
phenomenon like what we observe in

1104
00:40:08,800 --> 00:40:13,440
melanoma. This drug always have

1105
00:40:10,800 --> 00:40:16,240
monotherapy efficacy and very often

1106
00:40:13,440 --> 00:40:18,160
better than anti PD1 alone. And when we

1107
00:40:16,240 --> 00:40:20,079
combine the two drugs together by

1108
00:40:18,160 --> 00:40:21,400
halfing the dose of each, we get even

1109
00:40:20,079 --> 00:40:24,160
better

1110
00:40:21,400 --> 00:40:25,839
efficacy. So with this, we kind of felt

1111
00:40:24,160 --> 00:40:28,240
okay, we have to understand how this

1112
00:40:25,839 --> 00:40:29,920
gene work. At that time when we first

1113
00:40:28,240 --> 00:40:32,000
saw this gene, there were less than 10

1114
00:40:29,920 --> 00:40:34,400
papers ever published on this gene and

1115
00:40:32,000 --> 00:40:36,960
little known reported function. And so

1116
00:40:34,400 --> 00:40:39,839
we did the biology function of this uh

1117
00:40:36,960 --> 00:40:41,920
of this gene at the company. Um this is

1118
00:40:39,839 --> 00:40:43,680
also why I left Harvard to join the

1119
00:40:41,920 --> 00:40:46,880
company because my lab cannot work on

1120
00:40:43,680 --> 00:40:49,680
it. Um and uh we published a biology

1121
00:40:46,880 --> 00:40:51,839
study on the first half uh last year. Um

1122
00:40:49,680 --> 00:40:53,920
and uh we just submitted a second part

1123
00:40:51,839 --> 00:40:56,760
uh on the dendritic cell uh last

1124
00:40:53,920 --> 00:41:00,160
weekend. So this gene is kind of like a

1125
00:40:56,760 --> 00:41:02,240
PDL1 but for the innate uh immunity. It

1126
00:41:00,160 --> 00:41:04,960
suppresses the natural killer cells and

1127
00:41:02,240 --> 00:41:07,280
the dendritic cells especially when the

1128
00:41:04,960 --> 00:41:09,760
tumors are losing their MHC class one

1129
00:41:07,280 --> 00:41:12,960
antigen presentation. So they are

1130
00:41:09,760 --> 00:41:14,800
usually higher in the immune code tumors

1131
00:41:12,960 --> 00:41:17,520
and they are because when the tumors

1132
00:41:14,800 --> 00:41:20,160
don't express MHC class one they're

1133
00:41:17,520 --> 00:41:21,920
invisible to the T- cells. um but they

1134
00:41:20,160 --> 00:41:23,680
should be recognized and killed by the

1135
00:41:21,920 --> 00:41:27,040
ENK cells unless the cancer cell

1136
00:41:23,680 --> 00:41:29,359
overexpress IGSF8 and also it is

1137
00:41:27,040 --> 00:41:32,079
expressed on DC as well and interact

1138
00:41:29,359 --> 00:41:34,920
with dendritic cell to suppress the DC

1139
00:41:32,079 --> 00:41:37,920
antigen presentation and the T- cell um

1140
00:41:34,920 --> 00:41:40,319
activation and so with this antibbody we

1141
00:41:37,920 --> 00:41:42,560
can directly activate ENK cells and

1142
00:41:40,319 --> 00:41:45,280
dendritic cells and indirectly activate

1143
00:41:42,560 --> 00:41:48,560
T- cells so it's a very very exciting

1144
00:41:45,280 --> 00:41:50,480
mechanism um actually at the same time

1145
00:41:48,560 --> 00:41:53,280
as We work on the biology of this

1146
00:41:50,480 --> 00:41:56,480
target. We uh brought this drug to the

1147
00:41:53,280 --> 00:41:58,359
clinic and um uh we have by now finished

1148
00:41:56,480 --> 00:42:00,720
the phase one monotherapy dose

1149
00:41:58,359 --> 00:42:02,960
escalation. This drug has excellent

1150
00:42:00,720 --> 00:42:06,400
developability and really good PK

1151
00:42:02,960 --> 00:42:09,359
profiles. Um we have those 42 patients

1152
00:42:06,400 --> 00:42:12,240
and um 38 are evaluable. The drug is

1153
00:42:09,359 --> 00:42:14,319
very very safe and uh we saw tumor

1154
00:42:12,240 --> 00:42:17,119
shrinkage in non small cell lung cancer

1155
00:42:14,319 --> 00:42:19,520
and cervical cancer. But the very first

1156
00:42:17,119 --> 00:42:21,680
melanoma patient we tried was a partial

1157
00:42:19,520 --> 00:42:23,920
responders. And so we asked the sites to

1158
00:42:21,680 --> 00:42:26,319
give us more backfill of the melanoma

1159
00:42:23,920 --> 00:42:29,000
patients. And so by now we have dosed

1160
00:42:26,319 --> 00:42:31,920
the 17 melanoma patients uh with

1161
00:42:29,000 --> 00:42:33,760
monotherapy. And interestingly um well

1162
00:42:31,920 --> 00:42:37,240
all of them have previously been treated

1163
00:42:33,760 --> 00:42:39,599
with anti PD1. 16 has been treated with

1164
00:42:37,240 --> 00:42:41,839
anti-Cta4. And then we treated our drug,

1165
00:42:39,599 --> 00:42:44,480
you know, just monotherapy. And out of

1166
00:42:41,839 --> 00:42:46,640
the nine patients who previously never

1167
00:42:44,480 --> 00:42:49,839
responded to antiPD1 with a primary

1168
00:42:46,640 --> 00:42:52,720
refractory to antiPD1, we thought we saw

1169
00:42:49,839 --> 00:42:55,040
three confirmed partial responders and

1170
00:42:52,720 --> 00:42:57,040
three patients with tumor shrinkage and

1171
00:42:55,040 --> 00:42:59,680
another patient who are on wheelchairs

1172
00:42:57,040 --> 00:43:02,000
before after being treated with our drug

1173
00:42:59,680 --> 00:43:04,319
walked again. And so it's really

1174
00:43:02,000 --> 00:43:06,880
benefiting the patient. Um, this is from

1175
00:43:04,319 --> 00:43:08,720
the CT and PET CT scan. You can see the

1176
00:43:06,880 --> 00:43:11,920
very first patient or some

1177
00:43:08,720 --> 00:43:14,960
representative uh um tumors this big

1178
00:43:11,920 --> 00:43:16,640
foot lesion shrank significantly and the

1179
00:43:14,960 --> 00:43:19,760
second and third patients both have

1180
00:43:16,640 --> 00:43:23,040
liver metastasis and this one shrank by

1181
00:43:19,760 --> 00:43:25,680
uh 58% and a third patient the 24

1182
00:43:23,040 --> 00:43:27,839
millimeter um liver metastasis

1183
00:43:25,680 --> 00:43:30,640
completely disappeared. This patient

1184
00:43:27,839 --> 00:43:33,119
before our drug in seven months used

1185
00:43:30,640 --> 00:43:35,680
five different drugs and progressed very

1186
00:43:33,119 --> 00:43:38,000
quickly. And initially on our drug uh

1187
00:43:35,680 --> 00:43:40,319
the patient tumor was still growing and

1188
00:43:38,000 --> 00:43:42,480
then it started to respond uh at month

1189
00:43:40,319 --> 00:43:44,480
seven and the patient has been on our

1190
00:43:42,480 --> 00:43:47,520
treatment for over 13 months now and

1191
00:43:44,480 --> 00:43:50,960
still responding. Um in comparison to

1192
00:43:47,520 --> 00:43:53,079
other IO drugs this drug in the early uh

1193
00:43:50,960 --> 00:43:56,000
clinical study is actually better than

1194
00:43:53,079 --> 00:43:57,359
CT4 much much better than lac and tg

1195
00:43:56,000 --> 00:43:59,680
because they don't really have any

1196
00:43:57,359 --> 00:44:04,800
single agent efficacy. In fact it's

1197
00:43:59,680 --> 00:44:06,880
similar to antiPD1 from BMS. um for uh

1198
00:44:04,800 --> 00:44:08,480
for the merc drug you know that out of

1199
00:44:06,880 --> 00:44:11,119
30 patients they did have five

1200
00:44:08,480 --> 00:44:14,640
responders but these patients only had

1201
00:44:11,119 --> 00:44:17,520
2.5 line of prior treatment whereas um

1202
00:44:14,640 --> 00:44:19,760
in our phase one uh together with BMS

1203
00:44:17,520 --> 00:44:22,240
it's like four prior line of treatment

1204
00:44:19,760 --> 00:44:24,240
in imunotherapy every prior line of

1205
00:44:22,240 --> 00:44:27,280
treatment reduced the response by about

1206
00:44:24,240 --> 00:44:29,280
10%. And so we saw that our drug was

1207
00:44:27,280 --> 00:44:31,640
actually having similar efficacy as

1208
00:44:29,280 --> 00:44:34,400
antiPD1 in phase one

1209
00:44:31,640 --> 00:44:37,400
clinics. We also saw that the tumor have

1210
00:44:34,400 --> 00:44:39,839
significantly increased ENK and T- cell

1211
00:44:37,400 --> 00:44:42,000
infiltration even among patients who

1212
00:44:39,839 --> 00:44:44,000
don't respond to the drug suggesting

1213
00:44:42,000 --> 00:44:46,960
that these patient could be reensitized

1214
00:44:44,000 --> 00:44:49,800
to antiPD1. And also the responders seem

1215
00:44:46,960 --> 00:44:52,000
to have higher IGS8 expression than the

1216
00:44:49,800 --> 00:44:54,560
non-responders suggesting that we should

1217
00:44:52,000 --> 00:44:56,359
select the IGSF8 positive tumors to

1218
00:44:54,560 --> 00:44:59,599
enrich for responding

1219
00:44:56,359 --> 00:45:01,440
signals. So how does AI really help us?

1220
00:44:59,599 --> 00:45:02,960
If you look at the development of

1221
00:45:01,440 --> 00:45:04,640
antiPD1,

1222
00:45:02,960 --> 00:45:06,480
um we don't actually know when the

1223
00:45:04,640 --> 00:45:08,359
research started, but the very first

1224
00:45:06,480 --> 00:45:11,359
publication was in

1225
00:45:08,359 --> 00:45:13,680
1992 and uh it took another eight years

1226
00:45:11,359 --> 00:45:16,800
to uh for people to figure out the

1227
00:45:13,680 --> 00:45:18,640
interaction partner was PDL1 and then

1228
00:45:16,800 --> 00:45:20,960
another six years to develop the drug

1229
00:45:18,640 --> 00:45:23,839
and three years to do the antibbody uh

1230
00:45:20,960 --> 00:45:25,839
phase one uh study. Whereas from the

1231
00:45:23,839 --> 00:45:29,280
first day we saw this little known gene

1232
00:45:25,839 --> 00:45:33,160
was end of like 2019 to the end of phase

1233
00:45:29,280 --> 00:45:36,240
one was uh only five years. And this is

1234
00:45:33,160 --> 00:45:37,760
because AI told us how patient is

1235
00:45:36,240 --> 00:45:41,200
fighting the tumor without us

1236
00:45:37,760 --> 00:45:44,000
understanding why. And um um in in

1237
00:45:41,200 --> 00:45:46,640
actually a drug uh development um

1238
00:45:44,000 --> 00:45:49,680
trajectory. If you look at the revenues

1239
00:45:46,640 --> 00:45:52,160
generated on the KUDA drug um towards

1240
00:45:49,680 --> 00:45:54,560
the later years that's when the income

1241
00:45:52,160 --> 00:45:58,079
really comes. So if you can shrink the

1242
00:45:54,560 --> 00:46:01,599
uh time from patent to drug approval it

1243
00:45:58,079 --> 00:46:05,200
can sign significantly increase the drug

1244
00:46:01,599 --> 00:46:08,160
uh patent value and we are doing this uh

1245
00:46:05,200 --> 00:46:10,000
uh again to build a robust pipeline in

1246
00:46:08,160 --> 00:46:13,359
addition to this drug. you know we have

1247
00:46:10,000 --> 00:46:15,440
other antibodies and recently we had a a

1248
00:46:13,359 --> 00:46:18,480
partnership agreement with Mishubish

1249
00:46:15,440 --> 00:46:20,640
Tanab on some other programs again first

1250
00:46:18,480 --> 00:46:23,359
inclass novel targets that we have

1251
00:46:20,640 --> 00:46:26,640
antibodies for um and so how are we

1252
00:46:23,359 --> 00:46:29,920
going to use AI um so the the actually

1253
00:46:26,640 --> 00:46:32,079
the AI we use currently is just a deep

1254
00:46:29,920 --> 00:46:34,160
learning model um we can use

1255
00:46:32,079 --> 00:46:36,240
foundational models uh by pre-training

1256
00:46:34,160 --> 00:46:39,200
on all the proteins and all the

1257
00:46:36,240 --> 00:46:41,440
antibodies in blood and fine-tune on

1258
00:46:39,200 --> 00:46:43,920
antibodies from tumor or from other

1259
00:46:41,440 --> 00:46:46,800
diseases. Um but this takes a lot more

1260
00:46:43,920 --> 00:46:49,040
money. Um right now you know we we need

1261
00:46:46,800 --> 00:46:52,160
more resources to do this more uh

1262
00:46:49,040 --> 00:46:53,839
computationally intensive uh exercises.

1263
00:46:52,160 --> 00:46:55,760
Um but you know look forward to

1264
00:46:53,839 --> 00:46:57,920
collaborating with all of you guys

1265
00:46:55,760 --> 00:47:01,560
potentially to find a cure for cancer.

1266
00:46:57,920 --> 00:47:01,560
Thank you very much.

1267
00:47:06,160 --> 00:47:10,800
Wonderful. Thank you very much Shirley.

1268
00:47:08,560 --> 00:47:14,240
And now it's my pleasure to introduce my

1269
00:47:10,800 --> 00:47:16,400
faculty colleague uh Marzia Gosi um who

1270
00:47:14,240 --> 00:47:18,000
is associate professor at MIT in the

1271
00:47:16,400 --> 00:47:19,680
department of electrical engineering and

1272
00:47:18,000 --> 00:47:21,280
computer science and also in the

1273
00:47:19,680 --> 00:47:24,319
institute for medical engineering and

1274
00:47:21,280 --> 00:47:26,720
science. Um her her work is highlighting

1275
00:47:24,319 --> 00:47:29,040
how many of our current algorithms can

1276
00:47:26,720 --> 00:47:31,760
really fail patients. Uh so we'll go to

1277
00:47:29,040 --> 00:47:33,359
the darker side again. Um but then she

1278
00:47:31,760 --> 00:47:35,440
also provides new methods for the

1279
00:47:33,359 --> 00:47:38,560
ethical and reproducible use of machine

1280
00:47:35,440 --> 00:47:38,560
learning and health. So,

1281
00:47:53,560 --> 00:48:00,079
welcome. Thank you. There's not a timer,

1282
00:47:57,040 --> 00:48:04,640
is there? There is. It's counting down

1283
00:48:00,079 --> 00:48:06,079
already. What? Okay. Hi, everyone. Uh in

1284
00:48:04,640 --> 00:48:08,800
case you didn't know, there's a large

1285
00:48:06,079 --> 00:48:10,960
timer that's already counting down just

1286
00:48:08,800 --> 00:48:14,400
to scare us. And so I'm going to talk a

1287
00:48:10,960 --> 00:48:16,720
little bit about my research. Um my lab

1288
00:48:14,400 --> 00:48:18,400
uh at MIT is the healthy machine

1289
00:48:16,720 --> 00:48:20,079
learning lab and we really focus on

1290
00:48:18,400 --> 00:48:22,480
trying to construct methods that will

1291
00:48:20,079 --> 00:48:24,800
work well in healthcare. Um in some

1292
00:48:22,480 --> 00:48:26,400
cases you don't actually need a model.

1293
00:48:24,800 --> 00:48:28,559
Maybe you just need to understand that

1294
00:48:26,400 --> 00:48:30,319
there's some inefficiency. Um, and in

1295
00:48:28,559 --> 00:48:32,240
some cases, if you build the very best

1296
00:48:30,319 --> 00:48:34,160
model possible, if you don't deliver the

1297
00:48:32,240 --> 00:48:35,680
advice correctly, the best model and the

1298
00:48:34,160 --> 00:48:37,920
best person don't equal the best

1299
00:48:35,680 --> 00:48:40,240
behavior. So, thinking about that at a

1300
00:48:37,920 --> 00:48:42,079
higher scale,

1301
00:48:40,240 --> 00:48:44,160
um, the demonstrative example I always

1302
00:48:42,079 --> 00:48:46,559
give people is the simple one because I

1303
00:48:44,160 --> 00:48:48,800
I think it illustrates the issue. Let's

1304
00:48:46,559 --> 00:48:51,319
say that you want to build a system for

1305
00:48:48,800 --> 00:48:54,240
triaging patients who maybe have a chest

1306
00:48:51,319 --> 00:48:55,520
X-ray. Um, and if they're not sick,

1307
00:48:54,240 --> 00:48:56,720
you'd really like to send them home

1308
00:48:55,520 --> 00:48:59,200
early. You don't want them to wait

1309
00:48:56,720 --> 00:49:01,359
around. And we can build triage models.

1310
00:48:59,200 --> 00:49:03,119
Uh triage models are actually uh

1311
00:49:01,359 --> 00:49:05,119
reasonably easy to build these days

1312
00:49:03,119 --> 00:49:07,680
because you know every person who's ever

1313
00:49:05,119 --> 00:49:09,680
built an AI model has gone through this

1314
00:49:07,680 --> 00:49:11,680
you know nice pipeline where you pick a

1315
00:49:09,680 --> 00:49:13,440
problem, collect data, define an

1316
00:49:11,680 --> 00:49:15,599
outcome, develop your algorithm and then

1317
00:49:13,440 --> 00:49:18,400
potentially deploy it, right? And so we

1318
00:49:15,599 --> 00:49:20,720
can do that too. Uh we did do that. Um,

1319
00:49:18,400 --> 00:49:23,920
we chose this demonstrative example with

1320
00:49:20,720 --> 00:49:25,520
our faculty colleagues and we took the

1321
00:49:23,920 --> 00:49:27,359
three largest publicly available chest

1322
00:49:25,520 --> 00:49:31,119
X-ray data sets in the United States,

1323
00:49:27,359 --> 00:49:33,040
300,000 or over 700,000 images. You can

1324
00:49:31,119 --> 00:49:35,839
train a denset to try to predict the

1325
00:49:33,040 --> 00:49:38,400
finding um no finding which is the

1326
00:49:35,839 --> 00:49:40,160
person is healthy, they can go home and

1327
00:49:38,400 --> 00:49:42,079
then um we get a nice performance,

1328
00:49:40,160 --> 00:49:44,319
right? Which is what everybody does,

1329
00:49:42,079 --> 00:49:46,079
right? Everybody uh like makes these

1330
00:49:44,319 --> 00:49:47,200
really great models. I do this too that

1331
00:49:46,079 --> 00:49:49,920
have these really nice performance

1332
00:49:47,200 --> 00:49:53,200
metrics. The question is um how and when

1333
00:49:49,920 --> 00:49:55,520
should we be deploying these models? Um

1334
00:49:53,200 --> 00:49:58,319
there are many many models that have

1335
00:49:55,520 --> 00:50:00,960
been developed for a variety of uh

1336
00:49:58,319 --> 00:50:02,480
medical tasks across the range of uh

1337
00:50:00,960 --> 00:50:04,800
different data sets and both predictive

1338
00:50:02,480 --> 00:50:07,200
and generative settings. And when you

1339
00:50:04,800 --> 00:50:09,119
look at even just one, let's say here we

1340
00:50:07,200 --> 00:50:11,119
focus on medical question answering

1341
00:50:09,119 --> 00:50:13,119
which is a popular benchmark task for

1342
00:50:11,119 --> 00:50:14,960
machine learning conferences. we see

1343
00:50:13,119 --> 00:50:17,119
that models are very performant, right?

1344
00:50:14,960 --> 00:50:19,760
And this is across both uh closed and

1345
00:50:17,119 --> 00:50:21,839
open- source models um using a variety

1346
00:50:19,760 --> 00:50:23,599
of different techniques uh anything from

1347
00:50:21,839 --> 00:50:25,559
pre-training, fine-tuning, and just

1348
00:50:23,599 --> 00:50:28,240
prompt tuning.

1349
00:50:25,559 --> 00:50:30,880
Okay. Um and it's not just that these

1350
00:50:28,240 --> 00:50:33,200
models perform well, it's also that we

1351
00:50:30,880 --> 00:50:35,119
know that there are uh ways of

1352
00:50:33,200 --> 00:50:36,800
officially having models out there uh

1353
00:50:35,119 --> 00:50:39,200
for use in clinical settings. So for

1354
00:50:36,800 --> 00:50:41,480
example, the FDA can clear AI algorithms

1355
00:50:39,200 --> 00:50:44,319
to be used in a uh clinical

1356
00:50:41,480 --> 00:50:46,720
setting. So let's look back at uh my

1357
00:50:44,319 --> 00:50:48,240
algorithm, right? Maybe maybe this, you

1358
00:50:46,720 --> 00:50:49,440
know, performant algorithm is something

1359
00:50:48,240 --> 00:50:51,920
because it gets state-of-the-art

1360
00:50:49,440 --> 00:50:54,000
performance we'd like to deploy. But the

1361
00:50:51,920 --> 00:50:56,559
question is uh often we just look at

1362
00:50:54,000 --> 00:50:57,920
these sort of aggregated uh metrics,

1363
00:50:56,559 --> 00:50:59,760
right? And we're not thinking about how

1364
00:50:57,920 --> 00:51:01,920
that might apply in a wider more

1365
00:50:59,760 --> 00:51:04,559
heterogeneous setting. So for example,

1366
00:51:01,920 --> 00:51:06,880
let's look at the false positive rate of

1367
00:51:04,559 --> 00:51:09,040
this really really performant model in

1368
00:51:06,880 --> 00:51:10,319
different groups. And a false positive

1369
00:51:09,040 --> 00:51:12,319
rate here would mean that you're

1370
00:51:10,319 --> 00:51:14,079
underdiagnosing a patient because you're

1371
00:51:12,319 --> 00:51:16,559
falsely positively saying that they're

1372
00:51:14,079 --> 00:51:18,800
healthy. And our great model has the

1373
00:51:16,559 --> 00:51:20,240
largest underdiagnosis rate on female

1374
00:51:18,800 --> 00:51:21,760
patients, young patients, black

1375
00:51:20,240 --> 00:51:23,680
patients, and patients on Medicaid

1376
00:51:21,760 --> 00:51:25,599
insurance. And if you uh look at

1377
00:51:23,680 --> 00:51:27,680
patients who exist in an intersectional

1378
00:51:25,599 --> 00:51:29,680
identity, they're doing even worse.

1379
00:51:27,680 --> 00:51:31,599
Right? This is not unique to this

1380
00:51:29,680 --> 00:51:33,119
setting. Um, and really there's a

1381
00:51:31,599 --> 00:51:34,800
variety of reasons that these things

1382
00:51:33,119 --> 00:51:36,240
happen and there's also a variety of

1383
00:51:34,800 --> 00:51:38,559
ways that we can try to address them,

1384
00:51:36,240 --> 00:51:41,760
but it's something to be both aware of

1385
00:51:38,559 --> 00:51:44,319
and cautious about. So, I want to talk

1386
00:51:41,760 --> 00:51:46,240
briefly about how this happens in

1387
00:51:44,319 --> 00:51:48,319
medical data because I think at this

1388
00:51:46,240 --> 00:51:50,800
point hopefully we're all aware of how

1389
00:51:48,319 --> 00:51:52,520
this happens in natural images. Uh, has

1390
00:51:50,800 --> 00:51:55,200
everybody heard of a

1391
00:51:52,520 --> 00:51:56,960
shortcut? I'm seeing nods, but I gave a

1392
00:51:55,200 --> 00:51:59,119
lecture earlier today where people gave

1393
00:51:56,960 --> 00:52:01,599
me that face. And so I'll just briefly

1394
00:51:59,119 --> 00:52:04,160
say, you know, a shortcut in uh natural

1395
00:52:01,599 --> 00:52:05,920
images is when we know that this is a

1396
00:52:04,160 --> 00:52:07,680
model, a very nice well-trained model

1397
00:52:05,920 --> 00:52:09,839
knows that this is a cow and this is a

1398
00:52:07,680 --> 00:52:12,240
benign mole, but suddenly this cow is an

1399
00:52:09,839 --> 00:52:14,400
orca and this mole is cancerous. And

1400
00:52:12,240 --> 00:52:16,319
it's not because of the actual

1401
00:52:14,400 --> 00:52:18,880
underlying features we might want it to

1402
00:52:16,319 --> 00:52:22,400
use. It's because this model has never

1403
00:52:18,880 --> 00:52:24,000
seen a cow trapesing around in water. It

1404
00:52:22,400 --> 00:52:26,960
thinks that, you know, large black and

1405
00:52:24,000 --> 00:52:28,960
white mammals in water are orcas. And

1406
00:52:26,960 --> 00:52:30,240
also, maybe it's learned a shortcut

1407
00:52:28,960 --> 00:52:32,079
that, well, I know that when

1408
00:52:30,240 --> 00:52:34,160
dermatologists mark the area around a

1409
00:52:32,079 --> 00:52:36,079
mole, they're looking for growth, they

1410
00:52:34,160 --> 00:52:37,599
think it's cancerous, right? These are

1411
00:52:36,079 --> 00:52:39,440
things that you didn't explicitly tell

1412
00:52:37,599 --> 00:52:41,760
the model not to learn. And so, it

1413
00:52:39,440 --> 00:52:43,760
learned it because it's statistically

1414
00:52:41,760 --> 00:52:46,480
true. It's correlated in the data that

1415
00:52:43,760 --> 00:52:49,119
it's seen. And this is really funny when

1416
00:52:46,480 --> 00:52:51,760
we, you know, see that frisking cows in

1417
00:52:49,119 --> 00:52:53,760
water are orcas. It's less funny when we

1418
00:52:51,760 --> 00:52:57,040
think about features in medical images

1419
00:52:53,760 --> 00:52:59,280
that maybe might be used to mispredict

1420
00:52:57,040 --> 00:53:00,800
um in certain people. It's even less

1421
00:52:59,280 --> 00:53:02,480
funny when we think about things that

1422
00:53:00,800 --> 00:53:04,880
machine learning models can see that we

1423
00:53:02,480 --> 00:53:06,720
can't see. So, if you take a medical

1424
00:53:04,880 --> 00:53:08,880
note and redact all dimensions of

1425
00:53:06,720 --> 00:53:10,800
demographics like self-reported race,

1426
00:53:08,880 --> 00:53:13,680
human doctors can't predict that about a

1427
00:53:10,800 --> 00:53:15,760
patient. We tested them. uh but machine

1428
00:53:13,680 --> 00:53:18,160
learning models can with almost perfect

1429
00:53:15,760 --> 00:53:20,720
performance and even higher performance

1430
00:53:18,160 --> 00:53:23,119
when you take a uh chest X-ray or any

1431
00:53:20,720 --> 00:53:24,800
other kind of medical imaging. Um

1432
00:53:23,119 --> 00:53:26,720
radiologists cannot look at a chest

1433
00:53:24,800 --> 00:53:29,839
X-ray. We we tested them. They thought

1434
00:53:26,720 --> 00:53:32,800
they could but uh med radiologists they

1435
00:53:29,839 --> 00:53:34,480
are very confident. Um radiologists

1436
00:53:32,800 --> 00:53:36,319
cannot predict these things these

1437
00:53:34,480 --> 00:53:38,720
demographics but machine learning models

1438
00:53:36,319 --> 00:53:40,800
can with extremely high accuracy. So

1439
00:53:38,720 --> 00:53:42,880
what happens when you have a model that

1440
00:53:40,800 --> 00:53:45,760
can predict something perfectly, a

1441
00:53:42,880 --> 00:53:48,240
shortcut perfectly that humans can't

1442
00:53:45,760 --> 00:53:50,880
see? Well, what can happen is that it

1443
00:53:48,240 --> 00:53:53,760
can use that shortcut to mispredict more

1444
00:53:50,880 --> 00:53:56,079
in that group. So here we wanted to

1445
00:53:53,760 --> 00:53:58,079
explore this in three settings um in

1446
00:53:56,079 --> 00:53:59,359
dermatology, opthalmology and radiology.

1447
00:53:58,079 --> 00:54:02,000
These are all settings where we use

1448
00:53:59,359 --> 00:54:04,079
medical images to make a a diagnosis and

1449
00:54:02,000 --> 00:54:06,960
where we have AI models that do these

1450
00:54:04,079 --> 00:54:09,119
tasks. What we found is that in all

1451
00:54:06,960 --> 00:54:11,359
cases, models learn to recover

1452
00:54:09,119 --> 00:54:13,040
information about demographics that in

1453
00:54:11,359 --> 00:54:15,440
many cases would be very hard or

1454
00:54:13,040 --> 00:54:17,160
impossible for a human doctor to do. And

1455
00:54:15,440 --> 00:54:19,839
the more that they recover this

1456
00:54:17,160 --> 00:54:21,440
demographic secretly in their layers,

1457
00:54:19,839 --> 00:54:23,920
the worse they are at predicting the

1458
00:54:21,440 --> 00:54:25,520
outcome for a minority uh patient group

1459
00:54:23,920 --> 00:54:28,000
in that data setting. So, put another

1460
00:54:25,520 --> 00:54:29,680
way, the more I know who is female in a

1461
00:54:28,000 --> 00:54:31,599
chest X-ray, the worse I do at

1462
00:54:29,680 --> 00:54:33,440
predicting cardiomegaly in female

1463
00:54:31,599 --> 00:54:35,520
patients.

1464
00:54:33,440 --> 00:54:37,920
There are ways to fix this by example

1465
00:54:35,520 --> 00:54:41,200
for using robust uh by using robust

1466
00:54:37,920 --> 00:54:42,960
optimizers things like um uh group

1467
00:54:41,200 --> 00:54:45,119
distributionally robust optimization

1468
00:54:42,960 --> 00:54:47,680
where you can get this uh if you haven't

1469
00:54:45,119 --> 00:54:49,200
seen a paro plot economists love them

1470
00:54:47,680 --> 00:54:52,319
and one of our reviewers was an

1471
00:54:49,200 --> 00:54:55,760
economist. So here uh you can see the

1472
00:54:52,319 --> 00:54:58,000
overall AU right we want that to be high

1473
00:54:55,760 --> 00:54:59,839
of course on the Y-axis we have the

1474
00:54:58,000 --> 00:55:01,599
fairness gap and we want that to be low

1475
00:54:59,839 --> 00:55:03,599
of course and you can see when we use

1476
00:55:01,599 --> 00:55:06,400
vanilla optimization we get these teal

1477
00:55:03,599 --> 00:55:08,960
models that are up here for erm very

1478
00:55:06,400 --> 00:55:10,559
undesirable it's like lying right it's

1479
00:55:08,960 --> 00:55:13,440
saying good overall performance but the

1480
00:55:10,559 --> 00:55:15,280
gap is very high and if we use uh robust

1481
00:55:13,440 --> 00:55:17,599
optimizers we can shove that all the way

1482
00:55:15,280 --> 00:55:20,000
down this is great but this is when we

1483
00:55:17,599 --> 00:55:21,440
take data from Massachusetts train a

1484
00:55:20,000 --> 00:55:23,599
model from Massachusetts and then we

1485
00:55:21,440 --> 00:55:26,200
test it in new data from Massachusetts.

1486
00:55:23,599 --> 00:55:27,880
What happens when we test it in new data

1487
00:55:26,200 --> 00:55:30,720
from

1488
00:55:27,880 --> 00:55:32,400
Stanford gets much worse and the problem

1489
00:55:30,720 --> 00:55:34,480
is it doesn't get much much worse

1490
00:55:32,400 --> 00:55:36,640
uniformally. We actually aren't able to

1491
00:55:34,480 --> 00:55:38,720
predict whether a model will do much

1492
00:55:36,640 --> 00:55:40,480
better or much worse in a new setting

1493
00:55:38,720 --> 00:55:42,160
and that's a surprising new result.

1494
00:55:40,480 --> 00:55:44,640
Usually we believe that the best model

1495
00:55:42,160 --> 00:55:46,240
in one setting will sort of you know

1496
00:55:44,640 --> 00:55:48,079
it'll be worse but it'll be still the

1497
00:55:46,240 --> 00:55:49,599
best model of all the models in a new

1498
00:55:48,079 --> 00:55:50,799
setting. And this is not something that

1499
00:55:49,599 --> 00:55:52,680
we can get around. It's something that

1500
00:55:50,799 --> 00:55:56,079
you have to evaluate in new

1501
00:55:52,680 --> 00:55:57,760
settings. Um, so TLDDR1 human data is

1502
00:55:56,079 --> 00:56:00,160
tricky. Test models on data from

1503
00:55:57,760 --> 00:56:01,839
populations they'll be used on. The

1504
00:56:00,160 --> 00:56:03,599
second thing I want to talk about is how

1505
00:56:01,839 --> 00:56:06,319
we actually optimize models in

1506
00:56:03,599 --> 00:56:08,160
healthcare settings. Well, you know, uh

1507
00:56:06,319 --> 00:56:10,240
there's a hot topic about how we use

1508
00:56:08,160 --> 00:56:12,559
group attributes. Don't uh talk to

1509
00:56:10,240 --> 00:56:14,319
doctors about it or they'll hit you um

1510
00:56:12,559 --> 00:56:16,880
or yell at you. One or the other or

1511
00:56:14,319 --> 00:56:19,040
both. And so, uh, the problem is often

1512
00:56:16,880 --> 00:56:22,559
when you use a demographic attribute

1513
00:56:19,040 --> 00:56:26,480
like here, I view sex, um, and age, even

1514
00:56:22,559 --> 00:56:29,440
if I use no fancy AI, just a logistic

1515
00:56:26,480 --> 00:56:31,839
regression model, this model is 1%

1516
00:56:29,440 --> 00:56:33,599
better on average, but it gets that by

1517
00:56:31,839 --> 00:56:36,400
being much better in the young female

1518
00:56:33,599 --> 00:56:39,040
subgroup and worse in these two other

1519
00:56:36,400 --> 00:56:40,640
subgroups, right? And so again, this

1520
00:56:39,040 --> 00:56:42,799
happens when we have some sort of

1521
00:56:40,640 --> 00:56:44,720
optimization that is tuning for an

1522
00:56:42,799 --> 00:56:47,200
overall performance and not respecting

1523
00:56:44,720 --> 00:56:48,880
maybe interactions between features. And

1524
00:56:47,200 --> 00:56:51,119
while it's easy to point that out in a

1525
00:56:48,880 --> 00:56:52,559
logistic regression model, it gets much

1526
00:56:51,119 --> 00:56:54,559
harder when we deal with these large

1527
00:56:52,559 --> 00:56:57,280
vision language models, right, that have

1528
00:56:54,559 --> 00:56:58,880
billions of parameters. And so vision

1529
00:56:57,280 --> 00:57:00,920
language models are used for things like

1530
00:56:58,880 --> 00:57:03,200
generation, image classification, and

1531
00:57:00,920 --> 00:57:05,359
retrieval, but they also have a lot of

1532
00:57:03,200 --> 00:57:07,599
biases. And the way that people try to

1533
00:57:05,359 --> 00:57:09,440
debias these models is often this really

1534
00:57:07,599 --> 00:57:11,680
linear thing where you sort of estimate

1535
00:57:09,440 --> 00:57:13,680
where is male, estimate where is female

1536
00:57:11,680 --> 00:57:15,760
and then you project out and collapse

1537
00:57:13,680 --> 00:57:18,000
that dimension. But the problem is that

1538
00:57:15,760 --> 00:57:20,160
assumes linearity and these are really

1539
00:57:18,000 --> 00:57:22,400
complex topological objects that are

1540
00:57:20,160 --> 00:57:24,240
nonlinear. And so if you collapse male

1541
00:57:22,400 --> 00:57:25,839
and female doctor, you might do bad

1542
00:57:24,240 --> 00:57:28,720
things to the space for male and female

1543
00:57:25,839 --> 00:57:30,079
pilot or male and female manager. Right?

1544
00:57:28,720 --> 00:57:32,079
So it has downstream effects that are

1545
00:57:30,079 --> 00:57:34,240
hard to quantify. So a lot of what we're

1546
00:57:32,079 --> 00:57:36,960
doing in this space is trying to uh

1547
00:57:34,240 --> 00:57:38,920
understand how to work with this complex

1548
00:57:36,960 --> 00:57:41,440
nonlinear topology. For example, with

1549
00:57:38,920 --> 00:57:43,760
negation, uh despite their flexibility,

1550
00:57:41,440 --> 00:57:45,040
if you ask models um vision language

1551
00:57:43,760 --> 00:57:47,599
models to give you something with

1552
00:57:45,040 --> 00:57:49,280
negation, they fail. So if you say, I

1553
00:57:47,599 --> 00:57:52,000
want tables with no chairs, you're going

1554
00:57:49,280 --> 00:57:53,760
to get chairs. If you ask uh for a

1555
00:57:52,000 --> 00:57:55,839
picture of a dog, not on grass, you're

1556
00:57:53,760 --> 00:57:57,599
going to get grass. If you ask uh in

1557
00:57:55,839 --> 00:57:59,200
visual question answering whether uh

1558
00:57:57,599 --> 00:58:01,760
there is grass, it'll say yes, but

1559
00:57:59,200 --> 00:58:03,839
there's not. Um, sidebar, did you know

1560
00:58:01,760 --> 00:58:05,920
that the most doglike dog is a golden

1561
00:58:03,839 --> 00:58:08,000
retriever? If you look at the embedding

1562
00:58:05,920 --> 00:58:09,920
space for dog, all the other dogs are

1563
00:58:08,000 --> 00:58:12,160
very far away from it and golden

1564
00:58:09,920 --> 00:58:13,520
retriever is right on top. So, we have

1565
00:58:12,160 --> 00:58:15,280
trained vision language models that

1566
00:58:13,520 --> 00:58:17,680
golden retriever are the only dog out

1567
00:58:15,280 --> 00:58:19,760
there for us.

1568
00:58:17,680 --> 00:58:21,760
And maybe it's cute that in vision

1569
00:58:19,760 --> 00:58:24,480
language models we get these pictures of

1570
00:58:21,760 --> 00:58:26,480
dogs on grass. But it's not cute when I

1571
00:58:24,480 --> 00:58:28,400
want evidence of lung opacity and I

1572
00:58:26,480 --> 00:58:30,640
retrieve this image. But I say evidence

1573
00:58:28,400 --> 00:58:32,960
of lung opacity with no signs of edema

1574
00:58:30,640 --> 00:58:34,720
and I still get this image. Right? It's

1575
00:58:32,960 --> 00:58:36,319
very important that we process negation

1576
00:58:34,720 --> 00:58:39,839
correctly with medical vision language

1577
00:58:36,319 --> 00:58:41,599
models. This is very hard because when

1578
00:58:39,839 --> 00:58:42,960
we train large vision language models,

1579
00:58:41,599 --> 00:58:45,680
how do we train them? We train them like

1580
00:58:42,960 --> 00:58:47,440
this. Uh we always train them on was is

1581
00:58:45,680 --> 00:58:50,200
present. We don't, for example, say

1582
00:58:47,440 --> 00:58:53,040
black and white dog jumps over bar, no

1583
00:58:50,200 --> 00:58:53,880
helicopter. There's never a negation in

1584
00:58:53,040 --> 00:58:56,960
the

1585
00:58:53,880 --> 00:58:58,400
caption. And so consequently, vision

1586
00:58:56,960 --> 00:59:00,880
language models don't know how to

1587
00:58:58,400 --> 00:59:02,880
contextualize that. And again, this is

1588
00:59:00,880 --> 00:59:06,000
much harder in medical vision language

1589
00:59:02,880 --> 00:59:07,760
models because negation is really

1590
00:59:06,000 --> 00:59:09,520
present, right? Often we just have a

1591
00:59:07,760 --> 00:59:11,920
list of things that aren't present, lots

1592
00:59:09,520 --> 00:59:14,720
of negation. And so we made a benchmark

1593
00:59:11,920 --> 00:59:16,640
to try to understand how poorly uh

1594
00:59:14,720 --> 00:59:19,040
state-of-the-art vision language models

1595
00:59:16,640 --> 00:59:21,119
do in negation. And it turns out it's

1596
00:59:19,040 --> 00:59:22,960
really poorly. In fact, they tend to

1597
00:59:21,119 --> 00:59:25,040
embed things right on top of their

1598
00:59:22,960 --> 00:59:28,319
negations. Not a flower is right on top

1599
00:59:25,040 --> 00:59:31,760
of flower. And uh so takeaway number

1600
00:59:28,319 --> 00:59:33,599
two, uh robustness is hard. You have to

1601
00:59:31,760 --> 00:59:36,160
test models on things that they might

1602
00:59:33,599 --> 00:59:38,240
fail on even if humans might not. I see

1603
00:59:36,160 --> 00:59:40,079
my time is almost up, so I will breeze

1604
00:59:38,240 --> 00:59:41,720
through the last section which is about

1605
00:59:40,079 --> 00:59:44,000
deployment

1606
00:59:41,720 --> 00:59:46,480
considerations. E, you know, the goal is

1607
00:59:44,000 --> 00:59:48,480
not to have AI do everything. Hopefully.

1608
00:59:46,480 --> 00:59:51,520
Hopefully, unless you talk to Dr. Oz,

1609
00:59:48,480 --> 00:59:53,520
that's what he wants. Um, and so I know

1610
00:59:51,520 --> 00:59:55,440
he's like agents everywhere. I'm like,

1611
00:59:53,520 --> 00:59:58,079
isn't that the matrix? Isn't that what

1612
00:59:55,440 --> 00:59:59,920
the matrix wants? And so really what we

1613
00:59:58,079 --> 01:00:01,440
want is doctors working with AI

1614
00:59:59,920 --> 01:00:02,960
together, right? But if that's what we

1615
01:00:01,440 --> 01:00:04,319
want, that's what we need to measure.

1616
01:00:02,960 --> 01:00:07,280
And there's lots of good work that has

1617
01:00:04,319 --> 01:00:08,559
shown first the losses of bad AI, this

1618
01:00:07,280 --> 01:00:11,680
is not my paper, but I love it. It's

1619
01:00:08,559 --> 01:00:13,440
from 2020 is much worse than the gain

1620
01:00:11,680 --> 01:00:15,280
from good AI. So number one, make sure

1621
01:00:13,440 --> 01:00:16,720
that you have a good AI model, right?

1622
01:00:15,280 --> 01:00:18,960
That's the base and not all of the

1623
01:00:16,720 --> 01:00:21,119
models out there are good. Number two,

1624
01:00:18,960 --> 01:00:23,200
humans are extremely susceptible to

1625
01:00:21,119 --> 01:00:26,000
incorrect advice. This was even expert

1626
01:00:23,200 --> 01:00:28,240
radiologists when we measured. Okay? And

1627
01:00:26,000 --> 01:00:30,400
so it's very hard for humans to dismiss

1628
01:00:28,240 --> 01:00:33,520
incorrect advice. We're really gullible.

1629
01:00:30,400 --> 01:00:35,760
And finally, convincing advice delivery

1630
01:00:33,520 --> 01:00:37,599
style worked really well on doctors. So

1631
01:00:35,760 --> 01:00:39,599
when we told doctor to do something bad

1632
01:00:37,599 --> 01:00:41,200
as an order, they did it. When we told

1633
01:00:39,599 --> 01:00:44,000
them to do the same bad thing as a

1634
01:00:41,200 --> 01:00:45,359
factual um you know feature, they

1635
01:00:44,000 --> 01:00:47,599
ignored it and retained their original

1636
01:00:45,359 --> 01:00:50,720
fair decision-m destroying my life work

1637
01:00:47,599 --> 01:00:53,040
of making better models. So all of these

1638
01:00:50,720 --> 01:00:54,960
things are really important. These are

1639
01:00:53,040 --> 01:00:56,880
sort of the human factors that affect

1640
01:00:54,960 --> 01:00:58,559
whether a model will be useful or not.

1641
01:00:56,880 --> 01:00:59,920
And they're underststudied. So we really

1642
01:00:58,559 --> 01:01:02,000
need to understand that humans are

1643
01:00:59,920 --> 01:01:03,960
fallible. You have to test models and

1644
01:01:02,000 --> 01:01:06,319
humans in these high-risk situations

1645
01:01:03,960 --> 01:01:08,079
beforehand. And uh by doing that we can

1646
01:01:06,319 --> 01:01:09,500
move forward with ethical AI and health.

1647
01:01:08,079 --> 01:01:15,000
Thank you.

1648
01:01:09,500 --> 01:01:15,000
[Applause]

1649
01:01:16,880 --> 01:01:20,720
So thank you to all the speakers for

1650
01:01:19,280 --> 01:01:23,359
some really really wonderful and

1651
01:01:20,720 --> 01:01:25,599
thoughtprovoking talks. So I would like

1652
01:01:23,359 --> 01:01:28,319
to ask them all to come up here so that

1653
01:01:25,599 --> 01:01:31,440
we can have a discussion up here. And

1654
01:01:28,319 --> 01:01:31,440
hopefully we have a lot of

1655
01:01:44,119 --> 01:01:48,240
microphones. Okay. So I think this was

1656
01:01:46,480 --> 01:01:50,559
really really wonderful going through

1657
01:01:48,240 --> 01:01:53,200
you know from proteins all the way then

1658
01:01:50,559 --> 01:01:56,480
tissues drug discovery and then all the

1659
01:01:53,200 --> 01:01:58,960
way to hospital possibly applications

1660
01:01:56,480 --> 01:02:01,119
and seeing where things can go wrong. So

1661
01:01:58,960 --> 01:02:03,839
I think we have seen like really amazing

1662
01:02:01,119 --> 01:02:06,319
positive examples of you know the use of

1663
01:02:03,839 --> 01:02:08,640
ML and where we can get to and then also

1664
01:02:06,319 --> 01:02:10,559
some scary examples and so I think I

1665
01:02:08,640 --> 01:02:12,400
would love to hear from you of like you

1666
01:02:10,559 --> 01:02:15,040
know like we see the complexity of

1667
01:02:12,400 --> 01:02:17,200
biology and human health and in some

1668
01:02:15,040 --> 01:02:19,440
problems it seems like it's still you

1669
01:02:17,200 --> 01:02:21,359
know we're still very very far away from

1670
01:02:19,440 --> 01:02:23,920
making progress on these very complex

1671
01:02:21,359 --> 01:02:26,880
problems uh using AI and others are

1672
01:02:23,920 --> 01:02:29,680
totally in reach. So, how do you go

1673
01:02:26,880 --> 01:02:31,440
about deciding and and which problems do

1674
01:02:29,680 --> 01:02:33,200
you maybe think the ones who have very

1675
01:02:31,440 --> 01:02:35,440
positive examples of like what are the

1676
01:02:33,200 --> 01:02:38,079
problems that are totally not in reach?

1677
01:02:35,440 --> 01:02:40,359
Um, and what are the problems that are

1678
01:02:38,079 --> 01:02:45,040
kind of in reach on your

1679
01:02:40,359 --> 01:02:46,640
end? Anyone who wants to start?

1680
01:02:45,040 --> 01:02:49,839
All right. Well, I guess I'll start. Um,

1681
01:02:46,640 --> 01:02:52,160
hey everyone. Um, so I I think for for

1682
01:02:49,839 --> 01:02:54,079
us, uh, like we we're kind of hoping

1683
01:02:52,160 --> 01:02:55,760
that these giant large language models

1684
01:02:54,079 --> 01:02:58,319
will at some point start to generalize

1685
01:02:55,760 --> 01:03:00,400
in terms of start to understand what how

1686
01:02:58,319 --> 01:03:01,839
proteins actually fold and so on. Uh, at

1687
01:03:00,400 --> 01:03:03,280
the moment they're still in this status

1688
01:03:01,839 --> 01:03:05,280
where they're essentially storing

1689
01:03:03,280 --> 01:03:06,640
statistics of what evolution has tried.

1690
01:03:05,280 --> 01:03:09,280
But like if you want to go beyond what

1691
01:03:06,640 --> 01:03:10,880
evolution has done, like how do we so

1692
01:03:09,280 --> 01:03:12,160
that's sort of it's still an ongoing

1693
01:03:10,880 --> 01:03:14,640
challenge and we're still thinking how

1694
01:03:12,160 --> 01:03:16,160
to get these models to do it. um or even

1695
01:03:14,640 --> 01:03:17,520
if it's possible at all like maybe the

1696
01:03:16,160 --> 01:03:18,960
the way we're training them is not the

1697
01:03:17,520 --> 01:03:22,920
right way or maybe the architecture is

1698
01:03:18,960 --> 01:03:22,920
wrong. So not sure yet.

1699
01:03:23,680 --> 01:03:28,799
So when I was a PhD student at Stanford

1700
01:03:26,880 --> 01:03:32,240
uh at the time we were taking Deafany

1701
01:03:28,799 --> 01:03:34,720
Kohler's AI class and uh uh she was

1702
01:03:32,240 --> 01:03:37,680
discussing how deep blue beats the

1703
01:03:34,720 --> 01:03:40,319
casper of for chess playing and it took

1704
01:03:37,680 --> 01:03:42,480
another 25 years for general AI models

1705
01:03:40,319 --> 01:03:45,520
to really benefit you know the

1706
01:03:42,480 --> 01:03:49,359
everybody. I feel like for alpha fold 2

1707
01:03:45,520 --> 01:03:51,760
to beat um other computational biologist

1708
01:03:49,359 --> 01:03:55,039
in protein structure prediction is the

1709
01:03:51,760 --> 01:03:58,240
deep bulu moment we are still quite far

1710
01:03:55,039 --> 01:04:01,599
away from a general AI foundation model

1711
01:03:58,240 --> 01:04:03,760
for uh biology for the whole of biology

1712
01:04:01,599 --> 01:04:07,200
and so I think now it's really important

1713
01:04:03,760 --> 01:04:09,599
to know um especially as a company for

1714
01:04:07,200 --> 01:04:12,240
us you know how much we need to invest

1715
01:04:09,599 --> 01:04:15,039
in AI at the same time to ensure that

1716
01:04:12,240 --> 01:04:18,160
the company delivers value and move the

1717
01:04:15,039 --> 01:04:19,920
company forward. Um and I think we are

1718
01:04:18,160 --> 01:04:21,760
still a way to go but at least for

1719
01:04:19,920 --> 01:04:24,880
example right now we feel like the the

1720
01:04:21,760 --> 01:04:27,440
available data on tumor sequencing is

1721
01:04:24,880 --> 01:04:30,079
sufficient but for other diseases for

1722
01:04:27,440 --> 01:04:31,760
example neuroscience or Alzheimer we are

1723
01:04:30,079 --> 01:04:33,920
certainly very interested and there

1724
01:04:31,760 --> 01:04:35,359
certainly is also immune component you

1725
01:04:33,920 --> 01:04:39,119
know something in the brain maybe the

1726
01:04:35,359 --> 01:04:41,599
immune system is causing the disease and

1727
01:04:39,119 --> 01:04:43,760
or maybe there are still residuals to

1728
01:04:41,599 --> 01:04:46,880
fight the disease but we simply don't

1729
01:04:43,760 --> 01:04:50,240
have enough data there to make uh drug

1730
01:04:46,880 --> 01:04:54,079
predictions yet.

1731
01:04:50,240 --> 01:04:57,359
So I think that these models are really

1732
01:04:54,079 --> 01:04:59,119
um susceptible to all kinds of failure

1733
01:04:57,359 --> 01:05:01,039
just like Mars that Marz showed and

1734
01:04:59,119 --> 01:05:02,640
we've seen it in real time for some

1735
01:05:01,039 --> 01:05:05,039
models that we have deployed over over

1736
01:05:02,640 --> 01:05:07,119
the years and uh have assessed it on

1737
01:05:05,039 --> 01:05:08,880
actual patients and we've also published

1738
01:05:07,119 --> 01:05:12,920
some of those results from a pathology

1739
01:05:08,880 --> 01:05:15,760
pathology perspective. Um but

1740
01:05:12,920 --> 01:05:18,480
uh I I think there are ways you can make

1741
01:05:15,760 --> 01:05:21,599
them more robust. Uh and I think that

1742
01:05:18,480 --> 01:05:22,960
some of the more easier problems for

1743
01:05:21,599 --> 01:05:25,680
example in pathology were very

1744
01:05:22,960 --> 01:05:27,280
interested in having a universal triage

1745
01:05:25,680 --> 01:05:30,559
which can triage out all the negative

1746
01:05:27,280 --> 01:05:32,640
slides. It h it happened for papsmears

1747
01:05:30,559 --> 01:05:35,359
for cytologology in 1998 and there's

1748
01:05:32,640 --> 01:05:37,119
been an FDA approved tool since and it

1749
01:05:35,359 --> 01:05:40,079
it decreased the amount of work that

1750
01:05:37,119 --> 01:05:41,760
that was needed and uh technically we

1751
01:05:40,079 --> 01:05:43,599
could do that in in in pathology. It's

1752
01:05:41,760 --> 01:05:46,920
been difficult to get FDA approval for

1753
01:05:43,599 --> 01:05:50,480
it. Um and that's because uh it has very

1754
01:05:46,920 --> 01:05:52,559
uncertain failure modes. Um, on the

1755
01:05:50,480 --> 01:05:54,880
other hand, I think that the larger

1756
01:05:52,559 --> 01:05:57,839
models, foundation models that integrate

1757
01:05:54,880 --> 01:05:59,599
multiple kinds of uh clinical data are

1758
01:05:57,839 --> 01:06:03,599
really valuable discovery engines

1759
01:05:59,599 --> 01:06:06,799
because you can discover a lot of uh um

1760
01:06:03,599 --> 01:06:09,440
combination markers that you uh may not

1761
01:06:06,799 --> 01:06:11,680
have thought of otherwise for all all

1762
01:06:09,440 --> 01:06:14,079
kinds of complex complex disease and

1763
01:06:11,680 --> 01:06:18,240
also to serve as companion diagnostics

1764
01:06:14,079 --> 01:06:20,720
together with certain certain drugs.

1765
01:06:18,240 --> 01:06:24,720
I think there are really uh exciting

1766
01:06:20,720 --> 01:06:26,559
examples of where um machine learning uh

1767
01:06:24,720 --> 01:06:28,319
specifically AI generally is being

1768
01:06:26,559 --> 01:06:31,359
applied to problems that we're really

1769
01:06:28,319 --> 01:06:33,520
bad at. So for example, you know, um

1770
01:06:31,359 --> 01:06:34,960
adverse events in cancer, imunotherapy,

1771
01:06:33,520 --> 01:06:36,400
those those are things we're bad at,

1772
01:06:34,960 --> 01:06:38,280
right? We don't know how to do it. We're

1773
01:06:36,400 --> 01:06:40,880
trying to do something new um and

1774
01:06:38,280 --> 01:06:43,280
improve. Um there's a lot of uh

1775
01:06:40,880 --> 01:06:45,359
interesting applications I've seen in uh

1776
01:06:43,280 --> 01:06:47,839
women's health where everything is

1777
01:06:45,359 --> 01:06:50,799
trash. And so if you make any advance,

1778
01:06:47,839 --> 01:06:52,799
you're doing great. Um I think the issue

1779
01:06:50,799 --> 01:06:55,839
is that's not where a majority of the

1780
01:06:52,799 --> 01:06:57,839
effort is going in a lot of AI for

1781
01:06:55,839 --> 01:07:01,760
health more broadly, right? I think

1782
01:06:57,839 --> 01:07:03,839
we're very um benchmark focused, right?

1783
01:07:01,760 --> 01:07:06,960
And so if you look maybe beyond the the

1784
01:07:03,839 --> 01:07:09,280
cancer space to more broadly where AI is

1785
01:07:06,960 --> 01:07:11,200
um already deployed in healthcare,

1786
01:07:09,280 --> 01:07:12,960
right? A lot of the examples are

1787
01:07:11,200 --> 01:07:16,480
administrative examples, things that are

1788
01:07:12,960 --> 01:07:17,920
adjacent to clinical care like insurers

1789
01:07:16,480 --> 01:07:21,119
uh making decisions about who gets

1790
01:07:17,920 --> 01:07:22,720
different kind of care. Um uh deciding

1791
01:07:21,119 --> 01:07:24,720
who gets booked for appointments,

1792
01:07:22,720 --> 01:07:26,400
deciding who gets resources, writing

1793
01:07:24,720 --> 01:07:29,200
notes on your behalf, writing messages

1794
01:07:26,400 --> 01:07:31,760
on your behalf. And I think those are um

1795
01:07:29,200 --> 01:07:34,319
sort of uh dangerous use cases because

1796
01:07:31,760 --> 01:07:36,640
they mediate who is even able to access

1797
01:07:34,319 --> 01:07:37,760
care even further. So, I think there's a

1798
01:07:36,640 --> 01:07:39,119
lot of there are a lot of really

1799
01:07:37,760 --> 01:07:40,400
exciting things, but as we all just

1800
01:07:39,119 --> 01:07:42,640
said, like we need more data. We need

1801
01:07:40,400 --> 01:07:45,280
more data. What if we only get data from

1802
01:07:42,640 --> 01:07:47,440
certain kinds of people even more so now

1803
01:07:45,280 --> 01:07:49,119
that they're predicted that they

1804
01:07:47,440 --> 01:07:50,640
shouldn't be part of a trial or they

1805
01:07:49,119 --> 01:07:52,240
shouldn't get to see a pathologist or

1806
01:07:50,640 --> 01:07:55,520
they shouldn't like those those are very

1807
01:07:52,240 --> 01:07:57,520
scary I think examples

1808
01:07:55,520 --> 01:07:59,359
and since now this already came up we

1809
01:07:57,520 --> 01:08:01,599
need more data or you know what are

1810
01:07:59,359 --> 01:08:03,920
really the bottlenecks to making

1811
01:08:01,599 --> 01:08:07,760
progress. I mean one could be data. You

1812
01:08:03,920 --> 01:08:09,599
also all mentioned we need GPUs. Um you

1813
01:08:07,760 --> 01:08:11,920
know for us like building the large

1814
01:08:09,599 --> 01:08:14,960
scale AI models would require much more

1815
01:08:11,920 --> 01:08:16,960
funding even in industry. Um you also

1816
01:08:14,960 --> 01:08:18,960
mentioned the other way around as well

1817
01:08:16,960 --> 01:08:22,319
although GPUs are there but maybe you

1818
01:08:18,960 --> 01:08:24,480
cannot run the lab anymore. Um so so

1819
01:08:22,319 --> 01:08:26,400
what are though the real bottlenecks you

1820
01:08:24,480 --> 01:08:29,040
think? I mean yeah it could be that it

1821
01:08:26,400 --> 01:08:32,880
could be new algorithms. Um what is it

1822
01:08:29,040 --> 01:08:35,799
and which types of problems?

1823
01:08:32,880 --> 01:08:39,040
It's capitalism, guys.

1824
01:08:35,799 --> 01:08:40,960
Okay, we all know that you all and the

1825
01:08:39,040 --> 01:08:43,120
companies, if you're here, I see you,

1826
01:08:40,960 --> 01:08:45,440
right? That you have the data that it's

1827
01:08:43,120 --> 01:08:47,120
been deidentified via HIPPA and you

1828
01:08:45,440 --> 01:08:48,799
bought it. I know because my friends who

1829
01:08:47,120 --> 01:08:51,679
work there and are making millions call

1830
01:08:48,799 --> 01:08:53,839
me. Okay, we don't have millions. We

1831
01:08:51,679 --> 01:08:56,000
can't buy the same data. Um, it would be

1832
01:08:53,839 --> 01:08:57,359
nice if we could, right? And so I think

1833
01:08:56,000 --> 01:08:59,759
um one thing that would be really

1834
01:08:57,359 --> 01:09:02,640
helpful is if we did something as a

1835
01:08:59,759 --> 01:09:04,640
nation like invest more in all of us

1836
01:09:02,640 --> 01:09:07,359
which is a fantastic platform that I'm a

1837
01:09:04,640 --> 01:09:09,040
huge fan of um a lot of the work that is

1838
01:09:07,359 --> 01:09:10,719
done a lot of the really like leading

1839
01:09:09,040 --> 01:09:12,799
really cool work that's been done in the

1840
01:09:10,719 --> 01:09:15,440
past decade is always done first with

1841
01:09:12,799 --> 01:09:16,960
the UK bio bank because they invested in

1842
01:09:15,440 --> 01:09:18,960
that resource but I think we want to

1843
01:09:16,960 --> 01:09:23,520
have you know similar resources um

1844
01:09:18,960 --> 01:09:25,359
across the world of course also GPUs

1845
01:09:23,520 --> 01:09:27,199
so so I think that we know that there

1846
01:09:25,359 --> 01:09:28,880
are three things that you need to to do

1847
01:09:27,199 --> 01:09:30,960
this kind of work. You need the data,

1848
01:09:28,880 --> 01:09:33,600
compute and the talent. And there's an

1849
01:09:30,960 --> 01:09:36,400
abundance of talent in in this town as

1850
01:09:33,600 --> 01:09:38,560
needless to say. Um but for for data, I

1851
01:09:36,400 --> 01:09:40,799
completely agree. We need like no large

1852
01:09:38,560 --> 01:09:42,799
national consorcia. I think the UK bio

1853
01:09:40,799 --> 01:09:45,520
bank is a very good example. They did a

1854
01:09:42,799 --> 01:09:47,279
really good job at it. Um I mean all of

1855
01:09:45,520 --> 01:09:49,520
us is great but it's not as standardized

1856
01:09:47,279 --> 01:09:52,080
and integrated as uh as as we've seen

1857
01:09:49,520 --> 01:09:54,880
with UK UK biioank. There are really

1858
01:09:52,080 --> 01:09:57,280
large efforts. So I I I think ARPA is

1859
01:09:54,880 --> 01:10:00,239
leading some really large initiatives

1860
01:09:57,280 --> 01:10:02,640
unless they lose funding too. Um but the

1861
01:10:00,239 --> 01:10:04,800
they have the index cohort where they're

1862
01:10:02,640 --> 01:10:07,120
there's a very large scale goal of

1863
01:10:04,800 --> 01:10:08,480
making very large amounts of data just

1864
01:10:07,120 --> 01:10:12,159
publicly available. And the motivation

1865
01:10:08,480 --> 01:10:15,760
is that the TCGA was a um you know

1866
01:10:12,159 --> 01:10:17,440
10,000 case uh example and so much

1867
01:10:15,760 --> 01:10:19,679
research has come out of just using the

1868
01:10:17,440 --> 01:10:21,360
TCGA. anything in in my field in

1869
01:10:19,679 --> 01:10:24,719
computational pathology all the initial

1870
01:10:21,360 --> 01:10:26,960
work um the method development the

1871
01:10:24,719 --> 01:10:28,480
initial studies discovery was all done

1872
01:10:26,960 --> 01:10:31,840
on the on the TCG and that was just

1873
01:10:28,480 --> 01:10:33,360
10,000 cases and I think under the

1874
01:10:31,840 --> 01:10:36,480
umbrella of something like like like

1875
01:10:33,360 --> 01:10:38,080
ARPA they have the ability to uh just

1876
01:10:36,480 --> 01:10:40,320
digitize all the glass slides for

1877
01:10:38,080 --> 01:10:42,640
example and the rest of the data if you

1878
01:10:40,320 --> 01:10:44,960
if you can deidentify it is is easy and

1879
01:10:42,640 --> 01:10:47,199
then in pathology we also have the joint

1880
01:10:44,960 --> 01:10:49,280
pathology center from the military where

1881
01:10:47,199 --> 01:10:51,520
they have the largest repository of

1882
01:10:49,280 --> 01:10:54,800
pathology data going back to the civil

1883
01:10:51,520 --> 01:10:57,280
war. Uh and they are digitizing it very

1884
01:10:54,800 --> 01:10:59,520
very very very quickly and it's a it's a

1885
01:10:57,280 --> 01:11:01,679
national national resource and I think

1886
01:10:59,520 --> 01:11:05,120
part of their goal is to deidentify that

1887
01:11:01,679 --> 01:11:08,719
data and make it available for uh for

1888
01:11:05,120 --> 01:11:12,000
for research. So uh I think that would

1889
01:11:08,719 --> 01:11:13,920
that would happen. um the compute. So

1890
01:11:12,000 --> 01:11:17,199
what we do what we have done in the past

1891
01:11:13,920 --> 01:11:19,600
that's my my group had uh grants that

1892
01:11:17,199 --> 01:11:21,920
supported supported compute sometimes it

1893
01:11:19,600 --> 01:11:23,760
was just us and in other situations it

1894
01:11:21,920 --> 01:11:25,520
was together with other other

1895
01:11:23,760 --> 01:11:29,280
investigators

1896
01:11:25,520 --> 01:11:32,239
um and S10 awards and you know the they

1897
01:11:29,280 --> 01:11:36,320
were supporting at state state awards um

1898
01:11:32,239 --> 01:11:38,320
but uh uh I think that if if you look at

1899
01:11:36,320 --> 01:11:39,920
all major institutions a lot of compute

1900
01:11:38,320 --> 01:11:42,480
support has come from philanthropy so we

1901
01:11:39,920 --> 01:11:47,120
need more more of more of that and we we

1902
01:11:42,480 --> 01:11:49,840
we have that at Harvard. Uh and I I I

1903
01:11:47,120 --> 01:11:52,159
think just because these these

1904
01:11:49,840 --> 01:11:54,560
infrastructures they evolve so quickly

1905
01:11:52,159 --> 01:11:57,679
and how much compute you need to develop

1906
01:11:54,560 --> 01:12:00,159
some of these models. I mean uh a lot of

1907
01:11:57,679 --> 01:12:02,080
the lobbying politics behind building

1908
01:12:00,159 --> 01:12:03,840
the model that we built using so much

1909
01:12:02,080 --> 01:12:05,760
patient data was how do we get access to

1910
01:12:03,840 --> 01:12:08,640
the compute and data and and just

1911
01:12:05,760 --> 01:12:10,320
organize it u across many many of the

1912
01:12:08,640 --> 01:12:12,159
Harvard hospitals or or a number of

1913
01:12:10,320 --> 01:12:15,360
years.

1914
01:12:12,159 --> 01:12:19,520
Uh I would say one bottleneck or barrier

1915
01:12:15,360 --> 01:12:22,719
to get better or good data is the

1916
01:12:19,520 --> 01:12:26,400
pressure to publish high-profile papers.

1917
01:12:22,719 --> 01:12:28,640
Uh for example, tumor RNA sequencing is

1918
01:12:26,400 --> 01:12:30,560
really inexpensive. You can do it with a

1919
01:12:28,640 --> 01:12:33,199
couple hundred dollars, but people are

1920
01:12:30,560 --> 01:12:34,800
not doing it. Why? You you get another

1921
01:12:33,199 --> 01:12:38,560
few hundred samples. You can't even

1922
01:12:34,800 --> 01:12:41,280
publish a CNS paper. And yet if you do a

1923
01:12:38,560 --> 01:12:43,920
newest spatial transcripttoics data with

1924
01:12:41,280 --> 01:12:46,400
10 samples you can get a nature science.

1925
01:12:43,920 --> 01:12:48,480
And so I I remember Bill Kalin once said

1926
01:12:46,400 --> 01:12:52,480
that you know sometimes journals are

1927
01:12:48,480 --> 01:12:55,440
interested in seeing a a mention of hay

1928
01:12:52,480 --> 01:12:57,679
instead of a house of brick. We need

1929
01:12:55,440 --> 01:13:00,640
more house of brick type of data to

1930
01:12:57,679 --> 01:13:04,159
really train these really valuable uh

1931
01:13:00,640 --> 01:13:07,120
data to train good uh AI models and

1932
01:13:04,159 --> 01:13:09,120
because these really mention of hey the

1933
01:13:07,120 --> 01:13:10,640
technologies are still evolving the tech

1934
01:13:09,120 --> 01:13:12,560
you know like you have a little bit of

1935
01:13:10,640 --> 01:13:15,040
here a little bit of other samples they

1936
01:13:12,560 --> 01:13:17,120
can never really be integrated together

1937
01:13:15,040 --> 01:13:20,080
to generate really useful insights and

1938
01:13:17,120 --> 01:13:22,320
you probably only you see batch effect.

1939
01:13:20,080 --> 01:13:24,800
Yeah.

1940
01:13:22,320 --> 01:13:27,199
All right. Guess it's my turn. Um yeah

1941
01:13:24,800 --> 01:13:28,480
so I actually thought the last talk was

1942
01:13:27,199 --> 01:13:30,320
quite interesting because I was trying

1943
01:13:28,480 --> 01:13:32,400
to connect it back to the stuff that we

1944
01:13:30,320 --> 01:13:34,000
do in terms of fairness but when we

1945
01:13:32,400 --> 01:13:35,920
think of fairness and proteins it's more

1946
01:13:34,000 --> 01:13:37,920
like there's certain proteins families

1947
01:13:35,920 --> 01:13:39,199
that actually uh the models really

1948
01:13:37,920 --> 01:13:41,679
struggle on like they don't understand

1949
01:13:39,199 --> 01:13:43,280
and don't learn anything about um I

1950
01:13:41,679 --> 01:13:44,880
don't know if fair fairness is the right

1951
01:13:43,280 --> 01:13:47,280
word for it but they're the worst. We

1952
01:13:44,880 --> 01:13:49,520
hate them. Those protein families don't

1953
01:13:47,280 --> 01:13:51,760
deserve to be recognized.

1954
01:13:49,520 --> 01:13:54,400
Yeah. And it is one of those things that

1955
01:13:51,760 --> 01:13:55,920
we often like check. we say well do do

1956
01:13:54,400 --> 01:13:57,679
these models like they start to work

1957
01:13:55,920 --> 01:13:58,800
really well for large protein families

1958
01:13:57,679 --> 01:14:00,560
like where there's a lot of data but

1959
01:13:58,800 --> 01:14:03,040
then for small protein families very

1960
01:14:00,560 --> 01:14:06,000
underst sampled um don't don't it work

1961
01:14:03,040 --> 01:14:08,159
so well and uh yeah I think there's a

1962
01:14:06,000 --> 01:14:10,000
lot of interesting joking aside it's the

1963
01:14:08,159 --> 01:14:11,520
same effect right it's uh there's a

1964
01:14:10,000 --> 01:14:14,880
different dynamic that needs to be

1965
01:14:11,520 --> 01:14:17,520
captured right um and uh if it's an

1966
01:14:14,880 --> 01:14:19,840
under represented sample it's hard to

1967
01:14:17,520 --> 01:14:24,320
capture that effect so it's it really is

1968
01:14:19,840 --> 01:14:26,159
the same problem y makes sense

1969
01:14:24,320 --> 01:14:28,000
Cool. So I would like to since we don't

1970
01:14:26,159 --> 01:14:29,920
have that much time left to open it up

1971
01:14:28,000 --> 01:14:31,760
for questions. I'm sure this is very

1972
01:14:29,920 --> 01:14:35,199
thoughtprovoking and there will be a lot

1973
01:14:31,760 --> 01:14:37,520
of questions. Um maybe I'll give this

1974
01:14:35,199 --> 01:14:39,760
one.

1975
01:14:37,520 --> 01:14:41,520
So I have a question on when for all

1976
01:14:39,760 --> 01:14:43,440
these foundational models for OMIX they

1977
01:14:41,520 --> 01:14:46,640
are coming and it was good to see the

1978
01:14:43,440 --> 01:14:48,960
talk uh but what are the biases and also

1979
01:14:46,640 --> 01:14:50,960
the morning started with Anul's work

1980
01:14:48,960 --> 01:14:53,199
where he was talking about TNF biases

1981
01:14:50,960 --> 01:14:54,719
and stuff. So as a student it seems with

1982
01:14:53,199 --> 01:14:56,719
all the foundational models there are

1983
01:14:54,719 --> 01:14:58,400
there are sure there are many biases but

1984
01:14:56,719 --> 01:15:00,560
as a community I'm not sure we

1985
01:14:58,400 --> 01:15:02,880
understand it. It seems apart from

1986
01:15:00,560 --> 01:15:06,640
authors people may not understand where

1987
01:15:02,880 --> 01:15:08,239
the things so I mean what's your take on

1988
01:15:06,640 --> 01:15:10,880
mean as a student it seems that there

1989
01:15:08,239 --> 01:15:13,120
should be a s some consortium or some

1990
01:15:10,880 --> 01:15:15,360
symposium dedicated to figure out in

1991
01:15:13,120 --> 01:15:16,640
what scenario these foundational models

1992
01:15:15,360 --> 01:15:18,719
what are the issues with these

1993
01:15:16,640 --> 01:15:20,560
foundational models rather than what

1994
01:15:18,719 --> 01:15:23,480
great thing these do and what's your

1995
01:15:20,560 --> 01:15:26,320
take on it

1996
01:15:23,480 --> 01:15:28,400
yeah I mean I I think that there should

1997
01:15:26,320 --> 01:15:30,640
be so uh let me let me answer more

1998
01:15:28,400 --> 01:15:30,640
seriously

1999
01:15:30,760 --> 01:15:37,040
Um it I think that it would be really

2000
01:15:34,560 --> 01:15:39,440
valuable if we had a slightly more

2001
01:15:37,040 --> 01:15:41,360
invested regulatory landscape. Right. I

2002
01:15:39,440 --> 01:15:44,080
think for example if the bill passed by

2003
01:15:41,360 --> 01:15:45,679
the past administration on AI um safety

2004
01:15:44,080 --> 01:15:47,199
and equity would not have been repealed

2005
01:15:45,679 --> 01:15:49,520
or if there were something to replace

2006
01:15:47,199 --> 01:15:51,520
it. Um that could be more encompassing

2007
01:15:49,520 --> 01:15:52,880
and and cover foundation models in all

2008
01:15:51,520 --> 01:15:54,960
settings you know health settings and

2009
01:15:52,880 --> 01:16:00,960
research settings etc.

2010
01:15:54,960 --> 01:16:03,199
um uh work on understanding AI bias is

2011
01:16:00,960 --> 01:16:05,120
actively being defunded. I know MIT

2012
01:16:03,199 --> 01:16:07,040
faculty members whose NSF careers were

2013
01:16:05,120 --> 01:16:09,840
cancelled because that was their area of

2014
01:16:07,040 --> 01:16:11,280
focus. Everybody said the foundation,

2015
01:16:09,840 --> 01:16:12,800
you know, the foundations will step the

2016
01:16:11,280 --> 01:16:14,800
philanthropy will step up. They have

2017
01:16:12,800 --> 01:16:16,640
not. I promise you. Everybody said

2018
01:16:14,800 --> 01:16:18,960
companies will step up. Sorry, they have

2019
01:16:16,640 --> 01:16:22,000
not. And so this research is actually

2020
01:16:18,960 --> 01:16:24,000
uniquely hard to do right now. There is

2021
01:16:22,000 --> 01:16:26,560
very little funding. And if you do that

2022
01:16:24,000 --> 01:16:28,159
research and you have grants um on other

2023
01:16:26,560 --> 01:16:29,760
things with federal agencies, your

2024
01:16:28,159 --> 01:16:31,679
grants with federal agencies on those

2025
01:16:29,760 --> 01:16:33,199
other things might also be cancelled. So

2026
01:16:31,679 --> 01:16:35,520
this is something that I do think we

2027
01:16:33,199 --> 01:16:37,840
should do a lot of investment into, but

2028
01:16:35,520 --> 01:16:39,360
it is not um being funded right now. So

2029
01:16:37,840 --> 01:16:44,719
it's it's hard to do in an academic

2030
01:16:39,360 --> 01:16:46,880
setting. Um the play is to rebrand. This

2031
01:16:44,719 --> 01:16:49,480
is what I was told this morning. It's

2032
01:16:46,880 --> 01:16:52,400
not fairness, it's

2033
01:16:49,480 --> 01:16:56,159
safety. Okay. As long as we can get the

2034
01:16:52,400 --> 01:16:58,679
EA crowd to buy in and agree that when

2035
01:16:56,159 --> 01:17:01,679
AGI comes for us, they'll kill women

2036
01:16:58,679 --> 01:17:04,000
first. Makes sense, right? You know,

2037
01:17:01,679 --> 01:17:06,239
then we can all be AI safety people and

2038
01:17:04,000 --> 01:17:10,239
get some of that sweet FTX money once

2039
01:17:06,239 --> 01:17:13,719
they come back. Thank you.

2040
01:17:10,239 --> 01:17:13,719
Anyone else?

2041
01:17:18,480 --> 01:17:23,280
Um so one thing I've noticed is uh uh a

2042
01:17:21,440 --> 01:17:26,159
lot of the discussion about data

2043
01:17:23,280 --> 01:17:28,960
generation for these models is a little

2044
01:17:26,159 --> 01:17:31,199
bit agnostic in the sense that actually

2045
01:17:28,960 --> 01:17:34,000
you know as many of you showed it's it's

2046
01:17:31,199 --> 01:17:36,400
actually quite uh feasible to go and

2047
01:17:34,000 --> 01:17:38,560
figure out where the models do poorly.

2048
01:17:36,400 --> 01:17:40,400
So you may not actually you know if you

2049
01:17:38,560 --> 01:17:43,040
just go to the wide and collect data you

2050
01:17:40,400 --> 01:17:45,199
may actually be collecting the uh

2051
01:17:43,040 --> 01:17:48,239
targeting the wrong density of the

2052
01:17:45,199 --> 01:17:50,719
landscape of data. So like do you know

2053
01:17:48,239 --> 01:17:52,320
of I I I don't know as many but like do

2054
01:17:50,719 --> 01:17:56,000
you know of efforts that are actively

2055
01:17:52,320 --> 01:17:58,080
looking to fill holes like uh model

2056
01:17:56,000 --> 01:18:00,480
based data sampling strategies data

2057
01:17:58,080 --> 01:18:03,679
generation strategies wouldn't those be

2058
01:18:00,480 --> 01:18:06,480
more effective than but but I guess if

2059
01:18:03,679 --> 01:18:07,760
all of us is what what is the

2060
01:18:06,480 --> 01:18:09,520
what is the target sorry they're

2061
01:18:07,760 --> 01:18:11,520
oversampling for groups that are under

2062
01:18:09,520 --> 01:18:13,840
reppresented in in other studies that's

2063
01:18:11,520 --> 01:18:15,679
sort of their contribution I guess in in

2064
01:18:13,840 --> 01:18:18,080
in those kind of scenarios it's maybe

2065
01:18:15,679 --> 01:18:20,719
easier to tell but in like biological

2066
01:18:18,080 --> 01:18:22,400
foundation models and like you know uh

2067
01:18:20,719 --> 01:18:24,640
things like that it's it's very hard to

2068
01:18:22,400 --> 01:18:26,640
know a priority what it is but you can

2069
01:18:24,640 --> 01:18:29,199
iterate through it's sort of like active

2070
01:18:26,640 --> 01:18:30,640
learning but uh with a big human in the

2071
01:18:29,199 --> 01:18:32,560
loop you know many years of data

2072
01:18:30,640 --> 01:18:34,560
collection in the loop it just doesn't

2073
01:18:32,560 --> 01:18:35,840
seem like there are big efforts really

2074
01:18:34,560 --> 01:18:38,480
pushing I mean people have been saying

2075
01:18:35,840 --> 01:18:40,800
this for decades but I've just not seen

2076
01:18:38,480 --> 01:18:42,320
big push in that direction yeah I I

2077
01:18:40,800 --> 01:18:44,360
think one issue with biological data is

2078
01:18:42,320 --> 01:18:46,560
that there isn't enough standardization

2079
01:18:44,360 --> 01:18:47,840
in similar to what we get in medical

2080
01:18:46,560 --> 01:18:50,000
data, right? So, so, so a lot of people

2081
01:18:47,840 --> 01:18:51,760
are complaining about how unstandardized

2082
01:18:50,000 --> 01:18:53,520
all the medical data is, but but

2083
01:18:51,760 --> 01:18:55,120
biological data is often collected for

2084
01:18:53,520 --> 01:18:56,400
studies, it's like a hodgepodge of like

2085
01:18:55,120 --> 01:18:57,760
what what it was actually used for. And

2086
01:18:56,400 --> 01:19:00,000
when you when it comes to training these

2087
01:18:57,760 --> 01:19:03,320
foundation models, you want to use, you

2088
01:19:00,000 --> 01:19:05,520
know, every spatial

2089
01:19:03,320 --> 01:19:06,880
transcription, right? It was done using

2090
01:19:05,520 --> 01:19:08,719
number of different techniques. It's

2091
01:19:06,880 --> 01:19:10,239
it's collected for different purposes

2092
01:19:08,719 --> 01:19:11,760
was was done to answer completely

2093
01:19:10,239 --> 01:19:13,199
different questions. So, the

2094
01:19:11,760 --> 01:19:15,280
distribution of the data would be sort

2095
01:19:13,199 --> 01:19:17,679
of all over all over the place. So in in

2096
01:19:15,280 --> 01:19:19,560
in medical data we have some hope that

2097
01:19:17,679 --> 01:19:22,159
you know I mean we know from all these

2098
01:19:19,560 --> 01:19:24,159
studies from you know the large

2099
01:19:22,159 --> 01:19:26,000
companies that diversity of data is way

2100
01:19:24,159 --> 01:19:28,080
more important than the quantity of data

2101
01:19:26,000 --> 01:19:32,000
and it's just really difficult to find

2102
01:19:28,080 --> 01:19:34,159
diverse data uh for you know more

2103
01:19:32,000 --> 01:19:35,360
biologically oriented problems. So I

2104
01:19:34,159 --> 01:19:36,960
think what would happen is that there

2105
01:19:35,360 --> 01:19:38,400
are a lot of these foundation models for

2106
01:19:36,960 --> 01:19:39,679
all kinds of different purposes. The

2107
01:19:38,400 --> 01:19:40,880
next step is going to be that they're

2108
01:19:39,679 --> 01:19:43,120
all trained on different distributions

2109
01:19:40,880 --> 01:19:45,360
of data and they all represent the the

2110
01:19:43,120 --> 01:19:46,719
same kind of data. So, so, so because

2111
01:19:45,360 --> 01:19:48,080
they're they're inherent training

2112
01:19:46,719 --> 01:19:49,840
distributions are different, maybe you

2113
01:19:48,080 --> 01:19:51,600
can use multiple foundation models to

2114
01:19:49,840 --> 01:19:53,199
see, you know, mixture of foundation

2115
01:19:51,600 --> 01:19:54,560
models even using something very

2116
01:19:53,199 --> 01:19:55,920
simplistic for your downstream

2117
01:19:54,560 --> 01:19:57,440
downstream tasks. That's what would

2118
01:19:55,920 --> 01:19:59,199
happen in the in the short term before

2119
01:19:57,440 --> 01:20:01,440
we have more standardized data

2120
01:19:59,199 --> 01:20:03,840
collection protocols.

2121
01:20:01,440 --> 01:20:05,920
Can I just point out also that we're we

2122
01:20:03,840 --> 01:20:08,560
really like it when you know large

2123
01:20:05,920 --> 01:20:10,719
foundation models find something new in

2124
01:20:08,560 --> 01:20:12,560
in some settings and then we slap them

2125
01:20:10,719 --> 01:20:14,719
and say don't hallucinate in other

2126
01:20:12,560 --> 01:20:17,440
settings. And so it's also unclear what

2127
01:20:14,719 --> 01:20:19,840
properties we want for um this kind of

2128
01:20:17,440 --> 01:20:22,480
like forecasting without support in in

2129
01:20:19,840 --> 01:20:25,040
real data space.

2130
01:20:22,480 --> 01:20:26,560
Yeah, I guess I'll add in the protein

2131
01:20:25,040 --> 01:20:28,719
world. I mean we we have lots of

2132
01:20:26,560 --> 01:20:30,960
sequencing going on um and folks have

2133
01:20:28,719 --> 01:20:32,719
been trying to go to weird places like

2134
01:20:30,960 --> 01:20:34,560
under the ocean and so on and just

2135
01:20:32,719 --> 01:20:36,239
sequencing everything. I think I've seen

2136
01:20:34,560 --> 01:20:37,920
a study where somebody actually swiped

2137
01:20:36,239 --> 01:20:40,480
the outside of the space station and

2138
01:20:37,920 --> 01:20:42,400
found some interesting weird archa

2139
01:20:40,480 --> 01:20:44,400
living there. It's probably I mean I

2140
01:20:42,400 --> 01:20:45,320
don't think it came from space but

2141
01:20:44,400 --> 01:20:48,159
probably

2142
01:20:45,320 --> 01:20:49,840
was but but yeah there there's there's

2143
01:20:48,159 --> 01:20:52,080
definitely a lot of sequencing efforts

2144
01:20:49,840 --> 01:20:53,520
happening in specific um and and we

2145
01:20:52,080 --> 01:20:54,640
still see like every two years we're

2146
01:20:53,520 --> 01:20:56,640
roughly doubling in the number of

2147
01:20:54,640 --> 01:20:59,280
sequences that are quite different from

2148
01:20:56,640 --> 01:21:01,040
what we see before. Um so there so in

2149
01:20:59,280 --> 01:21:06,440
the protein world I think we're might be

2150
01:21:01,040 --> 01:21:06,440
okay for now until the finding is cut.

2151
01:21:10,640 --> 01:21:17,920
Thank you. Based on what you present all

2152
01:21:13,400 --> 01:21:19,080
all think it's more not if we can model

2153
01:21:17,920 --> 01:21:23,280
the

2154
01:21:19,080 --> 01:21:26,880
human body and health it's when and if

2155
01:21:23,280 --> 01:21:31,960
we can predict model and cure every

2156
01:21:26,880 --> 01:21:31,960
future diseases what's next

2157
01:21:33,280 --> 01:21:38,159
I'll take this as the last question

2158
01:21:36,159 --> 01:21:40,320
then we'll have universal child care

2159
01:21:38,159 --> 01:21:43,199
right afterwards that's the that's the

2160
01:21:40,320 --> 01:21:44,960
next fun, you know,

2161
01:21:43,199 --> 01:21:46,640
I guess I mean I'm guessing you're

2162
01:21:44,960 --> 01:21:49,199
thinking human health, but how about

2163
01:21:46,640 --> 01:21:52,239
like all the other animals out there? So

2164
01:21:49,199 --> 01:21:55,280
in general, we'll move on to the rest of

2165
01:21:52,239 --> 01:21:57,360
life, I suppose.

2166
01:21:55,280 --> 01:21:59,520
In addition to physical health, I think

2167
01:21:57,360 --> 01:22:01,440
mental health will still always be like

2168
01:21:59,520 --> 01:22:03,120
how are we going to make people happier,

2169
01:22:01,440 --> 01:22:05,920
right? Like there are also some

2170
01:22:03,120 --> 01:22:08,320
physiological things. I'm sure we'll

2171
01:22:05,920 --> 01:22:10,880
we'll have plenty of good things to work

2172
01:22:08,320 --> 01:22:13,679
on.

2173
01:22:10,880 --> 01:22:15,760
Basel has something more to add. No, I I

2174
01:22:13,679 --> 01:22:17,840
I I completely agree. I I think it'll

2175
01:22:15,760 --> 01:22:19,679
take a while to get there, but yeah, I

2176
01:22:17,840 --> 01:22:22,560
don't think it's happening anytime soon

2177
01:22:19,679 --> 01:22:24,719
like we've got a way many PhDs in front

2178
01:22:22,560 --> 01:22:27,040
of us.

2179
01:22:24,719 --> 01:22:29,040
So, with this and a lot more work to do,

2180
01:22:27,040 --> 01:22:30,880
thank you so much to this panel for

2181
01:22:29,040 --> 01:22:34,800
wonderful.

2182
01:22:30,880 --> 01:22:37,440
[Applause]

2183
01:22:34,800 --> 01:22:39,520
So this brings us already to the end of

2184
01:22:37,440 --> 01:22:42,080
this first uh annual symposium of the

2185
01:22:39,520 --> 01:22:44,000
Eric and Wendy Schmidt Center. I really

2186
01:22:42,080 --> 01:22:46,320
loved it. I loved all the exciting

2187
01:22:44,000 --> 01:22:48,960
talks. Um a lot of stimulating

2188
01:22:46,320 --> 01:22:52,239
discussions and you know we started from

2189
01:22:48,960 --> 01:22:54,560
very basic cell biology, tissue biology

2190
01:22:52,239 --> 01:22:57,679
um all the way to particular uh

2191
01:22:54,560 --> 01:22:59,360
pathology to um AI models that were

2192
01:22:57,679 --> 01:23:01,280
developed for particular biological

2193
01:22:59,360 --> 01:23:03,520
applications to foundation models that

2194
01:23:01,280 --> 01:23:06,000
are very very broad. So I hope this

2195
01:23:03,520 --> 01:23:08,000
meeting was exciting to all of you um

2196
01:23:06,000 --> 01:23:10,159
and that you were also all able to build

2197
01:23:08,000 --> 01:23:12,560
new connections and had a lot of uh

2198
01:23:10,159 --> 01:23:14,960
different discussions. You know ML will

2199
01:23:12,560 --> 01:23:17,360
transform all areas of biology and and

2200
01:23:14,960 --> 01:23:19,199
the medical sciences and you know this

2201
01:23:17,360 --> 01:23:21,199
is so important to bring this community

2202
01:23:19,199 --> 01:23:24,080
together to actually really make this

2203
01:23:21,199 --> 01:23:28,000
marriage uh become better and better and

2204
01:23:24,080 --> 01:23:31,040
stronger. Um so I would like to end by

2205
01:23:28,000 --> 01:23:34,320
thanking all the people who made this uh

2206
01:23:31,040 --> 01:23:36,639
so enjoyable and really made um this uh

2207
01:23:34,320 --> 01:23:39,360
conference and workshop come together.

2208
01:23:36,639 --> 01:23:41,440
Uh so that's the amazing team behind the

2209
01:23:39,360 --> 01:23:45,679
Eric and Wendy Schmidt Center. So, I

2210
01:23:41,440 --> 01:23:45,679
would love if they could all get up.

2211
01:23:48,440 --> 01:23:56,400
And so, we have Jennifer, Sue, Samanda,

2212
01:23:53,080 --> 01:23:58,320
Leticia, Nadia, Elva, and Ore. I think

2213
01:23:56,400 --> 01:23:59,910
they're all there. So, thank you so

2214
01:23:58,320 --> 01:24:02,840
much. This was

2215
01:23:59,910 --> 01:24:05,920
[Applause]

2216
01:24:02,840 --> 01:24:07,920
awesome. And also, Jirro Studio, who

2217
01:24:05,920 --> 01:24:12,159
helped us with everything, getting

2218
01:24:07,920 --> 01:24:12,159
through so carefully here. So, thank you

2219
01:24:14,679 --> 01:24:20,400
also. And with this, I know we still

2220
01:24:17,199 --> 01:24:24,560
have a song. Is that right? There is no

2221
01:24:20,400 --> 01:24:26,920
sock. There's no song.

2222
01:24:24,560 --> 01:24:28,560
I'm putting Lindsay on the spot.

2223
01:24:26,920 --> 01:24:30,719
[Laughter]

2224
01:24:28,560 --> 01:24:33,440
So then you all have to beg him for a

2225
01:24:30,719 --> 01:24:35,940
song before we go outside. But with

2226
01:24:33,440 --> 01:24:42,989
that, thank you all for coming.

2227
01:24:35,940 --> 01:24:42,989
[Applause]


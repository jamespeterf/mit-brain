1
00:00:02,200 --> 00:00:09,040
my name is Patty mass and I'm a faculty

2
00:00:04,880 --> 00:00:12,280
member at the MIT media laboratory and

3
00:00:09,040 --> 00:00:15,720
my work lies at the intersection of

4
00:00:12,280 --> 00:00:20,160
artificial intelligence human computer

5
00:00:15,720 --> 00:00:23,439
interaction and um basically psychology

6
00:00:20,160 --> 00:00:26,279
so I studied um artificial intelligence

7
00:00:23,439 --> 00:00:30,199
and computer science over 30 years ago

8
00:00:26,279 --> 00:00:34,040
back in Brussels Belgium and of course

9
00:00:30,199 --> 00:00:37,040
um the uh MIT AI lab as it was called

10
00:00:34,040 --> 00:00:40,320
back then was really the mecca where

11
00:00:37,040 --> 00:00:44,920
people uh would want to be if you did uh

12
00:00:40,320 --> 00:00:47,879
AI research so soon after getting my PhD

13
00:00:44,920 --> 00:00:50,719
I uh went to the AI lab to become a

14
00:00:47,879 --> 00:00:53,000
postto there and then after that I

15
00:00:50,719 --> 00:00:56,640
became a visiting Professor actually for

16
00:00:53,000 --> 00:00:59,440
a year and yeah was just super excited

17
00:00:56,640 --> 00:01:01,079
to be working with all these uh Founders

18
00:00:59,440 --> 00:01:03,519
in the field field and really these

19
00:01:01,079 --> 00:01:07,640
seminal figures people like Marvin

20
00:01:03,519 --> 00:01:11,600
Minsky Pat Winston uh Rodney Brooks and

21
00:01:07,640 --> 00:01:14,759
others so after being at MIT for 2 years

22
00:01:11,600 --> 00:01:18,360
at uh the AI lab again uh right now it's

23
00:01:14,759 --> 00:01:21,840
called seale actually um I decided to

24
00:01:18,360 --> 00:01:24,920
move to the media laboratory because I

25
00:01:21,840 --> 00:01:28,079
uh was more interested in helping people

26
00:01:24,920 --> 00:01:32,079
with uh being smarter and being better

27
00:01:28,079 --> 00:01:35,520
off rather than trying to um model

28
00:01:32,079 --> 00:01:39,640
intelligence in machines uh the media

29
00:01:35,520 --> 00:01:42,320
lab is a lot more focused on sort of um

30
00:01:39,640 --> 00:01:45,399
uh the human impact of emerging

31
00:01:42,320 --> 00:01:48,759
Technologies and really and societal

32
00:01:45,399 --> 00:01:52,119
impact and we really try to think hard

33
00:01:48,759 --> 00:01:54,119
about how um emerging Technologies or

34
00:01:52,119 --> 00:01:56,680
Cutting Edge Technologies like

35
00:01:54,119 --> 00:01:59,280
artificial intelligence but also

36
00:01:56,680 --> 00:02:02,840
wearables things like that how they

37
00:01:59,280 --> 00:02:07,240
might improve uh people's lives the

38
00:02:02,840 --> 00:02:11,440
reason why I uh do the work uh that I do

39
00:02:07,240 --> 00:02:16,200
is that um technology plays such a huge

40
00:02:11,440 --> 00:02:20,080
role in our lives um kids as young as to

41
00:02:16,200 --> 00:02:23,400
start using iPads and and uh they start

42
00:02:20,080 --> 00:02:27,760
learning from or via computers with

43
00:02:23,400 --> 00:02:32,319
things like KH Academy scratch Etc um as

44
00:02:27,760 --> 00:02:34,760
early as age 11 or 12 a lot of kids get

45
00:02:32,319 --> 00:02:38,400
smartphones and before that they already

46
00:02:34,760 --> 00:02:42,879
start using laptops Etc so from that

47
00:02:38,400 --> 00:02:45,920
very early age on we are um surrounded

48
00:02:42,879 --> 00:02:49,360
by technology and it plays such a huge

49
00:02:45,920 --> 00:02:51,599
role in our lives but unfortunately a

50
00:02:49,360 --> 00:02:54,440
lot of that technology that we use

51
00:02:51,599 --> 00:02:57,760
smartphones apps and all of that have

52
00:02:54,440 --> 00:03:02,760
not necessarily always been created with

53
00:02:57,760 --> 00:03:05,400
the best interests of people in mind um

54
00:03:02,760 --> 00:03:07,799
ultimately the companies that create all

55
00:03:05,400 --> 00:03:10,599
of these products have a bottom line

56
00:03:07,799 --> 00:03:13,040
that they have to think about and uh

57
00:03:10,599 --> 00:03:16,959
right now the the whole uh business

58
00:03:13,040 --> 00:03:20,159
model of advertising is still what

59
00:03:16,959 --> 00:03:24,159
drives a lot of Technology development

60
00:03:20,159 --> 00:03:27,159
and what um ends up uh deciding really

61
00:03:24,159 --> 00:03:30,599
what types of Technologies we do

62
00:03:27,159 --> 00:03:34,319
surround ourselves with so we try to ask

63
00:03:30,599 --> 00:03:37,640
the opposite question what if uh these

64
00:03:34,319 --> 00:03:39,000
technologies that are so present in our

65
00:03:37,640 --> 00:03:42,400
lives

66
00:03:39,000 --> 00:03:45,760
24x7 what if they were designed with uh

67
00:03:42,400 --> 00:03:49,879
the best interests of people in mind

68
00:03:45,760 --> 00:03:53,799
could technology help people uh learn

69
00:03:49,879 --> 00:03:56,439
take care of their health um um develop

70
00:03:53,799 --> 00:04:00,239
into the person that they ultimately

71
00:03:56,439 --> 00:04:03,760
want to be can it help uh the elderly

72
00:04:00,239 --> 00:04:07,920
when some of their um abilities uh

73
00:04:03,760 --> 00:04:11,560
decline such as memory and so on um so

74
00:04:07,920 --> 00:04:14,840
we we try to look at how these systems

75
00:04:11,560 --> 00:04:17,840
could help with all of these aspects of

76
00:04:14,840 --> 00:04:17,840
life


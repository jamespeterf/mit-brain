1
00:00:01,839 --> 00:00:05,520
Thank you Jo for the invitation. It's

2
00:00:04,160 --> 00:00:08,080
really a pleasure to be here. I know

3
00:00:05,520 --> 00:00:09,599
many people in the audience interacted

4
00:00:08,080 --> 00:00:12,000
with many people over the years and it's

5
00:00:09,599 --> 00:00:13,519
fun to be here and talk about these

6
00:00:12,000 --> 00:00:16,240
subjects something near and dear to my

7
00:00:13,519 --> 00:00:19,359
heart heart uh safe autonomy and in the

8
00:00:16,240 --> 00:00:21,199
intro I I like the the the the ratio of

9
00:00:19,359 --> 00:00:22,400
demos to theorems. So you can count in

10
00:00:21,199 --> 00:00:24,400
this there are theorems and there are

11
00:00:22,400 --> 00:00:26,080
demos. So we'll see what the ratio ends

12
00:00:24,400 --> 00:00:28,720
up being. But that's kind of the goal is

13
00:00:26,080 --> 00:00:30,720
how do we formally approach robotics and

14
00:00:28,720 --> 00:00:32,640
and before I begin any talk I really

15
00:00:30,720 --> 00:00:35,680
need to point out my students and

16
00:00:32,640 --> 00:00:38,079
posttos uh they're the instrumental

17
00:00:35,680 --> 00:00:40,079
element of this entire presentation. The

18
00:00:38,079 --> 00:00:41,680
videos wouldn't exist without them. The

19
00:00:40,079 --> 00:00:43,120
theorems by and large wouldn't exist

20
00:00:41,680 --> 00:00:46,320
without them. So they really make

21
00:00:43,120 --> 00:00:47,520
everything go. All right. So I don't

22
00:00:46,320 --> 00:00:49,039
think I need to say that we're in the

23
00:00:47,520 --> 00:00:50,879
moment of the humanoids, right? Everyone

24
00:00:49,039 --> 00:00:53,199
knows this. Everyone sees every other

25
00:00:50,879 --> 00:00:55,760
day. I at first I used to update the

26
00:00:53,199 --> 00:00:57,360
videos and then I just stopped because

27
00:00:55,760 --> 00:00:58,640
if I tried to grab the video of the

28
00:00:57,360 --> 00:01:00,879
moment of the dancing robot of the

29
00:00:58,640 --> 00:01:02,800
moment, I just couldn't keep up. But

30
00:01:00,879 --> 00:01:05,439
it's really incredible what's happened

31
00:01:02,800 --> 00:01:07,920
in the last like, you know, year or two

32
00:01:05,439 --> 00:01:10,240
in terms of humanoid robots and the way

33
00:01:07,920 --> 00:01:12,720
they're being deployed and the behaviors

34
00:01:10,240 --> 00:01:15,600
we're seeing. It's honestly mind-blowing

35
00:01:12,720 --> 00:01:17,920
from someone who back in the day I did

36
00:01:15,600 --> 00:01:19,840
like little simple planer walking robots

37
00:01:17,920 --> 00:01:21,520
and it actually would go viral, right?

38
00:01:19,840 --> 00:01:24,640
And now we're in a we're in a different

39
00:01:21,520 --> 00:01:26,960
era. Uh and so of course this extends to

40
00:01:24,640 --> 00:01:29,119
my lab. I have a humanoid, a G1 like

41
00:01:26,960 --> 00:01:30,799
many people have now. This was back in

42
00:01:29,119 --> 00:01:33,200
January and I like showing this video

43
00:01:30,799 --> 00:01:35,119
because this was just a couple days

44
00:01:33,200 --> 00:01:37,200
after we got the robot in our lab and we

45
00:01:35,119 --> 00:01:39,360
I was doing a demo here and there's a

46
00:01:37,200 --> 00:01:42,000
bunch of people standing off camera and

47
00:01:39,360 --> 00:01:44,079
the robot was walking and my student

48
00:01:42,000 --> 00:01:46,240
Gary told me during the demo that he was

49
00:01:44,079 --> 00:01:48,240
running our locomotion policy in this

50
00:01:46,240 --> 00:01:49,759
case an RL policy and I was shocked that

51
00:01:48,240 --> 00:01:52,240
he got it working in like two days and

52
00:01:49,759 --> 00:01:53,520
it was demo worthy. So this translation

53
00:01:52,240 --> 00:01:56,479
of getting things to actually go on

54
00:01:53,520 --> 00:01:58,320
hardware nowadays is incredibly fast. Of

55
00:01:56,479 --> 00:02:00,240
course, in my lab, we're really

56
00:01:58,320 --> 00:02:01,280
interested in where our heritage is. And

57
00:02:00,240 --> 00:02:04,159
what you'll see in this talk is

58
00:02:01,280 --> 00:02:05,600
modelbased control methods. So, we've

59
00:02:04,159 --> 00:02:07,680
been playing with this idea of

60
00:02:05,600 --> 00:02:11,200
understanding pure modelbased control.

61
00:02:07,680 --> 00:02:13,440
So, this is just MPC for humanoid

62
00:02:11,200 --> 00:02:15,680
locomotion. Zero learning involved. And

63
00:02:13,440 --> 00:02:17,599
this is an RL policy, sort of the

64
00:02:15,680 --> 00:02:19,520
standard RL policy. None of this was

65
00:02:17,599 --> 00:02:21,280
sort of published, but and you can see

66
00:02:19,520 --> 00:02:22,879
that we're trying to understand kind of

67
00:02:21,280 --> 00:02:25,520
how do these two things relate to one

68
00:02:22,879 --> 00:02:27,680
another uh in the lab. And that's really

69
00:02:25,520 --> 00:02:29,280
been what this talk is about now is kind

70
00:02:27,680 --> 00:02:31,200
of the last sort of year of

71
00:02:29,280 --> 00:02:34,160
soulsearching, let's say, together with

72
00:02:31,200 --> 00:02:35,840
some historic context in in where

73
00:02:34,160 --> 00:02:37,840
control methods can actually fit in

74
00:02:35,840 --> 00:02:40,560
this. Because the reality is is when you

75
00:02:37,840 --> 00:02:42,560
combine modelbased with learning based

76
00:02:40,560 --> 00:02:44,800
methods, you get some really special

77
00:02:42,560 --> 00:02:46,720
things. I have to admit as a modelbased

78
00:02:44,800 --> 00:02:48,879
person, as a as a someone that loves

79
00:02:46,720 --> 00:02:51,519
math, you cannot deny the power of

80
00:02:48,879 --> 00:02:53,440
injecting math into reinforcement

81
00:02:51,519 --> 00:02:54,640
learning. This is an example which I'm

82
00:02:53,440 --> 00:02:57,360
going to talk about later in the talk

83
00:02:54,640 --> 00:02:58,959
but this is running what we call CLF RL.

84
00:02:57,360 --> 00:03:00,640
Uh so it's an example of really this

85
00:02:58,959 --> 00:03:03,440
fusion and what we're able to achieve

86
00:03:00,640 --> 00:03:06,080
with it. But with the injection of

87
00:03:03,440 --> 00:03:07,680
learning based methods comes this sort

88
00:03:06,080 --> 00:03:09,920
of

89
00:03:07,680 --> 00:03:12,080
distribution shift failure mode right

90
00:03:09,920 --> 00:03:14,080
that's really catastrophic. So what

91
00:03:12,080 --> 00:03:15,519
happens in this video is this the robot

92
00:03:14,080 --> 00:03:17,840
as you'll see in the in the next bit

93
00:03:15,519 --> 00:03:19,440
when it plays in slow motion is it was

94
00:03:17,840 --> 00:03:21,760
walking just fine. This is just a pure

95
00:03:19,440 --> 00:03:24,159
RL policy in this case. And the the

96
00:03:21,760 --> 00:03:26,159
ankles strike. So it just starts with a

97
00:03:24,159 --> 00:03:28,239
self collision. That self collision

98
00:03:26,159 --> 00:03:29,599
knocks the robot into a domain it wasn't

99
00:03:28,239 --> 00:03:31,519
trained for. Right? You're out of

100
00:03:29,599 --> 00:03:33,519
distribution and all of a sudden it just

101
00:03:31,519 --> 00:03:35,599
goes crazy and it actually broke the

102
00:03:33,519 --> 00:03:36,879
ankles. It was it was a mess. And if

103
00:03:35,599 --> 00:03:38,000
you've ever played with robots and if

104
00:03:36,879 --> 00:03:39,920
you look on the internet, you see all

105
00:03:38,000 --> 00:03:41,440
these examples of robots going crazy.

106
00:03:39,920 --> 00:03:43,040
It's because they're you know when you

107
00:03:41,440 --> 00:03:44,480
train things on data and you deploy

108
00:03:43,040 --> 00:03:45,519
things based on that trained data, you

109
00:03:44,480 --> 00:03:46,959
don't really know what's going to

110
00:03:45,519 --> 00:03:49,040
happen, right? Right? So the fundamental

111
00:03:46,959 --> 00:03:51,040
question becomes how do we do things

112
00:03:49,040 --> 00:03:52,879
like guarantee safety in this context

113
00:03:51,040 --> 00:03:54,959
right what's the paradigm to guarantee

114
00:03:52,879 --> 00:03:56,560
safety and how do we certify it so

115
00:03:54,959 --> 00:03:59,040
that's really what this talk is about

116
00:03:56,560 --> 00:04:01,040
and I'm going to make the strong

117
00:03:59,040 --> 00:04:02,400
statement here that I hope to defend

118
00:04:01,040 --> 00:04:05,200
throughout the presentation which is

119
00:04:02,400 --> 00:04:07,920
that safety is the key bottleneck to the

120
00:04:05,200 --> 00:04:10,080
deployment of AI that if we don't solve

121
00:04:07,920 --> 00:04:12,319
this safety problem all the cool dancing

122
00:04:10,080 --> 00:04:15,680
videos you see online of humanoid robots

123
00:04:12,319 --> 00:04:18,799
will never be realized in any like real

124
00:04:15,680 --> 00:04:21,120
world application domain.

125
00:04:18,799 --> 00:04:24,160
So to add to this, let me sort of say

126
00:04:21,120 --> 00:04:25,600
this one more way. There's two axes that

127
00:04:24,160 --> 00:04:27,360
you look at with robots. There's

128
00:04:25,600 --> 00:04:29,520
performance and there's safety,

129
00:04:27,360 --> 00:04:31,199
robustness, reliability. Right now,

130
00:04:29,520 --> 00:04:33,520
everyone is pushing the performance

131
00:04:31,199 --> 00:04:35,759
axis. That's great, but it results in

132
00:04:33,520 --> 00:04:37,120
very brittle behaviors that again once

133
00:04:35,759 --> 00:04:39,600
you take them out of where they're

134
00:04:37,120 --> 00:04:41,840
trained, they can go crazy. So we need

135
00:04:39,600 --> 00:04:44,000
to enable those behaviors to be

136
00:04:41,840 --> 00:04:45,919
deployed. We need to we need to remove

137
00:04:44,000 --> 00:04:47,680
the friction that safety will give

138
00:04:45,919 --> 00:04:50,880
ultimately in these ideas being deployed

139
00:04:47,680 --> 00:04:54,560
in the real world. And my second claim

140
00:04:50,880 --> 00:04:57,040
is that control theory is the way to

141
00:04:54,560 --> 00:04:59,440
remove this blocker.

142
00:04:57,040 --> 00:05:01,360
So this is also a strong statement and

143
00:04:59,440 --> 00:05:03,600
incredibly biased from my perspective to

144
00:05:01,360 --> 00:05:05,040
be very clear um because I'm a control

145
00:05:03,600 --> 00:05:07,199
theorist. So of course I'm going to say

146
00:05:05,040 --> 00:05:08,960
control theory is going to be the you

147
00:05:07,199 --> 00:05:10,080
know enable this deployment. But I can

148
00:05:08,960 --> 00:05:12,320
think I can back it up with some

149
00:05:10,080 --> 00:05:13,919
evidence. In particular, this is an

150
00:05:12,320 --> 00:05:14,960
example of where control theory can play

151
00:05:13,919 --> 00:05:16,800
a role in what I'm going to talk about

152
00:05:14,960 --> 00:05:20,080
in this talk a bit. Things like a safety

153
00:05:16,800 --> 00:05:21,520
filter. You take an RL policy which you

154
00:05:20,080 --> 00:05:23,600
might be able to command to do bad

155
00:05:21,520 --> 00:05:25,360
things like knock over this box. You

156
00:05:23,600 --> 00:05:27,919
have a safety filter which is based on

157
00:05:25,360 --> 00:05:31,280
control theoretic methods. In this case,

158
00:05:27,919 --> 00:05:33,840
it's a CBFQP. And this safety filter

159
00:05:31,280 --> 00:05:36,000
modulates the RL algorithm to guarantee

160
00:05:33,840 --> 00:05:38,080
safety without knowing what the RL

161
00:05:36,000 --> 00:05:39,919
algorithm is or how it operates except

162
00:05:38,080 --> 00:05:42,320
that it takes a reference signal and

163
00:05:39,919 --> 00:05:44,560
tracks it. So we need to be able to deal

164
00:05:42,320 --> 00:05:46,240
with control with learning in a way that

165
00:05:44,560 --> 00:05:47,840
we have elements we might not be able to

166
00:05:46,240 --> 00:05:49,680
fully understand that is like blackbox

167
00:05:47,840 --> 00:05:51,120
elements and we need to have formal

168
00:05:49,680 --> 00:05:53,759
guarantees associated with that

169
00:05:51,120 --> 00:05:57,280
deployment and this will enable things

170
00:05:53,759 --> 00:05:58,800
to be actually deployed in practice. So

171
00:05:57,280 --> 00:06:00,400
before I go into that, I want to step

172
00:05:58,800 --> 00:06:02,479
back for a second again on my history of

173
00:06:00,400 --> 00:06:05,759
where I come from. I'm a modelbased

174
00:06:02,479 --> 00:06:08,080
control person, right? I love Leoponov.

175
00:06:05,759 --> 00:06:09,680
I love barrier. I love dynamical

176
00:06:08,080 --> 00:06:11,759
systems. I love nonlinear dynamical

177
00:06:09,680 --> 00:06:13,840
systems in particular. I love hybrid

178
00:06:11,759 --> 00:06:17,039
system models. And this is actually now

179
00:06:13,840 --> 00:06:18,639
a decade old video. So 10 years ago, and

180
00:06:17,039 --> 00:06:20,000
it's still pretty good. I got to say,

181
00:06:18,639 --> 00:06:23,600
sometimes we forget that good things

182
00:06:20,000 --> 00:06:26,000
were done before like a year ago. And uh

183
00:06:23,600 --> 00:06:27,759
this is this is full multi-dommain locom

184
00:06:26,000 --> 00:06:29,280
motion on a full-scale humanoid robot

185
00:06:27,759 --> 00:06:31,440
using just pure modelbased control

186
00:06:29,280 --> 00:06:32,880
methods CLFS where we actually have

187
00:06:31,440 --> 00:06:34,800
springs in the ankles. So we have

188
00:06:32,880 --> 00:06:36,560
compliant elements at the base and we're

189
00:06:34,800 --> 00:06:38,319
able to get very natural and efficient

190
00:06:36,560 --> 00:06:40,319
walking. This at the time was the most

191
00:06:38,319 --> 00:06:42,800
efficient locomotion ever realized on a

192
00:06:40,319 --> 00:06:44,560
humanoid type robot. We've taken these

193
00:06:42,800 --> 00:06:46,000
ideas and because they're they're model

194
00:06:44,560 --> 00:06:48,240
based, we can extend them to other

195
00:06:46,000 --> 00:06:50,560
robots. Of course, this is Cassie, which

196
00:06:48,240 --> 00:06:52,240
was for a while really the only biped

197
00:06:50,560 --> 00:06:54,319
robot you could buy built by Agility

198
00:06:52,240 --> 00:06:56,319
Robotics, uh, who is now deploying

199
00:06:54,319 --> 00:06:58,479
Digit. Uh, and we're able to apply a

200
00:06:56,319 --> 00:07:00,000
very similar paradigm in that case. So,

201
00:06:58,479 --> 00:07:01,680
let me kind of talk about what that is.

202
00:07:00,000 --> 00:07:03,759
So, let me do like a brief fiveminute

203
00:07:01,680 --> 00:07:05,360
primer or less two-minute primer on

204
00:07:03,759 --> 00:07:06,720
nonlinear control because most of

205
00:07:05,360 --> 00:07:08,479
nonlinear control can be really be

206
00:07:06,720 --> 00:07:10,720
broken down to everything on the the

207
00:07:08,479 --> 00:07:13,520
right side of this slide in a nutshell.

208
00:07:10,720 --> 00:07:15,599
Right? So, you have a nonlinear system

209
00:07:13,520 --> 00:07:16,720
just general nonlinear typically a fine.

210
00:07:15,599 --> 00:07:18,240
And if you want to do something like

211
00:07:16,720 --> 00:07:21,360
stabilize the system, what you do is

212
00:07:18,240 --> 00:07:23,520
find a certificate for that stability.

213
00:07:21,360 --> 00:07:24,960
In this case, the the certificate will

214
00:07:23,520 --> 00:07:26,800
be something like a leoponol function or

215
00:07:24,960 --> 00:07:28,880
a control leoponov function. Here I'm

216
00:07:26,800 --> 00:07:30,800
using leoponov with exponential decay.

217
00:07:28,880 --> 00:07:32,240
So you make sure that function satisfies

218
00:07:30,800 --> 00:07:33,919
a property you want. In this case,

219
00:07:32,240 --> 00:07:35,440
positive definite and that its

220
00:07:33,919 --> 00:07:38,400
derivative condition with respect to

221
00:07:35,440 --> 00:07:40,319
flows of the system satisfy a decay rate

222
00:07:38,400 --> 00:07:42,560
that guarantees the type of stability

223
00:07:40,319 --> 00:07:44,240
you want. And what this does by the

224
00:07:42,560 --> 00:07:46,000
comparison lema says that this thing

225
00:07:44,240 --> 00:07:48,400
decays like this. the scalar dynamical

226
00:07:46,000 --> 00:07:50,560
system which is clearly stable and that

227
00:07:48,400 --> 00:07:52,160
implies that that this V will actually

228
00:07:50,560 --> 00:07:54,319
exponentially stabilize because it's

229
00:07:52,160 --> 00:07:56,000
positive definite you know that X will

230
00:07:54,319 --> 00:07:58,879
ultimately drive to your goal state or

231
00:07:56,000 --> 00:08:00,479
wherever that function V is zero right

232
00:07:58,879 --> 00:08:02,800
and so you have this theorem that if

233
00:08:00,479 --> 00:08:04,479
there exists a CLF meaning if you have

234
00:08:02,800 --> 00:08:06,800
inputs that satisfy this derivative

235
00:08:04,479 --> 00:08:10,400
condition you exponentially stabilize to

236
00:08:06,800 --> 00:08:12,000
the zero level set of V in this case

237
00:08:10,400 --> 00:08:14,160
this is like a periodic orbit on your

238
00:08:12,000 --> 00:08:15,599
walking robot right so there's this

239
00:08:14,160 --> 00:08:17,520
right nice connection that if you can

240
00:08:15,599 --> 00:08:20,080
find this V you get this now of course

241
00:08:17,520 --> 00:08:22,479
there's great work out of MIT SOS on how

242
00:08:20,080 --> 00:08:24,000
you can find V's in the case of robotic

243
00:08:22,479 --> 00:08:26,720
systems you can actually use feedback

244
00:08:24,000 --> 00:08:29,759
linearization to find these leoponol

245
00:08:26,720 --> 00:08:32,479
functions sort of uh algorithmically

246
00:08:29,759 --> 00:08:34,719
formulaically and the end result of this

247
00:08:32,479 --> 00:08:36,320
process is an entire class of

248
00:08:34,719 --> 00:08:38,000
controllers that stabilize a system for

249
00:08:36,320 --> 00:08:41,839
which this is an example implemented on

250
00:08:38,000 --> 00:08:43,519
on Cassie clean meaning this is CLF now

251
00:08:41,839 --> 00:08:44,880
this works I mean this really does work

252
00:08:43,519 --> 00:08:46,160
in practice Of course, there's a lot of

253
00:08:44,880 --> 00:08:47,519
caveats that I don't show in these

254
00:08:46,160 --> 00:08:49,279
videos. Things like state estimation

255
00:08:47,519 --> 00:08:51,279
took 9 months to really pin down

256
00:08:49,279 --> 00:08:52,720
properly. It's a big problem in in

257
00:08:51,279 --> 00:08:54,160
realizing this stuff on robots.

258
00:08:52,720 --> 00:08:57,519
Something that RL actually helps a lot

259
00:08:54,160 --> 00:09:00,399
with. Um, so the question is how do we

260
00:08:57,519 --> 00:09:03,200
take these ideas now and how do we

261
00:09:00,399 --> 00:09:04,800
extend them or or inform learning with

262
00:09:03,200 --> 00:09:07,200
the the methods for modelbased control

263
00:09:04,800 --> 00:09:08,880
that prove so effective. And so this is

264
00:09:07,200 --> 00:09:10,560
one example now that I showed earlier

265
00:09:08,880 --> 00:09:12,880
but I want to uh focus on it's a very

266
00:09:10,560 --> 00:09:16,880
recent result where we can take what we

267
00:09:12,880 --> 00:09:18,240
did with CLF QPS and instead of

268
00:09:16,880 --> 00:09:19,760
generating a quadratic program

269
00:09:18,240 --> 00:09:20,959
controller that we put online and have

270
00:09:19,760 --> 00:09:23,040
to worry about things like state

271
00:09:20,959 --> 00:09:25,120
estimation like I mentioned you take

272
00:09:23,040 --> 00:09:26,800
these nonlinear controllers and you use

273
00:09:25,120 --> 00:09:29,120
it to generate the reward function for

274
00:09:26,800 --> 00:09:31,760
RL. In this case, our reward function is

275
00:09:29,120 --> 00:09:33,920
a really clean four terms basically

276
00:09:31,760 --> 00:09:37,200
requiring that this is a CLF and that it

277
00:09:33,920 --> 00:09:38,720
decays as a CLF should decay.

278
00:09:37,200 --> 00:09:40,480
You use this in training and then you

279
00:09:38,720 --> 00:09:42,160
get to use all the benefits that RL

280
00:09:40,480 --> 00:09:44,240
gives you which modelbased methods sort

281
00:09:42,160 --> 00:09:46,000
of don't. You can GPU parallelize and

282
00:09:44,240 --> 00:09:48,160
then domain randomize. And so you can do

283
00:09:46,000 --> 00:09:52,399
this massive simulation to train up the

284
00:09:48,160 --> 00:09:54,640
R RL policy to basically emulate the

285
00:09:52,399 --> 00:09:55,920
modelbased controller. Of course, the

286
00:09:54,640 --> 00:09:58,080
advantage here is we're not emulating

287
00:09:55,920 --> 00:09:59,519
human data. something that might only be

288
00:09:58,080 --> 00:10:02,080
true on one trajectory, but we're

289
00:09:59,519 --> 00:10:03,760
emulating this this rich dynamics that's

290
00:10:02,080 --> 00:10:06,080
present in the real nonlinear dynamics

291
00:10:03,760 --> 00:10:08,160
of the system itself. And when we do

292
00:10:06,080 --> 00:10:10,000
this, we're actually able to deploy this

293
00:10:08,160 --> 00:10:11,279
in zerootshot, meaning once we train

294
00:10:10,000 --> 00:10:13,120
this up, it actually really does work

295
00:10:11,279 --> 00:10:15,200
off the shelf. I'm not I'm not being

296
00:10:13,120 --> 00:10:16,480
sort of facitious here. We're able to

297
00:10:15,200 --> 00:10:18,640
lay this out. And not only are we going

298
00:10:16,480 --> 00:10:20,000
to we're able to do things like put this

299
00:10:18,640 --> 00:10:22,000
on the robot and make it walk really

300
00:10:20,000 --> 00:10:23,760
cleanly all over Caltech. It never fell

301
00:10:22,000 --> 00:10:25,440
once in this whole filming. It walked

302
00:10:23,760 --> 00:10:27,040
all over Caltech, but we're able to

303
00:10:25,440 --> 00:10:29,839
extend it to other behaviors because the

304
00:10:27,040 --> 00:10:31,279
advantage of modelbased methods is they

305
00:10:29,839 --> 00:10:33,680
essentially have an infinite amount of

306
00:10:31,279 --> 00:10:35,440
data in them if you'd like. Right? If

307
00:10:33,680 --> 00:10:37,120
data is a bottleneck for for collecting

308
00:10:35,440 --> 00:10:39,040
human data from video demonstration,

309
00:10:37,120 --> 00:10:40,160
etc. Modelbased methods have an infinite

310
00:10:39,040 --> 00:10:42,399
amount of data. For every initial

311
00:10:40,160 --> 00:10:43,680
condition, you get a trajectory. Right?

312
00:10:42,399 --> 00:10:45,200
For every controller, you get a

313
00:10:43,680 --> 00:10:46,480
trajectory. Right? Now, you have to find

314
00:10:45,200 --> 00:10:48,399
them. That's the difference. But once

315
00:10:46,480 --> 00:10:50,720
you find them, you can do lots of really

316
00:10:48,399 --> 00:10:53,760
cool things. So, this is a recent result

317
00:10:50,720 --> 00:10:55,600
we had with CLFRL. now for running. So

318
00:10:53,760 --> 00:10:57,200
we generate same process. We generate

319
00:10:55,600 --> 00:10:59,600
from a hybrid system model. We generate

320
00:10:57,200 --> 00:11:01,920
a CLF. That CLF is used as the reward

321
00:10:59,600 --> 00:11:04,959
function in RL. We train this up and

322
00:11:01,920 --> 00:11:08,000
then deploy it. And we did this in about

323
00:11:04,959 --> 00:11:09,519
two weeks from start to finish. Um and

324
00:11:08,000 --> 00:11:10,800
it turns out the hardest part was

325
00:11:09,519 --> 00:11:12,480
actually the fact that we have visual

326
00:11:10,800 --> 00:11:14,399
odometry on the robot as well to get it

327
00:11:12,480 --> 00:11:16,000
to run straight. And that visual

328
00:11:14,399 --> 00:11:17,519
odometry with onboard compute and

329
00:11:16,000 --> 00:11:19,120
everything was kind of the trickiest

330
00:11:17,519 --> 00:11:20,480
part of this. Making a robot run is one

331
00:11:19,120 --> 00:11:21,839
thing. Making it run in a straight line

332
00:11:20,480 --> 00:11:23,680
is is another one. And it's actually

333
00:11:21,839 --> 00:11:24,880
pretty challenging. We took it outside.

334
00:11:23,680 --> 00:11:27,440
It worked the first time we took it

335
00:11:24,880 --> 00:11:28,560
outside, meaning off the bat. And we

336
00:11:27,440 --> 00:11:30,399
threw a bunch of stuff at it because

337
00:11:28,560 --> 00:11:32,480
that's what you do with robots, right?

338
00:11:30,399 --> 00:11:36,399
Disturbance testing. The point is these

339
00:11:32,480 --> 00:11:39,279
modelbased methods do fuse with RL.

340
00:11:36,399 --> 00:11:41,200
Well, in my opinion, and this is just

341
00:11:39,279 --> 00:11:43,279
one example of sort of the the kind of

342
00:11:41,200 --> 00:11:45,040
things I think we can do going forward

343
00:11:43,279 --> 00:11:47,440
to take away some of the hackery of

344
00:11:45,040 --> 00:11:49,120
reward shaping, right? To to bring some

345
00:11:47,440 --> 00:11:51,040
formal principles. There's of course a

346
00:11:49,120 --> 00:11:52,560
wealth of examples outside of my lab on

347
00:11:51,040 --> 00:11:56,800
people doing principled RL including

348
00:11:52,560 --> 00:11:58,880
many people here at at MIT. So,

349
00:11:56,800 --> 00:12:01,120
so that's the story. Of course, with

350
00:11:58,880 --> 00:12:03,440
this story comes a caveat. I started the

351
00:12:01,120 --> 00:12:04,959
the the talk talking about safety being

352
00:12:03,440 --> 00:12:06,639
a blocker and I haven't addressed this

353
00:12:04,959 --> 00:12:09,519
at all yet. Right? So, this is the robot

354
00:12:06,639 --> 00:12:12,079
now running outside doing pretty well

355
00:12:09,519 --> 00:12:13,839
and then of course

356
00:12:12,079 --> 00:12:16,320
we get a collision. Right? Thankfully,

357
00:12:13,839 --> 00:12:19,040
it was the the the the stick holding the

358
00:12:16,320 --> 00:12:20,560
camera. It wasn't a person, but this

359
00:12:19,040 --> 00:12:21,760
does not have barrier functions on it.

360
00:12:20,560 --> 00:12:23,279
Does not have collision avoidance,

361
00:12:21,760 --> 00:12:26,160
right? And this is what I mean by safety

362
00:12:23,279 --> 00:12:28,480
as a blocker, right? When when you hit

363
00:12:26,160 --> 00:12:29,680
scenarios you didn't expect, you're

364
00:12:28,480 --> 00:12:31,279
going to have really bad things happen.

365
00:12:29,680 --> 00:12:33,040
And the problem is if this happens in

366
00:12:31,279 --> 00:12:35,200
this scenario outside, it's it's kind of

367
00:12:33,040 --> 00:12:37,360
okay. If this happens in your house and

368
00:12:35,200 --> 00:12:38,880
your dog's around or, you know, you

369
00:12:37,360 --> 00:12:40,160
don't want these kind of behaviors. This

370
00:12:38,880 --> 00:12:42,560
is these these robots are actually

371
00:12:40,160 --> 00:12:44,079
really scary and and it's also painful.

372
00:12:42,560 --> 00:12:46,720
I don't know if you can see my face up

373
00:12:44,079 --> 00:12:48,160
there, but I'm kind of cringing. I I

374
00:12:46,720 --> 00:12:50,480
thought we killed the robot there. I

375
00:12:48,160 --> 00:12:51,839
really did. Um, so again, I go back to

376
00:12:50,480 --> 00:12:54,639
this question. How do we guarantee

377
00:12:51,839 --> 00:12:56,560
safety for these systems? Right. So, I

378
00:12:54,639 --> 00:12:58,399
want to step back for a second now and

379
00:12:56,560 --> 00:12:59,680
and do a little history because I think

380
00:12:58,399 --> 00:13:01,440
history is important. I think especially

381
00:12:59,680 --> 00:13:03,519
in this day and age when there's so much

382
00:13:01,440 --> 00:13:05,680
stuff on the archive every day. We

383
00:13:03,519 --> 00:13:08,240
forget sometimes that no one lives in

384
00:13:05,680 --> 00:13:10,160
isolation. No idea comes from nothing.

385
00:13:08,240 --> 00:13:12,800
Um, there's a great quote from asthma

386
00:13:10,160 --> 00:13:15,360
there on exactly this topic. And so

387
00:13:12,800 --> 00:13:17,760
people have studied safety for a long

388
00:13:15,360 --> 00:13:20,240
time and it goes back to actually

389
00:13:17,760 --> 00:13:23,920
earlier than 1942. But Numu's theorem in

390
00:13:20,240 --> 00:13:27,040
1942 is really the de facto standard on

391
00:13:23,920 --> 00:13:28,880
safety. And what it says is that if you

392
00:13:27,040 --> 00:13:29,839
frame safety as forward set invariance,

393
00:13:28,880 --> 00:13:30,880
which is what I'm going to do throughout

394
00:13:29,839 --> 00:13:31,839
this talk. We can talk about that.

395
00:13:30,880 --> 00:13:34,639
There's lots of other interesting

396
00:13:31,839 --> 00:13:36,079
notions of safety uh safety on latent

397
00:13:34,639 --> 00:13:36,880
variables, semantic safety. There's a

398
00:13:36,079 --> 00:13:38,160
whole bunch of things you can think

399
00:13:36,880 --> 00:13:40,079
about. But in this case, starting

400
00:13:38,160 --> 00:13:41,760
simple, we want to make sure we don't go

401
00:13:40,079 --> 00:13:43,920
to bad states and we want to stay in

402
00:13:41,760 --> 00:13:46,320
good states. And in that case, it turns

403
00:13:43,920 --> 00:13:48,160
out that back in 1942,

404
00:13:46,320 --> 00:13:49,519
Nugumu figured out necessary and

405
00:13:48,160 --> 00:13:51,440
sufficient conditions for forward set

406
00:13:49,519 --> 00:13:52,959
invariance. And it's a very simple

407
00:13:51,440 --> 00:13:54,800
condition. If your function, if you have

408
00:13:52,959 --> 00:13:56,160
a function h that defines your safe set,

409
00:13:54,800 --> 00:13:58,320
it's positive on your safe set and

410
00:13:56,160 --> 00:13:59,920
negative outside, then the condition is

411
00:13:58,320 --> 00:14:02,160
simply that h dot must be greater than

412
00:13:59,920 --> 00:14:04,079
or equal to zero on the boundary of your

413
00:14:02,160 --> 00:14:06,079
safe set, right? Which makes total

414
00:14:04,079 --> 00:14:08,240
sense. meaning h dot the derivative

415
00:14:06,079 --> 00:14:10,000
along flows of your system, right? Which

416
00:14:08,240 --> 00:14:11,920
says if you're on the boundary and if h

417
00:14:10,000 --> 00:14:13,839
needs to be positive to stay in the set,

418
00:14:11,920 --> 00:14:16,160
your rate of change better be positive

419
00:14:13,839 --> 00:14:18,160
or at worst zero or it will go negative

420
00:14:16,160 --> 00:14:19,760
and you will leave your set, right? So

421
00:14:18,160 --> 00:14:21,120
it's very intuitive. Of course, proving

422
00:14:19,760 --> 00:14:23,360
it requires a little bit more, but it's

423
00:14:21,120 --> 00:14:25,760
very intuitive. People have used this

424
00:14:23,360 --> 00:14:29,120
conditions many many times in the last

425
00:14:25,760 --> 00:14:30,880
sort of you know 80 years, right? and

426
00:14:29,120 --> 00:14:34,399
it's actually been rediscovered on many

427
00:14:30,880 --> 00:14:36,079
occasions um including I won't say

428
00:14:34,399 --> 00:14:38,160
rediscovered recently but used recently

429
00:14:36,079 --> 00:14:39,839
in things like barrier certificates etc

430
00:14:38,160 --> 00:14:43,279
right so this was the state-of-the-art

431
00:14:39,839 --> 00:14:44,880
when I approached safety in 2014 of

432
00:14:43,279 --> 00:14:47,199
course there's something fundamentally

433
00:14:44,880 --> 00:14:50,560
missing about this picture if you want

434
00:14:47,199 --> 00:14:52,560
to do controller synthesis

435
00:14:50,560 --> 00:14:56,480
what do you do with a condition that's

436
00:14:52,560 --> 00:14:59,360
only true on the boundary of your set

437
00:14:56,480 --> 00:15:01,360
right

438
00:14:59,360 --> 00:15:02,720
Well, yeah. So, the the answer is if I

439
00:15:01,360 --> 00:15:04,160
have this condition on the boundary, I'm

440
00:15:02,720 --> 00:15:05,199
going to wait until I hit the boundary.

441
00:15:04,160 --> 00:15:06,880
Then I'm going to see if that condition

442
00:15:05,199 --> 00:15:08,480
is satisfied or not. And if not, I'm

443
00:15:06,880 --> 00:15:09,839
going to switch to another controller,

444
00:15:08,480 --> 00:15:11,760
right? But the question is when do you

445
00:15:09,839 --> 00:15:14,959
switch? And when you switch, is it

446
00:15:11,760 --> 00:15:16,880
continuous? Is it smooth? Do you do you

447
00:15:14,959 --> 00:15:18,320
maybe add some buffers in here so that

448
00:15:16,880 --> 00:15:19,920
you start switching a little early? Then

449
00:15:18,320 --> 00:15:21,120
how early do you switch? How does that

450
00:15:19,920 --> 00:15:23,279
matter? Right? You can see how you get

451
00:15:21,120 --> 00:15:24,639
to a rabbit hole very quickly. So, I

452
00:15:23,279 --> 00:15:26,079
wanted to ask the simple question, well,

453
00:15:24,639 --> 00:15:27,360
we shouldn't do that. we should just

454
00:15:26,079 --> 00:15:29,279
have a condition that's true at every

455
00:15:27,360 --> 00:15:30,399
point in the set then we don't have to

456
00:15:29,279 --> 00:15:32,320
worry about waiting to get to the

457
00:15:30,399 --> 00:15:34,560
boundary right so how do we find that

458
00:15:32,320 --> 00:15:37,120
condition and it turns out that the

459
00:15:34,560 --> 00:15:38,800
ginshin is very so again what control

460
00:15:37,120 --> 00:15:41,440
option we take the condition is actually

461
00:15:38,800 --> 00:15:43,920
very intuitive so the generalization is

462
00:15:41,440 --> 00:15:46,639
quite simple we take numu's condition

463
00:15:43,920 --> 00:15:48,639
and we just replace zero with minus

464
00:15:46,639 --> 00:15:51,279
alpha class k function but think about

465
00:15:48,639 --> 00:15:53,680
it as a as a as a constant if you want

466
00:15:51,279 --> 00:15:55,920
of h right then of course on the

467
00:15:53,680 --> 00:15:57,759
boundary you recover nuru theorem,

468
00:15:55,920 --> 00:15:59,040
right? When h is zero, this says h dot

469
00:15:57,759 --> 00:16:01,680
has to be greater than or equal to zero.

470
00:15:59,040 --> 00:16:03,440
But inside the set, what does it say? It

471
00:16:01,680 --> 00:16:05,120
says that h dot when you're inside the

472
00:16:03,440 --> 00:16:07,279
set, h can be positive. So this whole

473
00:16:05,120 --> 00:16:10,160
thing becomes negative. So h dot can

474
00:16:07,279 --> 00:16:11,759
decrease. So you can decrease h dot away

475
00:16:10,160 --> 00:16:13,839
and as you get closer, you have to sort

476
00:16:11,759 --> 00:16:15,120
of slow down. Now the question is does

477
00:16:13,839 --> 00:16:17,199
that give you the right behavior?

478
00:16:15,120 --> 00:16:19,519
Meaning do you slow down enough? Do you

479
00:16:17,199 --> 00:16:21,279
slow down too much? Right? It turns out

480
00:16:19,519 --> 00:16:22,480
that you slow down just the right amount

481
00:16:21,279 --> 00:16:24,720
meaning that this is necessary and

482
00:16:22,480 --> 00:16:26,560
sufficient for forward set invariance as

483
00:16:24,720 --> 00:16:29,120
laid out by these papers with me and

484
00:16:26,560 --> 00:16:31,680
Paulo Tabatada Jesse Grizzle etc. So

485
00:16:29,120 --> 00:16:33,839
this is what is now called modern-day

486
00:16:31,680 --> 00:16:35,839
control barrier functions, right? And

487
00:16:33,839 --> 00:16:38,320
they're surprisingly only about a decade

488
00:16:35,839 --> 00:16:40,240
old now. So what do we do with this? So

489
00:16:38,320 --> 00:16:41,920
once we have these conditions, we can

490
00:16:40,240 --> 00:16:43,360
use them for controller synthesis. But I

491
00:16:41,920 --> 00:16:45,040
want to note one thing going back to

492
00:16:43,360 --> 00:16:47,199
leaponov. It turns out that barrier

493
00:16:45,040 --> 00:16:48,720
functions actually generalize leoponov.

494
00:16:47,199 --> 00:16:50,160
If you take your set and you contract it

495
00:16:48,720 --> 00:16:52,000
to a point, you end up with a leoponov

496
00:16:50,160 --> 00:16:54,959
function. But in general, barrier

497
00:16:52,000 --> 00:16:56,560
functions are cover a bigger class of

498
00:16:54,959 --> 00:16:57,759
behaviors because they don't have to

499
00:16:56,560 --> 00:16:59,759
actually be positive definite

500
00:16:57,759 --> 00:17:01,360
themselves. They only sort of have to be

501
00:16:59,759 --> 00:17:04,640
positive definite with respect to the

502
00:17:01,360 --> 00:17:06,160
set outside the set. So that opens up

503
00:17:04,640 --> 00:17:08,319
additional behaviors meaning inside the

504
00:17:06,160 --> 00:17:09,919
set you can move around freely. So again

505
00:17:08,319 --> 00:17:11,679
once we have these CBFS what do we do

506
00:17:09,919 --> 00:17:13,039
with them? And then the answer I think

507
00:17:11,679 --> 00:17:14,319
the second sort of big thing that

508
00:17:13,039 --> 00:17:16,959
happened in the last decade was this

509
00:17:14,319 --> 00:17:19,600
idea of a safety filter. And this idea

510
00:17:16,959 --> 00:17:21,120
came about because

511
00:17:19,600 --> 00:17:23,360
actually we're given these challenge

512
00:17:21,120 --> 00:17:25,199
problems where we were told actively we

513
00:17:23,360 --> 00:17:27,360
could not modify the nominal controller

514
00:17:25,199 --> 00:17:29,520
on the system which as a control

515
00:17:27,360 --> 00:17:32,160
theorist is like the hardest thing in

516
00:17:29,520 --> 00:17:34,320
the world to hear. So we were sitting at

517
00:17:32,160 --> 00:17:36,400
a table with Ford and Toyota and we're

518
00:17:34,320 --> 00:17:38,080
presenting a bunch of CLF work and we're

519
00:17:36,400 --> 00:17:41,039
like we'd love to get these CLFs cuz I

520
00:17:38,080 --> 00:17:43,440
love CLFs on a car and they looked at me

521
00:17:41,039 --> 00:17:45,600
and they said that will never happen

522
00:17:43,440 --> 00:17:46,880
right? Why? Well, because we know what

523
00:17:45,600 --> 00:17:47,919
works on the car right now and we don't

524
00:17:46,880 --> 00:17:49,360
want to change something that works,

525
00:17:47,919 --> 00:17:52,000
right? If it ain't broke, don't fix it,

526
00:17:49,360 --> 00:17:53,360
as they say. So, but they said, if you

527
00:17:52,000 --> 00:17:54,400
can come up with a control method that

528
00:17:53,360 --> 00:17:56,880
lives outside of our current

529
00:17:54,400 --> 00:17:58,640
infrastructure, we'd be interested. And

530
00:17:56,880 --> 00:18:00,640
that's exactly what these safety filters

531
00:17:58,640 --> 00:18:03,280
do. They take any nominal controller,

532
00:18:00,640 --> 00:18:05,120
find the minimal modification

533
00:18:03,280 --> 00:18:06,400
subject to the safety constraint. So, of

534
00:18:05,120 --> 00:18:08,000
course, this gives you kind of a switch

535
00:18:06,400 --> 00:18:09,520
controller in essence. It's it's lip

536
00:18:08,000 --> 00:18:10,960
shit's continuous and smooth in some

537
00:18:09,520 --> 00:18:12,240
scenarios that says that if your

538
00:18:10,960 --> 00:18:13,919
controller is safe, you let it pass

539
00:18:12,240 --> 00:18:15,679
through and if it's not safe, you need

540
00:18:13,919 --> 00:18:17,919
to minimally modify it projected to the

541
00:18:15,679 --> 00:18:19,679
safe set, right? And this is an example

542
00:18:17,919 --> 00:18:21,280
of that in action. So on the left you

543
00:18:19,679 --> 00:18:23,039
have the nominal controller, which is

544
00:18:21,280 --> 00:18:24,559
actually a really well-tuned segway

545
00:18:23,039 --> 00:18:26,720
controller. And then of course my

546
00:18:24,559 --> 00:18:28,720
student in this im in this video is just

547
00:18:26,720 --> 00:18:30,960
joysticking it, trying to mess it up,

548
00:18:28,720 --> 00:18:32,799
and he can both make it go outside of

549
00:18:30,960 --> 00:18:35,039
that yellow region and knock the whole

550
00:18:32,799 --> 00:18:36,640
thing over. Right. Of course. Now on the

551
00:18:35,039 --> 00:18:38,320
right, you pass that exact same signal

552
00:18:36,640 --> 00:18:40,160
through a safety filter and no matter

553
00:18:38,320 --> 00:18:42,400
what he does, he can't knock it over get

554
00:18:40,160 --> 00:18:44,400
or leave the set. Of course, we've

555
00:18:42,400 --> 00:18:46,080
deployed this in lots of scenarios.

556
00:18:44,400 --> 00:18:47,679
We've done obstacle avoidance. So, in

557
00:18:46,080 --> 00:18:49,280
this case, you have a human pilot who's

558
00:18:47,679 --> 00:18:52,400
trying to crash the drone into into

559
00:18:49,280 --> 00:18:54,160
walls and they can't do it. Um, I should

560
00:18:52,400 --> 00:18:56,000
also note this generalizes potential

561
00:18:54,160 --> 00:18:57,600
fields, meaning you you actually get

562
00:18:56,000 --> 00:19:00,240
some improved behavior over potential

563
00:18:57,600 --> 00:19:02,080
fields. Uh, we've done it for multi-root

564
00:19:00,240 --> 00:19:03,760
systems. This was with Magnus Aggerstat.

565
00:19:02,080 --> 00:19:05,840
Um, this was actually some of the first

566
00:19:03,760 --> 00:19:07,840
experiments with CBFS ever. I was at

567
00:19:05,840 --> 00:19:09,679
Georgia Tech at the time and we put it

568
00:19:07,840 --> 00:19:12,480
on multi-root systems for collision

569
00:19:09,679 --> 00:19:14,160
avoidance. Uh, so in this case, the grad

570
00:19:12,480 --> 00:19:16,160
student again is flying this drone and

571
00:19:14,160 --> 00:19:19,520
trying to crash it through this this

572
00:19:16,160 --> 00:19:21,919
swarm of robots and you get this kind of

573
00:19:19,520 --> 00:19:24,080
virtual force field type behavior from

574
00:19:21,919 --> 00:19:26,320
the CBFS.

575
00:19:24,080 --> 00:19:30,000
So that's fun. And then we also put it

576
00:19:26,320 --> 00:19:31,600
on really compute inensive uh scenarios.

577
00:19:30,000 --> 00:19:35,600
So in this case, we have a high-speed

578
00:19:31,600 --> 00:19:37,919
racing drone and we're we're doing CBFS

579
00:19:35,600 --> 00:19:41,280
only on a very small bit of compute on

580
00:19:37,919 --> 00:19:43,200
this with onboard uh onboard sensing. So

581
00:19:41,280 --> 00:19:45,280
everything is self-contained and we're

582
00:19:43,200 --> 00:19:47,280
doing geoences. So in this case, you

583
00:19:45,280 --> 00:19:50,400
have these regions in space you can't

584
00:19:47,280 --> 00:19:52,000
leave and the the the student in this

585
00:19:50,400 --> 00:19:53,760
case is flying this thing as quick as it

586
00:19:52,000 --> 00:19:55,840
can towards these geoences and the the

587
00:19:53,760 --> 00:19:58,559
CBF prevents them from leaving the the

588
00:19:55,840 --> 00:20:00,559
the area. Right?

589
00:19:58,559 --> 00:20:01,919
this same math. And the reason I'm

590
00:20:00,559 --> 00:20:03,200
showing all these videos is once you

591
00:20:01,919 --> 00:20:04,799
have the math, everything just kind of

592
00:20:03,200 --> 00:20:07,440
follows, right? It's like a cascade

593
00:20:04,799 --> 00:20:10,160
effect. It's a waterfall effect because

594
00:20:07,440 --> 00:20:13,760
this same exact method we used on this

595
00:20:10,160 --> 00:20:16,559
we put on an actual jet aircraft. So,

596
00:20:13,760 --> 00:20:19,520
this is an F-16. This is the Vista uh

597
00:20:16,559 --> 00:20:21,200
F-16. And here we're doing geo fencing.

598
00:20:19,520 --> 00:20:23,520
So, there's a region in space you don't

599
00:20:21,200 --> 00:20:25,760
want to go. And at this moment in time

600
00:20:23,520 --> 00:20:28,480
right here, CBFs are actually flying the

601
00:20:25,760 --> 00:20:30,640
plane. So we're we're doing safety

602
00:20:28,480 --> 00:20:33,200
filtering of the pilot commands to

603
00:20:30,640 --> 00:20:36,240
guarantee that we don't leave the region

604
00:20:33,200 --> 00:20:38,559
and we're satisfying altitude floors and

605
00:20:36,240 --> 00:20:41,840
ceilings simultaneously and we're we're

606
00:20:38,559 --> 00:20:43,520
satisfying um G limit constraints among

607
00:20:41,840 --> 00:20:46,799
other things. So making sure we don't

608
00:20:43,520 --> 00:20:50,159
have too much uh force on the pilot. So

609
00:20:46,799 --> 00:20:51,600
we do can do all that together uh with a

610
00:20:50,159 --> 00:20:55,280
single actually in this case a single

611
00:20:51,600 --> 00:20:56,880
CBF that filters the pilot inputs. So

612
00:20:55,280 --> 00:21:00,159
there's no doubt that these things apply

613
00:20:56,880 --> 00:21:01,760
really generally. Um this led us to a

614
00:21:00,159 --> 00:21:03,360
lot of questions though. For example,

615
00:21:01,760 --> 00:21:06,320
one question that we started getting

616
00:21:03,360 --> 00:21:07,919
asked a lot was what about uncertainty,

617
00:21:06,320 --> 00:21:10,000
right? What do you do? Well, we have a

618
00:21:07,919 --> 00:21:12,320
whole set of results on input to state

619
00:21:10,000 --> 00:21:14,159
stability and input to state safety with

620
00:21:12,320 --> 00:21:15,520
respect to CBFS meaning if you have some

621
00:21:14,159 --> 00:21:17,600
bounded uncertainty, you can actually

622
00:21:15,520 --> 00:21:19,520
still guarantee safety. But we we

623
00:21:17,600 --> 00:21:21,120
realized very quickly that boundary

624
00:21:19,520 --> 00:21:23,520
uncertainty is fantastic, but we can

625
00:21:21,120 --> 00:21:26,960
actually extend this to unbounded

626
00:21:23,520 --> 00:21:29,360
disturbances if they're stochastic

627
00:21:26,960 --> 00:21:31,360
uh using stochastic CBFS. So in this

628
00:21:29,360 --> 00:21:32,799
case, we we switch to discrete time

629
00:21:31,360 --> 00:21:35,840
dynamical systems for which there's a

630
00:21:32,799 --> 00:21:38,400
discrete time CBF condition and we have

631
00:21:35,840 --> 00:21:40,320
a theorem that says that if you satisfy

632
00:21:38,400 --> 00:21:42,559
this condition in expectation, you're

633
00:21:40,320 --> 00:21:44,240
guaranteed to be safety uh to be

634
00:21:42,559 --> 00:21:46,000
guaranteed to be safe in probability.

635
00:21:44,240 --> 00:21:47,520
Meaning you can know that you have some

636
00:21:46,000 --> 00:21:50,559
probability of staying within your safe

637
00:21:47,520 --> 00:21:53,280
set for a finite number of steps and we

638
00:21:50,559 --> 00:21:56,559
can get an upper bound to that. Uh and

639
00:21:53,280 --> 00:21:58,880
we can use that to explicitly calculate

640
00:21:56,559 --> 00:22:01,039
the sa the safety filter in a stochastic

641
00:21:58,880 --> 00:22:03,360
setting. We can collect data. We can

642
00:22:01,039 --> 00:22:05,520
sort of learn the distribution and then

643
00:22:03,360 --> 00:22:07,280
from that get conditions we can actually

644
00:22:05,520 --> 00:22:09,120
implement in the safety filter. And so

645
00:22:07,280 --> 00:22:11,840
we do this in particular in the context

646
00:22:09,120 --> 00:22:13,840
of a drone with an unknown hanging mass.

647
00:22:11,840 --> 00:22:15,440
And if you've ever flown a drone and put

648
00:22:13,840 --> 00:22:17,679
a hanging mass, you know it's a very

649
00:22:15,440 --> 00:22:18,799
hard problem to keep that drone flying.

650
00:22:17,679 --> 00:22:20,960
And we did it in the context of

651
00:22:18,799 --> 00:22:24,400
geofencing. So in this case, the

652
00:22:20,960 --> 00:22:26,880
students trying to fl uh to slam the the

653
00:22:24,400 --> 00:22:30,000
drone into the ground. And the

654
00:22:26,880 --> 00:22:32,320
stochastic uh safety filter is making

655
00:22:30,000 --> 00:22:34,960
sure that that doesn't happen based on

656
00:22:32,320 --> 00:22:36,559
the data we collected. And the in this

657
00:22:34,960 --> 00:22:38,720
case in particular we updated the

658
00:22:36,559 --> 00:22:40,240
reduced order model to account for that

659
00:22:38,720 --> 00:22:42,960
learned

660
00:22:40,240 --> 00:22:45,600
uh element. So we can extend it to these

661
00:22:42,960 --> 00:22:47,440
uncertainty situations. Um this is one

662
00:22:45,600 --> 00:22:50,080
where we then take that idea and fold it

663
00:22:47,440 --> 00:22:52,080
into perception in the loop. So now

664
00:22:50,080 --> 00:22:54,640
we're doing onboard perception. So you

665
00:22:52,080 --> 00:22:56,559
can see the viewpoint of the drone and

666
00:22:54,640 --> 00:22:58,640
there's balls coming at it and it has to

667
00:22:56,559 --> 00:23:00,559
avoid it. Again, same framework as I

668
00:22:58,640 --> 00:23:02,480
implemented before or I discussed before

669
00:23:00,559 --> 00:23:03,840
but now we're doing this with perception

670
00:23:02,480 --> 00:23:05,200
in the loop.

671
00:23:03,840 --> 00:23:06,960
And here's another example with

672
00:23:05,200 --> 00:23:09,840
perception in the loop, but now we do it

673
00:23:06,960 --> 00:23:12,480
to a quadriped. So the lesson here again

674
00:23:09,840 --> 00:23:14,880
is we first had CBFS and now we have CBS

675
00:23:12,480 --> 00:23:16,720
with stochastic uncertainty for example

676
00:23:14,880 --> 00:23:18,640
due to model uncertainty, perception

677
00:23:16,720 --> 00:23:22,799
uncertainty and we can fold all that

678
00:23:18,640 --> 00:23:24,960
together in a stochastic framework. So

679
00:23:22,799 --> 00:23:27,679
in doing this we realized a couple

680
00:23:24,960 --> 00:23:30,000
things. First, we realized if we just do

681
00:23:27,679 --> 00:23:32,400
a safety filter like I talked about

682
00:23:30,000 --> 00:23:34,720
before, it's not as expressive as you

683
00:23:32,400 --> 00:23:36,159
might hope because there are because

684
00:23:34,720 --> 00:23:37,440
remember safety filters are sort of

685
00:23:36,159 --> 00:23:40,960
pointwise optimal, but they're not

686
00:23:37,440 --> 00:23:44,080
globally optimal, right? So, if you if

687
00:23:40,960 --> 00:23:45,840
you do MPC without a safety filter, you

688
00:23:44,080 --> 00:23:48,080
find kind of the inverse. It's

689
00:23:45,840 --> 00:23:50,480
expressive. So in this case the the

690
00:23:48,080 --> 00:23:52,000
quadriped tries to avoid the ball but

691
00:23:50,480 --> 00:23:53,679
because you're doing just a state

692
00:23:52,000 --> 00:23:55,200
constraint you don't have enough

693
00:23:53,679 --> 00:23:57,919
predictive power at that state

694
00:23:55,200 --> 00:23:59,679
constraint level. So doing a bunch of

695
00:23:57,919 --> 00:24:02,799
experiments in this space we discovered

696
00:23:59,679 --> 00:24:04,960
that MPC plus CBFS is a really powerful

697
00:24:02,799 --> 00:24:07,120
paradigm.

698
00:24:04,960 --> 00:24:08,480
So everything I presented previously was

699
00:24:07,120 --> 00:24:09,600
if you have this one layer control

700
00:24:08,480 --> 00:24:13,120
architecture and now we're going to

701
00:24:09,600 --> 00:24:14,880
bring multiple layers together. Okay. So

702
00:24:13,120 --> 00:24:16,400
let's see how that kind of works. So, by

703
00:24:14,880 --> 00:24:17,760
the way, this is a video I just took in

704
00:24:16,400 --> 00:24:20,159
my lab the other day. I went down to the

705
00:24:17,760 --> 00:24:21,760
lab and the robot was on. This was not

706
00:24:20,159 --> 00:24:22,880
pre-planned. We're not trying to do

707
00:24:21,760 --> 00:24:24,159
anything fancy here. And I think

708
00:24:22,880 --> 00:24:26,080
sometimes just showing the raw

709
00:24:24,159 --> 00:24:27,440
experiments really give you a sense of

710
00:24:26,080 --> 00:24:31,120
what these algorithms actually look

711
00:24:27,440 --> 00:24:33,120
like. So, it's

712
00:24:31,120 --> 00:24:35,840
by putting all these pieces together,

713
00:24:33,120 --> 00:24:37,679
doing MPC plus CBFS, we're we're

714
00:24:35,840 --> 00:24:40,960
starting to get into a very strange

715
00:24:37,679 --> 00:24:42,880
uncanny valley now, right?

716
00:24:40,960 --> 00:24:44,559
It starts to like pe now when we do lab

717
00:24:42,880 --> 00:24:47,120
tours, people actually start to feel

718
00:24:44,559 --> 00:24:48,720
sorry for the robot. They think it's

719
00:24:47,120 --> 00:24:49,919
it's getting its feelings hurt and they

720
00:24:48,720 --> 00:24:51,600
want to pet it. I'm not kidding you.

721
00:24:49,919 --> 00:24:53,440
Which is weird because previously they

722
00:24:51,600 --> 00:24:54,880
would always be scared of the robot,

723
00:24:53,440 --> 00:24:56,080
right? And if you can make people feel

724
00:24:54,880 --> 00:24:57,760
sorry for a robot, you're actually, I

725
00:24:56,080 --> 00:25:00,159
think, doing your job well because

726
00:24:57,760 --> 00:25:01,279
they're no longer scary, right? Uh so

727
00:25:00,159 --> 00:25:03,360
we're starting to see this real

728
00:25:01,279 --> 00:25:04,880
improvement. And this this actually

729
00:25:03,360 --> 00:25:06,159
hurts back to work that we did a long

730
00:25:04,880 --> 00:25:07,600
time ago. So we've been doing this for

731
00:25:06,159 --> 00:25:09,520
many years where we saw that when we

732
00:25:07,600 --> 00:25:11,520
layer these things together, we get

733
00:25:09,520 --> 00:25:13,840
better behavior, we get improved

734
00:25:11,520 --> 00:25:15,440
performance. So this goes to the second

735
00:25:13,840 --> 00:25:17,440
thread that I've sort of been on in the

736
00:25:15,440 --> 00:25:19,360
last 5 years in my lab, which is this

737
00:25:17,440 --> 00:25:21,679
notion of layered control architectures.

738
00:25:19,360 --> 00:25:23,440
So Giola and me both have done many

739
00:25:21,679 --> 00:25:25,440
workshops now on this, talking about how

740
00:25:23,440 --> 00:25:27,120
this is a really important secret sauce

741
00:25:25,440 --> 00:25:29,200
um to making robots work, and it really

742
00:25:27,120 --> 00:25:31,120
is. I want to show an example of this.

743
00:25:29,200 --> 00:25:32,880
There's no barrier functions here. This

744
00:25:31,120 --> 00:25:35,039
is an MPC together with a really good

745
00:25:32,880 --> 00:25:37,279
controller. And to me, this is this is

746
00:25:35,039 --> 00:25:40,159
one of my students, null, did this. This

747
00:25:37,279 --> 00:25:41,760
is just really good control.

748
00:25:40,159 --> 00:25:44,320
I mean, this is he's doing a geometric

749
00:25:41,760 --> 00:25:45,440
NPC layer on top of it. But this is my

750
00:25:44,320 --> 00:25:48,320
favorite video. One of my favorite

751
00:25:45,440 --> 00:25:50,880
videos of all time from the lab. This is

752
00:25:48,320 --> 00:25:54,320
a custom hopping robot that he makes hop

753
00:25:50,880 --> 00:25:57,039
literally across this plank.

754
00:25:54,320 --> 00:25:59,919
That is precise control to hop along a

755
00:25:57,039 --> 00:26:02,799
plank that's this big. Right? And again,

756
00:25:59,919 --> 00:26:05,120
what enabled this precise control?

757
00:26:02,799 --> 00:26:07,120
layered control architectures, right? So

758
00:26:05,120 --> 00:26:08,159
understanding, so I started with CBFS

759
00:26:07,120 --> 00:26:09,440
and then we started doing this and

760
00:26:08,159 --> 00:26:11,440
realizing that there's something really

761
00:26:09,440 --> 00:26:12,640
special here because once you have these

762
00:26:11,440 --> 00:26:13,919
layered architectures, they they're

763
00:26:12,640 --> 00:26:16,000
actually really robust. You can take the

764
00:26:13,919 --> 00:26:19,200
robot outside, can hop in lots of

765
00:26:16,000 --> 00:26:21,440
scenarios. Um, this is the cannon you

766
00:26:19,200 --> 00:26:24,159
guys stole. I put this video in because

767
00:26:21,440 --> 00:26:27,120
anybody know the story. MIT stole that

768
00:26:24,159 --> 00:26:29,039
cannon from Caltech. They dressed up as

769
00:26:27,120 --> 00:26:30,480
security guards and then they came on

770
00:26:29,039 --> 00:26:31,919
Caltech campus, stole the cannon and

771
00:26:30,480 --> 00:26:34,159
they reassembled it on top of one of the

772
00:26:31,919 --> 00:26:36,880
buildings here. Yeah. Okay. So, that was

773
00:26:34,159 --> 00:26:38,480
the cannon. We got it back though. I

774
00:26:36,880 --> 00:26:40,880
don't know how, but we got it back. So,

775
00:26:38,480 --> 00:26:42,559
it's still there. All right. And so, we

776
00:26:40,880 --> 00:26:44,400
can also start to do some interesting

777
00:26:42,559 --> 00:26:46,159
things like add safety layers back in.

778
00:26:44,400 --> 00:26:48,400
But now, we can do safety not at this

779
00:26:46,159 --> 00:26:50,159
low-level control, but actually at a

780
00:26:48,400 --> 00:26:53,600
higher level using simple reduced order

781
00:26:50,159 --> 00:26:55,120
mocks. Right? So what I mean is we can

782
00:26:53,600 --> 00:26:56,559
start with really good controllers and

783
00:26:55,120 --> 00:26:58,159
in this case we're doing a safety layer

784
00:26:56,559 --> 00:27:00,240
on top of them because this is a

785
00:26:58,159 --> 00:27:02,480
complicated controller that has multiple

786
00:27:00,240 --> 00:27:04,000
agent interaction with a fixed thing. So

787
00:27:02,480 --> 00:27:05,440
it's a really hard control problem but

788
00:27:04,000 --> 00:27:06,880
we can just add the safety layer on top

789
00:27:05,440 --> 00:27:09,279
of it and get the whole thing to be safe

790
00:27:06,880 --> 00:27:12,080
kind of out of the box.

791
00:27:09,279 --> 00:27:13,600
So So what's happening here? Well, I'm

792
00:27:12,080 --> 00:27:15,760
going to give you guys the secret sauce

793
00:27:13,600 --> 00:27:17,760
to implementing CBFS on hardware if

794
00:27:15,760 --> 00:27:20,320
you're interested. And it's it's exactly

795
00:27:17,760 --> 00:27:21,919
this layered control. So I showed you

796
00:27:20,320 --> 00:27:24,080
nonlinear dynamics earlier and that's a

797
00:27:21,919 --> 00:27:25,520
lot of fun. But let's step back for a

798
00:27:24,080 --> 00:27:27,679
second and just say let's suppose we

799
00:27:25,520 --> 00:27:29,120
have some reduced order model and then

800
00:27:27,679 --> 00:27:30,320
we want to put a safety filter on that

801
00:27:29,120 --> 00:27:32,320
reduced order model and that's going to

802
00:27:30,320 --> 00:27:34,799
feed into some full order dynamics. This

803
00:27:32,320 --> 00:27:36,320
full order dynamic model is being run by

804
00:27:34,799 --> 00:27:38,159
some controller that tracks that

805
00:27:36,320 --> 00:27:40,799
reference. We don't care what this is.

806
00:27:38,159 --> 00:27:43,039
This can be a policy, an RL policy. This

807
00:27:40,799 --> 00:27:44,480
can be a VA. I don't really care. All I

808
00:27:43,039 --> 00:27:46,960
know is that whatever it is, I needs to

809
00:27:44,480 --> 00:27:48,320
take velocity as a reference. That's it.

810
00:27:46,960 --> 00:27:49,840
And then I'm going to have my own

811
00:27:48,320 --> 00:27:51,919
controller sitting up there, my own

812
00:27:49,840 --> 00:27:53,760
internal reduced order model that I'm

813
00:27:51,919 --> 00:27:55,440
going to use for the safety filter. So

814
00:27:53,760 --> 00:27:58,159
think about it like this. Every element

815
00:27:55,440 --> 00:28:00,480
of an autonomy stack has its own model.

816
00:27:58,159 --> 00:28:01,919
If it's RL, that model was a simulator.

817
00:28:00,480 --> 00:28:03,679
If it's a safety filter, you're probably

818
00:28:01,919 --> 00:28:06,640
going to have some simple sort of maybe

819
00:28:03,679 --> 00:28:09,679
kinematic model. And in this scenario,

820
00:28:06,640 --> 00:28:11,760
you can formally guarantee safety

821
00:28:09,679 --> 00:28:13,919
without knowing what's happening down

822
00:28:11,760 --> 00:28:15,760
here.

823
00:28:13,919 --> 00:28:17,679
What I mean and this is the theorem is

824
00:28:15,760 --> 00:28:21,200
that if you have sufficiently good

825
00:28:17,679 --> 00:28:23,360
tracking, so that's what's up here. If

826
00:28:21,200 --> 00:28:25,200
you have in this case exponential

827
00:28:23,360 --> 00:28:27,120
tracking

828
00:28:25,200 --> 00:28:29,440
uh of this reduced order of this full

829
00:28:27,120 --> 00:28:31,200
order model, oops, too many slides. If

830
00:28:29,440 --> 00:28:34,159
you have sufficiently fast exponential

831
00:28:31,200 --> 00:28:35,919
tracking, then you're guaranteed that

832
00:28:34,159 --> 00:28:38,000
your system is safe. Meaning the full

833
00:28:35,919 --> 00:28:40,000
order dynamics of your system is safe

834
00:28:38,000 --> 00:28:41,919
buffered a little bit by this tracking

835
00:28:40,000 --> 00:28:43,039
error. Even if all you have is a reduced

836
00:28:41,919 --> 00:28:46,320
order model generating reference

837
00:28:43,039 --> 00:28:47,600
signals. Okay, make sense? And how does

838
00:28:46,320 --> 00:28:49,279
this work? I mean, this this kind of

839
00:28:47,600 --> 00:28:51,679
blows my mind the first time we figured

840
00:28:49,279 --> 00:28:53,679
this out, which was about 2022. Take

841
00:28:51,679 --> 00:28:55,840
your reduced order model to be the

842
00:28:53,679 --> 00:28:58,399
single integrator, simplest system

843
00:28:55,840 --> 00:28:59,919
imaginable, right? Take your barrier

844
00:28:58,399 --> 00:29:02,240
function to be don't hit obstacles in

845
00:28:59,919 --> 00:29:04,320
the environment. Then your CBF becomes

846
00:29:02,240 --> 00:29:05,840
this. And this is your safety filter,

847
00:29:04,320 --> 00:29:08,080
which is literally like I'm writing it

848
00:29:05,840 --> 00:29:10,240
down. It's like two lines of code. Put

849
00:29:08,080 --> 00:29:12,720
that safety filter on a quadriped and

850
00:29:10,240 --> 00:29:15,679
just modulate the joystick command, you

851
00:29:12,720 --> 00:29:17,679
get collision avoidance. Right?

852
00:29:15,679 --> 00:29:20,640
Take that exact same controller, put it

853
00:29:17,679 --> 00:29:23,200
on a drone as a reference command, you

854
00:29:20,640 --> 00:29:25,200
get collision avoidance,

855
00:29:23,200 --> 00:29:27,200
right? So understanding these layers

856
00:29:25,200 --> 00:29:29,360
mean you can really rapidly develop

857
00:29:27,200 --> 00:29:30,799
things. And of course, you can change

858
00:29:29,360 --> 00:29:32,320
the reduced order model. you can put

859
00:29:30,799 --> 00:29:34,559
like a unicycle model on the on the

860
00:29:32,320 --> 00:29:35,919
quadriped and do the same sort of you're

861
00:29:34,559 --> 00:29:39,440
going to get a more complicated safety

862
00:29:35,919 --> 00:29:41,120
filter, but the same thing applies.

863
00:29:39,440 --> 00:29:42,399
So, of course, there's trade-offs here.

864
00:29:41,120 --> 00:29:43,679
I mean, if you use a simple reduced

865
00:29:42,399 --> 00:29:45,200
order model, you're going to get fairly

866
00:29:43,679 --> 00:29:46,399
conservative behavior. It'll guarantee

867
00:29:45,200 --> 00:29:47,919
safety, but it will be kind of

868
00:29:46,399 --> 00:29:49,120
conservative. The better reduced order

869
00:29:47,919 --> 00:29:51,760
model, the less conservative the

870
00:29:49,120 --> 00:29:53,440
behavior will be, right? But this works

871
00:29:51,760 --> 00:29:56,399
in a lot of scenarios. So, we did this

872
00:29:53,440 --> 00:29:58,000
on a manipulator. So in this case our

873
00:29:56,399 --> 00:29:59,520
barrier function is actually assigned

874
00:29:58,000 --> 00:30:01,600
distance function with every point in

875
00:29:59,520 --> 00:30:03,039
the environment for which we generate

876
00:30:01,600 --> 00:30:04,960
our we have a simple just single

877
00:30:03,039 --> 00:30:06,399
integrator reduced order model which we

878
00:30:04,960 --> 00:30:08,480
pass as a reference velocity to the

879
00:30:06,399 --> 00:30:10,399
low-level control on the manipulator.

880
00:30:08,480 --> 00:30:11,919
And the one thing the one caveat here is

881
00:30:10,399 --> 00:30:13,760
because the sign distance function is

882
00:30:11,919 --> 00:30:16,320
not smooth. We had to find a smooth

883
00:30:13,760 --> 00:30:18,080
approximation which gave you a small gap

884
00:30:16,320 --> 00:30:21,039
that you had to account for in the CBF

885
00:30:18,080 --> 00:30:22,559
condition as a delta. I say this because

886
00:30:21,039 --> 00:30:24,399
it turns out that my my final sort of

887
00:30:22,559 --> 00:30:26,559
theory piece on this is you have to pay

888
00:30:24,399 --> 00:30:29,279
attention to the deltas here. These

889
00:30:26,559 --> 00:30:30,880
matter a lot. What I mean is if you try

890
00:30:29,279 --> 00:30:34,240
to do a reduced order model without a

891
00:30:30,880 --> 00:30:37,760
delta on really complicated systems, you

892
00:30:34,240 --> 00:30:39,440
actually can get safety violations.

893
00:30:37,760 --> 00:30:40,880
And the reason why you can get safety

894
00:30:39,440 --> 00:30:42,799
violations even though it's it doesn't

895
00:30:40,880 --> 00:30:46,000
look minor is because exactly this the

896
00:30:42,799 --> 00:30:47,919
tracking controller sort of we prove

897
00:30:46,000 --> 00:30:49,360
that you get sta stability of a slightly

898
00:30:47,919 --> 00:30:51,039
enlarged safe set when you have a

899
00:30:49,360 --> 00:30:52,640
tracking controller. If you don't

900
00:30:51,039 --> 00:30:54,320
account for that enlarged safe set

901
00:30:52,640 --> 00:30:55,760
you're going to get slight violations.

902
00:30:54,320 --> 00:30:58,640
So if you want to make things better you

903
00:30:55,760 --> 00:31:00,480
got a buffer with a delta. So this

904
00:30:58,640 --> 00:31:01,919
actually leads to input to state safety

905
00:31:00,480 --> 00:31:03,520
and a whole bunch of beautiful math that

906
00:31:01,919 --> 00:31:05,679
was in a bunch of papers if you're

907
00:31:03,520 --> 00:31:07,120
interested on how you can robustify the

908
00:31:05,679 --> 00:31:09,840
implementation of reduced order models

909
00:31:07,120 --> 00:31:11,520
in this way by picking better deltas.

910
00:31:09,840 --> 00:31:13,039
And in fact there's a theorem that says

911
00:31:11,520 --> 00:31:14,880
this works. So I want to be sort of

912
00:31:13,039 --> 00:31:18,080
explicit what what it fundamentally

913
00:31:14,880 --> 00:31:21,440
means is before without a delta if you

914
00:31:18,080 --> 00:31:23,360
have this tracking okay you need to have

915
00:31:21,440 --> 00:31:25,200
exponential tracking all the way down to

916
00:31:23,360 --> 00:31:28,240
zero to guarantee safety which is never

917
00:31:25,200 --> 00:31:29,840
in practice true. What the delta gives

918
00:31:28,240 --> 00:31:32,880
you is the ability to replace this

919
00:31:29,840 --> 00:31:34,480
condition with bounded tracking which

920
00:31:32,880 --> 00:31:36,799
any real system you'll have bounded

921
00:31:34,480 --> 00:31:38,240
tracking. Right? So then you can recover

922
00:31:36,799 --> 00:31:40,880
this this theorem that the full order

923
00:31:38,240 --> 00:31:43,039
dynamics is safe even if you only have

924
00:31:40,880 --> 00:31:46,320
these reduced order dynamics as long as

925
00:31:43,039 --> 00:31:47,760
you add a delta accordingly in essence.

926
00:31:46,320 --> 00:31:49,440
And that delta led to a lot of

927
00:31:47,760 --> 00:31:52,399
interesting things like collision

928
00:31:49,440 --> 00:31:54,000
avoidance locomotion this hopping robot

929
00:31:52,399 --> 00:31:55,440
doing collision avoidance. So we've been

930
00:31:54,000 --> 00:31:57,279
able to really study this in a lot of

931
00:31:55,440 --> 00:32:00,640
different contexts. what the role of

932
00:31:57,279 --> 00:32:02,000
delta is. Okay. So, so that's the story.

933
00:32:00,640 --> 00:32:03,679
So, that's the layered architecture

934
00:32:02,000 --> 00:32:05,840
story.

935
00:32:03,679 --> 00:32:08,559
So, what do we do with all of this stuff

936
00:32:05,840 --> 00:32:10,240
I presented to you so far, right? How do

937
00:32:08,559 --> 00:32:12,159
we handle all of these pieces? So, let

938
00:32:10,240 --> 00:32:14,159
me sort of recalibrate for one second

939
00:32:12,159 --> 00:32:15,600
because I know I can kind of it's always

940
00:32:14,159 --> 00:32:17,120
hard for me to give talks because I love

941
00:32:15,600 --> 00:32:18,480
all the work we did in the lab so much.

942
00:32:17,120 --> 00:32:19,840
I want to tell you about all of it and I

943
00:32:18,480 --> 00:32:22,399
have to kind of like step back and only

944
00:32:19,840 --> 00:32:24,960
tell you pieces and and and so I already

945
00:32:22,399 --> 00:32:26,480
told you a bunch of pieces but why does

946
00:32:24,960 --> 00:32:29,200
this matter to the original problem I

947
00:32:26,480 --> 00:32:32,000
posed? So let's go back to humanoid

948
00:32:29,200 --> 00:32:33,200
robots now. Now the videos I showed at

949
00:32:32,000 --> 00:32:35,519
the beginning of the talk they had a

950
00:32:33,200 --> 00:32:36,880
bunch of subtext in them that I didn't

951
00:32:35,519 --> 00:32:40,159
that at the time you probably didn't

952
00:32:36,880 --> 00:32:42,720
catch or maybe you did. First what model

953
00:32:40,159 --> 00:32:44,640
were we using for the safety filter?

954
00:32:42,720 --> 00:32:46,640
Right? Was I doing a forward or dynamic

955
00:32:44,640 --> 00:32:48,720
model with all the joints like nonlinear

956
00:32:46,640 --> 00:32:50,080
model for the safety filter? No. What

957
00:32:48,720 --> 00:32:52,880
model was I using? The answer is

958
00:32:50,080 --> 00:32:55,840
actually on the slide.

959
00:32:52,880 --> 00:32:57,760
Single integrator. There it is. Single

960
00:32:55,840 --> 00:32:59,360
integrator safety filter on the humanoid

961
00:32:57,760 --> 00:33:02,000
robot. And this is the behavior you get.

962
00:32:59,360 --> 00:33:03,760
It looks super dynamic, right? To

963
00:33:02,000 --> 00:33:05,919
imagine a single integrator gives that

964
00:33:03,760 --> 00:33:07,120
kind of behavior. Why? Because you

965
00:33:05,919 --> 00:33:09,440
actually have really good controllers

966
00:33:07,120 --> 00:33:12,720
below the surface. In this case, this is

967
00:33:09,440 --> 00:33:13,919
actually um Unit's uh RL walking

968
00:33:12,720 --> 00:33:16,799
controller, which is actually pretty

969
00:33:13,919 --> 00:33:18,960
good, of course, as you know. So, the

970
00:33:16,799 --> 00:33:21,360
better the controller gets down below,

971
00:33:18,960 --> 00:33:23,600
the better our safety filters get, even

972
00:33:21,360 --> 00:33:24,960
with reduced order models. And now we of

973
00:33:23,600 --> 00:33:27,200
course know from the second part of the

974
00:33:24,960 --> 00:33:29,200
talk that we actually get a formal

975
00:33:27,200 --> 00:33:31,519
guarantee of safety on this full order

976
00:33:29,200 --> 00:33:33,440
system even though we're only using a

977
00:33:31,519 --> 00:33:34,960
single integrator reduced order model.

978
00:33:33,440 --> 00:33:38,080
So, we have a theorem that says this

979
00:33:34,960 --> 00:33:39,600
thing will actually be safe, right?

980
00:33:38,080 --> 00:33:41,200
There's one other piece I didn't talk

981
00:33:39,600 --> 00:33:43,519
about though yet that we have to fold

982
00:33:41,200 --> 00:33:45,039
into the picture.

983
00:33:43,519 --> 00:33:48,679
Anybody have any idea what that is?

984
00:33:45,039 --> 00:33:48,679
What's the missing piece?

985
00:33:49,200 --> 00:33:52,000
I talked about the models. I talked

986
00:33:50,720 --> 00:33:53,840
about how I'm implementing. So you could

987
00:33:52,000 --> 00:33:56,080
should get a pretty good sense. It's

988
00:33:53,840 --> 00:33:57,760
actually the clue's on there.

989
00:33:56,080 --> 00:33:59,679
>> No, the learning is sitting here. I'll

990
00:33:57,760 --> 00:34:01,760
talk again about learning and we can do

991
00:33:59,679 --> 00:34:04,080
this with CLFRL2. That's you know we're

992
00:34:01,760 --> 00:34:05,760
sort of platform agnostic. It's sitting

993
00:34:04,080 --> 00:34:07,840
on the board right and sitting on the TV

994
00:34:05,760 --> 00:34:09,919
right there. Perception. How do we

995
00:34:07,840 --> 00:34:11,679
handle the perception component? So

996
00:34:09,919 --> 00:34:13,599
that's the last bit that's made a huge

997
00:34:11,679 --> 00:34:15,919
difference. In fact, I'm going to make a

998
00:34:13,599 --> 00:34:18,240
statement here that's pretty strong.

999
00:34:15,919 --> 00:34:20,000
Perception is in many ways and how you

1000
00:34:18,240 --> 00:34:21,440
handle perception in many ways much more

1001
00:34:20,000 --> 00:34:23,679
important than the model you use for a

1002
00:34:21,440 --> 00:34:27,040
safety filter.

1003
00:34:23,679 --> 00:34:29,119
Single integrator model with really good

1004
00:34:27,040 --> 00:34:30,879
perception handling makes all the

1005
00:34:29,119 --> 00:34:31,760
difference. What do I mean by this?

1006
00:34:30,879 --> 00:34:33,359
What's happening here? So this is

1007
00:34:31,760 --> 00:34:34,960
actually a recent result that was at RSS

1008
00:34:33,359 --> 00:34:37,359
this year, but I I really like it a lot.

1009
00:34:34,960 --> 00:34:39,520
It's really beautiful. What we can do is

1010
00:34:37,359 --> 00:34:42,240
take perception data whether it's liar

1011
00:34:39,520 --> 00:34:43,919
or camera it doesn't matter we can solve

1012
00:34:42,240 --> 00:34:45,359
and this was this was a result of my

1013
00:34:43,919 --> 00:34:47,760
students and posttos where they came up

1014
00:34:45,359 --> 00:34:51,119
with this idea of solving pson's

1015
00:34:47,760 --> 00:34:54,079
equation a PTE and they can do this in

1016
00:34:51,119 --> 00:34:57,040
real time at faster than a kilo hertz

1017
00:34:54,079 --> 00:34:58,720
super fast to build a single functional

1018
00:34:57,040 --> 00:35:01,839
representation of the environment that's

1019
00:34:58,720 --> 00:35:04,320
smooth for any number of obstacles so

1020
00:35:01,839 --> 00:35:05,599
much better than sign distance function

1021
00:35:04,320 --> 00:35:07,359
and the end result this is where a

1022
00:35:05,599 --> 00:35:09,920
single obstacle You can do it with many.

1023
00:35:07,359 --> 00:35:11,680
This is your sign. This is your pos

1024
00:35:09,920 --> 00:35:13,200
safety function as we call it. Of

1025
00:35:11,680 --> 00:35:15,280
course, positive means you're safe. And

1026
00:35:13,200 --> 00:35:16,880
as the ball rolls through the scene, you

1027
00:35:15,280 --> 00:35:18,960
get this negative bit which is unsafe.

1028
00:35:16,880 --> 00:35:20,240
And then of course, we're also have a a

1029
00:35:18,960 --> 00:35:22,160
safety constraint that we don't leave

1030
00:35:20,240 --> 00:35:23,680
this set here. So, we get zero along the

1031
00:35:22,160 --> 00:35:25,920
boundary.

1032
00:35:23,680 --> 00:35:27,119
And this determines H. And that's what

1033
00:35:25,920 --> 00:35:28,960
I'm really pointing out is that if you

1034
00:35:27,119 --> 00:35:30,880
look at a safety filter, what matters?

1035
00:35:28,960 --> 00:35:33,119
You have your model and you have your

1036
00:35:30,880 --> 00:35:35,839
barrier function H. And you have the

1037
00:35:33,119 --> 00:35:38,640
gradients of that H. All of those pieces

1038
00:35:35,839 --> 00:35:40,800
are as important as one another, right?

1039
00:35:38,640 --> 00:35:43,520
And this is addressing the H. The model

1040
00:35:40,800 --> 00:35:46,240
itself in this case is very simple. So

1041
00:35:43,520 --> 00:35:48,240
this is a method. This is just the same

1042
00:35:46,240 --> 00:35:49,520
thing. But now if you watch the screen

1043
00:35:48,240 --> 00:35:51,359
back here, I think you'll appreciate

1044
00:35:49,520 --> 00:35:52,960
much more what's happening, right? It's

1045
00:35:51,359 --> 00:35:55,200
real time synthesizing the barrier

1046
00:35:52,960 --> 00:35:57,359
function solving pan's equation. And

1047
00:35:55,200 --> 00:35:59,920
again, this is just unitry's offtheshelf

1048
00:35:57,359 --> 00:36:01,599
RO and my student just interacting with

1049
00:35:59,920 --> 00:36:04,160
it, which is I I like this video. By the

1050
00:36:01,599 --> 00:36:06,000
way, this also worked in one day. And I

1051
00:36:04,160 --> 00:36:07,520
only say that because to me a sign of

1052
00:36:06,000 --> 00:36:08,800
the like the math being right is you put

1053
00:36:07,520 --> 00:36:10,240
it on hardware and it kind of works out

1054
00:36:08,800 --> 00:36:11,760
of the box. If you have to force it

1055
00:36:10,240 --> 00:36:14,240
uphill, you're you're probably not

1056
00:36:11,760 --> 00:36:15,760
you're missing something.

1057
00:36:14,240 --> 00:36:17,520
Here's another example where we actually

1058
00:36:15,760 --> 00:36:19,359
added a couple pieces. First, we had a

1059
00:36:17,520 --> 00:36:20,800
geometric representation of the robot in

1060
00:36:19,359 --> 00:36:21,760
the posance equation. And second, we

1061
00:36:20,800 --> 00:36:23,520
were actually doing this predictive

1062
00:36:21,760 --> 00:36:25,760
safety filter, which is a CBF condition

1063
00:36:23,520 --> 00:36:27,599
in an MPC problem. And that gives us

1064
00:36:25,760 --> 00:36:29,119
this predictive behavior. So as the ball

1065
00:36:27,599 --> 00:36:31,280
comes, we don't just go out of the way,

1066
00:36:29,119 --> 00:36:32,960
but we actually turn and rotate to avoid

1067
00:36:31,280 --> 00:36:34,800
the collision. You can actually see on

1068
00:36:32,960 --> 00:36:37,119
the screen the trajectory from the

1069
00:36:34,800 --> 00:36:39,359
predictive safety filter together with

1070
00:36:37,119 --> 00:36:43,520
the geometric representation all being

1071
00:36:39,359 --> 00:36:45,040
done in this pan safety function. Right?

1072
00:36:43,520 --> 00:36:47,280
So

1073
00:36:45,040 --> 00:36:49,520
that's the perception part. Again, going

1074
00:36:47,280 --> 00:36:50,880
back to this, we can close the loop on

1075
00:36:49,520 --> 00:36:52,240
some of the other stuff we did as well

1076
00:36:50,880 --> 00:36:54,720
though, right? So I talked about

1077
00:36:52,240 --> 00:36:57,520
stochastic CBFS earlier. That was a

1078
00:36:54,720 --> 00:36:59,280
leadin to this. Again, I told you we're

1079
00:36:57,520 --> 00:37:01,440
doing single integrator reduced order

1080
00:36:59,280 --> 00:37:03,200
models and they work really well. True.

1081
00:37:01,440 --> 00:37:05,520
But we can also make them better. How do

1082
00:37:03,200 --> 00:37:07,920
we make them better? We can collect some

1083
00:37:05,520 --> 00:37:10,880
data from the deployment of the single

1084
00:37:07,920 --> 00:37:12,480
integrator CBF on the hardware. We take

1085
00:37:10,880 --> 00:37:15,280
this data and we can learn the

1086
00:37:12,480 --> 00:37:17,920
distribution and then get a stochastic

1087
00:37:15,280 --> 00:37:20,240
guarantee on safety and we can learn a

1088
00:37:17,920 --> 00:37:22,400
better reduced order model that we can

1089
00:37:20,240 --> 00:37:24,240
then use for the safety filter. And this

1090
00:37:22,400 --> 00:37:26,880
better reduced order model, this D here

1091
00:37:24,240 --> 00:37:28,720
that we're learning includes in it, I

1092
00:37:26,880 --> 00:37:32,960
keep hitting too many buttons, includes

1093
00:37:28,720 --> 00:37:34,800
in it sort of contains the the the RL

1094
00:37:32,960 --> 00:37:37,359
policy that was under the surface here,

1095
00:37:34,800 --> 00:37:38,720
right? And so this is what happens when

1096
00:37:37,359 --> 00:37:41,200
you do this. Our learned reduce order

1097
00:37:38,720 --> 00:37:43,200
model has much better tracking than the

1098
00:37:41,200 --> 00:37:46,160
original one. Better tracking means

1099
00:37:43,200 --> 00:37:48,400
smaller safe set expansion, which means

1100
00:37:46,160 --> 00:37:49,680
tighter performance. Right? So that's

1101
00:37:48,400 --> 00:37:51,200
where all these pieces start to come

1102
00:37:49,680 --> 00:37:53,280
together. Again, I'm trying to really

1103
00:37:51,200 --> 00:37:56,160
demonstrate the interplay. And once we

1104
00:37:53,280 --> 00:37:59,680
do that, we can get really cool

1105
00:37:56,160 --> 00:38:02,079
deployments. So, this is now this safety

1106
00:37:59,680 --> 00:38:04,800
filter, but using this learned reduced

1107
00:38:02,079 --> 00:38:06,240
order model together with stoastic CBFS

1108
00:38:04,800 --> 00:38:08,560
outdoors. So, we're doing obviously

1109
00:38:06,240 --> 00:38:10,160
onboard compute, onboard perception.

1110
00:38:08,560 --> 00:38:11,599
This is actually the perception in this

1111
00:38:10,160 --> 00:38:13,680
case. So, these are the obstacles the

1112
00:38:11,599 --> 00:38:17,119
robot's sensing in real time. That's my

1113
00:38:13,680 --> 00:38:20,960
student Gary who it's avoiding.

1114
00:38:17,119 --> 00:38:22,800
And this one's kind of cool. Again,

1115
00:38:20,960 --> 00:38:24,720
anytime you take a robot outside in the

1116
00:38:22,800 --> 00:38:26,960
real world, the humanoid, first, it's

1117
00:38:24,720 --> 00:38:28,880
super cool, and second, you get really

1118
00:38:26,960 --> 00:38:31,040
big crowds. I don't if you've noticed

1119
00:38:28,880 --> 00:38:32,240
this. This was just us taking this out.

1120
00:38:31,040 --> 00:38:33,760
We didn't tell people this was going to

1121
00:38:32,240 --> 00:38:35,520
happen, and pretty soon we had like 50

1122
00:38:33,760 --> 00:38:37,119
people watching watching the robot and

1123
00:38:35,520 --> 00:38:38,720
wanting to interact with it. There is a

1124
00:38:37,119 --> 00:38:40,800
very visceral uh connection with

1125
00:38:38,720 --> 00:38:42,240
humanoid robots. So, anyways, this was

1126
00:38:40,800 --> 00:38:44,400
this is cool though because now we have

1127
00:38:42,240 --> 00:38:46,720
really closed the loop.

1128
00:38:44,400 --> 00:38:49,280
So there's one element though we haven't

1129
00:38:46,720 --> 00:38:51,440
like fully closed though between all the

1130
00:38:49,280 --> 00:38:54,000
things I talked about so far and it was

1131
00:38:51,440 --> 00:38:56,079
said earlier now you can say it again

1132
00:38:54,000 --> 00:38:58,240
what do we need to bring it back to

1133
00:38:56,079 --> 00:38:59,760
learning okay so is there a will for

1134
00:38:58,240 --> 00:39:01,119
learning so everything I did yeah we

1135
00:38:59,760 --> 00:39:03,359
learned the reduced order model but

1136
00:39:01,119 --> 00:39:04,800
that's really like learning for control

1137
00:39:03,359 --> 00:39:06,400
which is very important learning the

1138
00:39:04,800 --> 00:39:07,760
reduced order model but can we take

1139
00:39:06,400 --> 00:39:10,160
these ideas and actually bring it to the

1140
00:39:07,760 --> 00:39:12,000
learning community and so this is a

1141
00:39:10,160 --> 00:39:16,960
recent result that is sort of in that

1142
00:39:12,000 --> 00:39:20,000
light where we actually do CBFS in

1143
00:39:16,960 --> 00:39:22,720
training to inherently learn safety

1144
00:39:20,000 --> 00:39:24,800
filters using all of the tricks that

1145
00:39:22,720 --> 00:39:26,880
we've assembled so far if you'd like.

1146
00:39:24,800 --> 00:39:28,640
Right? So what happens here? We have

1147
00:39:26,880 --> 00:39:30,720
some RL policy and we want to roll out

1148
00:39:28,640 --> 00:39:32,320
this RL policy together with this safety

1149
00:39:30,720 --> 00:39:33,599
constraint. So in this case the safety

1150
00:39:32,320 --> 00:39:35,040
constraint I'm showing here is the

1151
00:39:33,599 --> 00:39:37,280
stairs. We don't want the feet to hit

1152
00:39:35,040 --> 00:39:38,960
the stairs ever, right? Because we want

1153
00:39:37,280 --> 00:39:40,400
to walk walk up and down stairs. We can

1154
00:39:38,960 --> 00:39:41,920
also do it for collision avoidance and

1155
00:39:40,400 --> 00:39:43,200
other things, whatever you want, right?

1156
00:39:41,920 --> 00:39:44,640
So how do you do this? Well, you're

1157
00:39:43,200 --> 00:39:45,920
going to roll out your policy, but as

1158
00:39:44,640 --> 00:39:47,839
you roll out, you're going to safety

1159
00:39:45,920 --> 00:39:50,160
filter. How are you going to safety

1160
00:39:47,839 --> 00:39:52,000
filter? Well, I showed you earlier the

1161
00:39:50,160 --> 00:39:54,000
rollouts themselves. So, our actual

1162
00:39:52,000 --> 00:39:56,320
model in this case is a simulator. We

1163
00:39:54,000 --> 00:39:57,920
don't know the model, right? But for the

1164
00:39:56,320 --> 00:39:59,760
rollouts, we can use a reduced order

1165
00:39:57,920 --> 00:40:01,440
model. I showed you how good an

1166
00:39:59,760 --> 00:40:02,880
integrator works, right? So, let's use a

1167
00:40:01,440 --> 00:40:04,800
single integrator reduced order model,

1168
00:40:02,880 --> 00:40:06,480
but now discretetized.

1169
00:40:04,800 --> 00:40:08,560
And then for this, we need we would have

1170
00:40:06,480 --> 00:40:10,560
a discrete time CBF condition, which I

1171
00:40:08,560 --> 00:40:12,400
talked about earlier. I keep hitting the

1172
00:40:10,560 --> 00:40:13,760
wrong buttons. There we go. a discrete

1173
00:40:12,400 --> 00:40:15,599
time CBF condition. Well, it turns out

1174
00:40:13,760 --> 00:40:17,680
you're able to prove that you can

1175
00:40:15,599 --> 00:40:19,599
enforce the continuous time CBF

1176
00:40:17,680 --> 00:40:21,040
condition and that implies that the

1177
00:40:19,599 --> 00:40:23,599
discrete time condition is satisfied

1178
00:40:21,040 --> 00:40:25,760
which means your rollouts will be safe.

1179
00:40:23,599 --> 00:40:27,359
So we can go from continuous to discrete

1180
00:40:25,760 --> 00:40:29,599
and from the rollouts and reduced order

1181
00:40:27,359 --> 00:40:31,040
model to actual safety on the full order

1182
00:40:29,599 --> 00:40:33,599
dynamics which in this case is just the

1183
00:40:31,040 --> 00:40:35,040
simulator. Why does that matter? Because

1184
00:40:33,599 --> 00:40:38,320
once we have the continuous time

1185
00:40:35,040 --> 00:40:41,280
condition this is fine in your input.

1186
00:40:38,320 --> 00:40:42,960
Hence you get an explicit solution. You

1187
00:40:41,280 --> 00:40:44,880
have an explicit solution. You can do

1188
00:40:42,960 --> 00:40:47,760
what? Why do we need an explicit

1189
00:40:44,880 --> 00:40:49,599
solution in this case?

1190
00:40:47,760 --> 00:40:53,200
Anybody?

1191
00:40:49,599 --> 00:40:55,599
We can GPU paralyze, right? We can't yet

1192
00:40:53,200 --> 00:40:57,200
GPUs paralyze QP solves. Not

1193
00:40:55,599 --> 00:40:59,280
effectively. There's people working on

1194
00:40:57,200 --> 00:41:00,560
it. But explicit solutions mean it's

1195
00:40:59,280 --> 00:41:02,079
like two lines of code you add to your

1196
00:41:00,560 --> 00:41:03,359
rollup procedure as you're doing the RL.

1197
00:41:02,079 --> 00:41:04,960
Meaning there's no real computational

1198
00:41:03,359 --> 00:41:06,400
overhead. Which means now you can chain

1199
00:41:04,960 --> 00:41:08,960
at the rollouts. And then the final step

1200
00:41:06,400 --> 00:41:12,000
is you bring all that back. You take

1201
00:41:08,960 --> 00:41:14,400
this whe if safety is violated, you take

1202
00:41:12,000 --> 00:41:15,839
the correction term, you fold it back in

1203
00:41:14,400 --> 00:41:18,000
and you take your nominal reward and

1204
00:41:15,839 --> 00:41:19,280
modulate by this CBF. So the the reward

1205
00:41:18,000 --> 00:41:21,200
has some knowledge that you're

1206
00:41:19,280 --> 00:41:22,560
modulating this output and you put all

1207
00:41:21,200 --> 00:41:24,960
those pieces together and this is

1208
00:41:22,560 --> 00:41:28,240
actually now you deploy that on hardware

1209
00:41:24,960 --> 00:41:29,760
straight up and you can do stairs. In

1210
00:41:28,240 --> 00:41:34,079
fact, let me show you the outdoor

1211
00:41:29,760 --> 00:41:36,400
montage. So this is now CBFRL with CBFS

1212
00:41:34,079 --> 00:41:39,280
in training. There's actually no online

1213
00:41:36,400 --> 00:41:40,720
safety filter here. we sort of learned

1214
00:41:39,280 --> 00:41:42,319
the behavior. Now, in practice, I would

1215
00:41:40,720 --> 00:41:43,599
do an online filter as well, just to be

1216
00:41:42,319 --> 00:41:45,440
very clear. We're just showing that this

1217
00:41:43,599 --> 00:41:49,359
works without one and we're able to

1218
00:41:45,440 --> 00:41:51,119
handle pretty dramatic stairs. I mean,

1219
00:41:49,359 --> 00:41:52,800
we have a ways to go to make this super

1220
00:41:51,119 --> 00:41:54,079
smooth and fluid. To be clear, this is a

1221
00:41:52,800 --> 00:41:55,680
very recent result, but I'm kind of

1222
00:41:54,079 --> 00:41:58,160
showing where things can go when you

1223
00:41:55,680 --> 00:42:00,079
start to inject now control into

1224
00:41:58,160 --> 00:42:01,520
learning, right? Meaning, what we know

1225
00:42:00,079 --> 00:42:03,920
about control into the learning based

1226
00:42:01,520 --> 00:42:07,079
procedures, right? One more time because

1227
00:42:03,920 --> 00:42:07,079
it's pretty

1228
00:42:08,000 --> 00:42:12,240
I love watching robots, right? So, so

1229
00:42:11,040 --> 00:42:14,880
that's kind of bringing everything

1230
00:42:12,240 --> 00:42:17,280
really back full circle, right? Make

1231
00:42:14,880 --> 00:42:19,599
sense? See all those pieces? So, in the

1232
00:42:17,280 --> 00:42:21,760
end, you have this repertoire of things

1233
00:42:19,599 --> 00:42:24,400
that we've developed.

1234
00:42:21,760 --> 00:42:25,760
So, in particular,

1235
00:42:24,400 --> 00:42:28,960
I'm going to go back to this statement

1236
00:42:25,760 --> 00:42:31,280
of why learning needs control and

1237
00:42:28,960 --> 00:42:32,960
control theory. And I will say the

1238
00:42:31,280 --> 00:42:34,319
converse is also true. It's not in this

1239
00:42:32,960 --> 00:42:37,200
slide, but I want to really clearly

1240
00:42:34,319 --> 00:42:41,280
emphatically say that control also needs

1241
00:42:37,200 --> 00:42:42,640
learning. We need each other, right? We

1242
00:42:41,280 --> 00:42:45,520
need each other and we need to find

1243
00:42:42,640 --> 00:42:47,680
these common intersection points. Okay,

1244
00:42:45,520 --> 00:42:49,040
so on one level, why does again, why

1245
00:42:47,680 --> 00:42:50,720
does learning need control? Because

1246
00:42:49,040 --> 00:42:52,240
control can can help address the

1247
00:42:50,720 --> 00:42:54,640
bottlenecks that learning inherently

1248
00:42:52,240 --> 00:42:57,839
has. Learning does great at performance.

1249
00:42:54,640 --> 00:42:59,839
It is not great at robust certifiable

1250
00:42:57,839 --> 00:43:03,280
safety critical behaviors. Right?

1251
00:42:59,839 --> 00:43:05,760
Control theory has a century of making

1252
00:43:03,280 --> 00:43:08,319
sure that airplanes fly with 10 theus 9

1253
00:43:05,760 --> 00:43:10,400
safety right we need to take those

1254
00:43:08,319 --> 00:43:12,640
principles things like safety filters I

1255
00:43:10,400 --> 00:43:14,400
mean here we have a certification that

1256
00:43:12,640 --> 00:43:16,319
our system is safe that we can use to

1257
00:43:14,400 --> 00:43:19,040
verify and certify the system in many

1258
00:43:16,319 --> 00:43:21,359
contexts and we put this in independent

1259
00:43:19,040 --> 00:43:23,680
of your RL algorithm to guarantee safe

1260
00:43:21,359 --> 00:43:25,440
behaviors on the system right so that's

1261
00:43:23,680 --> 00:43:27,200
what it can do on that end and then

1262
00:43:25,440 --> 00:43:29,599
coming back again control guided

1263
00:43:27,200 --> 00:43:32,000
learning can help to unlock performance

1264
00:43:29,599 --> 00:43:36,000
So I actually think going beyond just

1265
00:43:32,000 --> 00:43:39,280
safety filtering control can genuinely

1266
00:43:36,000 --> 00:43:40,960
help learning be better, right? And and

1267
00:43:39,280 --> 00:43:44,319
these are two examples from my lab. I

1268
00:43:40,960 --> 00:43:45,839
mean again I I say in in in all

1269
00:43:44,319 --> 00:43:47,599
humbleness, I mean these are a couple

1270
00:43:45,839 --> 00:43:48,960
grad students, incredible grad students

1271
00:43:47,599 --> 00:43:50,800
that did this, right? But I don't have a

1272
00:43:48,960 --> 00:43:52,800
hundred people in my in a company like

1273
00:43:50,800 --> 00:43:55,280
pushing forward the latest like reward

1274
00:43:52,800 --> 00:43:57,440
function shaping and and and that's the

1275
00:43:55,280 --> 00:43:59,520
beauty of math is just a couple grad

1276
00:43:57,440 --> 00:44:00,800
students really smart really smart grad

1277
00:43:59,520 --> 00:44:03,599
students I don't want to downplay this

1278
00:44:00,800 --> 00:44:05,680
enough these guys are brilliant but we

1279
00:44:03,599 --> 00:44:06,720
can get really good running I'll put

1280
00:44:05,680 --> 00:44:07,920
this up against any of the

1281
00:44:06,720 --> 00:44:10,240
state-of-the-art running I'm seeing

1282
00:44:07,920 --> 00:44:13,119
right now right and it's all based on

1283
00:44:10,240 --> 00:44:15,280
just clean CLS and two weeks of

1284
00:44:13,119 --> 00:44:17,200
deployment of course the stair climbing

1285
00:44:15,280 --> 00:44:19,200
too which is which is very cool so we

1286
00:44:17,200 --> 00:44:20,960
can use these controlbased principles to

1287
00:44:19,200 --> 00:44:23,599
inform reinforcement learning and other

1288
00:44:20,960 --> 00:44:25,760
methods. This talk, so my final piece is

1289
00:44:23,599 --> 00:44:27,839
this talk really focused on RL

1290
00:44:25,760 --> 00:44:30,880
specifically. There's of course a lot of

1291
00:44:27,839 --> 00:44:32,560
other ways you can do learning VAS etc.

1292
00:44:30,880 --> 00:44:34,319
uh large language models and I think in

1293
00:44:32,560 --> 00:44:36,079
all those cases again similar messages

1294
00:44:34,319 --> 00:44:37,280
could be made. I'm just not an expert in

1295
00:44:36,079 --> 00:44:39,760
those domains and I don't want to talk

1296
00:44:37,280 --> 00:44:41,200
outside my box. But in this case I think

1297
00:44:39,760 --> 00:44:43,599
I hope at least I made a reasonably

1298
00:44:41,200 --> 00:44:46,160
compelling case as to how we can work

1299
00:44:43,599 --> 00:44:48,000
together in this front. And so why do we

1300
00:44:46,160 --> 00:44:50,720
want to do this? So, I'm just going to

1301
00:44:48,000 --> 00:44:53,680
close with two fun videos. Uh, first,

1302
00:44:50,720 --> 00:44:55,839
the CLFRL was actually invented out of

1303
00:44:53,680 --> 00:44:57,280
necessity, right? A great quote,

1304
00:44:55,839 --> 00:45:00,160
necessity is the mother invention,

1305
00:44:57,280 --> 00:45:02,000
right? So, we had to do this demo and we

1306
00:45:00,160 --> 00:45:03,680
had to get the robot to walk really well

1307
00:45:02,000 --> 00:45:06,079
in a lot of different scenarios with

1308
00:45:03,680 --> 00:45:08,640
different loads on its back. And I

1309
00:45:06,079 --> 00:45:10,079
couldn't imagine the reward like shaping

1310
00:45:08,640 --> 00:45:13,440
and tuning we would have to do to make

1311
00:45:10,079 --> 00:45:14,640
that all work in a month. So, I so I

1312
00:45:13,440 --> 00:45:16,000
worked with my students. I'm like, we

1313
00:45:14,640 --> 00:45:17,280
have to find a principal way to generate

1314
00:45:16,000 --> 00:45:19,839
different walking behaviors. In

1315
00:45:17,280 --> 00:45:22,240
particular, we rolled out CLFRL for the

1316
00:45:19,839 --> 00:45:24,160
first time in this scenario.

1317
00:45:22,240 --> 00:45:26,960
This was literally 2 weeks after we

1318
00:45:24,160 --> 00:45:28,640
invented the idea. Um, and why again

1319
00:45:26,960 --> 00:45:31,599
this humanoid robot, the G, this is the

1320
00:45:28,640 --> 00:45:32,800
the G1 is carrying this drone. It's more

1321
00:45:31,599 --> 00:45:35,520
than just a drone. It's actually called

1322
00:45:32,800 --> 00:45:38,160
M4. So, we had to walk with it and

1323
00:45:35,520 --> 00:45:40,880
that's CLFRL. Then, we had to do this

1324
00:45:38,160 --> 00:45:42,319
behavior of bending over. Why? Because

1325
00:45:40,880 --> 00:45:44,240
you don't want to carry a drone unless

1326
00:45:42,319 --> 00:45:46,720
it's going to go somewhere. So then the

1327
00:45:44,240 --> 00:45:48,960
drone takes off,

1328
00:45:46,720 --> 00:45:50,640
flies away. So what you're trying to do

1329
00:45:48,960 --> 00:45:52,560
here is leverage the locomotion

1330
00:45:50,640 --> 00:45:54,240
modalities of each of each platform to

1331
00:45:52,560 --> 00:45:56,400
its its greatest benefit. So then it can

1332
00:45:54,240 --> 00:45:58,800
transition into a a driving robot and

1333
00:45:56,400 --> 00:46:00,880
back to a flying robot, right? And it

1334
00:45:58,800 --> 00:46:02,319
can take off. So it's able to explore a

1335
00:46:00,880 --> 00:46:04,319
lot of spaces that might be hard for a

1336
00:46:02,319 --> 00:46:05,760
humanoid, right? It can get a lot of

1337
00:46:04,319 --> 00:46:07,680
places. Like here, it's flying over the

1338
00:46:05,760 --> 00:46:09,760
turtle pond at Caltech. And while it's

1339
00:46:07,680 --> 00:46:13,040
doing that, the humanoid can walk around

1340
00:46:09,760 --> 00:46:15,680
sort of the long way. So outdoors, the

1341
00:46:13,040 --> 00:46:16,960
drone and and the M4 in particular can

1342
00:46:15,680 --> 00:46:18,720
really move around quickly. Of course,

1343
00:46:16,960 --> 00:46:20,720
inside you probably don't want that

1344
00:46:18,720 --> 00:46:22,000
drone flying around the hallway and the

1345
00:46:20,720 --> 00:46:23,839
wheeled robot certainly can't go

1346
00:46:22,000 --> 00:46:25,839
upstairs, right? So that's where the

1347
00:46:23,839 --> 00:46:27,440
humanoid can really flourish. In fact,

1348
00:46:25,839 --> 00:46:29,520
the stair climbing again was invented

1349
00:46:27,440 --> 00:46:31,760
out of necessity. This was the first

1350
00:46:29,520 --> 00:46:33,760
time we ever implemented that stair

1351
00:46:31,760 --> 00:46:35,680
climbing idea and we did it pretty

1352
00:46:33,760 --> 00:46:37,920
successfully.

1353
00:46:35,680 --> 00:46:39,599
So So this is this is this is actually

1354
00:46:37,920 --> 00:46:41,200
what what led to a lot of these

1355
00:46:39,599 --> 00:46:42,319
inventions. It started at math and a

1356
00:46:41,200 --> 00:46:43,839
month later we were doing these things

1357
00:46:42,319 --> 00:46:45,440
and this is where you'd really like to

1358
00:46:43,839 --> 00:46:47,920
take humanoids really outdoors doing

1359
00:46:45,440 --> 00:46:50,400
real world things right and of course

1360
00:46:47,920 --> 00:46:53,200
ultimately my interest is humanoids

1361
00:46:50,400 --> 00:46:55,040
around people these are just students

1362
00:46:53,200 --> 00:46:57,200
around Caltech that stop to watch the

1363
00:46:55,040 --> 00:47:00,079
humanoid and we're running here we're

1364
00:46:57,200 --> 00:47:01,920
running a safety filter uh using the LAR

1365
00:47:00,079 --> 00:47:04,319
from the the one I showed you earlier

1366
00:47:01,920 --> 00:47:06,079
called shield and my student here is

1367
00:47:04,319 --> 00:47:07,680
just kind of there's this is an autonomy

1368
00:47:06,079 --> 00:47:09,280
he's driving the robot around but we

1369
00:47:07,680 --> 00:47:11,599
know and feel confident that it won't

1370
00:47:09,280 --> 00:47:13,200
run into the people because it's got a

1371
00:47:11,599 --> 00:47:15,119
safety filter on it. Right? So again,

1372
00:47:13,200 --> 00:47:17,119
this is the final bit which is we'd like

1373
00:47:15,119 --> 00:47:18,960
to deploy these robots in places around

1374
00:47:17,119 --> 00:47:21,680
people and to that we need to have real

1375
00:47:18,960 --> 00:47:23,680
confidence that it will really work uh

1376
00:47:21,680 --> 00:47:25,760
in real world scenarios. Right? And

1377
00:47:23,680 --> 00:47:31,040
underlying all of that and I'll go back

1378
00:47:25,760 --> 00:47:34,319
to my origins is math, right? I mean

1379
00:47:31,040 --> 00:47:36,400
math is the great unifier. Uh math is

1380
00:47:34,319 --> 00:47:37,920
what makes it all work. And one simple

1381
00:47:36,400 --> 00:47:40,640
equation

1382
00:47:37,920 --> 00:47:44,119
can go a really long way. So with that,

1383
00:47:40,640 --> 00:47:44,119
thank you very much.


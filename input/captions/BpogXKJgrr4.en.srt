1
00:00:00,480 --> 00:00:05,600
Today I'm very excited to introduce

2
00:00:03,360 --> 00:00:09,519
Mahel Chudich who's going to talk about

3
00:00:05,600 --> 00:00:12,639
um AI in medicine from code to clinic.

4
00:00:09,519 --> 00:00:14,639
Uh Dr. Chudich is a T32 postdoctoral

5
00:00:12,639 --> 00:00:16,720
research fellow in precision in genomic

6
00:00:14,639 --> 00:00:19,199
medicine at the center for precision

7
00:00:16,720 --> 00:00:21,600
psychiatry at Mass General Hospital and

8
00:00:19,199 --> 00:00:23,920
Harvard Medical School. He is jointly

9
00:00:21,600 --> 00:00:26,640
mentored by Drs. Jordan Smaller and

10
00:00:23,920 --> 00:00:28,720
Elvis Price and he earned his PhD at the

11
00:00:26,640 --> 00:00:30,720
University of Oxford where he studied

12
00:00:28,720 --> 00:00:32,320
computer vision applications of visual

13
00:00:30,720 --> 00:00:34,880
neuroscience.

14
00:00:32,320 --> 00:00:36,880
His current research integrates AI and

15
00:00:34,880 --> 00:00:38,960
biomedical sciences with a particular

16
00:00:36,880 --> 00:00:41,440
emphasis on psychiatry, genetic and

17
00:00:38,960 --> 00:00:43,680
neuroscience. Um, and with that I

18
00:00:41,440 --> 00:00:46,320
welcome our speaker. Thank you.

19
00:00:43,680 --> 00:00:48,000
>> Well, thank you for having me. Uh this

20
00:00:46,320 --> 00:00:49,680
presentation is going to be a little bit

21
00:00:48,000 --> 00:00:51,760
different than the other primers because

22
00:00:49,680 --> 00:00:57,280
there's going to be a lot less genetics

23
00:00:51,760 --> 00:01:00,480
and a lot more AI. Um but to begin, I

24
00:00:57,280 --> 00:01:02,800
think when we talk about artificial

25
00:01:00,480 --> 00:01:05,760
intelligence, there's not really a clear

26
00:01:02,800 --> 00:01:08,960
definition of what AI is, and I'm

27
00:01:05,760 --> 00:01:13,439
definitely not an expert uh to be able

28
00:01:08,960 --> 00:01:15,600
to define it. So I think for the scope

29
00:01:13,439 --> 00:01:17,920
of this presentation and and the way

30
00:01:15,600 --> 00:01:20,720
that we use artificial intelligence in

31
00:01:17,920 --> 00:01:22,880
the mainstream I think really

32
00:01:20,720 --> 00:01:25,280
corresponds to maybe some key

33
00:01:22,880 --> 00:01:28,159
technological innovations.

34
00:01:25,280 --> 00:01:30,479
Um and we can look at the Google trends

35
00:01:28,159 --> 00:01:32,880
for artificial intelligence and there's

36
00:01:30,479 --> 00:01:36,000
certain spikes that maybe will key us in

37
00:01:32,880 --> 00:01:38,159
on uh what these innovations are. The

38
00:01:36,000 --> 00:01:41,360
most obvious one is the release of chat

39
00:01:38,159 --> 00:01:43,520
GPT in November 2022.

40
00:01:41,360 --> 00:01:45,840
Um once that was released, it felt like

41
00:01:43,520 --> 00:01:49,759
everybody was using the term artificial

42
00:01:45,840 --> 00:01:52,079
intelligence. And the technology that I

43
00:01:49,759 --> 00:01:55,360
think is central in artificial

44
00:01:52,079 --> 00:01:58,399
intelligence as we know it today is deep

45
00:01:55,360 --> 00:02:01,040
learning. So the structure of this

46
00:01:58,399 --> 00:02:04,079
primer um we'll talk a little bit about

47
00:02:01,040 --> 00:02:05,840
deep learning, what it is. Um I won't go

48
00:02:04,079 --> 00:02:07,600
too heavy in the mathematics but will

49
00:02:05,840 --> 00:02:10,399
give you a good introduction as to what

50
00:02:07,600 --> 00:02:12,160
deep learning is. Then we'll talk about

51
00:02:10,399 --> 00:02:14,800
convolutional neural networks,

52
00:02:12,160 --> 00:02:19,360
generative AI and self-supervised

53
00:02:14,800 --> 00:02:23,840
learning. So most of the data that we'll

54
00:02:19,360 --> 00:02:26,959
be talking about in this primer is on

55
00:02:23,840 --> 00:02:29,040
medical images. Uh why? because

56
00:02:26,959 --> 00:02:32,800
artificial intelligence

57
00:02:29,040 --> 00:02:36,239
um really I felt became what it is

58
00:02:32,800 --> 00:02:38,720
through its ability to tackle a lot of

59
00:02:36,239 --> 00:02:41,200
image data sets which easily translated

60
00:02:38,720 --> 00:02:42,400
into medical image data sets and then

61
00:02:41,200 --> 00:02:44,400
through then there were different

62
00:02:42,400 --> 00:02:47,519
applications that came about that we'll

63
00:02:44,400 --> 00:02:49,680
talk about in a little bit but images

64
00:02:47,519 --> 00:02:52,400
were really the foundation for where

65
00:02:49,680 --> 00:02:55,519
artificial intelligence built off of and

66
00:02:52,400 --> 00:02:58,239
also there's some like it's very easy to

67
00:02:55,519 --> 00:03:00,720
understand through just the images

68
00:02:58,239 --> 00:03:03,360
themselves as to what these AI systems

69
00:03:00,720 --> 00:03:06,319
are doing rather than maybe just seeing

70
00:03:03,360 --> 00:03:08,879
some metric performance and and seeing

71
00:03:06,319 --> 00:03:12,319
how that's optimized.

72
00:03:08,879 --> 00:03:15,920
So to begin um we let's start with deep

73
00:03:12,319 --> 00:03:18,000
learning. What is it? Well, in some ways

74
00:03:15,920 --> 00:03:21,760
it's just a really complicated way to

75
00:03:18,000 --> 00:03:23,519
fit a line. You have an input which are

76
00:03:21,760 --> 00:03:27,519
just some numbers and you have an

77
00:03:23,519 --> 00:03:30,400
output. Uh and and those uh inputs can

78
00:03:27,519 --> 00:03:33,040
be maybe pixels in an image. It could be

79
00:03:30,400 --> 00:03:36,400
the voltage of an audio waveform. It

80
00:03:33,040 --> 00:03:38,239
could be a board game state. Um you also

81
00:03:36,400 --> 00:03:41,599
have an output which are just other

82
00:03:38,239 --> 00:03:44,159
numbers. And those other numbers can be

83
00:03:41,599 --> 00:03:46,480
a boolean to determine whether

84
00:03:44,159 --> 00:03:49,440
something's true or false. It could be

85
00:03:46,480 --> 00:03:51,760
text. It could be a future board game

86
00:03:49,440 --> 00:03:54,159
state. And then there's this mapping

87
00:03:51,760 --> 00:03:56,080
function that we're trying to learn. And

88
00:03:54,159 --> 00:03:58,799
that mapping function could be a dog

89
00:03:56,080 --> 00:04:01,439
classifier. It could be a speechtoext

90
00:03:58,799 --> 00:04:03,200
algorithm or it could maybe be a chess

91
00:04:01,439 --> 00:04:05,680
AI.

92
00:04:03,200 --> 00:04:08,400
And what essentially

93
00:04:05,680 --> 00:04:11,599
deep learning is trying to do like any

94
00:04:08,400 --> 00:04:14,959
learning optimization algorithm

95
00:04:11,599 --> 00:04:17,199
um it essentially has some initial

96
00:04:14,959 --> 00:04:19,680
parameters. is tries to see how

97
00:04:17,199 --> 00:04:21,840
accurately it can predict um the thing

98
00:04:19,680 --> 00:04:24,000
that it wants it to predict and then it

99
00:04:21,840 --> 00:04:25,759
slowly changes the parameters of the

100
00:04:24,000 --> 00:04:28,560
model to get closer and closer to the

101
00:04:25,759 --> 00:04:32,320
outcome that we care about.

102
00:04:28,560 --> 00:04:33,680
And uh this is very similar to linear

103
00:04:32,320 --> 00:04:36,000
regression, something that I'm sure

104
00:04:33,680 --> 00:04:38,800
we're all familiar with um with

105
00:04:36,000 --> 00:04:41,120
genomewide association studies, but just

106
00:04:38,800 --> 00:04:43,280
as a refresher for linear regression, we

107
00:04:41,120 --> 00:04:47,199
can just view it as maybe a slope and a

108
00:04:43,280 --> 00:04:49,360
bias. And then um we can try to optimize

109
00:04:47,199 --> 00:04:52,000
that based on some cost function. So

110
00:04:49,360 --> 00:04:53,759
that's a penalty to determine how poorly

111
00:04:52,000 --> 00:04:57,280
your model is doing. In this case, it's

112
00:04:53,759 --> 00:05:00,720
mean squared error. And then um in a

113
00:04:57,280 --> 00:05:04,240
gradient descent algorithm where you uh

114
00:05:00,720 --> 00:05:06,880
just slowly adjust these parameters,

115
00:05:04,240 --> 00:05:09,759
there's a learning rate and a learning

116
00:05:06,880 --> 00:05:12,479
um equation to to adjust the parameters

117
00:05:09,759 --> 00:05:16,160
over time. And we can see on the image

118
00:05:12,479 --> 00:05:19,759
in the the right how this line slowly

119
00:05:16,160 --> 00:05:21,520
changes to best fit the data points. And

120
00:05:19,759 --> 00:05:23,759
in a lot of ways, this is what deep

121
00:05:21,520 --> 00:05:25,440
learning is doing. Maybe not over two

122
00:05:23,759 --> 00:05:27,840
parameters, maybe over billions of

123
00:05:25,440 --> 00:05:30,080
parameters, but this is a very similar

124
00:05:27,840 --> 00:05:32,880
concept.

125
00:05:30,080 --> 00:05:35,680
And in data science, I think we are all

126
00:05:32,880 --> 00:05:37,680
familiar with this. Um, we can have

127
00:05:35,680 --> 00:05:40,160
maybe models that are underfit to the

128
00:05:37,680 --> 00:05:42,320
solution. So maybe the solution that we

129
00:05:40,160 --> 00:05:45,759
want to know is quite complex but we

130
00:05:42,320 --> 00:05:49,280
have uh less number of parameters that

131
00:05:45,759 --> 00:05:52,639
we need to um solve the problem

132
00:05:49,280 --> 00:05:55,120
accurately. Uh alternatively maybe we

133
00:05:52,639 --> 00:05:58,000
introduce more parameters into the model

134
00:05:55,120 --> 00:05:59,600
and uh we get a really really good fit

135
00:05:58,000 --> 00:06:01,360
on the training data but we don't

136
00:05:59,600 --> 00:06:02,880
necessarily learn the underlying

137
00:06:01,360 --> 00:06:04,319
distribution because we're overfitting

138
00:06:02,880 --> 00:06:07,919
to the training data and it doesn't

139
00:06:04,319 --> 00:06:10,880
create a general uh solution. And then

140
00:06:07,919 --> 00:06:13,120
ideally we would want a perfect balance

141
00:06:10,880 --> 00:06:15,600
of these parameters to maximally fit

142
00:06:13,120 --> 00:06:18,560
this data in a way that can generalize

143
00:06:15,600 --> 00:06:20,160
quite well. But understanding what is

144
00:06:18,560 --> 00:06:22,960
this balance of the number of parameters

145
00:06:20,160 --> 00:06:25,759
that we need that's that's quite tricky.

146
00:06:22,960 --> 00:06:27,360
So when we think about artificial

147
00:06:25,759 --> 00:06:30,000
intelligence

148
00:06:27,360 --> 00:06:32,240
um one way to think about it is how do

149
00:06:30,000 --> 00:06:35,199
we make decisions? How do we know

150
00:06:32,240 --> 00:06:38,880
whether a case or a patient has a

151
00:06:35,199 --> 00:06:41,600
certain condition? How do we know um

152
00:06:38,880 --> 00:06:45,120
whether a certain pixel in an image is

153
00:06:41,600 --> 00:06:47,440
that of a a tumor? And one way we can

154
00:06:45,120 --> 00:06:49,600
think about it, a very simple example is

155
00:06:47,440 --> 00:06:51,120
just a classification problem where you

156
00:06:49,600 --> 00:06:52,560
have some data points that belong to

157
00:06:51,120 --> 00:06:56,479
class one, you have some data points

158
00:06:52,560 --> 00:06:58,080
that belong to class two. And um the

159
00:06:56,479 --> 00:07:01,440
first

160
00:06:58,080 --> 00:07:03,680
uh solution to this and and kind of the

161
00:07:01,440 --> 00:07:06,080
the start of artificial intelligence

162
00:07:03,680 --> 00:07:10,000
came from this unit called the

163
00:07:06,080 --> 00:07:12,560
perceptron which was a model of just how

164
00:07:10,000 --> 00:07:15,120
neurons operate in the brain and action

165
00:07:12,560 --> 00:07:18,560
potentials where it integrates

166
00:07:15,120 --> 00:07:20,080
information and if the in uh information

167
00:07:18,560 --> 00:07:21,759
integrated doesn't reach a certain

168
00:07:20,080 --> 00:07:24,800
threshold then it won't fire but if it

169
00:07:21,759 --> 00:07:27,919
surpasses that threshold it will fire.

170
00:07:24,800 --> 00:07:30,560
Um, and that is kind of summarized by

171
00:07:27,919 --> 00:07:32,560
you have some inputs, you multiply it by

172
00:07:30,560 --> 00:07:34,160
some weights, you add everything

173
00:07:32,560 --> 00:07:36,000
together, and then you have this

174
00:07:34,160 --> 00:07:38,800
activation function, which in this case

175
00:07:36,000 --> 00:07:40,800
is a step function.

176
00:07:38,800 --> 00:07:42,400
Um, now maybe we can change it into

177
00:07:40,800 --> 00:07:44,080
something a little bit more familiar. We

178
00:07:42,400 --> 00:07:46,319
can replace that step function with the

179
00:07:44,080 --> 00:07:49,919
sigmoid function. And we can see that

180
00:07:46,319 --> 00:07:51,280
this equation then becomes a logistic

181
00:07:49,919 --> 00:07:54,240
regression. And this is something we

182
00:07:51,280 --> 00:07:56,240
should be familiar with.

183
00:07:54,240 --> 00:07:58,240
Now

184
00:07:56,240 --> 00:08:00,240
logistic regression can solve some

185
00:07:58,240 --> 00:08:03,360
problems but obviously there are more

186
00:08:00,240 --> 00:08:06,560
complex problems we would like uh a

187
00:08:03,360 --> 00:08:09,599
classification solution to have um to be

188
00:08:06,560 --> 00:08:12,400
able to solve. So linear reg um logistic

189
00:08:09,599 --> 00:08:14,879
regression is really good at solving um

190
00:08:12,400 --> 00:08:17,360
problems where the classes are linearly

191
00:08:14,879 --> 00:08:19,599
separable. But if we see on the example

192
00:08:17,360 --> 00:08:21,840
on the right the continuous exor problem

193
00:08:19,599 --> 00:08:25,120
where the upper right and the lower

194
00:08:21,840 --> 00:08:28,160
right uh quadrants are one class and

195
00:08:25,120 --> 00:08:31,759
then the upper left and the lower right

196
00:08:28,160 --> 00:08:33,760
quadrants are belong to another class.

197
00:08:31,759 --> 00:08:35,279
Uh one line is not sufficient to

198
00:08:33,760 --> 00:08:38,399
separate this data. So we need something

199
00:08:35,279 --> 00:08:41,120
more complex. Now one solution might be

200
00:08:38,399 --> 00:08:44,720
okay maybe we can add essentially

201
00:08:41,120 --> 00:08:46,720
another perceptron to that layer and

202
00:08:44,720 --> 00:08:49,360
have a perceptron that integrates the

203
00:08:46,720 --> 00:08:54,480
previous two perceptrons and that can

204
00:08:49,360 --> 00:08:56,320
give us a solution but it does better

205
00:08:54,480 --> 00:08:58,480
but maybe it's not the solution that we

206
00:08:56,320 --> 00:09:01,279
think of in our head.

207
00:08:58,480 --> 00:09:04,160
So another possible thing that we can do

208
00:09:01,279 --> 00:09:06,240
is we continue adding perceptrons. And

209
00:09:04,160 --> 00:09:08,800
this is called a multi-layer perceptron

210
00:09:06,240 --> 00:09:11,120
in MLP. And this is where we start to

211
00:09:08,800 --> 00:09:12,880
get to the birth of deep learning

212
00:09:11,120 --> 00:09:14,160
because we realize we can just make

213
00:09:12,880 --> 00:09:16,080
things bigger. And if we make things

214
00:09:14,160 --> 00:09:18,800
bigger, then we start getting to more

215
00:09:16,080 --> 00:09:21,440
complex solutions. But of course, the

216
00:09:18,800 --> 00:09:23,360
complexity of these problems can keep on

217
00:09:21,440 --> 00:09:24,720
expanding. And if we see the problem all

218
00:09:23,360 --> 00:09:28,480
the way to the right, maybe it's not

219
00:09:24,720 --> 00:09:31,680
entirely clear what the solution is. Um

220
00:09:28,480 --> 00:09:34,399
and to go about this what uh deep

221
00:09:31,680 --> 00:09:36,880
learning tries to do is it not only

222
00:09:34,399 --> 00:09:40,080
increases the width of the network by

223
00:09:36,880 --> 00:09:44,399
adding more vertical units stack units

224
00:09:40,080 --> 00:09:46,160
but also adds more depth. So more layers

225
00:09:44,399 --> 00:09:48,800
of perceptrons

226
00:09:46,160 --> 00:09:52,160
and when you keep on stacking these

227
00:09:48,800 --> 00:09:55,040
perceptrons you enable more more complex

228
00:09:52,160 --> 00:09:59,120
solutions to be learned. So deep

229
00:09:55,040 --> 00:10:01,440
learning essentially is just

230
00:09:59,120 --> 00:10:03,920
logistic regressions and multiple of

231
00:10:01,440 --> 00:10:06,880
them in stacked in multiple different

232
00:10:03,920 --> 00:10:08,720
ways. Over time we figured out ways uh

233
00:10:06,880 --> 00:10:10,800
to optimize it more efficiently moving

234
00:10:08,720 --> 00:10:13,279
away from just a sigmoid function to

235
00:10:10,800 --> 00:10:16,959
some other activation units. But this is

236
00:10:13,279 --> 00:10:20,560
the basis of deep learning. And kind of

237
00:10:16,959 --> 00:10:22,320
the main rule of thumb was the more data

238
00:10:20,560 --> 00:10:24,720
you have, the bigger models you can

239
00:10:22,320 --> 00:10:26,880
train, the more complex solutions you

240
00:10:24,720 --> 00:10:29,120
can learn and the better performance you

241
00:10:26,880 --> 00:10:31,200
have overall. And one of the main

242
00:10:29,120 --> 00:10:33,279
drivers for all this technological

243
00:10:31,200 --> 00:10:36,640
innovation that we see is really

244
00:10:33,279 --> 00:10:38,560
propelled by the idea that data keeps on

245
00:10:36,640 --> 00:10:40,160
expanding in our society. We keep on

246
00:10:38,560 --> 00:10:42,800
collecting more and more data so we can

247
00:10:40,160 --> 00:10:45,279
train these bigger and bigger models. So

248
00:10:42,800 --> 00:10:48,399
in the early days of AI, as you'll see,

249
00:10:45,279 --> 00:10:50,880
a lot of what was being done to increase

250
00:10:48,399 --> 00:10:54,079
performance was just to find ways to

251
00:10:50,880 --> 00:10:57,120
continue stacking these networks.

252
00:10:54,079 --> 00:11:00,079
And that brings us to uh convolutional

253
00:10:57,120 --> 00:11:02,720
neural networks. Not always will it work

254
00:11:00,079 --> 00:11:04,880
just to increase the size of these

255
00:11:02,720 --> 00:11:07,040
networks. Sometimes it requires certain

256
00:11:04,880 --> 00:11:09,600
architectural advancements

257
00:11:07,040 --> 00:11:12,160
uh depending on the domain that you're

258
00:11:09,600 --> 00:11:15,680
in. So convolutional neural networks

259
00:11:12,160 --> 00:11:19,120
were what was developed for images and

260
00:11:15,680 --> 00:11:21,279
started uh maybe its first applications

261
00:11:19,120 --> 00:11:23,040
in medicine.

262
00:11:21,279 --> 00:11:29,600
And what a convolutional neural network

263
00:11:23,040 --> 00:11:32,000
does is it realizes that um an image has

264
00:11:29,600 --> 00:11:34,320
translation and variance meaning that if

265
00:11:32,000 --> 00:11:37,120
you take an image of a dog and you shift

266
00:11:34,320 --> 00:11:40,480
that dog a little bit the classification

267
00:11:37,120 --> 00:11:42,640
of that image doesn't change. Whereas if

268
00:11:40,480 --> 00:11:44,160
you were to take that image and you were

269
00:11:42,640 --> 00:11:46,240
to flat it into a vector, you're going

270
00:11:44,160 --> 00:11:47,680
to lose all that spatial information of

271
00:11:46,240 --> 00:11:50,560
that image. So what a convolutional

272
00:11:47,680 --> 00:11:53,680
neural network does is instead of just

273
00:11:50,560 --> 00:11:57,680
having a a one-dimensional vector where

274
00:11:53,680 --> 00:12:00,000
it multiplies the weights of of the um

275
00:11:57,680 --> 00:12:02,880
multiplies the pixels by weights what it

276
00:12:00,000 --> 00:12:06,240
does is it takes the matrix it creates

277
00:12:02,880 --> 00:12:08,000
it into a 2D matrix and it sec

278
00:12:06,240 --> 00:12:09,519
throughout the entire image or it

279
00:12:08,000 --> 00:12:12,079
convolves throughout the entire image

280
00:12:09,519 --> 00:12:13,519
and it tries to find features at any

281
00:12:12,079 --> 00:12:15,279
location throughout the image. So you

282
00:12:13,519 --> 00:12:17,680
can imagine if it's trying to figure out

283
00:12:15,279 --> 00:12:20,079
a dog face, it doesn't matter whether

284
00:12:17,680 --> 00:12:21,760
that face of the dog is in the top left

285
00:12:20,079 --> 00:12:24,959
of the image or the bottom right of the

286
00:12:21,760 --> 00:12:26,880
image. It's translation invariant. So

287
00:12:24,959 --> 00:12:29,200
that was a really key technological

288
00:12:26,880 --> 00:12:33,200
innovation that allowed for image

289
00:12:29,200 --> 00:12:36,240
processing to really become what uh it

290
00:12:33,200 --> 00:12:38,480
to to have the success that it has had.

291
00:12:36,240 --> 00:12:40,800
And also there were just massive amounts

292
00:12:38,480 --> 00:12:44,720
of data that was widely available to

293
00:12:40,800 --> 00:12:47,040
start developing these algorithms. So um

294
00:12:44,720 --> 00:12:49,519
this was a really popular data set and

295
00:12:47,040 --> 00:12:52,639
still is. It's called ImageNet. It's 1.2

296
00:12:49,519 --> 00:12:56,320
million images. It has over 1,000 object

297
00:12:52,639 --> 00:12:58,320
classifications. The images are RGB. So

298
00:12:56,320 --> 00:12:59,839
um they're just natural scene images.

299
00:12:58,320 --> 00:13:01,600
And it's easy to collect this data

300
00:12:59,839 --> 00:13:03,680
because you can just kind of do a Google

301
00:13:01,600 --> 00:13:06,320
search, type dog, and then maybe

302
00:13:03,680 --> 00:13:08,000
download the top 10 dog images and that

303
00:13:06,320 --> 00:13:09,920
could be your part of your training data

304
00:13:08,000 --> 00:13:13,519
set.

305
00:13:09,920 --> 00:13:16,720
And um what ended up happening to to

306
00:13:13,519 --> 00:13:19,760
really excel on this data set uh there

307
00:13:16,720 --> 00:13:22,639
were a lot of different perturbations to

308
00:13:19,760 --> 00:13:25,519
architectures some of which included

309
00:13:22,639 --> 00:13:28,160
expanding the architectural complexity.

310
00:13:25,519 --> 00:13:31,360
So what you see in this figure on the x-

311
00:13:28,160 --> 00:13:33,519
axis is the number of operations that

312
00:13:31,360 --> 00:13:37,360
this architecture uses to compute its

313
00:13:33,519 --> 00:13:40,079
final output on the y- ais is the

314
00:13:37,360 --> 00:13:42,880
performance on imageet and you see this

315
00:13:40,079 --> 00:13:45,279
trend where if the architecture is per

316
00:13:42,880 --> 00:13:48,720
um performing more operations it

317
00:13:45,279 --> 00:13:51,600
typically does better on this data set.

318
00:13:48,720 --> 00:13:52,959
So in some ways maybe not exactly true

319
00:13:51,600 --> 00:13:55,360
but like the more complex the

320
00:13:52,959 --> 00:13:58,079
architecture the better it is but

321
00:13:55,360 --> 00:14:00,560
obviously that's dependent on the

322
00:13:58,079 --> 00:14:03,040
availability of large amounts of data

323
00:14:00,560 --> 00:14:05,680
and that simply is just not the case in

324
00:14:03,040 --> 00:14:08,160
medical imaging. There's different

325
00:14:05,680 --> 00:14:10,480
problems that happen when we apply

326
00:14:08,160 --> 00:14:13,279
machine learning and AI technology into

327
00:14:10,480 --> 00:14:16,079
medicine. First of all medical images

328
00:14:13,279 --> 00:14:18,320
can be a lot noisier than natural scene

329
00:14:16,079 --> 00:14:20,240
images. medical images are

330
00:14:18,320 --> 00:14:23,600
three-dimensional when we think of MRI

331
00:14:20,240 --> 00:14:26,399
or CT scans and just the quantity of

332
00:14:23,600 --> 00:14:29,519
data is significantly smaller than what

333
00:14:26,399 --> 00:14:33,040
we can see for just regular applications

334
00:14:29,519 --> 00:14:36,320
of AI um because we can't just download

335
00:14:33,040 --> 00:14:40,480
you know a 100,000 MRI images.

336
00:14:36,320 --> 00:14:43,519
So one technique that was really useful

337
00:14:40,480 --> 00:14:45,199
is this idea of pre-training

338
00:14:43,519 --> 00:14:49,760
architectures.

339
00:14:45,199 --> 00:14:52,560
So um when you train a convolutional

340
00:14:49,760 --> 00:14:55,839
neural network on natural scene images,

341
00:14:52,560 --> 00:14:58,720
some of the these perceptrons or these

342
00:14:55,839 --> 00:15:00,959
features that get encoded are really

343
00:14:58,720 --> 00:15:02,880
useful features for image processing.

344
00:15:00,959 --> 00:15:05,199
They can be edge detectors. They can be

345
00:15:02,880 --> 00:15:07,920
color opponency. There are these

346
00:15:05,199 --> 00:15:10,880
features that end up kind of compressing

347
00:15:07,920 --> 00:15:14,079
these images into a way that's a lot

348
00:15:10,880 --> 00:15:15,920
more trackable for later on layers to

349
00:15:14,079 --> 00:15:19,440
determine whether something is a dog or

350
00:15:15,920 --> 00:15:22,240
a cat. Um, but you can't learn these

351
00:15:19,440 --> 00:15:24,240
features as well if you play around and

352
00:15:22,240 --> 00:15:27,040
and train the architecture from scratch

353
00:15:24,240 --> 00:15:30,160
on a smaller amount of data. So what

354
00:15:27,040 --> 00:15:33,440
pre-training does is it says okay well

355
00:15:30,160 --> 00:15:36,000
maybe we can take advantage of these uh

356
00:15:33,440 --> 00:15:39,040
publicly available large data sets and

357
00:15:36,000 --> 00:15:43,600
we can train an architecture on that and

358
00:15:39,040 --> 00:15:47,600
then we kind of breeze the early and

359
00:15:43,600 --> 00:15:50,720
middle parameters and we simply retrain

360
00:15:47,600 --> 00:15:52,800
the final layers of that architecture on

361
00:15:50,720 --> 00:15:53,920
the domain that we care about. So in

362
00:15:52,800 --> 00:15:55,120
this way you're kind of getting the best

363
00:15:53,920 --> 00:15:57,759
of both worlds. you're getting the

364
00:15:55,120 --> 00:15:59,839
feature extractors uh using large

365
00:15:57,759 --> 00:16:01,279
amounts of data um but you're also

366
00:15:59,839 --> 00:16:02,880
fine-tuning you're adjusting this

367
00:16:01,279 --> 00:16:05,360
architecture to your specific

368
00:16:02,880 --> 00:16:08,720
application and this is when we start

369
00:16:05,360 --> 00:16:11,199
seeing its utility in medicine so I

370
00:16:08,720 --> 00:16:13,680
think one of the seminal papers in

371
00:16:11,199 --> 00:16:15,920
medical AI was this paper in nature

372
00:16:13,680 --> 00:16:19,199
looking at dermatological images and

373
00:16:15,920 --> 00:16:22,560
trying to classify the different uh skin

374
00:16:19,199 --> 00:16:26,079
conditions and its malignancy it had

375
00:16:22,560 --> 00:16:28,560
129,000 clinical images of over 2,000

376
00:16:26,079 --> 00:16:30,720
different diseases. Uh it used an

377
00:16:28,560 --> 00:16:34,320
inception model which was something that

378
00:16:30,720 --> 00:16:36,000
was shown on the previous graph. Um but

379
00:16:34,320 --> 00:16:39,360
interestingly it was pre-trained on

380
00:16:36,000 --> 00:16:42,000
imageet. Why? Because if the features

381
00:16:39,360 --> 00:16:44,639
are useful for natural scene images just

382
00:16:42,000 --> 00:16:48,399
like as humans we've evolved to be able

383
00:16:44,639 --> 00:16:51,360
to adapt and and go through the world

384
00:16:48,399 --> 00:16:54,639
and natural scenes. um it might be

385
00:16:51,360 --> 00:16:56,480
useful to detect skin lesions and that

386
00:16:54,639 --> 00:16:59,279
ends up being the case and when you do

387
00:16:56,480 --> 00:17:01,600
that pre-training um what they were able

388
00:16:59,279 --> 00:17:05,039
to show is that performance was on par

389
00:17:01,600 --> 00:17:06,720
with all uh tested experts. So this was

390
00:17:05,039 --> 00:17:09,760
when it was starting to challenge the

391
00:17:06,720 --> 00:17:12,160
narrative that that maybe AI can do as

392
00:17:09,760 --> 00:17:16,079
well as clinicians.

393
00:17:12,160 --> 00:17:20,400
Now similarly um this was an

394
00:17:16,079 --> 00:17:25,120
architecture used for radiology um to

395
00:17:20,400 --> 00:17:27,360
pick up pneumonia and yeah I think maybe

396
00:17:25,120 --> 00:17:28,799
in the mainstream people were saying

397
00:17:27,360 --> 00:17:30,640
that AI was going to come for

398
00:17:28,799 --> 00:17:32,880
radiologists. I think this was one of

399
00:17:30,640 --> 00:17:34,880
the papers that started that trajectory

400
00:17:32,880 --> 00:17:37,679
and essentially it's 10,000 X-ray

401
00:17:34,880 --> 00:17:39,919
images. In this case, they have a custom

402
00:17:37,679 --> 00:17:42,960
convolutional neural network. Um, but

403
00:17:39,919 --> 00:17:45,520
again, it's pre-trained on imageet and

404
00:17:42,960 --> 00:17:47,760
uh this architecture exceeds the average

405
00:17:45,520 --> 00:17:49,440
performance of radiologists.

406
00:17:47,760 --> 00:17:51,039
So, what's really interesting about this

407
00:17:49,440 --> 00:17:53,760
architecture as well is not only does it

408
00:17:51,039 --> 00:17:57,039
give a classification, but it kind of

409
00:17:53,760 --> 00:17:59,440
helps localize where the important

410
00:17:57,039 --> 00:18:01,280
regions of that image is. And the way

411
00:17:59,440 --> 00:18:02,720
that it's able to do this is as

412
00:18:01,280 --> 00:18:04,960
convolutional neural networks, as I

413
00:18:02,720 --> 00:18:07,280
explained prior, it's cicading through

414
00:18:04,960 --> 00:18:10,320
the entire image. In parts of the image,

415
00:18:07,280 --> 00:18:12,000
the uh architecture, the convolutional

416
00:18:10,320 --> 00:18:13,600
neural network isn't really doing much.

417
00:18:12,000 --> 00:18:16,000
There's not a lot of activation of these

418
00:18:13,600 --> 00:18:18,480
perceptrons, but in other parts of the

419
00:18:16,000 --> 00:18:20,880
image, there is a lot of activity. And

420
00:18:18,480 --> 00:18:22,400
the basic idea is if there's a lot of

421
00:18:20,880 --> 00:18:23,760
activity in that part of the image, then

422
00:18:22,400 --> 00:18:25,840
there's something that the architecture

423
00:18:23,760 --> 00:18:27,840
is finding interesting. there's probably

424
00:18:25,840 --> 00:18:31,760
something that maybe clinicians should

425
00:18:27,840 --> 00:18:34,480
pay closer attention to. Um, so that's

426
00:18:31,760 --> 00:18:36,480
one way of localizing regions of

427
00:18:34,480 --> 00:18:39,919
interest in an image, but we can kind of

428
00:18:36,480 --> 00:18:42,240
formalize it more explicitly through uh

429
00:18:39,919 --> 00:18:44,000
image segmentation. So this is an

430
00:18:42,240 --> 00:18:46,160
architecture called fully convolutional

431
00:18:44,000 --> 00:18:48,559
neural networks. Instead of just

432
00:18:46,160 --> 00:18:50,559
outputting one class for the entire

433
00:18:48,559 --> 00:18:52,880
image, what it does is it outputs a

434
00:18:50,559 --> 00:18:56,000
classification for every pixel in the

435
00:18:52,880 --> 00:18:58,000
image. And what you can see here, it

436
00:18:56,000 --> 00:19:00,080
kind of is able to segment the

437
00:18:58,000 --> 00:19:03,120
differences between the dog and the cat

438
00:19:00,080 --> 00:19:05,039
and the background. And uh unlike the

439
00:19:03,120 --> 00:19:08,080
previous architectures where maybe

440
00:19:05,039 --> 00:19:10,480
there's a hybrid between convolutional

441
00:19:08,080 --> 00:19:12,240
uh layers and fully connected layers or

442
00:19:10,480 --> 00:19:14,640
dense layers, this is fully

443
00:19:12,240 --> 00:19:16,480
convolutional. So um the entire

444
00:19:14,640 --> 00:19:18,720
architecture is just like essentially

445
00:19:16,480 --> 00:19:20,240
going pixel by pixel and and classifying

446
00:19:18,720 --> 00:19:22,240
or

447
00:19:20,240 --> 00:19:25,280
patches of the image by patches of the

448
00:19:22,240 --> 00:19:27,039
images and and classifying.

449
00:19:25,280 --> 00:19:29,360
And you can imagine this is incredibly

450
00:19:27,039 --> 00:19:32,160
useful in medicine. But there are

451
00:19:29,360 --> 00:19:34,559
additional technological limitations for

452
00:19:32,160 --> 00:19:36,960
its application in medicine. One being

453
00:19:34,559 --> 00:19:41,200
that medical images are just a lot

454
00:19:36,960 --> 00:19:43,919
bigger and that's problematic because

455
00:19:41,200 --> 00:19:46,400
just there's memory constraints for a

456
00:19:43,919 --> 00:19:50,960
GPU or a graphical processing unit. One

457
00:19:46,400 --> 00:19:54,880
of the key hardwares that's needed in um

458
00:19:50,960 --> 00:19:56,559
um medical AI or AI in general. And uh

459
00:19:54,880 --> 00:19:59,360
this architecture came out it's called

460
00:19:56,559 --> 00:20:01,440
the UNET. What it does quite well, and I

461
00:19:59,360 --> 00:20:04,799
don't want to go into too much detail,

462
00:20:01,440 --> 00:20:08,559
is it found a way to efficiently

463
00:20:04,799 --> 00:20:12,880
represent really high-level

464
00:20:08,559 --> 00:20:14,799
global features of that image um in a

465
00:20:12,880 --> 00:20:18,000
very lowdimensional space. So very

466
00:20:14,799 --> 00:20:20,320
memory efficient uh embedding. So you

467
00:20:18,000 --> 00:20:23,200
can imagine it might be important in an

468
00:20:20,320 --> 00:20:25,440
MRI image to know which part of the head

469
00:20:23,200 --> 00:20:28,240
you're looking at. Um obviously that

470
00:20:25,440 --> 00:20:29,679
spans multiple pixels and it's not

471
00:20:28,240 --> 00:20:32,400
efficient to store that in multiple

472
00:20:29,679 --> 00:20:35,440
pixels. Um but a unit tries to compress

473
00:20:32,400 --> 00:20:39,200
that. And what we see on the right are

474
00:20:35,440 --> 00:20:42,080
just some examples of more biomedical

475
00:20:39,200 --> 00:20:46,000
applications of just segmentations of

476
00:20:42,080 --> 00:20:48,640
different cells. Um obviously we can

477
00:20:46,000 --> 00:20:50,960
take this a step further. we can uh

478
00:20:48,640 --> 00:20:52,720
instead of just having 2D convolutions

479
00:20:50,960 --> 00:20:55,600
and just looking at images, we can

480
00:20:52,720 --> 00:20:58,480
instead look at 3D images and the way we

481
00:20:55,600 --> 00:21:00,080
do that is replace 2D convolutions by 3D

482
00:20:58,480 --> 00:21:02,320
convolutions.

483
00:21:00,080 --> 00:21:06,640
And what we see on the right is a

484
00:21:02,320 --> 00:21:09,280
conffocal image of a frog kidney and um

485
00:21:06,640 --> 00:21:13,360
and and the right panel of that is the

486
00:21:09,280 --> 00:21:15,280
3D reconstruction of that kidney.

487
00:21:13,360 --> 00:21:17,840
And you can imagine that the

488
00:21:15,280 --> 00:21:21,520
applications here in medicine are quite

489
00:21:17,840 --> 00:21:23,760
quite big. Um there's constant iteration

490
00:21:21,520 --> 00:21:26,240
of these architectures. This paper tries

491
00:21:23,760 --> 00:21:28,960
to come up with just a general approach

492
00:21:26,240 --> 00:21:32,480
to dealing with all these uh imaging

493
00:21:28,960 --> 00:21:34,880
data sets. But you can kind of uh do

494
00:21:32,480 --> 00:21:37,600
vascular segmentation, you can do tumor

495
00:21:34,880 --> 00:21:40,720
segmentation. All of this is of interest

496
00:21:37,600 --> 00:21:43,120
to clinicians.

497
00:21:40,720 --> 00:21:46,159
And one application I I find really

498
00:21:43,120 --> 00:21:48,000
interesting was the ability to do neural

499
00:21:46,159 --> 00:21:49,520
circuit reconstruction. So if you're

500
00:21:48,000 --> 00:21:53,200
studying parts of the brain, brain

501
00:21:49,520 --> 00:21:56,080
tissue, uh you can get an EM block of

502
00:21:53,200 --> 00:21:58,799
that brain tissue. Um and you can see

503
00:21:56,080 --> 00:22:00,720
the edges of the neurons

504
00:21:58,799 --> 00:22:03,039
uh but you can imagine just how much

505
00:22:00,720 --> 00:22:04,640
data is there. So they were able to use

506
00:22:03,039 --> 00:22:07,679
convolutional neural networks to

507
00:22:04,640 --> 00:22:10,080
essentially follow the neuron throughout

508
00:22:07,679 --> 00:22:12,480
its entirety and kind of reconstruct it

509
00:22:10,080 --> 00:22:14,400
as a 3D object. And on the right you see

510
00:22:12,480 --> 00:22:17,440
the reconstruction of the neuropill.

511
00:22:14,400 --> 00:22:20,480
This was first done in the mouse retina,

512
00:22:17,440 --> 00:22:24,400
but they also done it in the fly brain

513
00:22:20,480 --> 00:22:30,320
and I think as well as the human brain.

514
00:22:24,400 --> 00:22:31,840
Um, and now we're at generative AI.

515
00:22:30,320 --> 00:22:35,520
um

516
00:22:31,840 --> 00:22:39,440
and it's a little bit different than

517
00:22:35,520 --> 00:22:41,919
um supervised learning and it's harder

518
00:22:39,440 --> 00:22:44,000
to define in some ways. In supervised

519
00:22:41,919 --> 00:22:47,840
learning, you essentially have some

520
00:22:44,000 --> 00:22:50,640
input like an image and uh you have a

521
00:22:47,840 --> 00:22:52,400
mapping function to some output that you

522
00:22:50,640 --> 00:22:54,880
care about that can be a completely

523
00:22:52,400 --> 00:22:57,360
different domain like you know whether

524
00:22:54,880 --> 00:23:00,640
something's a dog or a cat, right? Um,

525
00:22:57,360 --> 00:23:05,200
but what generative AI tries to do is

526
00:23:00,640 --> 00:23:08,000
essentially create another type of data

527
00:23:05,200 --> 00:23:10,799
point in the domain that you care about.

528
00:23:08,000 --> 00:23:14,720
So in the way that I wrote it here, you

529
00:23:10,799 --> 00:23:17,760
have some variable Z. So this can be

530
00:23:14,720 --> 00:23:19,360
random noise or it can be you know a a

531
00:23:17,760 --> 00:23:22,000
different type of data and you have a

532
00:23:19,360 --> 00:23:25,039
mapping function that takes that laten

533
00:23:22,000 --> 00:23:30,159
embedding Z and maps it into a new data

534
00:23:25,039 --> 00:23:33,360
point X and this X prime uh it should be

535
00:23:30,159 --> 00:23:37,919
thought as belonging to the distribution

536
00:23:33,360 --> 00:23:39,360
of all other um like data points. This

537
00:23:37,919 --> 00:23:42,320
will make sense in the next couple

538
00:23:39,360 --> 00:23:46,799
slides. So let's say we want to create

539
00:23:42,320 --> 00:23:49,039
fake images of handwritten digits. So

540
00:23:46,799 --> 00:23:52,080
one of the key architectures which later

541
00:23:49,039 --> 00:23:54,880
got expanded to images um is called a

542
00:23:52,080 --> 00:23:57,039
generative adversarial network. And this

543
00:23:54,880 --> 00:23:59,520
is when people started becoming really

544
00:23:57,039 --> 00:24:01,679
creative with their cost functions and

545
00:23:59,520 --> 00:24:03,840
and really allowed the explosions of

546
00:24:01,679 --> 00:24:05,760
applications in AI. And what a

547
00:24:03,840 --> 00:24:08,000
generative adversarial network tries to

548
00:24:05,760 --> 00:24:10,080
do is it actually has two architectures

549
00:24:08,000 --> 00:24:12,480
that are competing against each other.

550
00:24:10,080 --> 00:24:16,159
You have one architecture that goes from

551
00:24:12,480 --> 00:24:17,840
random noise to some fake generated

552
00:24:16,159 --> 00:24:20,400
image. And then you have another

553
00:24:17,840 --> 00:24:22,559
architecture that is a discriminator

554
00:24:20,400 --> 00:24:24,400
that tries to determine whether the

555
00:24:22,559 --> 00:24:26,400
image it's seeing is from the real

556
00:24:24,400 --> 00:24:28,640
distribution or whether it's from the

557
00:24:26,400 --> 00:24:31,279
generated distribution. And these two

558
00:24:28,640 --> 00:24:33,440
architectures compete with one another.

559
00:24:31,279 --> 00:24:35,039
So that the generated the generator

560
00:24:33,440 --> 00:24:36,880
tries to come up with more and more

561
00:24:35,039 --> 00:24:40,960
realistic images. And then the

562
00:24:36,880 --> 00:24:43,919
discriminator needs to have uh in and um

563
00:24:40,960 --> 00:24:46,960
needs to learn how to discriminate

564
00:24:43,919 --> 00:24:49,120
between fake and real images. Um and

565
00:24:46,960 --> 00:24:51,520
when they compete, they eventually

566
00:24:49,120 --> 00:24:54,480
stabilize and you're left with this

567
00:24:51,520 --> 00:24:57,039
generator that's able to just produce a

568
00:24:54,480 --> 00:25:01,039
bunch of different fake images. So a

569
00:24:57,039 --> 00:25:03,520
very simple application of this is in

570
00:25:01,039 --> 00:25:08,080
uh handwritten digits but you can also

571
00:25:03,520 --> 00:25:09,760
imagine that um yeah it can be for you

572
00:25:08,080 --> 00:25:16,000
know natural scene images. It could be

573
00:25:09,760 --> 00:25:19,760
for faces. Um we can also

574
00:25:16,000 --> 00:25:22,640
uh kind of expand how we create these uh

575
00:25:19,760 --> 00:25:25,679
generated images. we can essentially

576
00:25:22,640 --> 00:25:28,880
condition what the generated images

577
00:25:25,679 --> 00:25:32,240
based off of some other version of that

578
00:25:28,880 --> 00:25:33,840
image. So in this conditional GAN um for

579
00:25:32,240 --> 00:25:35,919
image translation image to image

580
00:25:33,840 --> 00:25:38,000
translation we have a sketch of a boot

581
00:25:35,919 --> 00:25:41,120
and it's tasked to kind of create an

582
00:25:38,000 --> 00:25:43,440
image of that boot and the discriminator

583
00:25:41,120 --> 00:25:46,799
again needs to determine whether the

584
00:25:43,440 --> 00:25:49,039
sketch and the boot uh align with one

585
00:25:46,799 --> 00:25:52,720
another but also is a realistic

586
00:25:49,039 --> 00:25:54,880
representation of that translation.

587
00:25:52,720 --> 00:25:56,159
Um

588
00:25:54,880 --> 00:25:58,559
>> yes

589
00:25:56,159 --> 00:26:01,520
>> going back two slides I just want to

590
00:25:58,559 --> 00:26:03,679
understand the adversarial network. Um

591
00:26:01,520 --> 00:26:06,960
so with the discriminator the

592
00:26:03,679 --> 00:26:11,600
discriminator is working until

593
00:26:06,960 --> 00:26:13,440
the two computers are only until the

594
00:26:11,600 --> 00:26:15,440
generator is making things that the

595
00:26:13,440 --> 00:26:16,240
discriminator is just saying are real.

596
00:26:15,440 --> 00:26:21,200
Is that

597
00:26:16,240 --> 00:26:23,600
>> Yeah. I mean, so you can imagine like if

598
00:26:21,200 --> 00:26:26,880
the I mean they technically need to

599
00:26:23,600 --> 00:26:28,720
always be competitive and there these

600
00:26:26,880 --> 00:26:30,720
architectures are very unstable because

601
00:26:28,720 --> 00:26:33,679
if the generator becomes really really

602
00:26:30,720 --> 00:26:36,080
good at figuring out what is a fake

603
00:26:33,679 --> 00:26:40,240
image then the discriminator just

604
00:26:36,080 --> 00:26:42,960
doesn't have the ability to like learn

605
00:26:40,240 --> 00:26:45,600
as much and then it kind of is an easier

606
00:26:42,960 --> 00:26:47,919
test for the generator. So the generator

607
00:26:45,600 --> 00:26:51,520
ends up not being able to produce maybe

608
00:26:47,919 --> 00:26:53,919
the best images. So ideally uh they're

609
00:26:51,520 --> 00:26:56,159
training together and then there's a

610
00:26:53,919 --> 00:26:58,559
whole like literature on when to stop

611
00:26:56,159 --> 00:27:00,720
these two trainings, but they can

612
00:26:58,559 --> 00:27:02,400
diverge and that's really problematic.

613
00:27:00,720 --> 00:27:04,240
So you can also get the discriminator

614
00:27:02,400 --> 00:27:05,760
that ends up becoming so much better

615
00:27:04,240 --> 00:27:07,679
than the generator to the point where

616
00:27:05,760 --> 00:27:09,840
the generator is just unable to produce

617
00:27:07,679 --> 00:27:11,200
any images because whatever it puts out

618
00:27:09,840 --> 00:27:13,520
the discriminator is like no that's

619
00:27:11,200 --> 00:27:15,679
clearly fake. So ideally they're like

620
00:27:13,520 --> 00:27:18,480
learning together in a symbiotic

621
00:27:15,679 --> 00:27:19,760
relationship of sorts and if one starts

622
00:27:18,480 --> 00:27:22,720
doing much better than the other then it

623
00:27:19,760 --> 00:27:24,559
becomes problematic.

624
00:27:22,720 --> 00:27:28,120
Yeah. Yeah. Please ask questions if

625
00:27:24,559 --> 00:27:28,120
anybody has questions.

626
00:27:28,960 --> 00:27:33,120
So this is really cool. This is also an

627
00:27:31,120 --> 00:27:34,400
application of generative AI. It's a

628
00:27:33,120 --> 00:27:36,799
little bit of a different twist. This is

629
00:27:34,400 --> 00:27:40,400
called style transfer. And this idea is

630
00:27:36,799 --> 00:27:42,320
you have some image uh you know and you

631
00:27:40,400 --> 00:27:44,640
have the content of that image but you

632
00:27:42,320 --> 00:27:47,840
want to represent the content of that

633
00:27:44,640 --> 00:27:50,559
image um in a different style like Van

634
00:27:47,840 --> 00:27:52,720
Go star night and able the way that

635
00:27:50,559 --> 00:27:55,279
they're able to do this is to minimize

636
00:27:52,720 --> 00:27:57,360
the style loss constraint. There's a lot

637
00:27:55,279 --> 00:27:59,840
of mathematical jargon in here. I won't

638
00:27:57,360 --> 00:28:03,039
really explain it but this basic idea is

639
00:27:59,840 --> 00:28:04,880
to take um kind of this texture of one

640
00:28:03,039 --> 00:28:06,640
image and apply it to the content of

641
00:28:04,880 --> 00:28:09,600
another.

642
00:28:06,640 --> 00:28:13,919
And these ideas these concepts become

643
00:28:09,600 --> 00:28:17,520
really useful in medicine when we talk

644
00:28:13,919 --> 00:28:20,080
about harmonization. Uh so a huge issue

645
00:28:17,520 --> 00:28:23,279
in medical image analysis as you can

646
00:28:20,080 --> 00:28:25,279
imagine is uh the MRI images in one

647
00:28:23,279 --> 00:28:29,520
hospital can produce slightly different

648
00:28:25,279 --> 00:28:31,039
images than MR uh from an MRI at a

649
00:28:29,520 --> 00:28:33,679
different hospital. And when you try to

650
00:28:31,039 --> 00:28:35,840
do analysis uh you end up not

651
00:28:33,679 --> 00:28:38,320
necessarily picking out the features

652
00:28:35,840 --> 00:28:41,039
that you care about but rather just you

653
00:28:38,320 --> 00:28:43,440
stratify based on population differences

654
00:28:41,039 --> 00:28:47,120
between these two hospitals. So to be

655
00:28:43,440 --> 00:28:48,960
able to harmonize the different sites is

656
00:28:47,120 --> 00:28:50,720
really important when we start talking

657
00:28:48,960 --> 00:28:54,720
about metaanalyses.

658
00:28:50,720 --> 00:28:56,320
And there are more conventional or

659
00:28:54,720 --> 00:28:58,080
statistical approaches to do this. But

660
00:28:56,320 --> 00:29:02,080
we can also frame it as a deep learning

661
00:28:58,080 --> 00:29:06,799
problem where uh the top row are these

662
00:29:02,080 --> 00:29:08,880
images from some site and the bottom row

663
00:29:06,799 --> 00:29:12,080
are images from another site that we

664
00:29:08,880 --> 00:29:14,559
want the top row to look like. And the

665
00:29:12,080 --> 00:29:17,840
middle row is just essentially the same

666
00:29:14,559 --> 00:29:20,559
exact image uh from the top row but just

667
00:29:17,840 --> 00:29:22,720
in the style of the bottom row. So it's

668
00:29:20,559 --> 00:29:25,679
almost as if you're taking that patient

669
00:29:22,720 --> 00:29:27,919
and you're reimaging them in the

670
00:29:25,679 --> 00:29:31,799
hospital that uh you're going to do the

671
00:29:27,919 --> 00:29:31,799
primary analysis in.

672
00:29:32,000 --> 00:29:37,440
Um and this also becomes useful in

673
00:29:34,799 --> 00:29:40,000
something called domain adaptation.

674
00:29:37,440 --> 00:29:43,039
So let's say you essentially have two

675
00:29:40,000 --> 00:29:45,360
different types of image of the same

676
00:29:43,039 --> 00:29:48,399
concept. Let's say you have a PET scan

677
00:29:45,360 --> 00:29:51,760
and you also have a CT scan and you want

678
00:29:48,399 --> 00:29:55,279
to go from the CT scan to uh from the

679
00:29:51,760 --> 00:29:57,600
PET scan to the CT scan. Then you can do

680
00:29:55,279 --> 00:30:00,159
domain translation. It's the same thing.

681
00:29:57,600 --> 00:30:02,080
Instead of uh figuring out the similar

682
00:30:00,159 --> 00:30:04,320
textures between sites, you just find

683
00:30:02,080 --> 00:30:07,120
the similar textures between the imaging

684
00:30:04,320 --> 00:30:09,520
modality. And this allows you to

685
00:30:07,120 --> 00:30:12,480
increase the amount of data potentially

686
00:30:09,520 --> 00:30:15,440
um because maybe you don't need such

687
00:30:12,480 --> 00:30:17,919
heavy and sophisticated equipment. Maybe

688
00:30:15,440 --> 00:30:20,000
you can find cheaper ways to collect all

689
00:30:17,919 --> 00:30:22,640
the data that you care about for maybe

690
00:30:20,000 --> 00:30:26,080
tumor segmentation and then you can

691
00:30:22,640 --> 00:30:28,000
translate those uh cheaper images into

692
00:30:26,080 --> 00:30:30,720
the domain that you do end up caring

693
00:30:28,000 --> 00:30:33,360
about.

694
00:30:30,720 --> 00:30:35,840
And this isn't only for images. There

695
00:30:33,360 --> 00:30:38,960
are other applications for domains

696
00:30:35,840 --> 00:30:42,559
translation. This is going from RNA

697
00:30:38,960 --> 00:30:45,360
expression to ATAC profiles. Um, but

698
00:30:42,559 --> 00:30:47,120
they're very similar concepts and uh

699
00:30:45,360 --> 00:30:49,039
it's just basically taking one

700
00:30:47,120 --> 00:30:50,159
representation of the data and

701
00:30:49,039 --> 00:30:52,880
transferring it to another

702
00:30:50,159 --> 00:30:55,039
representation and it in some ways

703
00:30:52,880 --> 00:30:57,600
allows you to imputee data that might be

704
00:30:55,039 --> 00:31:01,360
missing which could be really useful.

705
00:30:57,600 --> 00:31:04,240
And I think that um why this is really

706
00:31:01,360 --> 00:31:07,840
important, why I brought this in this uh

707
00:31:04,240 --> 00:31:11,039
primer is because a lot of research in

708
00:31:07,840 --> 00:31:13,200
medical AI is really just a game with

709
00:31:11,039 --> 00:31:15,360
different publicly available data sets

710
00:31:13,200 --> 00:31:17,520
and kind of piecing them together to do

711
00:31:15,360 --> 00:31:19,440
the task that you care about. Like

712
00:31:17,520 --> 00:31:22,399
ideally, we would have just these

713
00:31:19,440 --> 00:31:24,480
massive data sets for the task that we

714
00:31:22,399 --> 00:31:27,919
care about, but that just doesn't exist.

715
00:31:24,480 --> 00:31:30,000
we have maybe you know some data for the

716
00:31:27,919 --> 00:31:31,840
task we care about and then we have lots

717
00:31:30,000 --> 00:31:35,200
of data and something that's different

718
00:31:31,840 --> 00:31:38,640
but tangentially related and what we can

719
00:31:35,200 --> 00:31:41,279
do with domain transl uh translation is

720
00:31:38,640 --> 00:31:44,880
we essentially can augment the data that

721
00:31:41,279 --> 00:31:46,880
we have um by being really smart with uh

722
00:31:44,880 --> 00:31:49,120
the way that we handle it. So you can

723
00:31:46,880 --> 00:31:51,360
imagine that if we have an MRI image and

724
00:31:49,120 --> 00:31:53,279
we care about tumor segmentation but we

725
00:31:51,360 --> 00:31:55,840
don't have that many images but what we

726
00:31:53,279 --> 00:31:59,200
do have are CT images and tumor

727
00:31:55,840 --> 00:32:02,880
segmentations and CT to MRI images then

728
00:31:59,200 --> 00:32:04,960
you can come up with a way uh to to um

729
00:32:02,880 --> 00:32:07,039
pre-train your architecture without

730
00:32:04,960 --> 00:32:10,480
having to collect more of the MRI and

731
00:32:07,039 --> 00:32:13,200
tumor segmentation images.

732
00:32:10,480 --> 00:32:15,120
And um I think this is an example that I

733
00:32:13,200 --> 00:32:17,760
found really cool. This was presented in

734
00:32:15,120 --> 00:32:19,360
the center for precision psychiatry a

735
00:32:17,760 --> 00:32:20,640
while ago and when she gave the

736
00:32:19,360 --> 00:32:24,960
presentation I was like this is kind of

737
00:32:20,640 --> 00:32:26,880
the perfect example of um you know

738
00:32:24,960 --> 00:32:29,200
playing around with the different data

739
00:32:26,880 --> 00:32:31,279
sets and domains that are available and

740
00:32:29,200 --> 00:32:33,200
in this paper what they were trying to

741
00:32:31,279 --> 00:32:35,360
do is essentially going from nocturnal

742
00:32:33,200 --> 00:32:38,880
breathing to be able to predict uh

743
00:32:35,360 --> 00:32:41,760
Parkinson's disease looking at um just

744
00:32:38,880 --> 00:32:44,000
kind of yeah breathing patterns during

745
00:32:41,760 --> 00:32:46,080
night um and you can imagine there's

746
00:32:44,000 --> 00:32:48,960
maybe not that much data to do that

747
00:32:46,080 --> 00:32:50,640
analysis, but what there is is there's

748
00:32:48,960 --> 00:32:54,320
relationships between nocturnal

749
00:32:50,640 --> 00:32:56,320
breathing and EEG signals. And um you

750
00:32:54,320 --> 00:33:00,320
can kind of play around with the

751
00:32:56,320 --> 00:33:01,519
different um like paired data sets and

752
00:33:00,320 --> 00:33:04,000
you can learn really rich

753
00:33:01,519 --> 00:33:07,519
representations of these features which

754
00:33:04,000 --> 00:33:10,720
allows uh for you to require like less

755
00:33:07,519 --> 00:33:12,320
data to solve the task that you end up

756
00:33:10,720 --> 00:33:14,559
caring about which in this case is

757
00:33:12,320 --> 00:33:16,480
prediction of Parkinson's.

758
00:33:14,559 --> 00:33:18,559
Okay. So now we're going to talk about

759
00:33:16,480 --> 00:33:21,360
self-supervised learning and this is

760
00:33:18,559 --> 00:33:24,559
when large language models um start

761
00:33:21,360 --> 00:33:27,039
coming into play. But what self-superi

762
00:33:24,559 --> 00:33:29,840
supervised learning tries to do is it

763
00:33:27,039 --> 00:33:33,120
says okay well maybe there's a really

764
00:33:29,840 --> 00:33:34,880
smart way we can just handle the data uh

765
00:33:33,120 --> 00:33:36,559
to to make use of the data that we do

766
00:33:34,880 --> 00:33:40,399
have. There's so much structure in this

767
00:33:36,559 --> 00:33:43,360
data. So for images a really kind of

768
00:33:40,399 --> 00:33:46,640
creative solution is okay maybe we take

769
00:33:43,360 --> 00:33:49,279
an image we rotate that image and we ask

770
00:33:46,640 --> 00:33:51,760
the architecture to determine its

771
00:33:49,279 --> 00:33:54,559
rotation. And you can imagine that this

772
00:33:51,760 --> 00:33:57,360
is actually quite a hard problem. Um

773
00:33:54,559 --> 00:33:59,279
because to know that an image of a bird

774
00:33:57,360 --> 00:34:00,799
sitting on a branch is upside down, you

775
00:33:59,279 --> 00:34:02,399
have to understand what a bird is and

776
00:34:00,799 --> 00:34:05,279
what the eyes are and what the branch

777
00:34:02,399 --> 00:34:07,039
is. And in doing so, the you end up

778
00:34:05,279 --> 00:34:09,679
learning these features that are quite

779
00:34:07,039 --> 00:34:12,240
rich and you can use that as the

780
00:34:09,679 --> 00:34:14,159
pre-trained features for your network

781
00:34:12,240 --> 00:34:16,480
and then you can do the fine-tuning on

782
00:34:14,159 --> 00:34:19,520
the subsequent task that you care about.

783
00:34:16,480 --> 00:34:21,679
Um there's so many uh subsequent

784
00:34:19,520 --> 00:34:23,599
applications to this. You can

785
00:34:21,679 --> 00:34:25,119
essentially take patches of the image.

786
00:34:23,599 --> 00:34:26,960
You can ask the architecture to figure

787
00:34:25,119 --> 00:34:31,280
out what part of the image it's looking

788
00:34:26,960 --> 00:34:32,879
at. You can um kind of show a grayscale

789
00:34:31,280 --> 00:34:35,520
image and a color version of that image

790
00:34:32,879 --> 00:34:38,240
and ask it to predict the other

791
00:34:35,520 --> 00:34:40,000
representation of that image.

792
00:34:38,240 --> 00:34:41,839
Um this becomes a little bit more clear

793
00:34:40,000 --> 00:34:44,560
when we start talking about multimodal

794
00:34:41,839 --> 00:34:47,760
learning especially in videos. So what

795
00:34:44,560 --> 00:34:52,320
you can do um like with videos as you

796
00:34:47,760 --> 00:34:55,359
can imagine um the sound corresponds to

797
00:34:52,320 --> 00:34:57,599
what the image of that video is and you

798
00:34:55,359 --> 00:35:00,400
can have a network that essentially

799
00:34:57,599 --> 00:35:04,320
where you shift the audio. You randomly

800
00:35:00,400 --> 00:35:06,320
shuffle the audio and you have the video

801
00:35:04,320 --> 00:35:09,599
and you ask the network to determine

802
00:35:06,320 --> 00:35:12,480
whether the audio is shuffled. And if

803
00:35:09,599 --> 00:35:14,400
it's able to tell whether it's the real

804
00:35:12,480 --> 00:35:16,560
corresponding audio or the shuffled

805
00:35:14,400 --> 00:35:20,240
audio, it starts learning an

806
00:35:16,560 --> 00:35:22,880
understanding of how a video should

807
00:35:20,240 --> 00:35:26,079
sound like and in that way you start

808
00:35:22,880 --> 00:35:27,680
getting rich features for video um

809
00:35:26,079 --> 00:35:29,440
segmentation.

810
00:35:27,680 --> 00:35:32,560
So what you we can see in the bottom

811
00:35:29,440 --> 00:35:35,359
right is essentially uh the architecture

812
00:35:32,560 --> 00:35:39,119
learning where the individual sounds of

813
00:35:35,359 --> 00:35:42,240
guitar are just based off of the ability

814
00:35:39,119 --> 00:35:45,200
to know whether the the audio of a

815
00:35:42,240 --> 00:35:48,640
guitar was shuffled or not.

816
00:35:45,200 --> 00:35:52,079
Um so in medical applications uh we can

817
00:35:48,640 --> 00:35:56,079
have maybe a synographer that is um

818
00:35:52,079 --> 00:35:58,560
looking at um a fetus and at the same

819
00:35:56,079 --> 00:36:01,920
time speaking into a microphone and we

820
00:35:58,560 --> 00:36:04,320
can do a very similar uh correspondence

821
00:36:01,920 --> 00:36:07,119
test where we kind of shuffle the audio

822
00:36:04,320 --> 00:36:10,000
and we ask the artificial neural network

823
00:36:07,119 --> 00:36:12,160
to determine whether the audio is

824
00:36:10,000 --> 00:36:15,200
corresponding or not corresponding. And

825
00:36:12,160 --> 00:36:17,760
this ends up uh producing great features

826
00:36:15,200 --> 00:36:20,400
for sub subsequent analysis. In this

827
00:36:17,760 --> 00:36:25,520
case, it's just trying to show in uh

828
00:36:20,400 --> 00:36:28,000
that um these architectures when you do

829
00:36:25,520 --> 00:36:32,560
this pre-training can better figure out

830
00:36:28,000 --> 00:36:34,560
the gaze of the the synographer. Um

831
00:36:32,560 --> 00:36:36,480
yeah,

832
00:36:34,560 --> 00:36:38,320
so another application of

833
00:36:36,480 --> 00:36:41,760
self-supervised learning which I think

834
00:36:38,320 --> 00:36:44,640
is a lot more ubiquitous is that of

835
00:36:41,760 --> 00:36:46,720
phrase completion. So you can have a

836
00:36:44,640 --> 00:36:49,440
sentence after running for miles she

837
00:36:46,720 --> 00:36:52,079
finally reached the and you ask the

838
00:36:49,440 --> 00:36:55,440
architecture to fill that in. Um, and

839
00:36:52,079 --> 00:36:58,560
you can imagine that if there's a lot of

840
00:36:55,440 --> 00:37:00,720
these sentences, you can kind of blind

841
00:36:58,560 --> 00:37:03,440
the architecture to certain parts of

842
00:37:00,720 --> 00:37:07,760
that sentence. And that allows for the

843
00:37:03,440 --> 00:37:09,760
advent of large language models. Um, I

844
00:37:07,760 --> 00:37:12,640
was always confused as to how you can

845
00:37:09,760 --> 00:37:15,680
take text and put it into an artificial

846
00:37:12,640 --> 00:37:18,000
neural network. Um, and OpenAI has a

847
00:37:15,680 --> 00:37:20,720
really good demonstration of this, uh,

848
00:37:18,000 --> 00:37:23,599
where you can see the words on the left

849
00:37:20,720 --> 00:37:25,359
being tokenized and they correspond to

850
00:37:23,599 --> 00:37:30,480
actual numbers. And once you have

851
00:37:25,359 --> 00:37:32,880
numbers, you can, uh, train, um, uh,

852
00:37:30,480 --> 00:37:34,960
yeah, it becomes differentiable. So you

853
00:37:32,880 --> 00:37:38,079
can train architectures to map those

854
00:37:34,960 --> 00:37:40,560
numbers into something more useful.

855
00:37:38,079 --> 00:37:42,480
Um, and one of the key advances that

856
00:37:40,560 --> 00:37:45,119
allowed for large language models are

857
00:37:42,480 --> 00:37:47,200
these transformer systems. Uh, I don't

858
00:37:45,119 --> 00:37:49,760
want to go into too much detail of what

859
00:37:47,200 --> 00:37:53,280
a transformer is, but it's a way to

860
00:37:49,760 --> 00:37:56,400
integrate sequential information and it

861
00:37:53,280 --> 00:37:59,040
but it does so such that it allows to

862
00:37:56,400 --> 00:38:01,119
focus on specific parts of the sequence

863
00:37:59,040 --> 00:38:03,839
at different points in time. This

864
00:38:01,119 --> 00:38:06,400
becomes really useful when we're looking

865
00:38:03,839 --> 00:38:08,240
at maybe an entire paragraph and we want

866
00:38:06,400 --> 00:38:11,280
to predict the word of the next sentence

867
00:38:08,240 --> 00:38:13,599
but we need to know the context of uh

868
00:38:11,280 --> 00:38:16,480
the first sentence in that paragraph.

869
00:38:13,599 --> 00:38:19,920
But also transformers are used for any

870
00:38:16,480 --> 00:38:24,160
sequence-based analysis. So, Alphafold

871
00:38:19,920 --> 00:38:27,119
has been um uh gamechanging in terms of

872
00:38:24,160 --> 00:38:30,480
protein folding and a way was able to do

873
00:38:27,119 --> 00:38:32,480
that is through transformers.

874
00:38:30,480 --> 00:38:34,000
And with the advent of large language

875
00:38:32,480 --> 00:38:35,520
models, there's so many more

876
00:38:34,000 --> 00:38:38,560
applications

877
00:38:35,520 --> 00:38:40,320
uh to use it for clinical notes. So, one

878
00:38:38,560 --> 00:38:42,960
really straightforward application is

879
00:38:40,320 --> 00:38:45,680
patient recruitment. Um the idea is you

880
00:38:42,960 --> 00:38:48,880
just take u a pre-trained model

881
00:38:45,680 --> 00:38:51,440
something like from open AI and you

882
00:38:48,880 --> 00:38:53,680
essentially go through all you know a

883
00:38:51,440 --> 00:38:56,240
subset of patients and you try to see

884
00:38:53,680 --> 00:38:59,040
which subset is eligible for the trial

885
00:38:56,240 --> 00:39:02,560
that you care about. Um and in doing so

886
00:38:59,040 --> 00:39:05,520
and and using LMS it allows for um

887
00:39:02,560 --> 00:39:09,599
clinicians to it reduces clinician

888
00:39:05,520 --> 00:39:12,320
effort by 42% which is quite high. Um we

889
00:39:09,599 --> 00:39:14,800
also can train large language models not

890
00:39:12,320 --> 00:39:16,560
only on English text. We can also just

891
00:39:14,800 --> 00:39:18,480
train them on clinical notes to have a

892
00:39:16,560 --> 00:39:20,720
better understanding of clinical

893
00:39:18,480 --> 00:39:23,280
trajectory. These subset of large

894
00:39:20,720 --> 00:39:26,400
language models are called uh clinical

895
00:39:23,280 --> 00:39:30,000
language models or clams. Um, so a

896
00:39:26,400 --> 00:39:32,000
really big clinical language model is

897
00:39:30,000 --> 00:39:33,839
Gatorron from the University of Florida

898
00:39:32,000 --> 00:39:36,480
is trained on 82 billion words from

899
00:39:33,839 --> 00:39:39,680
clinical notes from over two million

900
00:39:36,480 --> 00:39:41,680
patients. And in some medical

901
00:39:39,680 --> 00:39:43,839
questionans answering tasks, uh,

902
00:39:41,680 --> 00:39:46,400
clinicians were unable to determine

903
00:39:43,839 --> 00:39:50,240
whether it was from experts or whether

904
00:39:46,400 --> 00:39:54,480
it was from, uh, Gatorron. And then

905
00:39:50,240 --> 00:39:57,280
finally, I I think maybe this is a very

906
00:39:54,480 --> 00:39:59,680
exciting future direction

907
00:39:57,280 --> 00:40:04,400
um is using these large language models

908
00:39:59,680 --> 00:40:06,160
for outcome prediction. So for very rare

909
00:40:04,400 --> 00:40:08,400
conditions where you have limited

910
00:40:06,160 --> 00:40:12,960
amounts of data, it can be hard to

911
00:40:08,400 --> 00:40:15,440
create data sets um that that have

912
00:40:12,960 --> 00:40:17,280
enough samples to do the prediction that

913
00:40:15,440 --> 00:40:19,839
you want. But there's some early

914
00:40:17,280 --> 00:40:23,040
research showing that if you are able to

915
00:40:19,839 --> 00:40:24,560
train just on the corpus of medical text

916
00:40:23,040 --> 00:40:26,960
that there is that it has more

917
00:40:24,560 --> 00:40:30,240
contextual understanding. So when you

918
00:40:26,960 --> 00:40:32,400
try to apply it for these rare cases, it

919
00:40:30,240 --> 00:40:36,240
actually does better at predicting that

920
00:40:32,400 --> 00:40:38,960
outcome. Um and this is a potentially uh

921
00:40:36,240 --> 00:40:41,599
you know useful

922
00:40:38,960 --> 00:40:44,000
uh to expand artificial intelligence or

923
00:40:41,599 --> 00:40:45,839
machine learning past just structured

924
00:40:44,000 --> 00:40:48,640
data sets.

925
00:40:45,839 --> 00:40:50,640
So overall, uh there's a lot of great

926
00:40:48,640 --> 00:40:52,400
potential with AI and medicine, but

927
00:40:50,640 --> 00:40:54,320
there are also a lot of limitations. I

928
00:40:52,400 --> 00:40:56,960
didn't really have a lot of time to talk

929
00:40:54,320 --> 00:40:58,160
about those limitations, but overall, uh

930
00:40:56,960 --> 00:41:00,560
there's always going to be limited

931
00:40:58,160 --> 00:41:04,319
amounts of data, especially in medicine.

932
00:41:00,560 --> 00:41:09,200
Um there's a lot of different sites that

933
00:41:04,319 --> 00:41:10,800
can uh are have those data points secure

934
00:41:09,200 --> 00:41:15,599
and

935
00:41:10,800 --> 00:41:18,000
um there's no public consortium of the

936
00:41:15,599 --> 00:41:20,800
data available. So it's hard to run

937
00:41:18,000 --> 00:41:22,800
really large models. So there's always

938
00:41:20,800 --> 00:41:25,839
going to be innovation on how to adjust

939
00:41:22,800 --> 00:41:28,880
these models for limited amounts of

940
00:41:25,839 --> 00:41:30,880
data. But equally, I I think this is a

941
00:41:28,880 --> 00:41:35,040
growing concern is just making sure that

942
00:41:30,880 --> 00:41:37,119
the data stays private. Um when we kind

943
00:41:35,040 --> 00:41:40,560
of have these large language models that

944
00:41:37,119 --> 00:41:42,880
learn the corpus of text, um it's still

945
00:41:40,560 --> 00:41:44,720
uh trying to understand like how private

946
00:41:42,880 --> 00:41:47,040
that information is once it gets

947
00:41:44,720 --> 00:41:48,640
absorbed into large language model. And

948
00:41:47,040 --> 00:41:51,040
with all machine learning tasks,

949
00:41:48,640 --> 00:41:53,359
mitigating bias and hallucinations are a

950
00:41:51,040 --> 00:41:55,040
huge problem. If you train on a subset

951
00:41:53,359 --> 00:41:57,280
of individuals maybe of a certain

952
00:41:55,040 --> 00:41:59,359
ancestry and apply to different uh

953
00:41:57,280 --> 00:42:02,000
ancestry, you will get performance

954
00:41:59,359 --> 00:42:03,440
differences. But overall, thank you for

955
00:42:02,000 --> 00:42:07,400
the presentation. If you have any

956
00:42:03,440 --> 00:42:07,400
questions, let me know.

957
00:42:08,079 --> 00:42:13,440
>> Thank you so much. Um

958
00:42:10,880 --> 00:42:16,079
questions. I do have one online I can

959
00:42:13,440 --> 00:42:18,160
start with. Um, what are some examples

960
00:42:16,079 --> 00:42:20,400
of biological questions or problems that

961
00:42:18,160 --> 00:42:22,880
are poor candidates for using OpenAI's

962
00:42:20,400 --> 00:42:26,640
pre-trained models of fine tuning given

963
00:42:22,880 --> 00:42:30,000
that these are trained on all of the

964
00:42:26,640 --> 00:42:32,319
>> Yeah, I mean I I don't know whether I

965
00:42:30,000 --> 00:42:36,079
know unfortunately I feel like that's

966
00:42:32,319 --> 00:42:40,000
still an ongoing question because the

967
00:42:36,079 --> 00:42:42,240
amount that it can do is probably more

968
00:42:40,000 --> 00:42:45,280
is what's driving the research rather

969
00:42:42,240 --> 00:42:47,119
than um what its limitations are

970
00:42:45,280 --> 00:42:50,079
currently. So I think that's still an

971
00:42:47,119 --> 00:42:54,400
unanswered question of figuring out what

972
00:42:50,079 --> 00:42:56,400
exactly are its best use cases.

973
00:42:54,400 --> 00:43:02,880
of them and they celebrate these great

974
00:42:56,400 --> 00:43:04,720
research and so how I can understand

975
00:43:02,880 --> 00:43:06,960
the a lot of the examples that you

976
00:43:04,720 --> 00:43:10,160
presented where we're classifying things

977
00:43:06,960 --> 00:43:12,640
or even like multimodal making decisions

978
00:43:10,160 --> 00:43:14,640
but to accelerate scientific research

979
00:43:12,640 --> 00:43:18,560
you know like how does one program that

980
00:43:14,640 --> 00:43:22,000
or program architecture to that

981
00:43:18,560 --> 00:43:24,560
>> yeah I mean I I I think that's like

982
00:43:22,000 --> 00:43:26,640
that's the trillion dollar question.

983
00:43:24,560 --> 00:43:30,319
Yeah, I

984
00:43:26,640 --> 00:43:31,920
I think the angle that they're probably

985
00:43:30,319 --> 00:43:35,680
going for is more of from this

986
00:43:31,920 --> 00:43:37,760
generative AI point of view where um

987
00:43:35,680 --> 00:43:41,599
essentially you're taking very defined

988
00:43:37,760 --> 00:43:43,119
mappings from two different domains and

989
00:43:41,599 --> 00:43:45,040
you're essentially doing something

990
00:43:43,119 --> 00:43:47,119
that's greater than the sum of its parts

991
00:43:45,040 --> 00:43:51,920
like taking the style of Van Go and

992
00:43:47,119 --> 00:43:54,960
pasting it on an a photo of of houses.

993
00:43:51,920 --> 00:43:56,960
So I think the idea is that if you are

994
00:43:54,960 --> 00:43:59,040
just kind of training on all these

995
00:43:56,960 --> 00:44:01,280
different data sets then maybe can kind

996
00:43:59,040 --> 00:44:04,720
of pull ideas from different places and

997
00:44:01,280 --> 00:44:08,319
create something more comprehensive.

998
00:44:04,720 --> 00:44:11,520
Um but to my understanding like I

999
00:44:08,319 --> 00:44:13,839
haven't seen applications where it was

1000
00:44:11,520 --> 00:44:17,359
able to

1001
00:44:13,839 --> 00:44:19,359
like be more creative than um an expert

1002
00:44:17,359 --> 00:44:21,839
in that field. Yeah. I think Terrence

1003
00:44:19,359 --> 00:44:24,880
Tao he's a very famous mathematician and

1004
00:44:21,839 --> 00:44:27,680
he has a blog post where he talks about

1005
00:44:24,880 --> 00:44:31,280
um open AI and chat GPT models in

1006
00:44:27,680 --> 00:44:34,640
mathematics and he basically said that

1007
00:44:31,280 --> 00:44:36,319
um they do quite well at solving the

1008
00:44:34,640 --> 00:44:38,960
problem when you frame it to them

1009
00:44:36,319 --> 00:44:40,640
already but I think as a scientist it's

1010
00:44:38,960 --> 00:44:45,640
the framing that's always the most

1011
00:44:40,640 --> 00:44:45,640
challenging bit so yeah

1012
00:44:47,359 --> 00:44:51,760
>> I have like 100 questions but is no one

1013
00:44:49,680 --> 00:44:54,480
in the room.

1014
00:44:51,760 --> 00:44:55,920
>> Um, okay. So, I think the style transfer

1015
00:44:54,480 --> 00:44:57,839
is really interesting, especially when

1016
00:44:55,920 --> 00:45:01,200
you have maybe batch effects across

1017
00:44:57,839 --> 00:45:03,839
institutions. I was wondering if those

1018
00:45:01,200 --> 00:45:05,359
if the results are robust to the data

1019
00:45:03,839 --> 00:45:06,720
set that you use as like an anchor

1020
00:45:05,359 --> 00:45:08,800
point.

1021
00:45:06,720 --> 00:45:09,119
>> Oh, like as in can you switch the anchor

1022
00:45:08,800 --> 00:45:11,599
point?

1023
00:45:09,119 --> 00:45:13,440
>> Make everything look like hospital A and

1024
00:45:11,599 --> 00:45:15,440
everything like hospital B and do the

1025
00:45:13,440 --> 00:45:18,240
same analysis. Are you going to get

1026
00:45:15,440 --> 00:45:19,760
similar results? Yeah, I mean I I think

1027
00:45:18,240 --> 00:45:23,280
like usually the reference point is the

1028
00:45:19,760 --> 00:45:27,280
one where you have more examples.

1029
00:45:23,280 --> 00:45:31,520
Um yeah, I'm not I'm not sure whether

1030
00:45:27,280 --> 00:45:35,680
you'll have that much variability. Um

1031
00:45:31,520 --> 00:45:37,520
yeah, I mean yeah I yeah I'm not exactly

1032
00:45:35,680 --> 00:45:40,800
sure.

1033
00:45:37,520 --> 00:45:42,720
>> Um and then how do these models do with

1034
00:45:40,800 --> 00:45:46,240
novel finding? So if you had some sort

1035
00:45:42,720 --> 00:45:48,079
of image for whatever phenotype and it's

1036
00:45:46,240 --> 00:45:50,640
it's a rare disease and it's never seen

1037
00:45:48,079 --> 00:45:52,400
it before, is it forced to go into one

1038
00:45:50,640 --> 00:45:54,560
of the bins that you're looking at or

1039
00:45:52,400 --> 00:45:56,800
are these models able to like flag it

1040
00:45:54,560 --> 00:45:57,680
say, hey, this looks something different

1041
00:45:56,800 --> 00:45:59,680
like someone

1042
00:45:57,680 --> 00:46:01,359
>> Yeah. So yeah, I think that's an

1043
00:45:59,680 --> 00:46:03,839
interesting question and in a lot of

1044
00:46:01,359 --> 00:46:07,280
cases like AI where it does really well

1045
00:46:03,839 --> 00:46:11,440
is when the input output is defined in

1046
00:46:07,280 --> 00:46:13,599
large quantities. Um I think for rare

1047
00:46:11,440 --> 00:46:15,760
cases I I think there's a lot of

1048
00:46:13,599 --> 00:46:18,480
experimentation of understanding what is

1049
00:46:15,760 --> 00:46:20,400
a normal distribution of maybe a healthy

1050
00:46:18,480 --> 00:46:22,400
MRI images and trying to understand

1051
00:46:20,400 --> 00:46:24,079
those anomalies because obviously you

1052
00:46:22,400 --> 00:46:26,240
won't have a lot of examples of what

1053
00:46:24,079 --> 00:46:28,240
these rare cases are but maybe have a

1054
00:46:26,240 --> 00:46:30,240
better understanding of what a healthy

1055
00:46:28,240 --> 00:46:32,000
distribution looks like. But I think

1056
00:46:30,240 --> 00:46:34,240
that's like a huge limitation especially

1057
00:46:32,000 --> 00:46:38,720
in medical imaging because sometimes in

1058
00:46:34,240 --> 00:46:41,599
these rare cases that you know in an MRI

1059
00:46:38,720 --> 00:46:44,160
image there's so many pixels but what

1060
00:46:41,599 --> 00:46:46,400
you care about is in such a small part

1061
00:46:44,160 --> 00:46:49,359
of that image. So there's just not a lot

1062
00:46:46,400 --> 00:46:51,599
of signal to train the entire AI system.

1063
00:46:49,359 --> 00:46:54,800
So this presentation was mostly focused

1064
00:46:51,599 --> 00:46:58,240
on where AI I felt has had the most

1065
00:46:54,800 --> 00:47:01,920
significance in medicine and I think it

1066
00:46:58,240 --> 00:47:06,079
really comes down to how well phenotyped

1067
00:47:01,920 --> 00:47:07,920
the data is. Yeah,

1068
00:47:06,079 --> 00:47:10,720
>> we have one more online. Is anyone

1069
00:47:07,920 --> 00:47:13,440
looking at creating scale open data sets

1070
00:47:10,720 --> 00:47:15,200
like Nomad of medical imaging data? It

1071
00:47:13,440 --> 00:47:17,040
sounds like one of the biggest issues in

1072
00:47:15,200 --> 00:47:19,520
the field is just getting access to the

1073
00:47:17,040 --> 00:47:21,440
data. Yeah, I mean I'm sure that there's

1074
00:47:19,520 --> 00:47:23,040
a lot of different um consortiums that

1075
00:47:21,440 --> 00:47:25,599
that are trying to do I I think the

1076
00:47:23,040 --> 00:47:28,240
issue is always with the identification.

1077
00:47:25,599 --> 00:47:30,400
Um but even then

1078
00:47:28,240 --> 00:47:33,520
if you were to

1079
00:47:30,400 --> 00:47:38,079
have a public place to and I think there

1080
00:47:33,520 --> 00:47:40,079
are um online tools and and websites

1081
00:47:38,079 --> 00:47:42,400
that try to consolidate all this

1082
00:47:40,079 --> 00:47:44,560
information um but there's always going

1083
00:47:42,400 --> 00:47:47,839
to be differences in the instruments

1084
00:47:44,560 --> 00:47:50,319
that are used between sites. um even

1085
00:47:47,839 --> 00:47:52,240
within the institution in 10 years time

1086
00:47:50,319 --> 00:47:54,720
we can have a completely different MRI

1087
00:47:52,240 --> 00:47:57,200
setup that will just change the types of

1088
00:47:54,720 --> 00:48:00,240
data. So you always have to be cognizant

1089
00:47:57,200 --> 00:48:02,400
of um the really the amount of data

1090
00:48:00,240 --> 00:48:04,560
that's available and you're always going

1091
00:48:02,400 --> 00:48:08,480
to have this game of constraints given

1092
00:48:04,560 --> 00:48:10,960
data limitations and even if you were to

1093
00:48:08,480 --> 00:48:12,640
consolidate all these different types of

1094
00:48:10,960 --> 00:48:18,000
data I think you'll never get to the

1095
00:48:12,640 --> 00:48:20,480
scale of more um like natural

1096
00:48:18,000 --> 00:48:22,640
data sets that are being solved in

1097
00:48:20,480 --> 00:48:25,119
regular computer science like uh natural

1098
00:48:22,640 --> 00:48:27,680
scene images or large language because

1099
00:48:25,119 --> 00:48:30,400
uh it's there's so the data is so

1100
00:48:27,680 --> 00:48:32,400
ubiquitous.

1101
00:48:30,400 --> 00:48:36,119
>> Great. All right, let's think our

1102
00:48:32,400 --> 00:48:36,119
speaker one more time.


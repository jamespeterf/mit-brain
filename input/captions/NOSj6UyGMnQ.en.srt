1
00:00:00,320 --> 00:00:05,440
Hi everyone. Um, thank you all so much

2
00:00:02,800 --> 00:00:07,200
for coming to MIA today. Uh, we have two

3
00:00:05,440 --> 00:00:09,519
great speakers from UMass that'll be

4
00:00:07,200 --> 00:00:11,360
speaking with us. Um, I won't say too

5
00:00:09,519 --> 00:00:13,200
much just to let them have time to talk,

6
00:00:11,360 --> 00:00:15,679
but um, thank you guys so much for

7
00:00:13,200 --> 00:00:17,680
coming.

8
00:00:15,679 --> 00:00:19,359
>> Um, thank you. Thank you very much for

9
00:00:17,680 --> 00:00:20,720
having me. This was um, super cool. I

10
00:00:19,359 --> 00:00:23,600
had actually no idea this was a thing

11
00:00:20,720 --> 00:00:25,840
and now I have u a lot of YouTube to

12
00:00:23,600 --> 00:00:28,400
catch up on. So, I'm sure my I'm sure my

13
00:00:25,840 --> 00:00:31,199
my wife is going to be thrilled. Um, but

14
00:00:28,400 --> 00:00:32,719
I'm going to give you, you know, um, you

15
00:00:31,199 --> 00:00:34,000
know, kind of an overview more on, you

16
00:00:32,719 --> 00:00:36,239
know, what I've been working on really

17
00:00:34,000 --> 00:00:38,239
within the past year. Uh, working on the

18
00:00:36,239 --> 00:00:40,480
interpretable, uh, interpretation side

19
00:00:38,239 --> 00:00:42,800
of deep learning and what we can, um,

20
00:00:40,480 --> 00:00:45,760
learn from these trained neural networks

21
00:00:42,800 --> 00:00:48,000
on regulatory genomic data. Um, so my

22
00:00:45,760 --> 00:00:50,239
name is Greg. I am a bionformmatician in

23
00:00:48,000 --> 00:00:51,920
the lab of Japing Wang at UMasschan

24
00:00:50,239 --> 00:00:54,079
Medical School in genomics and

25
00:00:51,920 --> 00:00:56,160
computational biology. Um my only

26
00:00:54,079 --> 00:00:59,039
disclosure is that in my free time I

27
00:00:56,160 --> 00:01:00,879
even do more biioinformatics. So um I

28
00:00:59,039 --> 00:01:03,840
definitely need more hobbies I would

29
00:01:00,879 --> 00:01:06,159
say. Okay. So um I think we all have

30
00:01:03,840 --> 00:01:07,840
seen something like this before. Um

31
00:01:06,159 --> 00:01:09,040
that's why we're here. But our work

32
00:01:07,840 --> 00:01:11,040
we're particularly interested in the

33
00:01:09,040 --> 00:01:13,520
non-coding genome that constitutes 98

34
00:01:11,040 --> 00:01:15,520
and a half% of our three billion base

35
00:01:13,520 --> 00:01:19,520
pairs. And in particular, we're

36
00:01:15,520 --> 00:01:22,240
interested in um these regulatory

37
00:01:19,520 --> 00:01:25,040
elements, enhancers, promoters that

38
00:01:22,240 --> 00:01:28,000
regulate the 1% and specifically in a

39
00:01:25,040 --> 00:01:30,000
cell type tissue spec cell type tissue

40
00:01:28,000 --> 00:01:32,079
type specific manner and in particular

41
00:01:30,000 --> 00:01:37,159
when this goes ary and its implications

42
00:01:32,079 --> 00:01:37,159
on human health and disease.

43
00:01:39,360 --> 00:01:43,920
So my work in particular I study uh or

44
00:01:42,079 --> 00:01:45,600
I'm focused on transcription factors and

45
00:01:43,920 --> 00:01:48,720
specifically the about 1,600

46
00:01:45,600 --> 00:01:52,640
transcription factors that bind DNA in a

47
00:01:48,720 --> 00:01:54,799
sequence specific fashion and for our

48
00:01:52,640 --> 00:01:57,119
purposes I don't know why my computer's

49
00:01:54,799 --> 00:02:00,320
decided to not work but um as part of my

50
00:01:57,119 --> 00:02:02,399
work um you know I've curated I think

51
00:02:00,320 --> 00:02:04,000
you know over at this point 30,000

52
00:02:02,399 --> 00:02:05,840
chipsseek data sets or transcription

53
00:02:04,000 --> 00:02:07,280
factor chipsseek data sets from publicly

54
00:02:05,840 --> 00:02:10,879
available repositories

55
00:02:07,280 --> 00:02:12,480
And we're up to about se total of 75% of

56
00:02:10,879 --> 00:02:14,720
these transcription factors have at

57
00:02:12,480 --> 00:02:17,360
least one uh TF chipsseek assay

58
00:02:14,720 --> 00:02:19,120
available across any of these uh four

59
00:02:17,360 --> 00:02:21,760
repositories

60
00:02:19,120 --> 00:02:24,640
and specifically um you know but the

61
00:02:21,760 --> 00:02:27,040
coverage is uneven. So if we look you

62
00:02:24,640 --> 00:02:29,360
know surprise that we have about 3,000

63
00:02:27,040 --> 00:02:31,120
data sets for CTCF. CDCF has pretty much

64
00:02:29,360 --> 00:02:33,120
been uh chipped at this point in every

65
00:02:31,120 --> 00:02:35,440
cellar tissue type you can imagine. But

66
00:02:33,120 --> 00:02:37,680
as you um you know I just took the top

67
00:02:35,440 --> 00:02:38,959
60 transcription factors in terms of the

68
00:02:37,680 --> 00:02:41,200
number of data sets or publicly

69
00:02:38,959 --> 00:02:43,760
available data sets and you can see that

70
00:02:41,200 --> 00:02:46,080
the coverage um is quite sparse. So the

71
00:02:43,760 --> 00:02:48,640
focus of my work is can we fill this

72
00:02:46,080 --> 00:02:50,160
matrix in and if you actually zoom out

73
00:02:48,640 --> 00:02:52,480
on this entire matrix and you look

74
00:02:50,160 --> 00:02:54,640
across all 1600 transcription factors

75
00:02:52,480 --> 00:02:56,480
and about 1100 cell types that have at

76
00:02:54,640 --> 00:03:00,160
least one transcription factor chipsseek

77
00:02:56,480 --> 00:03:02,319
assay it's about 1% sparse. So um as

78
00:03:00,160 --> 00:03:04,319
much work as we've done in we have done

79
00:03:02,319 --> 00:03:06,800
in assaying these transcription factors

80
00:03:04,319 --> 00:03:08,959
in specific cell type contexts there's a

81
00:03:06,800 --> 00:03:11,440
lot more information um that we could

82
00:03:08,959 --> 00:03:12,640
learn or has still yet to be found. And

83
00:03:11,440 --> 00:03:14,239
then you can actually think that this

84
00:03:12,640 --> 00:03:16,800
matrix is actually infinite when you

85
00:03:14,239 --> 00:03:19,440
think about each cell or tissue has uh

86
00:03:16,800 --> 00:03:22,159
treatments conditions time points that

87
00:03:19,440 --> 00:03:24,560
could be assayed or studied.

88
00:03:22,159 --> 00:03:26,480
So um you know deep learning has

89
00:03:24,560 --> 00:03:28,000
transformed you know I'm sure you know

90
00:03:26,480 --> 00:03:29,760
given where I am I'm sure deep learning

91
00:03:28,000 --> 00:03:31,360
has come up once or twice but deep

92
00:03:29,760 --> 00:03:32,959
learning has kind of transformed the way

93
00:03:31,360 --> 00:03:35,760
not only our everyday lives but kind of

94
00:03:32,959 --> 00:03:37,920
the way we study regulatory genomics in

95
00:03:35,760 --> 00:03:39,440
the human genome but for our purposes we

96
00:03:37,920 --> 00:03:43,360
can think of a neural network as just

97
00:03:39,440 --> 00:03:47,120
taking DNA sequence and um you know

98
00:03:43,360 --> 00:03:49,599
learns uh features in in the DNA um in

99
00:03:47,120 --> 00:03:51,840
the sequence itself and transforms via

100
00:03:49,599 --> 00:03:53,599
neurons that sequence information into

101
00:03:51,840 --> 00:03:55,200
any form of output or prediction,

102
00:03:53,599 --> 00:03:59,040
whether it be a classification or

103
00:03:55,200 --> 00:04:00,480
regression task. Um, but unfortunately,

104
00:03:59,040 --> 00:04:02,159
the downside of neural networks is

105
00:04:00,480 --> 00:04:05,200
they're often thought of as black boxes.

106
00:04:02,159 --> 00:04:08,319
So, we don't often um it's not easy to

107
00:04:05,200 --> 00:04:10,400
or it's not often um readily available

108
00:04:08,319 --> 00:04:14,080
or known what these neural networks

109
00:04:10,400 --> 00:04:16,400
learn in uh taking your input and making

110
00:04:14,080 --> 00:04:18,639
a prediction or arriving at a given

111
00:04:16,400 --> 00:04:20,799
output. And that's kind of the focus on

112
00:04:18,639 --> 00:04:24,160
my work. My focus on my work is kind of

113
00:04:20,799 --> 00:04:25,759
opening up this black box. Um so if you

114
00:04:24,160 --> 00:04:27,520
think you know if you just take you just

115
00:04:25,759 --> 00:04:29,280
train a simple convolution neural

116
00:04:27,520 --> 00:04:31,919
network. So convolution neural networks

117
00:04:29,280 --> 00:04:34,240
excel excel at learning features in

118
00:04:31,919 --> 00:04:35,840
images. Well the DN a DNA sequence one

119
00:04:34,240 --> 00:04:37,840
hot encoded is just an image in and of

120
00:04:35,840 --> 00:04:41,199
itself and you just take a simple one

121
00:04:37,840 --> 00:04:43,360
kernel single output CNN and you train

122
00:04:41,199 --> 00:04:44,880
it on a CDCF chipsseek data set. You see

123
00:04:43,360 --> 00:04:46,880
that you know and this occurs within a

124
00:04:44,880 --> 00:04:48,960
matter of seconds. You see that the

125
00:04:46,880 --> 00:04:51,360
convolution filter if you just cast the

126
00:04:48,960 --> 00:04:53,919
values of the filter to nucleotides you

127
00:04:51,360 --> 00:04:56,479
see that it begins to look like a CTCF

128
00:04:53,919 --> 00:05:00,560
motif. And then we can use some you know

129
00:04:56,479 --> 00:05:02,160
um very simple matrix operations um very

130
00:05:00,560 --> 00:05:04,080
similar to what was done in some of the

131
00:05:02,160 --> 00:05:05,919
earliest of work in deep learning and

132
00:05:04,080 --> 00:05:07,440
regulatory genomics. So that being deep

133
00:05:05,919 --> 00:05:09,840
bind and study studying transcription

134
00:05:07,440 --> 00:05:12,000
factor binding Basset in studying um

135
00:05:09,840 --> 00:05:14,160
chromatin accessibility. we can convert

136
00:05:12,000 --> 00:05:16,160
that convolution filter into a CDCF

137
00:05:14,160 --> 00:05:18,400
motif that everybody um knows,

138
00:05:16,160 --> 00:05:19,919
recognizes, is familiar with. So, we've

139
00:05:18,400 --> 00:05:22,960
leveraged this. We've used the fact that

140
00:05:19,919 --> 00:05:25,840
CNN's excel at motif discovery. Um we've

141
00:05:22,960 --> 00:05:27,840
shown that they outperform you um you

142
00:05:25,840 --> 00:05:31,199
know both classical and other uh deep

143
00:05:27,840 --> 00:05:34,160
learning approaches um in uh motif

144
00:05:31,199 --> 00:05:36,240
discovery. And then um we were lucky

145
00:05:34,160 --> 00:05:38,560
lucky enough to partner with Eleanor

146
00:05:36,240 --> 00:05:40,240
Carlson here at the Broad um as part of

147
00:05:38,560 --> 00:05:41,600
the Zenomia consortium. So, we're very

148
00:05:40,240 --> 00:05:44,320
thankful for her for inviting us for

149
00:05:41,600 --> 00:05:45,680
being a part of that. Um, and we used,

150
00:05:44,320 --> 00:05:47,280
you know, deep learning to essentially

151
00:05:45,680 --> 00:05:50,160
annotate transcription factor binding

152
00:05:47,280 --> 00:05:52,400
sites for 367 transcription factors. And

153
00:05:50,160 --> 00:05:54,000
then we're able to project um all of

154
00:05:52,400 --> 00:05:56,639
these transcription factor binding sites

155
00:05:54,000 --> 00:05:57,759
into 2D space via UMAP. And what we were

156
00:05:56,639 --> 00:06:00,639
actually able to learn is we were

157
00:05:57,759 --> 00:06:02,400
actually able to learn when specific

158
00:06:00,639 --> 00:06:03,919
transcription factor binding sites so

159
00:06:02,400 --> 00:06:06,560
these specific regions of the genomes

160
00:06:03,919 --> 00:06:08,160
that um uh transcription factors bind

161
00:06:06,560 --> 00:06:10,319
we're actually able to see where they

162
00:06:08,160 --> 00:06:11,759
entered into the primate lineage. So

163
00:06:10,319 --> 00:06:14,000
that was really cool. So that was

164
00:06:11,759 --> 00:06:16,000
largely a focus of my um dissertation

165
00:06:14,000 --> 00:06:18,000
work. And then we used that we showed

166
00:06:16,000 --> 00:06:21,600
that you know not only does CNN's excel

167
00:06:18,000 --> 00:06:23,520
at uh learning motifs in TF chipsseek

168
00:06:21,600 --> 00:06:25,520
data but we showed that this phen that

169
00:06:23,520 --> 00:06:27,199
we can do this for any other kind of

170
00:06:25,520 --> 00:06:29,520
technology for assaying transcription

171
00:06:27,199 --> 00:06:32,960
factor binding. are showing here. Uh we

172
00:06:29,520 --> 00:06:34,720
can do this for HCL. So uh in in vitro

173
00:06:32,960 --> 00:06:36,560
high throughput method for assaying

174
00:06:34,720 --> 00:06:37,840
transcription factor binding and then

175
00:06:36,560 --> 00:06:39,919
you know as I am here as a

176
00:06:37,840 --> 00:06:41,280
representative of the wang lab our lab

177
00:06:39,919 --> 00:06:44,800
um in the brilliant software engineers

178
00:06:41,280 --> 00:06:45,680
in our lab um have built our factor book

179
00:06:44,800 --> 00:06:46,960
database you can just go to

180
00:06:45,680 --> 00:06:48,400
factorbook.org

181
00:06:46,960 --> 00:06:51,360
um and you can explore kind of all the

182
00:06:48,400 --> 00:06:53,440
data that we put together. Um forgot

183
00:06:51,360 --> 00:06:55,280
that that was two slides. And then um we

184
00:06:53,440 --> 00:06:58,720
continued to kind of refine our the way

185
00:06:55,280 --> 00:07:02,560
that we use um neural networks to

186
00:06:58,720 --> 00:07:06,160
ascertain motifs um in in this case a

187
00:07:02,560 --> 00:07:07,919
host of uh different technologies. And

188
00:07:06,160 --> 00:07:10,080
we, you know, we continue to refine this

189
00:07:07,919 --> 00:07:12,800
method and we're able to essent um to

190
00:07:10,080 --> 00:07:14,800
win the IBIS challenge which was a um

191
00:07:12,800 --> 00:07:16,880
kind of worldwide data science think

192
00:07:14,800 --> 00:07:21,440
like a Kaggle like competition but

193
00:07:16,880 --> 00:07:23,440
specific to um biology and we're able to

194
00:07:21,440 --> 00:07:26,160
um you know uh develop a method

195
00:07:23,440 --> 00:07:28,160
combining both CNN's and uh expectation

196
00:07:26,160 --> 00:07:30,319
maximization. So kind of old school

197
00:07:28,160 --> 00:07:31,680
bioinformatics method. It's crazy to say

198
00:07:30,319 --> 00:07:33,199
old school bionirmatics. you know,

199
00:07:31,680 --> 00:07:34,960
bionatics is a field that's only 20

200
00:07:33,199 --> 00:07:36,240
years old itself, but that's how kind of

201
00:07:34,960 --> 00:07:38,479
quick this field is moving and how

202
00:07:36,240 --> 00:07:39,759
evergreen this field is. Um, so that's

203
00:07:38,479 --> 00:07:41,520
really cool. I think that's just

204
00:07:39,759 --> 00:07:46,360
wrapping up. Um, and then we've used

205
00:07:41,520 --> 00:07:46,360
this to um Oh, yeah, absolutely.

206
00:07:53,120 --> 00:07:56,960
>> Oh, yeah. Yeah, yeah, absolutely. Uh,

207
00:07:55,520 --> 00:07:58,879
no, I have this one I'm wearing, right?

208
00:07:56,960 --> 00:07:59,919
I think [laughter]

209
00:07:58,879 --> 00:08:00,240
>> that's all the problems. Um,

210
00:07:59,919 --> 00:08:01,599
>> could you

211
00:08:00,240 --> 00:08:02,879
>> Yeah. Hey, no, thanks for stopping me. I

212
00:08:01,599 --> 00:08:05,280
I don't think I have enough slides to

213
00:08:02,879 --> 00:08:07,680
fill an entire however long we have. So,

214
00:08:05,280 --> 00:08:10,560
yeah. Can you comment a little bit on

215
00:08:07,680 --> 00:08:12,560
like the experimental approaches to

216
00:08:10,560 --> 00:08:16,160
define transcription factor binding

217
00:08:12,560 --> 00:08:17,599
sites and like what's what would you be

218
00:08:16,160 --> 00:08:19,199
cons I mean I see some of them up there

219
00:08:17,599 --> 00:08:21,840
but like there was there were I guess

220
00:08:19,199 --> 00:08:24,400
recent papers about like quote lower

221
00:08:21,840 --> 00:08:28,080
affinity transcription factor binding

222
00:08:24,400 --> 00:08:32,159
sites and contributions from like I

223
00:08:28,080 --> 00:08:35,200
guess flanking kind of nucleotides and

224
00:08:32,159 --> 00:08:37,440
>> um like is it getting more complicated

225
00:08:35,200 --> 00:08:38,800
ated our understanding of like what's

226
00:08:37,440 --> 00:08:40,075
actually going on. Can you just like

227
00:08:38,800 --> 00:08:40,719
comment like on how you would

228
00:08:40,075 --> 00:08:42,080
[clears throat] actually define a

229
00:08:40,719 --> 00:08:43,120
transcription factor binding site

230
00:08:42,080 --> 00:08:45,279
experimentally?

231
00:08:43,120 --> 00:08:46,959
>> Yeah. So for us so okay so if we're

232
00:08:45,279 --> 00:08:49,200
looking at say transcription factor

233
00:08:46,959 --> 00:08:50,800
chipsseek um transcription factor

234
00:08:49,200 --> 00:08:53,200
chipsseek data you know you take your

235
00:08:50,800 --> 00:08:54,640
reads align them you call peaks now you

236
00:08:53,200 --> 00:08:56,480
have your you know essentially you have

237
00:08:54,640 --> 00:08:58,320
your enriched genomic regions that are

238
00:08:56,480 --> 00:08:59,839
bound by the transcription factor. But

239
00:08:58,320 --> 00:09:02,560
you know if you you know ever worked

240
00:08:59,839 --> 00:09:04,959
with you know especially um you know uh

241
00:09:02,560 --> 00:09:06,640
chipsseek or you know even um DNA or

242
00:09:04,959 --> 00:09:09,360
attack peaks right they tend to be about

243
00:09:06,640 --> 00:09:11,200
200 300 base pairs long but we know

244
00:09:09,360 --> 00:09:14,080
specifically with a transcription factor

245
00:09:11,200 --> 00:09:17,279
they only bind a a specific six to 20

246
00:09:14,080 --> 00:09:18,959
base pair um nucleotide sequence and

247
00:09:17,279 --> 00:09:20,480
that's what I refer um you know when I

248
00:09:18,959 --> 00:09:22,000
say transcription factor binding site

249
00:09:20,480 --> 00:09:24,640
that's specifically what I'm referring

250
00:09:22,000 --> 00:09:26,640
to essentially the sequence within these

251
00:09:24,640 --> 00:09:27,839
peaks that the transcription factor is

252
00:09:26,640 --> 00:09:29,120
actually binding and that's what I've

253
00:09:27,839 --> 00:09:31,600
used deep learning to essentially

254
00:09:29,120 --> 00:09:33,760
annotate these sites for any

255
00:09:31,600 --> 00:09:35,600
transcription factor that we have a data

256
00:09:33,760 --> 00:09:37,680
set for. But you're absolutely right in

257
00:09:35,600 --> 00:09:40,160
terms of so if you look if you were to

258
00:09:37,680 --> 00:09:42,480
say there is some degree of correlation

259
00:09:40,160 --> 00:09:44,640
and it differs between from factor to

260
00:09:42,480 --> 00:09:47,519
factor. But if you essentially take the

261
00:09:44,640 --> 00:09:49,600
the the the peaks in a CDCF data set

262
00:09:47,519 --> 00:09:50,880
that have the highest signal, you'll

263
00:09:49,600 --> 00:09:52,560
find that those are your highest

264
00:09:50,880 --> 00:09:54,160
affinity sites. They're the ones where

265
00:09:52,560 --> 00:09:56,480
if you take the in the transcription

266
00:09:54,160 --> 00:09:58,640
factor binding site that specific 19

267
00:09:56,480 --> 00:10:00,880
base pair recognition sequence that CDCF

268
00:09:58,640 --> 00:10:03,040
actually recognizes it has the best

269
00:10:00,880 --> 00:10:05,360
match or the strongest match to the

270
00:10:03,040 --> 00:10:06,959
canonical motif. Now what you're in

271
00:10:05,360 --> 00:10:08,399
terms of now these you know these low

272
00:10:06,959 --> 00:10:10,080
affinity sites they're they're super

273
00:10:08,399 --> 00:10:11,519
important right because you know what's

274
00:10:10,080 --> 00:10:13,040
the prevailing theory that these low

275
00:10:11,519 --> 00:10:15,760
affinity sites are the ones that can be

276
00:10:13,040 --> 00:10:18,720
easily tuned or they can be the sites

277
00:10:15,760 --> 00:10:21,600
where maybe it's a CDCF site but maybe

278
00:10:18,720 --> 00:10:23,680
it's also an SP1 site. So maybe it's a

279
00:10:21,600 --> 00:10:26,000
site where two TFs actually come

280
00:10:23,680 --> 00:10:27,600
together and that's they're those are

281
00:10:26,000 --> 00:10:29,200
really difficult, right? They're really

282
00:10:27,600 --> 00:10:31,040
difficult for us to annotate. They're

283
00:10:29,200 --> 00:10:33,519
really difficult for us to define

284
00:10:31,040 --> 00:10:35,760
because what are they, right? We don't

285
00:10:33,519 --> 00:10:38,959
have we don't have like a a curated

286
00:10:35,760 --> 00:10:41,120
motif for a CTCF SP1 hybrid. So it's

287
00:10:38,959 --> 00:10:42,720
it's a really challenging and ongoing

288
00:10:41,120 --> 00:10:43,920
problem. And I would say for me and then

289
00:10:42,720 --> 00:10:46,480
the work that I'm going to discuss

290
00:10:43,920 --> 00:10:48,560
coming forward you know it's difficult

291
00:10:46,480 --> 00:10:50,480
that poses a problem because it's

292
00:10:48,560 --> 00:10:53,200
difficult to tell whether oh you have

293
00:10:50,480 --> 00:10:56,000
this kind of you know you know hybrid

294
00:10:53,200 --> 00:10:58,560
motif but is it noise or is it truly a

295
00:10:56,000 --> 00:11:00,480
hybrid so how would we how would we

296
00:10:58,560 --> 00:11:02,640
properly annotate them but then how

297
00:11:00,480 --> 00:11:04,480
would we also properly validate them so

298
00:11:02,640 --> 00:11:06,000
it's a really hard ongoing problem

299
00:11:04,480 --> 00:11:08,800
especially because these as I was saying

300
00:11:06,000 --> 00:11:12,160
before these these hybrid motifs tend to

301
00:11:08,800 --> 00:11:14,079
be lower affinity sites So they're the

302
00:11:12,160 --> 00:11:16,240
ones that, you know, maybe they have a p

303
00:11:14,079 --> 00:11:17,839
value slightly greater than 0.05. So

304
00:11:16,240 --> 00:11:19,680
when you call peaks, you don't even see

305
00:11:17,839 --> 00:11:22,560
them. So yeah, certainly, you know, it's

306
00:11:19,680 --> 00:11:23,920
something that we're aware of, um, and,

307
00:11:22,560 --> 00:11:26,640
you know, we think about, but it's

308
00:11:23,920 --> 00:11:29,640
definitely hard to pinpoint. Yeah, great

309
00:11:26,640 --> 00:11:29,640
question.

310
00:11:30,720 --> 00:11:35,240
>> There was a question on the chat.

311
00:11:35,519 --> 00:11:40,560
>> How do I see that? It's pretty

312
00:11:38,399 --> 00:11:44,079
impressive for a bionatician. I'm

313
00:11:40,560 --> 00:11:45,920
actually very computer dumb. So, how do

314
00:11:44,079 --> 00:11:49,640
I see or can someone read the question

315
00:11:45,920 --> 00:11:49,640
on this this

316
00:11:54,959 --> 00:11:59,519
>> uh so the question is uh can you detail

317
00:11:57,040 --> 00:12:03,360
how you transform the DNA sequences into

318
00:11:59,519 --> 00:12:08,320
images that can be ingested into a CNN?

319
00:12:03,360 --> 00:12:10,480
>> Sure. So um what we do is we actually if

320
00:12:08,320 --> 00:12:12,639
I if you allow me to go back actually

321
00:12:10,480 --> 00:12:16,000
this slide has it. Yeah. So what we can

322
00:12:12,639 --> 00:12:20,720
do is so here's your here's my kind of

323
00:12:16,000 --> 00:12:22,320
you know um toy uh nucleotide sequence I

324
00:12:20,720 --> 00:12:24,720
created and actually in this case I kind

325
00:12:22,320 --> 00:12:26,079
of inserted a a gata motif right so gota

326
00:12:24,720 --> 00:12:28,959
is a transcription factor so named

327
00:12:26,079 --> 00:12:30,560
because it recognizes gata. So, but what

328
00:12:28,959 --> 00:12:33,519
you can see is what we do is we actually

329
00:12:30,560 --> 00:12:36,160
take this string and we actually cast it

330
00:12:33,519 --> 00:12:38,240
to an Lx4

331
00:12:36,160 --> 00:12:40,160
array and when you stack them together

332
00:12:38,240 --> 00:12:42,639
it becomes a tensor. But what we can do

333
00:12:40,160 --> 00:12:46,240
is numerically we can convert the DNA

334
00:12:42,639 --> 00:12:50,800
string into essentially what becomes uh

335
00:12:46,240 --> 00:12:52,959
a matrix or array that is of length L by

336
00:12:50,800 --> 00:12:55,760
in this case four. But you can imagine

337
00:12:52,959 --> 00:12:57,600
it's just by however many um nucleotides

338
00:12:55,760 --> 00:12:59,200
you have or uh letters you have in your

339
00:12:57,600 --> 00:13:01,120
alphabet. So if you're looking at amino

340
00:12:59,200 --> 00:13:03,600
acids it'd be L by 20. If you're looking

341
00:13:01,120 --> 00:13:05,200
at DNA or RNA it'd be L by4. So

342
00:13:03,600 --> 00:13:07,600
essentially we just convert it to a we

343
00:13:05,200 --> 00:13:11,120
call a one hot encoded array of ones and

344
00:13:07,600 --> 00:13:13,279
zeros where one is um that nucleotide is

345
00:13:11,120 --> 00:13:15,839
present zero being that nucleotide is

346
00:13:13,279 --> 00:13:18,720
absent.

347
00:13:15,839 --> 00:13:20,480
>> So you you do 1D convention basically

348
00:13:18,720 --> 00:13:22,079
just move the uh

349
00:13:20,480 --> 00:13:23,440
>> Exactly. Exactly. And this is a great

350
00:13:22,079 --> 00:13:25,279
toy example you essentially. So you have

351
00:13:23,440 --> 00:13:27,760
your convolution kernel here. This is

352
00:13:25,279 --> 00:13:29,120
what the DNA sequence actually you know

353
00:13:27,760 --> 00:13:30,160
uh this is what the convolution kernel

354
00:13:29,120 --> 00:13:32,079
you know that's what's actually

355
00:13:30,160 --> 00:13:35,839
learning. So it's in this case it's

356
00:13:32,079 --> 00:13:37,519
learning the motif you know as um as

357
00:13:35,839 --> 00:13:39,360
training progresses. And that's what I'm

358
00:13:37,519 --> 00:13:40,720
showing you know if I go one slide back

359
00:13:39,360 --> 00:13:43,040
that's what we're showing here. We're

360
00:13:40,720 --> 00:13:45,279
essentially here is your actually um

361
00:13:43,040 --> 00:13:47,839
here is your filter. These are your one

362
00:13:45,279 --> 00:13:49,839
two three four nucleotides. Here's your

363
00:13:47,839 --> 00:13:51,360
what we would say is W is your motif

364
00:13:49,839 --> 00:13:53,279
width that you set in your neural

365
00:13:51,360 --> 00:13:55,839
network. You know, typically you set it

366
00:13:53,279 --> 00:13:57,839
to say like 32, something that's

367
00:13:55,839 --> 00:13:59,680
computer scientists, we love our uh

368
00:13:57,839 --> 00:14:01,760
powers of two. It's, you know, most

369
00:13:59,680 --> 00:14:03,360
computationally efficient. But for our

370
00:14:01,760 --> 00:14:05,839
purposes, we know that motifs are

371
00:14:03,360 --> 00:14:07,600
between six and 20 base pairs. Um, so

372
00:14:05,839 --> 00:14:09,680
you can see that this convolution kernel

373
00:14:07,600 --> 00:14:11,279
as as the model learns, you can see the

374
00:14:09,680 --> 00:14:13,120
model learns it, you know, the accuracy

375
00:14:11,279 --> 00:14:16,800
of the network, you know, is approaching

376
00:14:13,120 --> 00:14:20,000
90%. You can see that you know that

377
00:14:16,800 --> 00:14:22,320
convolution filter that's randomly uh um

378
00:14:20,000 --> 00:14:25,360
initiated you know learns some

379
00:14:22,320 --> 00:14:28,360
biologically meaningful information.

380
00:14:25,360 --> 00:14:28,360
Yeah,

381
00:14:28,880 --> 00:14:32,720
it depends on um depends. Yeah, I got

382
00:14:31,040 --> 00:14:35,680
it. Yeah, I got it. She was loud enough.

383
00:14:32,720 --> 00:14:38,399
Um it it depends on uh what you're

384
00:14:35,680 --> 00:14:40,000
looking at. If if we're training in this

385
00:14:38,399 --> 00:14:41,760
case, this is trained on transcription

386
00:14:40,000 --> 00:14:44,000
factor chipsseek. So essentially

387
00:14:41,760 --> 00:14:46,560
anything that comes from a peak is

388
00:14:44,000 --> 00:14:48,800
assigned a label of one. You know you

389
00:14:46,560 --> 00:14:50,880
can use um you know just randomly pull

390
00:14:48,800 --> 00:14:52,240
genomic regions and assign them zero as

391
00:14:50,880 --> 00:14:53,920
long as they don't intersect a peak in

392
00:14:52,240 --> 00:14:55,839
this case or you can just you know

393
00:14:53,920 --> 00:14:57,920
usually what we just do ducleotide

394
00:14:55,839 --> 00:14:59,680
shuffling. So preserving ducleotide

395
00:14:57,920 --> 00:15:01,680
content in any any other region is

396
00:14:59,680 --> 00:15:04,680
assigned a zero.

397
00:15:01,680 --> 00:15:04,680
>> Yeah.

398
00:15:07,519 --> 00:15:12,160
So I'm wondering for the chipsick data

399
00:15:10,240 --> 00:15:15,120
used for the training of the models. So

400
00:15:12,160 --> 00:15:18,079
does the chipsick consist of diverse

401
00:15:15,120 --> 00:15:18,720
tissues or very tissue specific data

402
00:15:18,079 --> 00:15:21,839
sets?

403
00:15:18,720 --> 00:15:23,680
>> So you can um you can train in both uh

404
00:15:21,839 --> 00:15:25,680
what so if you say train on a single

405
00:15:23,680 --> 00:15:28,320
data set we would call that single class

406
00:15:25,680 --> 00:15:30,320
learning or single class or single task

407
00:15:28,320 --> 00:15:32,399
classification. You can absolutely do

408
00:15:30,320 --> 00:15:34,399
that. You can do it in a as you were

409
00:15:32,399 --> 00:15:36,720
saying a multitask fashion where

410
00:15:34,399 --> 00:15:39,120
essentially okay well given all of the

411
00:15:36,720 --> 00:15:41,279
TF chipsseek data set um all of the

412
00:15:39,120 --> 00:15:43,279
transcription factor chipsseek

413
00:15:41,279 --> 00:15:45,279
experiments in a given bio sample cell

414
00:15:43,279 --> 00:15:47,519
or tissue you train on all of them at

415
00:15:45,279 --> 00:15:48,800
once and that's actually um I'm not

416
00:15:47,519 --> 00:15:50,880
showing it here that was actually part

417
00:15:48,800 --> 00:15:52,720
of my uh part of my dissertation was

418
00:15:50,880 --> 00:15:54,639
essentially looking at what happens when

419
00:15:52,720 --> 00:15:56,480
you train these neural networks in a

420
00:15:54,639 --> 00:15:59,440
single task versus multitask

421
00:15:56,480 --> 00:16:02,720
classification um scheme because you

422
00:15:59,440 --> 00:16:07,920
could what happens is sure you can train

423
00:16:02,720 --> 00:16:09,519
um a a model to predict transcription

424
00:16:07,920 --> 00:16:11,600
factor binding for all transcription

425
00:16:09,519 --> 00:16:14,240
factors at once in a cell type. But you

426
00:16:11,600 --> 00:16:16,639
what happens is that model learns cell

427
00:16:14,240 --> 00:16:20,880
type specific regulatory

428
00:16:16,639 --> 00:16:24,079
um patterns, but those aren't then

429
00:16:20,880 --> 00:16:25,600
generalizable to an unseen cell type. Um

430
00:16:24,079 --> 00:16:27,040
the best example I can think of, and I'm

431
00:16:25,600 --> 00:16:28,399
sorry I don't have the slides to show,

432
00:16:27,040 --> 00:16:30,320
but essentially take the transcription

433
00:16:28,399 --> 00:16:33,040
factor rest, right? REST is responsible

434
00:16:30,320 --> 00:16:35,839
for um silencing neuronal genes and

435
00:16:33,040 --> 00:16:39,519
non-neuronal cell types. REST actually

436
00:16:35,839 --> 00:16:42,240
plays or plays um you know plays or is a

437
00:16:39,519 --> 00:16:44,240
co-actor with um different transcription

438
00:16:42,240 --> 00:16:46,160
factors depending on the cell type. So

439
00:16:44,240 --> 00:16:49,199
if you take a rest data set that's

440
00:16:46,160 --> 00:16:51,839
trained in say HEPG2, but you train on

441
00:16:49,199 --> 00:16:54,160
all of the TFS at once, it performs very

442
00:16:51,839 --> 00:16:57,440
poorly when you try to um make

443
00:16:54,160 --> 00:16:59,199
predictions on an unseen cell type. So I

444
00:16:57,440 --> 00:17:02,079
guess the long story short is yes you

445
00:16:59,199 --> 00:17:04,160
can technically you can train on one

446
00:17:02,079 --> 00:17:06,640
label you can train on on many labels as

447
00:17:04,160 --> 00:17:07,679
you want but you run into difficulty and

448
00:17:06,640 --> 00:17:09,520
this isn't you know this isn't

449
00:17:07,679 --> 00:17:11,679
bionirmatics or computational biology

450
00:17:09,520 --> 00:17:13,839
specific you run into difficulties when

451
00:17:11,679 --> 00:17:15,439
you try to make inferences in unseen

452
00:17:13,839 --> 00:17:19,720
cell types and you know we call this

453
00:17:15,439 --> 00:17:19,720
essentially a lack of generalization

454
00:17:23,039 --> 00:17:27,120
cool this is good this is good because I

455
00:17:24,480 --> 00:17:29,120
definitely didn't have enough slides

456
00:17:27,120 --> 00:17:30,640
All right.

457
00:17:29,120 --> 00:17:33,039
And like I said, my computer is just

458
00:17:30,640 --> 00:17:34,559
like, I'm don't want to work today.

459
00:17:33,039 --> 00:17:36,799
That's fine. Me neither. Oh, this is

460
00:17:34,559 --> 00:17:40,080
working now. So, we've used this as part

461
00:17:36,799 --> 00:17:42,640
of our factor book project to um learn

462
00:17:40,080 --> 00:17:43,919
and annotate alternative binding sites.

463
00:17:42,640 --> 00:17:46,080
So, this is essentially going back to

464
00:17:43,919 --> 00:17:48,880
the question of what we can see really

465
00:17:46,080 --> 00:17:52,400
well is when two transcription factors

466
00:17:48,880 --> 00:17:55,200
um uh they like to uh cooperate together

467
00:17:52,400 --> 00:17:57,440
within fixed proximity. So we see that

468
00:17:55,200 --> 00:18:00,720
really well and the benefit of neural

469
00:17:57,440 --> 00:18:03,280
networks over uh classical

470
00:18:00,720 --> 00:18:05,120
uh motif discovery approaches is there's

471
00:18:03,280 --> 00:18:06,640
no need to essentially mask learned

472
00:18:05,120 --> 00:18:09,440
motifs. So if you've ever used like a

473
00:18:06,640 --> 00:18:11,200
like the meme suite to learn motifs in

474
00:18:09,440 --> 00:18:13,440
your data set, you essentially have to

475
00:18:11,200 --> 00:18:15,360
you learn a motif, you then mask those

476
00:18:13,440 --> 00:18:18,320
instances and then you learn another

477
00:18:15,360 --> 00:18:20,880
motif. So you wouldn't see these uh homo

478
00:18:18,320 --> 00:18:23,280
and heterodimeic motifs because you

479
00:18:20,880 --> 00:18:25,120
would learn the monomer first, mask it,

480
00:18:23,280 --> 00:18:26,559
then you wouldn't see the two together.

481
00:18:25,120 --> 00:18:27,760
So that's kind of the advantage of deep

482
00:18:26,559 --> 00:18:30,960
learning is we can learn these

483
00:18:27,760 --> 00:18:33,679
alternative hetereroimeic motifs because

484
00:18:30,960 --> 00:18:36,559
of the um there's no need to mask uh

485
00:18:33,679 --> 00:18:39,840
instances in the input sequences

486
00:18:36,559 --> 00:18:42,720
and then so so sorry give people a

487
00:18:39,840 --> 00:18:44,640
headache. So, so to kind of uh increase

488
00:18:42,720 --> 00:18:47,520
the complexity so we you know we we can

489
00:18:44,640 --> 00:18:49,679
we can learn use very simple neural

490
00:18:47,520 --> 00:18:52,000
network CNN's to learn motifs and

491
00:18:49,679 --> 00:18:55,039
transcription factor chipsseek but we

492
00:18:52,000 --> 00:18:56,960
can taking this kind of a step further

493
00:18:55,039 --> 00:18:58,320
um we can change you know we're not

494
00:18:56,960 --> 00:19:00,320
going to change our input we're still

495
00:18:58,320 --> 00:19:03,039
going to use DNA sequence as input but

496
00:19:00,320 --> 00:19:06,320
what if instead we said okay can I learn

497
00:19:03,039 --> 00:19:09,679
the single base pair resolution

498
00:19:06,320 --> 00:19:11,840
um attack seek or DNA seek signal so um

499
00:19:09,679 --> 00:19:14,240
our collaborators uh at Stanford. Anel

500
00:19:11,840 --> 00:19:17,360
Kutaj has in his lab have developed

501
00:19:14,240 --> 00:19:18,960
Chrome BPnet um short for you know

502
00:19:17,360 --> 00:19:21,600
chromatin accessibility base pair

503
00:19:18,960 --> 00:19:23,600
resolution network and what chrome bpnet

504
00:19:21,600 --> 00:19:25,600
does is it actually consists of two

505
00:19:23,600 --> 00:19:29,280
neural networks. One neural network

506
00:19:25,600 --> 00:19:32,880
actually learns the intrinsic bias

507
00:19:29,280 --> 00:19:34,880
component of the assay. Right? So what

508
00:19:32,880 --> 00:19:38,480
happens is you train a neural network

509
00:19:34,880 --> 00:19:40,640
first on um non- peak regions to

510
00:19:38,480 --> 00:19:43,120
essentially learn the intrinsic enzyme

511
00:19:40,640 --> 00:19:45,520
bias whether it be TN5 in the case of

512
00:19:43,120 --> 00:19:47,919
attackseek or DNA one in the case of DNA

513
00:19:45,520 --> 00:19:50,559
seek and then you use that you freeze

514
00:19:47,919 --> 00:19:54,320
that model and then you train a larger

515
00:19:50,559 --> 00:19:57,120
neural network to learn the individual

516
00:19:54,320 --> 00:19:59,440
um uh biascorrected

517
00:19:57,120 --> 00:20:01,840
chromatin accessibility profile and all

518
00:19:59,440 --> 00:20:03,679
we're showing here is that here it's you

519
00:20:01,840 --> 00:20:05,840
know And if you essentially take the

520
00:20:03,679 --> 00:20:08,080
number of predicted cut sites versus the

521
00:20:05,840 --> 00:20:09,679
number of actual cut sites in peaks, it

522
00:20:08,080 --> 00:20:11,520
does a pretty good job when looking in

523
00:20:09,679 --> 00:20:13,440
this case across chromosomes. So the d

524
00:20:11,520 --> 00:20:16,240
the the neural network hasn't seen uh

525
00:20:13,440 --> 00:20:18,960
that data in that held out chromosome.

526
00:20:16,240 --> 00:20:20,799
Um what we can do is we can actually um

527
00:20:18,960 --> 00:20:22,720
so rather than just interpreting

528
00:20:20,799 --> 00:20:24,480
interpreting the filters as motifs,

529
00:20:22,720 --> 00:20:26,480
which is kind of the easiest way, we can

530
00:20:24,480 --> 00:20:28,080
run these networks in reverse. And when

531
00:20:26,480 --> 00:20:31,919
you run these networks in reverse, these

532
00:20:28,080 --> 00:20:33,840
attribution based approaches for um you

533
00:20:31,919 --> 00:20:36,640
know sequence interpretation, we can

534
00:20:33,840 --> 00:20:39,760
actually learn what individual base

535
00:20:36,640 --> 00:20:43,440
pairs in a the DNA sequence contributed

536
00:20:39,760 --> 00:20:45,440
to making that prediction. So we do that

537
00:20:43,440 --> 00:20:46,880
and I'm showing you here just kind of a

538
00:20:45,440 --> 00:20:48,960
I actually don't even know what locus it

539
00:20:46,880 --> 00:20:51,760
is. It just looked nice. We take this um

540
00:20:48,960 --> 00:20:53,760
so this locus has a DNA seek peak here.

541
00:20:51,760 --> 00:20:57,120
you can see that the, you know, the it's

542
00:20:53,760 --> 00:20:59,679
not this nice uh smooth peak we're

543
00:20:57,120 --> 00:21:01,360
accustomed to seeing um from chromatin

544
00:20:59,679 --> 00:21:02,640
accessibility data because all we're

545
00:21:01,360 --> 00:21:04,640
actually doing is we're just taking the

546
00:21:02,640 --> 00:21:07,280
five prime cut sites of the read. So

547
00:21:04,640 --> 00:21:09,520
we're actually DNA one made the cleavage

548
00:21:07,280 --> 00:21:11,520
or cleaved the DNA and what you see is

549
00:21:09,520 --> 00:21:14,559
there's actually this bowl that's left

550
00:21:11,520 --> 00:21:16,400
behind and then we can actually if um I

551
00:21:14,559 --> 00:21:18,080
chose a good color you would actually

552
00:21:16,400 --> 00:21:20,080
see that we can accurately predict with

553
00:21:18,080 --> 00:21:22,559
chrome bpnet the chromatin accessibility

554
00:21:20,080 --> 00:21:23,919
profile at that region but most

555
00:21:22,559 --> 00:21:26,000
importantly is we can use these

556
00:21:23,919 --> 00:21:28,000
attribution based methods to calculate

557
00:21:26,000 --> 00:21:30,720
nucleotide importance and you'll see

558
00:21:28,000 --> 00:21:32,960
that the attributions sit perfectly

559
00:21:30,720 --> 00:21:34,720
right in the middle of that bowl that

560
00:21:32,960 --> 00:21:38,400
divot that's left behind. Because when a

561
00:21:34,720 --> 00:21:39,840
transcription factor binds DNA, TN5 DNA

562
00:21:38,400 --> 00:21:42,720
one can't get in there to cleave the

563
00:21:39,840 --> 00:21:44,559
DNA. And you zoom in on this locus and

564
00:21:42,720 --> 00:21:46,640
you essentially cast these attribution

565
00:21:44,559 --> 00:21:48,480
scores to nucleotides, you know, using

566
00:21:46,640 --> 00:21:50,000
the corresponding genomic sequence and

567
00:21:48,480 --> 00:21:51,919
you see that they actually resemble

568
00:21:50,000 --> 00:21:54,159
transcription factor binding sites. And

569
00:21:51,919 --> 00:21:55,840
again, if I used a good color down here,

570
00:21:54,159 --> 00:21:57,440
you would actually see that the

571
00:21:55,840 --> 00:22:00,240
predicted chromatin accessibility

572
00:21:57,440 --> 00:22:02,159
profile has this really nice bowl where

573
00:22:00,240 --> 00:22:05,360
otherwise in the observed signal, it's

574
00:22:02,159 --> 00:22:07,039
kind of it's kind of more sparse. So

575
00:22:05,360 --> 00:22:10,080
what the the network is doing is the

576
00:22:07,039 --> 00:22:12,240
network is able to essentially learn

577
00:22:10,080 --> 00:22:14,880
properly learn the underlying intrinsic

578
00:22:12,240 --> 00:22:16,799
enzyme bias and then predict separate

579
00:22:14,880 --> 00:22:18,400
that and predict the true chromatin

580
00:22:16,799 --> 00:22:19,520
accessibility profile. And if you're

581
00:22:18,400 --> 00:22:21,919
interested in all this, they have a

582
00:22:19,520 --> 00:22:24,159
preprint and bioarchchive that um it's

583
00:22:21,919 --> 00:22:25,679
really nice. I think I referenced it on

584
00:22:24,159 --> 00:22:27,120
the last slide. And then here you can

585
00:22:25,679 --> 00:22:28,559
see better because I chose a better

586
00:22:27,120 --> 00:22:30,559
color. You can actually see this works

587
00:22:28,559 --> 00:22:32,640
for a taxi as well. And then same thing,

588
00:22:30,559 --> 00:22:35,200
you see the nice bowl where the

589
00:22:32,640 --> 00:22:36,720
transcription factor sits. Um and then

590
00:22:35,200 --> 00:22:38,159
same thing, you have the the bowl that's

591
00:22:36,720 --> 00:22:39,520
left behind in the observed signal. We

592
00:22:38,159 --> 00:22:41,679
can accurately predict it and those

593
00:22:39,520 --> 00:22:42,960
contributions or attribution scores fall

594
00:22:41,679 --> 00:22:44,320
right in the middle of that footprint

595
00:22:42,960 --> 00:22:47,440
where that transcription factor is

596
00:22:44,320 --> 00:22:49,280
indeed bound. Um, so what we can do is

597
00:22:47,440 --> 00:22:52,480
we can actually scan these contribution

598
00:22:49,280 --> 00:22:54,480
tracks. So I kind of relate this to um,

599
00:22:52,480 --> 00:22:57,360
if you've ever used like a FIMO find

600
00:22:54,480 --> 00:22:59,760
instances of motif occurrences um, you

601
00:22:57,360 --> 00:23:03,360
know, it's kind of part of our normal

602
00:22:59,760 --> 00:23:05,919
workflow for whether it be bulk attack,

603
00:23:03,360 --> 00:23:08,000
DNA seek um, or single cell attack seek.

604
00:23:05,919 --> 00:23:10,799
We we we essentially want to look for

605
00:23:08,000 --> 00:23:13,039
what sequence features are enriched in,

606
00:23:10,799 --> 00:23:15,200
you know, those peaks or those regions.

607
00:23:13,039 --> 00:23:16,799
So we always kind of scan, we use a a

608
00:23:15,200 --> 00:23:18,720
library of motifs and we scan the

609
00:23:16,799 --> 00:23:21,120
genomic sequence. Well, that's kind of

610
00:23:18,720 --> 00:23:23,120
the old school way. Well, now what if we

611
00:23:21,120 --> 00:23:25,039
essentially weighted the nucleotide

612
00:23:23,120 --> 00:23:26,880
sequence by how important that

613
00:23:25,039 --> 00:23:29,919
nucleotide sequence, how important each

614
00:23:26,880 --> 00:23:32,240
individual nucleotide is to making that

615
00:23:29,919 --> 00:23:35,200
prediction. Well, now we can kind of

616
00:23:32,240 --> 00:23:37,200
scan genomic sequences, but in a cell

617
00:23:35,200 --> 00:23:40,159
type specific context. And what we see

618
00:23:37,200 --> 00:23:42,400
is when this happens the peaks whether

619
00:23:40,159 --> 00:23:44,559
they be DNA or a taxi peaks um we

620
00:23:42,400 --> 00:23:46,799
observe this kind of biodal biodality

621
00:23:44,559 --> 00:23:49,120
where you have um you know your set of

622
00:23:46,799 --> 00:23:50,720
chro open chromatin regions that do not

623
00:23:49,120 --> 00:23:53,760
possess a transcription factor binding

624
00:23:50,720 --> 00:23:55,679
site for a given TF and those that do

625
00:23:53,760 --> 00:23:57,600
and what this looks like in uh the real

626
00:23:55,679 --> 00:23:59,840
world um is it looks like this. So what

627
00:23:57,600 --> 00:24:02,640
happens is we have these transcription

628
00:23:59,840 --> 00:24:04,400
factors exhibit this biodality in the

629
00:24:02,640 --> 00:24:06,640
cell types in which they are active or

630
00:24:04,400 --> 00:24:09,919
expressed. So, um, kind of cherrypicked

631
00:24:06,640 --> 00:24:11,440
three TFs here, CDCF, SP1, and NRF1. Uh,

632
00:24:09,919 --> 00:24:12,880
showing you here the gene expression.

633
00:24:11,440 --> 00:24:14,799
Just pulled the gene expression from,

634
00:24:12,880 --> 00:24:17,120
uh, Node. You can see that those three

635
00:24:14,799 --> 00:24:18,960
TFs are about evenly expressed across

636
00:24:17,120 --> 00:24:22,080
these, uh, three cells. We're looking at

637
00:24:18,960 --> 00:24:24,159
HEP G2, so a liver cell line, GM12878, a

638
00:24:22,080 --> 00:24:25,520
white blood cell line, and then K562, a

639
00:24:24,159 --> 00:24:28,000
red blood cell line. And then you see

640
00:24:25,520 --> 00:24:29,919
for CDCF, you see that indeed CDCF, we

641
00:24:28,000 --> 00:24:31,440
see this biodal distribution. And then

642
00:24:29,919 --> 00:24:33,520
what we're also doing here is we can

643
00:24:31,440 --> 00:24:35,600
actually use this biodal distribution to

644
00:24:33,520 --> 00:24:37,520
derive a threshold for essentially

645
00:24:35,600 --> 00:24:39,200
whether or not we see an instance of

646
00:24:37,520 --> 00:24:41,600
that motif or not. And if you've ever

647
00:24:39,200 --> 00:24:43,039
used like a FIMO to scan your genomic

648
00:24:41,600 --> 00:24:44,960
sequences before, there's always this

649
00:24:43,039 --> 00:24:46,960
problem of what Pvalue threshold do I

650
00:24:44,960 --> 00:24:49,120
set, you tend to find that different p

651
00:24:46,960 --> 00:24:51,200
values um are better for different

652
00:24:49,120 --> 00:24:53,039
length motifs, different motifs of

653
00:24:51,200 --> 00:24:54,799
information content. This kind of takes

654
00:24:53,039 --> 00:24:57,039
care of that problem for us. And then

655
00:24:54,799 --> 00:24:58,640
what you see is if you take all of the

656
00:24:57,039 --> 00:25:00,559
transcription factor binding sites, so

657
00:24:58,640 --> 00:25:02,320
the individual six to 20 base pair

658
00:25:00,559 --> 00:25:03,919
nucleotides corresponding to the

659
00:25:02,320 --> 00:25:06,880
underlying transcription factor, and you

660
00:25:03,919 --> 00:25:08,880
aggregate both the observed and the bias

661
00:25:06,880 --> 00:25:10,720
corrected signal. In this case, I think

662
00:25:08,880 --> 00:25:12,320
it's DNA. So you see that indeed you

663
00:25:10,720 --> 00:25:13,840
have a bowl for all of these

664
00:25:12,320 --> 00:25:15,279
transcription factors. So not only can

665
00:25:13,840 --> 00:25:16,400
we pluck them out, we can observe their

666
00:25:15,279 --> 00:25:17,679
footprinting. So you can also think

667
00:25:16,400 --> 00:25:19,760
about it as another means of a

668
00:25:17,679 --> 00:25:21,360
footprinting method. But like I said, we

669
00:25:19,760 --> 00:25:23,120
see this in a this is um you know, we

670
00:25:21,360 --> 00:25:25,360
see this in a cell type specific context

671
00:25:23,120 --> 00:25:27,279
just like my uh clicker likes to work in

672
00:25:25,360 --> 00:25:33,279
specific contexts.

673
00:25:27,279 --> 00:25:36,400
Um so we see that um in HEPG2 HNF4A only

674
00:25:33,279 --> 00:25:38,640
um exhibits this biodality uh HFA I'm

675
00:25:36,400 --> 00:25:41,279
sorry only exhibits this biodality in

676
00:25:38,640 --> 00:25:44,080
HEPG2 or herpatic or liver cells where

677
00:25:41,279 --> 00:25:46,960
otherwise it does not. Same thing for

678
00:25:44,080 --> 00:25:48,880
NFCappa B. We see that it only exhibits

679
00:25:46,960 --> 00:25:51,039
this biodal

680
00:25:48,880 --> 00:25:53,200
um this biodal pattern in white blood

681
00:25:51,039 --> 00:25:55,200
cells but not in the liver cells or the

682
00:25:53,200 --> 00:25:56,559
red blood cells. And then lastly, you

683
00:25:55,200 --> 00:25:58,640
can see where we're going with this.

684
00:25:56,559 --> 00:26:00,799
Again, you know, H&FR only expressed in

685
00:25:58,640 --> 00:26:04,320
the liver, NFCAPPA B1 expressed only in

686
00:26:00,799 --> 00:26:06,320
the white blood cells and then uh got

687
00:26:04,320 --> 00:26:10,720
one only expressed in the red blood

688
00:26:06,320 --> 00:26:13,360
cells and it's only biodal um in those

689
00:26:10,720 --> 00:26:14,960
uh red blood cells.

690
00:26:13,360 --> 00:26:17,200
So just kind of going in a little

691
00:26:14,960 --> 00:26:18,640
further, we can look at CTCF here. So

692
00:26:17,200 --> 00:26:21,039
what we actually have is we actually

693
00:26:18,640 --> 00:26:22,880
have 1500 of these trained models

694
00:26:21,039 --> 00:26:26,240
corresponding calculated attribution

695
00:26:22,880 --> 00:26:28,799
scores um for 1500 combined DNA and

696
00:26:26,240 --> 00:26:30,799
attackseek data set um from the encode

697
00:26:28,799 --> 00:26:32,720
consortium and this work is you know

698
00:26:30,799 --> 00:26:34,960
essentially will is part of kind of

699
00:26:32,720 --> 00:26:36,240
phase four of the encode project and if

700
00:26:34,960 --> 00:26:38,720
we essentially just take the difference

701
00:26:36,240 --> 00:26:40,480
in the two means of the populations just

702
00:26:38,720 --> 00:26:43,600
using a two component Gaussian mixture

703
00:26:40,480 --> 00:26:45,279
model um some questions I always get is

704
00:26:43,600 --> 00:26:48,400
you know two component Gaussian mixture

705
00:26:45,279 --> 00:26:50,000
model um doesn't seem to fit great. This

706
00:26:48,400 --> 00:26:52,320
actually ties into the question before

707
00:26:50,000 --> 00:26:54,559
about um you know essentially these

708
00:26:52,320 --> 00:26:55,919
composite motifs motifs that resemble

709
00:26:54,559 --> 00:26:57,840
both you know more than one

710
00:26:55,919 --> 00:26:59,679
transcription factor that tends to be

711
00:26:57,840 --> 00:27:00,799
what this middle regime is. So if you

712
00:26:59,679 --> 00:27:02,559
actually convert this into a three

713
00:27:00,799 --> 00:27:05,039
component Gaussian mixture model you'd

714
00:27:02,559 --> 00:27:06,559
see one here and then one there

715
00:27:05,039 --> 00:27:08,960
essentially you would see that kind of

716
00:27:06,559 --> 00:27:10,480
that murky population but for our

717
00:27:08,960 --> 00:27:12,240
purposes and moving forward two works

718
00:27:10,480 --> 00:27:13,679
fine. But you essentially see that if

719
00:27:12,240 --> 00:27:15,600
you calculate the difference in the two

720
00:27:13,679 --> 00:27:17,600
means of the two populations you see

721
00:27:15,600 --> 00:27:19,760
that CDCF a ubiquitously expressed

722
00:27:17,600 --> 00:27:21,360
transcription factor that mean that

723
00:27:19,760 --> 00:27:23,520
difference in those two means is always

724
00:27:21,360 --> 00:27:25,520
great right we express CDCF is active in

725
00:27:23,520 --> 00:27:28,000
every cell line master regulator Swiss

726
00:27:25,520 --> 00:27:30,559
army knife of the human genome um to be

727
00:27:28,000 --> 00:27:32,480
corny but if you look at H&F again our

728
00:27:30,559 --> 00:27:33,919
our liver specific or herpatic specific

729
00:27:32,480 --> 00:27:35,440
transcription factor we see this

730
00:27:33,919 --> 00:27:37,120
biodality so if you take the difference

731
00:27:35,440 --> 00:27:38,799
of the two me means we use that as like

732
00:27:37,120 --> 00:27:40,880
a surrogate for biodality right

733
00:27:38,799 --> 00:27:45,039
obviously we we do statistical test as

734
00:27:40,880 --> 00:27:47,279
well but um we can see that it's HF only

735
00:27:45,039 --> 00:27:49,200
exhibits this by modality in you know

736
00:27:47,279 --> 00:27:56,159
liver and related tissue so intestine

737
00:27:49,200 --> 00:27:58,399
large intestine um liver etc so um so

738
00:27:56,159 --> 00:27:59,840
well to this point in the or you know up

739
00:27:58,399 --> 00:28:02,240
to this point you know we've only

740
00:27:59,840 --> 00:28:06,159
presumed that the given transcription

741
00:28:02,240 --> 00:28:07,279
factor is bound at these TFBS's that

742
00:28:06,159 --> 00:28:09,440
we've plucked out from these open

743
00:28:07,279 --> 00:28:10,720
chromatin regions but if you then

744
00:28:09,440 --> 00:28:12,480
essentially you go back and you

745
00:28:10,720 --> 00:28:14,559
intersect these TFBS's against all the

746
00:28:12,480 --> 00:28:16,240
chipsseek data sets that we've curated,

747
00:28:14,559 --> 00:28:20,159
you actually find that even in the best

748
00:28:16,240 --> 00:28:23,120
instance, you know, say CTCF and REST

749
00:28:20,159 --> 00:28:24,880
are bound about 80% of the time to these

750
00:28:23,120 --> 00:28:27,840
sites that we've plucked out. And this

751
00:28:24,880 --> 00:28:29,039
is mostly also due to the fact that um

752
00:28:27,840 --> 00:28:31,120
you know, these transcription factor

753
00:28:29,039 --> 00:28:33,360
binding sites don't often perfectly

754
00:28:31,120 --> 00:28:34,640
match. They they look like one, but it

755
00:28:33,360 --> 00:28:36,960
you know, kind of a threat could still

756
00:28:34,640 --> 00:28:38,720
be a thresholding issue. Um, and then

757
00:28:36,960 --> 00:28:40,480
this is just to highlight the fact that,

758
00:28:38,720 --> 00:28:42,240
you know, you know, we understand the

759
00:28:40,480 --> 00:28:44,000
kind of the limitations of this work is

760
00:28:42,240 --> 00:28:46,399
the fact that you can really only do

761
00:28:44,000 --> 00:28:48,640
this at a transcription factor family

762
00:28:46,399 --> 00:28:52,159
level, right? We know that we know that

763
00:28:48,640 --> 00:28:54,559
CDCF and CDCL have for the most part

764
00:28:52,159 --> 00:28:57,120
indistinguishable transcription factor

765
00:28:54,559 --> 00:28:59,760
motifs. Now, we can we can use the fact

766
00:28:57,120 --> 00:29:01,760
that CDCF is expressed everywhere. CDCFL

767
00:28:59,760 --> 00:29:03,679
is only, you know, um, expressed in the

768
00:29:01,760 --> 00:29:05,200
germ line. So you know we can

769
00:29:03,679 --> 00:29:06,880
essentially we can use other lines or

770
00:29:05,200 --> 00:29:09,039
orthogonal lines of evidence to

771
00:29:06,880 --> 00:29:10,799
essentially you know oh we we know that

772
00:29:09,039 --> 00:29:12,640
most likely it's this transcription

773
00:29:10,799 --> 00:29:13,679
factor member of this family and not the

774
00:29:12,640 --> 00:29:15,440
other. So essentially just showing you

775
00:29:13,679 --> 00:29:18,480
here that as part of this work we've

776
00:29:15,440 --> 00:29:21,440
essentially taken 60 620

777
00:29:18,480 --> 00:29:23,440
um TF motifs derived from chipsseek data

778
00:29:21,440 --> 00:29:26,640
and we've clustered them into it's about

779
00:29:23,440 --> 00:29:29,840
350 unique clusters based on their

780
00:29:26,640 --> 00:29:31,760
binding specificity. Um but here just

781
00:29:29,840 --> 00:29:33,360
highlighting again it's more likely if

782
00:29:31,760 --> 00:29:35,840
that transcription factor exhibits this

783
00:29:33,360 --> 00:29:38,720
biodality it's more than you know more

784
00:29:35,840 --> 00:29:41,840
than likely going to be bound. But can

785
00:29:38,720 --> 00:29:43,840
we make a more accurate prediction about

786
00:29:41,840 --> 00:29:47,440
whether or not that transcription factor

787
00:29:43,840 --> 00:29:49,360
binds this TFBS that we've plucked out?

788
00:29:47,440 --> 00:29:51,279
Well, what we can do is we can take all

789
00:29:49,360 --> 00:29:53,120
of these um you know chrome bpnet

790
00:29:51,279 --> 00:29:55,039
associated track. So we can take our

791
00:29:53,120 --> 00:29:57,279
observed signal profile, our predicted

792
00:29:55,039 --> 00:29:59,039
signal profile, the bias corrected

793
00:29:57,279 --> 00:30:01,120
profile

794
00:29:59,039 --> 00:30:02,480
um and then these contribution scores as

795
00:30:01,120 --> 00:30:04,080
well as evolutionary conservation

796
00:30:02,480 --> 00:30:06,159
because why not? It's just another you

797
00:30:04,080 --> 00:30:07,919
know tacking on another uh vector. And

798
00:30:06,159 --> 00:30:09,840
we can use that one hot encoded DNA

799
00:30:07,919 --> 00:30:11,840
sequence at these essentially puditive

800
00:30:09,840 --> 00:30:13,520
TFBS's or transcription factor binding

801
00:30:11,840 --> 00:30:16,000
sites. we can pass them through just a

802
00:30:13,520 --> 00:30:19,200
very small neural network um and we can

803
00:30:16,000 --> 00:30:21,440
actually make inferences or accurately

804
00:30:19,200 --> 00:30:24,000
predict that a transcription factor is

805
00:30:21,440 --> 00:30:26,159
bound at that location or TFBS that

806
00:30:24,000 --> 00:30:28,240
we've plucked out and more specifically

807
00:30:26,159 --> 00:30:30,799
if a transcription factor exhibits this

808
00:30:28,240 --> 00:30:33,360
biodality in both the training and the

809
00:30:30,799 --> 00:30:35,279
testing cell type we can accurately make

810
00:30:33,360 --> 00:30:37,760
inferences across cell type and this

811
00:30:35,279 --> 00:30:39,120
goes back to um we talked about in a

812
00:30:37,760 --> 00:30:41,520
previous question we talked about you

813
00:30:39,120 --> 00:30:42,799
know um the lack of generalization or

814
00:30:41,520 --> 00:30:44,480
neuronet networks, one of their

815
00:30:42,799 --> 00:30:46,240
downfalls is their inability to

816
00:30:44,480 --> 00:30:48,559
generalize across cell type. And that's

817
00:30:46,240 --> 00:30:50,960
really the focus of my work is to be

818
00:30:48,559 --> 00:30:54,000
able to make make accurate predictions

819
00:30:50,960 --> 00:30:56,320
across cell type and know specifically

820
00:30:54,000 --> 00:30:58,480
when we are confident in making those

821
00:30:56,320 --> 00:31:00,640
predictions. So highlighting here that

822
00:30:58,480 --> 00:31:04,399
essentially okay well you take um DNA in

823
00:31:00,640 --> 00:31:05,919
K562 and you train and then we're also

824
00:31:04,399 --> 00:31:07,760
training cross cell type and cross

825
00:31:05,919 --> 00:31:09,440
chromosome. So um if you ever done this

826
00:31:07,760 --> 00:31:11,760
work before, you essentially I train on

827
00:31:09,440 --> 00:31:13,840
all chromosomes but chromosome 1. I

828
00:31:11,760 --> 00:31:15,520
leave chromosome one out. And then when

829
00:31:13,840 --> 00:31:17,760
I make my inferences, I make my

830
00:31:15,520 --> 00:31:20,880
inferences across cell type but also

831
00:31:17,760 --> 00:31:22,720
cross chromosome. So if if there are any

832
00:31:20,880 --> 00:31:24,559
sort of patterns that are specific to a

833
00:31:22,720 --> 00:31:26,559
chromosome with respect to transcription

834
00:31:24,559 --> 00:31:29,360
factor binding, the model will never see

835
00:31:26,559 --> 00:31:32,880
it. So we can accurately make inferences

836
00:31:29,360 --> 00:31:35,600
you know within DNA in K562 cross cell

837
00:31:32,880 --> 00:31:37,360
type cross chromosome. We can do that.

838
00:31:35,600 --> 00:31:39,200
We can also same thing we can do the

839
00:31:37,360 --> 00:31:41,200
same thing for attack given attack seek

840
00:31:39,200 --> 00:31:44,399
in K562 we can accurately predict

841
00:31:41,200 --> 00:31:47,760
transcription factor binding in HEPG2

842
00:31:44,399 --> 00:31:49,360
and then the coolest part is um again

843
00:31:47,760 --> 00:31:51,679
really cool that my clicker started to

844
00:31:49,360 --> 00:31:54,559
decided to not work right there we can

845
00:31:51,679 --> 00:31:57,600
actually if you have a model or that's

846
00:31:54,559 --> 00:31:59,519
trained on DNA you can actually use that

847
00:31:57,600 --> 00:32:01,679
model to make inferences not only cross

848
00:31:59,519 --> 00:32:04,080
cell type cross chromosome but also

849
00:32:01,679 --> 00:32:05,840
cross assay if you have a taxseek data

850
00:32:04,080 --> 00:32:08,960
so this is actually really because the

851
00:32:05,840 --> 00:32:12,000
you know the encode consortium has um

852
00:32:08,960 --> 00:32:14,960
dozens if not hundreds of very deeply

853
00:32:12,000 --> 00:32:17,200
sequenced DNA seek data but for the most

854
00:32:14,960 --> 00:32:19,279
part due to costs the number of cells

855
00:32:17,200 --> 00:32:21,679
required at this point most people just

856
00:32:19,279 --> 00:32:23,200
do attack seek so but we can leverage

857
00:32:21,679 --> 00:32:25,440
all that information that we have as

858
00:32:23,200 --> 00:32:28,640
part of the encode consortium to make

859
00:32:25,440 --> 00:32:31,440
inferences cross cell type cross assay

860
00:32:28,640 --> 00:32:34,000
in essentially unseen attack seek data.

861
00:32:31,440 --> 00:32:36,960
Now what can we do with this? And so

862
00:32:34,000 --> 00:32:38,640
what we can do is well okay so now we we

863
00:32:36,960 --> 00:32:41,840
know which TFs we can accurately

864
00:32:38,640 --> 00:32:43,760
annotate and predict they are bound in a

865
00:32:41,840 --> 00:32:46,559
given cell type. We can construct this

866
00:32:43,760 --> 00:32:48,720
matrix of say we can take cy regulatory

867
00:32:46,559 --> 00:32:51,440
elements from encode. So promoters,

868
00:32:48,720 --> 00:32:53,279
enhancers, insulators, silencers from

869
00:32:51,440 --> 00:32:55,360
the encode consortium and we can

870
00:32:53,279 --> 00:32:57,279
annotate how many times this is just a

871
00:32:55,360 --> 00:32:59,840
toy example chatbt gave me on the train

872
00:32:57,279 --> 00:33:02,080
today. And you can essentially say okay

873
00:32:59,840 --> 00:33:04,799
well we can calculate the number of

874
00:33:02,080 --> 00:33:06,799
times that a given cy regulatory element

875
00:33:04,799 --> 00:33:08,799
harbors a transcription factor of

876
00:33:06,799 --> 00:33:10,720
interest. Again the ones that we know we

877
00:33:08,799 --> 00:33:12,640
can accurately pluck out. And then what

878
00:33:10,720 --> 00:33:15,919
we can do is we can embed this matrix of

879
00:33:12,640 --> 00:33:17,360
integers again into 2D space using um

880
00:33:15,919 --> 00:33:20,159
and you actually see that in this case

881
00:33:17,360 --> 00:33:23,039
about 100,000 cy regulatory elements

882
00:33:20,159 --> 00:33:25,760
that are open active in HEPG2 they

883
00:33:23,039 --> 00:33:28,159
actually form many distinct clusters

884
00:33:25,760 --> 00:33:30,480
based on cy regulatory syntax. So

885
00:33:28,159 --> 00:33:32,640
essentially which transcription factors

886
00:33:30,480 --> 00:33:34,480
they harbor transcription factor binding

887
00:33:32,640 --> 00:33:37,519
sites for. And here I'm just

888
00:33:34,480 --> 00:33:40,240
highlighting again highlighting that if

889
00:33:37,519 --> 00:33:43,360
you um just plucking out this specific

890
00:33:40,240 --> 00:33:47,679
cluster three here that this cluster

891
00:33:43,360 --> 00:33:49,600
three are your HEPG2 specific cis

892
00:33:47,679 --> 00:33:51,360
regulatory elements open chromatin

893
00:33:49,600 --> 00:33:52,799
regions again promoters and these are

894
00:33:51,360 --> 00:33:55,039
enhancers in this case they're they're

895
00:33:52,799 --> 00:33:57,200
all um enhancer like they're all distal

896
00:33:55,039 --> 00:33:58,880
um from a TSS but they're all the ones

897
00:33:57,200 --> 00:34:02,480
that harbor transcription factor binding

898
00:33:58,880 --> 00:34:05,840
sites for H&F1A and HNF1B. So we can use

899
00:34:02,480 --> 00:34:07,279
this to begin to essentially you know um

900
00:34:05,840 --> 00:34:09,679
interrogate these cyst regulatory

901
00:34:07,279 --> 00:34:12,079
elements in terms of you know not only

902
00:34:09,679 --> 00:34:14,000
are they active but why are they active

903
00:34:12,079 --> 00:34:16,879
who's contributing to their activity in

904
00:34:14,000 --> 00:34:20,159
the sense of who's binding there.

905
00:34:16,879 --> 00:34:21,919
So then lastly what we can do is well we

906
00:34:20,159 --> 00:34:23,760
just looked at one cell line and we said

907
00:34:21,919 --> 00:34:26,399
okay well in HEPG2 we're able to

908
00:34:23,760 --> 00:34:28,240
annotate which um you know which

909
00:34:26,399 --> 00:34:29,919
transcription factors are binding to

910
00:34:28,240 --> 00:34:32,480
which cis regulatory elements but if you

911
00:34:29,919 --> 00:34:34,720
look at one cyregulatory element across

912
00:34:32,480 --> 00:34:36,800
a host of um cells and tissue types and

913
00:34:34,720 --> 00:34:39,200
here I'm just um essentially showing you

914
00:34:36,800 --> 00:34:42,879
across I think this is actually um it's

915
00:34:39,200 --> 00:34:45,919
combined um bulk attack data with also

916
00:34:42,879 --> 00:34:48,879
single cell um single cell brain data up

917
00:34:45,919 --> 00:34:51,119
here you actually see that you see

918
00:34:48,879 --> 00:34:53,359
different transcription factor usage

919
00:34:51,119 --> 00:34:56,079
across different cell lines and we refer

920
00:34:53,359 --> 00:35:00,000
to these these regions as polyntactic.

921
00:34:56,079 --> 00:35:02,800
So they're open across several cells and

922
00:35:00,000 --> 00:35:05,119
tissue or tissue types but they do so or

923
00:35:02,800 --> 00:35:07,040
they're leveraging or using different

924
00:35:05,119 --> 00:35:09,520
transcription factors and different

925
00:35:07,040 --> 00:35:11,280
transcription factor binding sites in

926
00:35:09,520 --> 00:35:14,160
their activity. So this is kind of part

927
00:35:11,280 --> 00:35:15,839
of my work is you know how often you

928
00:35:14,160 --> 00:35:17,599
know obviously I just kind of I can just

929
00:35:15,839 --> 00:35:19,200
generate a bunch of PGs and I can just

930
00:35:17,599 --> 00:35:20,800
pick out the which one looks best but

931
00:35:19,200 --> 00:35:23,359
essentially you know part of our work is

932
00:35:20,800 --> 00:35:26,880
essentially can we calculate or can we

933
00:35:23,359 --> 00:35:29,280
quantify how often cis regulatory

934
00:35:26,880 --> 00:35:31,440
elements exhibit this polyntactic

935
00:35:29,280 --> 00:35:33,280
behavior. So that's kind of like kind of

936
00:35:31,440 --> 00:35:35,119
an offshoot of this project that I'm

937
00:35:33,280 --> 00:35:37,520
working on. Um and I think I think

938
00:35:35,119 --> 00:35:38,960
that's it. Yeah. So, um, you know, I

939
00:35:37,520 --> 00:35:40,320
just like to say, you know, thank you,

940
00:35:38,960 --> 00:35:41,839
you know, very much for having me. This

941
00:35:40,320 --> 00:35:44,160
is, um, you know, a really great

942
00:35:41,839 --> 00:35:46,480
opportunity to highlight all the the

943
00:35:44,160 --> 00:35:48,960
great work, um, of the Wang lab and more

944
00:35:46,480 --> 00:35:51,520
lab. We're essentially one, uh, giant,

945
00:35:48,960 --> 00:35:53,680
uh, conglomerate or entity at UMass Chan

946
00:35:51,520 --> 00:35:55,520
Medical School. Um, but would just like

947
00:35:53,680 --> 00:35:58,240
to thank, you know, all of the lab

948
00:35:55,520 --> 00:36:01,520
members, all of our, um, HPC admins

949
00:35:58,240 --> 00:36:03,280
that, you know, um, anytime I break

950
00:36:01,520 --> 00:36:06,160
something, they fix it for me, which is

951
00:36:03,280 --> 00:36:08,000
quite often. Um so yeah and with that I

952
00:36:06,160 --> 00:36:11,240
will take uh be happy to take any and

953
00:36:08,000 --> 00:36:11,240
all questions.

954
00:36:18,400 --> 00:36:21,920
>> Thank you. Great presentation um for

955
00:36:20,079 --> 00:36:23,680
your last slide where you showed

956
00:36:21,920 --> 00:36:25,520
basically like in different cell types

957
00:36:23,680 --> 00:36:28,000
or cell lines that these different

958
00:36:25,520 --> 00:36:29,520
regions um can be active due to

959
00:36:28,000 --> 00:36:31,520
different transcription factors. How

960
00:36:29,520 --> 00:36:33,599
much does that correlate with like the

961
00:36:31,520 --> 00:36:35,760
expression of that transcription factor

962
00:36:33,599 --> 00:36:38,240
in those cell types? Like would you be

963
00:36:35,760 --> 00:36:40,240
able to just infer that based on like

964
00:36:38,240 --> 00:36:42,160
what transcription factors are active?

965
00:36:40,240 --> 00:36:43,520
>> Exactly. Exactly. And it it comes down

966
00:36:42,160 --> 00:36:45,200
to at the end of the day those

967
00:36:43,520 --> 00:36:48,400
transcription factors do end up being

968
00:36:45,200 --> 00:36:50,400
the ones that are expressed. Um but we

969
00:36:48,400 --> 00:36:52,960
just don't know how often this is

970
00:36:50,400 --> 00:36:54,320
occurring. Um we don't know say this I

971
00:36:52,960 --> 00:36:56,560
know for a fact this is like an enhancer

972
00:36:54,320 --> 00:36:59,200
region. Is this enhancer regulating the

973
00:36:56,560 --> 00:37:02,480
same gene in one cell type as it is

974
00:36:59,200 --> 00:37:03,760
another? So questions like that as well.

975
00:37:02,480 --> 00:37:05,599
But yeah, absolutely. You can you can

976
00:37:03,760 --> 00:37:06,880
trace this back to the gene expression

977
00:37:05,599 --> 00:37:08,000
just like I did like a couple slides

978
00:37:06,880 --> 00:37:11,160
ago.

979
00:37:08,000 --> 00:37:11,160
>> Thank you.

980
00:37:18,800 --> 00:37:21,800
>> Hi.

981
00:37:22,960 --> 00:37:26,320
Um

982
00:37:24,480 --> 00:37:28,640
I wanted to ask about the if you can go

983
00:37:26,320 --> 00:37:30,800
back to the biodality.

984
00:37:28,640 --> 00:37:32,720
Um

985
00:37:30,800 --> 00:37:36,960
like

986
00:37:32,720 --> 00:37:40,800
in the next example I guess H HNF4 was

987
00:37:36,960 --> 00:37:44,960
it that you have a more zoomed in uh oh

988
00:37:40,800 --> 00:37:47,440
like yeah this one. So here

989
00:37:44,960 --> 00:37:50,640
>> um like I wouldn't have said that this

990
00:37:47,440 --> 00:37:53,839
is biodal. So no matter what you try

991
00:37:50,640 --> 00:37:56,720
always to fit a bimodel distribution

992
00:37:53,839 --> 00:37:58,800
like how do you evaluate after like for

993
00:37:56,720 --> 00:38:00,560
something that is less known you say

994
00:37:58,800 --> 00:38:02,160
okay let's assume that this is by model

995
00:38:00,560 --> 00:38:04,800
you fit the distribution and then you

996
00:38:02,160 --> 00:38:06,320
see some scores do you rely on

997
00:38:04,800 --> 00:38:08,240
literature information how do you know

998
00:38:06,320 --> 00:38:09,760
that that is not like just because

999
00:38:08,240 --> 00:38:10,960
you're going to always divide something

1000
00:38:09,760 --> 00:38:12,960
you're going to get something

1001
00:38:10,960 --> 00:38:14,480
>> yeah exactly exactly and actually in

1002
00:38:12,960 --> 00:38:16,000
talking with you know Jacob's been a

1003
00:38:14,480 --> 00:38:17,440
huge help on this project too and that's

1004
00:38:16,000 --> 00:38:18,720
exactly something the first thing he

1005
00:38:17,440 --> 00:38:21,040
brought up is how [clears throat] do you

1006
00:38:18,720 --> 00:38:23,040
know you're just not artificially,

1007
00:38:21,040 --> 00:38:26,079
>> you know, fitting two means where you

1008
00:38:23,040 --> 00:38:28,640
should really only have one, right? Um,

1009
00:38:26,079 --> 00:38:30,880
and so right now we just use the

1010
00:38:28,640 --> 00:38:35,359
difference in the two means as our

1011
00:38:30,880 --> 00:38:37,839
surrogate for biodality. Now I've also

1012
00:38:35,359 --> 00:38:39,599
you know incorporated more statistically

1013
00:38:37,839 --> 00:38:42,240
rigorous methods like Hardigan's dip

1014
00:38:39,599 --> 00:38:44,960
test to you know essentially assign a p

1015
00:38:42,240 --> 00:38:47,440
value for how much the distribution

1016
00:38:44,960 --> 00:38:49,920
deviates from you know uni modality I

1017
00:38:47,440 --> 00:38:51,760
guess for lack of a better term. Um but

1018
00:38:49,920 --> 00:38:55,280
that actually you know wouldn't actually

1019
00:38:51,760 --> 00:38:57,839
catch this case. So it's definitely it's

1020
00:38:55,280 --> 00:38:59,520
a it's a technical certainly a technical

1021
00:38:57,839 --> 00:39:01,440
problem that we have to that we have to

1022
00:38:59,520 --> 00:39:02,720
push through because what happens is you

1023
00:39:01,440 --> 00:39:04,240
actually see you know there's like

1024
00:39:02,720 --> 00:39:05,839
there's a you can imagine a mode there

1025
00:39:04,240 --> 00:39:07,680
like you could fit as many Gaussians as

1026
00:39:05,839 --> 00:39:09,119
you want into this right so essentially

1027
00:39:07,680 --> 00:39:10,480
you see like there's like a Gaussian

1028
00:39:09,119 --> 00:39:12,400
here and what happens is it actually

1029
00:39:10,480 --> 00:39:16,720
turns out to you know these are the

1030
00:39:12,400 --> 00:39:19,200
sequences that perfectly match the CA a

1031
00:39:16,720 --> 00:39:21,200
in the motif but then you see the

1032
00:39:19,200 --> 00:39:24,720
population here is the ones that only

1033
00:39:21,200 --> 00:39:26,720
slightly deviate from the consensus and

1034
00:39:24,720 --> 00:39:28,960
the problem is because you know motifs

1035
00:39:26,720 --> 00:39:30,720
are a different length you know they you

1036
00:39:28,960 --> 00:39:33,280
know they don't just it's not a picture

1037
00:39:30,720 --> 00:39:36,320
perfect biodal unimodal pattern so yeah

1038
00:39:33,280 --> 00:39:37,760
it's definitely an ongoing technical

1039
00:39:36,320 --> 00:39:39,280
problem that we have to solve because of

1040
00:39:37,760 --> 00:39:42,400
the biological implications

1041
00:39:39,280 --> 00:39:44,560
>> and kind of related to that and I

1042
00:39:42,400 --> 00:39:47,440
remember because I remember you showed

1043
00:39:44,560 --> 00:39:51,119
me this a long time ago but for how you

1044
00:39:47,440 --> 00:39:53,920
presented you rely a lot of course on

1045
00:39:51,119 --> 00:39:55,920
the motif like chromi pinet usually uses

1046
00:39:53,920 --> 00:39:57,839
modisco after like you know because yeah

1047
00:39:55,920 --> 00:39:59,680
the sequence attribution score

1048
00:39:57,839 --> 00:40:02,160
>> per se can still be yeah I don't know

1049
00:39:59,680 --> 00:40:04,000
what I'm looking at right so you either

1050
00:40:02,160 --> 00:40:06,160
>> so in your case you're relying on the

1051
00:40:04,000 --> 00:40:10,160
motif but I remember you in some

1052
00:40:06,160 --> 00:40:13,119
instances you improve the motif right

1053
00:40:10,160 --> 00:40:16,000
>> like you are able so I I guess what I'm

1054
00:40:13,119 --> 00:40:17,920
asking is how good does a motif need to

1055
00:40:16,000 --> 00:40:21,680
be for you to catch it basically how

1056
00:40:17,920 --> 00:40:23,760
robust it is and uh and also through

1057
00:40:21,680 --> 00:40:25,280
this method can you actually improve

1058
00:40:23,760 --> 00:40:27,119
just per database and

1059
00:40:25,280 --> 00:40:30,480
>> yeah so that's part of this as well so

1060
00:40:27,119 --> 00:40:33,839
essentially what I've done is for for

1061
00:40:30,480 --> 00:40:36,800
this every every TF that went into this

1062
00:40:33,839 --> 00:40:39,200
heat map is a TF motif that I have hand

1063
00:40:36,800 --> 00:40:40,560
curated so

1064
00:40:39,200 --> 00:40:42,160
and again it's kind of you know

1065
00:40:40,560 --> 00:40:44,079
unfortunately circular in the fact that

1066
00:40:42,160 --> 00:40:45,680
I'm the one who curates the database and

1067
00:40:44,079 --> 00:40:47,440
then I'm the one doing so like you know

1068
00:40:45,680 --> 00:40:49,680
it is a bit circular in that sense but

1069
00:40:47,440 --> 00:40:51,359
I'm essentially hand curating using the

1070
00:40:49,680 --> 00:40:54,480
most informationrich

1071
00:40:51,359 --> 00:40:56,240
motifs to do this essentially scanning

1072
00:40:54,480 --> 00:40:57,920
process because you know you sound

1073
00:40:56,240 --> 00:41:00,720
familiar with TF modiscoco and using

1074
00:40:57,920 --> 00:41:02,880
secret based methods to do denovo motis

1075
00:41:00,720 --> 00:41:05,520
discovery from contribution scores and

1076
00:41:02,880 --> 00:41:07,440
sometimes those motifs don't if you say

1077
00:41:05,520 --> 00:41:09,440
like run tomtom against those discovered

1078
00:41:07,440 --> 00:41:12,480
motifs against the literature aren't

1079
00:41:09,440 --> 00:41:15,839
fantastic matches right so that's why I

1080
00:41:12,480 --> 00:41:17,760
use the handcurated ones from chipsseek

1081
00:41:15,839 --> 00:41:19,760
um you know using like this just the

1082
00:41:17,760 --> 00:41:22,000
very simple kernel scanning method which

1083
00:41:19,760 --> 00:41:23,839
I find gives better motifs than the

1084
00:41:22,000 --> 00:41:26,000
attribution based methods.

1085
00:41:23,839 --> 00:41:27,920
>> And so what how many are you left with

1086
00:41:26,000 --> 00:41:29,040
from 1,500?

1087
00:41:27,920 --> 00:41:29,760
>> So 620.

1088
00:41:29,040 --> 00:41:33,200
>> 620.

1089
00:41:29,760 --> 00:41:36,560
>> 620. So they're the only 620 that I am

1090
00:41:33,200 --> 00:41:37,599
confident in from the chipsseek. Um

1091
00:41:36,560 --> 00:41:40,599
>> Yeah. Yeah. No, that's fine.

1092
00:41:37,599 --> 00:41:40,599
>> Yeah.

1093
00:41:40,800 --> 00:41:44,760
Nobody has asked it though.

1094
00:41:44,880 --> 00:41:50,079
>> This is for this is for the future.

1095
00:41:46,800 --> 00:41:52,880
>> Yeah. I there's been I think someone in

1096
00:41:50,079 --> 00:41:54,400
the lab did it but there are um other

1097
00:41:52,880 --> 00:41:57,200
papers that show that that of course a

1098
00:41:54,400 --> 00:41:59,359
lot of these motifs are more um

1099
00:41:57,200 --> 00:42:02,400
sensitive to others to genotype

1100
00:41:59,359 --> 00:42:05,760
variation. They show a little frequenc a

1101
00:42:02,400 --> 00:42:10,079
specific binding. So

1102
00:42:05,760 --> 00:42:12,560
have you thought are it's in your future

1103
00:42:10,079 --> 00:42:16,560
interest to try to incorporate genetics

1104
00:42:12,560 --> 00:42:18,480
and try to characterize them more in

1105
00:42:16,560 --> 00:42:20,880
like go to the basically to the clinical

1106
00:42:18,480 --> 00:42:22,560
like look up variations and try to

1107
00:42:20,880 --> 00:42:25,359
annotate

1108
00:42:22,560 --> 00:42:29,040
which one are more uh

1109
00:42:25,359 --> 00:42:31,760
oh yeah uh which one are

1110
00:42:29,040 --> 00:42:34,480
more likely to respond to a snip

1111
00:42:31,760 --> 00:42:36,000
variation more causal or something and

1112
00:42:34,480 --> 00:42:36,319
intersecting with G was this kind of

1113
00:42:36,000 --> 00:42:38,079
things.

1114
00:42:36,319 --> 00:42:40,960
>> Exactly. And that's like the that will

1115
00:42:38,079 --> 00:42:43,440
be essentially the hopefully the you

1116
00:42:40,960 --> 00:42:45,520
know tying this all together will be

1117
00:42:43,440 --> 00:42:48,800
exactly that intersecting all of these

1118
00:42:45,520 --> 00:42:50,640
essentially we'll use the the 1500

1119
00:42:48,800 --> 00:42:52,560
endode experiments DNA synagic

1120
00:42:50,640 --> 00:42:54,079
experiments to essentially call an atlas

1121
00:42:52,560 --> 00:42:55,280
of these transcription factor binding

1122
00:42:54,079 --> 00:42:56,240
sites and then that'll be one of the

1123
00:42:55,280 --> 00:42:57,839
first things we do is essentially

1124
00:42:56,240 --> 00:43:03,000
intersecting them with all the G-W was

1125
00:42:57,839 --> 00:43:03,000
and all these snips to do exactly that.

1126
00:43:04,720 --> 00:43:06,720
Right.

1127
00:43:05,119 --> 00:43:07,200
>> So this is going to be just posterior

1128
00:43:06,720 --> 00:43:08,880
like

1129
00:43:07,200 --> 00:43:10,960
>> Exactly. Yeah. So in in the case that

1130
00:43:08,880 --> 00:43:12,880
you said no that's not hasn't been using

1131
00:43:10,960 --> 00:43:14,800
like looking specifically at a specific

1132
00:43:12,880 --> 00:43:16,319
binding. No that's not not in the

1133
00:43:14,800 --> 00:43:18,480
immediate future.

1134
00:43:16,319 --> 00:43:21,200
>> Someone did

1135
00:43:18,480 --> 00:43:22,560
right or at least what was available at

1136
00:43:21,200 --> 00:43:24,880
the time

1137
00:43:22,560 --> 00:43:25,520
>> and did an alo specific study on that.

1138
00:43:24,880 --> 00:43:27,040
>> Yes.

1139
00:43:25,520 --> 00:43:29,440
>> Unfortunately that unfortunately that's

1140
00:43:27,040 --> 00:43:31,280
still sitting on um

1141
00:43:29,440 --> 00:43:32,720
>> this is the publish. Oh, publish.

1142
00:43:31,280 --> 00:43:33,280
>> I think someone did it.

1143
00:43:32,720 --> 00:43:34,800
>> Okay.

1144
00:43:33,280 --> 00:43:39,960
>> I double check.

1145
00:43:34,800 --> 00:43:39,960
>> Yeah. Yeah, show me. Yeah, show me.

1146
00:43:42,480 --> 00:43:48,240
Uh so for in your last slide um again

1147
00:43:46,480 --> 00:43:49,920
bringing in the genetics here I don't

1148
00:43:48,240 --> 00:43:52,000
know if you you mentioned for example

1149
00:43:49,920 --> 00:43:55,520
that you don't necessarily know if this

1150
00:43:52,000 --> 00:43:57,119
different um uh elements through the

1151
00:43:55,520 --> 00:43:59,760
different through binding to different

1152
00:43:57,119 --> 00:44:02,079
TFS will even regulate the same gene in

1153
00:43:59,760 --> 00:44:04,480
the in different tissues etc. So I was

1154
00:44:02,079 --> 00:44:07,280
wondering if you have already a few

1155
00:44:04,480 --> 00:44:10,000
examples or if you plan to have some in

1156
00:44:07,280 --> 00:44:12,960
the future of specific genes and how

1157
00:44:10,000 --> 00:44:14,800
that or maybe take uh this elements this

1158
00:44:12,960 --> 00:44:16,640
regulatory elements that we know what

1159
00:44:14,800 --> 00:44:19,280
gene they regulate at least in some

1160
00:44:16,640 --> 00:44:23,040
tissues because for example it's been um

1161
00:44:19,280 --> 00:44:25,040
proposed that more essential gene for

1162
00:44:23,040 --> 00:44:27,280
for example they have more complex

1163
00:44:25,040 --> 00:44:28,720
regulatory landscapes. So that might

1164
00:44:27,280 --> 00:44:31,680
actually be very interesting for someone

1165
00:44:28,720 --> 00:44:34,160
to see that the same gene has different

1166
00:44:31,680 --> 00:44:35,920
um is being regulated by a different

1167
00:44:34,160 --> 00:44:37,280
enhancer or a different pattern in the

1168
00:44:35,920 --> 00:44:38,240
same enhancer in different cell types.

1169
00:44:37,280 --> 00:44:40,560
So I think that would be very

1170
00:44:38,240 --> 00:44:42,240
interesting. Um yeah starting from from

1171
00:44:40,560 --> 00:44:42,720
genes that we know the enhancer gene

1172
00:44:42,240 --> 00:44:44,560
link.

1173
00:44:42,720 --> 00:44:45,839
>> Yeah. Yeah. Exactly. And we hope to

1174
00:44:44,560 --> 00:44:48,640
that's what part of what we hope to do

1175
00:44:45,839 --> 00:44:50,560
especially leveraging all of the um 3D

1176
00:44:48,640 --> 00:44:52,960
chrom chromatin interaction data we have

1177
00:44:50,560 --> 00:44:55,440
from encode is ab absolutely do that.

1178
00:44:52,960 --> 00:44:58,160
Yeah. my to-do my to-do list just keeps

1179
00:44:55,440 --> 00:45:00,240
getting longer and longer as I'm sure

1180
00:44:58,160 --> 00:45:02,880
all of ours does.

1181
00:45:00,240 --> 00:45:05,520
>> One more question if we um yeah I think

1182
00:45:02,880 --> 00:45:07,680
you briefly touched upon that. I wanted

1183
00:45:05,520 --> 00:45:10,240
to ask if there is uh anything more you

1184
00:45:07,680 --> 00:45:12,240
can comment on uh like the uh

1185
00:45:10,240 --> 00:45:14,480
cooperative or synergistic effects of

1186
00:45:12,240 --> 00:45:17,520
the different TFS or if if you have any

1187
00:45:14,480 --> 00:45:20,240
way of pursuing this further. Um yeah

1188
00:45:17,520 --> 00:45:22,240
like they bind they both have or yeah

1189
00:45:20,240 --> 00:45:25,440
let's say pairs for now they both have

1190
00:45:22,240 --> 00:45:28,960
to bind to like uh how does that factor

1191
00:45:25,440 --> 00:45:31,359
in in how how uh much more complicated

1192
00:45:28,960 --> 00:45:32,960
would it be to systematically

1193
00:45:31,359 --> 00:45:36,000
um

1194
00:45:32,960 --> 00:45:38,400
>> so it's easy no I don't mean e but it's

1195
00:45:36,000 --> 00:45:42,160
easier sorry as I give everyone a

1196
00:45:38,400 --> 00:45:43,920
headache here I don't remember where

1197
00:45:42,160 --> 00:45:47,200
do I have it here yeah I do so it's

1198
00:45:43,920 --> 00:45:50,560
easier when you're looking at

1199
00:45:47,200 --> 00:45:54,400
essentially two TFs that bind we know

1200
00:45:50,560 --> 00:45:57,119
bind at a distance. So we know that um f

1201
00:45:54,400 --> 00:45:58,160
uh foss and te cooperate together and we

1202
00:45:57,119 --> 00:46:01,440
actually know specifically they

1203
00:45:58,160 --> 00:46:03,359
cooperate together um in a lot of uh

1204
00:46:01,440 --> 00:46:05,520
cancerous cell types and we actually

1205
00:46:03,359 --> 00:46:06,960
know that actually not only do they

1206
00:46:05,520 --> 00:46:09,440
prefer but we actually know that they

1207
00:46:06,960 --> 00:46:11,520
prefer to be separated specifically by

1208
00:46:09,440 --> 00:46:12,960
six base pairs and you can do the

1209
00:46:11,520 --> 00:46:14,400
analysis you can actually you can you

1210
00:46:12,960 --> 00:46:16,240
can take these two motifs and you can

1211
00:46:14,400 --> 00:46:17,520
slide them across one another and you

1212
00:46:16,240 --> 00:46:18,880
can see the changes in the predictions

1213
00:46:17,520 --> 00:46:20,640
of the binding or chromatin

1214
00:46:18,880 --> 00:46:23,520
accessibility. you see it actually, you

1215
00:46:20,640 --> 00:46:27,359
know, spikes at that six base pairs. So,

1216
00:46:23,520 --> 00:46:30,160
when it's two motifs that um, you know,

1217
00:46:27,359 --> 00:46:33,040
are separated by a specific fixed

1218
00:46:30,160 --> 00:46:35,359
distance, we can see that really well.

1219
00:46:33,040 --> 00:46:37,520
When it's more murky and it's

1220
00:46:35,359 --> 00:46:39,599
essentially the two sites overlap one

1221
00:46:37,520 --> 00:46:41,359
another and, you know, you kind of

1222
00:46:39,599 --> 00:46:43,599
squint and it looks like one motif and

1223
00:46:41,359 --> 00:46:45,040
you then squint and, you know, look the

1224
00:46:43,599 --> 00:46:46,640
other way and it looks like the other.

1225
00:46:45,040 --> 00:46:48,800
That's very difficult and that's

1226
00:46:46,640 --> 00:46:52,240
something that's very hard. Do you have

1227
00:46:48,800 --> 00:46:54,480
any sense as to how often these two

1228
00:46:52,240 --> 00:46:56,240
motifs appear together versus separately

1229
00:46:54,480 --> 00:46:58,319
in the whole genome or like is is this a

1230
00:46:56,240 --> 00:47:01,520
trend that you see uh in the entire

1231
00:46:58,319 --> 00:47:02,880
genome or uh I don't know very local?

1232
00:47:01,520 --> 00:47:05,280
>> Yeah. Yeah. So in this I can tell you

1233
00:47:02,880 --> 00:47:08,240
specifically in this specific instance

1234
00:47:05,280 --> 00:47:10,640
of the essentially um fos ted dimer

1235
00:47:08,240 --> 00:47:12,079
there are thousands of these um and

1236
00:47:10,640 --> 00:47:14,000
specifically they're enriched if you

1237
00:47:12,079 --> 00:47:17,280
look if you were to pull um if you were

1238
00:47:14,000 --> 00:47:19,520
to run motif discovery on um like MCF7

1239
00:47:17,280 --> 00:47:21,440
cells A549 cells a lot of these these

1240
00:47:19,520 --> 00:47:23,839
cancerous cell lines you'll see an

1241
00:47:21,440 --> 00:47:26,880
enrichment for these and it occurs in

1242
00:47:23,839 --> 00:47:29,280
the thousands. Now in terms of like when

1243
00:47:26,880 --> 00:47:31,599
one versus the like when when they occur

1244
00:47:29,280 --> 00:47:33,680
exactly at six base pairs verse not I I

1245
00:47:31,599 --> 00:47:36,480
don't have that exact number but that

1246
00:47:33,680 --> 00:47:38,240
specific this this specific instance is

1247
00:47:36,480 --> 00:47:39,520
I don't know I don't know if it's in the

1248
00:47:38,240 --> 00:47:40,960
literature that it prefers to be six

1249
00:47:39,520 --> 00:47:44,720
base pairs. I know that it's that they

1250
00:47:40,960 --> 00:47:46,640
prefer it's they're always together but

1251
00:47:44,720 --> 00:47:49,680
yeah that analysis is sort that that

1252
00:47:46,640 --> 00:47:53,240
like field is still in its infancy.

1253
00:47:49,680 --> 00:47:53,240
>> Thank you. Yes.

1254
00:47:58,880 --> 00:48:02,240
>> Well, thank you so much, Greg, for

1255
00:48:00,319 --> 00:48:05,200
speaking. That was a great talk. I think

1256
00:48:02,240 --> 00:48:07,520
we'll do like a five to 10 minute break

1257
00:48:05,200 --> 00:48:09,359
um before we begin the next talk. We're

1258
00:48:07,520 --> 00:48:11,520
now gonna moving on to the next talk of

1259
00:48:09,359 --> 00:48:13,119
programming for MIA today. So, we'll be

1260
00:48:11,520 --> 00:48:15,200
hearing from Jacob Shriber, who actually

1261
00:48:13,119 --> 00:48:17,280
just began his lab at UMass Chan in

1262
00:48:15,200 --> 00:48:21,200
Worcester. Um and we're very excited to

1263
00:48:17,280 --> 00:48:23,520
hear about his work. Um so,

1264
00:48:21,200 --> 00:48:25,359
Well, thank you. As Laura mentioned, I

1265
00:48:23,520 --> 00:48:26,960
just started my group at UMass Chen

1266
00:48:25,359 --> 00:48:28,720
Medical School. And so, it's kind of

1267
00:48:26,960 --> 00:48:30,800
fortunate timing that I get to come here

1268
00:48:28,720 --> 00:48:32,240
and introduce to you a little bit about

1269
00:48:30,800 --> 00:48:34,240
what I've been doing over the course of

1270
00:48:32,240 --> 00:48:36,800
the last uh over the course of the last

1271
00:48:34,240 --> 00:48:38,720
few years. But before we talk about

1272
00:48:36,800 --> 00:48:41,839
that, let's take a little bit of a step

1273
00:48:38,720 --> 00:48:43,839
back. Over 20 years ago now, the first

1274
00:48:41,839 --> 00:48:45,680
draft of a human reference genome came

1275
00:48:43,839 --> 00:48:48,160
out and a little snippet of it looks

1276
00:48:45,680 --> 00:48:51,760
something like this. In the words of a

1277
00:48:48,160 --> 00:48:55,040
familiar face, Dr. Eric Lander, genome

1278
00:48:51,760 --> 00:48:56,640
bought the book hard to read.

1279
00:48:55,040 --> 00:48:58,880
Even though it is challenging for us

1280
00:48:56,640 --> 00:49:01,920
mere mortals to understand these long

1281
00:48:58,880 --> 00:49:04,319
sequences of AEC's, G's and T's, having

1282
00:49:01,920 --> 00:49:06,480
this map provided the basis for the next

1283
00:49:04,319 --> 00:49:08,960
generation of biochemical assays to be

1284
00:49:06,480 --> 00:49:10,720
developed. Here we can see four such

1285
00:49:08,960 --> 00:49:13,280
experiments, each measuring the binding

1286
00:49:10,720 --> 00:49:15,280
of an individual transcription factor.

1287
00:49:13,280 --> 00:49:17,440
Just by looking at these readouts, we

1288
00:49:15,280 --> 00:49:19,599
can see how informative these sorts of

1289
00:49:17,440 --> 00:49:22,079
experiments are. At this enhancer,

1290
00:49:19,599 --> 00:49:24,160
there's the binding of Oct 4, SOCK 2,

1291
00:49:22,079 --> 00:49:28,319
and Nanog, but not necessarily the

1292
00:49:24,160 --> 00:49:30,240
binding of KF. However, relying solely

1293
00:49:28,319 --> 00:49:32,240
on the readouts from these experiments

1294
00:49:30,240 --> 00:49:34,079
is kind of reminiscent of the blind men

1295
00:49:32,240 --> 00:49:36,079
trying to describe an elephant based on

1296
00:49:34,079 --> 00:49:38,559
what they felt. Just because we

1297
00:49:36,079 --> 00:49:40,720
understand what is happening and where

1298
00:49:38,559 --> 00:49:44,480
in the genome doesn't mean that we

1299
00:49:40,720 --> 00:49:46,160
understand why it is happening there.

1300
00:49:44,480 --> 00:49:47,839
And so enter sequencebased machine

1301
00:49:46,160 --> 00:49:49,520
learning models. Greg gave a great

1302
00:49:47,839 --> 00:49:51,599
introduction to the sorts of models that

1303
00:49:49,520 --> 00:49:53,839
I'm talking about here. But at a high

1304
00:49:51,599 --> 00:49:55,920
level there are many different internal

1305
00:49:53,839 --> 00:49:57,599
computational units that these sorts of

1306
00:49:55,920 --> 00:49:59,920
models can have. Convolutions,

1307
00:49:57,599 --> 00:50:02,800
transformers, etc. And there are many

1308
00:49:59,920 --> 00:50:04,880
different precise formulations of the

1309
00:50:02,800 --> 00:50:07,119
tasks that the models try to solve.

1310
00:50:04,880 --> 00:50:08,800
However, broadly speaking,

1311
00:50:07,119 --> 00:50:10,559
sequence-based machine learning models

1312
00:50:08,800 --> 00:50:13,040
are those that take in nucleotide

1313
00:50:10,559 --> 00:50:14,880
sequence and make predictions for the

1314
00:50:13,040 --> 00:50:17,119
outputs from these sorts of biochemical

1315
00:50:14,880 --> 00:50:18,800
assays. But the predictions from these

1316
00:50:17,119 --> 00:50:21,119
models, in my view, are kind of some of

1317
00:50:18,800 --> 00:50:22,800
the least interesting aspects of them.

1318
00:50:21,119 --> 00:50:24,800
Most of the assays that we deal with

1319
00:50:22,800 --> 00:50:27,119
provide us with genomewide readouts.

1320
00:50:24,800 --> 00:50:29,359
There is no more like secret genome that

1321
00:50:27,119 --> 00:50:31,599
we need to go and make predictions for.

1322
00:50:29,359 --> 00:50:33,599
Rather, in my view, one of the strengths

1323
00:50:31,599 --> 00:50:36,000
of these machine learning models is

1324
00:50:33,599 --> 00:50:38,240
being able to run them backwards to be

1325
00:50:36,000 --> 00:50:40,160
able to get them to explain why they

1326
00:50:38,240 --> 00:50:42,240
made the predictions that they did. And

1327
00:50:40,160 --> 00:50:44,079
if we look at this example here, we can

1328
00:50:42,240 --> 00:50:47,359
see that the reason why this model

1329
00:50:44,079 --> 00:50:49,839
predicted the binding of Oct 4 here is

1330
00:50:47,359 --> 00:50:52,480
because there's an octetic

1331
00:50:49,839 --> 00:50:54,480
binding site there. So over the course

1332
00:50:52,480 --> 00:50:57,040
of the last year, I've been working on

1333
00:50:54,480 --> 00:50:59,440
basically trying to take this mechanism

1334
00:50:57,040 --> 00:51:01,839
and repurpose it for design, but

1335
00:50:59,440 --> 00:51:06,480
specifically the design of edits to

1336
00:51:01,839 --> 00:51:08,800
biological sequences with a uh or edits

1337
00:51:06,480 --> 00:51:10,800
to biological sequences. The way that

1338
00:51:08,800 --> 00:51:12,559
this works is basically as follows. Just

1339
00:51:10,800 --> 00:51:14,000
like before, you have some sequence that

1340
00:51:12,559 --> 00:51:16,079
you're working with. You have your

1341
00:51:14,000 --> 00:51:18,559
machine learning model, but now you have

1342
00:51:16,079 --> 00:51:20,480
a new component, the desired output from

1343
00:51:18,559 --> 00:51:22,319
the model. Maybe you want to design a

1344
00:51:20,480 --> 00:51:24,079
region where proteins really bind very

1345
00:51:22,319 --> 00:51:25,520
strongly. Maybe you want to design a

1346
00:51:24,079 --> 00:51:27,119
region where the protein doesn't bind at

1347
00:51:25,520 --> 00:51:29,040
all or one that's a site that's

1348
00:51:27,119 --> 00:51:30,960
accessible, a site that's transcribed,

1349
00:51:29,040 --> 00:51:33,040
etc. Anything that can be the target of

1350
00:51:30,960 --> 00:51:34,400
machine learning prediction. The way

1351
00:51:33,040 --> 00:51:36,319
that this works is that you take your

1352
00:51:34,400 --> 00:51:37,760
sequence,

1353
00:51:36,319 --> 00:51:38,720
you run it through the model, and you

1354
00:51:37,760 --> 00:51:41,040
get what the [clears throat] actual

1355
00:51:38,720 --> 00:51:43,440
output from the model is. Now you take

1356
00:51:41,040 --> 00:51:46,160
the actual output, you compare it with

1357
00:51:43,440 --> 00:51:48,800
the desired output, and now you run this

1358
00:51:46,160 --> 00:51:50,880
difference backwards through the model.

1359
00:51:48,800 --> 00:51:52,559
Rather than being able to highlight the

1360
00:51:50,880 --> 00:51:55,520
nucleotides that are driving model

1361
00:51:52,559 --> 00:51:57,599
predictions like we did before,

1362
00:51:55,520 --> 00:52:00,559
we are now highlighting the nucleotides

1363
00:51:57,599 --> 00:52:03,200
that need to change in order to achieve

1364
00:52:00,559 --> 00:52:05,760
your target objective. But we encounter

1365
00:52:03,200 --> 00:52:08,000
a problem here. This design of edits

1366
00:52:05,760 --> 00:52:10,240
problem is discreet. We have to choose

1367
00:52:08,000 --> 00:52:12,559
which positions we want to edit and what

1368
00:52:10,240 --> 00:52:14,240
characters we want at that position. But

1369
00:52:12,559 --> 00:52:16,160
the values that we saw before were quite

1370
00:52:14,240 --> 00:52:18,319
continuous where the height of the

1371
00:52:16,160 --> 00:52:20,880
character basically corresponded to how

1372
00:52:18,319 --> 00:52:22,720
important it was to the model. So the

1373
00:52:20,880 --> 00:52:25,920
main technical challenge that we had to

1374
00:52:22,720 --> 00:52:28,640
overcome with our method was recasting

1375
00:52:25,920 --> 00:52:30,640
this discrete optimization problem as a

1376
00:52:28,640 --> 00:52:33,040
continuous optimization problem that

1377
00:52:30,640 --> 00:52:34,960
could be solved quite simply.

1378
00:52:33,040 --> 00:52:37,040
So the way that we did this was we

1379
00:52:34,960 --> 00:52:39,520
introduced this method called lidi that

1380
00:52:37,040 --> 00:52:42,240
ends up under uh learning an underlying

1381
00:52:39,520 --> 00:52:43,680
continuous weight matrix. Let's uh take

1382
00:52:42,240 --> 00:52:45,680
a look at what's happening midway

1383
00:52:43,680 --> 00:52:47,200
through this design process. We have our

1384
00:52:45,680 --> 00:52:49,760
initial sequence that we're trying to

1385
00:52:47,200 --> 00:52:51,760
edit. At this point in the design

1386
00:52:49,760 --> 00:52:53,839
process doesn't really care what it is.

1387
00:52:51,760 --> 00:52:55,520
Maybe has a slight preference for C. And

1388
00:52:53,839 --> 00:52:57,280
what we end up doing is sampling the

1389
00:52:55,520 --> 00:52:59,200
original character, the G, at that

1390
00:52:57,280 --> 00:53:01,359
position.

1391
00:52:59,200 --> 00:53:03,440
Then at the next position, uh, it's

1392
00:53:01,359 --> 00:53:05,599
originally an A, but Lydia thinks that

1393
00:53:03,440 --> 00:53:08,319
quite strongly it should be a T here.

1394
00:53:05,599 --> 00:53:11,040
And so we end up drawing a T, an edit to

1395
00:53:08,319 --> 00:53:13,440
that sequence. We can go down the entire

1396
00:53:11,040 --> 00:53:15,359
sequence mostly keeping with the

1397
00:53:13,440 --> 00:53:17,359
original sequence, but at some points

1398
00:53:15,359 --> 00:53:20,160
making edits to the sequence and we end

1399
00:53:17,359 --> 00:53:22,160
up with a new edited discrete sequence.

1400
00:53:20,160 --> 00:53:24,319
We can run that through the model, get

1401
00:53:22,160 --> 00:53:26,079
our actual output, compare it to the

1402
00:53:24,319 --> 00:53:27,839
desired output, run the difference

1403
00:53:26,079 --> 00:53:29,359
backwards through the model as before.

1404
00:53:27,839 --> 00:53:30,880
But when we encounter the edited

1405
00:53:29,359 --> 00:53:33,280
sequence, we can just go straight

1406
00:53:30,880 --> 00:53:36,079
through it and end up optimizing this

1407
00:53:33,280 --> 00:53:37,839
underlying continuous weight matrix. In

1408
00:53:36,079 --> 00:53:39,599
this manner, we have recasted the

1409
00:53:37,839 --> 00:53:41,680
discrete optimization problem of

1410
00:53:39,599 --> 00:53:43,920
choosing which edits to make as a

1411
00:53:41,680 --> 00:53:45,599
continuous optimization problem that can

1412
00:53:43,920 --> 00:53:47,359
be solved using just off-the-shelf

1413
00:53:45,599 --> 00:53:50,480
optimizers and really just a few lines

1414
00:53:47,359 --> 00:53:51,920
of code.

1415
00:53:50,480 --> 00:53:54,160
What's a little bit more complicated

1416
00:53:51,920 --> 00:53:56,720
though is the exact loss that Lid is

1417
00:53:54,160 --> 00:53:58,559
optimizing. It's comprised of two terms.

1418
00:53:56,720 --> 00:54:00,559
The first is the output loss term that

1419
00:53:58,559 --> 00:54:02,160
most design methods have. Are you

1420
00:54:00,559 --> 00:54:04,160
achieving your desired objective? Does

1421
00:54:02,160 --> 00:54:06,720
this sequence make the predictions that

1422
00:54:04,160 --> 00:54:09,520
you would like it to? The second is this

1423
00:54:06,720 --> 00:54:11,520
novel input loss term. It's basically

1424
00:54:09,520 --> 00:54:13,760
just counting the number of edits that

1425
00:54:11,520 --> 00:54:16,079
were made in that sequence. And so in

1426
00:54:13,760 --> 00:54:18,480
this manner, we are explicitly trying to

1427
00:54:16,079 --> 00:54:20,000
minimize the number of edits necessary

1428
00:54:18,480 --> 00:54:21,599
in order to achieve our target

1429
00:54:20,000 --> 00:54:22,880
objective.

1430
00:54:21,599 --> 00:54:24,559
Then of course because there are two

1431
00:54:22,880 --> 00:54:26,800
terms you have to have a mixture weight

1432
00:54:24,559 --> 00:54:29,040
there that controls uh the balance

1433
00:54:26,800 --> 00:54:31,280
between the two and the rough intuition

1434
00:54:29,040 --> 00:54:33,440
here is basically uh you set it to

1435
00:54:31,280 --> 00:54:35,839
however many units of the output loss

1436
00:54:33,440 --> 00:54:38,079
you want each edit to be able to reduce

1437
00:54:35,839 --> 00:54:40,000
by. So it takes a little bit of tweaking

1438
00:54:38,079 --> 00:54:42,800
but it's actually usually quite robust

1439
00:54:40,000 --> 00:54:44,800
to this. Then the first question is does

1440
00:54:42,800 --> 00:54:47,040
this sort of formulation work? And so we

1441
00:54:44,800 --> 00:54:48,400
paired it with a a situation I initially

1442
00:54:47,040 --> 00:54:49,839
thought was going to be quite simple but

1443
00:54:48,400 --> 00:54:52,640
ended up being quite interesting

1444
00:54:49,839 --> 00:54:55,839
afterward. This was the design of gata 2

1445
00:54:52,640 --> 00:54:57,520
binding sites. Uh Greg introduced in the

1446
00:54:55,839 --> 00:54:59,280
earlier talk that gatter is quite a

1447
00:54:57,520 --> 00:55:01,920
simple motif. It binds basically to the

1448
00:54:59,280 --> 00:55:04,160
motif gata and that's where I expected

1449
00:55:01,920 --> 00:55:06,800
it to land. And so we took some sites

1450
00:55:04,160 --> 00:55:09,920
that initially were not predicted by a

1451
00:55:06,800 --> 00:55:12,319
bpet model to uh have data binding the

1452
00:55:09,920 --> 00:55:14,640
dark uh the black line there. And we

1453
00:55:12,319 --> 00:55:16,880
wanted them to be edited to become a

1454
00:55:14,640 --> 00:55:18,640
site that gata bound quite strongly. And

1455
00:55:16,880 --> 00:55:20,559
after running our process we end up with

1456
00:55:18,640 --> 00:55:22,400
sequences over there. they don't quite

1457
00:55:20,559 --> 00:55:24,240
end up on the cyan line because remember

1458
00:55:22,400 --> 00:55:26,160
we have a mixture of two terms and that

1459
00:55:24,240 --> 00:55:28,400
if we got closer to the cyan line that

1460
00:55:26,160 --> 00:55:29,839
would cost too many edits to do but

1461
00:55:28,400 --> 00:55:32,720
basically we're still able to design

1462
00:55:29,839 --> 00:55:34,880
sequences that had strong data binding.

1463
00:55:32,720 --> 00:55:37,040
Yeah.

1464
00:55:34,880 --> 00:55:40,280
Oh sorry I need the microphone for the

1465
00:55:37,040 --> 00:55:40,280
people online

1466
00:55:41,520 --> 00:55:46,400
about the loss term uh because then you

1467
00:55:44,800 --> 00:55:49,440
say the number of edits that's the

1468
00:55:46,400 --> 00:55:51,520
discrete thing. So it's like the your

1469
00:55:49,440 --> 00:55:54,000
sampling it's like the pro you're

1470
00:55:51,520 --> 00:55:55,440
penalizing the probability difference

1471
00:55:54,000 --> 00:55:56,160
like can you just talk a bit about what

1472
00:55:55,440 --> 00:55:57,920
that

1473
00:55:56,160 --> 00:55:59,680
>> it's quite literally the the discrete

1474
00:55:57,920 --> 00:56:02,079
number of edits and so it's it ends up

1475
00:55:59,680 --> 00:56:04,160
being an integer loss and you can work

1476
00:56:02,079 --> 00:56:06,880
this into a differentiable loss in the

1477
00:56:04,160 --> 00:56:09,599
same way that you'd work an L1 loss in

1478
00:56:06,880 --> 00:56:10,960
uh in the sense that it's uh

1479
00:56:09,599 --> 00:56:12,640
>> we can talk a little bit more about it

1480
00:56:10,960 --> 00:56:13,280
afterwards but it's not that

1481
00:56:12,640 --> 00:56:14,480
complicated.

1482
00:56:13,280 --> 00:56:17,440
>> Okay.

1483
00:56:14,480 --> 00:56:19,200
>> Yeah. So uh yeah, can you uh say a

1484
00:56:17,440 --> 00:56:22,160
little bit more about the leidi matrix

1485
00:56:19,200 --> 00:56:24,559
itself? I was going to ask it's uh if

1486
00:56:22,160 --> 00:56:25,920
every row does it sum to one like is it

1487
00:56:24,559 --> 00:56:27,040
a probability of finding each

1488
00:56:25,920 --> 00:56:28,400
nucleotide?

1489
00:56:27,040 --> 00:56:30,559
>> Yes, that's a great question.

1490
00:56:28,400 --> 00:56:32,559
>> Is it parameterized somehow? How you

1491
00:56:30,559 --> 00:56:34,079
know how yeah it's dimension?

1492
00:56:32,559 --> 00:56:35,520
>> It's a really good question. Sometimes I

1493
00:56:34,079 --> 00:56:37,040
skip over the technical aspects here

1494
00:56:35,520 --> 00:56:38,799
because depending on the audience they

1495
00:56:37,040 --> 00:56:42,799
don't care. Uh but it's nice to

1496
00:56:38,799 --> 00:56:44,319
encounter an audience that does care.

1497
00:56:42,799 --> 00:56:46,319
The gist is basically that this weight

1498
00:56:44,319 --> 00:56:47,920
matrix is initialized to all zeros,

1499
00:56:46,319 --> 00:56:50,000
though you could potentially initialize

1500
00:56:47,920 --> 00:56:51,280
it to very small random values depending

1501
00:56:50,000 --> 00:56:52,960
on if you want to run this multiple

1502
00:56:51,280 --> 00:56:55,040
times and get something different. It's

1503
00:56:52,960 --> 00:56:58,079
initialized to all zeros. And what you

1504
00:56:55,040 --> 00:57:02,640
end up doing is you interpret the values

1505
00:56:58,079 --> 00:57:04,799
of these weights as uh logic. And so

1506
00:57:02,640 --> 00:57:06,799
it's not that you sample from the lid

1507
00:57:04,799 --> 00:57:09,040
weight matrix, it's that you sample from

1508
00:57:06,799 --> 00:57:11,760
the addition of the initial sequence and

1509
00:57:09,040 --> 00:57:13,920
the lid weight matrix. And so what you

1510
00:57:11,760 --> 00:57:16,000
end up doing is slightly preferencing

1511
00:57:13,920 --> 00:57:18,319
that probability distribution towards

1512
00:57:16,000 --> 00:57:21,119
the initial sequence but still allowing

1513
00:57:18,319 --> 00:57:24,000
the weight matrix to say absolutely not

1514
00:57:21,119 --> 00:57:25,280
if it thinks so so strongly. Does that

1515
00:57:24,000 --> 00:57:26,640
make sense that that's the reason

1516
00:57:25,280 --> 00:57:28,319
there's the plus sign there that you are

1517
00:57:26,640 --> 00:57:30,960
sampling from the addition of the

1518
00:57:28,319 --> 00:57:33,200
initial sequence and this weight matrix.

1519
00:57:30,960 --> 00:57:35,200
But another little detail here is that

1520
00:57:33,200 --> 00:57:37,359
that's not just the one hot encoded

1521
00:57:35,200 --> 00:57:38,960
initial sequence. It's basically the log

1522
00:57:37,359 --> 00:57:42,480
of the initial sequence plus a small

1523
00:57:38,960 --> 00:57:44,960
epsilon term where when the value is

1524
00:57:42,480 --> 00:57:50,520
like a g there that's a zero and for the

1525
00:57:44,960 --> 00:57:50,520
non-G positions it's like minus 4 or so

1526
00:57:55,760 --> 00:57:59,440
in principle that's another

1527
00:57:57,040 --> 00:58:01,119
hyperparameter but usually I found that

1528
00:57:59,440 --> 00:58:02,559
it it doesn't really make that much of a

1529
00:58:01,119 --> 00:58:04,720
difference that it just controls the

1530
00:58:02,559 --> 00:58:07,040
dynamic range of the final values

1531
00:58:04,720 --> 00:58:10,040
>> okay

1532
00:58:07,040 --> 00:58:10,040
Thanks.

1533
00:58:13,760 --> 00:58:19,119
>> Thanks. Um, on the next slide, could you

1534
00:58:15,599 --> 00:58:21,040
just reexplain like what's the starting

1535
00:58:19,119 --> 00:58:23,040
sequence you use before you start making

1536
00:58:21,040 --> 00:58:25,760
these edits to get the data to? Like is

1537
00:58:23,040 --> 00:58:27,920
it a random sequence or do you

1538
00:58:25,760 --> 00:58:28,960
>> and does it depend where you start in

1539
00:58:27,920 --> 00:58:31,119
terms of what you get?

1540
00:58:28,960 --> 00:58:33,680
>> That's a great question. We're going to

1541
00:58:31,119 --> 00:58:36,079
um hopefully talk about that exact

1542
00:58:33,680 --> 00:58:38,079
second question about differences in how

1543
00:58:36,079 --> 00:58:40,240
you start uh a little bit later in the

1544
00:58:38,079 --> 00:58:42,240
talk. This is entirely a toy example

1545
00:58:40,240 --> 00:58:44,319
meant to just show that lidi works in

1546
00:58:42,240 --> 00:58:46,240
principle. So here we took regions that

1547
00:58:44,319 --> 00:58:47,599
were not gata peaks. I didn't do

1548
00:58:46,240 --> 00:58:49,440
anything particularly clever here. So I

1549
00:58:47,599 --> 00:58:51,680
just took real genomic regions that GAT

1550
00:58:49,440 --> 00:58:53,280
did not bind to and I set it to a very

1551
00:58:51,680 --> 00:58:56,799
high value and I wanted to see whether

1552
00:58:53,280 --> 00:59:01,240
or not LBD could create edits that uh

1553
00:58:56,799 --> 00:59:01,240
caused you to have gata binding.

1554
00:59:03,839 --> 00:59:07,680
>> This is such a biologist question. I'm

1555
00:59:05,920 --> 00:59:10,160
sorry I feel a bit like a fish out of

1556
00:59:07,680 --> 00:59:11,520
water in this seminar, but how big is

1557
00:59:10,160 --> 00:59:13,040
the region? You know, we think about

1558
00:59:11,520 --> 00:59:14,720
transcription factor binding a lot and

1559
00:59:13,040 --> 00:59:16,160
how big is the region compared to like

1560
00:59:14,720 --> 00:59:19,359
nucleosome binding or

1561
00:59:16,160 --> 00:59:21,520
>> Yeah. Um, I'm going to remake this point

1562
00:59:19,359 --> 00:59:23,119
a little bit later, which is that the DD

1563
00:59:21,520 --> 00:59:24,480
is a design algorithm, which means that

1564
00:59:23,119 --> 00:59:26,319
it can be paired with any machine

1565
00:59:24,480 --> 00:59:28,000
learning model. And so the receptive

1566
00:59:26,319 --> 00:59:29,920
field you are doing the edits on depends

1567
00:59:28,000 --> 00:59:32,559
on the model that you're using. Here,

1568
00:59:29,920 --> 00:59:36,400
this is a BPET model whose input window

1569
00:59:32,559 --> 00:59:39,040
is intuitively 2,114 base pairs. Uh, and

1570
00:59:36,400 --> 00:59:42,599
so that's the size of the edits. Uh, the

1571
00:59:39,040 --> 00:59:42,599
window being edited.

1572
00:59:46,720 --> 00:59:52,480
Cool. Okay.

1573
00:59:49,280 --> 00:59:54,880
So, uh if we look at the losses, oh,

1574
00:59:52,480 --> 00:59:56,559
another question.

1575
00:59:54,880 --> 00:59:58,160
>> So, how do you actually optimize the

1576
00:59:56,559 --> 01:00:00,640
loss here? Do you use gradient descent

1577
00:59:58,160 --> 01:00:02,079
or some sort of like sampling like

1578
01:00:00,640 --> 01:00:02,480
genetic algorithm or something like

1579
01:00:02,079 --> 01:00:03,760
that?

1580
01:00:02,480 --> 01:00:06,240
>> Yeah, that's a great question. I just

1581
01:00:03,760 --> 01:00:08,319
use the atom optimizer. I use Atom

1582
01:00:06,240 --> 01:00:10,319
because everybody uses Atom and

1583
01:00:08,319 --> 01:00:12,160
specifically I use the Atom uh

1584
01:00:10,319 --> 01:00:14,079
implementation which has a bug in it and

1585
01:00:12,160 --> 01:00:16,000
not the Atom W implementation which has

1586
01:00:14,079 --> 01:00:18,400
fixed the bug because everybody uses the

1587
01:00:16,000 --> 01:00:20,480
Atom implementation or maybe not bug but

1588
01:00:18,400 --> 01:00:23,040
it misses a technical detail that from

1589
01:00:20,480 --> 01:00:25,599
the but that's what I use. You can use

1590
01:00:23,040 --> 01:00:28,559
any optimizer that you would like. uh

1591
01:00:25,599 --> 01:00:32,480
really just if you're using PyTorch

1592
01:00:28,559 --> 01:00:34,400
which you should uh it's the optimizer

1593
01:00:32,480 --> 01:00:36,720
that you use is completely decoupled

1594
01:00:34,400 --> 01:00:40,160
from the design process.

1595
01:00:36,720 --> 01:00:43,040
>> Yep. Thanks.

1596
01:00:40,160 --> 01:00:44,559
>> Okay. Uh so if you look at the if you

1597
01:00:43,040 --> 01:00:45,599
look at the losses during the design

1598
01:00:44,559 --> 01:00:48,000
process, you see that there are

1599
01:00:45,599 --> 01:00:50,960
basically three regimes. In this first

1600
01:00:48,000 --> 01:00:52,480
one, the input loss rapidly increases.

1601
01:00:50,960 --> 01:00:54,400
Basically, edits are being proposed

1602
01:00:52,480 --> 01:00:56,559
rapidly in order to try to meet our

1603
01:00:54,400 --> 01:00:58,720
desired objective.

1604
01:00:56,559 --> 01:01:00,799
In the second regime, these obviously

1605
01:00:58,720 --> 01:01:02,960
unhelpful edits kind of like edits which

1606
01:01:00,799 --> 01:01:04,960
are in LD if you think about it from a

1607
01:01:02,960 --> 01:01:06,960
computational perspective with the ones

1608
01:01:04,960 --> 01:01:08,480
that are actually valuable end up being

1609
01:01:06,960 --> 01:01:10,319
discarded because we're trying to

1610
01:01:08,480 --> 01:01:12,079
explicitly minimize the number of edits

1611
01:01:10,319 --> 01:01:14,079
that are being proposed. And then

1612
01:01:12,079 --> 01:01:16,240
there's this third long regime which is

1613
01:01:14,079 --> 01:01:19,359
a long tail. Basically that we are

1614
01:01:16,240 --> 01:01:22,079
slowly merging sets of slightly helpful

1615
01:01:19,359 --> 01:01:23,920
edits into smaller sets of moderately

1616
01:01:22,079 --> 01:01:26,319
helpful edits. Basically trying to see

1617
01:01:23,920 --> 01:01:28,160
whether or not um we can condense the

1618
01:01:26,319 --> 01:01:30,240
size even more. And if you look very

1619
01:01:28,160 --> 01:01:31,760
carefully there you can see that roughly

1620
01:01:30,240 --> 01:01:35,280
you're reducing the size number of edits

1621
01:01:31,760 --> 01:01:39,280
by 33% over the course of you know that

1622
01:01:35,280 --> 01:01:41,839
150 uh steps there.

1623
01:01:39,280 --> 01:01:44,079
So what edits are actually being

1624
01:01:41,839 --> 01:01:46,000
proposed? If we look at the gata site,

1625
01:01:44,079 --> 01:01:48,000
you might be unsurprised to see that

1626
01:01:46,000 --> 01:01:51,440
adding in gata binding takes five

1627
01:01:48,000 --> 01:01:53,440
nucleotides when the gata motif is gata.

1628
01:01:51,440 --> 01:01:55,040
But if you look at the exact positioning

1629
01:01:53,440 --> 01:01:57,200
of where these edits are happening, you

1630
01:01:55,040 --> 01:02:00,319
see something really interesting. Only

1631
01:01:57,200 --> 01:02:04,000
one edit, that really big a is happening

1632
01:02:00,319 --> 01:02:05,760
in the core gata site.

1633
01:02:04,000 --> 01:02:07,599
Three edits are being made in the

1634
01:02:05,760 --> 01:02:09,440
surrounding flanking regions, which is

1635
01:02:07,599 --> 01:02:11,200
another point that Greg alluded to in

1636
01:02:09,440 --> 01:02:13,520
his talk, which is that the flanking

1637
01:02:11,200 --> 01:02:16,720
context of these motifs can matter a

1638
01:02:13,520 --> 01:02:18,480
great deal. One edit is kind of out far

1639
01:02:16,720 --> 01:02:20,079
there. You may initially want to

1640
01:02:18,480 --> 01:02:22,079
discount what's going on there, but what

1641
01:02:20,079 --> 01:02:24,720
it's doing is it's adding in a towel

1642
01:02:22,079 --> 01:02:26,319
binding site. Towel is a co-actor of

1643
01:02:24,720 --> 01:02:28,640
GATA, which greatly enhances its

1644
01:02:26,319 --> 01:02:30,799
binding. And so what's happening here is

1645
01:02:28,640 --> 01:02:33,119
that not only are we making GAT the GATA

1646
01:02:30,799 --> 01:02:35,599
site nice and easy for GATA to bind to,

1647
01:02:33,119 --> 01:02:38,400
we are adding in a co-actor site. And so

1648
01:02:35,599 --> 01:02:40,960
Leidi is specifically targeting a site

1649
01:02:38,400 --> 01:02:43,200
which was almost gata almost a strong

1650
01:02:40,960 --> 01:02:45,280
gata site and specifically making the

1651
01:02:43,200 --> 01:02:46,960
nucleotide changes there as opposed to

1652
01:02:45,280 --> 01:02:49,119
just plopping in a motif somewhere

1653
01:02:46,960 --> 01:02:51,599
random in sequence.

1654
01:02:49,119 --> 01:02:53,040
If we uh use a simple pruning algorithm,

1655
01:02:51,599 --> 01:02:55,839
we can actually get this down to two

1656
01:02:53,040 --> 01:02:58,240
edits and still preserve 98% of the

1657
01:02:55,839 --> 01:02:59,599
predicted binding. So maybe you're still

1658
01:02:58,240 --> 01:03:01,280
not impressed. Maybe you think GAT is

1659
01:02:59,599 --> 01:03:03,760
quite a small motif. It's still not

1660
01:03:01,280 --> 01:03:05,920
surprising that five edits adds in gata.

1661
01:03:03,760 --> 01:03:09,440
This was quite pervasive. If we look at

1662
01:03:05,920 --> 01:03:11,599
CTCF, you can see that with just four

1663
01:03:09,440 --> 01:03:14,240
edits or three edits after pruning, we

1664
01:03:11,599 --> 01:03:16,880
were able to go from no CTCF binding to

1665
01:03:14,240 --> 01:03:19,039
strong predicted CTCF binding by

1666
01:03:16,880 --> 01:03:21,760
targeting a site in the genome that was

1667
01:03:19,039 --> 01:03:24,240
almost CTCF.

1668
01:03:21,760 --> 01:03:26,160
I have a kind of evolutionary hypothesis

1669
01:03:24,240 --> 01:03:27,440
about this which I'm as a computational

1670
01:03:26,160 --> 01:03:30,480
person I'm not particularly well

1671
01:03:27,440 --> 01:03:32,640
equipped to handle even super formalize

1672
01:03:30,480 --> 01:03:35,200
which is basically goes like this that

1673
01:03:32,640 --> 01:03:37,680
our genomes are a graveyard of past

1674
01:03:35,200 --> 01:03:40,240
viral infections transposon activity all

1675
01:03:37,680 --> 01:03:42,240
sorts of other things that used to do

1676
01:03:40,240 --> 01:03:44,640
stuff which was bad and our genome

1677
01:03:42,240 --> 01:03:47,039
evolved out that function in part by

1678
01:03:44,640 --> 01:03:48,960
disrupting key binding sites and so we

1679
01:03:47,039 --> 01:03:51,839
can use lidi to bring back these binding

1680
01:03:48,960 --> 01:03:54,559
sites um in a ways that you might not

1681
01:03:51,839 --> 01:03:56,720
intuitively expect. So I think about the

1682
01:03:54,559 --> 01:03:59,680
genome as being much more kind of

1683
01:03:56,720 --> 01:04:00,960
continuous than you might normally

1684
01:03:59,680 --> 01:04:03,520
expect. That there are so many sites

1685
01:04:00,960 --> 01:04:06,960
that are almost motifs, much more than

1686
01:04:03,520 --> 01:04:09,359
you would normally expect.

1687
01:04:06,960 --> 01:04:10,720
Um just for time reasons to make sure I

1688
01:04:09,359 --> 01:04:12,640
get to everything, I'm going to skip

1689
01:04:10,720 --> 01:04:15,359
this. An important point here is that

1690
01:04:12,640 --> 01:04:16,960
because the DD is gradient based, uh it

1691
01:04:15,359 --> 01:04:19,039
involves running these values backwards,

1692
01:04:16,960 --> 01:04:21,280
it ends up being quite faster than other

1693
01:04:19,039 --> 01:04:23,680
approaches that are out there. If we try

1694
01:04:21,280 --> 01:04:26,079
a simple approach where we take around

1695
01:04:23,680 --> 01:04:28,240
17 motifs that are relevant for the

1696
01:04:26,079 --> 01:04:29,920
design task that we care about and we

1697
01:04:28,240 --> 01:04:32,160
try plopping them in at every position

1698
01:04:29,920 --> 01:04:33,920
in the sequence and do our design that

1699
01:04:32,160 --> 01:04:36,720
way in this method which is called motif

1700
01:04:33,920 --> 01:04:39,119
implantation. It takes a few hundred

1701
01:04:36,720 --> 01:04:41,359
seconds to do the design task using this

1702
01:04:39,119 --> 01:04:44,160
model called say.

1703
01:04:41,359 --> 01:04:45,599
If we try greedy substitution which is

1704
01:04:44,160 --> 01:04:48,160
uh sometimes it's called directed

1705
01:04:45,599 --> 01:04:49,760
evolution where you make one nucleotide

1706
01:04:48,160 --> 01:04:52,160
edit at a time until you achieve your

1707
01:04:49,760 --> 01:04:55,760
desired objective. It takes around 200

1708
01:04:52,160 --> 01:04:58,240
seconds to achieve your target goal. If

1709
01:04:55,760 --> 01:05:00,559
you use lidi it can be over an order of

1710
01:04:58,240 --> 01:05:02,079
magnitude faster. And the reason for

1711
01:05:00,559 --> 01:05:04,000
this is because you can imagine that

1712
01:05:02,079 --> 01:05:05,359
greedy substitution is basically just

1713
01:05:04,000 --> 01:05:06,640
going through and saying does this edit

1714
01:05:05,359 --> 01:05:09,280
help? Does this edit help? Does this

1715
01:05:06,640 --> 01:05:10,960
edit help? for every possible edit that

1716
01:05:09,280 --> 01:05:13,680
one could make, kind of like a petulant

1717
01:05:10,960 --> 01:05:15,280
child. In contrast, Leidi potentially

1718
01:05:13,680 --> 01:05:17,520
can make multiple edits at the same

1719
01:05:15,280 --> 01:05:20,640
time. By using the gradient, it can even

1720
01:05:17,520 --> 01:05:22,079
add in entire motifs. And so each step,

1721
01:05:20,640 --> 01:05:23,599
even though it takes slightly longer

1722
01:05:22,079 --> 01:05:25,920
because you have to go forward and

1723
01:05:23,599 --> 01:05:27,680
backwards as opposed forward, adds in

1724
01:05:25,920 --> 01:05:30,480
more information to design task. You

1725
01:05:27,680 --> 01:05:32,559
take bigger steps towards your goal.

1726
01:05:30,480 --> 01:05:35,440
Um I'm going to skip this also for

1727
01:05:32,559 --> 01:05:38,400
reasons. So

1728
01:05:35,440 --> 01:05:41,440
um like the point I was making before,

1729
01:05:38,400 --> 01:05:43,119
Lidi is a design method. Sometimes when

1730
01:05:41,440 --> 01:05:45,200
people publish papers talking about how

1731
01:05:43,119 --> 01:05:47,119
they have a new design method, what they

1732
01:05:45,200 --> 01:05:48,960
really mean is they have a really cool

1733
01:05:47,119 --> 01:05:50,640
new machine learning model that they

1734
01:05:48,960 --> 01:05:52,640
have then applied standard design

1735
01:05:50,640 --> 01:05:54,319
methods to and those machine learning

1736
01:05:52,640 --> 01:05:55,760
models are cool and the ultimate designs

1737
01:05:54,319 --> 01:05:57,760
they get out of them are cool, but they

1738
01:05:55,760 --> 01:06:00,160
haven't actually proposed a new design

1739
01:05:57,760 --> 01:06:01,920
method. Because it is a design method,

1740
01:06:00,160 --> 01:06:03,599
Leidi can be paired with any model

1741
01:06:01,920 --> 01:06:05,359
that's out there. Any model you've

1742
01:06:03,599 --> 01:06:07,359
already trained in your lab or have on a

1743
01:06:05,359 --> 01:06:09,440
collaborator, any model that's already

1744
01:06:07,359 --> 01:06:10,960
public and out there. And so in order to

1745
01:06:09,440 --> 01:06:13,359
demonstrate this, we tried to apply

1746
01:06:10,960 --> 01:06:16,079
Leidi broadly just using out of the box

1747
01:06:13,359 --> 01:06:18,000
settings. Here's a different version of

1748
01:06:16,079 --> 01:06:19,760
our gata friend from before where we

1749
01:06:18,000 --> 01:06:21,520
take a region that exhibited median

1750
01:06:19,760 --> 01:06:23,839
activity in the genome. not particularly

1751
01:06:21,520 --> 01:06:25,280
high, not you know, not an anomalously

1752
01:06:23,839 --> 01:06:27,119
low region, but a region where gata

1753
01:06:25,280 --> 01:06:29,039
didn't bind. And we wanted to turn into

1754
01:06:27,119 --> 01:06:30,799
a really strong region where gata does

1755
01:06:29,039 --> 01:06:33,039
bind. And we're able to achieve that,

1756
01:06:30,799 --> 01:06:35,039
like we showed before. But then we

1757
01:06:33,039 --> 01:06:37,200
considered four different transcription

1758
01:06:35,039 --> 01:06:39,119
factors across two different models. Out

1759
01:06:37,200 --> 01:06:40,720
of the box, we were able to design edits

1760
01:06:39,119 --> 01:06:42,400
that achieved our target goal quite

1761
01:06:40,720 --> 01:06:43,839
simply.

1762
01:06:42,400 --> 01:06:45,920
Then we looked at four different models

1763
01:06:43,839 --> 01:06:47,440
of chromatin accessibility and again saw

1764
01:06:45,920 --> 01:06:49,839
that we were able to achieve our desired

1765
01:06:47,440 --> 01:06:50,720
goal uh without changing the settings at

1766
01:06:49,839 --> 01:06:52,079
all.

1767
01:06:50,720 --> 01:06:54,240
Then we looked at transcription

1768
01:06:52,079 --> 01:06:57,280
transcription initiation.

1769
01:06:54,240 --> 01:06:59,599
We looked at MP activity.

1770
01:06:57,280 --> 01:07:01,520
We looked at starsek data. And in each

1771
01:06:59,599 --> 01:07:03,680
one of these settings, Leidi was simply

1772
01:07:01,520 --> 01:07:05,520
able to design edits using the model in

1773
01:07:03,680 --> 01:07:08,319
order to achieve our target goal. So

1774
01:07:05,520 --> 01:07:11,319
Leidi is a generalpurpose designer of

1775
01:07:08,319 --> 01:07:11,319
edits.

1776
01:07:12,000 --> 01:07:17,440
All right. Sometimes this term

1777
01:07:15,200 --> 01:07:19,119
overfitting comes in when people talk

1778
01:07:17,440 --> 01:07:20,880
about training machine learning models.

1779
01:07:19,119 --> 01:07:23,039
They're worried that the model has

1780
01:07:20,880 --> 01:07:26,480
overfitit to the training set and is not

1781
01:07:23,039 --> 01:07:28,079
actually generalizable in practice.

1782
01:07:26,480 --> 01:07:30,559
Here it's important to keep in mind that

1783
01:07:28,079 --> 01:07:32,640
the same concepts can apply to design

1784
01:07:30,559 --> 01:07:35,680
that potentially the designs that you

1785
01:07:32,640 --> 01:07:38,079
create can overfit to the parameters of

1786
01:07:35,680 --> 01:07:39,680
the model. Maybe the model has learned

1787
01:07:38,079 --> 01:07:41,440
something wacky which doesn't actually

1788
01:07:39,680 --> 01:07:43,520
hold. Maybe you're able to push the

1789
01:07:41,440 --> 01:07:45,440
model out of distribution in some wacky

1790
01:07:43,520 --> 01:07:46,960
way. If you think about computer vision,

1791
01:07:45,440 --> 01:07:48,559
there are a series of papers that came

1792
01:07:46,960 --> 01:07:51,440
out that showed that if you had an

1793
01:07:48,559 --> 01:07:53,920
image, you could change one pixel value

1794
01:07:51,440 --> 01:07:56,640
in an imperceptible way to get it to

1795
01:07:53,920 --> 01:07:59,520
predict any class that you wanted. It's

1796
01:07:56,640 --> 01:08:00,799
not quite as easy to do with DNA models

1797
01:07:59,520 --> 01:08:03,440
because you just have discrete

1798
01:08:00,799 --> 01:08:05,680
characters, but that sort of idea is

1799
01:08:03,440 --> 01:08:08,000
potentially valid. And so a question

1800
01:08:05,680 --> 01:08:10,720
that we had is are the edits that we're

1801
01:08:08,000 --> 01:08:12,799
proposing actually generalizable or do

1802
01:08:10,720 --> 01:08:14,799
they you know are they just pushing the

1803
01:08:12,799 --> 01:08:16,560
model off distribution and so what we

1804
01:08:14,799 --> 01:08:19,359
did is we took edits that were designed

1805
01:08:16,560 --> 01:08:20,640
using BPN models each group here is for

1806
01:08:19,359 --> 01:08:22,799
a different transcription factor and

1807
01:08:20,640 --> 01:08:25,679
each color is a different external model

1808
01:08:22,799 --> 01:08:28,480
and we wanted to verify if we design

1809
01:08:25,679 --> 01:08:31,839
edits using BPAT

1810
01:08:28,480 --> 01:08:33,440
do external models also predict higher

1811
01:08:31,839 --> 01:08:35,120
you know binding we were considering

1812
01:08:33,440 --> 01:08:37,600
mostly just higher binding here. Do

1813
01:08:35,120 --> 01:08:39,600
these external models also cons give us

1814
01:08:37,600 --> 01:08:41,839
higher binding? And even more

1815
01:08:39,600 --> 01:08:44,400
indirectly, if we consider models of

1816
01:08:41,839 --> 01:08:47,359
chromatin accessibility, if we design

1817
01:08:44,400 --> 01:08:49,679
edits that say add in CTCF binding, do

1818
01:08:47,359 --> 01:08:52,239
models of chromatin accessibility

1819
01:08:49,679 --> 01:08:55,040
predict higher accessibility? And so in

1820
01:08:52,239 --> 01:08:56,880
each one of these cases, we saw that we

1821
01:08:55,040 --> 01:08:59,279
uh were able to that the models that

1822
01:08:56,880 --> 01:09:01,279
that the edits that we designed were

1823
01:08:59,279 --> 01:09:05,000
generalizable across models and we're

1824
01:09:01,279 --> 01:09:05,000
able to valid Yeah.

1825
01:09:08,159 --> 01:09:13,199
If if all the models predict that pixel

1826
01:09:10,719 --> 01:09:14,799
doesn't make the pixel biologically

1827
01:09:13,199 --> 01:09:16,159
relevant.

1828
01:09:14,799 --> 01:09:17,839
>> Like just because they agree that that

1829
01:09:16,159 --> 01:09:19,520
pixel is important doesn't make the

1830
01:09:17,839 --> 01:09:21,199
pixel relevant. Like you said, you can

1831
01:09:19,520 --> 01:09:23,759
still predict every class. They just

1832
01:09:21,199 --> 01:09:25,600
agree on.

1833
01:09:23,759 --> 01:09:27,440
>> So yeah. So here the the the idea is

1834
01:09:25,600 --> 01:09:29,600
that we're trying to not overfit to the

1835
01:09:27,440 --> 01:09:32,560
eccentricities of any specific model.

1836
01:09:29,600 --> 01:09:34,799
It's unlikely that very different models

1837
01:09:32,560 --> 01:09:36,719
trained on very in very different ways

1838
01:09:34,799 --> 01:09:38,640
on different processed forms of the

1839
01:09:36,719 --> 01:09:41,920
readouts even different forms of

1840
01:09:38,640 --> 01:09:44,920
biochemical assay would have the same

1841
01:09:41,920 --> 01:09:44,920
eccentricities

1842
01:09:46,719 --> 01:09:52,159
or like I think in the case where you

1843
01:09:49,679 --> 01:09:54,000
take a pixel and you are able to modify

1844
01:09:52,159 --> 01:09:55,840
it slightly to get any prediction that

1845
01:09:54,000 --> 01:09:57,600
you want that if you then fed that into

1846
01:09:55,840 --> 01:09:59,360
a second model you would not get the

1847
01:09:57,600 --> 01:10:00,880
same response that it's just an

1848
01:09:59,360 --> 01:10:01,760
eccentricity of the specific model

1849
01:10:00,880 --> 01:10:05,040
you're working with.

1850
01:10:01,760 --> 01:10:07,760
>> I see. And when you when you write led

1851
01:10:05,040 --> 01:10:11,199
plus pruning, is that the pruning is

1852
01:10:07,760 --> 01:10:13,679
post or is something that just happens?

1853
01:10:11,199 --> 01:10:15,440
>> Oh yeah, that's uh that's an optional

1854
01:10:13,679 --> 01:10:18,960
post-processing step afterward

1855
01:10:15,440 --> 01:10:19,760
>> like that like the you do

1856
01:10:18,960 --> 01:10:21,679
or

1857
01:10:19,760 --> 01:10:23,360
>> there's built-in functionality builtin

1858
01:10:21,679 --> 01:10:24,719
function. What we have is I mean you can

1859
01:10:23,360 --> 01:10:26,239
do whatever sort of pruding you want but

1860
01:10:24,719 --> 01:10:27,520
we do a greedy approach where you go

1861
01:10:26,239 --> 01:10:29,600
through every edit and you see what

1862
01:10:27,520 --> 01:10:32,159
happens when you revert it and if

1863
01:10:29,600 --> 01:10:33,760
reverting it doesn't bring you uh you

1864
01:10:32,159 --> 01:10:35,520
know there's a tolerance for how far

1865
01:10:33,760 --> 01:10:38,320
away from your desired objective you can

1866
01:10:35,520 --> 01:10:40,960
go during the pruning thing and if the

1867
01:10:38,320 --> 01:10:41,840
edits are within that tolerance then you

1868
01:10:40,960 --> 01:10:43,679
undo them

1869
01:10:41,840 --> 01:10:46,960
>> because I was just think seeing that

1870
01:10:43,679 --> 01:10:49,440
that you go to just a couple of bases I

1871
01:10:46,960 --> 01:10:51,199
would been curious to see from BPET for

1872
01:10:49,440 --> 01:10:54,320
example attribution scores like if

1873
01:10:51,199 --> 01:10:56,400
you're peing the top two most important

1874
01:10:54,320 --> 01:10:58,480
from from BPnet.

1875
01:10:56,400 --> 01:11:00,239
Um

1876
01:10:58,480 --> 01:11:03,360
like in a certain kind of way and trying

1877
01:11:00,239 --> 01:11:05,920
to understand the the like how you use

1878
01:11:03,360 --> 01:11:07,920
it and uh and

1879
01:11:05,920 --> 01:11:09,600
>> so are you saying for the pruning step?

1880
01:11:07,920 --> 01:11:12,080
Uh yeah, in general because right you

1881
01:11:09,600 --> 01:11:16,000
have you cannot make that many edits

1882
01:11:12,080 --> 01:11:18,320
like like you showed at the first output

1883
01:11:16,000 --> 01:11:21,760
>> and so and but in the end after you

1884
01:11:18,320 --> 01:11:24,239
prune you get just two bases

1885
01:11:21,760 --> 01:11:26,400
>> and maybe it was just a case but like if

1886
01:11:24,239 --> 01:11:28,320
those two bases are the one that Pineta

1887
01:11:26,400 --> 01:11:29,920
gives a very low attribution score

1888
01:11:28,320 --> 01:11:31,920
meaning that if they're not there

1889
01:11:29,920 --> 01:11:34,800
there's not accessibility. If you pick

1890
01:11:31,920 --> 01:11:36,320
just the top two,

1891
01:11:34,800 --> 01:11:38,560
the model will tell you that now there

1892
01:11:36,320 --> 01:11:42,400
is accessibility but maybe biologically

1893
01:11:38,560 --> 01:11:43,679
will not work. No, like I think this is

1894
01:11:42,400 --> 01:11:45,600
an interesting conversation that we

1895
01:11:43,679 --> 01:11:47,199
should talk about later. I think that

1896
01:11:45,600 --> 01:11:49,360
ultimately you're right that there are

1897
01:11:47,199 --> 01:11:51,760
many sorts of post-processing strategies

1898
01:11:49,360 --> 01:11:53,360
that one could use. I generally try to

1899
01:11:51,760 --> 01:11:54,880
avoid getting into this because there

1900
01:11:53,360 --> 01:11:56,640
are so many heristics that one could

1901
01:11:54,880 --> 01:11:59,280
consider. I was more just trying to make

1902
01:11:56,640 --> 01:12:00,719
the point that we were so close to a

1903
01:11:59,280 --> 01:12:01,920
data site and you might not have known

1904
01:12:00,719 --> 01:12:04,560
it if you had only looked at

1905
01:12:01,920 --> 01:12:08,520
attributions or if you you know had only

1906
01:12:04,560 --> 01:12:08,520
looked at predictions from the model.

1907
01:12:08,560 --> 01:12:11,920
>> Are you going to talk more about

1908
01:12:10,480 --> 01:12:12,320
experimental validation or is

1909
01:12:11,920 --> 01:12:15,320
>> Yes.

1910
01:12:12,320 --> 01:12:15,320
>> Okay.

1911
01:12:18,480 --> 01:12:24,480
>> Um yeah quick question about the

1912
01:12:20,640 --> 01:12:27,679
baseline. So um yeah, what do you mean

1913
01:12:24,480 --> 01:12:29,120
by same edit composite because it I'm

1914
01:12:27,679 --> 01:12:30,800
trying to understand whether this is a

1915
01:12:29,120 --> 01:12:33,199
result about the consistency of these

1916
01:12:30,800 --> 01:12:34,960
models or about your approach to find

1917
01:12:33,199 --> 01:12:37,600
something that is

1918
01:12:34,960 --> 01:12:40,080
>> consistent. So the same edit baseline is

1919
01:12:37,600 --> 01:12:42,800
that if we take the same number of edits

1920
01:12:40,080 --> 01:12:44,800
of each type like a to transitions etc

1921
01:12:42,800 --> 01:12:47,600
and we apply them randomly a hundred

1922
01:12:44,800 --> 01:12:49,199
times in that sequence what do the model

1923
01:12:47,600 --> 01:12:50,960
predictions look like? Okay. But there's

1924
01:12:49,199 --> 01:12:52,560
different ways to think about what same

1925
01:12:50,960 --> 01:12:54,159
is is going to be in that sense. So for

1926
01:12:52,560 --> 01:12:55,840
example, as you're saying, it's like the

1927
01:12:54,159 --> 01:13:00,320
frequency of one to other, but then

1928
01:12:55,840 --> 01:13:04,000
you've also got for example like do they

1929
01:13:00,320 --> 01:13:05,920
align match up with the attribution

1930
01:13:04,000 --> 01:13:07,760
uh the the bases that are contributing

1931
01:13:05,920 --> 01:13:09,679
to the like do you do you include that

1932
01:13:07,760 --> 01:13:11,360
information? So it's like

1933
01:13:09,679 --> 01:13:13,520
>> remember that these are sequences that

1934
01:13:11,360 --> 01:13:14,880
do not exhibit the activity normally. If

1935
01:13:13,520 --> 01:13:16,400
you look at the attributions, there's

1936
01:13:14,880 --> 01:13:18,159
going to be nothing because the models

1937
01:13:16,400 --> 01:13:20,000
are not predicting that there's binding.

1938
01:13:18,159 --> 01:13:21,440
So you can't really use the attributions

1939
01:13:20,000 --> 01:13:23,840
in order to guide where you want to make

1940
01:13:21,440 --> 01:13:25,440
edits.

1941
01:13:23,840 --> 01:13:28,000
>> Right. Okay. I see what you're saying.

1942
01:13:25,440 --> 01:13:30,080
But I mean you could take the gradient

1943
01:13:28,000 --> 01:13:31,920
or something to in in this particular

1944
01:13:30,080 --> 01:13:33,120
direction like try and control for I

1945
01:13:31,920 --> 01:13:34,239
mean if you start talking about you

1946
01:13:33,120 --> 01:13:35,600
taking the gradient in a certain

1947
01:13:34,239 --> 01:13:37,040
direction then you come up with lidi

1948
01:13:35,600 --> 01:13:38,239
right because that's what lidi does. It

1949
01:13:37,040 --> 01:13:39,920
uses the gradient.

1950
01:13:38,239 --> 01:13:41,199
>> Okay. But then just in general, do you

1951
01:13:39,920 --> 01:13:43,600
think this is saying something about

1952
01:13:41,199 --> 01:13:46,560
lidi or about the consistency of what's

1953
01:13:43,600 --> 01:13:48,159
driving these models?

1954
01:13:46,560 --> 01:13:50,640
>> I mean, I think ultimately it's both,

1955
01:13:48,159 --> 01:13:52,400
right? That if one model fails to pick

1956
01:13:50,640 --> 01:13:54,159
up on a motif that actually is

1957
01:13:52,400 --> 01:13:55,679
biologically plausible and a second

1958
01:13:54,159 --> 01:13:58,320
model is picked up on, like you're not

1959
01:13:55,679 --> 01:14:00,159
going to see as strong a like there's a

1960
01:13:58,320 --> 01:14:02,640
reason here that CTCF gives us the

1961
01:14:00,159 --> 01:14:04,400
cleanest signal, right? in terms of if

1962
01:14:02,640 --> 01:14:06,159
you design a CTCF binding site that

1963
01:14:04,400 --> 01:14:08,880
informer really agrees that that's a

1964
01:14:06,159 --> 01:14:10,640
CTCF site because CTCF is so simple.

1965
01:14:08,880 --> 01:14:12,880
These other ones have more complicated

1966
01:14:10,640 --> 01:14:15,520
binding modes and so there may be more

1967
01:14:12,880 --> 01:14:17,440
disagreement about what exactly is the

1968
01:14:15,520 --> 01:14:20,159
strongest version of each motif amongst

1969
01:14:17,440 --> 01:14:22,960
them. Uh so I mean I do think that it's

1970
01:14:20,159 --> 01:14:25,760
both. I think that

1971
01:14:22,960 --> 01:14:28,640
uh it can be a way of seeing how much

1972
01:14:25,760 --> 01:14:30,400
models agree with each other, but also

1973
01:14:28,640 --> 01:14:32,000
that it is a way of making sure that you

1974
01:14:30,400 --> 01:14:34,880
haven't done something absolutely wacky

1975
01:14:32,000 --> 01:14:35,840
with one model that nothing else agrees

1976
01:14:34,880 --> 01:14:37,520
is reasonable.

1977
01:14:35,840 --> 01:14:39,600
>> So a general principle would be like

1978
01:14:37,520 --> 01:14:42,159
you'd expect some signal in all of the

1979
01:14:39,600 --> 01:14:43,199
models, but then just the overall like

1980
01:14:42,159 --> 01:14:47,080
maximum.

1981
01:14:43,199 --> 01:14:47,080
>> Yeah, thanks.

1982
01:14:54,800 --> 01:14:58,320
I'm just curious if there's a biological

1983
01:14:56,560 --> 01:15:00,800
reason for why or the model design

1984
01:14:58,320 --> 01:15:03,840
reason for why that outlier exists with

1985
01:15:00,800 --> 01:15:08,640
informer and CTCF. Um is it something

1986
01:15:03,840 --> 01:15:10,480
specific to CTSCF binding sites?

1987
01:15:08,640 --> 01:15:12,320
I think that

1988
01:15:10,480 --> 01:15:16,400
>> so I think part of part of it is that

1989
01:15:12,320 --> 01:15:18,159
CTCF is a very conserved somewhat simp I

1990
01:15:16,400 --> 01:15:19,679
mean it's not super simple but it's like

1991
01:15:18,159 --> 01:15:21,920
it is more simple than some of the other

1992
01:15:19,679 --> 01:15:24,239
ones in terms of the what the motif is

1993
01:15:21,920 --> 01:15:27,600
and how strong the CTCF binds to all

1994
01:15:24,239 --> 01:15:29,760
instances of CTCF as for why informer

1995
01:15:27,600 --> 01:15:31,120
and not the other ones have such a

1996
01:15:29,760 --> 01:15:33,600
strong response I would say that that

1997
01:15:31,120 --> 01:15:37,520
just is because bpnet and informer here

1998
01:15:33,600 --> 01:15:40,920
seem to agree more on the exact um the

1999
01:15:37,520 --> 01:15:40,920
exact composition,

2000
01:15:42,320 --> 01:15:45,600
right? I think I have to keep going if I

2001
01:15:44,080 --> 01:15:49,760
want to get to some of what I think is

2002
01:15:45,600 --> 01:15:53,520
the most interesting aspect of this.

2003
01:15:49,760 --> 01:15:55,520
So, because of the DVD speed, we can use

2004
01:15:53,520 --> 01:15:57,920
multiple models simultaneously in the

2005
01:15:55,520 --> 01:15:59,760
design process. Sometimes the way that

2006
01:15:57,920 --> 01:16:01,600
research goes is that you design a

2007
01:15:59,760 --> 01:16:03,920
model, you train a model specifically

2008
01:16:01,600 --> 01:16:05,920
for the targets that you want to make

2009
01:16:03,920 --> 01:16:08,400
designs for, even if that's multiple

2010
01:16:05,920 --> 01:16:10,560
things. Because the DD is very fast, you

2011
01:16:08,400 --> 01:16:12,640
can use multiple models. Maybe you want

2012
01:16:10,560 --> 01:16:14,640
to use an informer model, but one of the

2013
01:16:12,640 --> 01:16:16,320
heads happens to be bad. So you train

2014
01:16:14,640 --> 01:16:18,000
your own specialized model for that one

2015
01:16:16,320 --> 01:16:19,280
head. Maybe you have an internal

2016
01:16:18,000 --> 01:16:20,480
experimental track that you want to

2017
01:16:19,280 --> 01:16:21,679
train a model for, but you want to

2018
01:16:20,480 --> 01:16:25,440
combine it with models that your

2019
01:16:21,679 --> 01:16:27,040
collaborators used, etc. And so, Leidi

2020
01:16:25,440 --> 01:16:29,280
is able to use these multiple models

2021
01:16:27,040 --> 01:16:31,440
simultaneously to really precisely

2022
01:16:29,280 --> 01:16:33,920
control multiple characteristics of the

2023
01:16:31,440 --> 01:16:36,400
design. So, the question becomes which

2024
01:16:33,920 --> 01:16:38,560
multiple models should we use? Well, I

2025
01:16:36,400 --> 01:16:39,840
spent the last year in Vienna at the

2026
01:16:38,560 --> 01:16:42,560
research institute of molecular

2027
01:16:39,840 --> 01:16:44,800
pathology sitting next to Alex Stark.

2028
01:16:42,560 --> 01:16:47,600
And so, given that I was contractually

2029
01:16:44,800 --> 01:16:49,440
obligated to use his starsek models and

2030
01:16:47,600 --> 01:16:52,000
so we use those in order to design cell

2031
01:16:49,440 --> 01:16:54,080
type specific enhancers in Drosophila.

2032
01:16:52,000 --> 01:16:55,760
So here we use two deep store models.

2033
01:16:54,080 --> 01:16:57,360
One of which was from a previous

2034
01:16:55,760 --> 01:16:59,520
published paper that we didn't touch at

2035
01:16:57,360 --> 01:17:01,440
all. The OSC model had to be retrained

2036
01:16:59,520 --> 01:17:04,239
for uh for this work but was not

2037
01:17:01,440 --> 01:17:06,000
originally proposed in this work. And we

2038
01:17:04,239 --> 01:17:08,880
but each one of them only models a

2039
01:17:06,000 --> 01:17:11,199
single cell line. This isn't a multitask

2040
01:17:08,880 --> 01:17:13,280
um setting. This is two distinct models

2041
01:17:11,199 --> 01:17:16,719
and we wanted to try to design enhancers

2042
01:17:13,280 --> 01:17:19,120
that were active in only one cell line.

2043
01:17:16,719 --> 01:17:21,360
But like I said before, one of the

2044
01:17:19,120 --> 01:17:23,199
aspects of Leidi is that it is designing

2045
01:17:21,360 --> 01:17:24,880
edits to an initial template sequence.

2046
01:17:23,199 --> 01:17:27,440
And so our natural question is what

2047
01:17:24,880 --> 01:17:29,520
should those template sequences be? The

2048
01:17:27,440 --> 01:17:31,280
simplest such set of template sequences

2049
01:17:29,520 --> 01:17:32,640
is regions that are never enhancers.

2050
01:17:31,280 --> 01:17:34,080
Regions that are non-enhancers in other

2051
01:17:32,640 --> 01:17:36,080
cell line and we want to turn them on in

2052
01:17:34,080 --> 01:17:38,640
one cell line, turn them on in the other

2053
01:17:36,080 --> 01:17:40,159
cell line.

2054
01:17:38,640 --> 01:17:42,640
And when we do that, we can see that

2055
01:17:40,159 --> 01:17:44,640
computationally we are able to designers

2056
01:17:42,640 --> 01:17:46,320
that are quite specific. On the top we

2057
01:17:44,640 --> 01:17:48,320
have the designs which are S2 specific

2058
01:17:46,320 --> 01:17:50,719
and the burgundy shows the predictions

2059
01:17:48,320 --> 01:17:52,640
for those sequences. The green shows the

2060
01:17:50,719 --> 01:17:54,080
predictions for OSC and we can see that

2061
01:17:52,640 --> 01:17:55,679
those are quite low even a little

2062
01:17:54,080 --> 01:17:58,320
negative and we see a little bit of the

2063
01:17:55,679 --> 01:18:00,560
reverse. These are this is in silica. So

2064
01:17:58,320 --> 01:18:02,320
these are predictions from the model but

2065
01:18:00,560 --> 01:18:04,640
we can consider other template pools as

2066
01:18:02,320 --> 01:18:07,199
well. We can take regions which were

2067
01:18:04,640 --> 01:18:09,440
initially enhancers in S2, regions which

2068
01:18:07,199 --> 01:18:11,600
are initially enhancers in OSC, ones

2069
01:18:09,440 --> 01:18:13,840
that are enhancers in both and then just

2070
01:18:11,600 --> 01:18:15,679
uniformly randomly generated DNA. So not

2071
01:18:13,840 --> 01:18:18,000
endogenous at all, just uniformly

2072
01:18:15,679 --> 01:18:19,120
randomly sampled. And in each one of

2073
01:18:18,000 --> 01:18:21,280
those cases, it seems like

2074
01:18:19,120 --> 01:18:24,000
computationally we were able to design

2075
01:18:21,280 --> 01:18:26,000
cell type specific enhancers. But the

2076
01:18:24,000 --> 01:18:28,080
question arose earlier, what about

2077
01:18:26,000 --> 01:18:30,480
experimental validation for these? So we

2078
01:18:28,080 --> 01:18:32,159
then went and uh Franciscoca in the

2079
01:18:30,480 --> 01:18:34,080
Alex's lab went and ran an actual

2080
01:18:32,159 --> 01:18:37,120
starsek experiment. And so this is

2081
01:18:34,080 --> 01:18:38,960
actual real starseek data. The dots

2082
01:18:37,120 --> 01:18:40,960
correspond to the target cell line that

2083
01:18:38,960 --> 01:18:42,320
we are trying to design activity in. And

2084
01:18:40,960 --> 01:18:44,719
what you can see is that the margin

2085
01:18:42,320 --> 01:18:46,880
between the two is quite large. Uh for

2086
01:18:44,719 --> 01:18:48,880
the OSE activity, the ones in green, we

2087
01:18:46,880 --> 01:18:50,800
can see that the activity in OS is quite

2088
01:18:48,880 --> 01:18:53,280
large and the activity in S2 is quite

2089
01:18:50,800 --> 01:18:54,880
restrained. The ones in Burgundy are a

2090
01:18:53,280 --> 01:18:57,040
little bit more of a complex story.

2091
01:18:54,880 --> 01:18:59,440
Ultimately, we use this loss which was

2092
01:18:57,040 --> 01:19:01,440
trying to maximize the gap between the

2093
01:18:59,440 --> 01:19:04,159
two as opposed to necessarily keeping

2094
01:19:01,440 --> 01:19:05,520
the offtarget cell line low. And so

2095
01:19:04,159 --> 01:19:07,440
that's why we get the results that we

2096
01:19:05,520 --> 01:19:09,760
see here where some of them seem that

2097
01:19:07,440 --> 01:19:12,560
quite a few seem to have activity in OSC

2098
01:19:09,760 --> 01:19:13,920
as well but stronger activity in S2.

2099
01:19:12,560 --> 01:19:15,120
It's just like across all these

2100
01:19:13,920 --> 01:19:18,640
different settings we were able to

2101
01:19:15,120 --> 01:19:20,400
design cells uh enhancers.

2102
01:19:18,640 --> 01:19:22,239
We then considered a more complex

2103
01:19:20,400 --> 01:19:24,320
setting what we're calling an affinity

2104
01:19:22,239 --> 01:19:26,719
catalog where not only are we trying to

2105
01:19:24,320 --> 01:19:28,560
control the cell type specificity of the

2106
01:19:26,719 --> 01:19:31,679
region we're also trying to control the

2107
01:19:28,560 --> 01:19:34,239
dosids in the onarget cell line. And so

2108
01:19:31,679 --> 01:19:36,560
we set specific targets here where where

2109
01:19:34,239 --> 01:19:38,400
we want to design weak enhancers,

2110
01:19:36,560 --> 01:19:40,480
mid-strength enhancers, strong

2111
01:19:38,400 --> 01:19:42,239
enhancers, and unnaturally strong

2112
01:19:40,480 --> 01:19:44,880
regions which are more strong than any

2113
01:19:42,239 --> 01:19:47,520
indogenous enhancer uh from previously

2114
01:19:44,880 --> 01:19:48,880
characterized starseek experiments. We

2115
01:19:47,520 --> 01:19:50,560
also wanted to see if we could design

2116
01:19:48,880 --> 01:19:52,480
enhancers which are active in both cell

2117
01:19:50,560 --> 01:19:53,840
lines from each one of these pools. And

2118
01:19:52,480 --> 01:19:54,960
so this was kind of a comprehensive

2119
01:19:53,840 --> 01:19:56,320
experiment. One of the benefits of

2120
01:19:54,960 --> 01:19:58,400
Starseek is that it's super high

2121
01:19:56,320 --> 01:19:59,920
throughput and so we're able to easily

2122
01:19:58,400 --> 01:20:01,440
do thousands of such candidate

2123
01:19:59,920 --> 01:20:03,280
sequences.

2124
01:20:01,440 --> 01:20:04,880
U

2125
01:20:03,280 --> 01:20:07,040
this is what the data looks like there

2126
01:20:04,880 --> 01:20:08,960
that it seems much more cell type

2127
01:20:07,040 --> 01:20:11,199
specific here because we are explicitly

2128
01:20:08,960 --> 01:20:14,239
trying to keep the offtarget cell line

2129
01:20:11,199 --> 01:20:16,400
off but we see a gradient of activity in

2130
01:20:14,239 --> 01:20:18,560
the ontarget cell line where there's a

2131
01:20:16,400 --> 01:20:20,560
bit of overlap there between the weak S2

2132
01:20:18,560 --> 01:20:22,480
enhancers and the weak o enhancers some

2133
01:20:20,560 --> 01:20:24,320
of them kind of dropped out but that

2134
01:20:22,480 --> 01:20:26,640
otherwise it's forming this sort of L

2135
01:20:24,320 --> 01:20:28,400
shape when we consider the enhancers

2136
01:20:26,640 --> 01:20:31,120
which are supposed to be active in both

2137
01:20:28,400 --> 01:20:32,480
they kind of follow the diagonal where

2138
01:20:31,120 --> 01:20:35,760
the regions that are they're getting

2139
01:20:32,480 --> 01:20:37,840
stronger and stronger cell lines.

2140
01:20:35,760 --> 01:20:39,520
So,

2141
01:20:37,840 --> 01:20:42,320
uh was kind of surprising here is how

2142
01:20:39,520 --> 01:20:45,360
few edits we were able to do this in

2143
01:20:42,320 --> 01:20:46,880
these uh sequences were 249 base pairs

2144
01:20:45,360 --> 01:20:48,800
long because that's the input window of

2145
01:20:46,880 --> 01:20:51,600
the deep store models. But that we were

2146
01:20:48,800 --> 01:20:53,679
able to design um cell type specific

2147
01:20:51,600 --> 01:20:56,000
enhancers that were of strong activity

2148
01:20:53,679 --> 01:20:58,719
in fewer than 20 edits. So by editing

2149
01:20:56,000 --> 01:21:01,440
less than 10% of the sequence uh we

2150
01:20:58,719 --> 01:21:03,360
could induce you know kind of strong

2151
01:21:01,440 --> 01:21:06,320
activity. The mining gap ones are a

2152
01:21:03,360 --> 01:21:09,280
little bit of a outlier there because

2153
01:21:06,320 --> 01:21:10,400
they are I can talk about that later but

2154
01:21:09,280 --> 01:21:11,920
basically they are a little bit of an

2155
01:21:10,400 --> 01:21:14,000
outlier due to the way that the

2156
01:21:11,920 --> 01:21:15,760
objective is formulated. But it was

2157
01:21:14,000 --> 01:21:19,280
quite surprising how few edits one was

2158
01:21:15,760 --> 01:21:21,120
able to uh one was able to use here. But

2159
01:21:19,280 --> 01:21:23,199
this brings up a natural question of

2160
01:21:21,120 --> 01:21:25,280
well okay so what are the edits that are

2161
01:21:23,199 --> 01:21:27,679
being made here? And so I want to share

2162
01:21:25,280 --> 01:21:29,440
two stories here uh that I thought were

2163
01:21:27,679 --> 01:21:30,880
really interesting.

2164
01:21:29,440 --> 01:21:33,040
The first was when we took a region

2165
01:21:30,880 --> 01:21:34,880
which was initially an S2 enhancer and

2166
01:21:33,040 --> 01:21:37,440
we wanted to edit it to become an

2167
01:21:34,880 --> 01:21:39,600
enhancer in OSC. You can imagine that

2168
01:21:37,440 --> 01:21:42,159
this involves two components. The first

2169
01:21:39,600 --> 01:21:44,480
is we have to turn off activity in S2

2170
01:21:42,159 --> 01:21:46,159
and then we have to turn on activity in

2171
01:21:44,480 --> 01:21:47,679
OSA.

2172
01:21:46,159 --> 01:21:49,440
And so when we look at the attributions

2173
01:21:47,679 --> 01:21:51,440
from the deep star models, you can see

2174
01:21:49,440 --> 01:21:53,360
that the reason that these models think

2175
01:21:51,440 --> 01:21:55,280
that this region is S2 specific

2176
01:21:53,360 --> 01:21:57,600
initially is because of the presence of

2177
01:21:55,280 --> 01:22:01,040
these two gata motives. Scatter is a S2

2178
01:21:57,600 --> 01:22:04,400
specific uh is a S2 specific factor

2179
01:22:01,040 --> 01:22:07,280
here. When we want to design enhancers

2180
01:22:04,400 --> 01:22:09,280
which have weak OSC specific activity,

2181
01:22:07,280 --> 01:22:11,040
you can see a few things are going on.

2182
01:22:09,280 --> 01:22:12,719
The first is that we make an edit on the

2183
01:22:11,040 --> 01:22:15,120
left hand side to knock out that data

2184
01:22:12,719 --> 01:22:16,639
binding site. We make two edits on the

2185
01:22:15,120 --> 01:22:18,639
right hand side to knock out the second

2186
01:22:16,639 --> 01:22:20,000
GAT binding site and then we make a few

2187
01:22:18,639 --> 01:22:21,760
edits that the model is a little bit

2188
01:22:20,000 --> 01:22:24,080
confused as to what exactly is going on

2189
01:22:21,760 --> 01:22:26,880
there. But we'll see in a second. With

2190
01:22:24,080 --> 01:22:29,280
10 total edits, we are able to convert

2191
01:22:26,880 --> 01:22:31,840
this from being a strong S2 specific

2192
01:22:29,280 --> 01:22:33,520
enhancer to a weak OS specific enhancer

2193
01:22:31,840 --> 01:22:34,960
where the experimental data verifies

2194
01:22:33,520 --> 01:22:38,400
that. I'm not showing the experimental

2195
01:22:34,960 --> 01:22:40,960
data, but it verifies that.

2196
01:22:38,400 --> 01:22:42,560
When we want to create a mid-strength OS

2197
01:22:40,960 --> 01:22:43,679
enhancer, you can see we're basically

2198
01:22:42,560 --> 01:22:45,199
doing the same thing. where we're

2199
01:22:43,679 --> 01:22:47,840
knocking out the gata binding sites on

2200
01:22:45,199 --> 01:22:49,520
either side but with one targeted edit

2201
01:22:47,840 --> 01:22:53,040
in the middle we have induced a traffic

2202
01:22:49,520 --> 01:22:54,639
jam motif now called traffic jam because

2203
01:22:53,040 --> 01:22:56,320
you know how drosopha people can be

2204
01:22:54,639 --> 01:22:58,560
sometimes

2205
01:22:56,320 --> 01:23:01,120
so what was interesting here is that

2206
01:22:58,560 --> 01:23:03,440
with one targeted edit just adding in

2207
01:23:01,120 --> 01:23:06,239
that C we were able to get a mid

2208
01:23:03,440 --> 01:23:08,880
strength OSE enhancer here but it took

2209
01:23:06,239 --> 01:23:11,600
us two edits before in order to get a

2210
01:23:08,880 --> 01:23:14,080
weak OSE enhancer and the reason is

2211
01:23:11,600 --> 01:23:15,920
because that C site there was critical

2212
01:23:14,080 --> 01:23:17,679
for getting the traffic jam motif at

2213
01:23:15,920 --> 01:23:19,920
all. And then you had to make a

2214
01:23:17,679 --> 01:23:22,639
subsequent edit to make it a weak

2215
01:23:19,920 --> 01:23:24,239
affinity version of that motif. So

2216
01:23:22,639 --> 01:23:26,239
sometimes activity in the genome when

2217
01:23:24,239 --> 01:23:28,000
you're doing editing isn't necessarily

2218
01:23:26,239 --> 01:23:30,320
linear with expectation. So it's not

2219
01:23:28,000 --> 01:23:31,760
exactly linear with the number of edits

2220
01:23:30,320 --> 01:23:34,239
needed for the amount of activity that

2221
01:23:31,760 --> 01:23:36,960
you want. It takes 10 total edits to get

2222
01:23:34,239 --> 01:23:38,880
uh to either direction and then 17 total

2223
01:23:36,960 --> 01:23:41,760
edits to make it a very strong version

2224
01:23:38,880 --> 01:23:43,600
of this OSE specific enhancer. Basically

2225
01:23:41,760 --> 01:23:45,840
what we end up doing is adding in a

2226
01:23:43,600 --> 01:23:48,000
second copy of this traffic jam motif

2227
01:23:45,840 --> 01:23:49,679
sort of on the dead body of the gata

2228
01:23:48,000 --> 01:23:52,679
motif that we had on the left hand side

2229
01:23:49,679 --> 01:23:52,679
there.

2230
01:23:52,719 --> 01:23:56,239
So then the second one that I wanted to

2231
01:23:54,320 --> 01:23:58,159
share with you was where we took a

2232
01:23:56,239 --> 01:24:00,239
region which was initially an OSC

2233
01:23:58,159 --> 01:24:02,800
specific enhancer and we wanted to make

2234
01:24:00,239 --> 01:24:05,280
it active in both cell lines. And so

2235
01:24:02,800 --> 01:24:07,600
this involves adding in activity as

2236
01:24:05,280 --> 01:24:10,239
opposed to you know swapping which uh

2237
01:24:07,600 --> 01:24:12,560
which cell line is activating

2238
01:24:10,239 --> 01:24:13,840
here. uh you can probably figure out

2239
01:24:12,560 --> 01:24:15,440
which one of the figures is being

2240
01:24:13,840 --> 01:24:18,000
included in the paper and which one was

2241
01:24:15,440 --> 01:24:20,400
made just for the uh slideshow. But here

2242
01:24:18,000 --> 01:24:22,560
we can see the attributions for the S2

2243
01:24:20,400 --> 01:24:25,120
cell line in the bottom and for the OSC

2244
01:24:22,560 --> 01:24:28,560
cell line on the top. The reason that

2245
01:24:25,120 --> 01:24:30,239
this wasn't an OS specific enhancer is

2246
01:24:28,560 --> 01:24:32,159
because of the presence of the traffic

2247
01:24:30,239 --> 01:24:34,159
jam motif with a little bit of other

2248
01:24:32,159 --> 01:24:37,520
stuff going on on the right hand side

2249
01:24:34,159 --> 01:24:39,280
there right next to it.

2250
01:24:37,520 --> 01:24:40,719
When we want to try making this weak in

2251
01:24:39,280 --> 01:24:42,000
both cell lines, we can see that not

2252
01:24:40,719 --> 01:24:46,000
much is really going on. There's some

2253
01:24:42,000 --> 01:24:48,239
stuff going on offscreen here.

2254
01:24:46,000 --> 01:24:50,320
When we want to make this a mid strength

2255
01:24:48,239 --> 01:24:51,360
enhancer in both cell lines is when we

2256
01:24:50,320 --> 01:24:53,920
start to see something really

2257
01:24:51,360 --> 01:24:56,639
interesting. By making these edits,

2258
01:24:53,920 --> 01:24:59,679
adding in a C and an A, we create a

2259
01:24:56,639 --> 01:25:03,040
traffic jam dur. This is a very strong

2260
01:24:59,679 --> 01:25:05,679
OSE specific signal there. But by

2261
01:25:03,040 --> 01:25:08,639
positioning the two traffic jam motifs

2262
01:25:05,679 --> 01:25:11,679
at that distance, what you end up doing

2263
01:25:08,639 --> 01:25:15,040
is implicitly creating an AP1 motif

2264
01:25:11,679 --> 01:25:17,760
within them. AP1 is specific to S2 as

2265
01:25:15,040 --> 01:25:20,480
well. And so this is something which I'm

2266
01:25:17,760 --> 01:25:23,280
describing as basically like Mario uh

2267
01:25:20,480 --> 01:25:25,920
motifs that these are motifs that are

2268
01:25:23,280 --> 01:25:27,679
that are explicitly within each other.

2269
01:25:25,920 --> 01:25:29,679
By being cell type specific for

2270
01:25:27,679 --> 01:25:32,400
different cell lines, you can now make

2271
01:25:29,679 --> 01:25:35,040
them active in multiple very distinct

2272
01:25:32,400 --> 01:25:36,800
cell lines. This only happens because

2273
01:25:35,040 --> 01:25:38,639
Leidi is trying to minimize the number

2274
01:25:36,800 --> 01:25:40,320
of edits that are being made. You could

2275
01:25:38,639 --> 01:25:41,920
imagine that there's no constraint. You

2276
01:25:40,320 --> 01:25:43,600
could just put the AP1 motif wherever.

2277
01:25:41,920 --> 01:25:46,000
You wouldn't have to think about this.

2278
01:25:43,600 --> 01:25:48,560
But it saw that by making these two

2279
01:25:46,000 --> 01:25:50,560
edits, you could add in activity in both

2280
01:25:48,560 --> 01:25:51,920
these cell lines at the same time. So I

2281
01:25:50,560 --> 01:25:53,600
think this is really interesting.

2282
01:25:51,920 --> 01:25:55,440
Sometimes we think about motifs as just

2283
01:25:53,600 --> 01:25:57,679
like, oh, there's a there's a blah motif

2284
01:25:55,440 --> 01:25:59,280
here and there's a blah motif over here.

2285
01:25:57,679 --> 01:26:01,280
But I've been trying to push for a while

2286
01:25:59,280 --> 01:26:03,440
now that the genome is much more

2287
01:26:01,280 --> 01:26:04,880
continuous than that. So here we have

2288
01:26:03,440 --> 01:26:07,040
different we have totally different

2289
01:26:04,880 --> 01:26:08,560
motifs that are overlapping each other.

2290
01:26:07,040 --> 01:26:10,400
Different proteins are binding to the

2291
01:26:08,560 --> 01:26:12,560
exact same nucleotides in different cell

2292
01:26:10,400 --> 01:26:14,000
lines.

2293
01:26:12,560 --> 01:26:15,520
And then we start to see stronger

2294
01:26:14,000 --> 01:26:16,960
activity in both when we want these to

2295
01:26:15,520 --> 01:26:19,360
be strong. And then we want them to be

2296
01:26:16,960 --> 01:26:20,960
unnaturally strong. Today uh we see

2297
01:26:19,360 --> 01:26:23,199
another version of the same phenomena

2298
01:26:20,960 --> 01:26:25,040
with the TJ Dmer and the APY motive on

2299
01:26:23,199 --> 01:26:29,000
the left hand side. So this is kind of a

2300
01:26:25,040 --> 01:26:29,000
reproducible sort of phenomena.

2301
01:26:29,040 --> 01:26:33,600
All right. Um I'm going to just skim

2302
01:26:31,920 --> 01:26:36,560
over a few things just some food for

2303
01:26:33,600 --> 01:26:38,960
thought for people. One of the other

2304
01:26:36,560 --> 01:26:40,960
inso experiments that we did is that we

2305
01:26:38,960 --> 01:26:42,880
paired together a chrome bpnet model

2306
01:26:40,960 --> 01:26:44,800
which made predictions for accessibility

2307
01:26:42,880 --> 01:26:46,080
with a bpnet model that made predictions

2308
01:26:44,800 --> 01:26:48,159
for the binding of an individual

2309
01:26:46,080 --> 01:26:51,280
protein. And by doing this, we're able

2310
01:26:48,159 --> 01:26:54,480
to design regions that were accessible

2311
01:26:51,280 --> 01:26:56,320
and control why they were accessible.

2312
01:26:54,480 --> 01:26:57,840
Instead of just using a panel of

2313
01:26:56,320 --> 01:26:59,360
different, you know, motifs depending

2314
01:26:57,840 --> 01:27:01,199
on, you know, what happened to be

2315
01:26:59,360 --> 01:27:03,520
available, we were able to create sites

2316
01:27:01,199 --> 01:27:06,000
which were uniformly accessible but

2317
01:27:03,520 --> 01:27:07,440
control which exact transcription

2318
01:27:06,000 --> 01:27:10,400
factors were binding and causing that

2319
01:27:07,440 --> 01:27:12,159
access or were binding in that in those

2320
01:27:10,400 --> 01:27:14,159
accessible sites. We don't have

2321
01:27:12,159 --> 01:27:17,199
experimental data for this yet, but

2322
01:27:14,159 --> 01:27:18,800
these uh incilico data looks uh quite

2323
01:27:17,199 --> 01:27:20,480
nice.

2324
01:27:18,800 --> 01:27:23,120
We can also turn this concept on its

2325
01:27:20,480 --> 01:27:24,719
head. We've been talking so much about

2326
01:27:23,120 --> 01:27:26,320
uh uh we've been talking so far about

2327
01:27:24,719 --> 01:27:28,239
using models that make predictions for

2328
01:27:26,320 --> 01:27:30,639
different sorts of things and being able

2329
01:27:28,239 --> 01:27:32,400
to control different parts of biology

2330
01:27:30,639 --> 01:27:33,760
with them. But what happens if you use

2331
01:27:32,400 --> 01:27:36,000
multiple models that make predictions

2332
01:27:33,760 --> 01:27:38,960
for the same thing? This can be used for

2333
01:27:36,000 --> 01:27:41,120
a more robust design setting that if you

2334
01:27:38,960 --> 01:27:43,520
make edits that all of the models have

2335
01:27:41,120 --> 01:27:45,280
to agree are helpful for a particular

2336
01:27:43,520 --> 01:27:47,280
task like the binding of a particular

2337
01:27:45,280 --> 01:27:49,520
protein or accessibility, you're much

2338
01:27:47,280 --> 01:27:52,400
much less likely to overfit to the

2339
01:27:49,520 --> 01:27:54,320
eccentricities of any specific model.

2340
01:27:52,400 --> 01:27:55,840
This is a little bit uh difficult to

2341
01:27:54,320 --> 01:27:57,840
interpret. who are reworking the figure.

2342
01:27:55,840 --> 01:28:01,280
But the gist is basically that when you

2343
01:27:57,840 --> 01:28:02,480
use even one other model, when you pair

2344
01:28:01,280 --> 01:28:04,560
together two models that make

2345
01:28:02,480 --> 01:28:06,480
predictions for the same things, you get

2346
01:28:04,560 --> 01:28:08,719
designs which are much more robust and

2347
01:28:06,480 --> 01:28:13,560
much better validated by external models

2348
01:28:08,719 --> 01:28:13,560
than if you use any individual model.

2349
01:28:14,560 --> 01:28:18,280
Okay. Uh

2350
01:28:20,239 --> 01:28:23,760
this last part is a little bit uh

2351
01:28:22,159 --> 01:28:27,920
complicated. So I think that I'm just

2352
01:28:23,760 --> 01:28:29,760
gonna wrap it up at this point and

2353
01:28:27,920 --> 01:28:34,840
I think I was gonna wrap it up at this

2354
01:28:29,760 --> 01:28:34,840
point and thank all of my colle

2355
01:28:34,960 --> 01:28:40,080
and summarize it. Uh so basically leidi

2356
01:28:38,080 --> 01:28:41,679
is a design method which means that it

2357
01:28:40,080 --> 01:28:43,120
can be paired with any machine learning

2358
01:28:41,679 --> 01:28:45,280
model or a collection of machine

2359
01:28:43,120 --> 01:28:47,120
learning model to design edits to an

2360
01:28:45,280 --> 01:28:48,639
initial template sequence that can

2361
01:28:47,120 --> 01:28:51,199
control very precisely the

2362
01:28:48,639 --> 01:28:54,320
characteristics of that sequence.

2363
01:28:51,199 --> 01:28:56,480
Um we have introduced this idea of an

2364
01:28:54,320 --> 01:28:58,639
affinity catalog where instead of just

2365
01:28:56,480 --> 01:29:00,159
designing for a single target which is

2366
01:28:58,639 --> 01:29:02,320
pretty common right now trying to design

2367
01:29:00,159 --> 01:29:04,719
very strongly cell type specific

2368
01:29:02,320 --> 01:29:06,960
activity you try to make designs for

2369
01:29:04,719 --> 01:29:08,719
many different steps along a path

2370
01:29:06,960 --> 01:29:11,120
because this can be quite useful not

2371
01:29:08,719 --> 01:29:14,639
only in practice but also for

2372
01:29:11,120 --> 01:29:16,159
understanding the biology of sequences.

2373
01:29:14,639 --> 01:29:19,840
So

2374
01:29:16,159 --> 01:29:21,520
um I think that the

2375
01:29:19,840 --> 01:29:23,520
in general the development of these

2376
01:29:21,520 --> 01:29:25,199
sorts of models these sorts of methods

2377
01:29:23,520 --> 01:29:26,880
which make use of the train models are

2378
01:29:25,199 --> 01:29:28,800
important for the field. We've been

2379
01:29:26,880 --> 01:29:30,480
spending a lot of time trying to

2380
01:29:28,800 --> 01:29:32,320
optimize the predictive performance of

2381
01:29:30,480 --> 01:29:34,719
the models that we train. We have

2382
01:29:32,320 --> 01:29:37,920
competitions that try to you know

2383
01:29:34,719 --> 01:29:39,520
encourage development in this but we

2384
01:29:37,920 --> 01:29:41,280
don't really know what to do with these

2385
01:29:39,520 --> 01:29:43,120
mo maybe not don't know what to do but

2386
01:29:41,280 --> 01:29:45,040
much less focus has been paid to what

2387
01:29:43,120 --> 01:29:47,199
exactly we do with these models after

2388
01:29:45,040 --> 01:29:49,280
they have been trained and so design I

2389
01:29:47,199 --> 01:29:50,800
think is a really promising area for how

2390
01:29:49,280 --> 01:29:53,120
we can use these models that actually

2391
01:29:50,800 --> 01:29:54,719
make a real world impact. So I'd like to

2392
01:29:53,120 --> 01:29:56,000
thank all my collaborators over the

2393
01:29:54,719 --> 01:29:58,239
years that have helped with this project

2394
01:29:56,000 --> 01:30:00,159
and many other collaborations and thank

2395
01:29:58,239 --> 01:30:02,880
you for taking the time to listen to me.

2396
01:30:00,159 --> 01:30:02,880
Thank you.

2397
01:30:07,760 --> 01:30:11,600
Um thank you for the great talk. I think

2398
01:30:09,679 --> 01:30:14,159
this is related to Orura's question a

2399
01:30:11,600 --> 01:30:16,000
little bit actually. Um a lot of these

2400
01:30:14,159 --> 01:30:17,440
sequence of function models are trained

2401
01:30:16,000 --> 01:30:20,159
on the reference genome, right?

2402
01:30:17,440 --> 01:30:22,960
>> Yeah. And um

2403
01:30:20,159 --> 01:30:24,800
in the past the reference genome the the

2404
01:30:22,960 --> 01:30:27,760
reference al didn't necessarily need to

2405
01:30:24,800 --> 01:30:29,360
be the most frequent one observed in the

2406
01:30:27,760 --> 01:30:31,679
population because I don't think we've

2407
01:30:29,360 --> 01:30:34,159
had sequenced that many. Um I read that

2408
01:30:31,679 --> 01:30:37,199
the newest like the most recent version

2409
01:30:34,159 --> 01:30:42,000
updated some of the reference alals to

2410
01:30:37,199 --> 01:30:45,199
um the more frequent um alals. Anyway,

2411
01:30:42,000 --> 01:30:46,800
so I think some of the models are maybe

2412
01:30:45,199 --> 01:30:48,639
trained may may have been I don't

2413
01:30:46,800 --> 01:30:51,280
actually know trained on an older

2414
01:30:48,639 --> 01:30:53,280
reference genome. Some of them may be

2415
01:30:51,280 --> 01:30:55,679
trained on a newer reference genome and

2416
01:30:53,280 --> 01:31:01,280
I'm assuming your initial sequence is

2417
01:30:55,679 --> 01:31:03,760
the reference genome. Um how much does

2418
01:31:01,280 --> 01:31:07,440
can you comment on whether

2419
01:31:03,760 --> 01:31:10,000
the consistency between the models with

2420
01:31:07,440 --> 01:31:12,080
respect to the you know base sequence

2421
01:31:10,000 --> 01:31:12,560
used in training matters.

2422
01:31:12,080 --> 01:31:14,239
>> Yeah.

2423
01:31:12,560 --> 01:31:16,000
>> Um yeah

2424
01:31:14,239 --> 01:31:17,520
>> this is a great question. Something you

2425
01:31:16,000 --> 01:31:20,719
may also be interested in is that I

2426
01:31:17,520 --> 01:31:22,800
think that autoboot had a paper a few

2427
01:31:20,719 --> 01:31:26,000
years ago showing that the HG19

2428
01:31:22,800 --> 01:31:28,800
reference genome had the markers of type

2429
01:31:26,000 --> 01:31:30,400
1 diabetes in it. And so for anyone who

2430
01:31:28,800 --> 01:31:32,560
was studying diabetes using that

2431
01:31:30,400 --> 01:31:34,960
reference genome, it may have given a

2432
01:31:32,560 --> 01:31:37,600
incorrect impression of the genetic

2433
01:31:34,960 --> 01:31:39,199
landscape there, which is weird because

2434
01:31:37,600 --> 01:31:40,239
the way he phrased it at least, and I

2435
01:31:39,199 --> 01:31:42,080
don't know if this is true, it just

2436
01:31:40,239 --> 01:31:43,199
seemed like nobody had looked before to

2437
01:31:42,080 --> 01:31:44,400
see whether or not these sorts of

2438
01:31:43,199 --> 01:31:46,719
disease markers were present in

2439
01:31:44,400 --> 01:31:48,880
reference genomes as to whether or not

2440
01:31:46,719 --> 01:31:51,520
this affects machine learning models. I

2441
01:31:48,880 --> 01:31:53,679
think the field is kind of split. The

2442
01:31:51,520 --> 01:31:54,960
intuition makes sense as you clear the

2443
01:31:53,679 --> 01:31:56,000
presented that if you train on the

2444
01:31:54,960 --> 01:31:57,840
reference genome but the reference

2445
01:31:56,000 --> 01:32:00,719
genome is not correct how could the

2446
01:31:57,840 --> 01:32:02,639
machine learning models be correct

2447
01:32:00,719 --> 01:32:04,800
but when people go and they try to train

2448
01:32:02,639 --> 01:32:06,719
on either corrected versions or

2449
01:32:04,800 --> 01:32:08,400
personalized versions or using a variety

2450
01:32:06,719 --> 01:32:09,760
of genome it doesn't actually seem to

2451
01:32:08,400 --> 01:32:11,840
increase predictive performance that

2452
01:32:09,760 --> 01:32:14,239
much so I think it's still an open

2453
01:32:11,840 --> 01:32:16,239
question of whether or not we haven't

2454
01:32:14,239 --> 01:32:18,159
yet found the best ways of improving

2455
01:32:16,239 --> 01:32:20,239
predictive performance given the

2456
01:32:18,159 --> 01:32:21,520
variation that we're able to incorporate

2457
01:32:20,239 --> 01:32:23,120
whether or not we haven't actually

2458
01:32:21,520 --> 01:32:25,440
gotten that much data that really

2459
01:32:23,120 --> 01:32:26,800
incorporates personal variance or if

2460
01:32:25,440 --> 01:32:30,480
there's just something else that we're

2461
01:32:26,800 --> 01:32:32,719
missing because it is true conceptually

2462
01:32:30,480 --> 01:32:34,719
that any limitations in the data will

2463
01:32:32,719 --> 01:32:36,960
become present in the models. But this

2464
01:32:34,719 --> 01:32:38,639
is also

2465
01:32:36,960 --> 01:32:40,320
it's unclear whether or not if you're

2466
01:32:38,639 --> 01:32:41,920
averaging over tens of thousands of

2467
01:32:40,320 --> 01:32:43,760
protein binding sites whether or not the

2468
01:32:41,920 --> 01:32:47,760
variation at any particular or like even

2469
01:32:43,760 --> 01:32:51,040
a dozen sites really matters that much.

2470
01:32:47,760 --> 01:32:53,920
>> Thanks for the great talk. Um so I guess

2471
01:32:51,040 --> 01:32:55,440
uh my question is related to

2472
01:32:53,920 --> 01:32:58,080
uh whether you've done experimental

2473
01:32:55,440 --> 01:33:00,639
validation on other models which have

2474
01:32:58,080 --> 01:33:02,719
you know more nonlinearities added. So I

2475
01:33:00,639 --> 01:33:04,159
guess for lidi you know the benefit is

2476
01:33:02,719 --> 01:33:06,639
you know you have a pre-trained model

2477
01:33:04,159 --> 01:33:09,920
and you have you're basically optimizing

2478
01:33:06,639 --> 01:33:11,360
a given sequence using that. So and you

2479
01:33:09,920 --> 01:33:13,600
know it's speedy you can plug in

2480
01:33:11,360 --> 01:33:15,520
different models as well. Uh but have

2481
01:33:13,600 --> 01:33:17,520
you compared performance on experimental

2482
01:33:15,520 --> 01:33:19,199
data with you know maybe you have a

2483
01:33:17,520 --> 01:33:21,199
generator network for example and then

2484
01:33:19,199 --> 01:33:21,440
you have your pre-trained predictor.

2485
01:33:21,199 --> 01:33:23,199
>> Yeah.

2486
01:33:21,440 --> 01:33:27,679
>> Uh and you know have you compared that

2487
01:33:23,199 --> 01:33:29,600
and you see any uh improvements or

2488
01:33:27,679 --> 01:33:30,880
Yeah. I'm just curious if you run those

2489
01:33:29,600 --> 01:33:32,880
comparisons.

2490
01:33:30,880 --> 01:33:34,719
>> Yeah. I think the the short answer is

2491
01:33:32,880 --> 01:33:38,159
that no we don't have experimental data

2492
01:33:34,719 --> 01:33:39,679
for these sorts of generative models. Um

2493
01:33:38,159 --> 01:33:42,159
there are some practical reasons. The

2494
01:33:39,679 --> 01:33:46,080
first being I don't have a wet lab. Um

2495
01:33:42,159 --> 01:33:49,440
but there are other just intuitively I

2496
01:33:46,080 --> 01:33:53,760
am sometimes skeptical about this idea

2497
01:33:49,440 --> 01:33:56,239
of these generative models um because

2498
01:33:53,760 --> 01:33:58,719
what you have to do is train a whole

2499
01:33:56,239 --> 01:34:00,880
separate model for your design task

2500
01:33:58,719 --> 01:34:02,800
against the Oracle model that Lidi is

2501
01:34:00,880 --> 01:34:04,960
using and so it's basically like

2502
01:34:02,800 --> 01:34:07,280
stacking spinning plates on top of each

2503
01:34:04,960 --> 01:34:09,280
other. I already don't trust the machine

2504
01:34:07,280 --> 01:34:11,199
learning model that I'm using the DD on.

2505
01:34:09,280 --> 01:34:13,679
And now this idea of having to train and

2506
01:34:11,199 --> 01:34:16,320
quality control a whole second model

2507
01:34:13,679 --> 01:34:19,040
before I can even do design even if it

2508
01:34:16,320 --> 01:34:21,920
was successful. It seems to me that it

2509
01:34:19,040 --> 01:34:23,840
would be a huge investment of time that

2510
01:34:21,920 --> 01:34:25,520
isn't necessary because ultimately you

2511
01:34:23,840 --> 01:34:29,560
can just use a method like the DD in

2512
01:34:25,520 --> 01:34:29,560
order to get designs as well.

2513
01:34:32,400 --> 01:34:36,800
Uh this is probably a bit of a silly

2514
01:34:34,480 --> 01:34:38,320
question but you uh talked about how

2515
01:34:36,800 --> 01:34:40,880
that it is a design algorithm and you

2516
01:34:38,320 --> 01:34:44,159
can pair it with any machine learning. I

2517
01:34:40,880 --> 01:34:46,000
was wondering how exactly do you plug

2518
01:34:44,159 --> 01:34:47,600
this machine learning model like how how

2519
01:34:46,000 --> 01:34:49,280
is it is it for the user to do that for

2520
01:34:47,600 --> 01:34:50,480
example what kind of integration does it

2521
01:34:49,280 --> 01:34:51,920
actually entail

2522
01:34:50,480 --> 01:34:53,600
>> or to talk about the implementation

2523
01:34:51,920 --> 01:34:56,480
details that if you have the model as a

2524
01:34:53,600 --> 01:34:58,560
pietorch object you just drop it and the

2525
01:34:56,480 --> 01:35:00,400
initial sequence into the lid function

2526
01:34:58,560 --> 01:35:02,639
as well as what you want the output from

2527
01:35:00,400 --> 01:35:05,520
the model to be and you're done. So all

2528
01:35:02,639 --> 01:35:06,800
you need is the pietorch object. Uh if

2529
01:35:05,520 --> 01:35:08,400
you want to use multiple models

2530
01:35:06,800 --> 01:35:11,199
simultaneously,

2531
01:35:08,400 --> 01:35:12,960
you you basically just can create a

2532
01:35:11,199 --> 01:35:14,639
wrapper class, we have one provided for

2533
01:35:12,960 --> 01:35:16,880
you where you just put put in a list of

2534
01:35:14,639 --> 01:35:18,159
models and then what the corresponding

2535
01:35:16,880 --> 01:35:21,040
output would be, you end up like

2536
01:35:18,159 --> 01:35:22,400
concatenating or whatever the um it's

2537
01:35:21,040 --> 01:35:23,760
not always straightforward because if

2538
01:35:22,400 --> 01:35:25,679
you want to have one model that makes

2539
01:35:23,760 --> 01:35:26,960
predictions for a profile and another

2540
01:35:25,679 --> 01:35:28,480
model that makes predictions for a

2541
01:35:26,960 --> 01:35:31,199
single scaler, you can't just

2542
01:35:28,480 --> 01:35:32,400
concatenate those. But you can do it

2543
01:35:31,199 --> 01:35:33,760
with lyidity if you follow the

2544
01:35:32,400 --> 01:35:36,080
guidelines.

2545
01:35:33,760 --> 01:35:40,320
>> Thank you. And the second question uh on

2546
01:35:36,080 --> 01:35:41,760
this uh on the like um final part of

2547
01:35:40,320 --> 01:35:44,800
your presentation where you talked about

2548
01:35:41,760 --> 01:35:48,159
combining models like uh chrome bpnet

2549
01:35:44,800 --> 01:35:49,920
and bpnet for example and um combining

2550
01:35:48,159 --> 01:35:52,000
where are the chromodin accessible and

2551
01:35:49,920 --> 01:35:54,880
why it is accessible. I'm guessing what

2552
01:35:52,000 --> 01:35:56,400
you find is a subset of the two um a

2553
01:35:54,880 --> 01:35:59,920
small one I'm guessing or I don't know

2554
01:35:56,400 --> 01:36:02,560
how small um like you have open

2555
01:35:59,920 --> 01:36:05,040
chromatin but only for a subset of that

2556
01:36:02,560 --> 01:36:06,800
you can actually figure out why

2557
01:36:05,040 --> 01:36:09,199
something if actually something is

2558
01:36:06,800 --> 01:36:12,719
binding there and why uh I was wondering

2559
01:36:09,199 --> 01:36:15,120
if you have um or thinking about any

2560
01:36:12,719 --> 01:36:16,800
examples where you can do some

2561
01:36:15,120 --> 01:36:19,199
biological validation why this is

2562
01:36:16,800 --> 01:36:20,960
interesting or if there is any way of um

2563
01:36:19,199 --> 01:36:23,360
pursuing this. Well, in terms of why

2564
01:36:20,960 --> 01:36:25,360
it's interesting that most of what this

2565
01:36:23,360 --> 01:36:27,760
boils down to is the design of

2566
01:36:25,360 --> 01:36:31,120
constructs for say AAVs or other sorts

2567
01:36:27,760 --> 01:36:33,280
of uh other sorts of probes. basically

2568
01:36:31,120 --> 01:36:36,239
that if you want to design something

2569
01:36:33,280 --> 01:36:37,920
which say glows uh you know you want to

2570
01:36:36,239 --> 01:36:39,280
design something which expresses GFP in

2571
01:36:37,920 --> 01:36:41,360
proportion to the concentration of

2572
01:36:39,280 --> 01:36:43,040
particular protein then you want you

2573
01:36:41,360 --> 01:36:44,400
know a particular transcription factor

2574
01:36:43,040 --> 01:36:46,880
then you want that transcription factor

2575
01:36:44,400 --> 01:36:50,000
to bind and through its binding increase

2576
01:36:46,880 --> 01:36:52,239
the expression of GFP and so if you are

2577
01:36:50,000 --> 01:36:54,480
designing a promoter site you want to

2578
01:36:52,239 --> 01:36:56,320
make sure that there are not secretly

2579
01:36:54,480 --> 01:36:57,920
maybe not secretly but that there just

2580
01:36:56,320 --> 01:37:00,320
aren't other sorts of binding sites

2581
01:36:57,920 --> 01:37:02,960
there so that the signal is convoluted

2582
01:37:00,320 --> 01:37:06,480
by the binding of other proteins and so

2583
01:37:02,960 --> 01:37:08,239
this very specific sort of um targeting

2584
01:37:06,480 --> 01:37:09,600
of a TF has quite a few practical

2585
01:37:08,239 --> 01:37:12,159
applications when you want to design

2586
01:37:09,600 --> 01:37:15,199
these sorts of reporters.

2587
01:37:12,159 --> 01:37:17,040
>> So uh so there is lot of reg as you said

2588
01:37:15,199 --> 01:37:19,199
like you know designing this is for like

2589
01:37:17,040 --> 01:37:24,159
in this whole cell experiment or in in

2590
01:37:19,199 --> 01:37:26,000
in vivo experiments uh so there is also

2591
01:37:24,159 --> 01:37:27,679
regulation a lot of regulation inside is

2592
01:37:26,000 --> 01:37:28,000
like a lot of things affect each other

2593
01:37:27,679 --> 01:37:31,280
right?

2594
01:37:28,000 --> 01:37:33,920
>> Yeah. So since we are only like two like

2595
01:37:31,280 --> 01:37:35,840
one uh step down I think you have showed

2596
01:37:33,920 --> 01:37:37,920
like okay we can have a promoter far end

2597
01:37:35,840 --> 01:37:40,560
of the protein and uh far out of

2598
01:37:37,920 --> 01:37:42,400
sequence and which the promoter can bind

2599
01:37:40,560 --> 01:37:44,239
and therefore increase the activity but

2600
01:37:42,400 --> 01:37:48,560
there are multiple steps cascades of

2601
01:37:44,239 --> 01:37:52,080
steps under down this initial thing. So

2602
01:37:48,560 --> 01:37:54,000
how like uh what could be like have you

2603
01:37:52,080 --> 01:37:55,679
done what could be done to sort of get

2604
01:37:54,000 --> 01:37:57,119
to that type of simulate?

2605
01:37:55,679 --> 01:37:59,520
>> Yes. So that's a great question.

2606
01:37:57,119 --> 01:38:01,520
Basically the gist is that predicting

2607
01:37:59,520 --> 01:38:03,440
transcription factor predict binding

2608
01:38:01,520 --> 01:38:04,719
accessibility transcription initiation

2609
01:38:03,440 --> 01:38:06,480
that's nice but that's not the whole

2610
01:38:04,719 --> 01:38:08,400
story when it comes to gene expression

2611
01:38:06,480 --> 01:38:10,400
and if we want to very specifically

2612
01:38:08,400 --> 01:38:12,239
target gene expression patterns we need

2613
01:38:10,400 --> 01:38:14,960
to do more than just these sorts of

2614
01:38:12,239 --> 01:38:18,000
models. So the nice thing about lyidity

2615
01:38:14,960 --> 01:38:19,440
is that you could any sort of model

2616
01:38:18,000 --> 01:38:21,440
that's differentiable and takes in

2617
01:38:19,440 --> 01:38:23,520
sequence context you could use and so if

2618
01:38:21,440 --> 01:38:25,679
we were able to model the how uh

2619
01:38:23,520 --> 01:38:28,239
changing protein binding patterns

2620
01:38:25,679 --> 01:38:29,920
influence accessibility and stack on top

2621
01:38:28,239 --> 01:38:31,440
of that a model that looks at how

2622
01:38:29,920 --> 01:38:33,440
changes in that predicted gene

2623
01:38:31,440 --> 01:38:35,199
expression might change global patterns.

2624
01:38:33,440 --> 01:38:37,920
You could stack all that together and

2625
01:38:35,199 --> 01:38:41,600
use that uh with lidi as long as it

2626
01:38:37,920 --> 01:38:43,199
becomes a single differentable unit. Uh

2627
01:38:41,600 --> 01:38:45,520
the gist is basically that this is a

2628
01:38:43,199 --> 01:38:47,920
weakness on the predictive modeling side

2629
01:38:45,520 --> 01:38:50,239
that lidi itself can't solve but when

2630
01:38:47,920 --> 01:38:53,119
one of us does solve it uh you can

2631
01:38:50,239 --> 01:38:55,199
immediately plug in lid to do designs.

2632
01:38:53,119 --> 01:38:57,760
>> Thanks. I wanted to follow up on the um

2633
01:38:55,199 --> 01:38:59,360
question of practical um applications. I

2634
01:38:57,760 --> 01:39:02,480
think this is perhaps more of like a a

2635
01:38:59,360 --> 01:39:04,560
suggestion than a question, but um the

2636
01:39:02,480 --> 01:39:06,719
reporter design is obviously really

2637
01:39:04,560 --> 01:39:10,880
really helpful, but in real world

2638
01:39:06,719 --> 01:39:15,440
applications um there are times when we

2639
01:39:10,880 --> 01:39:18,320
do want to create different enhancers in

2640
01:39:15,440 --> 01:39:21,360
um engineered cells. The the big one is

2641
01:39:18,320 --> 01:39:23,199
carti cells. So Alex Marson and Luke

2642
01:39:21,360 --> 01:39:25,760
Gilbert I think just had this really

2643
01:39:23,199 --> 01:39:28,159
nice paper where they did joint genetic

2644
01:39:25,760 --> 01:39:30,239
to make the cart tea and then epigenetic

2645
01:39:28,159 --> 01:39:31,920
to reduce T- cell exhaustion. But of

2646
01:39:30,239 --> 01:39:34,800
course the epigenetic you know a pro of

2647
01:39:31,920 --> 01:39:37,360
it is that it's not um very durable but

2648
01:39:34,800 --> 01:39:42,159
a a con is that it's not very durable.

2649
01:39:37,360 --> 01:39:44,080
So um in that case editing an endogenous

2650
01:39:42,159 --> 01:39:47,520
enhancer

2651
01:39:44,080 --> 01:39:50,239
in in a you know a targeted way to make

2652
01:39:47,520 --> 01:39:52,639
it more active to activate a given gene

2653
01:39:50,239 --> 01:39:55,280
expression program is very desirable.

2654
01:39:52,639 --> 01:39:59,520
And so I think my questions suggestion

2655
01:39:55,280 --> 01:40:02,719
is how many places in the human

2656
01:39:59,520 --> 01:40:05,840
non-coding genome in human enhancers

2657
01:40:02,719 --> 01:40:07,199
could you predict that maybe one or two

2658
01:40:05,840 --> 01:40:10,480
base changes because that's probably

2659
01:40:07,199 --> 01:40:12,480
what's practical, right? Is possible to

2660
01:40:10,480 --> 01:40:14,960
create to go from a weak enhancer to a

2661
01:40:12,480 --> 01:40:18,159
strong enhancer or to toggle an enhancer

2662
01:40:14,960 --> 01:40:20,560
based on your like you know minimum

2663
01:40:18,159 --> 01:40:22,480
maximum um effects because that would be

2664
01:40:20,560 --> 01:40:23,600
super interesting to know. That's a

2665
01:40:22,480 --> 01:40:25,360
really good question. That's something

2666
01:40:23,600 --> 01:40:27,440
we haven't uh quite looked at yet

2667
01:40:25,360 --> 01:40:29,520
because we weren't sure what to do with

2668
01:40:27,440 --> 01:40:31,520
the results once we had them. You know,

2669
01:40:29,520 --> 01:40:33,679
it's nice to publish a list of such

2670
01:40:31,520 --> 01:40:35,440
edits, but it presumably require

2671
01:40:33,679 --> 01:40:38,080
experimental validation in order to

2672
01:40:35,440 --> 01:40:40,000
reach its full impact, which uh I don't

2673
01:40:38,080 --> 01:40:44,040
yet have a collaborator in that space.

2674
01:40:40,000 --> 01:40:44,040
It's a really good idea though.

2675
01:40:45,119 --> 01:40:50,000
Uh so that was really interesting. Thank

2676
01:40:47,119 --> 01:40:52,960
you. You mostly talked about recruiting

2677
01:40:50,000 --> 01:40:54,880
activatory factors to enhance

2678
01:40:52,960 --> 01:40:57,040
expression. Have you tried to design

2679
01:40:54,880 --> 01:40:59,119
repressor elements?

2680
01:40:57,040 --> 01:41:02,639
>> That's a good question. Uh we have not

2681
01:40:59,119 --> 01:41:06,159
tried to design repressor elements yet

2682
01:41:02,639 --> 01:41:07,679
in part because it's challenging to know

2683
01:41:06,159 --> 01:41:09,840
whether or not you've designed a

2684
01:41:07,679 --> 01:41:12,239
repressor or you just haven't designed

2685
01:41:09,840 --> 01:41:15,520
an activator.

2686
01:41:12,239 --> 01:41:17,440
And so that would require careful

2687
01:41:15,520 --> 01:41:20,080
design where you have something which is

2688
01:41:17,440 --> 01:41:22,080
slightly active and you need to make

2689
01:41:20,080 --> 01:41:24,880
sure that you also haven't encountered

2690
01:41:22,080 --> 01:41:26,159
dropout just of the signal. Right? Uh

2691
01:41:24,880 --> 01:41:27,679
this is something I talked with Alex

2692
01:41:26,159 --> 01:41:29,840
about when we were trying to design the

2693
01:41:27,679 --> 01:41:32,480
experiments and ultimately we decided

2694
01:41:29,840 --> 01:41:35,520
that because of all these caveats when

2695
01:41:32,480 --> 01:41:37,440
it comes to repression that it may be

2696
01:41:35,520 --> 01:41:41,960
more challenging than an initial paper

2697
01:41:37,440 --> 01:41:41,960
would but it's super interesting.

2698
01:41:44,560 --> 01:41:46,880
Cool. Well, if there aren't any other

2699
01:41:45,840 --> 01:41:48,400
questions, I'll just mention that

2700
01:41:46,880 --> 01:41:50,400
because I'm a new faculty member, I'm

2701
01:41:48,400 --> 01:41:52,560
always looking for new grad students and

2702
01:41:50,400 --> 01:41:54,480
postocs. So, if anyone's interested or

2703
01:41:52,560 --> 01:41:57,770
knows someone who might be interested,

2704
01:41:54,480 --> 01:41:59,790
happy to chat.

2705
01:41:57,770 --> 01:41:59,790
[applause]


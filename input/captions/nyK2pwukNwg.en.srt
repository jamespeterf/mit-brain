1
00:00:00,080 --> 00:00:03,760
Thanks so much. Awesome. Um, well, yeah,

2
00:00:02,480 --> 00:00:04,920
it's a a pleasure to be here. Can

3
00:00:03,760 --> 00:00:09,760
everyone hear me

4
00:00:04,920 --> 00:00:13,440
clearly? Okay. Um, right. So, I come

5
00:00:09,760 --> 00:00:16,240
from two stop two stops away. And, um, I

6
00:00:13,440 --> 00:00:18,480
want to introduce you to a, uh, concept

7
00:00:16,240 --> 00:00:20,480
that has recently kind of completely

8
00:00:18,480 --> 00:00:22,240
reformulated how I think about where and

9
00:00:20,480 --> 00:00:25,119
when we should deploy AI because if I

10
00:00:22,240 --> 00:00:27,039
look at the AI for society seminar, you

11
00:00:25,119 --> 00:00:30,160
know, call, it's about the role of AI in

12
00:00:27,039 --> 00:00:31,679
society. Oh, so um let me start there.

13
00:00:30,160 --> 00:00:33,680
When should we use AI and when shouldn't

14
00:00:31,679 --> 00:00:36,480
we? I think this distinction between

15
00:00:33,680 --> 00:00:38,239
consequentialist thinking and what um

16
00:00:36,480 --> 00:00:40,160
professor Talbot and philosophy calls

17
00:00:38,239 --> 00:00:42,719
dialectical activities is a really

18
00:00:40,160 --> 00:00:45,520
important um compass for us to think

19
00:00:42,719 --> 00:00:47,039
about. So consequentialist thinking is

20
00:00:45,520 --> 00:00:48,719
reasoning when you're reasoning about

21
00:00:47,039 --> 00:00:50,960
actions and it's all about the ends

22
00:00:48,719 --> 00:00:52,640
right. Um a lot of HCI work that's my

23
00:00:50,960 --> 00:00:54,559
home field human computer interaction is

24
00:00:52,640 --> 00:00:57,280
about you know providing new means to

25
00:00:54,559 --> 00:00:59,760
get to the same ends or um uh new means

26
00:00:57,280 --> 00:01:02,160
to get to new ends and uh so you know if

27
00:00:59,760 --> 00:01:03,920
I'm at a hackathon uh maybe I don't care

28
00:01:02,160 --> 00:01:05,920
about the code that is being generated

29
00:01:03,920 --> 00:01:08,640
for me I just care that it has certain

30
00:01:05,920 --> 00:01:12,000
qualities that um you know reflect the

31
00:01:08,640 --> 00:01:14,479
um uh the the new idea that I have and

32
00:01:12,000 --> 00:01:16,080
if I'm dealing with email I hate email

33
00:01:14,479 --> 00:01:17,520
um I care about the relationships that

34
00:01:16,080 --> 00:01:20,080
email supports and I don't want to harm

35
00:01:17,520 --> 00:01:21,680
them but the email itself. You know, if

36
00:01:20,080 --> 00:01:24,159
something could do that for me, that

37
00:01:21,680 --> 00:01:26,720
would be great. Um, whereas with

38
00:01:24,159 --> 00:01:28,799
dialectical activities, they are a

39
00:01:26,720 --> 00:01:31,600
really special subset of activities

40
00:01:28,799 --> 00:01:32,680
where the they are have intrinsic value.

41
00:01:31,600 --> 00:01:35,759
Uh

42
00:01:32,680 --> 00:01:37,600
oh. And um they have intrinsic value

43
00:01:35,759 --> 00:01:42,159
that is revealed through repeated deep

44
00:01:37,600 --> 00:01:44,640
engagement. Right? So um this was my uh

45
00:01:42,159 --> 00:01:46,880
fuzzy rubber duck during my PhD in the

46
00:01:44,640 --> 00:01:49,040
building across the street where I was

47
00:01:46,880 --> 00:01:51,200
uh AI assisted programming didn't exist

48
00:01:49,040 --> 00:01:52,880
back then. So I had to repeatedly deep

49
00:01:51,200 --> 00:01:55,759
deeply engage with the codebase that I

50
00:01:52,880 --> 00:01:57,280
was building for like the key um uh part

51
00:01:55,759 --> 00:01:59,200
of my thesis. And only because I was

52
00:01:57,280 --> 00:02:02,159
repeatedly deeply engaging with it did I

53
00:01:59,200 --> 00:02:04,079
realize that the exercise of

54
00:02:02,159 --> 00:02:05,360
implementing a scheme interpreter and

55
00:02:04,079 --> 00:02:07,520
scheme that we used to have to do

56
00:02:05,360 --> 00:02:08,879
freshman year um was was replaying

57
00:02:07,520 --> 00:02:10,399
itself because I was implementing a

58
00:02:08,879 --> 00:02:12,319
Python interpreter in Python, right?

59
00:02:10,399 --> 00:02:15,360
that that kind of epiphany moment would

60
00:02:12,319 --> 00:02:18,080
not have been uh available to me if an

61
00:02:15,360 --> 00:02:21,040
AI had shortcircuited the process of

62
00:02:18,080 --> 00:02:23,040
engaging deeply with my code. Uh

63
00:02:21,040 --> 00:02:25,360
similarly, you know, um if you're you're

64
00:02:23,040 --> 00:02:26,879
writing a thank you note to a friend or

65
00:02:25,360 --> 00:02:28,959
you're reflecting on the meaning of a

66
00:02:26,879 --> 00:02:31,680
relationship in in a in a eulogy, right?

67
00:02:28,959 --> 00:02:33,760
If an AI uh wrote that for you based on

68
00:02:31,680 --> 00:02:35,680
a bullet list of like uh milestones in

69
00:02:33,760 --> 00:02:38,239
the relationship, um did you really get

70
00:02:35,680 --> 00:02:39,720
the value out of that exercise? um uh

71
00:02:38,239 --> 00:02:43,120
such as honoring a

72
00:02:39,720 --> 00:02:45,840
friend. Um necessary conditions of

73
00:02:43,120 --> 00:02:48,080
learning is a um is a a book about a

74
00:02:45,840 --> 00:02:49,920
particular theory of learning that I

75
00:02:48,080 --> 00:02:51,920
have repeatedly engaged with and it has

76
00:02:49,920 --> 00:02:54,640
revealed new insights to me every single

77
00:02:51,920 --> 00:02:56,560
time. AI cannot read it for me. Um or if

78
00:02:54,640 --> 00:03:00,640
it did, I wouldn't have those insights.

79
00:02:56,560 --> 00:03:02,239
Um um and also, you know, um if it uh

80
00:03:00,640 --> 00:03:04,400
had summarized this paper that

81
00:03:02,239 --> 00:03:06,480
introduced to me this concept at all, I

82
00:03:04,400 --> 00:03:08,959
wouldn't be uh probably have as

83
00:03:06,480 --> 00:03:10,239
influenced. So

84
00:03:08,959 --> 00:03:13,360
um teaching is an example of a

85
00:03:10,239 --> 00:03:15,760
dialectical activity. Uh giving talks I

86
00:03:13,360 --> 00:03:17,280
have learned in the last 48 hours new

87
00:03:15,760 --> 00:03:19,519
things about my work because I was

88
00:03:17,280 --> 00:03:21,360
forced to explain it again in a new way

89
00:03:19,519 --> 00:03:24,400
to a new audience. So for that I am very

90
00:03:21,360 --> 00:03:25,920
grateful already. Um uh even you know

91
00:03:24,400 --> 00:03:28,159
parenting um most people are not

92
00:03:25,920 --> 00:03:30,400
consequentialist about parenting. um

93
00:03:28,159 --> 00:03:32,080
they would not take the offer of uh

94
00:03:30,400 --> 00:03:34,080
exporting their kid to be raised

95
00:03:32,080 --> 00:03:36,080
elsewhere provided that the kid one of

96
00:03:34,080 --> 00:03:38,480
reaching 18 would have sufficiently

97
00:03:36,080 --> 00:03:39,959
comparable you know kind of beliefs uh

98
00:03:38,480 --> 00:03:42,480
uh uh to

99
00:03:39,959 --> 00:03:44,720
you. Okay. So why should we care about

100
00:03:42,480 --> 00:03:46,080
making this distinction? Argue this is a

101
00:03:44,720 --> 00:03:48,920
key distinction for deciding about when

102
00:03:46,080 --> 00:03:50,799
to use AI because

103
00:03:48,920 --> 00:03:53,680
uh when you're working with

104
00:03:50,799 --> 00:03:57,120
consequentialist uh activities AI truly

105
00:03:53,680 --> 00:03:59,760
can help. But if you try to apply AI to

106
00:03:57,120 --> 00:04:01,519
a dialectical activity, people who

107
00:03:59,760 --> 00:04:03,200
already know the value that would be

108
00:04:01,519 --> 00:04:05,920
revealed if they engage with it deeply

109
00:04:03,200 --> 00:04:07,760
will consider your tool useless or

110
00:04:05,920 --> 00:04:10,000
harmful because it would shortcircuit

111
00:04:07,760 --> 00:04:11,599
that value. Or if they've never

112
00:04:10,000 --> 00:04:12,799
repeatedly engaged with it um already,

113
00:04:11,599 --> 00:04:14,319
if they've never, you know, thought

114
00:04:12,799 --> 00:04:16,400
deeply about programming and they are

115
00:04:14,319 --> 00:04:19,440
starting off their um journey as

116
00:04:16,400 --> 00:04:21,840
programmers with AI assistance, um they

117
00:04:19,440 --> 00:04:23,199
may never realize that that value can

118
00:04:21,840 --> 00:04:24,560
come through, right? you're cutting off

119
00:04:23,199 --> 00:04:27,000
their ability to discover the

120
00:04:24,560 --> 00:04:30,320
dialectical nature of the

121
00:04:27,000 --> 00:04:32,880
activity. So, um there's a kind of

122
00:04:30,320 --> 00:04:35,520
preient comment in a uh paper by my

123
00:04:32,880 --> 00:04:39,240
colleague uh Kristoff Guyos and his uh

124
00:04:35,520 --> 00:04:42,000
former PhD student Ken Arnold um at

125
00:04:39,240 --> 00:04:43,680
IUI20 where they um they're looking at

126
00:04:42,000 --> 00:04:46,560
predictive text and how it affects what

127
00:04:43,680 --> 00:04:48,320
people wrote. They said for um well, for

128
00:04:46,560 --> 00:04:49,680
the most most part people wrote more

129
00:04:48,320 --> 00:04:51,919
efficiently with predictive text

130
00:04:49,680 --> 00:04:54,080
systems. This may have come at the cost

131
00:04:51,919 --> 00:04:55,840
of thoughtfulness, right? And this here,

132
00:04:54,080 --> 00:04:58,000
you know, when you are trying to measure

133
00:04:55,840 --> 00:05:01,280
the impact of introducing AI or some

134
00:04:58,000 --> 00:05:03,040
other smart intelligence into your um uh

135
00:05:01,280 --> 00:05:04,880
into your activity, you know, if you

136
00:05:03,040 --> 00:05:06,720
treat people like transcribing machines,

137
00:05:04,880 --> 00:05:08,560
you consider it to be a consequentialist

138
00:05:06,720 --> 00:05:10,000
activity that you are accelerating.

139
00:05:08,560 --> 00:05:11,600
Sure, you can say we made them more

140
00:05:10,000 --> 00:05:13,600
efficient, right? But the the writing

141
00:05:11,600 --> 00:05:15,360
was more predictable predictable that

142
00:05:13,600 --> 00:05:17,600
they produced in that study. It was less

143
00:05:15,360 --> 00:05:19,280
thoughtful, right? And so because you

144
00:05:17,600 --> 00:05:22,000
didn't treat people as thoughtful human

145
00:05:19,280 --> 00:05:24,080
being, you know, human beings that um

146
00:05:22,000 --> 00:05:25,280
might in the process of writing, if

147
00:05:24,080 --> 00:05:28,639
you've heard the phrase writing is

148
00:05:25,280 --> 00:05:30,320
thinking, come up with new ways of um uh

149
00:05:28,639 --> 00:05:33,240
new insights as they engage with the

150
00:05:30,320 --> 00:05:36,160
activity and you're cutting that off. So

151
00:05:33,240 --> 00:05:37,280
um to be meta about it, right? Um as I

152
00:05:36,160 --> 00:05:40,400
mentioned, writing this talk is a

153
00:05:37,280 --> 00:05:41,759
dialectical activity. Um I have to

154
00:05:40,400 --> 00:05:44,320
re-engage with the concept of

155
00:05:41,759 --> 00:05:46,320
dialectical activities, resee my own

156
00:05:44,320 --> 00:05:49,199
work through this lens.

157
00:05:46,320 --> 00:05:52,000
um go uh and and keep going back and

158
00:05:49,199 --> 00:05:54,160
forth with um Howchi Zang's philosophy

159
00:05:52,000 --> 00:05:56,000
paper on this and there's also

160
00:05:54,160 --> 00:05:57,440
non-diical activities, right? So,

161
00:05:56,000 --> 00:05:59,199
searching for sufficiently appropriate

162
00:05:57,440 --> 00:06:01,520
photos for the examples that I've

163
00:05:59,199 --> 00:06:03,600
provided, copying and pasting these

164
00:06:01,520 --> 00:06:06,479
previously made slides and and

165
00:06:03,600 --> 00:06:08,400
rejiggering them um because of this new

166
00:06:06,479 --> 00:06:12,560
lens through which I'm looking at them.

167
00:06:08,400 --> 00:06:14,479
Uh citation lookup, all of these things

168
00:06:12,560 --> 00:06:16,800
I'd love AI help with. it will not

169
00:06:14,479 --> 00:06:18,400
diminish the activity's value. Um, but

170
00:06:16,800 --> 00:06:20,319
the dialectical activities, if I didn't

171
00:06:18,400 --> 00:06:22,880
realize they were dialectical, I might

172
00:06:20,319 --> 00:06:25,400
um mistakenly I think mistakenly design

173
00:06:22,880 --> 00:06:28,240
AI to help with them or accept AI's

174
00:06:25,400 --> 00:06:29,440
help. And we'll um which I would argue

175
00:06:28,240 --> 00:06:31,440
uh in this case would fundamentally

176
00:06:29,440 --> 00:06:34,720
remove some of its dialectical nature.

177
00:06:31,440 --> 00:06:36,319
So first takeaway would be that um if we

178
00:06:34,720 --> 00:06:37,840
were thinking about AI in society, we

179
00:06:36,319 --> 00:06:39,600
should think really carefully about what

180
00:06:37,840 --> 00:06:41,759
components of an activity are

181
00:06:39,600 --> 00:06:43,520
dialectical and then be very careful

182
00:06:41,759 --> 00:06:44,960
about designing systems that affect

183
00:06:43,520 --> 00:06:46,880
those components. I'm not saying that

184
00:06:44,960 --> 00:06:52,160
you can't have AI play some role in

185
00:06:46,880 --> 00:06:54,880
there. Um uh but um if you are not you

186
00:06:52,160 --> 00:06:56,720
know it's it um exactly what you can and

187
00:06:54,880 --> 00:06:59,039
can't do without fundamentally changing

188
00:06:56,720 --> 00:07:01,840
the dialectical activity I think is is

189
00:06:59,039 --> 00:07:04,639
um uh something that we need to consider

190
00:07:01,840 --> 00:07:05,919
in every situation. Okay. So I've

191
00:07:04,639 --> 00:07:07,919
explained the concept of dialectical

192
00:07:05,919 --> 00:07:09,759
activities. Let's look at some of my own

193
00:07:07,919 --> 00:07:11,840
um uh work through this lens. So I

194
00:07:09,759 --> 00:07:14,319
promised two systems. First about AI

195
00:07:11,840 --> 00:07:19,120
writing. Uh I was my attention was drawn

196
00:07:14,319 --> 00:07:20,800
to this um uh blue sky comment. Even

197
00:07:19,120 --> 00:07:23,520
accepting the premise that AI produces

198
00:07:20,800 --> 00:07:25,360
useful writing which no one should um

199
00:07:23,520 --> 00:07:27,520
using AI in education is like using a

200
00:07:25,360 --> 00:07:28,960
forklift at the gym. The weights do not

201
00:07:27,520 --> 00:07:30,639
actually need to be moved from place to

202
00:07:28,960 --> 00:07:33,599
place. That is not the work. The work is

203
00:07:30,639 --> 00:07:34,599
what happens within you. Right? So, you

204
00:07:33,599 --> 00:07:37,080
know,

205
00:07:34,599 --> 00:07:39,680
um,

206
00:07:37,080 --> 00:07:41,680
uh, I'm going to talk about using AI in

207
00:07:39,680 --> 00:07:44,720
the context of writing original research

208
00:07:41,680 --> 00:07:47,440
papers, okay? where you could argue um

209
00:07:44,720 --> 00:07:49,759
maybe AI has no place but I think that

210
00:07:47,440 --> 00:07:51,840
we've developed some strategies that

211
00:07:49,759 --> 00:07:55,080
don't take away the dialectical nature

212
00:07:51,840 --> 00:07:56,960
and um still um make some aspects of

213
00:07:55,080 --> 00:08:02,280
writing I don't want to say less

214
00:07:56,960 --> 00:08:04,720
effortful but um maybe a little more um

215
00:08:02,280 --> 00:08:06,800
enhanced okay so if you're writing a

216
00:08:04,720 --> 00:08:08,960
paper you know good old overleaf I'm

217
00:08:06,800 --> 00:08:10,639
sure many of you have used it uh it's a

218
00:08:08,960 --> 00:08:12,479
dialectical activity and it's also for a

219
00:08:10,639 --> 00:08:15,280
particular audience you're generally I

220
00:08:12,479 --> 00:08:16,879
would argue you not ever writing without

221
00:08:15,280 --> 00:08:19,599
some audience in mind whether that's a

222
00:08:16,879 --> 00:08:24,479
particular conference um or a particular

223
00:08:19,599 --> 00:08:25,840
type of reader. It's effortful and um

224
00:08:24,479 --> 00:08:28,240
and that effective communication

225
00:08:25,840 --> 00:08:30,039
requires reasoning about the receiving

226
00:08:28,240 --> 00:08:32,880
audience's

227
00:08:30,039 --> 00:08:35,360
expectations. So um you know for example

228
00:08:32,880 --> 00:08:38,240
if you break certain rules that can

229
00:08:35,360 --> 00:08:40,640
distract or confuse the reader.

230
00:08:38,240 --> 00:08:42,640
um the information they might want might

231
00:08:40,640 --> 00:08:44,800
be in a place where they don't expect so

232
00:08:42,640 --> 00:08:45,839
they don't know where to find it. Uh if

233
00:08:44,800 --> 00:08:48,240
you've ever heard the phrase know the

234
00:08:45,839 --> 00:08:50,080
rules so you can break them effectively,

235
00:08:48,240 --> 00:08:51,839
right? Um it's it's not that you are

236
00:08:50,080 --> 00:08:54,480
constrained by those rules, you just

237
00:08:51,839 --> 00:08:58,720
need to reason about them as you decide

238
00:08:54,480 --> 00:09:00,760
uh how best to communicate your ideas.

239
00:08:58,720 --> 00:09:04,000
So

240
00:09:00,760 --> 00:09:06,480
um existing AI assisted writing systems

241
00:09:04,000 --> 00:09:07,920
in this class uh or sorry that that that

242
00:09:06,480 --> 00:09:10,080
we were kind of responding to that

243
00:09:07,920 --> 00:09:11,839
pre-existed to the system that we made

244
00:09:10,080 --> 00:09:15,040
they generate they generally generate

245
00:09:11,839 --> 00:09:16,959
text okay um but the risk with this

246
00:09:15,040 --> 00:09:19,279
characteristic is that it might be too

247
00:09:16,959 --> 00:09:21,760
close to an original source document and

248
00:09:19,279 --> 00:09:25,440
you are not resilient to that mistake on

249
00:09:21,760 --> 00:09:27,360
the AI's part right um uh you it's

250
00:09:25,440 --> 00:09:29,360
extraordinarily difficult to detect that

251
00:09:27,360 --> 00:09:30,360
AI choice that could land you in real

252
00:09:29,360 --> 00:09:32,959
hot

253
00:09:30,360 --> 00:09:35,200
water. They also often only show a

254
00:09:32,959 --> 00:09:37,120
couple of examples because the kind of

255
00:09:35,200 --> 00:09:39,200
going thought process is that more than

256
00:09:37,120 --> 00:09:40,720
a couple examples is overwhelming.

257
00:09:39,200 --> 00:09:42,640
Choice overload, people kind of shut

258
00:09:40,720 --> 00:09:44,720
down, right? Why would you do that? Just

259
00:09:42,640 --> 00:09:46,399
carefully choose those few examples.

260
00:09:44,720 --> 00:09:48,560
Problem with that is that you may be

261
00:09:46,399 --> 00:09:50,959
vulnerable to retrieval quality, right?

262
00:09:48,560 --> 00:09:52,560
So the AI that's choosing or or whatever

263
00:09:50,959 --> 00:09:55,519
intelligence is uh choosing those

264
00:09:52,560 --> 00:09:57,440
examples. If it's bad choices, you have

265
00:09:55,519 --> 00:09:59,279
very little recourse and you may anchor

266
00:09:57,440 --> 00:10:01,040
on those one of those choices

267
00:09:59,279 --> 00:10:02,880
unintentionally. And again, you're back

268
00:10:01,040 --> 00:10:03,920
kind of in this plagiarism um place. You

269
00:10:02,880 --> 00:10:07,680
don't really have that sense of that

270
00:10:03,920 --> 00:10:09,800
like uh of the the full diversity um uh

271
00:10:07,680 --> 00:10:12,880
from just a couple

272
00:10:09,800 --> 00:10:16,120
examples. Uh you could I I've not seen

273
00:10:12,880 --> 00:10:18,560
any existing systems except some sort of

274
00:10:16,120 --> 00:10:22,240
fine-tuning, right? Um but even if they

275
00:10:18,560 --> 00:10:24,240
did um even if even if there was writing

276
00:10:22,240 --> 00:10:25,839
system you said I want to write like you

277
00:10:24,240 --> 00:10:27,839
know um you know here's the audience I'm

278
00:10:25,839 --> 00:10:29,040
you know here's some examples of papers

279
00:10:27,839 --> 00:10:32,000
written by the audience I'm trying to

280
00:10:29,040 --> 00:10:34,079
write for even if you had uh chain forge

281
00:10:32,000 --> 00:10:36,000
which is um still publicly available

282
00:10:34,079 --> 00:10:38,320
it's um there's a Kai paper about it uh

283
00:10:36,000 --> 00:10:40,480
last year or uh our uh kind of

284
00:10:38,320 --> 00:10:42,560
rrendering enhancements that are also at

285
00:10:40,480 --> 00:10:46,320
Kai last year that helped you see

286
00:10:42,560 --> 00:10:48,000
variation across compare the outputs of

287
00:10:46,320 --> 00:10:49,760
multiple models right? One may be

288
00:10:48,000 --> 00:10:52,720
fine-tuned, one without the fine-tuning

289
00:10:49,760 --> 00:10:55,519
for a particular audience. Um, it's

290
00:10:52,720 --> 00:10:57,120
still hard to to to in a kind of big

291
00:10:55,519 --> 00:10:59,120
picture view understand whether that

292
00:10:57,120 --> 00:11:01,279
fine-tuning action, you know, what if

293
00:10:59,120 --> 00:11:04,519
any it changed about how the LLM is

294
00:11:01,279 --> 00:11:07,120
generating text for your purpose.

295
00:11:04,519 --> 00:11:09,600
So, we created a system called Corpus

296
00:11:07,120 --> 00:11:11,680
Studio at this year's Kai um which takes

297
00:11:09,600 --> 00:11:14,959
a radically different approach. It

298
00:11:11,680 --> 00:11:18,160
retrieves many examples retrieves and

299
00:11:14,959 --> 00:11:20,160
many being the operative uh words here

300
00:11:18,160 --> 00:11:21,920
from the corpus of papers that informed

301
00:11:20,160 --> 00:11:25,600
your audience's expectations. So other

302
00:11:21,920 --> 00:11:28,399
papers that were um uh uh previously

303
00:11:25,600 --> 00:11:29,760
published at the same conference and um

304
00:11:28,399 --> 00:11:31,680
because it's retrieval, you don't have

305
00:11:29,760 --> 00:11:34,160
to worry about AI introducing plagiarism

306
00:11:31,680 --> 00:11:36,560
you can't detect. Because there's many,

307
00:11:34,160 --> 00:11:40,000
you are not vulnerable to subconsciously

308
00:11:36,560 --> 00:11:42,800
anchoring um or kind of having less of a

309
00:11:40,000 --> 00:11:45,040
um big picture about uh what options you

310
00:11:42,800 --> 00:11:46,120
might have or what people might expect.

311
00:11:45,040 --> 00:11:48,880
And

312
00:11:46,120 --> 00:11:52,600
um and also having many examples you

313
00:11:48,880 --> 00:11:56,079
know um gives you um if you can see

314
00:11:52,600 --> 00:11:58,640
emergent patterns it can help you think

315
00:11:56,079 --> 00:12:00,959
about uh what that implicit norm is and

316
00:11:58,640 --> 00:12:04,720
how you want to either fulfill that norm

317
00:12:00,959 --> 00:12:06,800
or uh break it. And we also compute and

318
00:12:04,720 --> 00:12:10,399
render cross document sorry cross

319
00:12:06,800 --> 00:12:11,920
example relationships so that you can um

320
00:12:10,399 --> 00:12:14,000
you don't have to do all of that thought

321
00:12:11,920 --> 00:12:17,200
process yourself. we kind of try to um

322
00:12:14,000 --> 00:12:19,600
give you a leg up in forming mental

323
00:12:17,200 --> 00:12:21,200
models of how people write in that

324
00:12:19,600 --> 00:12:22,200
community to communicate what they want

325
00:12:21,200 --> 00:12:24,920
to

326
00:12:22,200 --> 00:12:27,399
say. So

327
00:12:24,920 --> 00:12:31,120
um all

328
00:12:27,399 --> 00:12:32,399
right at the document level we apply um

329
00:12:31,120 --> 00:12:34,480
something called positional diction

330
00:12:32,399 --> 00:12:36,880
clustering on the section titles. That

331
00:12:34,480 --> 00:12:38,880
positional diction clustering comes from

332
00:12:36,880 --> 00:12:40,560
um this previous kai paper for LLM

333
00:12:38,880 --> 00:12:42,720
outputs, but in this case it's being run

334
00:12:40,560 --> 00:12:45,079
on the document outlines like the

335
00:12:42,720 --> 00:12:49,360
section titles of all the papers in your

336
00:12:45,079 --> 00:12:53,600
corpus. And this basically just um kind

337
00:12:49,360 --> 00:12:57,720
of align uh similar sorry diction

338
00:12:53,600 --> 00:13:02,880
similar position similar section

339
00:12:57,720 --> 00:13:04,959
titles and um clusters them. Right? So,

340
00:13:02,880 --> 00:13:06,720
uh, you'll still have distinct clusters

341
00:13:04,959 --> 00:13:09,200
of titles even if they're identical, if

342
00:13:06,720 --> 00:13:13,279
they if they commonly occur in different

343
00:13:09,200 --> 00:13:17,600
parts of the document. And then we reify

344
00:13:13,279 --> 00:13:19,680
the size of those clusters uh with a um

345
00:13:17,600 --> 00:13:23,440
a histogram. Right? So, the introduction

346
00:13:19,680 --> 00:13:25,920
maybe in this three document example is

347
00:13:23,440 --> 00:13:28,800
uh present in all three. The background

348
00:13:25,920 --> 00:13:31,360
only was uh in one of them. Related work

349
00:13:28,800 --> 00:13:33,279
was in two. um at the beginning it was

350
00:13:31,360 --> 00:13:34,720
also once at the end which is very

351
00:13:33,279 --> 00:13:38,079
uncommon choice in the communities that

352
00:13:34,720 --> 00:13:39,920
I like to speak to um there was only one

353
00:13:38,079 --> 00:13:42,560
out of the three had a formative study

354
00:13:39,920 --> 00:13:45,680
all of them had system design section

355
00:13:42,560 --> 00:13:48,000
though um we render when there's a

356
00:13:45,680 --> 00:13:50,000
diversity of

357
00:13:48,000 --> 00:13:52,720
um to give you information sent about

358
00:13:50,000 --> 00:13:54,639
the content of a cluster we underline

359
00:13:52,720 --> 00:13:56,800
the tokens within that cluster that are

360
00:13:54,639 --> 00:14:00,000
consistent across all cluster members so

361
00:13:56,800 --> 00:14:01,560
you have some sense of what kind of uh

362
00:14:00,000 --> 00:14:04,399
brings that cluster

363
00:14:01,560 --> 00:14:06,720
together and then um you know the rest

364
00:14:04,399 --> 00:14:08,000
uh the example here are also all in the

365
00:14:06,720 --> 00:14:10,399
three examples. So if you do that for

366
00:14:08,000 --> 00:14:12,480
hundreds or thousands of papers um you

367
00:14:10,399 --> 00:14:14,800
can get this what we call an ordered

368
00:14:12,480 --> 00:14:16,240
distribution um that gives you kind of a

369
00:14:14,800 --> 00:14:18,760
big picture view of having registered

370
00:14:16,240 --> 00:14:22,720
all the paper structures against each

371
00:14:18,760 --> 00:14:25,120
other. Um a critical note is that this

372
00:14:22,720 --> 00:14:27,120
positional diction clustering algorithm

373
00:14:25,120 --> 00:14:28,800
is what you could call a uh structural

374
00:14:27,120 --> 00:14:30,800
mapping engine. This comes this is

375
00:14:28,800 --> 00:14:33,040
language that comes from the structural

376
00:14:30,800 --> 00:14:35,760
mapping or structural alignment theory

377
00:14:33,040 --> 00:14:38,240
of human cognition. Right? In a sense we

378
00:14:35,760 --> 00:14:40,560
all in order to com um to look at a

379
00:14:38,240 --> 00:14:42,720
bunch of things. We start comparing them

380
00:14:40,560 --> 00:14:44,320
to compare them our brain starts kind of

381
00:14:42,720 --> 00:14:47,040
iterating through representations of

382
00:14:44,320 --> 00:14:49,199
them and finding alignments of them so

383
00:14:47,040 --> 00:14:51,360
that you can you know notice their

384
00:14:49,199 --> 00:14:53,120
commonalities but also the differences

385
00:14:51,360 --> 00:14:54,800
within those alignments. Right? So this

386
00:14:53,120 --> 00:14:56,959
is all happening subconsciously and

387
00:14:54,800 --> 00:14:58,480
we're just trying to premputee that so

388
00:14:56,959 --> 00:15:00,399
that you can kind of stand on the

389
00:14:58,480 --> 00:15:04,240
shoulders of the computer rather than

390
00:15:00,399 --> 00:15:07,279
being overwhelmed by a wall of text. So

391
00:15:04,240 --> 00:15:10,880
um this is what I think enables people

392
00:15:07,279 --> 00:15:13,560
to enjoy and leverage the many examples

393
00:15:10,880 --> 00:15:17,199
that were um our alternative to

394
00:15:13,560 --> 00:15:20,000
generating uh text or kind of um more

395
00:15:17,199 --> 00:15:21,880
intelligently choosing a smaller set of

396
00:15:20,000 --> 00:15:24,120
examples.

397
00:15:21,880 --> 00:15:27,600
So

398
00:15:24,120 --> 00:15:29,440
um in order to uh for the sentence level

399
00:15:27,600 --> 00:15:30,880
example retrieval because we not just do

400
00:15:29,440 --> 00:15:34,800
it at the document level but also at the

401
00:15:30,880 --> 00:15:37,120
sentence level we have an editor where

402
00:15:34,800 --> 00:15:41,040
you are uh typing where you can you know

403
00:15:37,120 --> 00:15:42,959
in markdown say write um uh indicate

404
00:15:41,040 --> 00:15:44,880
that you're starting a new section you

405
00:15:42,959 --> 00:15:47,320
know hashtag participants if you're

406
00:15:44,880 --> 00:15:50,079
doing a user study and then

407
00:15:47,320 --> 00:15:52,880
um uh you know you can have some text

408
00:15:50,079 --> 00:15:55,120
but then At some point if you ret click

409
00:15:52,880 --> 00:15:57,680
retrieve right the sentence that you are

410
00:15:55,120 --> 00:16:01,360
currently in and the context around that

411
00:15:57,680 --> 00:16:02,839
sentence the section title um and uh

412
00:16:01,360 --> 00:16:05,199
even its

413
00:16:02,839 --> 00:16:08,240
offset goes through a vector embedding

414
00:16:05,199 --> 00:16:11,199
space and is used to retrieve analogous

415
00:16:08,240 --> 00:16:13,920
sentences in the papers in the corpus.

416
00:16:11,199 --> 00:16:15,680
Right? So um whether you've finished

417
00:16:13,920 --> 00:16:17,279
that sentence and you want to reflect on

418
00:16:15,680 --> 00:16:21,560
it or you're in the process of trying to

419
00:16:17,279 --> 00:16:24,560
write it, we can retrieve we retrieve 25

420
00:16:21,560 --> 00:16:27,279
examples of other sentences that may

421
00:16:24,560 --> 00:16:29,440
have not necessarily similar diction but

422
00:16:27,279 --> 00:16:32,720
similar um position within their

423
00:16:29,440 --> 00:16:35,040
structure and um some uh overlap in

424
00:16:32,720 --> 00:16:37,360
semantics.

425
00:16:35,040 --> 00:16:42,240
So um because let's see now we don't

426
00:16:37,360 --> 00:16:44,720
have a full uh we did not yet find a way

427
00:16:42,240 --> 00:16:46,320
to operationalize a to make a structure

428
00:16:44,720 --> 00:16:47,440
mapping engine for these sentences

429
00:16:46,320 --> 00:16:49,759
because they were a lot more diverse

430
00:16:47,440 --> 00:16:52,320
than the structure u than the uh

431
00:16:49,759 --> 00:16:54,320
document level structures. But um

432
00:16:52,320 --> 00:16:55,920
instead we kind of tried to get

433
00:16:54,320 --> 00:16:58,000
ourselves as close as possible by at

434
00:16:55,920 --> 00:17:00,320
least highlight premputing the

435
00:16:58,000 --> 00:17:02,360
overlapping tokens for example across

436
00:17:00,320 --> 00:17:04,319
these and highlighting them in

437
00:17:02,360 --> 00:17:06,000
colorcoordinated things. So, so maybe

438
00:17:04,319 --> 00:17:08,400
that that that you know the hypothesis

439
00:17:06,000 --> 00:17:10,720
with this might help you your own

440
00:17:08,400 --> 00:17:13,280
structure mapping engine see emergent

441
00:17:10,720 --> 00:17:16,079
structure. Um maybe you're in a part of

442
00:17:13,280 --> 00:17:17,679
the uh document there where the language

443
00:17:16,079 --> 00:17:19,120
is very stereotype. There's written

444
00:17:17,679 --> 00:17:21,439
expectations about what information you

445
00:17:19,120 --> 00:17:23,600
provide. there's a typical order and in

446
00:17:21,439 --> 00:17:25,600
other places maybe there's very little

447
00:17:23,600 --> 00:17:26,959
overlap across the retrieved sentences

448
00:17:25,600 --> 00:17:28,720
because that you know you're you're in a

449
00:17:26,959 --> 00:17:30,080
part of the document where it's the

450
00:17:28,720 --> 00:17:32,480
reader doesn't have strong expectations

451
00:17:30,080 --> 00:17:35,840
and you're free to do whatever you want

452
00:17:32,480 --> 00:17:37,360
um without worrying too much. So um you

453
00:17:35,840 --> 00:17:39,360
can see in the full interface on the

454
00:17:37,360 --> 00:17:41,520
left on the left hand side we have this

455
00:17:39,360 --> 00:17:43,280
ordered distribution that big picture

456
00:17:41,520 --> 00:17:45,280
view

457
00:17:43,280 --> 00:17:48,640
uh and on the right hand side we have

458
00:17:45,280 --> 00:17:50,640
the what others wrote as well as what

459
00:17:48,640 --> 00:17:52,160
others wrote next which is another 25

460
00:17:50,640 --> 00:17:53,760
sentences which were ones that they

461
00:17:52,160 --> 00:17:55,280
immediately came after the retrieved

462
00:17:53,760 --> 00:17:57,360
sentences based on where you currently

463
00:17:55,280 --> 00:17:59,120
were. So this is kind of the miniature

464
00:17:57,360 --> 00:18:01,919
version of the blank page problem,

465
00:17:59,120 --> 00:18:05,039
right? Um uh kind of in uh helping you

466
00:18:01,919 --> 00:18:06,360
see where other people went next. This

467
00:18:05,039 --> 00:18:09,760
is the

468
00:18:06,360 --> 00:18:11,600
um overarching uh kind of the the

469
00:18:09,760 --> 00:18:14,480
markdown editor in the middle that has

470
00:18:11,600 --> 00:18:18,080
this spatial retrieval um to populate

471
00:18:14,480 --> 00:18:21,039
both these lists, right? So um you know

472
00:18:18,080 --> 00:18:25,520
clicking tab um to retrieve uh both

473
00:18:21,039 --> 00:18:25,520
these columns. Okay.

474
00:18:26,039 --> 00:18:32,280
So, I would

475
00:18:28,440 --> 00:18:35,919
argue that this might be an example of a

476
00:18:32,280 --> 00:18:38,559
strategy that is providing AI assistance

477
00:18:35,919 --> 00:18:40,799
to a dialectical activity without

478
00:18:38,559 --> 00:18:42,919
fundamentally changing

479
00:18:40,799 --> 00:18:46,000
um uh the the the you know, it's it's

480
00:18:42,919 --> 00:18:49,039
it's almost orthogonal to the reflection

481
00:18:46,000 --> 00:18:51,799
that people are going through. Um, and

482
00:18:49,039 --> 00:18:54,480
so I would argue that we have not we we

483
00:18:51,799 --> 00:18:56,799
um this is a p I would argue this is a

484
00:18:54,480 --> 00:18:58,160
positive example of AI supporting

485
00:18:56,799 --> 00:18:59,919
dialectical activities without

486
00:18:58,160 --> 00:19:01,840
interfering. But I'm I'm very much open

487
00:18:59,919 --> 00:19:03,360
to uh to push back on that

488
00:19:01,840 --> 00:19:04,960
characterization because we should get

489
00:19:03,360 --> 00:19:07,520
on the same page about, you know, what

490
00:19:04,960 --> 00:19:08,600
is and isn't harming these really

491
00:19:07,520 --> 00:19:11,120
critical

492
00:19:08,600 --> 00:19:12,559
activities. Um,

493
00:19:11,120 --> 00:19:15,280
yes. Yeah. I'm a little unclear about

494
00:19:12,559 --> 00:19:17,600
what the interaction actually is. Is it

495
00:19:15,280 --> 00:19:20,480
you're you're just writing and then it's

496
00:19:17,600 --> 00:19:23,280
it's um like a a complete it tries to

497
00:19:20,480 --> 00:19:25,280
complete a phrase or tries to what's the

498
00:19:23,280 --> 00:19:27,760
interaction actually? So the interaction

499
00:19:25,280 --> 00:19:31,320
is you are writing in that center panel.

500
00:19:27,760 --> 00:19:34,400
Um here let me just go back real quick.

501
00:19:31,320 --> 00:19:37,840
Um so uh uh you're writing the center

502
00:19:34,400 --> 00:19:40,559
panel and as you uh you can be informed

503
00:19:37,840 --> 00:19:41,840
by um interacting with these clusters.

504
00:19:40,559 --> 00:19:43,840
If if you're thinking about how to

505
00:19:41,840 --> 00:19:45,520
structure it, you know, you perhaps you

506
00:19:43,840 --> 00:19:47,440
already kind of structured your paper.

507
00:19:45,520 --> 00:19:48,720
So I'll just mostly the interaction was

508
00:19:47,440 --> 00:19:51,200
mostly with the right hand side with

509
00:19:48,720 --> 00:19:53,760
sentence retrieval where as you write

510
00:19:51,200 --> 00:19:55,919
either a full or partial sentence given

511
00:19:53,760 --> 00:19:59,280
the prior context in your document

512
00:19:55,919 --> 00:20:02,000
including the um uh the the sentence or

513
00:19:59,280 --> 00:20:05,200
sentence fragment and the section title,

514
00:20:02,000 --> 00:20:07,120
it indexes into your corpus and

515
00:20:05,200 --> 00:20:09,280
retrieves sentences that have similar

516
00:20:07,120 --> 00:20:10,960
semantic meaning. Right? So like you're

517
00:20:09,280 --> 00:20:13,440
you're calling it the interaction is I'm

518
00:20:10,960 --> 00:20:16,240
I'm retrieving I'm a little stuck. I

519
00:20:13,440 --> 00:20:18,400
want to know how other people at this

520
00:20:16,240 --> 00:20:20,640
point in their paper what they wrote

521
00:20:18,400 --> 00:20:23,200
about especially what they wrote about

522
00:20:20,640 --> 00:20:26,640
relative to what I you know am writing

523
00:20:23,200 --> 00:20:29,679
about. Okay. I I I I still don't get

524
00:20:26,640 --> 00:20:32,080
that. So I'm typing along in markdown in

525
00:20:29,679 --> 00:20:34,960
that in this since this is a static

526
00:20:32,080 --> 00:20:37,039
screen. So we have you're typing a few

527
00:20:34,960 --> 00:20:38,960
participants mentioned. Yes. And then

528
00:20:37,039 --> 00:20:41,760
maybe I you do that. You see everything

529
00:20:38,960 --> 00:20:43,840
in section C here. I if I if I want to

530
00:20:41,760 --> 00:20:45,679
invoke retrieval at that time because

531
00:20:43,840 --> 00:20:47,679
retrieval is costly. I'm not constantly

532
00:20:45,679 --> 00:20:49,440
refreshing lots of sentences in your

533
00:20:47,679 --> 00:20:50,880
face. Okay. So if I if I say that's what

534
00:20:49,440 --> 00:20:52,720
I'm trying to figure out. Is it the

535
00:20:50,880 --> 00:20:55,039
display dynamic or is it just on demand

536
00:20:52,720 --> 00:20:57,280
or? It's on demand. Okay. And it's and

537
00:20:55,039 --> 00:20:59,760
how do you and you have to hit a special

538
00:20:57,280 --> 00:21:01,679
operation when you get to that mention?

539
00:20:59,760 --> 00:21:03,280
Well I Right. So, I typed a few

540
00:21:01,679 --> 00:21:05,480
participants mentioned and then I hit

541
00:21:03,280 --> 00:21:08,640
tab and that

542
00:21:05,480 --> 00:21:11,600
retrieves 50 sentences

543
00:21:08,640 --> 00:21:13,360
screen. Well, this is probably like not

544
00:21:11,600 --> 00:21:14,720
I mean it's probably the leftovers of

545
00:21:13,360 --> 00:21:17,760
what I last retrieved. I don't think

546
00:21:14,720 --> 00:21:19,760
that they we wiped that away and um um I

547
00:21:17,760 --> 00:21:21,760
believe the students um who built this

548
00:21:19,760 --> 00:21:24,559
did allow this to be collapsed, right?

549
00:21:21,760 --> 00:21:27,520
if you really don't want to see it but

550
00:21:24,559 --> 00:21:29,039
um uh primarily you know we we we had it

551
00:21:27,520 --> 00:21:31,280
visible so that people remembered that

552
00:21:29,039 --> 00:21:33,039
this novel affordance was there right

553
00:21:31,280 --> 00:21:35,600
during the inter the study so in a

554
00:21:33,039 --> 00:21:38,480
certain sense the study wasn't even like

555
00:21:35,600 --> 00:21:40,960
hey this is exactly how you should

556
00:21:38,480 --> 00:21:43,520
design this kind of AI writing assistant

557
00:21:40,960 --> 00:21:46,320
it was more like can we design enough

558
00:21:43,520 --> 00:21:48,159
cognitive support that people can

559
00:21:46,320 --> 00:21:49,760
benefit from these many retrieved

560
00:21:48,159 --> 00:21:51,520
examples to augment their thought

561
00:21:49,760 --> 00:21:54,240
process as they compose

562
00:21:51,520 --> 00:21:55,919
truly unique new writing that you know

563
00:21:54,240 --> 00:21:57,360
an AI could never generate for them

564
00:21:55,919 --> 00:21:58,440
because they're the first person to have

565
00:21:57,360 --> 00:22:01,760
that

566
00:21:58,440 --> 00:22:03,760
thought. Does that make sense? Yeah. Why

567
00:22:01,760 --> 00:22:05,200
don't you just go? Okay. All right. But

568
00:22:03,760 --> 00:22:07,919
you know if you have the question other

569
00:22:05,200 --> 00:22:10,400
people do too. So yes, I have another

570
00:22:07,919 --> 00:22:14,320
question. So you had mentioned that you

571
00:22:10,400 --> 00:22:15,919
um you you know one of the reasons why

572
00:22:14,320 --> 00:22:17,600
people were given these single responses

573
00:22:15,919 --> 00:22:19,520
was because it was overwhelming to get

574
00:22:17,600 --> 00:22:21,440
like a lot of different responses. Well,

575
00:22:19,520 --> 00:22:25,120
it could be if there was no cognitive

576
00:22:21,440 --> 00:22:27,200
support. Okay. But but you did find that

577
00:22:25,120 --> 00:22:28,799
this was not overwhelming in the sense

578
00:22:27,200 --> 00:22:31,440
that like as opposed to saying something

579
00:22:28,799 --> 00:22:33,919
more iterative like was it a conscious

580
00:22:31,440 --> 00:22:36,640
decision to have I guess the right panel

581
00:22:33,919 --> 00:22:38,720
with Yeah. Yes. Right. So in a sense the

582
00:22:36,640 --> 00:22:41,280
the the implicit design challenge that

583
00:22:38,720 --> 00:22:43,840
we gave ourselves was um we know that

584
00:22:41,280 --> 00:22:45,840
many examples can prevent you from

585
00:22:43,840 --> 00:22:47,679
overfitting on a particular couple,

586
00:22:45,840 --> 00:22:49,280
right? It can prevent you from anchoring

587
00:22:47,679 --> 00:22:51,520
and implic, you know, accidentally kind

588
00:22:49,280 --> 00:22:53,360
of plagiarizing. Um, it can give you a

589
00:22:51,520 --> 00:22:55,120
better sense of the expectations of your

590
00:22:53,360 --> 00:22:57,679
readers. There's all these positive

591
00:22:55,120 --> 00:22:59,679
things that come out if I can get these,

592
00:22:57,679 --> 00:23:02,400
you know, if I can help you consume more

593
00:22:59,679 --> 00:23:03,760
than a handful of examples. So, if I can

594
00:23:02,400 --> 00:23:05,840
retrieve them and that they are

595
00:23:03,760 --> 00:23:08,640
semantically tight enough that they are

596
00:23:05,840 --> 00:23:10,320
more likely than not, but not always,

597
00:23:08,640 --> 00:23:12,000
right? Unreliable AI is part of the

598
00:23:10,320 --> 00:23:13,840
title related to what you're you're

599
00:23:12,000 --> 00:23:15,840
typing out. And if I can post-process

600
00:23:13,840 --> 00:23:18,000
them in some way that helps you see and

601
00:23:15,840 --> 00:23:19,679
I realize, you know, here these are not

602
00:23:18,000 --> 00:23:21,120
necessarily showing kind of any emergent

603
00:23:19,679 --> 00:23:22,880
structure, right? So there's like a lot

604
00:23:21,120 --> 00:23:24,159
more variation here. So, you know, in a

605
00:23:22,880 --> 00:23:25,679
certain sense, it's like, well, these

606
00:23:24,159 --> 00:23:27,120
are one-off examples that, you know,

607
00:23:25,679 --> 00:23:28,320
might give you some ideas about what you

608
00:23:27,120 --> 00:23:29,919
want to include in your sentence, but

609
00:23:28,320 --> 00:23:31,520
there isn't some sort of overarching

610
00:23:29,919 --> 00:23:33,520
expectation that the reader has given

611
00:23:31,520 --> 00:23:35,440
this particular prompt. But where there

612
00:23:33,520 --> 00:23:36,880
are kind of expectations in stylized

613
00:23:35,440 --> 00:23:38,559
writing, right? the same way that

614
00:23:36,880 --> 00:23:39,760
there's very particular ways in which pe

615
00:23:38,559 --> 00:23:41,760
papers are structured in a given

616
00:23:39,760 --> 00:23:45,200
community you you might you know that

617
00:23:41,760 --> 00:23:46,720
will um if requested be revealed. So

618
00:23:45,200 --> 00:23:48,320
it's like can we provide people the

619
00:23:46,720 --> 00:23:51,039
cognitive support? Can we shortcut

620
00:23:48,320 --> 00:23:53,120
enough of the cognition

621
00:23:51,039 --> 00:23:57,280
um that they can benefit from the the

622
00:23:53,120 --> 00:23:59,919
schema that emerges? Yes. Did you um did

623
00:23:57,280 --> 00:24:03,679
you compare this against um people who

624
00:23:59,919 --> 00:24:06,000
would use LLM's like Q&A to be like oh

625
00:24:03,679 --> 00:24:07,440
what do the papers say about like so

626
00:24:06,000 --> 00:24:10,400
like that says a few participants

627
00:24:07,440 --> 00:24:13,279
mentioned but what does the what do the

628
00:24:10,400 --> 00:24:16,000
research papers say about um like how

629
00:24:13,279 --> 00:24:18,640
participants would like use this thing

630
00:24:16,000 --> 00:24:22,520
we yes yes I mean that would be a a very

631
00:24:18,640 --> 00:24:25,039
interesting you know contrast

632
00:24:22,520 --> 00:24:26,480
um for these kinds of dialectical

633
00:24:25,039 --> 00:24:28,159
activities ities that require deep

634
00:24:26,480 --> 00:24:29,919
engagement over a non-trivial amount of

635
00:24:28,159 --> 00:24:31,440
time about something they cared about.

636
00:24:29,919 --> 00:24:33,120
Like in this user study that we did,

637
00:24:31,440 --> 00:24:34,559
people brought their own manuscripts.

638
00:24:33,120 --> 00:24:37,360
They continued trying to write their own

639
00:24:34,559 --> 00:24:39,600
manuscripts in this interface. You lose

640
00:24:37,360 --> 00:24:41,360
the ability, I shouldn't say lose,

641
00:24:39,600 --> 00:24:44,320
within an amount of time that people are

642
00:24:41,360 --> 00:24:47,360
willing to spend with you and and um uh

643
00:24:44,320 --> 00:24:50,400
it's harder to kind of swap in different

644
00:24:47,360 --> 00:24:53,520
conditions. And so this paper and papers

645
00:24:50,400 --> 00:24:56,159
since we've stopped kind of including

646
00:24:53,520 --> 00:24:59,279
strict baselines or strict um

647
00:24:56,159 --> 00:25:01,600
alternatives and a certain because um um

648
00:24:59,279 --> 00:25:04,000
while informative the first point the

649
00:25:01,600 --> 00:25:06,240
first question is is this even can cog

650
00:25:04,000 --> 00:25:08,159
people cognitively benefit from this if

651
00:25:06,240 --> 00:25:09,600
yes we move on to that next. So like

652
00:25:08,159 --> 00:25:12,559
this this would be that would be a great

653
00:25:09,600 --> 00:25:15,520
follow-up experiment. Um uh now I will

654
00:25:12,559 --> 00:25:16,720
point out okay I already know one thing

655
00:25:15,520 --> 00:25:20,000
that's going to be a failure mode

656
00:25:16,720 --> 00:25:21,760
potentially. Okay, for having a say a

657
00:25:20,000 --> 00:25:23,520
chat, you know what what other things do

658
00:25:21,760 --> 00:25:26,600
people include when describing an

659
00:25:23,520 --> 00:25:29,360
experimental setup, right? Um, say the

660
00:25:26,600 --> 00:25:31,440
LM hallucinates an extra step, right?

661
00:25:29,360 --> 00:25:32,799
That that step is really common in that

662
00:25:31,440 --> 00:25:34,320
community over there, but I'm not part

663
00:25:32,799 --> 00:25:35,679
of that community, but it's, you know,

664
00:25:34,320 --> 00:25:38,000
got so much training data from over

665
00:25:35,679 --> 00:25:39,279
there, it kind of leaked in, right? Um

666
00:25:38,000 --> 00:25:42,559
because everything else was kind of

667
00:25:39,279 --> 00:25:45,840
similar. And um what if it left out

668
00:25:42,559 --> 00:25:48,000
something that is really uncommon, but

669
00:25:45,840 --> 00:25:49,640
if you saw it, you'd be like, "Oh yeah,

670
00:25:48,000 --> 00:25:53,840
I should be including that too, right?"

671
00:25:49,640 --> 00:25:56,320
Like good practice is often initially an

672
00:25:53,840 --> 00:25:57,919
aberration from the the typical and and

673
00:25:56,320 --> 00:26:00,320
people recognize it as good and it

674
00:25:57,919 --> 00:26:02,640
becomes more and more common, right? So

675
00:26:00,320 --> 00:26:04,559
um if I'm only relying on a chatbot to

676
00:26:02,640 --> 00:26:07,440
summarize these things, I cannot be

677
00:26:04,559 --> 00:26:09,919
resilient to both kind of imputation of

678
00:26:07,440 --> 00:26:11,640
things from adjacent communities or the

679
00:26:09,919 --> 00:26:14,799
missing out of things that are rare but

680
00:26:11,640 --> 00:26:17,520
good. So by scaling up the number of

681
00:26:14,799 --> 00:26:20,000
retrievalss, my hope and also trying to

682
00:26:17,520 --> 00:26:22,159
help people um see any emerging schema,

683
00:26:20,000 --> 00:26:23,919
my hope is that they can notice the

684
00:26:22,159 --> 00:26:26,159
common and uncommon things. If the

685
00:26:23,919 --> 00:26:28,240
uncommon thing is bad, fine, you can

686
00:26:26,159 --> 00:26:29,919
know that it's bad. if it's good, you

687
00:26:28,240 --> 00:26:31,600
have the opportunity to replicate that

688
00:26:29,919 --> 00:26:34,320
good choice, that uncommon good choice

689
00:26:31,600 --> 00:26:37,120
in your own work. And I would argue that

690
00:26:34,320 --> 00:26:39,240
you cannot if you're relying on a chat

691
00:26:37,120 --> 00:26:42,320
with an AI to answer the same

692
00:26:39,240 --> 00:26:45,279
question. So I would I would to to kind

693
00:26:42,320 --> 00:26:48,960
of kill my own, you know, I would call

694
00:26:45,279 --> 00:26:50,640
this an AI more AI resilient interface,

695
00:26:48,960 --> 00:26:52,840
right? I'm more resilient to the choices

696
00:26:50,640 --> 00:26:56,159
that the AI makes on my

697
00:26:52,840 --> 00:26:58,000
behalf. Thanks.

698
00:26:56,159 --> 00:27:00,880
Okay, I'm gonna keep moving unless

699
00:26:58,000 --> 00:27:03,520
another but yes, I um very much

700
00:27:00,880 --> 00:27:05,720
appreciate these questions. Okay, so um

701
00:27:03,520 --> 00:27:07,600
yeah, these were um we had 16

702
00:27:05,720 --> 00:27:09,760
participants. They drafted their

703
00:27:07,600 --> 00:27:12,559
structure, then they drafted pros. Um

704
00:27:09,760 --> 00:27:14,600
took up to 75 minutes. We gave them $25.

705
00:27:12,559 --> 00:27:16,960
They were working on their Kai paper

706
00:27:14,600 --> 00:27:18,559
anyway. I at least one was working on a

707
00:27:16,960 --> 00:27:20,799
Europe's paper. I don't know how they

708
00:27:18,559 --> 00:27:23,600
got in.

709
00:27:20,799 --> 00:27:25,360
All right. So, um what we found was that

710
00:27:23,600 --> 00:27:28,400
um the section title frequency was used

711
00:27:25,360 --> 00:27:29,919
to gauge norms. So, that worked. Um some

712
00:27:28,400 --> 00:27:32,000
adapted section titles from the

713
00:27:29,919 --> 00:27:33,760
distribution while others um just kind

714
00:27:32,000 --> 00:27:35,279
of like took the existing titles that

715
00:27:33,760 --> 00:27:37,520
they already had in a draft and kind of

716
00:27:35,279 --> 00:27:38,799
maybe modified them knowing now what

717
00:27:37,520 --> 00:27:41,360
maybe expectations were of their

718
00:27:38,799 --> 00:27:43,200
readers. People noticed variation within

719
00:27:41,360 --> 00:27:44,559
section title clusters. So, this notion

720
00:27:43,200 --> 00:27:46,720
of kind of trying to reveal what was

721
00:27:44,559 --> 00:27:49,520
consistent or possibly varying within a

722
00:27:46,720 --> 00:27:51,440
cluster seemed to work. Um people found

723
00:27:49,520 --> 00:27:53,120
it help helpful to see uncommon titles.

724
00:27:51,440 --> 00:27:54,640
So this person said the section titles

725
00:27:53,120 --> 00:27:56,080
are more diverse than I thought. There's

726
00:27:54,640 --> 00:27:58,080
things like you know expert interviews

727
00:27:56,080 --> 00:27:59,520
which I've never done. These are um

728
00:27:58,080 --> 00:28:00,880
there were a few others that I found

729
00:27:59,520 --> 00:28:03,279
which were pretty new to me. Definitely

730
00:28:00,880 --> 00:28:05,679
broaders my sort of horizon. Right? So

731
00:28:03,279 --> 00:28:07,520
this is the value of the longtail and if

732
00:28:05,679 --> 00:28:10,399
you can make that long tail cognitively

733
00:28:07,520 --> 00:28:12,480
accessible by precomputing what's common

734
00:28:10,399 --> 00:28:15,120
and letting that kind of those those

735
00:28:12,480 --> 00:28:16,960
differences uh surface. Um some also

736
00:28:15,120 --> 00:28:19,200
opted to deviate from implied norms. So

737
00:28:16,960 --> 00:28:23,600
people didn't feel like they were stuck

738
00:28:19,200 --> 00:28:26,080
um uh to um what was most common on the

739
00:28:23,600 --> 00:28:28,640
sentence level side. People alternate

740
00:28:26,080 --> 00:28:30,960
between iterating pros and engaging with

741
00:28:28,640 --> 00:28:32,480
retrievals. So to your point about you

742
00:28:30,960 --> 00:28:33,919
know we kind of thought well you'd be

743
00:28:32,480 --> 00:28:36,240
writing along and then you're like a

744
00:28:33,919 --> 00:28:38,159
little help tab right and look at the

745
00:28:36,240 --> 00:28:40,000
the stuff but they were actually kind of

746
00:28:38,159 --> 00:28:41,440
because this is an implicit query

747
00:28:40,000 --> 00:28:43,559
whatever you were writing you know the

748
00:28:41,440 --> 00:28:46,240
sentence that you were you were writing

749
00:28:43,559 --> 00:28:47,760
um people would edit the sentence

750
00:28:46,240 --> 00:28:48,960
because they were refining their edit I

751
00:28:47,760 --> 00:28:51,279
mean they're in the process of of

752
00:28:48,960 --> 00:28:52,799
composing but sometimes that that that

753
00:28:51,279 --> 00:28:54,960
editing sometimes seemed to be more

754
00:28:52,799 --> 00:28:56,640
about modifying the retrievalss the

755
00:28:54,960 --> 00:28:58,640
retrieved sentences than it was about

756
00:28:56,640 --> 00:29:00,399
like what the final compos composed

757
00:28:58,640 --> 00:29:01,919
sentence would be. So, they're kind of

758
00:29:00,399 --> 00:29:04,080
blending the two of composition and

759
00:29:01,919 --> 00:29:07,120
querying, but anyway, um it's not

760
00:29:04,080 --> 00:29:10,480
necessarily a bad thing. Uh um they used

761
00:29:07,120 --> 00:29:12,240
retrieved sentences to uh get community

762
00:29:10,480 --> 00:29:14,880
specific terminology, phrasing,

763
00:29:12,240 --> 00:29:18,080
structure, and ideas. They discovered

764
00:29:14,880 --> 00:29:20,080
relevant uh literature for citations. Um

765
00:29:18,080 --> 00:29:22,080
so, it was true that you could save

766
00:29:20,080 --> 00:29:23,520
individual sentences, you know, look at

767
00:29:22,080 --> 00:29:25,760
the kind of local context of that

768
00:29:23,520 --> 00:29:27,440
sentence and what paper occurred in. So

769
00:29:25,760 --> 00:29:28,960
people sometimes when they noticed uh a

770
00:29:27,440 --> 00:29:31,679
sentence that they um piqu their

771
00:29:28,960 --> 00:29:33,039
interest they could uh at a later time a

772
00:29:31,679 --> 00:29:35,600
bookmark for a later time to engage with

773
00:29:33,039 --> 00:29:37,919
that the paper it came from. In terms of

774
00:29:35,600 --> 00:29:39,360
confidence and perception um one

775
00:29:37,919 --> 00:29:40,720
participant said it's great to read what

776
00:29:39,360 --> 00:29:42,799
others wrote because we perform a

777
00:29:40,720 --> 00:29:44,559
similar process but we did not mention

778
00:29:42,799 --> 00:29:45,840
that um in our own writing. So it' be

779
00:29:44,559 --> 00:29:47,919
great if we could add those. So this

780
00:29:45,840 --> 00:29:50,000
notion of of you know maybe this was in

781
00:29:47,919 --> 00:29:51,840
a paper that was in a completely

782
00:29:50,000 --> 00:29:53,679
different superficially different field

783
00:29:51,840 --> 00:29:56,720
but there was some some process some

784
00:29:53,679 --> 00:29:58,799
similarity some analogical sentence that

785
00:29:56,720 --> 00:30:00,799
you would um never have found if you

786
00:29:58,799 --> 00:30:03,039
were searching in a traditional way that

787
00:30:00,799 --> 00:30:05,840
um uh revealed the relationship they

788
00:30:03,039 --> 00:30:07,279
could follow up on. So exposure to

789
00:30:05,840 --> 00:30:09,760
similar work boosted their confidence in

790
00:30:07,279 --> 00:30:11,600
how they were writing. Um but also if

791
00:30:09,760 --> 00:30:12,960
they didn't see a lot of other sentences

792
00:30:11,600 --> 00:30:14,880
like the one they were writing, it

793
00:30:12,960 --> 00:30:16,880
boosted their sense of novelty. Though

794
00:30:14,880 --> 00:30:19,200
you know obviously this was all from one

795
00:30:16,880 --> 00:30:20,640
corpus. So if it's not in the corpus

796
00:30:19,200 --> 00:30:22,320
that doesn't mean it doesn't exist,

797
00:30:20,640 --> 00:30:24,320
right? So you have to be a little

798
00:30:22,320 --> 00:30:27,080
careful about misperceptions we could

799
00:30:24,320 --> 00:30:29,760
give them. And in the sentence rendering

800
00:30:27,080 --> 00:30:31,279
um people did initially find this

801
00:30:29,760 --> 00:30:33,520
overwhelming. And I will just point out

802
00:30:31,279 --> 00:30:35,039
these the these strategies of like

803
00:30:33,520 --> 00:30:38,240
graying out repeated words across

804
00:30:35,039 --> 00:30:39,600
sentences and such. Um it's not based on

805
00:30:38,240 --> 00:30:42,320
a structure mapping engine. We are just

806
00:30:39,600 --> 00:30:44,240
kind of showing s superficial

807
00:30:42,320 --> 00:30:45,840
similarities. And for that reason I

808
00:30:44,240 --> 00:30:48,080
think we both highlighted possible

809
00:30:45,840 --> 00:30:50,159
analogical relationships across them and

810
00:30:48,080 --> 00:30:52,000
and correspondences that had nothing to

811
00:30:50,159 --> 00:30:54,000
do with analogical relationships. And so

812
00:30:52,000 --> 00:30:55,760
it was almost like we were jamming the

813
00:30:54,000 --> 00:30:58,960
same channel with good and bad

814
00:30:55,760 --> 00:31:00,880
information. So I based on that I think

815
00:30:58,960 --> 00:31:02,799
um uh developing structure mapping

816
00:31:00,880 --> 00:31:04,399
engines for new contexts if you want to

817
00:31:02,799 --> 00:31:06,559
employ this is really important you

818
00:31:04,399 --> 00:31:08,840
can't skip it.

819
00:31:06,559 --> 00:31:13,200
Um

820
00:31:08,840 --> 00:31:15,520
so we when they were drafting the

821
00:31:13,200 --> 00:31:17,520
structure they had we did do a little

822
00:31:15,520 --> 00:31:18,960
kind of controlled uh you know baseline

823
00:31:17,520 --> 00:31:20,880
experience where they were either

824
00:31:18,960 --> 00:31:23,760
drafting in like Google Docs with no

825
00:31:20,880 --> 00:31:26,000
assistance or with a view of that right

826
00:31:23,760 --> 00:31:28,399
that uh left-hand side um just because

827
00:31:26,000 --> 00:31:30,720
we felt like you know didn't take that

828
00:31:28,399 --> 00:31:32,480
long and and we felt obligated to have a

829
00:31:30,720 --> 00:31:33,840
baseline because so much work you know

830
00:31:32,480 --> 00:31:34,799
it's kind of hard to say how good

831
00:31:33,840 --> 00:31:37,519
something is if you don't have something

832
00:31:34,799 --> 00:31:40,399
to compare it to and you Sure enough,

833
00:31:37,519 --> 00:31:42,960
people liked drafting their structure in

834
00:31:40,399 --> 00:31:45,120
uh corpus studio better than in the

835
00:31:42,960 --> 00:31:46,799
baseline. Okay, not surprising. But what

836
00:31:45,120 --> 00:31:48,159
more interesting is what um the

837
00:31:46,799 --> 00:31:50,480
questions we tried to ask and answer

838
00:31:48,159 --> 00:31:52,640
without that baseline when they're

839
00:31:50,480 --> 00:31:53,760
drafting pros. Right? So the the two two

840
00:31:52,640 --> 00:31:56,000
questions that I want to highlight here

841
00:31:53,760 --> 00:31:57,679
is um how much they agreed with the

842
00:31:56,000 --> 00:31:59,039
statement. I have a clearer sense of

843
00:31:57,679 --> 00:32:00,480
when it might be appropriate to break

844
00:31:59,039 --> 00:32:02,919
the writing expectations of the target

845
00:32:00,480 --> 00:32:07,679
venue for sentences that I write.

846
00:32:02,919 --> 00:32:09,760
Um this is like um uh not quite as as

847
00:32:07,679 --> 00:32:11,440
positive. Um well, okay, sorry. So

848
00:32:09,760 --> 00:32:13,600
here's the zero, right? So there's more

849
00:32:11,440 --> 00:32:15,600
positive than negative. Um more

850
00:32:13,600 --> 00:32:17,360
agreement with um the statement that

851
00:32:15,600 --> 00:32:21,360
evaluating many sentences from other

852
00:32:17,360 --> 00:32:22,960
previous papers at once. Um sorry uh

853
00:32:21,360 --> 00:32:24,320
gave me a better understanding of the

854
00:32:22,960 --> 00:32:25,519
typical writing expectations of the

855
00:32:24,320 --> 00:32:27,200
target venue.

856
00:32:25,519 --> 00:32:29,200
you know, these these goals that we had

857
00:32:27,200 --> 00:32:31,440
for our users, we at least even without

858
00:32:29,200 --> 00:32:34,399
a baseline can can show we have some

859
00:32:31,440 --> 00:32:36,840
evidence that we achieved those goals um

860
00:32:34,399 --> 00:32:41,120
even if certain aspects of it were

861
00:32:36,840 --> 00:32:43,200
overwhelming. Um okay, so

862
00:32:41,120 --> 00:32:46,080
um again using this language of

863
00:32:43,200 --> 00:32:48,000
resilience to AI, right, or um you know

864
00:32:46,080 --> 00:32:50,000
kind of reliable outcomes despite

865
00:32:48,000 --> 00:32:51,519
unreliable AI, right? Right, we're

866
00:32:50,000 --> 00:32:54,000
arguing here that this alternative

867
00:32:51,519 --> 00:32:56,159
approach of retrieving many examples and

868
00:32:54,000 --> 00:32:57,760
render, you know, uh computationally uh

869
00:32:56,159 --> 00:32:59,840
analyzing them and rendering them with

870
00:32:57,760 --> 00:33:02,399
respect to how you see cross example

871
00:32:59,840 --> 00:33:04,960
relationships makes users more resilient

872
00:33:02,399 --> 00:33:06,880
to the AI's possibility of plagiarizing

873
00:33:04,960 --> 00:33:10,000
if they were if if it was um generating

874
00:33:06,880 --> 00:33:12,080
text, their own plagiarism risks, and um

875
00:33:10,000 --> 00:33:15,279
whatever quality of retrieval that they

876
00:33:12,080 --> 00:33:17,720
have, right? Just less sensitive to it.

877
00:33:15,279 --> 00:33:20,200
Um which I think is a good thing.

878
00:33:17,720 --> 00:33:24,399
Um so

879
00:33:20,200 --> 00:33:27,279
um all right so that is um uh this work

880
00:33:24,399 --> 00:33:28,880
this was a collaboration with um my

881
00:33:27,279 --> 00:33:31,679
colleague Daniel Bushek and his student

882
00:33:28,880 --> 00:33:34,000
high Chelsea and Hi uh were co-first

883
00:33:31,679 --> 00:33:35,519
authors on this um but yeah if we had to

884
00:33:34,000 --> 00:33:37,440
rename it um you know through the lens

885
00:33:35,519 --> 00:33:41,679
of dialectical activity and the the

886
00:33:37,440 --> 00:33:43,039
notion of um supporting cognition and um

887
00:33:41,679 --> 00:33:45,120
uh making people more resilient you

888
00:33:43,039 --> 00:33:47,039
could have just as easily re um retitled

889
00:33:45,120 --> 00:33:48,799
this paper corpus supporting the

890
00:33:47,039 --> 00:33:51,720
dialectical activity of writing with AI

891
00:33:48,799 --> 00:33:54,399
retrieval of unknown and variable

892
00:33:51,720 --> 00:33:55,760
reliability. Okay. So the second paper I

893
00:33:54,399 --> 00:33:58,080
want to talk about little in a little

894
00:33:55,760 --> 00:34:00,799
bit less depth is also going to be

895
00:33:58,080 --> 00:34:02,799
presented next week at KAI and it's um a

896
00:34:00,799 --> 00:34:06,240
collaboration um equal collaboration

897
00:34:02,799 --> 00:34:08,079
with Toby Lee at Notre Dame. It's led um

898
00:34:06,240 --> 00:34:10,879
by his wonderful student Simrat who's

899
00:34:08,079 --> 00:34:12,879
really taken this uh my proposal of

900
00:34:10,879 --> 00:34:17,119
thinking about these theories of uh

901
00:34:12,879 --> 00:34:18,720
human um concept learning like uh the

902
00:34:17,119 --> 00:34:21,599
emergent structure that we see in

903
00:34:18,720 --> 00:34:23,359
examples and using that to think about

904
00:34:21,599 --> 00:34:24,720
uh machine teaching right so I have a

905
00:34:23,359 --> 00:34:27,599
notion in my head how do I communicate

906
00:34:24,720 --> 00:34:31,119
that to the computer so it can more

907
00:34:27,599 --> 00:34:32,960
reliably carry out my desires say um uh

908
00:34:31,119 --> 00:34:35,359
when doing qualitative coding on some

909
00:34:32,960 --> 00:34:38,159
data or

910
00:34:35,359 --> 00:34:39,280
annotating additional data. So I'll just

911
00:34:38,159 --> 00:34:41,200
point out we're very thrilled it was

912
00:34:39,280 --> 00:34:43,679
awarded with a best paper award though

913
00:34:41,200 --> 00:34:46,800
these things are um half random and we

914
00:34:43,679 --> 00:34:48,159
call it mocha um just for short um the

915
00:34:46,800 --> 00:34:51,760
name of the system that instantiates

916
00:34:48,159 --> 00:34:53,440
this. So okay so variation theory is the

917
00:34:51,760 --> 00:34:55,679
one theory we haven't talked about yet

918
00:34:53,440 --> 00:34:56,920
um it's really clear here or necessary

919
00:34:55,679 --> 00:34:59,200
to

920
00:34:56,920 --> 00:35:00,960
discuss basically variation theory is

921
00:34:59,200 --> 00:35:03,760
about the experience of difference and

922
00:35:00,960 --> 00:35:06,160
how that affects your conceptualization

923
00:35:03,760 --> 00:35:08,720
of the what you are trying to describe

924
00:35:06,160 --> 00:35:10,640
for yourself or someone else or

925
00:35:08,720 --> 00:35:13,119
something else right so if I'm

926
00:35:10,640 --> 00:35:16,960
interested in uh uh characterizing a

927
00:35:13,119 --> 00:35:18,960
banana um there's critical dimensions

928
00:35:16,960 --> 00:35:21,200
where you can see difference here these

929
00:35:18,960 --> 00:35:23,280
other along shape right if I'm too far

930
00:35:21,200 --> 00:35:26,160
away from the banana shape I I cease to

931
00:35:23,280 --> 00:35:28,320
be a banana um whereas color is not uh

932
00:35:26,160 --> 00:35:30,400
it's a superficial aspect right you can

933
00:35:28,320 --> 00:35:33,760
have red bananas green bananas right um

934
00:35:30,400 --> 00:35:36,079
and we want um of course there's many

935
00:35:33,760 --> 00:35:39,119
dimensions of variation that can be

936
00:35:36,079 --> 00:35:42,720
either critical or superficial and um

937
00:35:39,119 --> 00:35:46,160
both types are important for a model to

938
00:35:42,720 --> 00:35:48,800
understand which are which so um you

939
00:35:46,160 --> 00:35:52,680
know if I had only had access to uh this

940
00:35:48,800 --> 00:35:56,320
apple um is it some some sort of greens

941
00:35:52,680 --> 00:35:58,560
and watermelon then um I would not have

942
00:35:56,320 --> 00:36:00,800
been able if if I did not carefully

943
00:35:58,560 --> 00:36:02,640
construct these counter examples I still

944
00:36:00,800 --> 00:36:04,079
wouldn't actually have that much or have

945
00:36:02,640 --> 00:36:06,400
communicated that much about what makes

946
00:36:04,079 --> 00:36:11,599
a banana a banana because these vary in

947
00:36:06,400 --> 00:36:13,599
both color and shape right um so so um

948
00:36:11,599 --> 00:36:17,200
providing

949
00:36:13,599 --> 00:36:19,440
um providing examples that leave all

950
00:36:17,200 --> 00:36:21,200
dimen dimensions fixed but one is one

951
00:36:19,440 --> 00:36:22,839
way to kind of communicate to someone or

952
00:36:21,200 --> 00:36:25,359
something what's critical and what's

953
00:36:22,839 --> 00:36:27,079
superficial. Right? So um the question

954
00:36:25,359 --> 00:36:29,119
we asked was how we could generate

955
00:36:27,079 --> 00:36:32,560
counterfactuals say to augment an

956
00:36:29,119 --> 00:36:36,160
existing data set um that variation

957
00:36:32,560 --> 00:36:38,320
theory would predict are helpful.

958
00:36:36,160 --> 00:36:41,359
So um rather than you know revealing

959
00:36:38,320 --> 00:36:42,400
variation that exists in a corpus that

960
00:36:41,359 --> 00:36:44,320
you're kind of you're stuck with

961
00:36:42,400 --> 00:36:46,760
whatever variation exists can we

962
00:36:44,320 --> 00:36:52,040
strategically generate it um to to help

963
00:36:46,760 --> 00:36:57,440
clarify the concept of banana or um so

964
00:36:52,040 --> 00:36:59,440
um yeah um I will point out that um

965
00:36:57,440 --> 00:37:01,359
variation theory only predicts that

966
00:36:59,440 --> 00:37:02,400
these are helpful for human learners.

967
00:37:01,359 --> 00:37:05,520
That's where it comes from. It comes

968
00:37:02,400 --> 00:37:07,760
from learning sciences. Um but uh uh

969
00:37:05,520 --> 00:37:09,040
Simret led um a beautiful paper that's

970
00:37:07,760 --> 00:37:10,320
currently on archive and I believe in

971
00:37:09,040 --> 00:37:13,920
the is in the process of being accepted

972
00:37:10,320 --> 00:37:15,680
at NLP conference um about uh the fact

973
00:37:13,920 --> 00:37:17,760
that you know this variation theory

974
00:37:15,680 --> 00:37:19,440
while evaluated in the context of human

975
00:37:17,760 --> 00:37:21,359
learning is really just describing kind

976
00:37:19,440 --> 00:37:23,599
of an information theory kind of basic

977
00:37:21,359 --> 00:37:26,560
fact right so um we do have evidence

978
00:37:23,599 --> 00:37:29,119
that machine learn you know uh short

979
00:37:26,560 --> 00:37:32,320
fueshot learning of machines is also

980
00:37:29,119 --> 00:37:34,440
benefited from kind of listening to the

981
00:37:32,320 --> 00:37:37,760
design implications of var variation

982
00:37:34,440 --> 00:37:38,960
theory. So um we want the model to know

983
00:37:37,760 --> 00:37:40,400
that these superficial dimensions of

984
00:37:38,960 --> 00:37:42,240
variation are relevant. We want the

985
00:37:40,400 --> 00:37:44,240
model to know where the boundaries of

986
00:37:42,240 --> 00:37:46,640
the concept are along critical

987
00:37:44,240 --> 00:37:49,200
dimensions of variation. That's the

988
00:37:46,640 --> 00:37:53,680
purpose of these counter examples. This

989
00:37:49,200 --> 00:37:57,200
is a lot harder to do um for humans if

990
00:37:53,680 --> 00:37:59,520
it's not fruit but text because text

991
00:37:57,200 --> 00:38:02,720
unlike fruit you know it you have to

992
00:37:59,520 --> 00:38:04,800
it's linearly parsed. We have a large

993
00:38:02,720 --> 00:38:07,440
site vocabulary, right, which allows us

994
00:38:04,800 --> 00:38:10,640
to read things fairly quickly, but we

995
00:38:07,440 --> 00:38:12,800
still um uh you know, without kind of

996
00:38:10,640 --> 00:38:14,240
premputation of relationships across

997
00:38:12,800 --> 00:38:15,920
redundant sentences, you're really just

998
00:38:14,240 --> 00:38:17,359
stuck reading them and mentally

999
00:38:15,920 --> 00:38:20,160
remembering the differences between

1000
00:38:17,359 --> 00:38:22,079
them. So um you know and and also I

1001
00:38:20,160 --> 00:38:23,760
guess the um the dimensions of variation

1002
00:38:22,079 --> 00:38:26,640
that are critical and superficial for a

1003
00:38:23,760 --> 00:38:29,359
certain concept like a comment on a Yelp

1004
00:38:26,640 --> 00:38:32,960
review about ambiance is a lot harder to

1005
00:38:29,359 --> 00:38:34,960
even um give a name to except by

1006
00:38:32,960 --> 00:38:38,560
defining of you know in terms of like

1007
00:38:34,960 --> 00:38:39,920
positive and negative examples. Um and

1008
00:38:38,560 --> 00:38:41,520
there's no ground truth for ambiance

1009
00:38:39,920 --> 00:38:43,040
either. It's like that's that's a

1010
00:38:41,520 --> 00:38:45,440
concept that you may be refining in your

1011
00:38:43,040 --> 00:38:47,520
own head as you review examples whether

1012
00:38:45,440 --> 00:38:49,640
they are naturally in the data set or

1013
00:38:47,520 --> 00:38:54,000
counterfactual um

1014
00:38:49,640 --> 00:38:57,680
generations. Okay. So, Mocha combines

1015
00:38:54,000 --> 00:38:59,040
variation theory um and structural

1016
00:38:57,680 --> 00:39:01,359
mapping theory in a really interesting

1017
00:38:59,040 --> 00:39:04,640
way. So, because we can generate we

1018
00:39:01,359 --> 00:39:07,440
strategically generate examples that um

1019
00:39:04,640 --> 00:39:10,240
basically are variations of an original

1020
00:39:07,440 --> 00:39:12,960
in uh in corpus example. So this says

1021
00:39:10,240 --> 00:39:15,280
breakfast was delicious, right? Um and

1022
00:39:12,960 --> 00:39:17,440
we have a model predicted um and

1023
00:39:15,280 --> 00:39:19,520
probably user confirmed label that this

1024
00:39:17,440 --> 00:39:22,320
is uh about kind of the products that

1025
00:39:19,520 --> 00:39:25,119
are sold by this restaurant um that the

1026
00:39:22,320 --> 00:39:28,160
Yelp review is from. And um we have an

1027
00:39:25,119 --> 00:39:30,079
initial guess from whatever earlier um

1028
00:39:28,160 --> 00:39:33,720
annotations were provided of this

1029
00:39:30,079 --> 00:39:36,640
neurosyolic pattern um that basically

1030
00:39:33,720 --> 00:39:38,160
um uh the neurosymbolic pattern is

1031
00:39:36,640 --> 00:39:41,200
pretty basic right now. It's just like

1032
00:39:38,160 --> 00:39:43,839
um it is uh you you've fulfilled the

1033
00:39:41,200 --> 00:39:45,760
pattern that predicts product if there

1034
00:39:43,839 --> 00:39:47,440
are uh there is a word that matches a

1035
00:39:45,760 --> 00:39:49,920
synonym of delicious or a synonym of

1036
00:39:47,440 --> 00:39:52,800
good. Right? So this is basically a um

1037
00:39:49,920 --> 00:39:55,320
it's a superficial aspect of the data

1038
00:39:52,800 --> 00:40:00,480
that is also quite possibly

1039
00:39:55,320 --> 00:40:03,920
overfit. So, um, Mocha then generates um

1040
00:40:00,480 --> 00:40:06,400
a bunch of variations that are still

1041
00:40:03,920 --> 00:40:08,960
alignable by construction with the top

1042
00:40:06,400 --> 00:40:12,320
one, right? They they they share in this

1043
00:40:08,960 --> 00:40:14,839
case all breakfast and they all share um

1044
00:40:12,320 --> 00:40:17,119
the fact that they fit they match this

1045
00:40:14,839 --> 00:40:19,760
pattern, but they've been tweaked in the

1046
00:40:17,119 --> 00:40:22,320
smallest possible way to have a

1047
00:40:19,760 --> 00:40:24,560
different predicted um category, right?

1048
00:40:22,320 --> 00:40:26,400
to cross the conceptual boundary outside

1049
00:40:24,560 --> 00:40:29,200
of banana or in this case outside of

1050
00:40:26,400 --> 00:40:32,640
product into some other category that um

1051
00:40:29,200 --> 00:40:36,720
exists or could exist. And so then um

1052
00:40:32,640 --> 00:40:38,480
the human is going to confirm or come

1053
00:40:36,720 --> 00:40:40,960
up, you know, kind of um label

1054
00:40:38,480 --> 00:40:42,720
themselves these proposed out of concept

1055
00:40:40,960 --> 00:40:44,800
examples to clarify those boundaries

1056
00:40:42,720 --> 00:40:47,760
along the implied critical dimensions of

1057
00:40:44,800 --> 00:40:49,200
variation that are are kind of uh we're

1058
00:40:47,760 --> 00:40:51,760
not explicitly labeling them. These are

1059
00:40:49,200 --> 00:40:53,440
across many different uh critical

1060
00:40:51,760 --> 00:40:55,760
boundaries of v variation that we're not

1061
00:40:53,440 --> 00:40:58,720
explicitly naming. But by crossing the c

1062
00:40:55,760 --> 00:41:01,599
the the uh concept boundary

1063
00:40:58,720 --> 00:41:04,160
um they are going to help us um uh

1064
00:41:01,599 --> 00:41:06,240
refine that initially overfit feature

1065
00:41:04,160 --> 00:41:08,400
that's picking out something um that

1066
00:41:06,240 --> 00:41:12,640
kind of makes that example the category

1067
00:41:08,400 --> 00:41:17,680
that it is. Um because we construct them

1068
00:41:12,640 --> 00:41:20,160
to be alignable, right? um or we can uh

1069
00:41:17,680 --> 00:41:22,160
kind of post-process them and gray out

1070
00:41:20,160 --> 00:41:24,720
what's similar and draw your attention

1071
00:41:22,160 --> 00:41:28,000
just to the part that is uh different.

1072
00:41:24,720 --> 00:41:30,160
And because volume of of counterfactual

1073
00:41:28,000 --> 00:41:32,400
examples, the more you can label, the

1074
00:41:30,160 --> 00:41:35,520
better you can communicate, both refine

1075
00:41:32,400 --> 00:41:38,480
for yourself what it is that you know,

1076
00:41:35,520 --> 00:41:41,760
product means to you in a Yelp context.

1077
00:41:38,480 --> 00:41:44,079
um uh and um and better communicate more

1078
00:41:41,760 --> 00:41:47,200
hopefully to make a more reliable AI

1079
00:41:44,079 --> 00:41:49,440
classifier of that same concept. Um you

1080
00:41:47,200 --> 00:41:53,280
see three but there are many that the

1081
00:41:49,440 --> 00:41:56,079
person can um add. Right. So first

1082
00:41:53,280 --> 00:41:58,079
question that we had was um whether or

1083
00:41:56,079 --> 00:42:00,079
not Mocha would affect task user

1084
00:41:58,079 --> 00:42:01,839
efficiency and cognitive load. Right.

1085
00:42:00,079 --> 00:42:03,520
Yes. Yeah. I'm sorry I had the same

1086
00:42:01,839 --> 00:42:05,920
question but you know what is the

1087
00:42:03,520 --> 00:42:09,920
interaction? Are you writing a review?

1088
00:42:05,920 --> 00:42:14,560
What is the So the interaction is um I

1089
00:42:09,920 --> 00:42:16,960
have I'm trying to say label um uh I'm

1090
00:42:14,560 --> 00:42:19,839
trying to do labeling of uh Yelp data in

1091
00:42:16,960 --> 00:42:21,760
terms of what it is uh commenting on. So

1092
00:42:19,839 --> 00:42:23,200
that are you trying to classify reviews

1093
00:42:21,760 --> 00:42:24,880
that already exist or are you writing?

1094
00:42:23,200 --> 00:42:28,240
Yes, I'm classifi I have a data set of

1095
00:42:24,880 --> 00:42:30,800
of Yelp reviews. Okay. And um they the

1096
00:42:28,240 --> 00:42:32,880
the sentences in the Yelp reviews are

1097
00:42:30,800 --> 00:42:34,240
addressing different aspects of the

1098
00:42:32,880 --> 00:42:36,480
restaurant and I want to teach the

1099
00:42:34,240 --> 00:42:39,520
machine to annotate, you know, to to

1100
00:42:36,480 --> 00:42:41,839
parse those Yelp reviews in terms of

1101
00:42:39,520 --> 00:42:46,160
what concept about a restaurant they're

1102
00:42:41,839 --> 00:42:48,000
commenting on. So you're trying to uh

1103
00:42:46,160 --> 00:42:50,440
categorize Yelp reviews that are

1104
00:42:48,000 --> 00:42:53,760
pre-existing and then you're but your

1105
00:42:50,440 --> 00:42:55,200
category is is not predefined, right?

1106
00:42:53,760 --> 00:42:57,119
I'm trying to teach the machine. In

1107
00:42:55,200 --> 00:42:58,880
fact, so this is building off of work

1108
00:42:57,119 --> 00:43:01,040
I'm that was published previously uh

1109
00:42:58,880 --> 00:43:04,800
called BAT which was you know kind of AI

1110
00:43:01,040 --> 00:43:07,839
assisted um annotation of short texts

1111
00:43:04,800 --> 00:43:09,599
right um and so uh the short texts

1112
00:43:07,839 --> 00:43:12,800
people would come up with categories and

1113
00:43:09,599 --> 00:43:16,160
then ask the AI this neurosymbolic AI to

1114
00:43:12,800 --> 00:43:18,079
um propose other texts in the large

1115
00:43:16,160 --> 00:43:20,480
corpus that might get the same label

1116
00:43:18,079 --> 00:43:23,200
right and as they additionally labeled

1117
00:43:20,480 --> 00:43:26,079
um examples in the corpus the patterns

1118
00:43:23,200 --> 00:43:28,319
that detected did you know you know had

1119
00:43:26,079 --> 00:43:30,000
the learned patterns became more and

1120
00:43:28,319 --> 00:43:32,480
less and less overfitit and more and

1121
00:43:30,000 --> 00:43:34,079
more appropriately um uh having higher

1122
00:43:32,480 --> 00:43:36,160
and higher accuracy in identifying

1123
00:43:34,079 --> 00:43:38,160
additional correct applications of that

1124
00:43:36,160 --> 00:43:41,440
label. The problem is is that the

1125
00:43:38,160 --> 00:43:43,760
diversity of examples in say that Yel

1126
00:43:41,440 --> 00:43:45,760
data set may not be optimal for quickly

1127
00:43:43,760 --> 00:43:48,000
communicating the notion of that concept

1128
00:43:45,760 --> 00:43:50,240
to the machine or even like really fully

1129
00:43:48,000 --> 00:43:53,000
understanding what is and isn't part of

1130
00:43:50,240 --> 00:43:55,839
ambiance to the person. Right? So these

1131
00:43:53,000 --> 00:43:59,839
counterfactual uh generation is to kind

1132
00:43:55,839 --> 00:44:03,200
of amp up the the uh the variation

1133
00:43:59,839 --> 00:44:05,319
they're exposed to to prompt early and

1134
00:44:03,200 --> 00:44:08,160
early that reflection of what they they

1135
00:44:05,319 --> 00:44:09,839
want and communicate that in that in the

1136
00:44:08,160 --> 00:44:12,000
in as quickly as possible to the

1137
00:44:09,839 --> 00:44:14,319
machine. Okay. So how how would that

1138
00:44:12,000 --> 00:44:16,480
relate to things like you know active

1139
00:44:14,319 --> 00:44:18,319
learning or basic basic? This is active

1140
00:44:16,480 --> 00:44:20,800
learning, right? Okay. Yeah. It's just

1141
00:44:18,319 --> 00:44:22,240
so so this is um I mean so the the paper

1142
00:44:20,800 --> 00:44:23,680
that I'm not discussing that is like

1143
00:44:22,240 --> 00:44:25,599
going off to an LLP because it wasn't

1144
00:44:23,680 --> 00:44:27,359
about human interaction was like hey

1145
00:44:25,599 --> 00:44:29,359
does variation theory help active

1146
00:44:27,359 --> 00:44:31,200
learning happen faster right and the

1147
00:44:29,359 --> 00:44:32,560
answer was yes which is cool right

1148
00:44:31,200 --> 00:44:34,240
because variation theory even though it

1149
00:44:32,560 --> 00:44:36,400
was designed for humans it's just really

1150
00:44:34,240 --> 00:44:39,520
just basic information uh you know how

1151
00:44:36,400 --> 00:44:40,960
much information is quantified um but

1152
00:44:39,520 --> 00:44:43,680
here I was like all right it's better

1153
00:44:40,960 --> 00:44:46,480
for the machine can we make it better

1154
00:44:43,680 --> 00:44:47,760
for the human too right if if so so um

1155
00:44:46,480 --> 00:44:50,880
here let me give you an example example

1156
00:44:47,760 --> 00:44:52,960
of um people experienced counter

1157
00:44:50,880 --> 00:44:54,720
examples that they had to label that

1158
00:44:52,960 --> 00:44:56,960
weren't generated in this strategic way

1159
00:44:54,720 --> 00:44:59,839
and weren't ren you know rendered um

1160
00:44:56,960 --> 00:45:02,000
with this kind of pre-ferencing. Um we

1161
00:44:59,839 --> 00:45:03,680
had them uh another condition the next

1162
00:45:02,000 --> 00:45:05,119
one was they were generated

1163
00:45:03,680 --> 00:45:07,200
strategically to be this more

1164
00:45:05,119 --> 00:45:09,119
informative variation theory inspired

1165
00:45:07,200 --> 00:45:10,240
way but we didn't postprocess them in

1166
00:45:09,119 --> 00:45:13,520
any way. Okay, so you still had like

1167
00:45:10,240 --> 00:45:15,040
this long list of of things you had to

1168
00:45:13,520 --> 00:45:16,800
detect the difference with every single

1169
00:45:15,040 --> 00:45:18,640
one. And then we had the final condition

1170
00:45:16,800 --> 00:45:20,960
like you know we strategically generate

1171
00:45:18,640 --> 00:45:22,880
them. We do this post hawk analysis of

1172
00:45:20,960 --> 00:45:25,359
where they are similar and different.

1173
00:45:22,880 --> 00:45:27,200
And um we we people either experienced

1174
00:45:25,359 --> 00:45:29,960
an emotion data set labeling the emotion

1175
00:45:27,200 --> 00:45:33,040
expressed in natural language or in the

1176
00:45:29,960 --> 00:45:35,440
Yelp for um in this case we didn't allow

1177
00:45:33,040 --> 00:45:37,040
them to define their own um we gave them

1178
00:45:35,440 --> 00:45:38,960
a name for a concept that they had to

1179
00:45:37,040 --> 00:45:40,720
teach the computer. in the previous work

1180
00:45:38,960 --> 00:45:45,040
they could define whatever concepts they

1181
00:45:40,720 --> 00:45:46,760
they wanted. Um so what we found was

1182
00:45:45,040 --> 00:45:51,520
that

1183
00:45:46,760 --> 00:45:53,119
um this uh that basically um variation

1184
00:45:51,520 --> 00:45:54,480
theory which we already knew from the

1185
00:45:53,119 --> 00:45:57,200
previous paper was helping the machine

1186
00:45:54,480 --> 00:45:58,800
learn faster. When we when we combine

1187
00:45:57,200 --> 00:46:00,800
that with this post-processing, right,

1188
00:45:58,800 --> 00:46:03,440
which was enabled by the strategic

1189
00:46:00,800 --> 00:46:07,119
generation of these these variations, um

1190
00:46:03,440 --> 00:46:08,839
suddenly people got a lot faster at um

1191
00:46:07,119 --> 00:46:11,839
generating a batch. They could just

1192
00:46:08,839 --> 00:46:14,240
likeup, right? So the machine was

1193
00:46:11,839 --> 00:46:15,599
learning faster and they were faster at

1194
00:46:14,240 --> 00:46:17,200
clarifying for themselves and the

1195
00:46:15,599 --> 00:46:21,599
machine with these counter examples what

1196
00:46:17,200 --> 00:46:23,280
it is that they meant. Um and so um you

1197
00:46:21,599 --> 00:46:26,240
know the the fact that the there was

1198
00:46:23,280 --> 00:46:28,640
higher variability in that in that first

1199
00:46:26,240 --> 00:46:30,800
the first uh the time to first

1200
00:46:28,640 --> 00:46:32,720
annotation applied speaks to the fact

1201
00:46:30,800 --> 00:46:35,200
that people had to get to familiar with

1202
00:46:32,720 --> 00:46:37,920
the system, right? um they felt more

1203
00:46:35,200 --> 00:46:40,160
skilled over time as they learned how we

1204
00:46:37,920 --> 00:46:43,040
were reifying relationships across

1205
00:46:40,160 --> 00:46:44,560
counterfactual examples um and and

1206
00:46:43,040 --> 00:46:47,440
between the counterfactual examples and

1207
00:46:44,560 --> 00:46:49,839
the original incorpass example um to

1208
00:46:47,440 --> 00:46:52,319
really kind of benefit from this uh

1209
00:46:49,839 --> 00:46:52,319
cognitive

1210
00:46:52,760 --> 00:46:59,040
assistance.

1211
00:46:54,440 --> 00:47:02,160
Um we also um just focusing on on um the

1212
00:46:59,040 --> 00:47:04,160
third research question we asked um how

1213
00:47:02,160 --> 00:47:06,560
useful Mocha was in allowing people to

1214
00:47:04,160 --> 00:47:08,560
learn about their own evolving

1215
00:47:06,560 --> 00:47:10,400
conception of the label. We have uh you

1216
00:47:08,560 --> 00:47:12,480
know people did acknowledge um for

1217
00:47:10,400 --> 00:47:14,000
example P3 said I think by changing

1218
00:47:12,480 --> 00:47:15,440
different parts of of it the original

1219
00:47:14,000 --> 00:47:16,640
sentence it highlighted a part of the

1220
00:47:15,440 --> 00:47:18,240
sentences that I was not previously

1221
00:47:16,640 --> 00:47:21,520
focused on. Right? that difference

1222
00:47:18,240 --> 00:47:23,119
allows discernment and and so that did

1223
00:47:21,520 --> 00:47:24,880
help my sort of reframe of what I

1224
00:47:23,119 --> 00:47:28,319
initially had labeled. Right? So this

1225
00:47:24,880 --> 00:47:30,480
notion of um almost close reading that

1226
00:47:28,319 --> 00:47:33,240
um and reflection that this uh made

1227
00:47:30,480 --> 00:47:37,760
visible to them cog salient

1228
00:47:33,240 --> 00:47:40,520
cognitively. So um so that's that work.

1229
00:47:37,760 --> 00:47:43,480
We're we're almost out of time. So,

1230
00:47:40,520 --> 00:47:47,440
um

1231
00:47:43,480 --> 00:47:51,880
I I'll point out that um uh you could

1232
00:47:47,440 --> 00:47:54,480
say that um well, you you could say that

1233
00:47:51,880 --> 00:47:56,319
uh refining one's understanding of a

1234
00:47:54,480 --> 00:47:58,079
concept is also a dialectical activity.

1235
00:47:56,319 --> 00:48:00,160
By repeatedly engaging with things, you

1236
00:47:58,079 --> 00:48:02,880
may come to understand new ways of

1237
00:48:00,160 --> 00:48:05,040
defining what is or isn't um you know,

1238
00:48:02,880 --> 00:48:06,480
ambiance, right? It's that sounds better

1239
00:48:05,040 --> 00:48:08,400
than saying what is or isn't banana.

1240
00:48:06,480 --> 00:48:12,720
That one's pretty clear-cut.

1241
00:48:08,400 --> 00:48:15,359
Um but um so both of them to some extent

1242
00:48:12,720 --> 00:48:16,560
are AI helping dialectical activities.

1243
00:48:15,359 --> 00:48:17,920
So, we've seen from these two examples

1244
00:48:16,560 --> 00:48:20,000
that one way for AI to support

1245
00:48:17,920 --> 00:48:22,240
dialectical activities is by revealing

1246
00:48:20,000 --> 00:48:24,559
existing variation

1247
00:48:22,240 --> 00:48:27,440
um in a relevant collection of data

1248
00:48:24,559 --> 00:48:29,200
corpus of of papers that um that your

1249
00:48:27,440 --> 00:48:31,200
your audience has already read or

1250
00:48:29,200 --> 00:48:33,920
generating it strategically, right? as

1251
00:48:31,200 --> 00:48:36,160
was done in the um in teaching a machine

1252
00:48:33,920 --> 00:48:40,079
about a particular concept to um and

1253
00:48:36,160 --> 00:48:43,200
this revealing or um pres presentation

1254
00:48:40,079 --> 00:48:45,000
of strategically generated variation

1255
00:48:43,200 --> 00:48:47,280
helps deepen the human's cognitive

1256
00:48:45,000 --> 00:48:48,640
engagement, right? They they notice

1257
00:48:47,280 --> 00:48:50,559
things they wouldn't have discerned in

1258
00:48:48,640 --> 00:48:52,800
isolation.

1259
00:48:50,559 --> 00:48:55,040
And um so the AI is supporting the

1260
00:48:52,800 --> 00:48:56,119
dialectical activity when the um I would

1261
00:48:55,040 --> 00:48:58,960
argue

1262
00:48:56,119 --> 00:49:01,520
that one guiding way in which we can

1263
00:48:58,960 --> 00:49:04,079
design for AI support of these really

1264
00:49:01,520 --> 00:49:06,400
important activities is to think about

1265
00:49:04,079 --> 00:49:09,760
how we can make the thought processes

1266
00:49:06,400 --> 00:49:12,480
that reveal the value happen still

1267
00:49:09,760 --> 00:49:15,040
within the user's mind. Right? um that

1268
00:49:12,480 --> 00:49:16,559
we cannot if we start to compute the

1269
00:49:15,040 --> 00:49:19,520
process that already is happening in the

1270
00:49:16,559 --> 00:49:20,960
user's mind or we um we start to

1271
00:49:19,520 --> 00:49:23,359
encroach on the value that they might

1272
00:49:20,960 --> 00:49:26,720
otherwise get. Right now I realize it's

1273
00:49:23,359 --> 00:49:28,240
a little bit of a of a um uh almost

1274
00:49:26,720 --> 00:49:30,160
contradicts this notion of like oh I'm

1275
00:49:28,240 --> 00:49:31,520
going to premputee these relationships

1276
00:49:30,160 --> 00:49:33,280
so that people can keep you know

1277
00:49:31,520 --> 00:49:36,000
thinking about the the emergent patterns

1278
00:49:33,280 --> 00:49:38,160
from that. Um, so maybe in a sense you

1279
00:49:36,000 --> 00:49:40,480
you could say if you're really sure that

1280
00:49:38,160 --> 00:49:42,160
you have the right representation and

1281
00:49:40,480 --> 00:49:44,079
the right structural mapping engine that

1282
00:49:42,160 --> 00:49:46,319
aligns them and and reifies those

1283
00:49:44,079 --> 00:49:47,760
alignments, then great, you know, you

1284
00:49:46,319 --> 00:49:50,240
you're helping them get where they would

1285
00:49:47,760 --> 00:49:53,160
already have gotten. Um, however, if

1286
00:49:50,240 --> 00:49:55,680
there's uh many different possible

1287
00:49:53,160 --> 00:49:57,839
representations and therefore alignments

1288
00:49:55,680 --> 00:49:59,839
over those those representations, by

1289
00:49:57,839 --> 00:50:02,319
surfacing one, you might impair their

1290
00:49:59,839 --> 00:50:06,160
ability to see the others. So like use

1291
00:50:02,319 --> 00:50:10,280
with caution. Um and

1292
00:50:06,160 --> 00:50:14,240
um my final thought here is that um

1293
00:50:10,280 --> 00:50:17,119
uh you know no matter what the AI does,

1294
00:50:14,240 --> 00:50:20,319
I still at the end of the day want to

1295
00:50:17,119 --> 00:50:22,960
make sure that the humans are resilient

1296
00:50:20,319 --> 00:50:25,040
to AI choices that are objectively wrong

1297
00:50:22,960 --> 00:50:27,359
or contextually inappropriate for them

1298
00:50:25,040 --> 00:50:29,599
or or just subjectively disliked. And

1299
00:50:27,359 --> 00:50:34,000
these choices can often be hidden.

1300
00:50:29,599 --> 00:50:35,520
Right? If I um uh uh going blazingly

1301
00:50:34,000 --> 00:50:39,359
fast, you know, if I get a generative

1302
00:50:35,520 --> 00:50:40,960
summary of um stuff on a um on a search

1303
00:50:39,359 --> 00:50:43,119
query about like the probability of

1304
00:50:40,960 --> 00:50:45,119
having twins in your late 30s, right?

1305
00:50:43,119 --> 00:50:46,800
It's very difficult to detect whether or

1306
00:50:45,119 --> 00:50:49,040
not this is right. It sound, you know,

1307
00:50:46,800 --> 00:50:50,720
looks good to me, right? Um even though

1308
00:50:49,040 --> 00:50:53,920
those those statistics look a little bit

1309
00:50:50,720 --> 00:50:55,680
high. Um and and it looks corroborated

1310
00:50:53,920 --> 00:50:58,240
by a different feature down the page,

1311
00:50:55,680 --> 00:51:01,119
right? Turns out both of those things it

1312
00:50:58,240 --> 00:51:02,240
was not hard not easy for me to notice

1313
00:51:01,119 --> 00:51:05,599
right that they were actually pointing

1314
00:51:02,240 --> 00:51:07,520
to the same original paper sorry uh page

1315
00:51:05,599 --> 00:51:09,440
where it had truncated the fact that

1316
00:51:07,520 --> 00:51:11,760
younger people had an even higher rate

1317
00:51:09,440 --> 00:51:13,920
so that that they left out the the thing

1318
00:51:11,760 --> 00:51:15,760
that would have violated my expectations

1319
00:51:13,920 --> 00:51:18,400
and then it also left out the context

1320
00:51:15,760 --> 00:51:20,960
that these were people using IVF where

1321
00:51:18,400 --> 00:51:22,319
doctors often intentionally put multiple

1322
00:51:20,960 --> 00:51:23,920
embryos in to maximize the chance of

1323
00:51:22,319 --> 00:51:26,000
live birth. Right? It was answering a

1324
00:51:23,920 --> 00:51:28,720
completely different question but I was

1325
00:51:26,000 --> 00:51:30,000
completely. You cannot blame me for not

1326
00:51:28,720 --> 00:51:31,200
recognizing this except for the fact

1327
00:51:30,000 --> 00:51:33,960
that that seemed a little higher than

1328
00:51:31,200 --> 00:51:38,000
average, right? But um this these this

1329
00:51:33,960 --> 00:51:40,079
variation, okay, um can be a great way

1330
00:51:38,000 --> 00:51:42,400
to combat this. So, you know, these

1331
00:51:40,079 --> 00:51:45,200
deceptive patterns AI can generate these

1332
00:51:42,400 --> 00:51:46,800
deceptive patterns. We cannot as

1333
00:51:45,200 --> 00:51:48,880
designers

1334
00:51:46,800 --> 00:51:50,720
um just throw up our hands, right, and

1335
00:51:48,880 --> 00:51:53,440
say, well, we you know, we gave you the

1336
00:51:50,720 --> 00:51:56,160
information. We didn't. Um, this is this

1337
00:51:53,440 --> 00:51:58,400
is where the variation saved me. I uh

1338
00:51:56,160 --> 00:51:59,920
query um full weight daily for pregnancy

1339
00:51:58,400 --> 00:52:01,119
and and I'm sure you know that many

1340
00:51:59,920 --> 00:52:03,520
pregnant people are looking to the

1341
00:52:01,119 --> 00:52:05,839
internet for information on on you just

1342
00:52:03,520 --> 00:52:07,200
this kind of of query. I get two

1343
00:52:05,839 --> 00:52:09,599
answers. They're off by an order of

1344
00:52:07,200 --> 00:52:13,760
magnitude. 400 micrograms or 4,000.

1345
00:52:09,599 --> 00:52:15,680
Okay, because I got two bad results.

1346
00:52:13,760 --> 00:52:17,359
Okay, they're both wrong. The first one

1347
00:52:15,680 --> 00:52:20,319
is telling me how much it was the first

1348
00:52:17,359 --> 00:52:22,400
time we ever had recommendations. The

1349
00:52:20,319 --> 00:52:24,400
second one is telling me how much I

1350
00:52:22,400 --> 00:52:26,960
should take if I'm at high risk for a

1351
00:52:24,400 --> 00:52:30,640
neural tube defect. Okay, two bad

1352
00:52:26,960 --> 00:52:32,400
answers, but I became more I my outcomes

1353
00:52:30,640 --> 00:52:35,599
were better because I revealed both of

1354
00:52:32,400 --> 00:52:38,079
them and that um sparked my engagement

1355
00:52:35,599 --> 00:52:40,559
um to know that I should look further.

1356
00:52:38,079 --> 00:52:42,640
Uh you know this is a mockup of other

1357
00:52:40,559 --> 00:52:46,880
ways in which we can supervi um super

1358
00:52:42,640 --> 00:52:49,680
provo sorry super oh goodness juxtapose.

1359
00:52:46,880 --> 00:52:51,680
I'll go with that. Juxtapose different

1360
00:52:49,680 --> 00:52:53,280
narrations of the same event, right? Who

1361
00:52:51,680 --> 00:52:55,839
was the actor? If I read any one of

1362
00:52:53,280 --> 00:52:58,559
these lead sentences about um this

1363
00:52:55,839 --> 00:53:01,680
particular event back in like 2019, I

1364
00:52:58,559 --> 00:53:03,680
might have taken for granted that um uh

1365
00:53:01,680 --> 00:53:05,440
that the Treasury Department did this,

1366
00:53:03,680 --> 00:53:07,520
right? Um but actually, who was the

1367
00:53:05,440 --> 00:53:09,680
actor? The the contrast poses the

1368
00:53:07,520 --> 00:53:11,920
question implicitly. We have work where

1369
00:53:09,680 --> 00:53:14,800
we show this um for large language

1370
00:53:11,920 --> 00:53:16,880
models. The last thing that I will um

1371
00:53:14,800 --> 00:53:19,280
leave you with is that while I've talked

1372
00:53:16,880 --> 00:53:22,559
about how great variation is um it's not

1373
00:53:19,280 --> 00:53:24,559
a panacea. The variation that we show

1374
00:53:22,559 --> 00:53:26,160
and the variation that we don't show can

1375
00:53:24,559 --> 00:53:28,800
actually constrain your imagination

1376
00:53:26,160 --> 00:53:34,160
about what that other world is. So if I

1377
00:53:28,800 --> 00:53:36,079
go to um uh if I um if I go to you and I

1378
00:53:34,160 --> 00:53:39,359
say um you can either get the surgery

1379
00:53:36,079 --> 00:53:42,480
now or you can get the surgery uh at an

1380
00:53:39,359 --> 00:53:45,040
emergency next week, right? um I've

1381
00:53:42,480 --> 00:53:46,480
constrained that the your imagination to

1382
00:53:45,040 --> 00:53:48,319
the things that are different between

1383
00:53:46,480 --> 00:53:50,400
getting surgery now or later when in

1384
00:53:48,319 --> 00:53:52,559
reality there are other you know if I

1385
00:53:50,400 --> 00:53:54,319
had said or not get surgery that

1386
00:53:52,559 --> 00:53:56,160
dimension of variation is still salient

1387
00:53:54,319 --> 00:53:58,800
to you rather than something you have to

1388
00:53:56,160 --> 00:54:00,480
cognitively try to remember. Um so our

1389
00:53:58,800 --> 00:54:02,960
our choices can be shaped by the

1390
00:54:00,480 --> 00:54:03,880
variation we do show and what we hide.

1391
00:54:02,960 --> 00:54:06,720
So

1392
00:54:03,880 --> 00:54:08,960
um there's there's um I've worked on

1393
00:54:06,720 --> 00:54:10,559
this notion of AI resilient interfaces.

1394
00:54:08,960 --> 00:54:12,319
I have an AI resilient alternative

1395
00:54:10,559 --> 00:54:14,960
summarization that I can talk talk about

1396
00:54:12,319 --> 00:54:17,520
um that I've run out of time for. Um I

1397
00:54:14,960 --> 00:54:18,960
define there's a a nice working nice I

1398
00:54:17,520 --> 00:54:21,200
hope you'll check out my working paper

1399
00:54:18,960 --> 00:54:22,800
that uh in which we try to define this

1400
00:54:21,200 --> 00:54:25,280
generalization of an AI resilient

1401
00:54:22,800 --> 00:54:26,640
interface. Um but I I summarize it as an

1402
00:54:25,280 --> 00:54:28,160
interface that increases the safety

1403
00:54:26,640 --> 00:54:29,599
usability and utility of AI powered

1404
00:54:28,160 --> 00:54:31,920
features by giving people the ability to

1405
00:54:29,599 --> 00:54:33,680
notice AI choices, have the context

1406
00:54:31,920 --> 00:54:36,000
necessary to judge them and recover with

1407
00:54:33,680 --> 00:54:38,480
them from them with ease. It's a high

1408
00:54:36,000 --> 00:54:40,079
bar. Maybe nothing will ever perfectly

1409
00:54:38,480 --> 00:54:42,480
meet it. Um but I think it's something

1410
00:54:40,079 --> 00:54:45,359
that we should be shooting for. Um and

1411
00:54:42,480 --> 00:54:47,599
um uh uh it definitely resonates with

1412
00:54:45,359 --> 00:54:50,559
the wording of the initial se uh seminar

1413
00:54:47,599 --> 00:54:52,240
invitation that I received. So um all

1414
00:54:50,559 --> 00:54:54,400
the papers that I talked about today,

1415
00:54:52,240 --> 00:54:56,319
you can um take a look at them. Uh

1416
00:54:54,400 --> 00:54:58,720
they're linked in this um through this

1417
00:54:56,319 --> 00:55:01,040
QR code in a Google document. And I'm

1418
00:54:58,720 --> 00:55:02,880
happy to take uh any uh further

1419
00:55:01,040 --> 00:55:09,709
questions that you have.

1420
00:55:02,880 --> 00:55:09,709
[Applause]


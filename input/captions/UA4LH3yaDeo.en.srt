1
00:00:13,559 --> 00:00:18,400
hi everyone today's topic is protein

2
00:00:15,240 --> 00:00:20,600
structure determination with cryoem uh

3
00:00:18,400 --> 00:00:23,119
cryoem as an experimental technique has

4
00:00:20,600 --> 00:00:25,279
existed for over half a century but it's

5
00:00:23,119 --> 00:00:27,279
really been growing in popularity

6
00:00:25,279 --> 00:00:29,480
probably over the past decade both

7
00:00:27,279 --> 00:00:31,720
amongst biologists who want to you know

8
00:00:29,480 --> 00:00:33,920
push forward Discovery but also amongst

9
00:00:31,720 --> 00:00:35,399
computationalists who you know are faced

10
00:00:33,920 --> 00:00:37,200
with new challenges in processing the

11
00:00:35,399 --> 00:00:39,280
data um and so I'm really excited to be

12
00:00:37,200 --> 00:00:41,800
giving this intro on what the method's

13
00:00:39,280 --> 00:00:43,360
about and then in about an hour Ellen

14
00:00:41,800 --> 00:00:45,079
will pick up and talk about how our

15
00:00:43,360 --> 00:00:47,600
research group is um actually

16
00:00:45,079 --> 00:00:49,079
implementing tools to process this sort

17
00:00:47,600 --> 00:00:51,920
of

18
00:00:49,079 --> 00:00:54,399
data um so as a starting point uh as we

19
00:00:51,920 --> 00:00:57,000
all know proteins are really fundamental

20
00:00:54,399 --> 00:01:00,039
to all the processes that go on in our

21
00:00:57,000 --> 00:01:01,559
body uh from catalyzing reactions to

22
00:01:00,039 --> 00:01:03,920
being the building blocks of our bodies

23
00:01:01,559 --> 00:01:05,040
to transmitting signals um and so

24
00:01:03,920 --> 00:01:06,680
understanding proteins is really

25
00:01:05,040 --> 00:01:09,000
fundamental not only to understanding

26
00:01:06,680 --> 00:01:11,159
life but also intervening rationally

27
00:01:09,000 --> 00:01:13,080
within medicine and health uh and also

28
00:01:11,159 --> 00:01:14,799
driving innovation in Industries like

29
00:01:13,080 --> 00:01:17,280
nanotech and

30
00:01:14,799 --> 00:01:18,880
biotechnology there are many different

31
00:01:17,280 --> 00:01:20,560
lenses through which we can study

32
00:01:18,880 --> 00:01:22,320
proteins but today we're specifically

33
00:01:20,560 --> 00:01:24,960
interested in studying proteins through

34
00:01:22,320 --> 00:01:26,520
the lens of structure uh so proteins

35
00:01:24,960 --> 00:01:28,360
take on really a wide range of

36
00:01:26,520 --> 00:01:30,040
structures and just as importantly

37
00:01:28,360 --> 00:01:32,280
proteins are also highly dynamic so

38
00:01:30,040 --> 00:01:35,159
they're flexible subunits can bind

39
00:01:32,280 --> 00:01:37,640
unbind um and this Dynamic structure is

40
00:01:35,159 --> 00:01:40,479
really critical to their function across

41
00:01:37,640 --> 00:01:42,600
multile scales so on the left here you

42
00:01:40,479 --> 00:01:44,719
can see that these sort of really local

43
00:01:42,600 --> 00:01:47,399
fluctuations of side chains Within These

44
00:01:44,719 --> 00:01:51,000
binding Pockets Drive binding to

45
00:01:47,399 --> 00:01:53,479
substrates um in this dining molecule

46
00:01:51,000 --> 00:01:55,920
Global movements of domains allows this

47
00:01:53,479 --> 00:01:57,439
protein to carry cargo across the cell

48
00:01:55,920 --> 00:01:59,920
and on the very right is the nuclear

49
00:01:57,439 --> 00:02:02,320
pore complex which consists of hundreds

50
00:01:59,920 --> 00:02:04,719
of different protein subunits which are

51
00:02:02,320 --> 00:02:07,479
interacting in concert to selectively

52
00:02:04,719 --> 00:02:08,800
allow passage of substrates into and out

53
00:02:07,479 --> 00:02:10,800
of the

54
00:02:08,800 --> 00:02:12,440
nucleus and so there are multiple

55
00:02:10,800 --> 00:02:14,560
techniques we can use to study this

56
00:02:12,440 --> 00:02:17,120
structure they broadly fall into three

57
00:02:14,560 --> 00:02:20,680
categories one is experiment including

58
00:02:17,120 --> 00:02:22,040
Kow crystallography NMR where you know

59
00:02:20,680 --> 00:02:24,760
we use experimental techniques to

60
00:02:22,040 --> 00:02:26,480
directly probe samples of proteins

61
00:02:24,760 --> 00:02:29,280
physics based methods like molecular

62
00:02:26,480 --> 00:02:32,000
Dynamics where we use our knowledge of

63
00:02:29,280 --> 00:02:34,519
biophysics to simulate the Dynamics of

64
00:02:32,000 --> 00:02:36,879
proteins and finally statistical methods

65
00:02:34,519 --> 00:02:39,599
like Alpha fold which use these data

66
00:02:36,879 --> 00:02:42,040
driven driven priors to make sort of

67
00:02:39,599 --> 00:02:44,480
plausible hypotheses about structures

68
00:02:42,040 --> 00:02:46,959
from their

69
00:02:44,480 --> 00:02:49,480
sequence today again we're specifically

70
00:02:46,959 --> 00:02:51,879
focusing on cryo electron microscopy

71
00:02:49,480 --> 00:02:54,840
which is an experimental technique again

72
00:02:51,879 --> 00:02:56,800
it's been around for a while but um

73
00:02:54,840 --> 00:02:59,560
currently it's going what sometimes

74
00:02:56,800 --> 00:03:02,480
called a resolution Revolution where due

75
00:02:59,560 --> 00:03:04,519
to advances both on the hardware side in

76
00:03:02,480 --> 00:03:06,200
the microscopes as well as on the

77
00:03:04,519 --> 00:03:08,799
software side in terms of processing

78
00:03:06,200 --> 00:03:11,640
algorithms we're now able to process a

79
00:03:08,799 --> 00:03:13,760
much broader range of proteins and also

80
00:03:11,640 --> 00:03:16,560
uh achieve really high resolution

81
00:03:13,760 --> 00:03:20,159
structures um like you can see on the

82
00:03:16,560 --> 00:03:24,120
right um this also comes with a whole

83
00:03:20,159 --> 00:03:27,319
new host of computational challenges and

84
00:03:24,120 --> 00:03:29,519
opportunities and so the plan for today

85
00:03:27,319 --> 00:03:31,760
I'll start off with an overview of the

86
00:03:29,519 --> 00:03:33,239
whole crym pipeline going from you know

87
00:03:31,760 --> 00:03:35,200
if you're a structural biologist

88
00:03:33,239 --> 00:03:37,200
interested in studying some protein how

89
00:03:35,200 --> 00:03:38,959
do you go from an idea of that Target

90
00:03:37,200 --> 00:03:40,879
protein to actually depositing a

91
00:03:38,959 --> 00:03:43,159
structure in the in a database like the

92
00:03:40,879 --> 00:03:44,640
protein datab Bank um and then I'll

93
00:03:43,159 --> 00:03:46,920
spend some time talking about the

94
00:03:44,640 --> 00:03:48,120
classical algorithms for cim

95
00:03:46,920 --> 00:03:51,040
reconstruction just to get the

96
00:03:48,120 --> 00:03:53,560
underlying uh Theory and then that'll

97
00:03:51,040 --> 00:03:55,400
set up the final part of my talk on

98
00:03:53,560 --> 00:03:57,159
Modern methods for heterogenous

99
00:03:55,400 --> 00:03:59,120
reconstruction um and then finally

100
00:03:57,159 --> 00:04:01,680
leading into Ellen's talk giving some

101
00:03:59,120 --> 00:04:03,040
broader cont text for these methods um

102
00:04:01,680 --> 00:04:06,239
and some of the newer developments

103
00:04:03,040 --> 00:04:08,360
within our lab tackling these

104
00:04:06,239 --> 00:04:10,040
challenges so starting out with an

105
00:04:08,360 --> 00:04:13,040
overview of the

106
00:04:10,040 --> 00:04:15,239
pipeline the first step is that given a

107
00:04:13,040 --> 00:04:17,519
Target protein I'm first going to purify

108
00:04:15,239 --> 00:04:20,440
amplify and purify that protein from my

109
00:04:17,519 --> 00:04:22,600
cells and flash freeze it or vitrify it

110
00:04:20,440 --> 00:04:24,600
under liquid nitrogen conditions so this

111
00:04:22,600 --> 00:04:26,520
freezing process a it TR traps the

112
00:04:24,600 --> 00:04:28,919
molecules in place so that we can image

113
00:04:26,520 --> 00:04:32,120
them under long exposures um and it also

114
00:04:28,919 --> 00:04:34,600
increases their tolerance to radiation

115
00:04:32,120 --> 00:04:36,680
damage within the microscope um one

116
00:04:34,600 --> 00:04:38,759
other important aspect of this freezing

117
00:04:36,680 --> 00:04:40,400
process is that uh for context one of

118
00:04:38,759 --> 00:04:42,680
the other major experimental techniques

119
00:04:40,400 --> 00:04:44,680
for structure determination is X-ray

120
00:04:42,680 --> 00:04:46,000
crystallography and in crystallography

121
00:04:44,680 --> 00:04:47,919
you typically have to well you have to

122
00:04:46,000 --> 00:04:49,600
crystallize the sample and that's often

123
00:04:47,919 --> 00:04:51,960
a very difficult thing especially when

124
00:04:49,600 --> 00:04:53,720
you have highly flexible molecules um

125
00:04:51,960 --> 00:04:56,320
really large complexes consisting of

126
00:04:53,720 --> 00:04:58,560
multiple subunits um and so cryo first

127
00:04:56,320 --> 00:05:01,080
of all has really allowed uh access to a

128
00:04:58,560 --> 00:05:03,400
broader range of protein specimens uh

129
00:05:01,080 --> 00:05:05,360
because more samples are amenable to

130
00:05:03,400 --> 00:05:07,600
just flash freezing than they are to

131
00:05:05,360 --> 00:05:09,400
crystallization yeah I think I might ask

132
00:05:07,600 --> 00:05:11,520
some basic questions during your talk

133
00:05:09,400 --> 00:05:14,160
because it's outside of of my field but

134
00:05:11,520 --> 00:05:16,320
um I find them fascinating so uh for

135
00:05:14,160 --> 00:05:18,639
x-ray Crystal crystallography I think

136
00:05:16,320 --> 00:05:22,199
I've heard of it in context of uh

137
00:05:18,639 --> 00:05:25,120
individual proteins like proteins

138
00:05:22,199 --> 00:05:27,080
uh use being used for proteins to

139
00:05:25,120 --> 00:05:30,080
determine structure but is it done on a

140
00:05:27,080 --> 00:05:32,560
cell level like cryoem is or am I

141
00:05:30,080 --> 00:05:34,120
confusing it with something else uh

142
00:05:32,560 --> 00:05:37,479
sorry could you repeat on on the what

143
00:05:34,120 --> 00:05:40,240
level um so with crym you take cell

144
00:05:37,479 --> 00:05:43,960
level images right uh do you get that

145
00:05:40,240 --> 00:05:46,639
for um x-ray c crystallography as well

146
00:05:43,960 --> 00:05:49,160
or is it like for

147
00:05:46,639 --> 00:05:52,199
molecules all like distribution of you

148
00:05:49,160 --> 00:05:55,759
know um different proteins in the cell

149
00:05:52,199 --> 00:05:57,639
yeah so I guess in both for the crym

150
00:05:55,759 --> 00:05:59,440
that I'm presenting here it also is a

151
00:05:57,639 --> 00:06:00,240
similar setup as fortography Where We

152
00:05:59,440 --> 00:06:02,240
Are

153
00:06:00,240 --> 00:06:04,680
we're not Imaging a cell we are just

154
00:06:02,240 --> 00:06:06,759
purifying um a specific protein and

155
00:06:04,680 --> 00:06:09,680
imaging that sample um there's an

156
00:06:06,759 --> 00:06:12,400
extension of CM for this Inu cellular

157
00:06:09,680 --> 00:06:15,919
samples which I'll talk about okay I see

158
00:06:12,400 --> 00:06:18,280
thank you y um yeah so we freeze our

159
00:06:15,919 --> 00:06:20,639
sample and the other really important

160
00:06:18,280 --> 00:06:22,319
aspect of this freezing process is that

161
00:06:20,639 --> 00:06:24,520
because the freezing process so fast

162
00:06:22,319 --> 00:06:27,160
we're trapping these molecules in sort

163
00:06:24,520 --> 00:06:28,440
of a native state um where the

164
00:06:27,160 --> 00:06:30,440
confirmations of each of those

165
00:06:28,440 --> 00:06:32,639
individual particles in the s Le will be

166
00:06:30,440 --> 00:06:35,039
approximately distributed according to

167
00:06:32,639 --> 00:06:36,360
the sort of thermodynamic equilibrium

168
00:06:35,039 --> 00:06:38,639
and so that provides us with a really

169
00:06:36,360 --> 00:06:40,000
powerful opportunity to study not just

170
00:06:38,639 --> 00:06:41,960
you know the single sort of average

171
00:06:40,000 --> 00:06:44,800
static structure but actually access

172
00:06:41,960 --> 00:06:47,039
this full confirmational

173
00:06:44,800 --> 00:06:48,840
landscape so once we've gotten this

174
00:06:47,039 --> 00:06:50,599
sample we can put it into an electron

175
00:06:48,840 --> 00:06:53,639
microscope which looks like the thing on

176
00:06:50,599 --> 00:06:55,759
the left and IR radiated with electrons

177
00:06:53,639 --> 00:06:57,240
and so what the microscope gives us is a

178
00:06:55,759 --> 00:07:00,599
micrograph or a collection of

179
00:06:57,240 --> 00:07:03,639
micrographs which is a 2d ection of the

180
00:07:00,599 --> 00:07:07,400
electron scattering potential the

181
00:07:03,639 --> 00:07:09,240
sample um the key idea is that uh you

182
00:07:07,400 --> 00:07:11,240
know you have water and then you have

183
00:07:09,240 --> 00:07:12,560
these particles embedded within them and

184
00:07:11,240 --> 00:07:15,080
so due to you know differential

185
00:07:12,560 --> 00:07:17,360
scattering um you end up getting sort of

186
00:07:15,080 --> 00:07:19,919
the contrast in these

187
00:07:17,360 --> 00:07:21,919
images so in the micrograph each one of

188
00:07:19,919 --> 00:07:25,199
those dark spots you see is one

189
00:07:21,919 --> 00:07:26,560
individual molecule of the protein and

190
00:07:25,199 --> 00:07:29,000
so in order

191
00:07:26,560 --> 00:07:30,800
to do structure processing the first

192
00:07:29,000 --> 00:07:32,919
thing we have to do is actually extract

193
00:07:30,800 --> 00:07:34,840
each one of those individual particles

194
00:07:32,919 --> 00:07:36,440
this can be done in a variety of ways

195
00:07:34,840 --> 00:07:38,520
including you know machine learning

196
00:07:36,440 --> 00:07:40,360
techniques or using prior structural

197
00:07:38,520 --> 00:07:42,440
templates but after extracting those

198
00:07:40,360 --> 00:07:45,120
particles what do we end up with is

199
00:07:42,440 --> 00:07:48,240
usually between 10,000 up to maybe even

200
00:07:45,120 --> 00:07:50,639
10 million of these individual 2D images

201
00:07:48,240 --> 00:07:54,520
and each one of those consists of a

202
00:07:50,639 --> 00:07:57,440
unique particle captured from the

203
00:07:54,520 --> 00:07:59,599
sample One Challenge in general in crym

204
00:07:57,440 --> 00:08:02,000
data sets is that there tends to be a

205
00:07:59,599 --> 00:08:05,960
lot of junk or outlier particles this is

206
00:08:02,000 --> 00:08:09,479
both due to um imperfections in the

207
00:08:05,960 --> 00:08:11,400
purification and freezing process um as

208
00:08:09,479 --> 00:08:13,560
well as inaccuracies in the particle

209
00:08:11,400 --> 00:08:14,919
picking process yes oh can I ask you

210
00:08:13,560 --> 00:08:17,599
thank you can I ask you a quick question

211
00:08:14,919 --> 00:08:20,000
about the electron microgram so I know

212
00:08:17,599 --> 00:08:22,639
like cry kind of took off a lot in the

213
00:08:20,000 --> 00:08:25,039
last like maybe 10 or 15 years and I

214
00:08:22,639 --> 00:08:27,000
heard one of the reasons was like just

215
00:08:25,039 --> 00:08:30,879
Imaging got better or the cameras got

216
00:08:27,000 --> 00:08:33,719
better is that correct or am I imagining

217
00:08:30,879 --> 00:08:35,599
yeah that uh I don't know the exact year

218
00:08:33,719 --> 00:08:39,760
but yeah direct electron detectors where

219
00:08:35,599 --> 00:08:43,360
you can get um yeah direct counts of

220
00:08:39,760 --> 00:08:46,440
electrons uh spatially uh yeah gave much

221
00:08:43,360 --> 00:08:48,959
better S of signal signal in these

222
00:08:46,440 --> 00:08:51,720
images um and if you have additional

223
00:08:48,959 --> 00:08:51,720
context

224
00:08:52,519 --> 00:08:56,560
here just echoing R like better Hardware

225
00:08:55,279 --> 00:08:58,399
increasing the amount of signal in the

226
00:08:56,560 --> 00:08:59,839
collected images such that now you can

227
00:08:58,399 --> 00:09:03,560
get Atomic resolution solution

228
00:08:59,839 --> 00:09:03,560
structures this was about like

229
00:09:06,040 --> 00:09:12,000
2013 um yeah so characteristically these

230
00:09:08,959 --> 00:09:13,399
data sets do contain a lot of partic

231
00:09:12,000 --> 00:09:15,440
junk particles and so this is going to

232
00:09:13,399 --> 00:09:17,760
be a processing challenge that comes up

233
00:09:15,440 --> 00:09:19,279
later in Ellen's results again but at

234
00:09:17,760 --> 00:09:21,320
this phase at the 2D level there are

235
00:09:19,279 --> 00:09:23,399
certain things we can do specifically

236
00:09:21,320 --> 00:09:25,760
sort of grouping similar looking images

237
00:09:23,399 --> 00:09:28,959
and sort of throwing out classes um that

238
00:09:25,760 --> 00:09:30,680
correspond junk and finally the core

239
00:09:28,959 --> 00:09:32,120
comput

240
00:09:30,680 --> 00:09:34,440
uh question that we're interested in is

241
00:09:32,120 --> 00:09:37,519
the 3D reconstruction problem of how do

242
00:09:34,440 --> 00:09:40,640
we go from all these really noisy 2D

243
00:09:37,519 --> 00:09:43,160
projection images of these particles um

244
00:09:40,640 --> 00:09:46,240
viewed at different angles and go to the

245
00:09:43,160 --> 00:09:48,640
underlying 3D structure or 3D uh

246
00:09:46,240 --> 00:09:50,880
electron scattering map uh this is in

247
00:09:48,640 --> 00:09:52,720
general a very challenging problem both

248
00:09:50,880 --> 00:09:56,279
because as you can see the images are

249
00:09:52,720 --> 00:09:59,120
very noisy the signal to noise ratios uh

250
00:09:56,279 --> 00:10:02,839
can be you know as high as 0.1 but also

251
00:09:59,120 --> 00:10:07,079
as low as 0.01 so sort you know signal

252
00:10:02,839 --> 00:10:10,160
to noise ratio sort of 1 to 1,000 um

253
00:10:07,079 --> 00:10:12,839
also the particle orientations are

254
00:10:10,160 --> 00:10:15,519
unknown um and so you know in the sample

255
00:10:12,839 --> 00:10:18,519
all those individual molecules are

256
00:10:15,519 --> 00:10:20,160
rotated randomly um and so in order to

257
00:10:18,519 --> 00:10:21,920
sort of combine the signal we need to be

258
00:10:20,160 --> 00:10:23,560
able to have a common reference frame

259
00:10:21,920 --> 00:10:25,079
that we can average that signal and so

260
00:10:23,560 --> 00:10:26,839
the second thing is that we don't know

261
00:10:25,079 --> 00:10:28,560
what orientation each of those particles

262
00:10:26,839 --> 00:10:31,440
is in and so we're going to have to

263
00:10:28,560 --> 00:10:33,519
estimate those parameters in addition to

264
00:10:31,440 --> 00:10:35,720
the underlying

265
00:10:33,519 --> 00:10:37,320
structure another challenge but also a

266
00:10:35,720 --> 00:10:38,720
major opportunity as I said is

267
00:10:37,320 --> 00:10:41,120
structural

268
00:10:38,720 --> 00:10:43,079
heterogenity um so each one of those

269
00:10:41,120 --> 00:10:45,800
images again corresponds to one

270
00:10:43,079 --> 00:10:47,639
completely unique molecule and so this

271
00:10:45,800 --> 00:10:48,920
gives us the ability instead of

272
00:10:47,639 --> 00:10:51,560
reconstructing a single average

273
00:10:48,920 --> 00:10:53,360
structure to reconstruct a full

274
00:10:51,560 --> 00:10:54,920
distribution of structures um again

275
00:10:53,360 --> 00:10:56,959
that's a major opportunity that allows

276
00:10:54,920 --> 00:11:01,240
us to understand more about biology but

277
00:10:56,959 --> 00:11:01,240
also presents challenges

278
00:11:01,639 --> 00:11:06,519
and then finally uh after usually long

279
00:11:04,120 --> 00:11:08,440
processing pipelines if you achieve a

280
00:11:06,519 --> 00:11:11,040
sufficiently high resolution 3D

281
00:11:08,440 --> 00:11:13,720
reconstruction you can then use that to

282
00:11:11,040 --> 00:11:15,320
guide building an atomic model which is

283
00:11:13,720 --> 00:11:18,839
typically what gets deposited in a

284
00:11:15,320 --> 00:11:18,839
database such as the protein

285
00:11:19,000 --> 00:11:24,360
dat okay so that's a lightning overview

286
00:11:21,959 --> 00:11:27,720
of the cryan processing pipeline um next

287
00:11:24,360 --> 00:11:30,360
I'll talk about how this reconstruction

288
00:11:27,720 --> 00:11:32,519
problem of 2D images 3D structure has

289
00:11:30,360 --> 00:11:34,519
traditionally been tackled quick

290
00:11:32,519 --> 00:11:36,519
question yeah can can you briefly

291
00:11:34,519 --> 00:11:40,639
address the difference between cryo em

292
00:11:36,519 --> 00:11:42,200
and cryo ET sure yeah um so in actually

293
00:11:40,639 --> 00:11:46,399
yeah this is a good side to explain that

294
00:11:42,200 --> 00:11:50,160
on so in cry em so there's your sample

295
00:11:46,399 --> 00:11:51,120
and we acquire just one one micrograph

296
00:11:50,160 --> 00:11:55,200
one

297
00:11:51,120 --> 00:11:57,519
image um in cry we then tilt the sample

298
00:11:55,200 --> 00:11:59,800
and acquire multiple different views of

299
00:11:57,519 --> 00:12:02,200
the same sample and so you can

300
00:11:59,800 --> 00:12:04,839
essentially treat cry cry stands for

301
00:12:02,200 --> 00:12:07,040
tomography so you can treat cry as the

302
00:12:04,839 --> 00:12:10,600
multi view version of crym and the

303
00:12:07,040 --> 00:12:11,920
reason why that's helpful um is because

304
00:12:10,600 --> 00:12:14,680
especially when you want to study

305
00:12:11,920 --> 00:12:16,800
structure within the cellular context so

306
00:12:14,680 --> 00:12:19,120
you know you want to look at these

307
00:12:16,800 --> 00:12:21,399
molecules in the context of membranes

308
00:12:19,120 --> 00:12:24,079
and organel um and you know other

309
00:12:21,399 --> 00:12:26,000
aspects of the cell uh you typically

310
00:12:24,079 --> 00:12:27,680
want you know a full 3d reconstruction

311
00:12:26,000 --> 00:12:29,800
of the sample containing all those

312
00:12:27,680 --> 00:12:31,440
different organal um

313
00:12:29,800 --> 00:12:33,040
and so yeah that's where a situation

314
00:12:31,440 --> 00:12:34,680
where tomography can be helpful where

315
00:12:33,040 --> 00:12:36,120
you acquire multiple views at different

316
00:12:34,680 --> 00:12:38,320
angles and then you can do a back

317
00:12:36,120 --> 00:12:40,760
projection to get um you know a full

318
00:12:38,320 --> 00:12:42,600
tomographic volume so I guess that for

319
00:12:40,760 --> 00:12:44,360
that one you wouldn't go about with

320
00:12:42,600 --> 00:12:47,120
purification so this one you would

321
00:12:44,360 --> 00:12:48,959
purify the protein before you do cryoem

322
00:12:47,120 --> 00:12:54,360
and there you would just use like a cell

323
00:12:48,959 --> 00:12:58,920
or a tissue directly yeah exactly yeah

324
00:12:54,360 --> 00:13:00,920
y um so before talk about reconstruction

325
00:12:58,920 --> 00:13:02,959
uh we first need to build a model of how

326
00:13:00,920 --> 00:13:05,240
these images are

327
00:13:02,959 --> 00:13:08,199
formed and so this equation here is

328
00:13:05,240 --> 00:13:10,120
showing that um so let V be the

329
00:13:08,199 --> 00:13:12,639
underlying structure so here I'm just

330
00:13:10,120 --> 00:13:13,959
assuming homogeneity so we just have one

331
00:13:12,639 --> 00:13:15,800
single structure that doesn't have any

332
00:13:13,959 --> 00:13:18,320
confirmational changes so we're going to

333
00:13:15,800 --> 00:13:21,040
call that structure V any one of these

334
00:13:18,320 --> 00:13:25,040
images is obtained by projecting that

335
00:13:21,040 --> 00:13:28,079
volume along some direction some angle

336
00:13:25,040 --> 00:13:29,639
that angle I'm going to call f i and P

337
00:13:28,079 --> 00:13:31,079
is just the projection operator

338
00:13:29,639 --> 00:13:33,279
essentially integrating or summing

339
00:13:31,079 --> 00:13:36,000
across that volume

340
00:13:33,279 --> 00:13:37,839
projection that image is then uh

341
00:13:36,000 --> 00:13:40,440
corrupted with the contrast transfer

342
00:13:37,839 --> 00:13:41,959
function which describes the aberration

343
00:13:40,440 --> 00:13:44,639
of the

344
00:13:41,959 --> 00:13:47,399
microscope and then finally we add

345
00:13:44,639 --> 00:13:51,199
gaussian noise this noise corresponds to

346
00:13:47,399 --> 00:13:53,320
shot noise of the microscope detector um

347
00:13:51,199 --> 00:13:54,639
sort of owing to the quantum random

348
00:13:53,320 --> 00:13:58,040
nature of

349
00:13:54,639 --> 00:13:59,759
electrons and so that forms uh one image

350
00:13:58,040 --> 00:14:03,199
which we denote by

351
00:13:59,759 --> 00:14:05,399
XI um another Point actually this this

352
00:14:03,199 --> 00:14:07,360
fii this orientation or this pose I

353
00:14:05,399 --> 00:14:09,320
talked about actually consists of two

354
00:14:07,360 --> 00:14:11,199
components so one is a random

355
00:14:09,320 --> 00:14:13,440
orientation of this molecule within the

356
00:14:11,199 --> 00:14:15,440
sample the second is a 2d translation

357
00:14:13,440 --> 00:14:18,880
because when we do our particle picking

358
00:14:15,440 --> 00:14:20,720
uh typically without a 3D reference um

359
00:14:18,880 --> 00:14:22,560
the particles within those 2D images are

360
00:14:20,720 --> 00:14:23,880
going to be a little offs so we both

361
00:14:22,560 --> 00:14:25,560
need to account for this random

362
00:14:23,880 --> 00:14:28,560
orientation as well as this 2D

363
00:14:25,560 --> 00:14:28,560
translation

364
00:14:29,759 --> 00:14:34,160
so then the CM reconstruction problem is

365
00:14:32,160 --> 00:14:37,000
the inverse of that image formation

366
00:14:34,160 --> 00:14:39,600
model where what's observed is a data

367
00:14:37,000 --> 00:14:44,839
set of these exis these images and what

368
00:14:39,600 --> 00:14:44,839
we aim to find is the underlying map

369
00:14:46,519 --> 00:14:52,079
v um a note that just in what follows

370
00:14:50,120 --> 00:14:54,800
I'm going to assume that those contrast

371
00:14:52,079 --> 00:14:57,160
transfer function values C are known and

372
00:14:54,800 --> 00:14:58,199
fixed that's a reasonable assumption

373
00:14:57,160 --> 00:14:59,920
because you can estimate those

374
00:14:58,199 --> 00:15:02,560
parameters to typically earlier in

375
00:14:59,920 --> 00:15:05,320
processing in the 2D stage um however

376
00:15:02,560 --> 00:15:06,360
again the poses are unknown um and so

377
00:15:05,320 --> 00:15:08,839
that is something we're going to have to

378
00:15:06,360 --> 00:15:08,839
estimate

379
00:15:13,000 --> 00:15:19,959
yeah I guess uh for the gaussian noise

380
00:15:16,160 --> 00:15:21,880
uh model is this kind of is this

381
00:15:19,959 --> 00:15:23,680
actually backed by the the data as in if

382
00:15:21,880 --> 00:15:25,360
I run it on something blank I get out

383
00:15:23,680 --> 00:15:28,759
gaussian noise or is this just to make

384
00:15:25,360 --> 00:15:31,240
it tractable and easy to solve post fact

385
00:15:28,759 --> 00:15:34,240
um in terms of being physically

386
00:15:31,240 --> 00:15:37,000
realistic it's there are more realistic

387
00:15:34,240 --> 00:15:40,040
models um so it is shot or more like

388
00:15:37,000 --> 00:15:42,959
aonian noise uh and also the forward

389
00:15:40,040 --> 00:15:44,279
model even in the forward model uh

390
00:15:42,959 --> 00:15:47,519
treating it as a just straight

391
00:15:44,279 --> 00:15:50,279
projection is uh usually a reasonable

392
00:15:47,519 --> 00:15:51,639
assumption but you can have even more

393
00:15:50,279 --> 00:15:54,920
expressive models where you do like

394
00:15:51,639 --> 00:15:56,480
multi slice wave propagation um and yeah

395
00:15:54,920 --> 00:15:59,120
so sorry so should I think of this as

396
00:15:56,480 --> 00:16:01,160
like a counts of how many times I'm like

397
00:15:59,120 --> 00:16:03,399
my Imaging modality kind of went through

398
00:16:01,160 --> 00:16:06,079
and hit the sensor underneath I so it's

399
00:16:03,399 --> 00:16:07,000
fully a positive kind of uh thing that

400
00:16:06,079 --> 00:16:10,040
I'm

401
00:16:07,000 --> 00:16:12,079
observing uh yes it is an electron count

402
00:16:10,040 --> 00:16:15,680
yeah interesting

403
00:16:12,079 --> 00:16:18,720
thanks yes uh hi sorry one more question

404
00:16:15,680 --> 00:16:21,000
um why do you like if you're

405
00:16:18,720 --> 00:16:23,680
automatically segmenting out the

406
00:16:21,000 --> 00:16:25,560
particles like why wouldn't you just

407
00:16:23,680 --> 00:16:29,440
assume that they were

408
00:16:25,560 --> 00:16:32,720
centered like if you're just yeah yeah

409
00:16:29,440 --> 00:16:35,519
so they'll be they'll the particles will

410
00:16:32,720 --> 00:16:38,639
be centered with respect to the image

411
00:16:35,519 --> 00:16:40,480
that they're in but once you when you

412
00:16:38,639 --> 00:16:43,319
need to combine all these images into a

413
00:16:40,480 --> 00:16:45,399
3D reconstruction you then are going to

414
00:16:43,319 --> 00:16:48,000
have to sort of shift those images a

415
00:16:45,399 --> 00:16:50,600
little without a 3D reference the notion

416
00:16:48,000 --> 00:16:53,600
of a center for a 2D image is still

417
00:16:50,600 --> 00:16:53,600
defin

418
00:16:54,120 --> 00:16:59,360
yeah okay um so this is the the problem

419
00:16:57,600 --> 00:17:01,720
we interested in again so we observing

420
00:16:59,360 --> 00:17:03,520
the xise these images and we aim to

421
00:17:01,720 --> 00:17:05,360
recover the underlying

422
00:17:03,520 --> 00:17:07,640
structure

423
00:17:05,360 --> 00:17:09,000
um we can think of this in a

424
00:17:07,640 --> 00:17:12,679
probabilistic

425
00:17:09,000 --> 00:17:15,839
framework um and so we can frame the

426
00:17:12,679 --> 00:17:17,959
Reconstruction problem as finding a set

427
00:17:15,839 --> 00:17:20,600
of parameters so the structures and

428
00:17:17,959 --> 00:17:23,679
these orientations that maximizes the

429
00:17:20,600 --> 00:17:26,240
likelihood of the data given the

430
00:17:23,679 --> 00:17:29,039
parameters each one of those images is

431
00:17:26,240 --> 00:17:30,400
independent so the full likelihood is

432
00:17:29,039 --> 00:17:32,200
just going to be the product of the

433
00:17:30,400 --> 00:17:34,600
individual likelihoods of observing each

434
00:17:32,200 --> 00:17:34,600
of those

435
00:17:35,120 --> 00:17:39,440
images One sort of assumption we can

436
00:17:37,440 --> 00:17:41,880
make at this phase is the thing we

437
00:17:39,440 --> 00:17:44,760
really care about is optimizing that

438
00:17:41,880 --> 00:17:47,360
volume v and those particle orientations

439
00:17:44,760 --> 00:17:50,360
or poses are just nuisance parameters um

440
00:17:47,360 --> 00:17:53,559
that we don't directly care about and so

441
00:17:50,360 --> 00:17:55,559
we can marginalize over all those

442
00:17:53,559 --> 00:17:58,200
poses

443
00:17:55,559 --> 00:18:00,600
um the marginalization is over the space

444
00:17:58,200 --> 00:18:03,919
of poses which consists of an element of

445
00:18:00,600 --> 00:18:07,159
s SO3 so rotations and an element of uh

446
00:18:03,919 --> 00:18:07,159
R2 which is a

447
00:18:08,400 --> 00:18:13,480
2d okay so from this all we need is

448
00:18:11,520 --> 00:18:15,600
really an expression for this so what is

449
00:18:13,480 --> 00:18:19,320
the likelihood of a single image given a

450
00:18:15,600 --> 00:18:21,200
volume and a pose to get that we can

451
00:18:19,320 --> 00:18:23,919
think back to our image formation model

452
00:18:21,200 --> 00:18:26,200
so again we said an image is formed by

453
00:18:23,919 --> 00:18:29,039
projecting this volume and then adding

454
00:18:26,200 --> 00:18:30,919
some gausian noise alternatively we can

455
00:18:29,039 --> 00:18:33,559
reformulate that by saying that the

456
00:18:30,919 --> 00:18:35,120
image itself is a sample from some

457
00:18:33,559 --> 00:18:37,559
gaussian multivaried gausian

458
00:18:35,120 --> 00:18:40,039
distribution centered on that clean

459
00:18:37,559 --> 00:18:42,440
projection image with and with the

460
00:18:40,039 --> 00:18:42,440
variant

461
00:18:42,600 --> 00:18:47,919
Sigma and so given that interpretation

462
00:18:45,400 --> 00:18:50,039
of the image uh the likelihood of

463
00:18:47,919 --> 00:18:51,760
observing these image the image given

464
00:18:50,039 --> 00:18:54,760
the model of parameters is just going to

465
00:18:51,760 --> 00:18:57,720
be what you get when you plug um the

466
00:18:54,760 --> 00:19:00,760
image to the gaussian PDF for the

467
00:18:57,720 --> 00:19:03,039
multivaried gausian centered on this

468
00:19:00,760 --> 00:19:05,440
mean which is the clean image um and

469
00:19:03,039 --> 00:19:08,120
with that Sigma and so you know if you

470
00:19:05,440 --> 00:19:11,240
recall sort of the gaan PDF this takes a

471
00:19:08,120 --> 00:19:15,120
form like this it's sort of the L2 Norm

472
00:19:11,240 --> 00:19:19,120
between um the point and the mean with

473
00:19:15,120 --> 00:19:19,120
this you know normalization constant out

474
00:19:20,400 --> 00:19:27,159
front okay

475
00:19:24,120 --> 00:19:28,960
sorry okay so we have this expression

476
00:19:27,159 --> 00:19:30,360
for the full likelihood we have this

477
00:19:28,960 --> 00:19:31,919
expression for the likelihood of a

478
00:19:30,360 --> 00:19:34,280
single image so all we have to do is

479
00:19:31,919 --> 00:19:37,559
then take this and and plug it into

480
00:19:34,280 --> 00:19:41,000
there oh can I can I ask a question yeah

481
00:19:37,559 --> 00:19:43,840
you said that like the uh the protein

482
00:19:41,000 --> 00:19:46,480
itself is in a range of confirmations so

483
00:19:43,840 --> 00:19:49,919
is the V also like a distribution the

484
00:19:46,480 --> 00:19:52,120
cryoem density oh yeah so uh in what I'm

485
00:19:49,919 --> 00:19:54,600
showing here I'm assuming that this is a

486
00:19:52,120 --> 00:19:57,000
protein that is static so we just have

487
00:19:54,600 --> 00:19:59,840
one underlying structure um I'll I'll

488
00:19:57,000 --> 00:20:02,400
sort of build up to the case of having

489
00:19:59,840 --> 00:20:02,400
yeah that full

490
00:20:03,080 --> 00:20:07,240
distribution so we can take that uh you

491
00:20:05,799 --> 00:20:08,640
know the single image likelihood plug it

492
00:20:07,240 --> 00:20:10,320
into the total likelihood you get an

493
00:20:08,640 --> 00:20:12,240
expression like that um and then the

494
00:20:10,320 --> 00:20:15,799
optimization problem essentially ends up

495
00:20:12,240 --> 00:20:19,159
being maximizing that full likelihood

496
00:20:15,799 --> 00:20:20,840
with respect to the volume B and you get

497
00:20:19,159 --> 00:20:23,840
an expression like

498
00:20:20,840 --> 00:20:23,840
that

499
00:20:24,360 --> 00:20:29,600
um so again this expression is saying

500
00:20:27,440 --> 00:20:32,360
that you know we want to find the volume

501
00:20:29,600 --> 00:20:35,360
v that you know maximize the likelihood

502
00:20:32,360 --> 00:20:36,240
over all the images again marginalizing

503
00:20:35,360 --> 00:20:39,760
over the

504
00:20:36,240 --> 00:20:41,919
poses unfortunately this expression is

505
00:20:39,760 --> 00:20:44,400
intractable we won't be able to solve

506
00:20:41,919 --> 00:20:47,559
for V in a close form solution and so we

507
00:20:44,400 --> 00:20:48,880
will need another technique um so the

508
00:20:47,559 --> 00:20:51,080
way this is typically done is

509
00:20:48,880 --> 00:20:53,080
expectation maximization which is a very

510
00:20:51,080 --> 00:20:58,280
common approach in these sort of

511
00:20:53,080 --> 00:21:00,159
problems and the idea is that the um the

512
00:20:58,280 --> 00:21:02,559
margin alized full log likelihood that

513
00:21:00,159 --> 00:21:05,120
we just computed is intractable

514
00:21:02,559 --> 00:21:07,080
unfortunately but we can actually

515
00:21:05,120 --> 00:21:10,200
optimize a different quantity instead

516
00:21:07,080 --> 00:21:12,400
which is this expected log likelihood um

517
00:21:10,200 --> 00:21:14,600
you can read more on the evidence lower

518
00:21:12,400 --> 00:21:17,039
bound or elbow but the basic idea is

519
00:21:14,600 --> 00:21:19,240
that this objective it's not the same as

520
00:21:17,039 --> 00:21:22,000
the true objective I showed but it's a

521
00:21:19,240 --> 00:21:24,159
lower bound on it and by optimizing this

522
00:21:22,000 --> 00:21:26,760
we can get a reasonably good

523
00:21:24,159 --> 00:21:31,039
optimization of the true objective as

524
00:21:26,760 --> 00:21:33,799
well if we take a look at this quantity

525
00:21:31,039 --> 00:21:36,760
that we want to optimize um there two

526
00:21:33,799 --> 00:21:38,760
ways to sort of maximize this right one

527
00:21:36,760 --> 00:21:41,520
so this is ex this is saying this is an

528
00:21:38,760 --> 00:21:44,120
expectation of this log likelihood over

529
00:21:41,520 --> 00:21:45,640
the space of poses and so to maximize

530
00:21:44,120 --> 00:21:48,600
this there essentially two things we can

531
00:21:45,640 --> 00:21:50,440
do one is to draw these poses from a

532
00:21:48,600 --> 00:21:52,159
distribution that matches the true

533
00:21:50,440 --> 00:21:54,400
distribution of

534
00:21:52,159 --> 00:21:56,679
poses the second thing we can do is

535
00:21:54,400 --> 00:21:58,840
choosing a volume that that maximizes

536
00:21:56,679 --> 00:22:00,559
this expectation um and so the M

537
00:21:58,840 --> 00:22:03,720
algorithm is essentially alternating

538
00:22:00,559 --> 00:22:07,880
between these two steps in the Eep what

539
00:22:03,720 --> 00:22:10,600
we're doing is estimating the best um

540
00:22:07,880 --> 00:22:14,880
estimating the likelihood of different

541
00:22:10,600 --> 00:22:17,320
poses so um first of all okay recall

542
00:22:14,880 --> 00:22:19,159
that the post space is is continuous

543
00:22:17,320 --> 00:22:20,600
right both translations and rotations in

544
00:22:19,159 --> 00:22:23,320
order to make things easier for us we're

545
00:22:20,600 --> 00:22:25,000
going to discretize um into sort of set

546
00:22:23,320 --> 00:22:27,679
of candidate poses that we want to

547
00:22:25,000 --> 00:22:30,279
evaluate and so this is saying that in

548
00:22:27,679 --> 00:22:32,799
the Eep for each one of those images

549
00:22:30,279 --> 00:22:35,080
we're going to evaluate uh you know How

550
00:22:32,799 --> 00:22:37,279
likely is that image to arise from each

551
00:22:35,080 --> 00:22:39,640
of those candidate poses and so we

552
00:22:37,279 --> 00:22:42,799
essentially get a posterior distribution

553
00:22:39,640 --> 00:22:43,720
um of of again How likely each pose is

554
00:22:42,799 --> 00:22:47,120
for that

555
00:22:43,720 --> 00:22:49,840
image and then the M step is given those

556
00:22:47,120 --> 00:22:52,440
estimates of the poses then choosing a

557
00:22:49,840 --> 00:22:55,760
volum that that maximizes that

558
00:22:52,440 --> 00:22:57,559
expectation um so again key idea we're

559
00:22:55,760 --> 00:23:00,799
just going to alternate between a

560
00:22:57,559 --> 00:23:05,200
optimizing the orientations or poses and

561
00:23:00,799 --> 00:23:08,039
then optimizing the volume given those

562
00:23:05,200 --> 00:23:10,760
orientations luckily uh this is you know

563
00:23:08,039 --> 00:23:13,520
sort of a complex equation but um the

564
00:23:10,760 --> 00:23:15,960
key takeaway is that this form of the

565
00:23:13,520 --> 00:23:18,720
objective does have a closed form

566
00:23:15,960 --> 00:23:21,240
solution so by going from that original

567
00:23:18,720 --> 00:23:24,760
objective to this lower bound but we end

568
00:23:21,240 --> 00:23:30,159
up with is um an explicit expression for

569
00:23:24,760 --> 00:23:33,720
the volume that maximizes that objective

570
00:23:30,159 --> 00:23:36,279
and if you try to interpret what this is

571
00:23:33,720 --> 00:23:40,559
saying it's saying that the optimal

572
00:23:36,279 --> 00:23:43,840
volume is essentially in 3D

573
00:23:40,559 --> 00:23:46,360
space taking all your images and

574
00:23:43,840 --> 00:23:50,159
basically taking a weighted sum over

575
00:23:46,360 --> 00:23:53,200
them so every image for every single

576
00:23:50,159 --> 00:23:54,840
orientation taking this weighted sum

577
00:23:53,200 --> 00:23:56,600
where the weights are higher for

578
00:23:54,840 --> 00:24:00,440
orientations that are sort of more

579
00:23:56,600 --> 00:24:03,520
likely to produce that image

580
00:24:00,440 --> 00:24:06,200
um just to make this more intuitive uh

581
00:24:03,520 --> 00:24:08,320
here is a graphic so again the Eep

582
00:24:06,200 --> 00:24:10,919
consists of estimating the best

583
00:24:08,320 --> 00:24:14,640
orientation parameters given the current

584
00:24:10,919 --> 00:24:18,919
volume so here's let's say our current

585
00:24:14,640 --> 00:24:21,279
volume we can create a bunch of we can

586
00:24:18,919 --> 00:24:23,720
use the forward simulation model to

587
00:24:21,279 --> 00:24:27,120
create a bunch of clean projection

588
00:24:23,720 --> 00:24:29,760
images for each of those candidate poses

589
00:24:27,120 --> 00:24:32,360
and then we can compare each of those

590
00:24:29,760 --> 00:24:34,720
projection images against the True Image

591
00:24:32,360 --> 00:24:36,880
and compute the error between them this

592
00:24:34,720 --> 00:24:39,480
will give us a sense of which ones of

593
00:24:36,880 --> 00:24:41,200
those candidate poses were good poses

594
00:24:39,480 --> 00:24:43,480
which ones of those were likely and

595
00:24:41,200 --> 00:24:45,640
which of those is

596
00:24:43,480 --> 00:24:47,440
unlikely and so this gives us that

597
00:24:45,640 --> 00:24:49,080
reprojection era gives us these weights

598
00:24:47,440 --> 00:24:51,159
of you know what again what poses are

599
00:24:49,080 --> 00:24:56,320
the most likely so given those estimates

600
00:24:51,159 --> 00:24:58,039
of the poses the M step is then

601
00:24:56,320 --> 00:24:59,039
essentially back projecting all those

602
00:24:58,039 --> 00:25:02,320
images

603
00:24:59,039 --> 00:25:03,880
according to the poses um when say back

604
00:25:02,320 --> 00:25:05,720
projection you can think of it as the

605
00:25:03,880 --> 00:25:08,080
inverse of the projection operator right

606
00:25:05,720 --> 00:25:09,919
so for projection we took this volume

607
00:25:08,080 --> 00:25:11,960
and we essentially integrated or summed

608
00:25:09,919 --> 00:25:14,240
we did a projection back projection

609
00:25:11,960 --> 00:25:16,320
essentially corresponds to doing the

610
00:25:14,240 --> 00:25:18,200
opposite process taking this 2D and

611
00:25:16,320 --> 00:25:19,919
going back into 3D what does that

612
00:25:18,200 --> 00:25:23,000
actually mean I think it's easier to

613
00:25:19,919 --> 00:25:24,840
interpret um in Fier space so far I've

614
00:25:23,000 --> 00:25:27,799
been talking about you know the real

615
00:25:24,840 --> 00:25:31,360
physical space um fora space is the

616
00:25:27,799 --> 00:25:33,360
space of uh spatial frequencies and so

617
00:25:31,360 --> 00:25:35,919
in this space according to something

618
00:25:33,360 --> 00:25:37,799
called the Fier slice theorem in real

619
00:25:35,919 --> 00:25:39,720
space again you have a volume you

620
00:25:37,799 --> 00:25:42,760
project it you get a 2D image it turns

621
00:25:39,720 --> 00:25:45,520
out in Fier space um that the Fier

622
00:25:42,760 --> 00:25:48,279
transform of an image is a central slice

623
00:25:45,520 --> 00:25:51,679
of the forier transform of the volume so

624
00:25:48,279 --> 00:25:53,960
the image is just the slice of the

625
00:25:51,679 --> 00:25:56,159
forier volume and so that's what we mean

626
00:25:53,960 --> 00:25:58,000
when we say back projection when we say

627
00:25:56,159 --> 00:25:59,960
we back project an image According to

628
00:25:58,000 --> 00:26:02,679
some pose it means we're just going to

629
00:25:59,960 --> 00:26:06,039
insert that image into the 3D Volume

630
00:26:02,679 --> 00:26:07,600
along some orientation in 4A space and

631
00:26:06,039 --> 00:26:10,640
this corresponds to the inverse of the

632
00:26:07,600 --> 00:26:13,760
forward operation so again just to recap

633
00:26:10,640 --> 00:26:15,880
Eep estimate the best poses M step

634
00:26:13,760 --> 00:26:18,600
according to those best poses basically

635
00:26:15,880 --> 00:26:20,559
place all these images back and do a

636
00:26:18,600 --> 00:26:22,760
back projection in order to recover the

637
00:26:20,559 --> 00:26:24,960
underlying volume and keep iterating

638
00:26:22,760 --> 00:26:27,320
going back and forth between these two

639
00:26:24,960 --> 00:26:29,440
steps so this is like a very general

640
00:26:27,320 --> 00:26:32,640
framework for how to to do

641
00:26:29,440 --> 00:26:34,360
reconstruction um you know it's not even

642
00:26:32,640 --> 00:26:36,039
specific to cryo this is sort of a you

643
00:26:34,360 --> 00:26:38,000
know a general way of formulating any

644
00:26:36,039 --> 00:26:40,679
sort of tomographic reconstruction

645
00:26:38,000 --> 00:26:42,559
problem um specifically in cryo there

646
00:26:40,679 --> 00:26:44,159
are some remaining challenges which

647
00:26:42,559 --> 00:26:48,240
prevent that procedure from being

648
00:26:44,159 --> 00:26:50,120
effective and that's a a one just

649
00:26:48,240 --> 00:26:52,919
property of the expectation maximization

650
00:26:50,120 --> 00:26:55,320
algorithm is that it always improves the

651
00:26:52,919 --> 00:26:57,200
likelihood uh but that also means that

652
00:26:55,320 --> 00:27:00,200
it will probably get stuck in a local

653
00:26:57,200 --> 00:27:02,159
Optima unless you initialize it properly

654
00:27:00,200 --> 00:27:04,520
second as we see these images are

655
00:27:02,159 --> 00:27:07,320
extremely noisy and so during this

656
00:27:04,520 --> 00:27:09,600
process of aligning images to the volume

657
00:27:07,320 --> 00:27:12,080
it's very easy to overfit to the noise

658
00:27:09,600 --> 00:27:14,360
in the images rather than the underlying

659
00:27:12,080 --> 00:27:17,200
signal um and so we need some strategies

660
00:27:14,360 --> 00:27:18,880
for dealing with both these problems for

661
00:27:17,200 --> 00:27:20,720
dealing with the first problem of how do

662
00:27:18,880 --> 00:27:23,760
we deal with initialization so that em

663
00:27:20,720 --> 00:27:27,640
actually converges uh

664
00:27:23,760 --> 00:27:30,399
one uh Innovation introduced around 2017

665
00:27:27,640 --> 00:27:32,720
by this software package cryos spark was

666
00:27:30,399 --> 00:27:34,840
to you know before directly running the

667
00:27:32,720 --> 00:27:36,559
expectation maximization algorithm on a

668
00:27:34,840 --> 00:27:39,159
completely random initialization of the

669
00:27:36,559 --> 00:27:41,000
volume they first do gradient descent on

670
00:27:39,159 --> 00:27:43,120
that true objective so this is the true

671
00:27:41,000 --> 00:27:44,240
objective that we initially derived even

672
00:27:43,120 --> 00:27:46,000
though we don't have a close form

673
00:27:44,240 --> 00:27:48,279
solution for it we can do gradient

674
00:27:46,000 --> 00:27:50,360
descent on it um and so they start out

675
00:27:48,279 --> 00:27:52,320
just doing gradient descent to optimize

676
00:27:50,360 --> 00:27:55,279
the volume with respect to that true

677
00:27:52,320 --> 00:27:58,320
objective that gives you not a great

678
00:27:55,279 --> 00:28:00,519
volume but a reasonable initialization

679
00:27:58,320 --> 00:28:01,919
you can then feature the EM algorithm uh

680
00:28:00,519 --> 00:28:05,480
to increase the chances of actually

681
00:28:01,919 --> 00:28:05,480
finding that Global

682
00:28:05,919 --> 00:28:11,399
minimum the second Innovation pertaining

683
00:28:08,799 --> 00:28:14,039
to how do we prevent overfitting our

684
00:28:11,399 --> 00:28:15,919
parameters to the noise in the images uh

685
00:28:14,039 --> 00:28:18,159
this was introduced by

686
00:28:15,919 --> 00:28:20,399
ReliOn uh which is a different software

687
00:28:18,159 --> 00:28:22,000
package and the idea is that the

688
00:28:20,399 --> 00:28:24,640
objective I presented was the maximum

689
00:28:22,000 --> 00:28:26,640
likelihood estimator but you can also

690
00:28:24,640 --> 00:28:30,440
formulate this in a basan framework and

691
00:28:26,640 --> 00:28:35,240
do a maximum uh a posterior

692
00:28:30,440 --> 00:28:36,840
posterior uh uh objective um so the map

693
00:28:35,240 --> 00:28:39,840
estimator is going to have the mle

694
00:28:36,840 --> 00:28:42,480
objective along with this prior term

695
00:28:39,840 --> 00:28:42,480
which serves as

696
00:28:42,559 --> 00:28:49,440
regularization that prior term is

697
00:28:46,039 --> 00:28:53,240
typically just saying that each of the

698
00:28:49,440 --> 00:28:54,480
Fier components so each of those um the

699
00:28:53,240 --> 00:28:56,799
powers of each of the spatial

700
00:28:54,480 --> 00:29:00,000
frequencies within the volume is drawn

701
00:28:56,799 --> 00:29:04,480
from a zero mean I uh it's a relatively

702
00:29:00,000 --> 00:29:06,960
simple prior uh but the variance of that

703
00:29:04,480 --> 00:29:09,320
prior is usually also optimized during

704
00:29:06,960 --> 00:29:11,679
this process um and the idea is that we

705
00:29:09,320 --> 00:29:14,240
can sort of estimate reasonable

706
00:29:11,679 --> 00:29:16,919
frequency dependent variances depending

707
00:29:14,240 --> 00:29:20,200
on our sort of known knowledge of the

708
00:29:16,919 --> 00:29:22,760
power spectrum of of crym images um so

709
00:29:20,200 --> 00:29:25,240
this essentially just provides a form of

710
00:29:22,760 --> 00:29:28,279
regularization uh where especially early

711
00:29:25,240 --> 00:29:29,880
in training when the amount of

712
00:29:28,279 --> 00:29:33,120
information content that those high

713
00:29:29,880 --> 00:29:35,640
frequencies is quite low this object uh

714
00:29:33,120 --> 00:29:37,519
this regularization um sort of prevents

715
00:29:35,640 --> 00:29:39,360
overfitting to those high frequencies

716
00:29:37,519 --> 00:29:42,279
and sort of dampens those components

717
00:29:39,360 --> 00:29:42,279
early on in the

718
00:29:42,559 --> 00:29:47,360
process okay so that's sort of the EM

719
00:29:45,360 --> 00:29:49,760
algorithm question was just asked on how

720
00:29:47,360 --> 00:29:51,320
do we actually discretize the poses so

721
00:29:49,760 --> 00:29:54,240
again the specific um thing we're

722
00:29:51,320 --> 00:29:56,440
interested in is again I presented uh

723
00:29:54,240 --> 00:29:58,360
this way of optimizing the volumes and I

724
00:29:56,440 --> 00:30:00,240
said we can take that integration over

725
00:29:58,360 --> 00:30:01,919
the entire space of poses and turn it

726
00:30:00,240 --> 00:30:03,760
into a sum over a discrete set of

727
00:30:01,919 --> 00:30:07,039
candidate poses so one question is how

728
00:30:03,760 --> 00:30:09,000
do we actually dis discretize the space

729
00:30:07,039 --> 00:30:10,799
um so we can think about how to do it uh

730
00:30:09,000 --> 00:30:13,360
what if we just brute force it right so

731
00:30:10,799 --> 00:30:16,760
what if we take the space of poses and

732
00:30:13,360 --> 00:30:18,399
just break it up into a really fine grid

733
00:30:16,760 --> 00:30:21,360
uh that's not going to work because if

734
00:30:18,399 --> 00:30:24,519
you look at uh you know how many poses

735
00:30:21,360 --> 00:30:26,200
we'd have to get you know one degree one

736
00:30:24,519 --> 00:30:28,600
degree of rotation error it would

737
00:30:26,200 --> 00:30:30,840
correspond to nearly 19 million

738
00:30:28,600 --> 00:30:33,440
different poses and you can do some back

739
00:30:30,840 --> 00:30:36,240
of the envelope math if you have a if

740
00:30:33,440 --> 00:30:39,919
your images are of size you know 128 by

741
00:30:36,240 --> 00:30:41,360
128 um even for a single image Computing

742
00:30:39,919 --> 00:30:42,799
like a repr projection error doing a

743
00:30:41,360 --> 00:30:46,320
back projection it's going to be on the

744
00:30:42,799 --> 00:30:47,919
order of 310 billion operations now we

745
00:30:46,320 --> 00:30:50,799
have you know hundreds of thousands or

746
00:30:47,919 --> 00:30:53,200
millions of images larger images and we

747
00:30:50,799 --> 00:30:55,519
need to run em you know in an iterative

748
00:30:53,200 --> 00:30:57,720
man and so this just becomes completely

749
00:30:55,519 --> 00:31:00,200
intractable and so we need a strategy

750
00:30:57,720 --> 00:31:02,600
for for discretizing the space better

751
00:31:00,200 --> 00:31:05,080
and so we're going to do two

752
00:31:02,600 --> 00:31:07,880
things um and they're both sort of based

753
00:31:05,080 --> 00:31:09,600
on this observation that in general the

754
00:31:07,880 --> 00:31:13,360
the error

755
00:31:09,600 --> 00:31:15,679
between uh the pose error is uh smooth

756
00:31:13,360 --> 00:31:17,840
with respect to the pose

757
00:31:15,679 --> 00:31:20,039
meaning you know it doesn't jump around

758
00:31:17,840 --> 00:31:22,639
a lot right this is the optimal pose as

759
00:31:20,039 --> 00:31:24,919
I move away from the pose it sort of

760
00:31:22,639 --> 00:31:27,600
there sort of falls off gradually so we

761
00:31:24,919 --> 00:31:28,799
can make use of this observation to do a

762
00:31:27,600 --> 00:31:31,880
couple of of her

763
00:31:28,799 --> 00:31:33,600
istics um and again so they're based on

764
00:31:31,880 --> 00:31:35,240
this idea again that we have large areas

765
00:31:33,600 --> 00:31:37,360
of post space that are either good or

766
00:31:35,240 --> 00:31:40,320
bad so we can reject large areas at a

767
00:31:37,360 --> 00:31:43,320
time the first idea is subdivision or

768
00:31:40,320 --> 00:31:45,120
hierarchical git search uh which says

769
00:31:43,320 --> 00:31:47,559
you know we can start out with a very

770
00:31:45,120 --> 00:31:50,399
coarse sampling of poses so split up the

771
00:31:47,559 --> 00:31:52,880
space very coarsely you know find the

772
00:31:50,399 --> 00:31:55,679
best poses within this coar space only

773
00:31:52,880 --> 00:31:58,919
take the best ones divide them up even

774
00:31:55,679 --> 00:32:01,080
more search again take the best ones

775
00:31:58,919 --> 00:32:04,639
divide them further search again and

776
00:32:01,080 --> 00:32:08,399
essentially um you only evaluate the

777
00:32:04,639 --> 00:32:11,600
really fine uh fine samplings for just a

778
00:32:08,399 --> 00:32:14,919
few poses instead of all of

779
00:32:11,600 --> 00:32:18,240
them that's one idea um the second idea

780
00:32:14,919 --> 00:32:19,480
is that when we compute um when we

781
00:32:18,240 --> 00:32:21,320
compute that pose error that

782
00:32:19,480 --> 00:32:25,240
reprojection error between you know this

783
00:32:21,320 --> 00:32:27,279
clean image and our uh our real image so

784
00:32:25,240 --> 00:32:28,679
again that's that error right so X is

785
00:32:27,279 --> 00:32:32,919
the real image

786
00:32:28,679 --> 00:32:35,720
um cpv is that reprojection and taking

787
00:32:32,919 --> 00:32:37,440
the L2 Norm gives us uh measure of the

788
00:32:35,720 --> 00:32:40,240
air between those two things I measure

789
00:32:37,440 --> 00:32:42,320
how good that poses we note that this is

790
00:32:40,240 --> 00:32:44,240
just summing over all the pixels right

791
00:32:42,320 --> 00:32:46,080
so just compute the error pixel by pixel

792
00:32:44,240 --> 00:32:49,519
sum over all of them which means we can

793
00:32:46,080 --> 00:32:51,200
also split it up into two terms one

794
00:32:49,519 --> 00:32:52,679
corresponding to just low frequency

795
00:32:51,200 --> 00:32:54,000
components of the image and one

796
00:32:52,679 --> 00:32:56,440
corresponding to the high frequency

797
00:32:54,000 --> 00:32:57,880
components of the image and now one key

798
00:32:56,440 --> 00:33:00,200
observation we can make is that

799
00:32:57,880 --> 00:33:03,120
typically this POS estimation process

800
00:33:00,200 --> 00:33:05,279
aligning these images is dominated by

801
00:33:03,120 --> 00:33:07,120
low frequency components and so we can

802
00:33:05,279 --> 00:33:09,760
actually ignore those higher frequency

803
00:33:07,120 --> 00:33:15,000
terms and only compute the error on the

804
00:33:09,760 --> 00:33:17,600
low frequency terms um and so that

805
00:33:15,000 --> 00:33:19,159
is that is a cheaper right because we're

806
00:33:17,600 --> 00:33:21,000
only Computing it on a subset of the

807
00:33:19,159 --> 00:33:22,960
frequencies uh but it also actually

808
00:33:21,000 --> 00:33:25,440
improves the alignment because you know

809
00:33:22,960 --> 00:33:28,840
it avoids again sort of aligning to the

810
00:33:25,440 --> 00:33:31,360
higher frequency noise comp um and in

811
00:33:28,840 --> 00:33:32,720
practice uh you know one question is

812
00:33:31,360 --> 00:33:35,639
like how do you actually choose what

813
00:33:32,720 --> 00:33:38,440
constitutes low frequency typically uh

814
00:33:35,639 --> 00:33:40,559
the bandwidth is increased over time so

815
00:33:38,440 --> 00:33:42,519
very early on training uh when you don't

816
00:33:40,559 --> 00:33:44,919
have a good volume you just have a blob

817
00:33:42,519 --> 00:33:46,919
you use a very low value of L meaning

818
00:33:44,919 --> 00:33:49,480
you only evaluate these errors on the

819
00:33:46,919 --> 00:33:51,360
very low frequencies and as you progress

820
00:33:49,480 --> 00:33:52,919
in training you just keep increasing to

821
00:33:51,360 --> 00:33:54,679
include higher and higher frequency

822
00:33:52,919 --> 00:33:58,360
components as you build up this higher

823
00:33:54,679 --> 00:33:58,360
resolution Rec Construction

824
00:33:59,240 --> 00:34:05,279
um one last note is that I've sort of

825
00:34:02,440 --> 00:34:08,079
presented all that with uh in terms of s

826
00:34:05,279 --> 00:34:09,480
SO3 so rotations but like I said we do

827
00:34:08,079 --> 00:34:11,919
also have to estimate these 2D

828
00:34:09,480 --> 00:34:14,280
translational shifts um and doing so we

829
00:34:11,919 --> 00:34:16,440
can use very similar techniques as I

830
00:34:14,280 --> 00:34:18,280
said for the rotations in particular you

831
00:34:16,440 --> 00:34:20,800
know we can still do the sort of

832
00:34:18,280 --> 00:34:24,079
hierarchical grid search discoring the

833
00:34:20,800 --> 00:34:26,599
space of 2D

834
00:34:24,079 --> 00:34:28,480
translations one other note I'll make is

835
00:34:26,599 --> 00:34:30,000
that when I presented the algorithm I

836
00:34:28,480 --> 00:34:33,159
presented in a sort of a purely

837
00:34:30,000 --> 00:34:35,240
probabilistic framework where we um

838
00:34:33,159 --> 00:34:38,280
essentially assigned a like assigned a

839
00:34:35,240 --> 00:34:40,720
probability each possible pose for each

840
00:34:38,280 --> 00:34:42,760
possible image What's Done in practice

841
00:34:40,720 --> 00:34:45,440
in a lot of programs is that instead of

842
00:34:42,760 --> 00:34:48,800
con constructing that full posterior of

843
00:34:45,440 --> 00:34:51,159
poses you actually just take the the

844
00:34:48,800 --> 00:34:53,200
best pose and so you alternate between

845
00:34:51,159 --> 00:34:55,839
estimating the absolute best pose and

846
00:34:53,200 --> 00:34:59,640
then using the best pose to um then

847
00:34:55,839 --> 00:34:59,640
update your volume reconstruction

848
00:35:03,200 --> 00:35:06,720
okay and then finally um so again

849
00:35:05,400 --> 00:35:08,240
everything I presented was through the

850
00:35:06,720 --> 00:35:09,599
lens of homogeneous reconstruction so

851
00:35:08,240 --> 00:35:12,040
assuming we just have one single

852
00:35:09,599 --> 00:35:13,839
underlying static structure uh but now

853
00:35:12,040 --> 00:35:16,040
we can start thinking about how do we

854
00:35:13,839 --> 00:35:18,720
incorporate the structural heterogenity

855
00:35:16,040 --> 00:35:21,400
we have multiple underlying

856
00:35:18,720 --> 00:35:23,440
structures so we can modify our image

857
00:35:21,400 --> 00:35:27,000
formation model so assume we have a

858
00:35:23,440 --> 00:35:29,560
setting like this so here is a ribosome

859
00:35:27,000 --> 00:35:31,520
and this is an ass uming ribosome so

860
00:35:29,560 --> 00:35:34,480
essentially as the ribosome is maturing

861
00:35:31,520 --> 00:35:36,119
different subunits get added on um and

862
00:35:34,480 --> 00:35:38,200
so here we have this case of discrete

863
00:35:36,119 --> 00:35:40,240
heterogenity where each of those images

864
00:35:38,200 --> 00:35:42,760
may arise from one of let's say those

865
00:35:40,240 --> 00:35:45,200
four structures so how do we account for

866
00:35:42,760 --> 00:35:46,839
that where we want to reconstruct all

867
00:35:45,200 --> 00:35:49,839
four of those structures from our

868
00:35:46,839 --> 00:35:51,680
Imaging data um we can modify our image

869
00:35:49,839 --> 00:35:54,000
formation model so now it's going to

870
00:35:51,680 --> 00:35:56,400
look extremely similar except instead of

871
00:35:54,000 --> 00:36:01,079
having just a single V I have this V

872
00:35:56,400 --> 00:36:03,560
indexed by AI where AI is the class um

873
00:36:01,079 --> 00:36:05,480
of of that particular

874
00:36:03,560 --> 00:36:07,240
image so now the multiclass

875
00:36:05,480 --> 00:36:09,319
Reconstruction problem is again instead

876
00:36:07,240 --> 00:36:11,880
of finding a single volume find the

877
00:36:09,319 --> 00:36:13,960
entire set of optimal volumes um

878
00:36:11,880 --> 00:36:15,800
assuming that we have K volumes given

879
00:36:13,960 --> 00:36:18,400
the data again the challenge here is

880
00:36:15,800 --> 00:36:21,040
that all we have is this raw 2D image

881
00:36:18,400 --> 00:36:23,280
data set we don't have labels on each

882
00:36:21,040 --> 00:36:25,760
image of which structure it Rose from so

883
00:36:23,280 --> 00:36:27,760
we'll have to both find the volume but

884
00:36:25,760 --> 00:36:31,560
then also find those class assignments

885
00:36:27,760 --> 00:36:31,560
of which particle belongs to which

886
00:36:31,640 --> 00:36:35,640
volume um I won't go through the the

887
00:36:33,800 --> 00:36:38,359
full derivation here this is just to

888
00:36:35,640 --> 00:36:39,440
show that uh the objective looks very

889
00:36:38,359 --> 00:36:42,560
similar to what we saw in the

890
00:36:39,440 --> 00:36:44,079
homogeneous case so um I'm assuming here

891
00:36:42,560 --> 00:36:45,520
that we know the poses ahead of time

892
00:36:44,079 --> 00:36:47,520
that's actually a reasonable assumption

893
00:36:45,520 --> 00:36:49,480
to sometimes you do the sort of 3D

894
00:36:47,520 --> 00:36:52,440
classification after doing an initial

895
00:36:49,480 --> 00:36:54,400
homogeneous reconstruction so with that

896
00:36:52,440 --> 00:36:55,440
assumption uh we saw in the original

897
00:36:54,400 --> 00:36:57,839
objective we were essentially

898
00:36:55,440 --> 00:37:00,520
marginalizing over the space of poses

899
00:36:57,839 --> 00:37:02,839
here we're just marginalizing over the

900
00:37:00,520 --> 00:37:05,200
class assignments okay so that's the

901
00:37:02,839 --> 00:37:08,480
only thing that really changes in the

902
00:37:05,200 --> 00:37:10,960
objective and the EM algorithm is going

903
00:37:08,480 --> 00:37:12,839
to look very similar again recall in in

904
00:37:10,960 --> 00:37:15,040
what I just presented we alternated

905
00:37:12,839 --> 00:37:17,079
between estimating the poses and

906
00:37:15,040 --> 00:37:20,040
updating these volumes we're going to do

907
00:37:17,079 --> 00:37:21,920
the same thing here we're going to um in

908
00:37:20,040 --> 00:37:23,200
the Eep we're going to instead estimate

909
00:37:21,920 --> 00:37:24,960
the class assignments or the

910
00:37:23,200 --> 00:37:27,160
probabilities of an image belonging to

911
00:37:24,960 --> 00:37:29,440
different classes and then using that in

912
00:37:27,160 --> 00:37:31,560
the m step we're again going to update

913
00:37:29,440 --> 00:37:34,000
the volume um where if you look at the

914
00:37:31,560 --> 00:37:36,079
update equation the volume for a given

915
00:37:34,000 --> 00:37:39,200
class is going to be again the sort of

916
00:37:36,079 --> 00:37:41,760
weighted average over every image

917
00:37:39,200 --> 00:37:45,280
weighted by How likely is it that that

918
00:37:41,760 --> 00:37:47,760
image belongs to that class yeah um

919
00:37:45,280 --> 00:37:50,680
every class we still have different

920
00:37:47,760 --> 00:37:54,880
possible poses though right yes that is

921
00:37:50,680 --> 00:37:58,839
true um so it is uh right in in a full

922
00:37:54,880 --> 00:38:00,599
formulation there is a per class CL pose

923
00:37:58,839 --> 00:38:02,720
as well it sort of depends on the route

924
00:38:00,599 --> 00:38:04,400
you take during processing so this one

925
00:38:02,720 --> 00:38:07,119
route do a homogeneous first just use

926
00:38:04,400 --> 00:38:10,319
those poses purely classify there other

927
00:38:07,119 --> 00:38:10,319
routes where you can do the joint

928
00:38:13,079 --> 00:38:18,440
optimization um yeah so the process is

929
00:38:16,440 --> 00:38:20,960
going to look very similar just doing

930
00:38:18,440 --> 00:38:24,480
this optimization over class assignment

931
00:38:20,960 --> 00:38:27,280
um in practice uh 3D classification

932
00:38:24,480 --> 00:38:29,839
which I just showed is still uh it's

933
00:38:27,280 --> 00:38:32,839
called challenging um for a multitude of

934
00:38:29,839 --> 00:38:36,240
reasons uh first you know we assume that

935
00:38:32,839 --> 00:38:39,079
each image arises from a single uh from

936
00:38:36,240 --> 00:38:40,440
you know one of K structures this is you

937
00:38:39,079 --> 00:38:41,880
know well suited for the example I

938
00:38:40,440 --> 00:38:44,119
showed where you have this rabis in

939
00:38:41,880 --> 00:38:46,560
discrete States um but for a lot of

940
00:38:44,119 --> 00:38:48,119
molecules they exhibit more continuous

941
00:38:46,560 --> 00:38:49,960
motions right where like a domain is

942
00:38:48,119 --> 00:38:52,560
moving around and so it's hard to

943
00:38:49,960 --> 00:38:54,880
represent those forms of heterogen with

944
00:38:52,560 --> 00:38:58,359
just a discrete set of

945
00:38:54,880 --> 00:39:01,079
structures um generally ALS also we have

946
00:38:58,359 --> 00:39:02,560
to set K ahead of time which can be very

947
00:39:01,079 --> 00:39:04,359
ad hoc and challenging if you don't know

948
00:39:02,560 --> 00:39:07,400
what's in your data set you sort of have

949
00:39:04,359 --> 00:39:09,839
to sweep or guess the values of K and

950
00:39:07,400 --> 00:39:11,839
there's also optimization tends to be

951
00:39:09,839 --> 00:39:14,680
challenging especially because as you

952
00:39:11,839 --> 00:39:17,200
increase K it you dilute the number of

953
00:39:14,680 --> 00:39:18,760
particles in each of those classes um

954
00:39:17,200 --> 00:39:21,359
and so that you know makes each of the

955
00:39:18,760 --> 00:39:24,160
volumes worse harder to

956
00:39:21,359 --> 00:39:27,440
op okay so that's a rundown of sort of

957
00:39:24,160 --> 00:39:28,599
classical reconstruction um and you know

958
00:39:27,440 --> 00:39:30,079
those really highlight the core

959
00:39:28,599 --> 00:39:32,560
principles understanding you know the

960
00:39:30,079 --> 00:39:34,400
more modern outs that we'll talk

961
00:39:32,560 --> 00:39:36,599
about

962
00:39:34,400 --> 00:39:38,200
um so in terms of you know how do people

963
00:39:36,599 --> 00:39:40,319
do reconstruction now for these more

964
00:39:38,200 --> 00:39:42,640
challenging forms of heterogenity so

965
00:39:40,319 --> 00:39:44,720
again we'd really like to tackle cases

966
00:39:42,640 --> 00:39:47,839
like this right of continuous

967
00:39:44,720 --> 00:39:49,880
heterogeneity we cannot represent um you

968
00:39:47,839 --> 00:39:52,480
know such variability with just you know

969
00:39:49,880 --> 00:39:55,000
K volumes so we really need to learn a

970
00:39:52,480 --> 00:39:57,000
full distribution over

971
00:39:55,000 --> 00:40:00,319
volumes again in terms of the image

972
00:39:57,000 --> 00:40:03,400
formation model we can modify it again

973
00:40:00,319 --> 00:40:06,000
now instead of a single structure or you

974
00:40:03,400 --> 00:40:08,319
know multiple volumes index by K we're

975
00:40:06,000 --> 00:40:13,520
now going to have a full distribution of

976
00:40:08,319 --> 00:40:17,400
volumes which we say V Theta z z is some

977
00:40:13,520 --> 00:40:19,160
latent variable which represents the um

978
00:40:17,400 --> 00:40:23,359
represents the confirmation of a

979
00:40:19,160 --> 00:40:25,400
particular image and in terms of um

980
00:40:23,359 --> 00:40:27,040
continuous heterogenity you can you can

981
00:40:25,400 --> 00:40:27,880
imagine you have a molecule with some

982
00:40:27,040 --> 00:40:29,880
domain

983
00:40:27,880 --> 00:40:31,680
that under goes some sort of linear

984
00:40:29,880 --> 00:40:34,400
one-dimensional

985
00:40:31,680 --> 00:40:37,520
motion this Z you can think of as some

986
00:40:34,400 --> 00:40:40,119
Laten variable corresponding to values

987
00:40:37,520 --> 00:40:42,760
of of that reaction coordinate along

988
00:40:40,119 --> 00:40:45,160
which that domain moves um and so this

989
00:40:42,760 --> 00:40:47,440
expression is saying um for the

990
00:40:45,160 --> 00:40:50,400
confirmation of a given particle we plug

991
00:40:47,440 --> 00:40:53,280
this into this uh this distribution

992
00:40:50,400 --> 00:40:55,079
which parametrizes a volume given that

993
00:40:53,280 --> 00:40:57,720
specific

994
00:40:55,079 --> 00:41:00,720
confirmation so again our our goal for

995
00:40:57,720 --> 00:41:03,280
reconstruction is going to be to

996
00:41:00,720 --> 00:41:05,720
optimize that full volume distribution V

997
00:41:03,280 --> 00:41:08,680
Theta um and also jointly on a per

998
00:41:05,720 --> 00:41:11,520
particle basis estimate uh this

999
00:41:08,680 --> 00:41:14,440
representation of its confirmation

1000
00:41:11,520 --> 00:41:18,440
C in general there are a lot of choices

1001
00:41:14,440 --> 00:41:21,839
we can take on how to uh how to model

1002
00:41:18,440 --> 00:41:23,680
this problem um and so the multiclass

1003
00:41:21,839 --> 00:41:26,359
discrete setting that I talked about you

1004
00:41:23,680 --> 00:41:28,359
can sort of view where we still have a z

1005
00:41:26,359 --> 00:41:30,560
there representing the confirmation with

1006
00:41:28,359 --> 00:41:32,520
Z corresponds to you know a discrete set

1007
00:41:30,560 --> 00:41:35,359
class

1008
00:41:32,520 --> 00:41:37,920
indices um but now we'd like to tackle

1009
00:41:35,359 --> 00:41:40,560
this case where Z belongs to some you

1010
00:41:37,920 --> 00:41:42,240
know continuous range of values which

1011
00:41:40,560 --> 00:41:44,920
will help us parameterize you know more

1012
00:41:42,240 --> 00:41:47,040
continuous motions um and in general we

1013
00:41:44,920 --> 00:41:49,640
can have both nonlinear and linear

1014
00:41:47,040 --> 00:41:53,160
parameterizations uh and so there set of

1015
00:41:49,640 --> 00:41:55,960
tools 3D vaa rovar where the mapping

1016
00:41:53,160 --> 00:41:58,079
from this confirmation to the volume is

1017
00:41:55,960 --> 00:42:00,520
linear so it use this techniques like

1018
00:41:58,079 --> 00:42:02,720
PCA and then there also classes of

1019
00:42:00,520 --> 00:42:04,800
models uh for example using deep

1020
00:42:02,720 --> 00:42:07,680
learning that have a nonlinear mapping

1021
00:42:04,800 --> 00:42:11,800
from Z to this volume

1022
00:42:07,680 --> 00:42:13,680
space um and again within this nonlinear

1023
00:42:11,800 --> 00:42:16,440
parameterizations uh there many

1024
00:42:13,680 --> 00:42:18,400
different design choices you can make uh

1025
00:42:16,440 --> 00:42:20,520
just using neural representations which

1026
00:42:18,400 --> 00:42:23,079
I'll talk about next um but you can also

1027
00:42:20,520 --> 00:42:25,599
encode different assumptions for example

1028
00:42:23,079 --> 00:42:26,880
deformable GMM or flow Fields where you

1029
00:42:25,599 --> 00:42:28,920
make sort of assumptions that you have

1030
00:42:26,880 --> 00:42:30,880
like a single canonical volume that

1031
00:42:28,920 --> 00:42:31,760
deforms along some coordinate so

1032
00:42:30,880 --> 00:42:34,079
essentially there are many different

1033
00:42:31,760 --> 00:42:36,440
design choices we can make um I won't

1034
00:42:34,079 --> 00:42:39,319
get into all of them but specifically

1035
00:42:36,440 --> 00:42:41,640
I'll talk about um the principles

1036
00:42:39,319 --> 00:42:44,720
underlying cryo Dragon which is the tool

1037
00:42:41,640 --> 00:42:48,400
and software package that we work on in

1038
00:42:44,720 --> 00:42:50,839
our lab um and so to introduce the

1039
00:42:48,400 --> 00:42:54,119
architecture first we can think about

1040
00:42:50,839 --> 00:42:56,000
how to efficiently parameterize volumes

1041
00:42:54,119 --> 00:42:58,280
in this new setting right so in the

1042
00:42:56,000 --> 00:43:00,079
homogeneous case we essentially

1043
00:42:58,280 --> 00:43:03,200
optimized the volume of this we had this

1044
00:43:00,079 --> 00:43:05,160
cubic grid of voxal right and we

1045
00:43:03,200 --> 00:43:10,760
optimized the values of each of those

1046
00:43:05,160 --> 00:43:12,720
voxels to to build up this volume um we

1047
00:43:10,760 --> 00:43:14,680
there's another way we can parameterize

1048
00:43:12,720 --> 00:43:16,640
the same volume which is using something

1049
00:43:14,680 --> 00:43:18,200
called a neural field and the idea of a

1050
00:43:16,640 --> 00:43:20,040
neural field that we're going to

1051
00:43:18,200 --> 00:43:22,200
implicitly instead of storting an

1052
00:43:20,040 --> 00:43:24,559
explicit cubic grid of oxil we're going

1053
00:43:22,200 --> 00:43:26,440
to implicitly represent that volume

1054
00:43:24,559 --> 00:43:28,079
through a function in this case the

1055
00:43:26,440 --> 00:43:30,400
function takes on the form of a neural

1056
00:43:28,079 --> 00:43:33,960
network but when I say a function it's

1057
00:43:30,400 --> 00:43:36,880
some mapping from a point in 3D space to

1058
00:43:33,960 --> 00:43:38,240
the value the density at that space at

1059
00:43:36,880 --> 00:43:41,400
at that

1060
00:43:38,240 --> 00:43:44,160
point um and so in

1061
00:43:41,400 --> 00:43:46,720
particular instead of again explicitly

1062
00:43:44,160 --> 00:43:49,440
representing every voxel here in order

1063
00:43:46,720 --> 00:43:51,880
to build up a volume we'd take this

1064
00:43:49,440 --> 00:43:54,359
function and evaluate it at a bunch of

1065
00:43:51,880 --> 00:43:57,599
3D coordinates sort of to sort of

1066
00:43:54,359 --> 00:44:00,520
rasterize you know voxal by voxal build

1067
00:43:57,599 --> 00:44:00,520
up this

1068
00:44:00,880 --> 00:44:07,119
volume

1069
00:44:02,960 --> 00:44:09,359
um some other details uh you might

1070
00:44:07,119 --> 00:44:13,240
wonder you know are both of these like

1071
00:44:09,359 --> 00:44:15,160
equivalent in terms of accuracy Um this

1072
00:44:13,240 --> 00:44:16,880
can be sometimes harder to optimize

1073
00:44:15,160 --> 00:44:19,880
implicitly but there are sort of Tricks

1074
00:44:16,880 --> 00:44:23,160
we can add to make it uh to make it

1075
00:44:19,880 --> 00:44:25,160
accurate uh in particular uh one key

1076
00:44:23,160 --> 00:44:28,599
Insight that Ellen had When developing

1077
00:44:25,160 --> 00:44:30,960
this um was that instead of giving this

1078
00:44:28,599 --> 00:44:33,359
network this function this raw 3D

1079
00:44:30,960 --> 00:44:35,319
coordinates we can featu these 3D

1080
00:44:33,359 --> 00:44:37,440
coordinates into some higher dimensional

1081
00:44:35,319 --> 00:44:39,520
Space by transforming it with a bunch of

1082
00:44:37,440 --> 00:44:41,599
sinusoidal functions and that sort of

1083
00:44:39,520 --> 00:44:43,480
helps the optimization um of these

1084
00:44:41,599 --> 00:44:47,480
neural fields and representing these

1085
00:44:43,480 --> 00:44:50,920
volumes um this concept of a oh and this

1086
00:44:47,480 --> 00:44:53,200
is just illustrating that same point so

1087
00:44:50,920 --> 00:44:55,319
U there's this experiment where you can

1088
00:44:53,200 --> 00:44:57,240
do where like ignoring reconstruction

1089
00:44:55,319 --> 00:44:59,200
you can do this very simple test of you

1090
00:44:57,240 --> 00:45:02,800
know can one of these neural networks

1091
00:44:59,200 --> 00:45:05,720
just learn a single 2D image and if you

1092
00:45:02,800 --> 00:45:08,800
just try to have it learn this image

1093
00:45:05,720 --> 00:45:10,160
just using those raw 3D coordinates it

1094
00:45:08,800 --> 00:45:11,960
turns out that because of the inductive

1095
00:45:10,160 --> 00:45:14,119
biases in neural networks you get

1096
00:45:11,960 --> 00:45:16,160
something very blurry but then by

1097
00:45:14,119 --> 00:45:18,359
transforming those coordinates into this

1098
00:45:16,160 --> 00:45:21,599
higher dimensional sinal space we're

1099
00:45:18,359 --> 00:45:23,400
then able to learn um learn these high

1100
00:45:21,599 --> 00:45:25,960
resolution

1101
00:45:23,400 --> 00:45:27,480
images and so in general this technique

1102
00:45:25,960 --> 00:45:28,800
of neural uh

1103
00:45:27,480 --> 00:45:31,440
okay and this is just one more

1104
00:45:28,800 --> 00:45:33,760
demonstration that again for pretty high

1105
00:45:31,440 --> 00:45:36,839
resolution you know images of size you

1106
00:45:33,760 --> 00:45:38,880
know 360 by 360 both the explicit voxal

1107
00:45:36,839 --> 00:45:43,359
based representation and the neural

1108
00:45:38,880 --> 00:45:43,359
representation um Can converge to high

1109
00:45:44,280 --> 00:45:50,800
resolution is the positional encoding

1110
00:45:46,599 --> 00:45:50,800
equalent to a forer transform of the

1111
00:45:53,440 --> 00:45:58,520
point essentially to do a for transform

1112
00:45:56,280 --> 00:46:01,000
of of anything you you you take the

1113
00:45:58,520 --> 00:46:02,920
sinusoidal and Co Co cosiness at

1114
00:46:01,000 --> 00:46:05,680
multiple frequencies and just add them

1115
00:46:02,920 --> 00:46:08,599
up right right we're not representing

1116
00:46:05,680 --> 00:46:11,599
the amplitudes of the components of the

1117
00:46:08,599 --> 00:46:14,640
forier so it's it's like a forier

1118
00:46:11,599 --> 00:46:16,640
spectrum instead of a point is that a

1119
00:46:14,640 --> 00:46:18,839
fair way to think about it or am I

1120
00:46:16,640 --> 00:46:21,559
missing something I think it's not

1121
00:46:18,839 --> 00:46:24,079
exactly so it's is the same so yes you

1122
00:46:21,559 --> 00:46:25,920
do uh it's similar in the sense that

1123
00:46:24,079 --> 00:46:28,520
yeah you're transforming into a set of

1124
00:46:25,920 --> 00:46:30,119
sinusoids um it's not a direct I guess

1125
00:46:28,520 --> 00:46:31,960
forier transformation we're not adding

1126
00:46:30,119 --> 00:46:33,599
them the the coefficients for all those

1127
00:46:31,960 --> 00:46:35,480
forier components there're different

1128
00:46:33,599 --> 00:46:38,480
choices you can make but I think by

1129
00:46:35,480 --> 00:46:40,440
default we just draw them from a gausian

1130
00:46:38,480 --> 00:46:42,240
so yeah the coefficients of all those

1131
00:46:40,440 --> 00:46:46,240
different sinusoids are sort of random

1132
00:46:42,240 --> 00:46:46,240
they don't corespond to the actual

1133
00:46:48,319 --> 00:46:52,359
forier um and this is just a slide

1134
00:46:50,240 --> 00:46:55,200
saying that this idea of like neural

1135
00:46:52,359 --> 00:46:58,480
field representations of volumes or

1136
00:46:55,200 --> 00:47:00,319
images is not C specific thing um and in

1137
00:46:58,480 --> 00:47:02,960
general after the development of it it's

1138
00:47:00,319 --> 00:47:05,640
seen a use in really a wide range of

1139
00:47:02,960 --> 00:47:09,240
fields um just in general sort of see an

1140
00:47:05,640 --> 00:47:11,520
understanding robotic planning and

1141
00:47:09,240 --> 00:47:13,920
other okay

1142
00:47:11,520 --> 00:47:15,319
um what I just showed was just two

1143
00:47:13,920 --> 00:47:16,720
different ways of representing the same

1144
00:47:15,319 --> 00:47:18,720
volume right either explicitly or

1145
00:47:16,720 --> 00:47:21,079
implicitly to this function why is that

1146
00:47:18,720 --> 00:47:22,480
actually useful um it becomes more

1147
00:47:21,079 --> 00:47:24,760
useful once we start thinking about

1148
00:47:22,480 --> 00:47:26,280
heterogen right and so in particular

1149
00:47:24,760 --> 00:47:28,040
when it comes to these explicit voxal

1150
00:47:26,280 --> 00:47:30,240
based represent ations in order to

1151
00:47:28,040 --> 00:47:33,800
represent heterogenity you need to store

1152
00:47:30,240 --> 00:47:36,200
and optimize multiple discrete volumes

1153
00:47:33,800 --> 00:47:37,920
whereas in the neural field setting this

1154
00:47:36,200 --> 00:47:39,760
is so much more expressive because what

1155
00:47:37,920 --> 00:47:42,520
we can do to represent heterogenity is

1156
00:47:39,760 --> 00:47:44,480
to Simply feed in an additional input to

1157
00:47:42,520 --> 00:47:46,680
the network which corresponds to that

1158
00:47:44,480 --> 00:47:48,960
confirmation V see right so in addition

1159
00:47:46,680 --> 00:47:50,440
to this 3D coordinate um you know

1160
00:47:48,960 --> 00:47:52,520
whether we want this function to

1161
00:47:50,440 --> 00:47:55,160
represent one structure or 10 structures

1162
00:47:52,520 --> 00:47:56,880
or 10,000 structures the size of the

1163
00:47:55,160 --> 00:47:58,480
network doesn't grow right we still have

1164
00:47:56,880 --> 00:48:00,960
have just this same structure of the

1165
00:47:58,480 --> 00:48:03,280
network all we change is the value of

1166
00:48:00,960 --> 00:48:06,559
this confirmation Z and so in this

1167
00:48:03,280 --> 00:48:08,880
manner um the implicit representation is

1168
00:48:06,559 --> 00:48:10,599
a much more scalable way of representing

1169
00:48:08,880 --> 00:48:12,280
multiple volumes corresponding to

1170
00:48:10,599 --> 00:48:14,880
explicitly storing and optimizing

1171
00:48:12,280 --> 00:48:14,880
explicit

1172
00:48:14,960 --> 00:48:18,720
box um one remaining question is that

1173
00:48:17,839 --> 00:48:21,319
I've been talking about this

1174
00:48:18,720 --> 00:48:23,319
confirmation latent Z which represents

1175
00:48:21,319 --> 00:48:24,680
the confirmation of each particle uh

1176
00:48:23,319 --> 00:48:26,240
where do we actually get that

1177
00:48:24,680 --> 00:48:28,520
confirmation from to feed into this

1178
00:48:26,240 --> 00:48:30,640
neural field

1179
00:48:28,520 --> 00:48:32,960
we do that using a second neural network

1180
00:48:30,640 --> 00:48:34,920
and so this PRI Dragon tool for

1181
00:48:32,960 --> 00:48:36,920
heterogenous reconstruction the full

1182
00:48:34,920 --> 00:48:39,200
architecture is a variational auto

1183
00:48:36,920 --> 00:48:42,119
encoder consisting of two main parts the

1184
00:48:39,200 --> 00:48:45,440
first is an encoder the encoder takes as

1185
00:48:42,119 --> 00:48:48,720
input a single one of those 2D images

1186
00:48:45,440 --> 00:48:52,480
and based on this Maps it to this

1187
00:48:48,720 --> 00:48:53,839
confirmation lat Z and then the decoder

1188
00:48:52,480 --> 00:48:56,319
which is this neural field we just

1189
00:48:53,839 --> 00:48:58,640
discussed takes as input that lane

1190
00:48:56,319 --> 00:49:00,920
variable and produces a volume

1191
00:48:58,640 --> 00:49:03,079
corresponding to that specific

1192
00:49:00,920 --> 00:49:05,319
confirmation which has been estimated

1193
00:49:03,079 --> 00:49:05,319
from

1194
00:49:08,880 --> 00:49:15,839
this how do

1195
00:49:10,920 --> 00:49:15,839
we train such a model

1196
00:49:16,040 --> 00:49:20,960
um so if we consider a single training

1197
00:49:18,640 --> 00:49:22,960
example right so we take our image we

1198
00:49:20,960 --> 00:49:25,960
push it through the encoder this gives

1199
00:49:22,960 --> 00:49:29,319
us again this Laten variable z um by the

1200
00:49:25,960 --> 00:49:31,040
way Z typically Ty Al takes on uh we

1201
00:49:29,319 --> 00:49:34,799
empirically find that between eight and

1202
00:49:31,040 --> 00:49:36,319
16 Dimensions Works in general the Z

1203
00:49:34,799 --> 00:49:37,960
should be as many dimensions as there

1204
00:49:36,319 --> 00:49:39,440
are degrees of freedom within the

1205
00:49:37,960 --> 00:49:42,240
underlying molecular

1206
00:49:39,440 --> 00:49:43,799
system um so again image goes to the

1207
00:49:42,240 --> 00:49:45,960
encoder you get this Lane variable

1208
00:49:43,799 --> 00:49:48,520
representing that image's confirmation

1209
00:49:45,960 --> 00:49:50,799
push it through the decoder and for the

1210
00:49:48,520 --> 00:49:53,119
sake of training again we note based on

1211
00:49:50,799 --> 00:49:56,119
the Fier slice theorem that this input

1212
00:49:53,119 --> 00:49:59,359
image is a centrally oriented slice of

1213
00:49:56,119 --> 00:50:01,640
the output vol volume so we can do and

1214
00:49:59,359 --> 00:50:03,640
also recall that the neural field maps a

1215
00:50:01,640 --> 00:50:06,599
single coordinate in space to the

1216
00:50:03,640 --> 00:50:08,359
density at that space so if we know the

1217
00:50:06,599 --> 00:50:09,839
poses assume we know the pose for this

1218
00:50:08,359 --> 00:50:13,160
image know the

1219
00:50:09,839 --> 00:50:15,359
orientation we can evaluate the decoder

1220
00:50:13,160 --> 00:50:17,680
along each one of the points

1221
00:50:15,359 --> 00:50:20,319
corresponding to that pose right so we

1222
00:50:17,680 --> 00:50:22,680
know that this image fits into the

1223
00:50:20,319 --> 00:50:25,760
volume in some specific pose so we can

1224
00:50:22,680 --> 00:50:28,040
evaluate the decoder along every Point

1225
00:50:25,760 --> 00:50:31,440
corresponding to the image plane of that

1226
00:50:28,040 --> 00:50:34,760
of that image um and then we can take

1227
00:50:31,440 --> 00:50:38,119
the loss just the the error MSE error

1228
00:50:34,760 --> 00:50:40,760
between the predicted image and the

1229
00:50:38,119 --> 00:50:43,200
original image and that sort of provides

1230
00:50:40,760 --> 00:50:46,280
this training signal which optimizes the

1231
00:50:43,200 --> 00:50:49,079
values um of the decoder as well as the

1232
00:50:46,280 --> 00:50:52,079
encoder sort of this end to end

1233
00:50:49,079 --> 00:50:52,079
fashion

1234
00:50:52,280 --> 00:50:57,599
um great the main takeaway here I think

1235
00:50:54,880 --> 00:50:58,960
is just that uh this is sort of a really

1236
00:50:57,599 --> 00:51:01,000
expressive model especially if you're

1237
00:50:58,960 --> 00:51:02,599
continuous heterogene right we're not

1238
00:51:01,000 --> 00:51:04,160
optimizing multiple discreete voxal

1239
00:51:02,599 --> 00:51:06,599
grids we're essentially mapping each

1240
00:51:04,160 --> 00:51:08,559
images this continuous space of

1241
00:51:06,599 --> 00:51:12,480
confirmations and then using that to

1242
00:51:08,559 --> 00:51:12,480
decode continuous distribution of

1243
00:51:14,760 --> 00:51:20,119
volumes um one last point just

1244
00:51:18,559 --> 00:51:22,760
connecting this back to sort of the

1245
00:51:20,119 --> 00:51:24,440
classical reconstruction uh even though

1246
00:51:22,760 --> 00:51:25,920
the architecture looks maybe quite

1247
00:51:24,440 --> 00:51:28,280
different from the EM algorithm we

1248
00:51:25,920 --> 00:51:30,680
discussed for reconstruction there

1249
00:51:28,280 --> 00:51:33,040
actually do exist some deep connections

1250
00:51:30,680 --> 00:51:35,000
particularly in the algorithm you know

1251
00:51:33,040 --> 00:51:37,000
the the poses and the class assignments

1252
00:51:35,000 --> 00:51:38,760
were also Laten variables that we sort

1253
00:51:37,000 --> 00:51:41,920
of did this marginalization over by

1254
00:51:38,760 --> 00:51:43,960
Computing with the full posterior um in

1255
00:51:41,920 --> 00:51:46,720
the same regard these confirmation

1256
00:51:43,960 --> 00:51:50,079
variables Z are also a form of Laten

1257
00:51:46,720 --> 00:51:52,720
variables in general it's much harder to

1258
00:51:50,079 --> 00:51:54,880
um compute the you know full posterior

1259
00:51:52,720 --> 00:51:57,400
over these right so for poses we

1260
00:51:54,880 --> 00:52:00,000
enumerated a bunch of poses and and Tred

1261
00:51:57,400 --> 00:52:02,799
out each one it's much harder to do for

1262
00:52:00,000 --> 00:52:04,079
this L the confirmation variable Z

1263
00:52:02,799 --> 00:52:05,559
because again the space is much more

1264
00:52:04,079 --> 00:52:08,200
High dimensional you know maybe eight or

1265
00:52:05,559 --> 00:52:09,720
16 Dimensions it's sort of unbounded um

1266
00:52:08,200 --> 00:52:12,640
and so we need better ways of sort of

1267
00:52:09,720 --> 00:52:15,480
predicting that confirmation Z which is

1268
00:52:12,640 --> 00:52:17,559
why we bring in an encoder uh this is

1269
00:52:15,480 --> 00:52:20,799
sort of the idea of a mortised inference

1270
00:52:17,559 --> 00:52:22,920
which says we can um instead of like

1271
00:52:20,799 --> 00:52:24,799
trying out every value of Z you can sort

1272
00:52:22,920 --> 00:52:27,040
of reduce the space and find plausible

1273
00:52:24,799 --> 00:52:30,520
ones by mapping directly from the input

1274
00:52:27,040 --> 00:52:30,520
image to that value

1275
00:52:32,000 --> 00:52:39,880
Z okay um finally in the last couple of

1276
00:52:36,359 --> 00:52:41,599
minutes um you know uh so that that's

1277
00:52:39,880 --> 00:52:43,760
the underlying Cry Dragon architecture

1278
00:52:41,599 --> 00:52:46,960
and training how does this get applied

1279
00:52:43,760 --> 00:52:48,799
to real data um so first of all once

1280
00:52:46,960 --> 00:52:51,400
you've trained this model in the fashion

1281
00:52:48,799 --> 00:52:54,160
I said you can encode all your images

1282
00:52:51,400 --> 00:52:55,480
again to get a latent variable

1283
00:52:54,160 --> 00:52:57,520
representing the confirmation for each

1284
00:52:55,480 --> 00:52:59,400
one of those images you can plot them

1285
00:52:57,520 --> 00:53:01,319
and so you get a plot like this again

1286
00:52:59,400 --> 00:53:02,960
each one of the points corresponds to

1287
00:53:01,319 --> 00:53:04,680
that low dimensional Lane representation

1288
00:53:02,960 --> 00:53:06,200
for one of those images and so this

1289
00:53:04,680 --> 00:53:08,480
gives us sort of visualization of the

1290
00:53:06,200 --> 00:53:10,559
empirical data distribution um and so

1291
00:53:08,480 --> 00:53:13,720
from here what we can do is do things

1292
00:53:10,559 --> 00:53:15,319
like a we can sample volumes along you

1293
00:53:13,720 --> 00:53:17,920
know continuous trajectories in the

1294
00:53:15,319 --> 00:53:19,559
space we can cluster the space Maybe

1295
00:53:17,920 --> 00:53:22,000
using K means clustering to get

1296
00:53:19,559 --> 00:53:24,200
representative disr samples um and we

1297
00:53:22,000 --> 00:53:26,680
can also you know identify sort of these

1298
00:53:24,200 --> 00:53:29,079
clusters of particles that you can then

1299
00:53:26,680 --> 00:53:31,920
refine in traditional tools or filter

1300
00:53:29,079 --> 00:53:31,920
out in the case of

1301
00:53:32,559 --> 00:53:38,480
junk uh so a couple of quick

1302
00:53:35,480 --> 00:53:40,119
examples uh here is this again ribosome

1303
00:53:38,480 --> 00:53:42,880
a ribosome data set where you have

1304
00:53:40,119 --> 00:53:45,119
multiple States discrete states with

1305
00:53:42,880 --> 00:53:46,480
subunits sort of bound or Unbound

1306
00:53:45,119 --> 00:53:49,440
depending on where in the maturation

1307
00:53:46,480 --> 00:53:51,839
process this ribosome is um traditional

1308
00:53:49,440 --> 00:53:54,400
processing in the C 3D classification

1309
00:53:51,839 --> 00:53:55,760
based approach as I said leads to

1310
00:53:54,400 --> 00:53:57,880
procedures that tend to be very

1311
00:53:55,760 --> 00:54:00,760
iterative and hierarchical so you know

1312
00:53:57,880 --> 00:54:02,960
you run one round of 3D classification

1313
00:54:00,760 --> 00:54:04,680
to get you know maybe five substance

1314
00:54:02,960 --> 00:54:06,359
particles then you have to do more

1315
00:54:04,680 --> 00:54:09,000
rounds of 3D classification on each of

1316
00:54:06,359 --> 00:54:10,720
those subsets to divide them further Etc

1317
00:54:09,000 --> 00:54:13,599
and ends up being sort of this iterative

1318
00:54:10,720 --> 00:54:15,920
process um whereas with this more with

1319
00:54:13,599 --> 00:54:18,520
Cry Dragon um and in general these more

1320
00:54:15,920 --> 00:54:20,400
like expressive models of heterogenity

1321
00:54:18,520 --> 00:54:23,040
uh empirically these models are able to

1322
00:54:20,400 --> 00:54:24,880
learn a lot more in just a single shot

1323
00:54:23,040 --> 00:54:27,359
and so here training this model on this

1324
00:54:24,880 --> 00:54:29,680
data set each of the major clusters

1325
00:54:27,359 --> 00:54:31,599
corresponds to one of the major States

1326
00:54:29,680 --> 00:54:33,760
but then if you dig deeper within each

1327
00:54:31,599 --> 00:54:35,960
of those clusters you're also able to

1328
00:54:33,760 --> 00:54:37,760
pull out all those minor States all in

1329
00:54:35,960 --> 00:54:41,359
just like a single round

1330
00:54:37,760 --> 00:54:44,440
training um and also additionally

1331
00:54:41,359 --> 00:54:46,480
identify sort of these rare States um

1332
00:54:44,440 --> 00:54:48,559
again because you know the process isn't

1333
00:54:46,480 --> 00:54:51,440
super ad hoc and iterative you're really

1334
00:54:48,559 --> 00:54:54,960
able to pull the most out of your

1335
00:54:51,440 --> 00:54:57,200
data um one more example so this is a

1336
00:54:54,960 --> 00:54:59,520
sply the previous example showed how

1337
00:54:57,200 --> 00:55:01,079
even for a case of discreet heterogenity

1338
00:54:59,520 --> 00:55:03,000
these neural models are really

1339
00:55:01,079 --> 00:55:04,240
expressive um but they're you know

1340
00:55:03,000 --> 00:55:06,040
especially expressive when it comes to

1341
00:55:04,240 --> 00:55:08,720
more these more continuous forms of

1342
00:55:06,040 --> 00:55:10,640
heterogen um here's the spone

1343
00:55:08,720 --> 00:55:13,440
traditionally and what you would do to

1344
00:55:10,640 --> 00:55:15,760
process this is manually identify

1345
00:55:13,440 --> 00:55:18,640
different domains different moving parts

1346
00:55:15,760 --> 00:55:20,920
and reconstruct and refine each of those

1347
00:55:18,640 --> 00:55:24,160
separately

1348
00:55:20,920 --> 00:55:27,039
um this is showing that again sort of in

1349
00:55:24,160 --> 00:55:28,920
a single shot without any strong priers

1350
00:55:27,039 --> 00:55:30,720
on you know what domains are moving you

1351
00:55:28,920 --> 00:55:33,119
can train one of these models and

1352
00:55:30,720 --> 00:55:35,240
sampling these continuous trajectories

1353
00:55:33,119 --> 00:55:37,000
in this case the a principal component

1354
00:55:35,240 --> 00:55:40,280
of the lay in space allows us to

1355
00:55:37,000 --> 00:55:42,760
visualize these more continuous

1356
00:55:40,280 --> 00:55:45,200
Dynamics um right and this is just

1357
00:55:42,760 --> 00:55:47,760
showing uh again you really get sort of

1358
00:55:45,200 --> 00:55:49,920
this full distribution corresponding to

1359
00:55:47,760 --> 00:55:52,280
your entire data set so each one of the

1360
00:55:49,920 --> 00:55:53,839
particles in your data sets maps to sort

1361
00:55:52,280 --> 00:55:55,839
of this unique volume allowing you to

1362
00:55:53,839 --> 00:55:57,359
really fully explore the confirmational

1363
00:55:55,839 --> 00:56:01,000
landscape

1364
00:55:57,359 --> 00:56:03,200
okay so to summarize um prum is very

1365
00:56:01,000 --> 00:56:04,720
powerful experimental technique

1366
00:56:03,200 --> 00:56:06,799
especially when it comes to Dynamic

1367
00:56:04,720 --> 00:56:08,240
proteins because uh this freezing

1368
00:56:06,799 --> 00:56:10,559
process captures them in this near

1369
00:56:08,240 --> 00:56:12,960
native state this sort of equilibrium

1370
00:56:10,559 --> 00:56:14,599
distribution um we talked about sort of

1371
00:56:12,960 --> 00:56:16,799
the probabilistic techniques underlying

1372
00:56:14,599 --> 00:56:19,440
classical reconstruction which provide

1373
00:56:16,799 --> 00:56:21,160
the core principles which then motivate

1374
00:56:19,440 --> 00:56:23,520
this new class of heterogenous

1375
00:56:21,160 --> 00:56:26,319
reconstruction methods which has emerged

1376
00:56:23,520 --> 00:56:27,559
for the past few years um and again

1377
00:56:26,319 --> 00:56:29,039
these heterogenous reconstruction

1378
00:56:27,559 --> 00:56:30,640
methods you can make many different

1379
00:56:29,039 --> 00:56:34,000
design choices and code many different

1380
00:56:30,640 --> 00:56:36,599
priors uh I specifically presented prior

1381
00:56:34,000 --> 00:56:38,680
Dragon which is one particular model

1382
00:56:36,599 --> 00:56:40,839
which uses this implicit neural

1383
00:56:38,680 --> 00:56:43,280
representation uh to provide this really

1384
00:56:40,839 --> 00:56:45,839
expressive and sort of assumption free

1385
00:56:43,280 --> 00:56:45,839
model of

1386
00:56:48,319 --> 00:56:53,920
heterogene so tough act to follow Rish

1387
00:56:50,839 --> 00:56:55,520
gave an amazing overview of the kind of

1388
00:56:53,920 --> 00:56:57,319
fundamental theoretical aspects of

1389
00:56:55,520 --> 00:56:59,119
crying reconstruction ction hopefully

1390
00:56:57,319 --> 00:57:00,599
I'll give like broader big picture

1391
00:56:59,119 --> 00:57:01,880
overview of some of the things that our

1392
00:57:00,599 --> 00:57:05,319
group works

1393
00:57:01,880 --> 00:57:07,400
on so kind of at a high level the

1394
00:57:05,319 --> 00:57:10,559
motivation of the methods that our group

1395
00:57:07,400 --> 00:57:12,880
develops are to uh develop computational

1396
00:57:10,559 --> 00:57:16,440
methods to push forward scientific

1397
00:57:12,880 --> 00:57:18,079
discovery and so definitely uh something

1398
00:57:16,440 --> 00:57:20,359
that we have been talking about and what

1399
00:57:18,079 --> 00:57:23,160
I will talk about today is how we can

1400
00:57:20,359 --> 00:57:25,359
develop methods for cryoem and cry data

1401
00:57:23,160 --> 00:57:27,960
analysis in particular extracting the

1402
00:57:25,359 --> 00:57:30,920
confirmational ens symbols um of these

1403
00:57:27,960 --> 00:57:32,880
macromolecular machines in

1404
00:57:30,920 --> 00:57:34,480
C uh something that's particularly

1405
00:57:32,880 --> 00:57:36,799
exciting especially right now in this

1406
00:57:34,480 --> 00:57:38,839
landscape of like large kind of uh deep

1407
00:57:36,799 --> 00:57:41,119
learning models is connecting these kind

1408
00:57:38,839 --> 00:57:43,359
of large scale uh generative models with

1409
00:57:41,119 --> 00:57:45,640
experimental data so that's definitely a

1410
00:57:43,359 --> 00:57:47,880
major Focus especially for molecular and

1411
00:57:45,640 --> 00:57:49,039
structural biology and then finally I

1412
00:57:47,880 --> 00:57:50,480
won't talk about this today but

1413
00:57:49,039 --> 00:57:53,480
something we're very excited about is

1414
00:57:50,480 --> 00:57:57,000
developing new AI methods for uh small

1415
00:57:53,480 --> 00:57:59,280
molecules and natural products

1416
00:57:57,000 --> 00:58:01,000
okay there's a couple of repeats but

1417
00:57:59,280 --> 00:58:03,039
I'll go through a lot of the intro very

1418
00:58:01,000 --> 00:58:04,760
quickly the biological motivation we

1419
00:58:03,039 --> 00:58:06,839
want to solve proin structures and we

1420
00:58:04,760 --> 00:58:08,680
want to be able to visualize uh their

1421
00:58:06,839 --> 00:58:10,799
confirmational ensembles because that

1422
00:58:08,680 --> 00:58:13,400
gets us much closer to understanding the

1423
00:58:10,799 --> 00:58:16,400
function of these ma

1424
00:58:13,400 --> 00:58:18,079
machines um and you might be very aware

1425
00:58:16,400 --> 00:58:20,440
of breakthroughs in machine learning

1426
00:58:18,079 --> 00:58:21,920
methods for structural biology namely

1427
00:58:20,440 --> 00:58:23,760
the development of alpha fold and

1428
00:58:21,920 --> 00:58:25,839
related systems for predicting protein

1429
00:58:23,760 --> 00:58:27,760
structures um there's also been a lot of

1430
00:58:25,839 --> 00:58:29,319
really interesting methods kind of

1431
00:58:27,760 --> 00:58:31,960
connecting these structure prediction

1432
00:58:29,319 --> 00:58:34,920
models with protein language models uh

1433
00:58:31,960 --> 00:58:38,839
with generative models to do denovo uh

1434
00:58:34,920 --> 00:58:41,240
protein generation like chroma great uh

1435
00:58:38,839 --> 00:58:44,200
alpha alpha numerical proteins right

1436
00:58:41,240 --> 00:58:46,200
there and so one of the main kind of

1437
00:58:44,200 --> 00:58:47,960
takeaways is that these unified machine

1438
00:58:46,200 --> 00:58:50,839
Le learning Frameworks are stateof

1439
00:58:47,960 --> 00:58:53,680
the-art for a lot of kind of uh tasks in

1440
00:58:50,839 --> 00:58:55,520
protein structure space but for a lot of

1441
00:58:53,680 --> 00:58:56,920
the things that I think we care about as

1442
00:58:55,520 --> 00:58:59,559
biologists so putting our kind of

1443
00:58:56,920 --> 00:59:01,319
structural biologists hat on um I think

1444
00:58:59,559 --> 00:59:03,000
the goalposts have just Advanced so

1445
00:59:01,319 --> 00:59:05,039
we're still very data limited for many

1446
00:59:03,000 --> 00:59:06,599
problems including kind of understanding

1447
00:59:05,039 --> 00:59:08,200
the downstream function and

1448
00:59:06,599 --> 00:59:12,839
understanding kind of how these

1449
00:59:08,200 --> 00:59:14,680
molecules interact in C2 which is why uh

1450
00:59:12,839 --> 00:59:16,480
I'm very kind of uh grateful that our

1451
00:59:14,680 --> 00:59:18,039
group works on these methods for

1452
00:59:16,480 --> 00:59:20,400
advancing the type of data that we can

1453
00:59:18,039 --> 00:59:24,000
get hopefully even uh help with training

1454
00:59:20,400 --> 00:59:24,000
the Next Generation versions of these

1455
00:59:24,480 --> 00:59:29,599
structure um as already very nicely

1456
00:59:27,200 --> 00:59:31,760
introduced proteins and other biom

1457
00:59:29,599 --> 00:59:34,520
biomolecules form these large dynamic

1458
00:59:31,760 --> 00:59:36,480
macro machines and if we really want to

1459
00:59:34,520 --> 00:59:38,319
understand kind of the function of these

1460
00:59:36,480 --> 00:59:40,160
machines it would be amazing to be able

1461
00:59:38,319 --> 00:59:41,880
to visualize uh the entire

1462
00:59:40,160 --> 00:59:44,599
confirmational ensembles either at kind

1463
00:59:41,880 --> 00:59:48,359
of like high resolutions or even uh at

1464
00:59:44,599 --> 00:59:50,000
kind of broader uh in context uh in

1465
00:59:48,359 --> 00:59:52,280
context

1466
00:59:50,000 --> 00:59:54,960
environments unfortunately techniques to

1467
00:59:52,280 --> 00:59:57,200
study these molecular motions especially

1468
00:59:54,960 --> 00:59:59,520
at kind of atomic Atomic level

1469
00:59:57,200 --> 01:00:01,559
resolutions are rather limited so we

1470
00:59:59,520 --> 01:00:04,880
have NMR which is typically limited to

1471
01:00:01,559 --> 01:00:06,760
smaller proteins um well what I like to

1472
01:00:04,880 --> 01:00:08,640
call kind of avant guard crystallography

1473
01:00:06,760 --> 01:00:10,559
based approaches like EFX XEL

1474
01:00:08,640 --> 01:00:12,119
crystallography this still requires

1475
01:00:10,559 --> 01:00:13,039
sample crystallization but you can maybe

1476
01:00:12,119 --> 01:00:16,079
look at some of the mechanical

1477
01:00:13,039 --> 01:00:18,079
deformations of these uh of the kind of

1478
01:00:16,079 --> 01:00:20,400
proteins within the Crystal

1479
01:00:18,079 --> 01:00:22,200
lus and then in a previous life I've

1480
01:00:20,400 --> 01:00:24,839
worked on molecular Dynamic simulations

1481
01:00:22,200 --> 01:00:26,880
so can we actually kind of run long tan

1482
01:00:24,839 --> 01:00:28,720
scale MD simulations get an in silico

1483
01:00:26,880 --> 01:00:31,160
microscope into the Dynamics of these

1484
01:00:28,720 --> 01:00:32,480
systems um very very challenging to do

1485
01:00:31,160 --> 01:00:34,480
computationally and there's also a lot

1486
01:00:32,480 --> 01:00:36,039
of fundamental kind of challenges in the

1487
01:00:34,480 --> 01:00:38,119
underlying accuracy of these force

1488
01:00:36,039 --> 01:00:39,920
fields hacking Alpha fold I think is

1489
01:00:38,119 --> 01:00:42,280
pretty interesting what kind of signals

1490
01:00:39,920 --> 01:00:44,559
are in the underlying msas but then when

1491
01:00:42,280 --> 01:00:45,960
I learned about crym uh kind of near the

1492
01:00:44,559 --> 01:00:47,799
beginning of my PhD I was like ah this

1493
01:00:45,960 --> 01:00:49,799
is a very very cool experimental

1494
01:00:47,799 --> 01:00:51,839
technique that can allow us potentially

1495
01:00:49,799 --> 01:00:54,799
to extract the kind of confirmational

1496
01:00:51,839 --> 01:00:57,920
ensembles of these uh nanoc scale

1497
01:00:54,799 --> 01:00:57,920
nanometer scale machines

1498
01:00:57,960 --> 01:01:02,319
so I won't go over kind of construction

1499
01:01:00,599 --> 01:01:05,760
fundamentals because we just had an

1500
01:01:02,319 --> 01:01:07,880
amazing primer by Rish um but again we

1501
01:01:05,760 --> 01:01:09,799
have a sample flash frozen we have a

1502
01:01:07,880 --> 01:01:11,520
collected set of micrographs and then

1503
01:01:09,799 --> 01:01:12,760
from there we have a collected set of

1504
01:01:11,520 --> 01:01:14,319
single particle images that are

1505
01:01:12,760 --> 01:01:16,920
characteristically very

1506
01:01:14,319 --> 01:01:19,200
noisy and the name of the game is to

1507
01:01:16,920 --> 01:01:20,839
reconstruct in 3D the electron

1508
01:01:19,200 --> 01:01:24,160
scattering potential for this kind of

1509
01:01:20,839 --> 01:01:27,000
volume function from our Collective

1510
01:01:24,160 --> 01:01:29,440
images um and this I definitely won't go

1511
01:01:27,000 --> 01:01:32,200
over since we just had a primer on it

1512
01:01:29,440 --> 01:01:33,920
the goal is to estimate our volumes and

1513
01:01:32,200 --> 01:01:35,640
uh the poses typically with maximum

1514
01:01:33,920 --> 01:01:37,000
likelihood techniques and there's a lot

1515
01:01:35,640 --> 01:01:38,480
of state-of-the-art software packages

1516
01:01:37,000 --> 01:01:40,760
for doing this especially in the

1517
01:01:38,480 --> 01:01:43,079
homogeneous case so ReliOn carpark for

1518
01:01:40,760 --> 01:01:46,039
Prine and so

1519
01:01:43,079 --> 01:01:47,559
on um Rish also gave a quick overview

1520
01:01:46,039 --> 01:01:49,359
about this but I think this provides a

1521
01:01:47,559 --> 01:01:51,839
nice intuition for this iterative DM

1522
01:01:49,359 --> 01:01:53,720
algorithm that we talked about um and so

1523
01:01:51,839 --> 01:01:55,079
this is the furry slice theorem the

1524
01:01:53,720 --> 01:01:57,119
furry slice theorem states that the

1525
01:01:55,079 --> 01:01:59,279
furry transform of a 2d projection of a

1526
01:01:57,119 --> 01:02:01,359
volume is a central slice out of the 3D

1527
01:01:59,279 --> 01:02:02,680
for transfer of the volume where the

1528
01:02:01,359 --> 01:02:05,440
orientation of that slice is

1529
01:02:02,680 --> 01:02:07,319
perpendicular to the direction and so if

1530
01:02:05,440 --> 01:02:09,640
we have a set of images and we know

1531
01:02:07,319 --> 01:02:11,760
their poses we can convert convert or

1532
01:02:09,640 --> 01:02:13,319
take the ffts and then insert them as

1533
01:02:11,760 --> 01:02:15,480
slices into the correct kind of

1534
01:02:13,319 --> 01:02:17,319
orientations in 3D space and then take

1535
01:02:15,480 --> 01:02:19,440
the inverse fft to get back our real

1536
01:02:17,319 --> 01:02:22,520
space kind of visualization of the

1537
01:02:19,440 --> 01:02:24,599
volume and then that kind of gives the

1538
01:02:22,520 --> 01:02:26,760
uh intuition for how these iterative em

1539
01:02:24,599 --> 01:02:29,440
algorithms work given some initial

1540
01:02:26,760 --> 01:02:31,960
volume v you estimate your poses and

1541
01:02:29,440 --> 01:02:33,880
given those poses you reestimate volume

1542
01:02:31,960 --> 01:02:35,839
and rinse and repeat until convergence

1543
01:02:33,880 --> 01:02:38,559
ideally to the global minimum although

1544
01:02:35,839 --> 01:02:40,240
there's a lot op that and Rish already

1545
01:02:38,559 --> 01:02:41,640
gave an overview of these

1546
01:02:40,240 --> 01:02:45,119
state-of-the-art software packages for

1547
01:02:41,640 --> 01:02:48,160
doing that mly rely on

1548
01:02:45,119 --> 01:02:49,880
and okay so that was homogeneous

1549
01:02:48,160 --> 01:02:52,440
reconstruction but we have this

1550
01:02:49,880 --> 01:02:55,520
heterogenity problem uh which is the

1551
01:02:52,440 --> 01:02:58,119
kind of major opportunity next so each

1552
01:02:55,520 --> 01:02:59,640
crime image contains a unique molecule

1553
01:02:58,119 --> 01:03:02,200
and uh potentially a different

1554
01:02:59,640 --> 01:03:04,279
confirmational state so the ability to

1555
01:03:02,200 --> 01:03:06,240
image these heterogeneous structures is

1556
01:03:04,279 --> 01:03:07,680
a major opportunity in crym and

1557
01:03:06,240 --> 01:03:09,160
especially relative to other techniques

1558
01:03:07,680 --> 01:03:11,119
like crystallography where we've

1559
01:03:09,160 --> 01:03:12,440
experimentally rigidified each copy of

1560
01:03:11,119 --> 01:03:14,680
our molecule in the exact same

1561
01:03:12,440 --> 01:03:16,799
confirmation in we actually get the

1562
01:03:14,680 --> 01:03:19,000
experimental data needed to study the

1563
01:03:16,799 --> 01:03:21,119
kind of intrinsic structural landscape

1564
01:03:19,000 --> 01:03:23,799
of these macro of these protein

1565
01:03:21,119 --> 01:03:25,440
complexes unfortunately dealing with

1566
01:03:23,799 --> 01:03:27,720
this heterogenity is very challenging

1567
01:03:25,440 --> 01:03:29,359
and see approaches really include just

1568
01:03:27,720 --> 01:03:30,960
ad hoc filtering or getting rid of as

1569
01:03:29,359 --> 01:03:32,599
much of it as possible which is

1570
01:03:30,960 --> 01:03:35,279
obviously not ideal if you're interested

1571
01:03:32,599 --> 01:03:37,039
in intrinsic heterogen um and then

1572
01:03:35,279 --> 01:03:38,279
something called M Class reconstruction

1573
01:03:37,039 --> 01:03:41,640
which we already actually talked a lot

1574
01:03:38,279 --> 01:03:46,160
about um and that leads to these kind of

1575
01:03:41,640 --> 01:03:48,960
uh very um manually made SI figures in

1576
01:03:46,160 --> 01:03:51,359
all the pran papers where a practitioner

1577
01:03:48,960 --> 01:03:53,079
has the expertise to know like how to

1578
01:03:51,359 --> 01:03:56,240
sweep how to choose subsets how to

1579
01:03:53,079 --> 01:03:57,760
combine them uh and Main takeaway here

1580
01:03:56,240 --> 01:03:59,400
is that at the top of this processing

1581
01:03:57,760 --> 01:04:00,039
pipeline there are millions and millions

1582
01:03:59,400 --> 01:04:04,119
of

1583
01:04:00,039 --> 01:04:06,559
images but by the end um you have two

1584
01:04:04,119 --> 01:04:08,839
albe at high resolution structures but

1585
01:04:06,559 --> 01:04:10,640
you've ALS you've also thrown away a

1586
01:04:08,839 --> 01:04:12,880
significant portion of your data so in

1587
01:04:10,640 --> 01:04:16,640
this case um maybe 90%

1588
01:04:12,880 --> 01:04:18,200
of the question is what's in that 90% um

1589
01:04:16,640 --> 01:04:20,319
and so the identification and Analysis

1590
01:04:18,200 --> 01:04:23,039
of heterogeneity especially continuous

1591
01:04:20,319 --> 01:04:25,520
forms of hydrogen uh is an open problem

1592
01:04:23,039 --> 01:04:28,160
in PR Rec construction and this is the

1593
01:04:25,520 --> 01:04:30,520
problem problem um that I originally

1594
01:04:28,160 --> 01:04:32,839
sought to kind of answer at the

1595
01:04:30,520 --> 01:04:34,400
beginning my PhD so can we design a

1596
01:04:32,839 --> 01:04:36,559
modern machine learning method for this

1597
01:04:34,400 --> 01:04:38,359
heterogenity problem cm and still

1598
01:04:36,559 --> 01:04:40,839
continues to be kind of a major research

1599
01:04:38,359 --> 01:04:43,520
question in my

1600
01:04:40,839 --> 01:04:45,839
group so you'll also kind of be familiar

1601
01:04:43,520 --> 01:04:47,480
with this slide so in heterogeneous

1602
01:04:45,839 --> 01:04:49,480
reconstruction we extend the image

1603
01:04:47,480 --> 01:04:52,079
formation model instead of a single

1604
01:04:49,480 --> 01:04:53,400
volume uh for each image we now have

1605
01:04:52,079 --> 01:04:56,880
this distribution of volumes

1606
01:04:53,400 --> 01:04:58,920
parameterized by S variable model

1607
01:04:56,880 --> 01:05:00,240
and I think I think it's important to

1608
01:04:58,920 --> 01:05:01,880
take a step back and think about what

1609
01:05:00,240 --> 01:05:04,079
are the sources of heterogenity because

1610
01:05:01,880 --> 01:05:05,640
that motivates kind of how we design

1611
01:05:04,079 --> 01:05:08,039
these uh how we want to design our

1612
01:05:05,640 --> 01:05:10,799
volume distribution our paration of this

1613
01:05:08,039 --> 01:05:13,760
distribution and so

1614
01:05:10,799 --> 01:05:15,880
um yeah I like these acronyms because it

1615
01:05:13,760 --> 01:05:17,160
becomes a mouthful to say confirmational

1616
01:05:15,880 --> 01:05:19,119
heterogenity and compositional

1617
01:05:17,160 --> 01:05:21,319
heterogenity over and over again uh but

1618
01:05:19,119 --> 01:05:24,359
we have confet which you know can

1619
01:05:21,319 --> 01:05:27,119
originate from shape deformations of our

1620
01:05:24,359 --> 01:05:29,480
proteins our bi molecules and then we

1621
01:05:27,119 --> 01:05:31,599
have compet which refers to kind of

1622
01:05:29,480 --> 01:05:33,880
compositional differences in the so you

1623
01:05:31,599 --> 01:05:36,400
can think of that as like object class

1624
01:05:33,880 --> 01:05:39,359
um and then in practice there's usually

1625
01:05:36,400 --> 01:05:41,160
a lot of real het which comes from

1626
01:05:39,359 --> 01:05:43,480
artifacts and non- idealities during

1627
01:05:41,160 --> 01:05:44,880
Imaging maybe Crystal and Ice forming on

1628
01:05:43,480 --> 01:05:46,720
the images that get falsely picked

1629
01:05:44,880 --> 01:05:48,920
during the

1630
01:05:46,720 --> 01:05:50,200
particle and different methods there's

1631
01:05:48,920 --> 01:05:52,000
now a lot of different methods they use

1632
01:05:50,200 --> 01:05:54,440
different choices of the volume

1633
01:05:52,000 --> 01:05:56,599
parameterization lat variable model and

1634
01:05:54,440 --> 01:05:58,240
also way they do inference of all these

1635
01:05:56,599 --> 01:06:01,480
variables and so there's a lot of

1636
01:05:58,240 --> 01:06:03,160
different design traces um and then one

1637
01:06:01,480 --> 01:06:06,279
last thing to note is that most methods

1638
01:06:03,160 --> 01:06:08,640
treat poses as known before doing

1639
01:06:06,279 --> 01:06:10,960
heterogen okay so that's the setting of

1640
01:06:08,640 --> 01:06:13,640
like heterogeneous reconstruction cem

1641
01:06:10,960 --> 01:06:15,279
our method which is called Cry Dragon

1642
01:06:13,640 --> 01:06:17,960
it's an acronym it stands for deep

1643
01:06:15,279 --> 01:06:20,520
reconstructing dat networks and here our

1644
01:06:17,960 --> 01:06:22,440
task is 3D reconstruction instead of a

1645
01:06:20,520 --> 01:06:24,440
single kind of homogeneous structure

1646
01:06:22,440 --> 01:06:25,599
from our data set of unlabeled images we

1647
01:06:24,440 --> 01:06:27,680
want to reconstruct this load

1648
01:06:25,599 --> 01:06:30,440
dimensional continuous

1649
01:06:27,680 --> 01:06:32,880
structures um so yeah Rich already gave

1650
01:06:30,440 --> 01:06:34,720
an overview but we framed this

1651
01:06:32,880 --> 01:06:36,079
heterogeneous reconstruction problem as

1652
01:06:34,720 --> 01:06:38,039
unsupervised learning of a deep

1653
01:06:36,079 --> 01:06:39,760
generative model where the generative

1654
01:06:38,039 --> 01:06:41,880
models parameterized using this neural

1655
01:06:39,760 --> 01:06:43,799
field and particularly exciting to see

1656
01:06:41,880 --> 01:06:45,599
kind of the general or the broad

1657
01:06:43,799 --> 01:06:47,799
applicability of this classic methods in

1658
01:06:45,599 --> 01:06:49,640
computer vision and fundamentally moving

1659
01:06:47,799 --> 01:06:51,240
forward we're interested in developing

1660
01:06:49,640 --> 01:06:53,400
new methods that kind of broaden the

1661
01:06:51,240 --> 01:06:56,039
scope of what we can get out of cryan

1662
01:06:53,400 --> 01:06:57,640
dat andal biolog

1663
01:06:56,039 --> 01:06:59,640
okay so I'm going to skip over these

1664
01:06:57,640 --> 01:07:01,359
real quick but the main takeaway that R

1665
01:06:59,640 --> 01:07:02,960
already nicely went through is that BR

1666
01:07:01,359 --> 01:07:04,720
Dragon structures are parameterized

1667
01:07:02,960 --> 01:07:06,920
using a neural network instead of boxal

1668
01:07:04,720 --> 01:07:08,720
array and then the main reason we do

1669
01:07:06,920 --> 01:07:10,520
this is that it gives us a very elegant

1670
01:07:08,720 --> 01:07:12,839
way of modeling especially continuous

1671
01:07:10,520 --> 01:07:15,039
forms of het so instead of having to

1672
01:07:12,839 --> 01:07:16,880
model K separate boxal arrays again

1673
01:07:15,039 --> 01:07:18,640
there becomes as buyas variant trade-off

1674
01:07:16,880 --> 01:07:20,799
especially with larger numbers of K as

1675
01:07:18,640 --> 01:07:22,559
well as computational considerations uh

1676
01:07:20,799 --> 01:07:25,000
we can simply extend the input dimension

1677
01:07:22,559 --> 01:07:27,480
of our neural network to uh condition on

1678
01:07:25,000 --> 01:07:29,599
an additional L

1679
01:07:27,480 --> 01:07:32,720
variable okay this slide we're also

1680
01:07:29,599 --> 01:07:34,319
already familiar with um and so I don't

1681
01:07:32,720 --> 01:07:36,640
think I have anything else to say other

1682
01:07:34,319 --> 01:07:39,000
than it's all expressed in fur space so

1683
01:07:36,640 --> 01:07:41,119
each input image is a 2d planer slice

1684
01:07:39,000 --> 01:07:44,240
out of the volume in the free domain

1685
01:07:41,119 --> 01:07:47,160
even though these this image is kind

1686
01:07:44,240 --> 01:07:50,039
of okay and the main advantage is that

1687
01:07:47,160 --> 01:07:52,680
this is a very flexible model uh with

1688
01:07:50,039 --> 01:07:55,480
very few initial assumptions about the

1689
01:07:52,680 --> 01:07:57,119
data and so um this kind of neural net

1690
01:07:55,480 --> 01:07:59,279
networ or this coordinate basal Network

1691
01:07:57,119 --> 01:08:02,520
whatever kind of distribution of uh

1692
01:07:59,279 --> 01:08:04,680
structures it can model uh we can uh or

1693
01:08:02,520 --> 01:08:08,559
it can learn from the

1694
01:08:04,680 --> 01:08:10,920
data okay so at test time we have this

1695
01:08:08,559 --> 01:08:12,920
encoder and decoder um and again R

1696
01:08:10,920 --> 01:08:14,520
already went through this but given a

1697
01:08:12,920 --> 01:08:15,960
set of images we can encode them into

1698
01:08:14,520 --> 01:08:17,960
this low dimensional Laten space and

1699
01:08:15,960 --> 01:08:19,679
just directly visualize that space see

1700
01:08:17,960 --> 01:08:21,440
if there's anything interesting we can

1701
01:08:19,679 --> 01:08:23,759
even learn about maybe the clustering

1702
01:08:21,440 --> 01:08:25,920
and this empirical data

1703
01:08:23,759 --> 01:08:28,199
distribution and we can use the decoder

1704
01:08:25,920 --> 01:08:30,319
neural network to generate or sample

1705
01:08:28,199 --> 01:08:33,040
volumes at different values of our

1706
01:08:30,319 --> 01:08:34,359
latent variable um so we can view

1707
01:08:33,040 --> 01:08:36,600
representative

1708
01:08:34,359 --> 01:08:38,480
samples maybe given two end states of

1709
01:08:36,600 --> 01:08:40,199
Interest we can do an interpolation in

1710
01:08:38,480 --> 01:08:42,400
the latent space or maybe a random walk

1711
01:08:40,199 --> 01:08:43,839
in the latent space and generate the

1712
01:08:42,400 --> 01:08:45,880
corresponding kind of continuous

1713
01:08:43,839 --> 01:08:48,159
trajectory continuous

1714
01:08:45,880 --> 01:08:51,239
model and then we can take subsets of

1715
01:08:48,159 --> 01:08:53,799
our data set to either filter from a lot

1716
01:08:51,239 --> 01:08:55,480
of kind of real artifacts or validate

1717
01:08:53,799 --> 01:08:58,159
kind of an individual structure using

1718
01:08:55,480 --> 01:08:58,159
traditional kind of

1719
01:08:58,480 --> 01:09:04,159
hom quick question so so you mentioned

1720
01:09:00,920 --> 01:09:06,319
that this uh this approach uses none or

1721
01:09:04,159 --> 01:09:08,159
very few assumptions so what are the

1722
01:09:06,319 --> 01:09:10,640
assumptions it uses and how does it

1723
01:09:08,159 --> 01:09:12,279
compare with the assumptions made in the

1724
01:09:10,640 --> 01:09:14,359
traditional approach where you assume

1725
01:09:12,279 --> 01:09:18,319
it's sampled from a normal distribution

1726
01:09:14,359 --> 01:09:20,960
yeah um the I guess the main assumption

1727
01:09:18,319 --> 01:09:22,920
is that the rep uh the distribution of

1728
01:09:20,960 --> 01:09:25,040
structures can be represented in some

1729
01:09:22,920 --> 01:09:28,199
lower dimensional space like dimensional

1730
01:09:25,040 --> 01:09:29,880
space but we don't make any kind of more

1731
01:09:28,199 --> 01:09:33,080
strict assumptions about what that

1732
01:09:29,880 --> 01:09:33,080
distribution look

1733
01:09:34,719 --> 01:09:39,719
like cool so in the original development

1734
01:09:37,679 --> 01:09:42,960
of crow Dragon um we did a lot of

1735
01:09:39,719 --> 01:09:45,880
validation on synthetic data sets um

1736
01:09:42,960 --> 01:09:47,640
just to make sure that everything was

1737
01:09:45,880 --> 01:09:50,960
working but then something that I was

1738
01:09:47,640 --> 01:09:52,480
very kind of uh motivated to do is to

1739
01:09:50,960 --> 01:09:54,560
create an actual software package around

1740
01:09:52,480 --> 01:09:56,800
this tool that people structural

1741
01:09:54,560 --> 01:09:58,880
biologists and electron microscopists

1742
01:09:56,800 --> 01:10:01,280
can train these models to analyze their

1743
01:09:58,880 --> 01:10:02,800
data sets and visualize the heterogeny

1744
01:10:01,280 --> 01:10:04,719
and so R already went through these two

1745
01:10:02,800 --> 01:10:06,199
examples but we have this kind of

1746
01:10:04,719 --> 01:10:08,080
assembling bacterial ribosome where

1747
01:10:06,199 --> 01:10:09,600
we're able to discover new structures

1748
01:10:08,080 --> 01:10:10,800
and then this pre- catalic spliceosome

1749
01:10:09,600 --> 01:10:12,400
on the right where we're able to

1750
01:10:10,800 --> 01:10:14,719
visualize these kind of large scale

1751
01:10:12,400 --> 01:10:16,159
continuous dynamics of this large macro

1752
01:10:14,719 --> 01:10:18,640
molecular

1753
01:10:16,159 --> 01:10:19,760
machine at Princeton I'm very lucky to

1754
01:10:18,640 --> 01:10:21,760
have Michael in the group who is a

1755
01:10:19,760 --> 01:10:24,080
research software engineer who has taken

1756
01:10:21,760 --> 01:10:25,920
over like maintenance and support of

1757
01:10:24,080 --> 01:10:28,199
this software package that's absolutely

1758
01:10:25,920 --> 01:10:30,440
amazing um hopefully it's relatively

1759
01:10:28,199 --> 01:10:32,280
easy to use uh with a pretty

1760
01:10:30,440 --> 01:10:35,360
straightforward software pipeline we

1761
01:10:32,280 --> 01:10:38,080
have extensive tutorials maybe too much

1762
01:10:35,360 --> 01:10:40,640
but we'll see uh on how to use the tool

1763
01:10:38,080 --> 01:10:42,040
and how to kind of interpret the results

1764
01:10:40,640 --> 01:10:44,520
um and we're working on kind of

1765
01:10:42,040 --> 01:10:46,960
enhancements Integrations some of these

1766
01:10:44,520 --> 01:10:50,000
new kind of post estimation methods uh

1767
01:10:46,960 --> 01:10:54,080
getting that kind of integrated into the

1768
01:10:50,000 --> 01:10:55,400
main cool and so there's a lot of like

1769
01:10:54,080 --> 01:10:56,920
kind of interesting things we can do

1770
01:10:55,400 --> 01:10:59,719
with Cry Dragon but there's all the

1771
01:10:56,920 --> 01:11:01,280
limitations which have motivated the

1772
01:10:59,719 --> 01:11:02,800
kind of new directions and crime

1773
01:11:01,280 --> 01:11:05,640
reconstruction that our group ISR

1774
01:11:02,800 --> 01:11:07,400
working on so I will just give a quick

1775
01:11:05,640 --> 01:11:09,920
overview of a couple of these different

1776
01:11:07,400 --> 01:11:12,920
methods but I'll focus on Cry Dragon ET

1777
01:11:09,920 --> 01:11:12,920
which is how we do structure

1778
01:11:13,280 --> 01:11:19,840
determinations okay

1779
01:11:15,880 --> 01:11:21,719
so uh I think it was great to get in the

1780
01:11:19,840 --> 01:11:23,600
primer a deep dive into this pose

1781
01:11:21,719 --> 01:11:24,800
estimation problem because it's actually

1782
01:11:23,600 --> 01:11:27,199
very very interesting and very

1783
01:11:24,800 --> 01:11:29,920
engineering intensive and usually just

1784
01:11:27,199 --> 01:11:32,280
kind of completely skipped over but uh

1785
01:11:29,920 --> 01:11:34,000
to obtain kind of this rendered slice by

1786
01:11:32,280 --> 01:11:35,920
the fre slice serum you need to know the

1787
01:11:34,000 --> 01:11:37,440
orientation of that slice so we have

1788
01:11:35,920 --> 01:11:40,480
this pose which is a tuple of the

1789
01:11:37,440 --> 01:11:42,440
rotation a 2d translation so we need

1790
01:11:40,480 --> 01:11:45,159
some model to approximate pose or we

1791
01:11:42,440 --> 01:11:47,040
need some approach to approximate pose

1792
01:11:45,159 --> 01:11:51,480
how do we do

1793
01:11:47,040 --> 01:11:53,400
this um I won't go into too much detail

1794
01:11:51,480 --> 01:11:55,239
but a lot of the research in the group

1795
01:11:53,400 --> 01:11:57,480
so far has been kind of explored

1796
01:11:55,239 --> 01:11:59,400
exploring different ways for doing posst

1797
01:11:57,480 --> 01:12:01,520
estimation and this is a setting of Crum

1798
01:11:59,400 --> 01:12:02,920
called abon reconstruction and so that's

1799
01:12:01,520 --> 01:12:06,840
where we start reconstruction without

1800
01:12:02,920 --> 01:12:08,440
any prior estimates of poses um uh we've

1801
01:12:06,840 --> 01:12:10,560
talked about exhaustive search this

1802
01:12:08,440 --> 01:12:12,159
hierarchical kind of grid search which

1803
01:12:10,560 --> 01:12:13,320
is very robust to high noise levels

1804
01:12:12,159 --> 01:12:14,880
because we're kind of exhaustively

1805
01:12:13,320 --> 01:12:16,880
enumerating the whole space and testing

1806
01:12:14,880 --> 01:12:18,920
them all it's very slow so we're not

1807
01:12:16,880 --> 01:12:21,760
doing 19 million slices but we're doing

1808
01:12:18,920 --> 01:12:23,280
you know thousands of slices um and

1809
01:12:21,760 --> 01:12:24,760
especially with a neural model where we

1810
01:12:23,280 --> 01:12:26,360
have to do a full forward pass through

1811
01:12:24,760 --> 01:12:29,040
neural network

1812
01:12:26,360 --> 01:12:30,639
slow um our loss function is

1813
01:12:29,040 --> 01:12:32,199
differentiable with respect to our POS

1814
01:12:30,639 --> 01:12:34,440
varibles so we can you know just do

1815
01:12:32,199 --> 01:12:36,880
direct gradient descent on our poses

1816
01:12:34,440 --> 01:12:39,000
that's very fast but this requires

1817
01:12:36,880 --> 01:12:41,159
initialization um and then we've also

1818
01:12:39,000 --> 01:12:43,080
explored various kind of amortized

1819
01:12:41,159 --> 01:12:44,920
inference approaches or basically put on

1820
01:12:43,080 --> 01:12:46,239
our deep learning hats and then like ah

1821
01:12:44,920 --> 01:12:50,159
let's just train a model to predict the

1822
01:12:46,239 --> 01:12:51,960
pose given the image um this is very

1823
01:12:50,159 --> 01:12:54,360
fast to evaluate but this is also kind

1824
01:12:51,960 --> 01:12:56,199
of unstable to train it needs learning

1825
01:12:54,360 --> 01:13:00,000
and is tricky to show and kind of This

1826
01:12:56,199 --> 01:13:01,960
truly kind of generalized set okay um so

1827
01:13:00,000 --> 01:13:03,159
we've tried all the above and just

1828
01:13:01,960 --> 01:13:05,719
skipping to the

1829
01:13:03,159 --> 01:13:08,120
punchline um the latest version which

1830
01:13:05,719 --> 01:13:10,440
we've called crry Dragon AI incorporates

1831
01:13:08,120 --> 01:13:13,080
the exhaustive search and this SGD or

1832
01:13:10,440 --> 01:13:15,880
radiant disp based approach to POS and

1833
01:13:13,080 --> 01:13:18,920
really the research question is can we

1834
01:13:15,880 --> 01:13:21,040
perform singleshot abon reconstruction

1835
01:13:18,920 --> 01:13:22,440
of modern crime data sets they're very

1836
01:13:21,040 --> 01:13:24,159
large data sets that have millions of

1837
01:13:22,440 --> 01:13:25,880
crime images they're typically

1838
01:13:24,159 --> 01:13:29,120
unfiltered so there's kind of these

1839
01:13:25,880 --> 01:13:30,840
outliers in the distribution um and do

1840
01:13:29,120 --> 01:13:34,040
this in like a reasonable amount of time

1841
01:13:30,840 --> 01:13:36,040
so in kind of a scalable fashion um I

1842
01:13:34,040 --> 01:13:37,480
won't go into detail but we switch off

1843
01:13:36,040 --> 01:13:40,760
between this hierarchal post search and

1844
01:13:37,480 --> 01:13:43,360
an auto auto decoder framework um we

1845
01:13:40,760 --> 01:13:45,440
address kind of you know the trade-offs

1846
01:13:43,360 --> 01:13:46,320
between memorization of the input Imes

1847
01:13:45,440 --> 01:13:47,800
versus

1848
01:13:46,320 --> 01:13:51,719
generalization um there is

1849
01:13:47,800 --> 01:13:53,520
regularization from the neural model and

1850
01:13:51,719 --> 01:13:56,239
uh we've been able to show the discovery

1851
01:13:53,520 --> 01:14:02,239
of rare States from large kind of card

1852
01:13:56,239 --> 01:14:02,239
data sets and this is driven by axle R

1853
01:14:02,360 --> 01:14:07,040
and um there's a couple of directions

1854
01:14:05,159 --> 01:14:09,679
that we've even been extending our Cry

1855
01:14:07,040 --> 01:14:13,040
Dragon AI method uh and just really

1856
01:14:09,679 --> 01:14:16,719
quickly one is modeling complex mixtures

1857
01:14:13,040 --> 01:14:19,960
using a kind of mixture of neural Fields

1858
01:14:16,719 --> 01:14:21,760
so we call this model Hydra and kind of

1859
01:14:19,960 --> 01:14:24,880
One Direction we're pushing is instead

1860
01:14:21,760 --> 01:14:25,639
of you know a single neural field can we

1861
01:14:24,880 --> 01:14:27,120
have

1862
01:14:25,639 --> 01:14:29,600
like what what what is a bottleneck if

1863
01:14:27,120 --> 01:14:33,480
we really want to reconstruct a complex

1864
01:14:29,600 --> 01:14:34,760
mixture uh or complex sample so this is

1865
01:14:33,480 --> 01:14:37,520
kind of this hybrid architecture

1866
01:14:34,760 --> 01:14:40,600
combining Cry Dragon Ai and 3

1867
01:14:37,520 --> 01:14:43,440
classification um and we're doing both

1868
01:14:40,600 --> 01:14:46,000
inference of kind of uh which moral

1869
01:14:43,440 --> 01:14:48,760
field which class we're in as well as

1870
01:14:46,000 --> 01:14:51,400
the confirmational state and the poses

1871
01:14:48,760 --> 01:14:54,159
so it's a very very challenging inverse

1872
01:14:51,400 --> 01:14:56,520
problem um here's some results on a

1873
01:14:54,159 --> 01:14:59,840
synthetic data set we mix together uh

1874
01:14:56,520 --> 01:15:01,960
moving raboso moving spone and moving C

1875
01:14:59,840 --> 01:15:03,760
protein and we can reconstruct all three

1876
01:15:01,960 --> 01:15:06,159
classes simultaneously without any

1877
01:15:03,760 --> 01:15:09,080
labels of the lat unknown latent

1878
01:15:06,159 --> 01:15:12,239
variables and then apply to a real data

1879
01:15:09,080 --> 01:15:14,719
set of red blood cell lysate um we can

1880
01:15:12,239 --> 01:15:16,719
recover both this ryar complex and a

1881
01:15:14,719 --> 01:15:17,679
couple of other complexes present in the

1882
01:15:16,719 --> 01:15:20,320
data

1883
01:15:17,679 --> 01:15:21,960
set this is kind of doing the

1884
01:15:20,320 --> 01:15:23,560
hierarchical classification based

1885
01:15:21,960 --> 01:15:26,520
approach with prospark

1886
01:15:23,560 --> 01:15:29,000
and uh in contrast just using a single

1887
01:15:26,520 --> 01:15:30,639
neural field or Fri Dragon AI we get one

1888
01:15:29,000 --> 01:15:32,880
class that looks like the rer complex

1889
01:15:30,639 --> 01:15:34,440
but then the other class just or the

1890
01:15:32,880 --> 01:15:36,880
other region in the Laten space or it's

1891
01:15:34,440 --> 01:15:39,040
just one class becomes a jumble of the

1892
01:15:36,880 --> 01:15:41,760
other kind

1893
01:15:39,040 --> 01:15:44,480
of that's one extension of this abon ISU

1894
01:15:41,760 --> 01:15:46,000
approach the second is moving into cry

1895
01:15:44,480 --> 01:15:47,960
and so I'll focus a little bit on this

1896
01:15:46,000 --> 01:15:50,719
on the kind of last end of the talk but

1897
01:15:47,960 --> 01:15:53,400
I'll just mention that instead of doing

1898
01:15:50,719 --> 01:15:55,360
uh cem or instead of having a single

1899
01:15:53,400 --> 01:15:58,280
image per particle now we have a series

1900
01:15:55,360 --> 01:16:00,199
of images we adapt this two-stage poses

1901
01:15:58,280 --> 01:16:03,639
procedure this is really driven by Rish

1902
01:16:00,199 --> 01:16:06,159
to the abono setting for subtomograms in

1903
01:16:03,639 --> 01:16:08,840
C2 um and then just showing one result

1904
01:16:06,159 --> 01:16:12,480
slide this is the kind of translation

1905
01:16:08,840 --> 01:16:16,000
elongation states of the 7ds ribosome uh

1906
01:16:12,480 --> 01:16:19,520
from Inu data fully trained fully

1907
01:16:16,000 --> 01:16:22,480
aition okay so we're making progress on

1908
01:16:19,520 --> 01:16:24,000
abon reconstruction one thing to note is

1909
01:16:22,480 --> 01:16:25,560
that all these kind of reconstruction

1910
01:16:24,000 --> 01:16:28,520
methods we've talked about about are

1911
01:16:25,560 --> 01:16:31,639
purely image data driven so we don't

1912
01:16:28,520 --> 01:16:33,960
kind of Leverage any information we have

1913
01:16:31,639 --> 01:16:37,000
about the underlying kind of chemistry

1914
01:16:33,960 --> 01:16:38,679
or the sequence of the mes so one I

1915
01:16:37,000 --> 01:16:39,760
think Direction that's very interesting

1916
01:16:38,679 --> 01:16:41,920
and I think a lot of people are working

1917
01:16:39,760 --> 01:16:43,280
on it right now is can we Bridge these

1918
01:16:41,920 --> 01:16:44,880
methods between protein structure

1919
01:16:43,280 --> 01:16:46,239
prediction we're using you know the

1920
01:16:44,880 --> 01:16:48,560
sequence information all the

1921
01:16:46,239 --> 01:16:50,159
evolutionary related sequences and

1922
01:16:48,560 --> 01:16:51,920
protein structor determination where we

1923
01:16:50,159 --> 01:16:53,920
taking kind of Imaging data and doing

1924
01:16:51,920 --> 01:16:55,360
this inverse problem analyzing the

1925
01:16:53,920 --> 01:16:57,159
measurement data

1926
01:16:55,360 --> 01:16:58,360
PRI reconstruction methods currently

1927
01:16:57,159 --> 01:17:00,600
don't leverage any of this PR

1928
01:16:58,360 --> 01:17:03,520
information about the underlying PR

1929
01:17:00,600 --> 01:17:05,199
physics but if we did could we you know

1930
01:17:03,520 --> 01:17:08,960
um push forward what we can get out of

1931
01:17:05,199 --> 01:17:11,000
data yeah um On a related note it's not

1932
01:17:08,960 --> 01:17:13,639
really directly about the you know

1933
01:17:11,000 --> 01:17:15,840
protein language model to um or or the

1934
01:17:13,639 --> 01:17:16,920
sequence to structure but um it seems to

1935
01:17:15,840 --> 01:17:20,440
me

1936
01:17:16,920 --> 01:17:23,080
that the at least the two types of

1937
01:17:20,440 --> 01:17:25,159
images that uh R showed in the end there

1938
01:17:23,080 --> 01:17:26,800
was a ribosome in the beginning was a

1939
01:17:25,159 --> 01:17:30,280
different protein those looked very

1940
01:17:26,800 --> 01:17:32,320
different so it occurs to me that it may

1941
01:17:30,280 --> 01:17:35,679
be able to one may be able to classify

1942
01:17:32,320 --> 01:17:37,040
these to the cropped images as this

1943
01:17:35,679 --> 01:17:40,040
protein even if we don't know what the

1944
01:17:37,040 --> 01:17:42,840
confirmation is and maybe yeah do some

1945
01:17:40,040 --> 01:17:45,199
sort of supervision on I think that

1946
01:17:42,840 --> 01:17:47,080
would be really interesting uh because I

1947
01:17:45,199 --> 01:17:48,280
think this purely unsupervised way it's

1948
01:17:47,080 --> 01:17:50,040
just going to get harder and harder with

1949
01:17:48,280 --> 01:17:52,080
more more complex samples and we do know

1950
01:17:50,040 --> 01:17:53,639
a lot of stuff maybe we don't even need

1951
01:17:52,080 --> 01:17:54,679
the sequence we just need like templates

1952
01:17:53,639 --> 01:17:55,639
or something like that so I think that

1953
01:17:54,679 --> 01:17:56,880
would would definitely be a really

1954
01:17:55,639 --> 01:17:59,440
interesting Direction but it's not

1955
01:17:56,880 --> 01:18:01,840
really done yet no

1956
01:17:59,440 --> 01:18:05,480
okay good

1957
01:18:01,840 --> 01:18:08,080
research cool okay so I don't have

1958
01:18:05,480 --> 01:18:09,600
anything super kind of groundbreaking

1959
01:18:08,080 --> 01:18:11,760
but one kind of proof of concept

1960
01:18:09,600 --> 01:18:13,280
direction that we've been taking is to

1961
01:18:11,760 --> 01:18:15,560
use these pre-trained protein diff

1962
01:18:13,280 --> 01:18:17,199
Fusion models as a prior in various

1963
01:18:15,560 --> 01:18:19,639
types of inverse problems in protein

1964
01:18:17,199 --> 01:18:21,440
space um and so this we're not tackling

1965
01:18:19,639 --> 01:18:23,520
3D reconstruction yet but we've been

1966
01:18:21,440 --> 01:18:25,080
doing some toy experiments uh where

1967
01:18:23,520 --> 01:18:27,679
we're filling in kind of doing like

1968
01:18:25,080 --> 01:18:30,600
protein infilling uh kind of uh

1969
01:18:27,679 --> 01:18:33,199
satisfaction of NMR distance restraints

1970
01:18:30,600 --> 01:18:34,920
and cry atomic model building and here

1971
01:18:33,199 --> 01:18:36,960
we're what we're doing is turning

1972
01:18:34,920 --> 01:18:39,560
partial and noisy measurements from our

1973
01:18:36,960 --> 01:18:42,560
experimental data uh and combining this

1974
01:18:39,560 --> 01:18:44,840
with a uh pre-trained diffusion model

1975
01:18:42,560 --> 01:18:44,840
here

1976
01:18:44,880 --> 01:18:50,000
chome um one thing to kind of keep in

1977
01:18:47,679 --> 01:18:52,400
mind uh that is always top of Mind

1978
01:18:50,000 --> 01:18:55,480
especially when we're combining these

1979
01:18:52,400 --> 01:18:57,719
maybe like uh large generative models

1980
01:18:55,480 --> 01:18:59,239
trained on existing proteins versus new

1981
01:18:57,719 --> 01:19:01,760
experimental data of new proteins that

1982
01:18:59,239 --> 01:19:04,120
we want to solve is how much do these

1983
01:19:01,760 --> 01:19:06,120
kind of pre-trained models limit the

1984
01:19:04,120 --> 01:19:08,480
ability to discover new things so I

1985
01:19:06,120 --> 01:19:10,400
think that's like one maybe just core

1986
01:19:08,480 --> 01:19:12,520
question to ask and core question to

1987
01:19:10,400 --> 01:19:15,080
consider especially with respect to

1988
01:19:12,520 --> 01:19:18,719
validation um and just with respect to

1989
01:19:15,080 --> 01:19:18,719
what do you want to get out of your

1990
01:19:19,080 --> 01:19:25,639
expens um and so that you know led to

1991
01:19:23,159 --> 01:19:28,560
kind of this project on Venture Mar

1992
01:19:25,639 --> 01:19:30,400
right so now with these kind of large

1993
01:19:28,560 --> 01:19:31,719
protein generative models maybe with

1994
01:19:30,400 --> 01:19:35,360
some of these other reconstruction

1995
01:19:31,719 --> 01:19:38,600
methods that use more you know um like

1996
01:19:35,360 --> 01:19:40,360
opinionated forward models uh how do we

1997
01:19:38,600 --> 01:19:42,120
actually un how do we actually interpret

1998
01:19:40,360 --> 01:19:43,040
the results especially when we're

1999
01:19:42,120 --> 01:19:45,840
considering

2000
01:19:43,040 --> 01:19:47,840
K so we're in an era now where

2001
01:19:45,840 --> 01:19:49,440
reconstruction of these molecular movies

2002
01:19:47,840 --> 01:19:52,120
is possible you get these like really

2003
01:19:49,440 --> 01:19:54,199
compelling and beautiful visualizations

2004
01:19:52,120 --> 01:19:55,480
of these macro machines so here's like a

2005
01:19:54,199 --> 01:19:58,239
couple different

2006
01:19:55,480 --> 01:19:59,880
methods um the representation so like

2007
01:19:58,239 --> 01:20:02,760
how we actually model this distribution

2008
01:19:59,880 --> 01:20:04,679
of volumes matters it really can

2009
01:20:02,760 --> 01:20:06,440
potentially it does bias the results of

2010
01:20:04,679 --> 01:20:07,960
the rec construction and it should

2011
01:20:06,440 --> 01:20:10,400
really depend on kind of what prior

2012
01:20:07,960 --> 01:20:13,159
information we have about the system and

2013
01:20:10,400 --> 01:20:16,239
also what biological question we want to

2014
01:20:13,159 --> 01:20:19,960
answer one kind of

2015
01:20:16,239 --> 01:20:22,280
unfortunate uh you know uh truth is that

2016
01:20:19,960 --> 01:20:24,719
there's no ground Truth For Real data so

2017
01:20:22,280 --> 01:20:26,480
we don't really know what's in the data

2018
01:20:24,719 --> 01:20:28,360
and evaluation especially when we're

2019
01:20:26,480 --> 01:20:30,320
kind of comparing these different models

2020
01:20:28,360 --> 01:20:32,520
currently requires just benchmarking by

2021
01:20:30,320 --> 01:20:35,520
eye so like does this look reasonable

2022
01:20:32,520 --> 01:20:35,520
does not our

2023
01:20:36,040 --> 01:20:41,000
priors um and so in Prior bench uh this

2024
01:20:39,280 --> 01:20:45,440
was led by minku a graduate student in

2025
01:20:41,000 --> 01:20:47,480
the group uh we built a large data set a

2026
01:20:45,440 --> 01:20:49,719
large synthetic data set modeling

2027
01:20:47,480 --> 01:20:52,960
different types of p8 so I'll go over

2028
01:20:49,719 --> 01:20:54,800
that uh briefly and then we benchmarked

2029
01:20:52,960 --> 01:20:57,760
10 different methods uh both deep

2030
01:20:54,800 --> 01:21:00,280
learning based linear nonlinear abono

2031
01:20:57,760 --> 01:21:01,920
methods and also came up with new

2032
01:21:00,280 --> 01:21:05,080
metrics and ways of comparing these

2033
01:21:01,920 --> 01:21:06,639
different het construction methods um

2034
01:21:05,080 --> 01:21:09,320
one thing that I think is particularly

2035
01:21:06,639 --> 01:21:11,159
useful for methods developers is the

2036
01:21:09,320 --> 01:21:13,760
different kinds of data sets that we

2037
01:21:11,159 --> 01:21:17,000
developed so we have both kind of easier

2038
01:21:13,760 --> 01:21:19,440
versions of both compet and compet that

2039
01:21:17,000 --> 01:21:22,040
are useful for Diagnostic purposes so

2040
01:21:19,440 --> 01:21:23,560
this IG 1D is an IGG antibody that has

2041
01:21:22,040 --> 01:21:25,199
this simple onedimensional circular

2042
01:21:23,560 --> 01:21:27,120
motion and so what you're looking for in

2043
01:21:25,199 --> 01:21:30,800
the latent space is a nice Rainbow

2044
01:21:27,120 --> 01:21:32,639
Circle um and also ribos assembly which

2045
01:21:30,800 --> 01:21:35,520
is a mixture of ribosomes so very

2046
01:21:32,639 --> 01:21:38,320
economical PRM and then we are also

2047
01:21:35,520 --> 01:21:40,560
considering we designed very challenging

2048
01:21:38,320 --> 01:21:43,040
data sets where no methods currently

2049
01:21:40,560 --> 01:21:45,800
perform that well to motivate uh kind of

2050
01:21:43,040 --> 01:21:47,679
new methods development so one is iggl

2051
01:21:45,800 --> 01:21:50,080
so here we're kind of sampling random

2052
01:21:47,679 --> 01:21:52,239
dihedral angles from this Linker region

2053
01:21:50,080 --> 01:21:54,560
and so I think this is for an antibody

2054
01:21:52,239 --> 01:21:55,920
IGG antibody and the Fab is oriented

2055
01:21:54,560 --> 01:21:57,320
randomly but I think that's

2056
01:21:55,920 --> 01:21:59,120
representative of a lot of systems where

2057
01:21:57,320 --> 01:22:01,440
we have a smaller domain that's kind of

2058
01:21:59,120 --> 01:22:04,280
moving uh and is kind of disordered

2059
01:22:01,440 --> 01:22:07,480
relative to a larger fixed domain Spike

2060
01:22:04,280 --> 01:22:09,199
MD is a uh data set generated from a

2061
01:22:07,480 --> 01:22:12,560
longtime scale molecular Dynamic

2062
01:22:09,199 --> 01:22:14,280
simulation so instead of just like 100

2063
01:22:12,560 --> 01:22:16,320
underlying ground tree structures in

2064
01:22:14,280 --> 01:22:17,880
this data set there's 46,000 underlying

2065
01:22:16,320 --> 01:22:19,520
ground tree structures and so an

2066
01:22:17,880 --> 01:22:22,120
interesting question is how well does

2067
01:22:19,520 --> 01:22:24,040
the uh do the methods really approximate

2068
01:22:22,120 --> 01:22:26,840
this much kind of higher dimensional

2069
01:22:24,040 --> 01:22:29,280
spaces structures and then finally Tomo

2070
01:22:26,840 --> 01:22:31,480
toin 100 is a mixture of a 100 different

2071
01:22:29,280 --> 01:22:34,440
complexes commonly found within cells so

2072
01:22:31,480 --> 01:22:36,600
instead of sticking to you know four

2073
01:22:34,440 --> 01:22:39,080
different rib assembly ribosome assembly

2074
01:22:36,600 --> 01:22:41,000
States or a couple that you usually get

2075
01:22:39,080 --> 01:22:43,159
from these structural biology papers can

2076
01:22:41,000 --> 01:22:46,480
we push the envelope in terms of much

2077
01:22:43,159 --> 01:22:49,600
much larger sets of protein

2078
01:22:46,480 --> 01:22:52,000
complexes okay so cry we still

2079
01:22:49,600 --> 01:22:54,719
definitely want to check the results

2080
01:22:52,000 --> 01:22:57,239
qualitatively um so here's I think Crow

2081
01:22:54,719 --> 01:22:59,719
results on these different data sets so

2082
01:22:57,239 --> 01:23:02,199
again IGG 1D we have a nice mov Circle

2083
01:22:59,719 --> 01:23:06,679
ribos em we have like 16 different

2084
01:23:02,199 --> 01:23:08,960
clusters um and maybe in these cases for

2085
01:23:06,679 --> 01:23:12,000
Spike MD and Tomo 100 it becomes less

2086
01:23:08,960 --> 01:23:14,480
clear how we interpret the

2087
01:23:12,000 --> 01:23:17,000
results um and especially when we want

2088
01:23:14,480 --> 01:23:20,840
to compare between methods right and so

2089
01:23:17,000 --> 01:23:23,480
here's cryo dragon and a bunch of other

2090
01:23:20,840 --> 01:23:26,600
hetrogeneous reconstruction methods um

2091
01:23:23,480 --> 01:23:31,920
we have both rures and also plant spaces

2092
01:23:26,600 --> 01:23:31,920
and so yeah how do we analyze it

2093
01:23:34,480 --> 01:23:40,400
yeah so for like MD Spike um in this

2094
01:23:38,600 --> 01:23:41,440
situation like in the previous slide it

2095
01:23:40,400 --> 01:23:42,760
seemed like there were a continuous

2096
01:23:41,440 --> 01:23:44,280
distribution of States so would we

2097
01:23:42,760 --> 01:23:47,719
expect the um Maps over here to be kind

2098
01:23:44,280 --> 01:23:49,199
of as like with something doing well

2099
01:23:47,719 --> 01:23:50,840
would we be able to qualitatively tell

2100
01:23:49,199 --> 01:23:53,840
by saying like oh the um Maps look

2101
01:23:50,840 --> 01:23:56,000
relatively continuous in this case um

2102
01:23:53,840 --> 01:23:56,960
yes and no like you would think right

2103
01:23:56,000 --> 01:23:58,239
like if you have a continuous

2104
01:23:56,960 --> 01:24:00,239
distribution you would want a continuous

2105
01:23:58,239 --> 01:24:02,400
umap but then the layout of these latent

2106
01:24:00,239 --> 01:24:06,440
spaces is very arbitrary so how do you

2107
01:24:02,400 --> 01:24:09,560
actually you know Quant Quant quantify

2108
01:24:06,440 --> 01:24:11,480
the results or like quantify how well uh

2109
01:24:09,560 --> 01:24:13,639
these distributions are learn and what

2110
01:24:11,480 --> 01:24:16,480
can you really interpret of

2111
01:24:13,639 --> 01:24:18,080
these yeah very inspired by similar

2112
01:24:16,480 --> 01:24:19,960
challenges from the Single Cell

2113
01:24:18,080 --> 01:24:23,239
literature for

2114
01:24:19,960 --> 01:24:25,480
example um and so one nice thing is that

2115
01:24:23,239 --> 01:24:27,920
we do have quantification can because

2116
01:24:25,480 --> 01:24:30,320
this is synthetic data where we know all

2117
01:24:27,920 --> 01:24:31,679
of the latent variables all the unknown

2118
01:24:30,320 --> 01:24:34,120
variables that are hidden from

2119
01:24:31,679 --> 01:24:36,320
construction methods we can kind of

2120
01:24:34,120 --> 01:24:38,960
quantify these volume reconstruction

2121
01:24:36,320 --> 01:24:41,280
metrics um one thing that we note is no

2122
01:24:38,960 --> 01:24:43,239
method dominates dominates across the

2123
01:24:41,280 --> 01:24:44,920
different forms of hyrogen so like

2124
01:24:43,239 --> 01:24:48,119
compet

2125
01:24:44,920 --> 01:24:50,800
compet types of like confirmational

2126
01:24:48,119 --> 01:24:53,960
heterogenity abon reconstruction methods

2127
01:24:50,800 --> 01:24:56,440
are still needed so this like joint um

2128
01:24:53,960 --> 01:24:58,920
confirm inference and pose estimation is

2129
01:24:56,440 --> 01:25:02,000
very very challenging inverse problem

2130
01:24:58,920 --> 01:25:03,360
and these metrics they're they work you

2131
01:25:02,000 --> 01:25:05,000
can kind of compare you can make these

2132
01:25:03,360 --> 01:25:07,320
large tables which I think people in

2133
01:25:05,000 --> 01:25:08,880
machine learning really like um but

2134
01:25:07,320 --> 01:25:10,520
better metrics are still needed and I

2135
01:25:08,880 --> 01:25:12,840
think one interesting research Direction

2136
01:25:10,520 --> 01:25:15,600
especially if you come from both the

2137
01:25:12,840 --> 01:25:17,639
kind of ML and the structural biology

2138
01:25:15,600 --> 01:25:19,600
background is designing better metrics

2139
01:25:17,639 --> 01:25:21,440
maybe that are dat set specific that can

2140
01:25:19,600 --> 01:25:22,520
really answer kind of deeper questions

2141
01:25:21,440 --> 01:25:25,040
about you know the different

2142
01:25:22,520 --> 01:25:27,960
confirmational states uh in micro States

2143
01:25:25,040 --> 01:25:29,719
for example of them

2144
01:25:27,960 --> 01:25:31,440
likeed

2145
01:25:29,719 --> 01:25:34,320
okay

2146
01:25:31,440 --> 01:25:36,000
so what is this all working towards I've

2147
01:25:34,320 --> 01:25:38,239
talked about Avid issue reconstruction

2148
01:25:36,000 --> 01:25:41,400
I've talked about kind of benchmarking

2149
01:25:38,239 --> 01:25:43,760
and really the point of all this of this

2150
01:25:41,400 --> 01:25:46,080
heterogeneous reconstruction is to move

2151
01:25:43,760 --> 01:25:49,800
to in my opinion my opinion is to move

2152
01:25:46,080 --> 01:25:51,800
to more complex samples so instead of

2153
01:25:49,800 --> 01:25:53,880
like solving a single structure in its

2154
01:25:51,800 --> 01:25:54,800
confirmational state can we instead

2155
01:25:53,880 --> 01:25:57,960
solve

2156
01:25:54,800 --> 01:25:59,159
complex mixtures or even structures from

2157
01:25:57,960 --> 01:26:02,639
intact

2158
01:25:59,159 --> 01:26:04,800
cells okay now we can kind of talk about

2159
01:26:02,639 --> 01:26:06,639
cryo electric topography I will just do

2160
01:26:04,800 --> 01:26:09,719
that by showing

2161
01:26:06,639 --> 01:26:12,119
this um instead of a purified solution

2162
01:26:09,719 --> 01:26:14,360
of a molecule a purified solution of

2163
01:26:12,119 --> 01:26:18,280
your protein or bimolecular complex

2164
01:26:14,360 --> 01:26:19,760
interest here you have a whole cell a

2165
01:26:18,280 --> 01:26:21,840
whole cell is usually too big to be

2166
01:26:19,760 --> 01:26:24,880
electron transparent depending on the

2167
01:26:21,840 --> 01:26:29,400
cell um and so what you do is f ion be

2168
01:26:24,880 --> 01:26:31,199
Milling you use a beam of ions to Mill

2169
01:26:29,400 --> 01:26:34,560
away kind of

2170
01:26:31,199 --> 01:26:37,040
oblate a the top and bottom and so what

2171
01:26:34,560 --> 01:26:39,900
you're end up what you end up with is a

2172
01:26:37,040 --> 01:26:41,600
very thin cross-section of

2173
01:26:39,900 --> 01:26:45,520
[Music]

2174
01:26:41,600 --> 01:26:48,920
yourself and then instead of a single

2175
01:26:45,520 --> 01:26:50,480
image now we do tomography right so it's

2176
01:26:48,920 --> 01:26:51,960
the same electron microscope it's same

2177
01:26:50,480 --> 01:26:53,840
transmission electron microscope but

2178
01:26:51,960 --> 01:26:56,600
instead of just a single image now we

2179
01:26:53,840 --> 01:27:00,400
spread electron dose across a series of

2180
01:26:56,600 --> 01:27:02,679
images in practice 41 um so we take kind

2181
01:27:00,400 --> 01:27:06,159
of 41 images as we rotate this Imaging

2182
01:27:02,679 --> 01:27:08,920
stage and we see this 3D kind of slice

2183
01:27:06,159 --> 01:27:12,400
out of the cell in all these

2184
01:27:08,920 --> 01:27:16,880
different so this is a tomogram right

2185
01:27:12,400 --> 01:27:19,480
yep um so the ion beam Milling is lit

2186
01:27:16,880 --> 01:27:23,000
physically manipulating the cell um is

2187
01:27:19,480 --> 01:27:24,520
there any concern over that affecting

2188
01:27:23,000 --> 01:27:26,960
the

2189
01:27:24,520 --> 01:27:29,000
um confirmation that the proteins are in

2190
01:27:26,960 --> 01:27:32,000
or this

2191
01:27:29,000 --> 01:27:34,159
assembling yeah so it's already Frozen

2192
01:27:32,000 --> 01:27:36,520
beforehand but there is a lot of kind of

2193
01:27:34,159 --> 01:27:37,840
like sample preparation consideration so

2194
01:27:36,520 --> 01:27:39,080
if it's a large enough cell you want to

2195
01:27:37,840 --> 01:27:41,560
high pressure freeze it so it all

2196
01:27:39,080 --> 01:27:43,920
vitrifies at the same time and then this

2197
01:27:41,560 --> 01:27:46,480
is actually kind of beyond my area of

2198
01:27:43,920 --> 01:27:49,000
expertise but I think there's like a

2199
01:27:46,480 --> 01:27:50,600
plasma focused IMB Mill is less likely

2200
01:27:49,000 --> 01:27:53,480
to deposit a bunch of other stuff than

2201
01:27:50,600 --> 01:27:55,199
like a metal ion or something that so

2202
01:27:53,480 --> 01:27:58,040
there are you know thermofisher is

2203
01:27:55,199 --> 01:27:59,520
working on it and interested in people

2204
01:27:58,040 --> 01:28:02,719
buying their

2205
01:27:59,520 --> 01:28:06,080
stuff um okay and on the right this is a

2206
01:28:02,719 --> 01:28:08,639
tomogram so this is we take the like 41

2207
01:28:06,080 --> 01:28:11,840
separate images or the micrographs and

2208
01:28:08,639 --> 01:28:15,040
then just do a 3D reconstruction um and

2209
01:28:11,840 --> 01:28:19,199
we can visualize here you know a bag of

2210
01:28:15,040 --> 01:28:22,560
rib this is uh s

2211
01:28:19,199 --> 01:28:24,639
service and then I think what's been so

2212
01:28:22,560 --> 01:28:27,159
exciting about cry

2213
01:28:24,639 --> 01:28:30,520
is that even though we're looking at

2214
01:28:27,159 --> 01:28:32,639
things at low resolution we can

2215
01:28:30,520 --> 01:28:34,600
computationally kind of do the same

2216
01:28:32,639 --> 01:28:36,679
trick that we do in single particle PRI

2217
01:28:34,600 --> 01:28:38,600
so we can take individual instances of

2218
01:28:36,679 --> 01:28:40,760
our molecule of interest and

2219
01:28:38,600 --> 01:28:42,800
computationally like Orient them combine

2220
01:28:40,760 --> 01:28:45,159
the information aggregate the signal and

2221
01:28:42,800 --> 01:28:47,440
get ne Atomic resolution structures but

2222
01:28:45,159 --> 01:28:50,719
instead of you know a structure of your

2223
01:28:47,440 --> 01:28:53,360
protein in a kind of crystallin lattice

2224
01:28:50,719 --> 01:28:54,679
instead of the structure in kind of in

2225
01:28:53,360 --> 01:28:57,239
in a

2226
01:28:54,679 --> 01:28:59,199
aquous solution in vitro this is the

2227
01:28:57,239 --> 01:29:01,760
structure of the protein complex the

2228
01:28:59,199 --> 01:29:03,040
ribosome here in C so the actual native

2229
01:29:01,760 --> 01:29:06,239
structure that's closest to the

2230
01:29:03,040 --> 01:29:07,239
functional state of the of the molecule

2231
01:29:06,239 --> 01:29:09,600
of

2232
01:29:07,239 --> 01:29:12,199
exas um and in this case they were even

2233
01:29:09,600 --> 01:29:14,440
able to see the structure of a small

2234
01:29:12,199 --> 01:29:18,159
molecule antibiotic

2235
01:29:14,440 --> 01:29:20,960
M okay amazing so why don't we do this

2236
01:29:18,159 --> 01:29:24,800
for everything you know unfortunately

2237
01:29:20,960 --> 01:29:26,239
the cry processing workflow in practice

2238
01:29:24,800 --> 01:29:27,920
look something like this this is

2239
01:29:26,239 --> 01:29:31,000
literally the workflow that I think

2240
01:29:27,920 --> 01:29:34,600
Sager did to process some of our CR data

2241
01:29:31,000 --> 01:29:36,840
analysis um you can kind of appreciate

2242
01:29:34,600 --> 01:29:38,400
that the metadata is a lot more

2243
01:29:36,840 --> 01:29:41,320
complicated now because we have the set

2244
01:29:38,400 --> 01:29:44,320
of images 41 tilts you need to align

2245
01:29:41,320 --> 01:29:46,560
them all in 3D and like you know how

2246
01:29:44,320 --> 01:29:48,119
much you as you move the Imaging stage

2247
01:29:46,560 --> 01:29:50,719
but obviously you want to like

2248
01:29:48,119 --> 01:29:53,199
reestimate that and then you have to

2249
01:29:50,719 --> 01:29:54,360
like pick out the subtomograms and then

2250
01:29:53,199 --> 01:29:56,239
there's actually all these other

2251
01:29:54,360 --> 01:29:58,080
considerations on whether we take like

2252
01:29:56,239 --> 01:30:00,320
3D data versus 2D data and it just

2253
01:29:58,080 --> 01:30:03,199
becomes nightmare practice it's all

2254
01:30:00,320 --> 01:30:07,360
academic software as well so you know

2255
01:30:03,199 --> 01:30:10,880
yeah I'll just stop there um and in the

2256
01:30:07,360 --> 01:30:12,920
cray Dragon ET project um or I guess one

2257
01:30:10,880 --> 01:30:15,040
more point I want to make about this

2258
01:30:12,920 --> 01:30:17,760
kind of cry processing workflow is a lot

2259
01:30:15,040 --> 01:30:20,400
of the you know repetitive nature of it

2260
01:30:17,760 --> 01:30:22,400
is because of the heterogen because the

2261
01:30:20,400 --> 01:30:23,560
particle picking problem is not solved

2262
01:30:22,400 --> 01:30:25,199
although there is a recent kaggle

2263
01:30:23,560 --> 01:30:27,880
challenge about that you're headed by

2264
01:30:25,199 --> 01:30:29,400
the transer Imaging Institute um and so

2265
01:30:27,880 --> 01:30:30,560
you're picking a bunch of like random

2266
01:30:29,400 --> 01:30:32,639
stuff that's not necessarily your

2267
01:30:30,560 --> 01:30:34,920
protein of interest and then you are

2268
01:30:32,639 --> 01:30:36,440
computationally trying to filter it and

2269
01:30:34,920 --> 01:30:38,239
analyze the heterogenity and kind of

2270
01:30:36,440 --> 01:30:41,480
classify the different states and it's

2271
01:30:38,239 --> 01:30:43,440
very very slow and yeah that's the

2272
01:30:41,480 --> 01:30:44,880
heterogeneity is definitely one a

2273
01:30:43,440 --> 01:30:46,840
contribution to why this processing

2274
01:30:44,880 --> 01:30:50,000
workflow is a bit of a

2275
01:30:46,840 --> 01:30:51,320
nightmare um and so something that we

2276
01:30:50,000 --> 01:30:54,679
worked on in the group right when I

2277
01:30:51,320 --> 01:30:58,440
started is extending PR Dragon which

2278
01:30:54,679 --> 01:31:02,040
is ideally like in the ideal case useful

2279
01:30:58,440 --> 01:31:05,760
for single shot heterogen analysis um of

2280
01:31:02,040 --> 01:31:07,520
single particle data to PRI data so the

2281
01:31:05,760 --> 01:31:09,560
high level kind of schematic looks

2282
01:31:07,520 --> 01:31:11,600
pretty similar um and so the main

2283
01:31:09,560 --> 01:31:13,760
changes are instead of a single view

2284
01:31:11,600 --> 01:31:15,360
encoder we do a multi view encoder

2285
01:31:13,760 --> 01:31:18,199
actually this is a little bit different

2286
01:31:15,360 --> 01:31:19,960
than the standard way uh subtomograms

2287
01:31:18,199 --> 01:31:22,159
which are kind of these Sub sub volumes

2288
01:31:19,960 --> 01:31:24,719
are analyzed so we actually take the

2289
01:31:22,159 --> 01:31:27,880
under individual tilted sub

2290
01:31:24,719 --> 01:31:30,639
tilted images um and then the Ford Model

2291
01:31:27,880 --> 01:31:32,040
instead of single particle crym is cry

2292
01:31:30,639 --> 01:31:35,159
which is very similar we just have to

2293
01:31:32,040 --> 01:31:37,159
take into account kind of uh the details

2294
01:31:35,159 --> 01:31:41,440
about like electron dose

2295
01:31:37,159 --> 01:31:43,320
exposure yeah um and then kind of just

2296
01:31:41,440 --> 01:31:44,880
highlighting in single particle we have

2297
01:31:43,320 --> 01:31:47,199
single image but in soap tomogram

2298
01:31:44,880 --> 01:31:48,520
averaging we have kind of multiple views

2299
01:31:47,199 --> 01:31:50,920
which is actually kind of interesting

2300
01:31:48,520 --> 01:31:54,800
from a verical

2301
01:31:50,920 --> 01:31:56,880
standpoint and um in the kind of

2302
01:31:54,800 --> 01:32:01,320
development and Analysis of Cry Dragon

2303
01:31:56,880 --> 01:32:04,440
ET we were able to apply it to the same

2304
01:32:01,320 --> 01:32:07,320
um uh uh 7s ribosome from the

2305
01:32:04,440 --> 01:32:10,760
microplasmas pneumonia data set uh done

2306
01:32:07,320 --> 01:32:14,040
by the Muhammad Lab at Hy hyberg and see

2307
01:32:10,760 --> 01:32:16,239
the same kind of translational States um

2308
01:32:14,040 --> 01:32:18,440
and also in collaboration with

2309
01:32:16,239 --> 01:32:22,080
thermofisher they collected this very

2310
01:32:18,440 --> 01:32:24,560
large uh data set of plasma BM Lamela of

2311
01:32:22,080 --> 01:32:27,199
esier we were able to char

2312
01:32:24,560 --> 01:32:31,239
the confirm confirmational Landscapes of

2313
01:32:27,199 --> 01:32:33,520
the ribosomes and fat fatty acid

2314
01:32:31,239 --> 01:32:36,000
comp okay I think I'm actually going to

2315
01:32:33,520 --> 01:32:38,400
go through the PRI ET results kind of

2316
01:32:36,000 --> 01:32:40,119
quickly just to save time questions um

2317
01:32:38,400 --> 01:32:43,040
but again just the overall pipeline we

2318
01:32:40,119 --> 01:32:45,560
have a very M we reconstruct a 3D

2319
01:32:43,040 --> 01:32:48,040
tomogram and then we pick the individual

2320
01:32:45,560 --> 01:32:49,960
instances solve their structures get the

2321
01:32:48,040 --> 01:32:51,480
confirmational Landscapes and then in in

2322
01:32:49,960 --> 01:32:53,960
addition to seeing the confirmational

2323
01:32:51,480 --> 01:32:56,400
states we can also map them back in

2324
01:32:53,960 --> 01:32:59,440
spatial context so I think that's a

2325
01:32:56,400 --> 01:33:01,679
really powerful aspect of Cry

2326
01:32:59,440 --> 01:33:03,960
Dragon this is what we get out of cry

2327
01:33:01,679 --> 01:33:06,719
drag e so here's Laten space

2328
01:33:03,960 --> 01:33:09,800
representation in this case maybe like a

2329
01:33:06,719 --> 01:33:12,600
130,000 particles of the ribosome sorry

2330
01:33:09,800 --> 01:33:15,199
19,000 particles and just by visual

2331
01:33:12,600 --> 01:33:17,840
inspection we had one class that was one

2332
01:33:15,199 --> 01:33:20,360
cluster that was just like kind of drunk

2333
01:33:17,840 --> 01:33:23,000
particles one cluster that looked like

2334
01:33:20,360 --> 01:33:24,920
the ribosome in the rotated State and

2335
01:33:23,000 --> 01:33:27,719
one class that looked like the ribosome

2336
01:33:24,920 --> 01:33:29,880
where the small sub small subun small

2337
01:33:27,719 --> 01:33:32,840
subunit was in the non rotated

2338
01:33:29,880 --> 01:33:35,040
State um because we don't want our model

2339
01:33:32,840 --> 01:33:37,000
to be wasting its expressive capacity on

2340
01:33:35,040 --> 01:33:39,000
these bad particles we just filter the

2341
01:33:37,000 --> 01:33:41,040
data set with the good particles TR it

2342
01:33:39,000 --> 01:33:43,239
again we again see this nice kind of

2343
01:33:41,040 --> 01:33:45,320
partition partitioning of the two

2344
01:33:43,239 --> 01:33:47,960
rotations

2345
01:33:45,320 --> 01:33:49,719
St um and then we dug deeper so we're

2346
01:33:47,960 --> 01:33:51,920
not just looking into the two like

2347
01:33:49,719 --> 01:33:54,520
rotate ratcheted and not ratcheted State

2348
01:33:51,920 --> 01:33:56,679
we uh just like visualized mapped out

2349
01:33:54,520 --> 01:33:59,119
all these different Elation factors

2350
01:33:56,679 --> 01:34:00,639
initiation factors and also the actual

2351
01:33:59,119 --> 01:34:03,560
TRNA

2352
01:34:00,639 --> 01:34:06,040
finding um

2353
01:34:03,560 --> 01:34:08,920
and that sh

2354
01:34:06,040 --> 01:34:11,000
right so these you know especially if

2355
01:34:08,920 --> 01:34:13,159
you're a maybe crystallographer this is

2356
01:34:11,000 --> 01:34:15,400
like very Blobby uh right so you don't

2357
01:34:13,159 --> 01:34:17,320
like see the high resolution details but

2358
01:34:15,400 --> 01:34:19,159
then we what we did in this case is we

2359
01:34:17,320 --> 01:34:20,840
used Crow Dragon to kind of classify

2360
01:34:19,159 --> 01:34:23,000
these different states and then we can

2361
01:34:20,840 --> 01:34:25,719
do the traditional back projection using

2362
01:34:23,000 --> 01:34:25,719
the full resolution

2363
01:34:26,199 --> 01:34:31,440
higher resolution structures of these um

2364
01:34:28,880 --> 01:34:31,440
translation

2365
01:34:31,719 --> 01:34:36,080
elongation um as another kind of

2366
01:34:34,000 --> 01:34:39,080
demonstration instead of the ribosomes

2367
01:34:36,080 --> 01:34:41,719
which are very abundant we also analyzed

2368
01:34:39,080 --> 01:34:43,600
uh the fatty a syas complex so the

2369
01:34:41,719 --> 01:34:46,040
traditional kind of subram averaging

2370
01:34:43,600 --> 01:34:48,159
approach uh from the picked particles

2371
01:34:46,040 --> 01:34:50,679
looks something like this when we look

2372
01:34:48,159 --> 01:34:53,440
at the same data set with PRI Dragon ET

2373
01:34:50,679 --> 01:34:54,600
we get this Laten space and we see kind

2374
01:34:53,440 --> 01:34:57,239
of

2375
01:34:54,600 --> 01:34:59,159
a distribution of structures only one

2376
01:34:57,239 --> 01:35:02,119
region of which actually looks like the

2377
01:34:59,159 --> 01:35:06,159
fatty acid inas complex so when we take

2378
01:35:02,119 --> 01:35:08,159
the subset of particles and then do a uh

2379
01:35:06,159 --> 01:35:10,639
refinement a traditional refinement we

2380
01:35:08,159 --> 01:35:13,840
now get a much higher resolution

2381
01:35:10,639 --> 01:35:16,600
beautiful structure of the East P

2382
01:35:13,840 --> 01:35:19,000
acid on the left is showing kind of the

2383
01:35:16,600 --> 01:35:23,880
training progression of a crow Dragon ET

2384
01:35:19,000 --> 01:35:25,719
model um on oh so on just like the the

2385
01:35:23,880 --> 01:35:28,600
full data set and I think one of the

2386
01:35:25,719 --> 01:35:30,800
main uh takeaways was that this is hap

2387
01:35:28,600 --> 01:35:32,880
this happens on like you know less than

2388
01:35:30,800 --> 01:35:35,080
an hour so like in only a few minutes we

2389
01:35:32,880 --> 01:35:37,360
can actually distinguish good from bad

2390
01:35:35,080 --> 01:35:40,199
which would be really good for this kind

2391
01:35:37,360 --> 01:35:42,679
of very slow classification process that

2392
01:35:40,199 --> 01:35:45,159
takes like weeks or

2393
01:35:42,679 --> 01:35:47,199
longer we run a new model on just this

2394
01:35:45,159 --> 01:35:49,520
subset of around 5,000 like quote

2395
01:35:47,199 --> 01:35:51,679
unquote bonified particles we actually

2396
01:35:49,520 --> 01:35:54,199
begin to see the very subtle rotations

2397
01:35:51,679 --> 01:35:57,360
of this B Bas complex

2398
01:35:54,199 --> 01:36:02,000
um between the two known

2399
01:35:57,360 --> 01:36:04,000
States um kind of big picture so we can

2400
01:36:02,000 --> 01:36:06,639
visualize these interesting

2401
01:36:04,000 --> 01:36:09,000
intermolecular um confirmations one

2402
01:36:06,639 --> 01:36:10,360
thing that's interesting is integrating

2403
01:36:09,000 --> 01:36:13,360
this processing Pipeline with the

2404
01:36:10,360 --> 01:36:14,600
traditional proc processing pipeline um

2405
01:36:13,360 --> 01:36:17,400
something that Rish has been working on

2406
01:36:14,600 --> 01:36:19,360
recently is aono reconstruction and cry

2407
01:36:17,400 --> 01:36:22,040
where we have like much more complex

2408
01:36:19,360 --> 01:36:25,040
samples since this is the actual kind of

2409
01:36:22,040 --> 01:36:29,080
collection of pren compli that you see

2410
01:36:25,040 --> 01:36:31,360
uh in Vivo yeah in C and so can we

2411
01:36:29,080 --> 01:36:33,600
actually process this in silico to

2412
01:36:31,360 --> 01:36:35,800
reconstruct

2413
01:36:33,600 --> 01:36:37,119
molecular this is a slide from my Therma

2414
01:36:35,800 --> 01:36:39,639
Fisher collaborator although I think

2415
01:36:37,119 --> 01:36:42,159
he's recently moved to St Jude um

2416
01:36:39,639 --> 01:36:44,480
traditionally in structural biology the

2417
01:36:42,159 --> 01:36:46,440
analysis of data sets is per very kind

2418
01:36:44,480 --> 01:36:48,960
of like done by the group so each group

2419
01:36:46,440 --> 01:36:52,560
will analyze collect a data set analyze

2420
01:36:48,960 --> 01:36:54,520
it then deposit into to the pdb priority

2421
01:36:52,560 --> 01:36:56,880
data kind of fundamentally breaks the

2422
01:36:54,520 --> 01:37:00,800
Paradigm I think of structural biology

2423
01:36:56,880 --> 01:37:03,600
because in a couple ways one it's like

2424
01:37:00,800 --> 01:37:06,440
much large kind of much larger in scale

2425
01:37:03,600 --> 01:37:08,360
it's much more expensive um kind of

2426
01:37:06,440 --> 01:37:10,119
experimentally to collect the data

2427
01:37:08,360 --> 01:37:12,320
extremely expensive computationally to

2428
01:37:10,119 --> 01:37:13,840
process the data it's very very hard and

2429
01:37:12,320 --> 01:37:15,920
the data set doesn't just give you a

2430
01:37:13,840 --> 01:37:18,840
single structure it gets you kind of the

2431
01:37:15,920 --> 01:37:19,920
entire molecular details of the whole uh

2432
01:37:18,840 --> 01:37:22,480
the whole

2433
01:37:19,920 --> 01:37:25,080
organism um and so I think there's this

2434
01:37:22,480 --> 01:37:26,600
new paradigm that that uh especially

2435
01:37:25,080 --> 01:37:28,960
Folks at the Chan Zuckerberg Imaging

2436
01:37:26,600 --> 01:37:32,119
Institute are really kind of inspired to

2437
01:37:28,960 --> 01:37:33,360
do which is um instead of all kind of

2438
01:37:32,119 --> 01:37:35,679
working on different things all

2439
01:37:33,360 --> 01:37:38,960
collaborating together and

2440
01:37:35,679 --> 01:37:38,960
analyzing as a

2441
01:37:39,360 --> 01:37:44,040
community um and so to summarize um

2442
01:37:42,440 --> 01:37:47,520
again just recapitulating some of the

2443
01:37:44,040 --> 01:37:49,520
things that Rish said so crym and cry

2444
01:37:47,520 --> 01:37:52,639
are particularly interesting modalities

2445
01:37:49,520 --> 01:37:54,080
since we capture this new type of data

2446
01:37:52,639 --> 01:37:56,920
of um

2447
01:37:54,080 --> 01:37:59,080
um you know where molecules are in a

2448
01:37:56,920 --> 01:38:01,480
quote near native state sampled from a

2449
01:37:59,080 --> 01:38:03,080
quote equilibrium distribution cations

2450
01:38:01,480 --> 01:38:06,560
where these quotation marks are the

2451
01:38:03,080 --> 01:38:09,320
caveats uh due to sample kind of

2452
01:38:06,560 --> 01:38:10,840
preparation there are now many Tools in

2453
01:38:09,320 --> 01:38:13,560
addition to cry Dragon becoming

2454
01:38:10,840 --> 01:38:15,440
available to study hogen and cryoem so

2455
01:38:13,560 --> 01:38:16,920
as a practitioner kind of the choice and

2456
01:38:15,440 --> 01:38:18,599
algorithm encodes a lot of different

2457
01:38:16,920 --> 01:38:20,400
assumptions about the heterogeneity that

2458
01:38:18,599 --> 01:38:22,000
you might visualize from the model and

2459
01:38:20,400 --> 01:38:24,040
so that's always important to keep in

2460
01:38:22,000 --> 01:38:27,360
mind that's driven our bench marking

2461
01:38:24,040 --> 01:38:28,719
work cry dragon's kind of neural field

2462
01:38:27,360 --> 01:38:31,239
is a very expressive model of

2463
01:38:28,719 --> 01:38:34,199
heterogeneity and so I think that's nice

2464
01:38:31,239 --> 01:38:36,320
to be able to discover new States in a

2465
01:38:34,199 --> 01:38:38,320
relatively unbiased setting as well as

2466
01:38:36,320 --> 01:38:40,960
visualize these continuous

2467
01:38:38,320 --> 01:38:42,920
Dynamics um and then the last thing I

2468
01:38:40,960 --> 01:38:47,320
want to end on is a couple of thoughts

2469
01:38:42,920 --> 01:38:47,320
of crym in this post Al

2470
01:38:48,480 --> 01:38:56,560
era or not there we go so what's next

2471
01:38:53,960 --> 01:38:58,280
um I definitely think there are very

2472
01:38:56,560 --> 01:38:59,840
interesting things to do in just this

2473
01:38:58,280 --> 01:39:02,080
machine learning for cing reconstruction

2474
01:38:59,840 --> 01:39:05,159
setting for heterogenity how do we bring

2475
01:39:02,080 --> 01:39:06,800
in the kind of underlying Atomic models

2476
01:39:05,159 --> 01:39:09,520
um or the underlying chemistry or

2477
01:39:06,800 --> 01:39:11,599
physics but I do think kind of models

2478
01:39:09,520 --> 01:39:14,239
that break this Paradigm will be very

2479
01:39:11,599 --> 01:39:16,320
kind of uh beneficial for the whole carg

2480
01:39:14,239 --> 01:39:18,360
and processing pipeline we can really

2481
01:39:16,320 --> 01:39:21,800
broaden the scope to more challenging

2482
01:39:18,360 --> 01:39:24,040
targets or challenging systems um PRM

2483
01:39:21,800 --> 01:39:25,599
right now is still you know quite

2484
01:39:24,040 --> 01:39:26,840
bespoke and manually intensive

2485
01:39:25,599 --> 01:39:28,920
especially this traditional 3D

2486
01:39:26,840 --> 01:39:31,679
classification procedure so can we you

2487
01:39:28,920 --> 01:39:33,280
know commoditize and just like automate

2488
01:39:31,679 --> 01:39:36,159
a bunch of the crry and

2489
01:39:33,280 --> 01:39:38,239
processing and can kind of new machine

2490
01:39:36,159 --> 01:39:40,040
learning methods motivate different

2491
01:39:38,239 --> 01:39:42,199
paradigms for Imaging and processing

2492
01:39:40,040 --> 01:39:45,360
right so are really stuck to just like

2493
01:39:42,199 --> 01:39:47,000
single image and uh can we design

2494
01:39:45,360 --> 01:39:48,760
different ways of collecting the data

2495
01:39:47,000 --> 01:39:52,840
for header

2496
01:39:48,760 --> 01:39:55,400
sh obviously moving forward kind of the

2497
01:39:52,840 --> 01:39:59,400
uh one kind of main takeaway I have of

2498
01:39:55,400 --> 01:40:00,800
especially crime data is that um these

2499
01:39:59,400 --> 01:40:03,199
current generation of structure

2500
01:40:00,800 --> 01:40:03,960
prediction models don't predict dynamics

2501
01:40:03,199 --> 01:40:06,440
that well like the different

2502
01:40:03,960 --> 01:40:09,360
confirmational ensembles and so if we

2503
01:40:06,440 --> 01:40:11,119
can just collect the data to train the

2504
01:40:09,360 --> 01:40:12,679
next generation of prediction or design

2505
01:40:11,119 --> 01:40:14,599
algorithms I think that would be very

2506
01:40:12,679 --> 01:40:16,840
exciting so closing the loop between

2507
01:40:14,599 --> 01:40:19,920
prediction and determination and really

2508
01:40:16,840 --> 01:40:21,679
kind of unlocking new applications um in

2509
01:40:19,920 --> 01:40:23,360
kind of understanding Pro Dynamics

2510
01:40:21,679 --> 01:40:25,719
proing design and also the interaction

2511
01:40:23,360 --> 01:40:28,119
ction with other types of molecules that

2512
01:40:25,719 --> 01:40:31,040
are not as commonly

2513
01:40:28,119 --> 01:40:34,800
found and then finally bringing this all

2514
01:40:31,040 --> 01:40:37,159
together uh for Inu visual proteomics

2515
01:40:34,800 --> 01:40:40,119
with Technologies like Crow as well as

2516
01:40:37,159 --> 01:40:43,080
other types of biochemical and

2517
01:40:40,119 --> 01:40:47,159
bio with that uh thank you all for

2518
01:40:43,080 --> 01:40:48,440
listening to two hours of prum almost um

2519
01:40:47,159 --> 01:40:51,000
and I would especially like to thank

2520
01:40:48,440 --> 01:40:53,880
members of my group so Raman and Ryan

2521
01:40:51,000 --> 01:40:55,679
drove the Cry Dragon ET project Axel has

2522
01:40:53,880 --> 01:40:58,520
been doing a ton of work on both post

2523
01:40:55,679 --> 01:41:01,040
estimation as well as our APD 3D method

2524
01:40:58,520 --> 01:41:02,920
which with the uh chroma or the prot

2525
01:41:01,040 --> 01:41:04,440
fusion models Rish has played an

2526
01:41:02,920 --> 01:41:07,000
instrumental role in like so many of

2527
01:41:04,440 --> 01:41:10,199
these different projects um mq drove cry

2528
01:41:07,000 --> 01:41:11,719
bench and Michael um has been supporting

2529
01:41:10,199 --> 01:41:14,560
the software and integrating a bunch of

2530
01:41:11,719 --> 01:41:16,679
these new methods into PR dragon as well

2531
01:41:14,560 --> 01:41:19,440
as uh like to thank the other members of

2532
01:41:16,679 --> 01:41:21,599
my group a bunch of our collaborators um

2533
01:41:19,440 --> 01:41:26,280
and our funding sources and thank you

2534
01:41:21,599 --> 01:41:26,280
all for listening e


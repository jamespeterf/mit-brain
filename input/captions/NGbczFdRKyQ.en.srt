1
00:00:00,160 --> 00:00:04,640
Thank you so much. Thank you Sherry. Uh

2
00:00:02,080 --> 00:00:06,720
it's been great to be here and uh I'm

3
00:00:04,640 --> 00:00:08,800
very inspired by this uh day of talks

4
00:00:06,720 --> 00:00:10,000
meeting with you all and uh thank you to

5
00:00:08,800 --> 00:00:12,320
Sarah as well. Thank you to the lids

6
00:00:10,000 --> 00:00:14,080
organizers. Thanks to everyone for uh

7
00:00:12,320 --> 00:00:16,960
making this so smooth. So yeah, this is

8
00:00:14,080 --> 00:00:20,400
called Mo Earth. Now we just rebranded a

9
00:00:16,960 --> 00:00:22,400
couple couple months ago. And so um

10
00:00:20,400 --> 00:00:24,320
Earth is the name of this new foundation

11
00:00:22,400 --> 00:00:25,680
model and platform that I'll be uh

12
00:00:24,320 --> 00:00:29,519
telling you guys about. We we launched

13
00:00:25,680 --> 00:00:32,399
this as Sher said uh just um just last

14
00:00:29,519 --> 00:00:34,480
week actually. So I said in the abstract

15
00:00:32,399 --> 00:00:36,320
Earth AI is surging in popularity and I

16
00:00:34,480 --> 00:00:39,040
uh I got feedback on this abstract from

17
00:00:36,320 --> 00:00:41,120
my wife which I always do and she said

18
00:00:39,040 --> 00:00:42,960
uh hey you know really love what you're

19
00:00:41,120 --> 00:00:45,520
doing but also it might be a bit of a

20
00:00:42,960 --> 00:00:47,600
stretch to say this is surging. And so I

21
00:00:45,520 --> 00:00:49,440
looked it up to prove to her that this

22
00:00:47,600 --> 00:00:51,280
was in fact the case and here's the

23
00:00:49,440 --> 00:00:52,879
interest over time. And I think it's

24
00:00:51,280 --> 00:00:56,000
rightfully that that inflection point is

25
00:00:52,879 --> 00:00:58,879
somewhere around uh mid this year. And

26
00:00:56,000 --> 00:01:01,840
so she believed me. But then to put it

27
00:00:58,879 --> 00:01:05,119
in context, of course, the LLM space has

28
00:01:01,840 --> 00:01:08,240
been uh rather dominant in the AI world

29
00:01:05,119 --> 00:01:10,960
of late. So in the end, we're both right

30
00:01:08,240 --> 00:01:13,280
and our marriage is still strong. Um but

31
00:01:10,960 --> 00:01:14,799
in in in in uh in more serious terms,

32
00:01:13,280 --> 00:01:17,200
like I think in general, AGI is

33
00:01:14,799 --> 00:01:20,320
receiving a ton of press, right? It's

34
00:01:17,200 --> 00:01:22,000
like basically constant. And I think

35
00:01:20,320 --> 00:01:23,360
it's

36
00:01:22,000 --> 00:01:25,920
maybe not the thing we need to be

37
00:01:23,360 --> 00:01:28,000
talking about. We we may or may not

38
00:01:25,920 --> 00:01:30,320
build AGI and you know different people

39
00:01:28,000 --> 00:01:32,479
will give you a different uh timeline

40
00:01:30,320 --> 00:01:34,079
for when that's going to occur. I don't

41
00:01:32,479 --> 00:01:36,320
think necessarily that just because we

42
00:01:34,079 --> 00:01:37,360
build AGI if we do in fact build it and

43
00:01:36,320 --> 00:01:39,680
we can talk about what the real

44
00:01:37,360 --> 00:01:41,119
definition is if we want. But even if we

45
00:01:39,680 --> 00:01:43,520
get there it's not going to magically

46
00:01:41,119 --> 00:01:45,200
solve all of our problems. And here are

47
00:01:43,520 --> 00:01:47,680
two papers, one from Microsoft and one

48
00:01:45,200 --> 00:01:50,960
from Anthropic about uh or maybe it's

49
00:01:47,680 --> 00:01:52,640
open AI about kind of what it would mean

50
00:01:50,960 --> 00:01:54,560
and and you know what would happen once

51
00:01:52,640 --> 00:01:56,720
we have AGI and perhaps we have sparks

52
00:01:54,560 --> 00:01:59,439
of AGI at this point. I think these are

53
00:01:56,720 --> 00:02:00,799
basically not the thing we should be

54
00:01:59,439 --> 00:02:02,479
focused on. I think we should be

55
00:02:00,799 --> 00:02:05,040
focusing on steering artificial

56
00:02:02,479 --> 00:02:07,360
intelligence towards our highest ideals

57
00:02:05,040 --> 00:02:10,160
towards what we think really matters um

58
00:02:07,360 --> 00:02:11,440
from the outset. So I'm from AI2 as Sher

59
00:02:10,160 --> 00:02:12,640
mentioned the Allen Institute of

60
00:02:11,440 --> 00:02:14,560
Artificial Intelligence. This is a

61
00:02:12,640 --> 00:02:16,640
nonprofit AI research institute that was

62
00:02:14,560 --> 00:02:20,000
founded about 10 years ago by uh the

63
00:02:16,640 --> 00:02:22,319
late Paul Allen uh Microsoft co-founder

64
00:02:20,000 --> 00:02:24,560
Paul Allen and our mission is to build

65
00:02:22,319 --> 00:02:27,040
AI for some of the world's big

66
00:02:24,560 --> 00:02:30,720
challenges and we build AI I would say a

67
00:02:27,040 --> 00:02:34,480
little bit differently from um perhaps

68
00:02:30,720 --> 00:02:37,120
from uh from the norm. So we first of

69
00:02:34,480 --> 00:02:39,519
all center the user from the outset of

70
00:02:37,120 --> 00:02:40,959
R&D and in our case that means literally

71
00:02:39,519 --> 00:02:42,400
speaking to users from the very

72
00:02:40,959 --> 00:02:43,920
beginning of the project from before we

73
00:02:42,400 --> 00:02:45,680
even start the model research and

74
00:02:43,920 --> 00:02:47,840
development talk project we're talking

75
00:02:45,680 --> 00:02:50,000
with the users who are going to be the

76
00:02:47,840 --> 00:02:51,840
recipients of that technology so we can

77
00:02:50,000 --> 00:02:53,760
ensure that whatever we're building is

78
00:02:51,840 --> 00:02:55,280
closely aligned with their interests and

79
00:02:53,760 --> 00:02:58,239
that might be an agriculture and food

80
00:02:55,280 --> 00:02:59,840
security or wildfire resilience or uh

81
00:02:58,239 --> 00:03:01,440
deforestation cause mapping in the

82
00:02:59,840 --> 00:03:02,959
Amazon. So we talk to those folks

83
00:03:01,440 --> 00:03:05,200
literally from the very beginning before

84
00:03:02,959 --> 00:03:06,959
we do any before we write any code to

85
00:03:05,200 --> 00:03:08,400
make sure that we understand what it is

86
00:03:06,959 --> 00:03:10,319
that we're trying to build and what

87
00:03:08,400 --> 00:03:12,800
success would look like from their

88
00:03:10,319 --> 00:03:15,440
perspective. Another big principle of

89
00:03:12,800 --> 00:03:17,760
AI2 and and uh that underlies our work

90
00:03:15,440 --> 00:03:19,360
is openness. So we strive for open

91
00:03:17,760 --> 00:03:21,040
artificial intelligence research and

92
00:03:19,360 --> 00:03:23,680
development and that means open code,

93
00:03:21,040 --> 00:03:25,920
open data, open training and evaluation.

94
00:03:23,680 --> 00:03:28,319
Uh all of our libraries are open. The

95
00:03:25,920 --> 00:03:30,720
the both pre and post training code are

96
00:03:28,319 --> 00:03:32,239
open. and we open the um these these

97
00:03:30,720 --> 00:03:33,440
libraries are on GitHub right now. You

98
00:03:32,239 --> 00:03:35,519
can look at all this stuff if you want

99
00:03:33,440 --> 00:03:37,200
to. You can inspect exactly what we did.

100
00:03:35,519 --> 00:03:39,760
Uh the models are of course available on

101
00:03:37,200 --> 00:03:41,599
hugging face the weights I should say

102
00:03:39,760 --> 00:03:42,879
and the training data that we use to to

103
00:03:41,599 --> 00:03:44,640
to build those models. So you can

104
00:03:42,879 --> 00:03:47,120
replicate exactly what we did. You can

105
00:03:44,640 --> 00:03:50,000
extend it. You can um critique it. You

106
00:03:47,120 --> 00:03:51,920
can find flaws uh and um and let us know

107
00:03:50,000 --> 00:03:53,440
and and uh we we take that very

108
00:03:51,920 --> 00:03:55,360
seriously and and and we care a lot

109
00:03:53,440 --> 00:03:57,200
about that. We also open source our

110
00:03:55,360 --> 00:03:59,040
production inference services. So a lot

111
00:03:57,200 --> 00:04:00,080
of the models I'm going to be talking to

112
00:03:59,040 --> 00:04:01,439
you about today, especially the

113
00:04:00,080 --> 00:04:03,280
applications are literally run. They're

114
00:04:01,439 --> 00:04:04,640
running right now in production. The

115
00:04:03,280 --> 00:04:06,400
exact same code that we're running in

116
00:04:04,640 --> 00:04:08,319
production right now is available to

117
00:04:06,400 --> 00:04:10,080
you. You can look at it. And then the

118
00:04:08,319 --> 00:04:11,599
final big difference I would say is that

119
00:04:10,080 --> 00:04:13,360
rather than just a model, we really want

120
00:04:11,599 --> 00:04:15,120
to support the full ML life cycle. And

121
00:04:13,360 --> 00:04:17,280
we see this as central to kind of

122
00:04:15,120 --> 00:04:20,560
putting the user at the center of

123
00:04:17,280 --> 00:04:21,680
development. So we are uh in this case

124
00:04:20,560 --> 00:04:24,160
uh I'll be talking to you about a

125
00:04:21,680 --> 00:04:25,759
platform that open that is the entire

126
00:04:24,160 --> 00:04:26,960
life cycle of machine learning uh

127
00:04:25,759 --> 00:04:28,800
research and development all the way

128
00:04:26,960 --> 00:04:31,280
from like raw data acquisition through

129
00:04:28,800 --> 00:04:33,120
training or through annotation training

130
00:04:31,280 --> 00:04:35,360
and so on. So we really strive for

131
00:04:33,120 --> 00:04:38,080
endto-end solutions which we think are

132
00:04:35,360 --> 00:04:39,840
um again really critical for our users

133
00:04:38,080 --> 00:04:42,400
and also these these three principles

134
00:04:39,840 --> 00:04:44,240
really are uh self-reinforcing. Um

135
00:04:42,400 --> 00:04:46,960
openness is really not a crutch it's

136
00:04:44,240 --> 00:04:48,320
it's an advantage. Um and and here are

137
00:04:46,960 --> 00:04:49,919
some examples of the applications that

138
00:04:48,320 --> 00:04:51,040
we've built on the AI for the planet

139
00:04:49,919 --> 00:04:52,880
team. So some of these you may have

140
00:04:51,040 --> 00:04:55,199
heard of. This talk is going to be

141
00:04:52,880 --> 00:04:57,199
focused on the earth but I want to give

142
00:04:55,199 --> 00:04:59,600
you guys a little bit of a a kind of

143
00:04:57,199 --> 00:05:01,040
motivation or like how we got to uh

144
00:04:59,600 --> 00:05:02,639
building wanting to build this like big

145
00:05:01,040 --> 00:05:04,560
open platform. So these are a bunch of

146
00:05:02,639 --> 00:05:07,520
programs that have been around for um in

147
00:05:04,560 --> 00:05:11,360
some cases many years um started at uh

148
00:05:07,520 --> 00:05:13,199
at AI2 and uh Skylight I want to talk a

149
00:05:11,360 --> 00:05:15,199
little bit about in detail because it

150
00:05:13,199 --> 00:05:16,560
offers some examples of kind of building

151
00:05:15,199 --> 00:05:18,160
these uh computer vision these

152
00:05:16,560 --> 00:05:19,840
artificial intelligence models at global

153
00:05:18,160 --> 00:05:22,320
scale for real-time applications for a

154
00:05:19,840 --> 00:05:25,199
bunch of users. Um and it was kind of a

155
00:05:22,320 --> 00:05:28,880
key motivating uh factor behind the

156
00:05:25,199 --> 00:05:30,479
creation of Omo Earth. So Paul Allen uh

157
00:05:28,880 --> 00:05:33,680
and and this is the AI for the planet

158
00:05:30,479 --> 00:05:35,840
team uh and

159
00:05:33,680 --> 00:05:37,840
I just wanted to recognize them. So this

160
00:05:35,840 --> 00:05:40,240
is it's I'm uh there's a large team

161
00:05:37,840 --> 00:05:44,720
that's uh built all this technology and

162
00:05:40,240 --> 00:05:47,600
um I'm just one person. So uh Paul Allen

163
00:05:44,720 --> 00:05:49,840
he uh he envisioned a future where so

164
00:05:47,600 --> 00:05:52,240
skylight was started about seven maybe

165
00:05:49,840 --> 00:05:53,840
eight years ago and Paul Allen thought

166
00:05:52,240 --> 00:05:55,199
that you know eventually artificial

167
00:05:53,840 --> 00:05:56,320
intelligence would get to a point and

168
00:05:55,199 --> 00:05:58,560
eventually there would be sufficient

169
00:05:56,320 --> 00:06:00,400
satellites uh in both frequency and

170
00:05:58,560 --> 00:06:02,320
revisit and everything that we would be

171
00:06:00,400 --> 00:06:05,039
able to basically constantly monitor the

172
00:06:02,320 --> 00:06:07,680
oceans like remote like high high seas

173
00:06:05,039 --> 00:06:09,759
basically with uh computer vision and

174
00:06:07,680 --> 00:06:13,680
this would enable uh maritime

175
00:06:09,759 --> 00:06:16,720
transparency um protection of uh marine

176
00:06:13,680 --> 00:06:18,479
protected areas and basically have have

177
00:06:16,720 --> 00:06:20,160
eyes on the water and and this

178
00:06:18,479 --> 00:06:22,240
transparency is of course critical to

179
00:06:20,160 --> 00:06:23,199
sustainability. So I'll talk to I'm

180
00:06:22,240 --> 00:06:25,759
going to talk a little bit about the

181
00:06:23,199 --> 00:06:27,600
models that we built um that enable

182
00:06:25,759 --> 00:06:29,199
this. So one side of the models are

183
00:06:27,600 --> 00:06:30,720
satellite imagery based detection. So

184
00:06:29,199 --> 00:06:32,080
this is like literally vessel detection

185
00:06:30,720 --> 00:06:33,840
on the high seas from a bunch of

186
00:06:32,080 --> 00:06:35,199
different satellites. Um satellites are

187
00:06:33,840 --> 00:06:36,880
constantly orbiting the earth of course

188
00:06:35,199 --> 00:06:38,880
and we and many of these sources prov

189
00:06:36,880 --> 00:06:41,840
are are public data. So we can take them

190
00:06:38,880 --> 00:06:43,280
and and do uh uh detection with them.

191
00:06:41,840 --> 00:06:44,800
And then the other side is is GPS

192
00:06:43,280 --> 00:06:47,919
sequence modeling which I I'll briefly

193
00:06:44,800 --> 00:06:49,600
touch on. This is just a quick primer. A

194
00:06:47,919 --> 00:06:51,440
lot of people in this room are probably

195
00:06:49,600 --> 00:06:52,800
very familiar with uh how this generally

196
00:06:51,440 --> 00:06:55,039
works. So I just want to walk through

197
00:06:52,800 --> 00:06:56,960
very quickly. Um so we have activity on

198
00:06:55,039 --> 00:06:58,639
in the remote areas somewhere on the

199
00:06:56,960 --> 00:07:00,319
high seas. We get an image from an

200
00:06:58,639 --> 00:07:02,720
orbiting satellite that's down linked to

201
00:07:00,319 --> 00:07:04,400
a ground station. Uh eventually copied

202
00:07:02,720 --> 00:07:06,240
to our servers. We run a model against

203
00:07:04,400 --> 00:07:08,800
that and then we serve this up via some

204
00:07:06,240 --> 00:07:10,639
API or GUI. In the case of Skylight, uh

205
00:07:08,800 --> 00:07:12,160
it's both. And this is serving currently

206
00:07:10,639 --> 00:07:15,120
a couple hundred or 300 or so

207
00:07:12,160 --> 00:07:18,080
organizations across like 60 countries.

208
00:07:15,120 --> 00:07:20,400
And this whole process uh occurs in like

209
00:07:18,080 --> 00:07:22,080
a matter of uh hours in the case of a

210
00:07:20,400 --> 00:07:24,400
satellite that I'm about to show in just

211
00:07:22,080 --> 00:07:26,240
90 minutes. So we need to make these

212
00:07:24,400 --> 00:07:28,160
models extremely accurate, extremely

213
00:07:26,240 --> 00:07:29,599
reliable because people depend on them

214
00:07:28,160 --> 00:07:31,919
and people are literally making

215
00:07:29,599 --> 00:07:34,479
decisions with very limited resources

216
00:07:31,919 --> 00:07:36,720
on, you know, on the basis of this

217
00:07:34,479 --> 00:07:38,960
information. So if you have a, you know,

218
00:07:36,720 --> 00:07:40,720
$50,000 fuel budget and we're saying,

219
00:07:38,960 --> 00:07:42,560
you know, we we see some activity out

220
00:07:40,720 --> 00:07:44,560
here and, you know, in this marine

221
00:07:42,560 --> 00:07:46,160
protected area, for example, uh we

222
00:07:44,560 --> 00:07:47,680
better be right. And we care a lot about

223
00:07:46,160 --> 00:07:50,000
being right and and false negatives and

224
00:07:47,680 --> 00:07:53,520
false positives both uh cause big

225
00:07:50,000 --> 00:07:55,199
problems. So here's one example just in

226
00:07:53,520 --> 00:07:57,199
more concrete terms like what exactly we

227
00:07:55,199 --> 00:07:58,240
built and why. So you probably know

228
00:07:57,199 --> 00:08:00,960
different satellites have different

229
00:07:58,240 --> 00:08:03,759
strengths and weaknesses. Uh Vers is a

230
00:08:00,960 --> 00:08:05,840
satellite that can see through uh see at

231
00:08:03,759 --> 00:08:07,680
night. So it's sensitive to light. Um

232
00:08:05,840 --> 00:08:10,240
it's actually exquisitly sensitive to

233
00:08:07,680 --> 00:08:13,520
night uh to to to light. You can pick

234
00:08:10,240 --> 00:08:15,680
out literally street lights on highways

235
00:08:13,520 --> 00:08:17,680
on the across the whole world. And if

236
00:08:15,680 --> 00:08:19,039
you have Earth at night on your phone or

237
00:08:17,680 --> 00:08:20,960
on an iPhone or whatever, this is the

238
00:08:19,039 --> 00:08:22,400
data that that's coming from. So the

239
00:08:20,960 --> 00:08:24,960
pretty pictures, it's called Black

240
00:08:22,400 --> 00:08:26,000
Marble comes from from this data. And

241
00:08:24,960 --> 00:08:28,080
there's a couple there's several

242
00:08:26,000 --> 00:08:29,520
satellites now that are public publicly

243
00:08:28,080 --> 00:08:31,840
available and support this uh this

244
00:08:29,520 --> 00:08:33,599
particular sensor. So couple great

245
00:08:31,840 --> 00:08:36,159
things about this satellite. It's uh the

246
00:08:33,599 --> 00:08:37,760
the it's we're getting real-time

247
00:08:36,159 --> 00:08:38,880
coverage or near real-time coverage, I

248
00:08:37,760 --> 00:08:40,560
should say. It's about 90 minutes from

249
00:08:38,880 --> 00:08:42,080
everywhere on Earth, and that's really

250
00:08:40,560 --> 00:08:43,760
quite good, especially for satellites.

251
00:08:42,080 --> 00:08:45,120
It's global. It's providing global

252
00:08:43,760 --> 00:08:47,839
coverage. So that's excellent. literally

253
00:08:45,120 --> 00:08:50,320
everywhere, high seas, land, everything.

254
00:08:47,839 --> 00:08:51,760
Uh there's a roughly a 3x uh three times

255
00:08:50,320 --> 00:08:53,680
a day revisit rate, which is really

256
00:08:51,760 --> 00:08:56,880
good. So you can see kind of successive

257
00:08:53,680 --> 00:08:59,200
snapshot successive pictures of the same

258
00:08:56,880 --> 00:09:01,040
uh vessel, but the spatial resolution is

259
00:08:59,200 --> 00:09:01,839
quite poor uh relatively speaking. So

260
00:09:01,040 --> 00:09:03,120
especially if you're doing something

261
00:09:01,839 --> 00:09:05,680
like object detection or vessel

262
00:09:03,120 --> 00:09:07,680
detection, 750 m is really not good. But

263
00:09:05,680 --> 00:09:10,720
you can see lights and if you're doing

264
00:09:07,680 --> 00:09:12,880
bad things uh uh you can probably turn

265
00:09:10,720 --> 00:09:14,399
off your GPS transponder for example but

266
00:09:12,880 --> 00:09:17,279
you can't turn off your lights or it's

267
00:09:14,399 --> 00:09:19,360
much more difficult to do so. Uh so we

268
00:09:17,279 --> 00:09:20,720
leverage the satellite for detection but

269
00:09:19,360 --> 00:09:24,080
it wasn't built for detection. It was

270
00:09:20,720 --> 00:09:26,399
built for clouds and for for detecting

271
00:09:24,080 --> 00:09:28,080
clouds for uh basically for atmospheric

272
00:09:26,399 --> 00:09:29,680
modeling for atmospheric purposes

273
00:09:28,080 --> 00:09:31,360
definitely not for vessel detection the

274
00:09:29,680 --> 00:09:34,240
way we've repurposed it here. So we've

275
00:09:31,360 --> 00:09:36,000
had to do some things to make it uh work

276
00:09:34,240 --> 00:09:37,360
and uh and this is roughly what that

277
00:09:36,000 --> 00:09:38,720
model looks like. So we have vessel

278
00:09:37,360 --> 00:09:40,480
detection which in this case this is a

279
00:09:38,720 --> 00:09:44,959
super simple model. It's literally a 2D

280
00:09:40,480 --> 00:09:46,399
CNN like ve very very uh very fast very

281
00:09:44,959 --> 00:09:49,440
efficient kernel with a bunch of other

282
00:09:46,399 --> 00:09:50,800
detectors for various uh sources of

283
00:09:49,440 --> 00:09:53,360
false positive that occur when you

284
00:09:50,800 --> 00:09:56,720
actually uh try to operationalize this

285
00:09:53,360 --> 00:09:58,240
kind of model. um when we first uh got

286
00:09:56,720 --> 00:09:59,760
this model. So our initial version of

287
00:09:58,240 --> 00:10:01,200
this was literally just vessel detection

288
00:09:59,760 --> 00:10:02,640
and we shipped that put it into the

289
00:10:01,200 --> 00:10:04,160
service looked at the outputs and it was

290
00:10:02,640 --> 00:10:08,160
it was terrible. It was absolutely

291
00:10:04,160 --> 00:10:09,519
unusable and um we realized that we were

292
00:10:08,160 --> 00:10:11,360
detecting all these other things which

293
00:10:09,519 --> 00:10:13,360
are sources of of false positives. So we

294
00:10:11,360 --> 00:10:15,360
decided we needed to build detectors for

295
00:10:13,360 --> 00:10:17,200
all of those. Um so over the course of

296
00:10:15,360 --> 00:10:20,880
building this model we built detectors

297
00:10:17,200 --> 00:10:23,279
for uh gas flares uh like oil platforms

298
00:10:20,880 --> 00:10:24,640
um lightning. Actually, this this uh

299
00:10:23,279 --> 00:10:27,360
this model is really good at detecting

300
00:10:24,640 --> 00:10:28,880
lightning if you need that. Uh aurora um

301
00:10:27,360 --> 00:10:32,160
aurora is a huge source of false

302
00:10:28,880 --> 00:10:34,480
positives and um the aurora move. You

303
00:10:32,160 --> 00:10:37,279
may have seen them uh uh last week. They

304
00:10:34,480 --> 00:10:38,480
were really far south. Uh so all these

305
00:10:37,279 --> 00:10:39,760
are sources of false positives. So you

306
00:10:38,480 --> 00:10:42,160
have to control for all those. We built

307
00:10:39,760 --> 00:10:44,240
a model. It's a it's a 2D CNN with these

308
00:10:42,160 --> 00:10:45,839
channels, moonlight, land, sea, clouds,

309
00:10:44,240 --> 00:10:47,360
uh and the nanowatts which is the signal

310
00:10:45,839 --> 00:10:49,120
itself. So this model is tiny. It's like

311
00:10:47,360 --> 00:10:52,079
40,000 parameters. it can be run as part

312
00:10:49,120 --> 00:10:53,519
of CI/CD and it's very effective. Um I

313
00:10:52,079 --> 00:10:55,920
want to just briefly comment on the fact

314
00:10:53,519 --> 00:10:58,240
that you know in general when we do

315
00:10:55,920 --> 00:10:59,920
offline training we see extremely high

316
00:10:58,240 --> 00:11:01,440
quality data and it's fairly easy to

317
00:10:59,920 --> 00:11:02,959
make a really good model. When we ship

318
00:11:01,440 --> 00:11:04,240
that model when we actually get into a

319
00:11:02,959 --> 00:11:07,839
production it typically doesn't work

320
00:11:04,240 --> 00:11:10,640
very well and um and most models uh

321
00:11:07,839 --> 00:11:12,399
generally don't see production and so

322
00:11:10,640 --> 00:11:14,399
users are not going to see see practical

323
00:11:12,399 --> 00:11:16,160
benefit. And so we think about this a

324
00:11:14,399 --> 00:11:18,079
lot and one of the way to address one of

325
00:11:16,160 --> 00:11:20,160
the ways to address this is to make it

326
00:11:18,079 --> 00:11:22,880
extremely easy to get feedback from

327
00:11:20,160 --> 00:11:24,480
users. So I'm showing here a skylight

328
00:11:22,880 --> 00:11:25,839
platform that's on the bottom. And

329
00:11:24,480 --> 00:11:27,519
notice how simple this is. This is

330
00:11:25,839 --> 00:11:29,200
literally as simple as it gets, right?

331
00:11:27,519 --> 00:11:33,120
You you do not need a sophisticated

332
00:11:29,200 --> 00:11:35,760
detector to detect that that's uh um

333
00:11:33,120 --> 00:11:37,360
that this is a vessel here. Um it's not

334
00:11:35,760 --> 00:11:39,839
always that simple. I'm showing a very

335
00:11:37,360 --> 00:11:41,600
simple example. um gets a little bit

336
00:11:39,839 --> 00:11:43,279
harder than that but in general we just

337
00:11:41,600 --> 00:11:45,519
show users hey this is what the model

338
00:11:43,279 --> 00:11:48,399
saw uh and and this is what it sees in

339
00:11:45,519 --> 00:11:50,640
the case of veers and then uh just tell

340
00:11:48,399 --> 00:11:53,040
us if it's right or wrong right you you

341
00:11:50,640 --> 00:11:54,320
know these our experts are generally

342
00:11:53,040 --> 00:11:55,680
they will know and they'll be able to

343
00:11:54,320 --> 00:11:56,880
tell us oh that looks like a cloud or

344
00:11:55,680 --> 00:11:58,560
false positive or something like that or

345
00:11:56,880 --> 00:12:00,880
we know it's a gas flare there oh it's a

346
00:11:58,560 --> 00:12:02,640
new platform oh it's a new wind turbine

347
00:12:00,880 --> 00:12:05,200
whatever so we just make it super easy

348
00:12:02,640 --> 00:12:07,519
to get feedback the model that we were

349
00:12:05,200 --> 00:12:09,839
uh not I'm not going to use the word

350
00:12:07,519 --> 00:12:12,320
competing But the another model in the

351
00:12:09,839 --> 00:12:16,399
space that people were asking us to

352
00:12:12,320 --> 00:12:18,000
compare ourselves to um was uh basically

353
00:12:16,399 --> 00:12:21,040
this is how they provided feedback. It's

354
00:12:18,000 --> 00:12:22,720
the upper up upper row here. And and you

355
00:12:21,040 --> 00:12:25,040
know it's very difficult to interpret

356
00:12:22,720 --> 00:12:26,720
this even if you know you know about

357
00:12:25,040 --> 00:12:28,480
signal processing and know how this

358
00:12:26,720 --> 00:12:30,240
model was trained. It's pretty difficult

359
00:12:28,480 --> 00:12:32,160
to immediately interpolate oh okay that

360
00:12:30,240 --> 00:12:34,000
model was right or wrong. Right? It's

361
00:12:32,160 --> 00:12:36,399
much easier to just look at the output.

362
00:12:34,000 --> 00:12:38,240
Um and we do this via feedback and it's

363
00:12:36,399 --> 00:12:39,600
very effective. So we've done this for a

364
00:12:38,240 --> 00:12:41,279
bunch of satellites now and we have

365
00:12:39,600 --> 00:12:43,440
computer vision. This is all operating

366
00:12:41,279 --> 00:12:46,240
right now at global scale in real time

367
00:12:43,440 --> 00:12:47,920
serving uh about 70 countries and uh

368
00:12:46,240 --> 00:12:50,240
we're covering these satellites viewers.

369
00:12:47,920 --> 00:12:52,639
So that's the one I just showed you. And

370
00:12:50,240 --> 00:12:55,279
then Sentinel 1 which is radar that's

371
00:12:52,639 --> 00:12:57,440
synthetic aperture radar. Sentinel 2

372
00:12:55,279 --> 00:12:59,519
which is optical imagery and and LANCAT

373
00:12:57,440 --> 00:13:00,880
8 N9 which is also optical imagery. So

374
00:12:59,519 --> 00:13:02,240
all these satellites again they have

375
00:13:00,880 --> 00:13:06,240
different strengths and weaknesses. We

376
00:13:02,240 --> 00:13:07,920
use them all uh at at the same time and

377
00:13:06,240 --> 00:13:09,600
users rely on these signals for

378
00:13:07,920 --> 00:13:11,760
different so synthetic aperture radar

379
00:13:09,600 --> 00:13:14,240
you can see through clouds ve at night

380
00:13:11,760 --> 00:13:16,720
as I said um optical is of course very

381
00:13:14,240 --> 00:13:18,560
useful and uh so these models generally

382
00:13:16,720 --> 00:13:20,880
kind of work in tandem with one another

383
00:13:18,560 --> 00:13:23,120
and users uh rely on all of them they're

384
00:13:20,880 --> 00:13:25,200
um quite performant at this point we've

385
00:13:23,120 --> 00:13:27,839
been iterating for a while they're right

386
00:13:25,200 --> 00:13:30,160
around say like 90 F1 uh they're very

387
00:13:27,839 --> 00:13:32,320
reliable they're literally always on um

388
00:13:30,160 --> 00:13:35,360
and and a bunch of users depend on them.

389
00:13:32,320 --> 00:13:37,920
They run at reasonably low latency, so

390
00:13:35,360 --> 00:13:40,240
90 minutes for vehic it's it's hours or

391
00:13:37,920 --> 00:13:43,360
so for for the others. Um, and these run

392
00:13:40,240 --> 00:13:46,399
on T4s. These are super light models and

393
00:13:43,360 --> 00:13:47,920
they are T4 is like, you know, basically

394
00:13:46,399 --> 00:13:49,120
the cheapest GPU. I don't know. Google's

395
00:13:47,920 --> 00:13:51,279
probably going to turn them off soon at

396
00:13:49,120 --> 00:13:55,040
this point because they're so um

397
00:13:51,279 --> 00:13:57,920
uncommon, but uh we get we get great uh

398
00:13:55,040 --> 00:14:00,800
utility out of them and they're um uh

399
00:13:57,920 --> 00:14:02,240
they're uh uh they they work they work

400
00:14:00,800 --> 00:14:04,000
for these models. So everything here has

401
00:14:02,240 --> 00:14:07,519
been open sourced both the models and

402
00:14:04,000 --> 00:14:08,800
the APIs as I mentioned. Uh and um and

403
00:14:07,519 --> 00:14:10,000
we provide this for free. You can go to

404
00:14:08,800 --> 00:14:12,720
this link actually if you want to see

405
00:14:10,000 --> 00:14:15,360
this. Uh this is a public version of

406
00:14:12,720 --> 00:14:17,680
this uh of we have a public version of

407
00:14:15,360 --> 00:14:20,639
these maps uh or of the kind of the the

408
00:14:17,680 --> 00:14:21,920
the outputs um dynamic and and you can

409
00:14:20,639 --> 00:14:23,360
look and actually I show I'm going to

410
00:14:21,920 --> 00:14:25,680
show a few examples because I just think

411
00:14:23,360 --> 00:14:28,000
it's cool. Computer vision is fun. Um so

412
00:14:25,680 --> 00:14:29,519
this is some kind of uh fishing vessel

413
00:14:28,000 --> 00:14:31,600
with maybe a person or something like

414
00:14:29,519 --> 00:14:34,240
that. Um here's a vessel that we

415
00:14:31,600 --> 00:14:35,760
discovered. This was underwater. So uh

416
00:14:34,240 --> 00:14:38,000
in this case we found like this

417
00:14:35,760 --> 00:14:40,399
shipwreck basically. Um here I'm showing

418
00:14:38,000 --> 00:14:42,560
this is uh just outside of Boston. I

419
00:14:40,399 --> 00:14:45,440
just came up. This is what I found last

420
00:14:42,560 --> 00:14:46,880
night on on the plane over here. And

421
00:14:45,440 --> 00:14:48,959
here I'm just showing you that like

422
00:14:46,880 --> 00:14:50,800
synthetic aperture radar. This is

423
00:14:48,959 --> 00:14:52,880
actually like quite hard to do this

424
00:14:50,800 --> 00:14:56,079
really well at scale. The signal is

425
00:14:52,880 --> 00:14:57,519
fairly faint. Um but we've and we've

426
00:14:56,079 --> 00:15:01,040
trained this model on something like

427
00:14:57,519 --> 00:15:02,800
50,000 uh expertly labeled annotations.

428
00:15:01,040 --> 00:15:05,760
This took years just to be clear like

429
00:15:02,800 --> 00:15:07,120
this this and and and and um one of the

430
00:15:05,760 --> 00:15:08,720
reasons I'm showing you all this is that

431
00:15:07,120 --> 00:15:10,639
I think there's a ton of value here but

432
00:15:08,720 --> 00:15:12,000
it's really hard to extract. Um so

433
00:15:10,639 --> 00:15:14,000
anyway so this is synthetic aperture

434
00:15:12,000 --> 00:15:15,360
radar and and here you're just so this

435
00:15:14,000 --> 00:15:18,560
is not optical. This is not what a human

436
00:15:15,360 --> 00:15:21,600
eye sees. This is what radar sees. Um

437
00:15:18,560 --> 00:15:24,240
and uh in this case uh you know this was

438
00:15:21,600 --> 00:15:26,079
positive a positive detection. Um and

439
00:15:24,240 --> 00:15:28,720
and radar sees through clouds. So that's

440
00:15:26,079 --> 00:15:30,959
very useful. Um, we've also done uh

441
00:15:28,720 --> 00:15:32,480
global real-time modeling for the same

442
00:15:30,959 --> 00:15:34,959
platform, for the Skylight platform with

443
00:15:32,480 --> 00:15:36,639
GPS data. And I'm just showing you a

444
00:15:34,959 --> 00:15:38,320
quick example here of of what that looks

445
00:15:36,639 --> 00:15:39,839
like. So, GPS data, I think, is

446
00:15:38,320 --> 00:15:41,199
generally another pretty rich source of

447
00:15:39,839 --> 00:15:44,240
information that is comparatively

448
00:15:41,199 --> 00:15:46,720
undervalued. Um GPS is usually

449
00:15:44,240 --> 00:15:48,399
transponded by every vessel on the ocean

450
00:15:46,720 --> 00:15:49,920
unless you're like really a bad actor

451
00:15:48,399 --> 00:15:51,759
and then you're probably going to turn

452
00:15:49,920 --> 00:15:53,360
off your um you're probably not going to

453
00:15:51,759 --> 00:15:55,839
constantly broadcast your location, but

454
00:15:53,360 --> 00:15:58,959
it's generally used by most uh most

455
00:15:55,839 --> 00:16:02,800
vessels. And we can model GPS data

456
00:15:58,959 --> 00:16:04,320
really similar to how we model uh uh

457
00:16:02,800 --> 00:16:06,240
language data. The difference here is of

458
00:16:04,320 --> 00:16:08,320
course we have kind of this geoloccation

459
00:16:06,240 --> 00:16:11,279
lat long plus a sock but we can just

460
00:16:08,320 --> 00:16:13,519
trans transform this into uh um tokens

461
00:16:11,279 --> 00:16:15,120
in a way that transformers understand uh

462
00:16:13,519 --> 00:16:16,959
do the standard thing and language model

463
00:16:15,120 --> 00:16:18,720
training. Here's the custom model that

464
00:16:16,959 --> 00:16:20,560
we built on top and then we can get

465
00:16:18,720 --> 00:16:22,720
really high precision high accuracy

466
00:16:20,560 --> 00:16:25,759
classification of all these GPS

467
00:16:22,720 --> 00:16:29,360
sequences at every moment in time on the

468
00:16:25,759 --> 00:16:31,519
whole world um in real time. So we're

469
00:16:29,360 --> 00:16:34,720
processing right now right now as we

470
00:16:31,519 --> 00:16:37,040
speak in skylight uh about 5 million uh

471
00:16:34,720 --> 00:16:39,199
GPS uh it's called AIS automatic

472
00:16:37,040 --> 00:16:41,279
identification system GPS's messages per

473
00:16:39,199 --> 00:16:42,480
day. This is all running again on T4s.

474
00:16:41,279 --> 00:16:45,839
These models are pretty small. This

475
00:16:42,480 --> 00:16:47,600
model I think is on the order of

476
00:16:45,839 --> 00:16:49,519
I think it's about a million or so

477
00:16:47,600 --> 00:16:52,240
parameters. It's super super efficient,

478
00:16:49,519 --> 00:16:53,680
fast to run. And here we're providing uh

479
00:16:52,240 --> 00:16:55,440
basically we're just telling all of our

480
00:16:53,680 --> 00:16:57,120
users what the vessels are doing at any

481
00:16:55,440 --> 00:16:59,040
moment in time so they can go and

482
00:16:57,120 --> 00:17:01,759
intercept as needed if a vessel is doing

483
00:16:59,040 --> 00:17:03,519
something nefarious um or just knowledge

484
00:17:01,759 --> 00:17:05,439
of exactly what's going on. So this is

485
00:17:03,519 --> 00:17:09,039
happening or this these models are

486
00:17:05,439 --> 00:17:10,640
running in real time everywhere um and

487
00:17:09,039 --> 00:17:12,400
they're producing literally

488
00:17:10,640 --> 00:17:15,839
instantaneous classifications of the

489
00:17:12,400 --> 00:17:17,760
entire uh of the entire planet um with

490
00:17:15,839 --> 00:17:19,679
with with these uh with these models.

491
00:17:17,760 --> 00:17:21,039
This is outside of Boston. And this is

492
00:17:19,679 --> 00:17:23,600
showing you in the last like I think

493
00:17:21,039 --> 00:17:25,760
it's couple weeks or so maybe month um

494
00:17:23,600 --> 00:17:27,679
just literally every single GPS message

495
00:17:25,760 --> 00:17:29,200
that was broadcasted from all the

496
00:17:27,679 --> 00:17:31,840
vessels that were in and around the

497
00:17:29,200 --> 00:17:34,160
Boston uh sea area and and what they

498
00:17:31,840 --> 00:17:35,760
were doing. Um we can use these same

499
00:17:34,160 --> 00:17:39,120
models to forecast human wildlife

500
00:17:35,760 --> 00:17:40,720
conflict. So uh we haven't uh uh

501
00:17:39,120 --> 00:17:42,720
produced this model yet but we believe

502
00:17:40,720 --> 00:17:44,400
we can take uh earth observation data

503
00:17:42,720 --> 00:17:46,960
for land cover mapping combine that with

504
00:17:44,400 --> 00:17:50,799
GPS data combine that again with weather

505
00:17:46,960 --> 00:17:53,280
data to to get a sense of what um what

506
00:17:50,799 --> 00:17:54,640
animals are going to do in especially

507
00:17:53,280 --> 00:17:56,559
around national parks where there's

508
00:17:54,640 --> 00:17:58,400
concerns for human wildlife conflict.

509
00:17:56,559 --> 00:17:59,760
Human wildlife conflict for elephants

510
00:17:58,400 --> 00:18:02,160
for example is the leading cause of

511
00:17:59,760 --> 00:18:03,280
death now uh for elephants. And so we

512
00:18:02,160 --> 00:18:07,200
believe we can do something similar

513
00:18:03,280 --> 00:18:09,120
here. take the Atlas models uh and um

514
00:18:07,200 --> 00:18:11,600
and basically forecast where there's

515
00:18:09,120 --> 00:18:12,960
going to be a conflict. Um this is just

516
00:18:11,600 --> 00:18:15,440
a pretty picture that I wanted to show

517
00:18:12,960 --> 00:18:18,000
you. This is uh basically all GPS data

518
00:18:15,440 --> 00:18:20,000
in the world um in the last this was I

519
00:18:18,000 --> 00:18:23,120
think 2020

520
00:18:20,000 --> 00:18:27,280
2024. Um this is roughly 5 terabytes of

521
00:18:23,120 --> 00:18:30,160
data and it was just to force me to

522
00:18:27,280 --> 00:18:32,720
pause and think carefully but yeah this

523
00:18:30,160 --> 00:18:34,720
is just a pretty picture. Um so the the

524
00:18:32,720 --> 00:18:37,200
net for us was that earth scale modeling

525
00:18:34,720 --> 00:18:39,120
is generally pretty hard. Um it all

526
00:18:37,200 --> 00:18:41,679
these models took years to make and to

527
00:18:39,120 --> 00:18:43,120
build and to ship. Um each one was like

528
00:18:41,679 --> 00:18:44,880
very different. We had to kind of do

529
00:18:43,120 --> 00:18:47,440
slightly different things. Build the

530
00:18:44,880 --> 00:18:48,880
machinery to both train and then also to

531
00:18:47,440 --> 00:18:50,880
productionize and deploy them. And it

532
00:18:48,880 --> 00:18:53,120
was it was just very hard each time. It

533
00:18:50,880 --> 00:18:55,919
was fairly resource intensive. Uh and we

534
00:18:53,120 --> 00:18:58,000
get asked to make tons of models. Um

535
00:18:55,919 --> 00:18:59,919
it's very difficult to do this at scale

536
00:18:58,000 --> 00:19:01,440
or for many different tasks. So you need

537
00:18:59,919 --> 00:19:03,280
expert labelers, you need machine

538
00:19:01,440 --> 00:19:04,640
learning research teams. This really is

539
00:19:03,280 --> 00:19:06,480
not a solved problem. You generally

540
00:19:04,640 --> 00:19:08,640
can't take off-the-shelf models and just

541
00:19:06,480 --> 00:19:10,240
like make them work for this kind of uh

542
00:19:08,640 --> 00:19:11,760
use case. You need training

543
00:19:10,240 --> 00:19:14,160
infrastructure, thousands or maybe

544
00:19:11,760 --> 00:19:16,000
millions of GPU GPU hours to train the

545
00:19:14,160 --> 00:19:17,840
base foundation models that do all these

546
00:19:16,000 --> 00:19:19,520
things. You need dedicated inference

547
00:19:17,840 --> 00:19:20,640
systems and and of course you need to

548
00:19:19,520 --> 00:19:22,480
maintain these things if they're going

549
00:19:20,640 --> 00:19:25,120
to be productionized. So basically this

550
00:19:22,480 --> 00:19:27,760
is out of scope for many nonprofits and

551
00:19:25,120 --> 00:19:29,520
NOS's [snorts] and we said well what if

552
00:19:27,760 --> 00:19:31,200
we can do this you know for the world

553
00:19:29,520 --> 00:19:33,360
and make this a public good and really

554
00:19:31,200 --> 00:19:35,200
just kind of build it once foundational

555
00:19:33,360 --> 00:19:37,679
infrastructure one time and then give it

556
00:19:35,200 --> 00:19:40,160
away and let people kind of leverage the

557
00:19:37,679 --> 00:19:43,600
same technology that we've been uh using

558
00:19:40,160 --> 00:19:46,000
for uh to to to build our uh models and

559
00:19:43,600 --> 00:19:47,760
and that's what the earth project is

560
00:19:46,000 --> 00:19:49,840
about that's what we just launched as

561
00:19:47,760 --> 00:19:51,679
Sher mentioned and so the idea here is

562
00:19:49,840 --> 00:19:53,280
we have massive global scale realtime

563
00:19:51,679 --> 00:19:55,039
data coming from all different kinds of

564
00:19:53,280 --> 00:19:56,480
sensors, not just the satellites, but

565
00:19:55,039 --> 00:19:58,400
also there's ground sensors, there's

566
00:19:56,480 --> 00:20:00,320
buoys, there's there's uh there's

567
00:19:58,400 --> 00:20:02,160
weather balloons, there's all kinds of

568
00:20:00,320 --> 00:20:04,080
different sensors. Let's take all these

569
00:20:02,160 --> 00:20:06,559
data that's let's train a large

570
00:20:04,080 --> 00:20:09,120
foundation model with all these sources.

571
00:20:06,559 --> 00:20:10,799
Then let's integrate it into a full

572
00:20:09,120 --> 00:20:12,799
platform that enables actually

573
00:20:10,799 --> 00:20:14,640
leveraging this technology. And I'll

574
00:20:12,799 --> 00:20:16,960
show uh you what that means in a second.

575
00:20:14,640 --> 00:20:18,240
So we can empower many different comp

576
00:20:16,960 --> 00:20:20,000
you know many different organizations

577
00:20:18,240 --> 00:20:22,240
many different NOS's many different uh

578
00:20:20,000 --> 00:20:24,720
users who who want this technology but

579
00:20:22,240 --> 00:20:27,440
don't have the resources to get it and

580
00:20:24,720 --> 00:20:28,799
we really think that this is the the

581
00:20:27,440 --> 00:20:30,080
right time to do so. We think that

582
00:20:28,799 --> 00:20:31,440
artificial intelligence is about where

583
00:20:30,080 --> 00:20:33,760
it needs to be. The data is where it

584
00:20:31,440 --> 00:20:35,440
needs to be. Um, we get asked literally

585
00:20:33,760 --> 00:20:37,520
by hundreds of organizations to build

586
00:20:35,440 --> 00:20:39,440
various models and we just we we kept

587
00:20:37,520 --> 00:20:40,720
saying no honestly and it was a bit

588
00:20:39,440 --> 00:20:42,559
heartbreaking because these

589
00:20:40,720 --> 00:20:44,240
organizations have extremely important

590
00:20:42,559 --> 00:20:45,919
missions that we want to be able to help

591
00:20:44,240 --> 00:20:47,520
and that really is kind of aligned with

592
00:20:45,919 --> 00:20:49,520
our mission about building you know

593
00:20:47,520 --> 00:20:51,919
artificial intelligence for for good and

594
00:20:49,520 --> 00:20:53,679
and and for these challenges and we

595
00:20:51,919 --> 00:20:56,480
didn't want to keep saying no and so we

596
00:20:53,679 --> 00:20:59,360
said let's build this this platform and

597
00:20:56,480 --> 00:21:02,080
that's called earth. So, OMO Earth is

598
00:20:59,360 --> 00:21:04,799
this new uh very very new platform that

599
00:21:02,080 --> 00:21:08,320
we just uh released a couple weeks ago

600
00:21:04,799 --> 00:21:12,400
uh la last week and it's a it's a set of

601
00:21:08,320 --> 00:21:14,559
um it's a set of uh models that we also

602
00:21:12,400 --> 00:21:16,880
built new foundation models uh that are

603
00:21:14,559 --> 00:21:19,600
state-of-the-art a platform that enables

604
00:21:16,880 --> 00:21:21,120
leveraging these models and then and

605
00:21:19,600 --> 00:21:23,760
then fine-tuning them for various

606
00:21:21,120 --> 00:21:26,320
downstream applications like ecosystem

607
00:21:23,760 --> 00:21:29,600
extent, biodiversity, uh conservation,

608
00:21:26,320 --> 00:21:31,919
sustainability um forest deforestation

609
00:21:29,600 --> 00:21:34,080
uh in the Amazon, forest risk uh

610
00:21:31,919 --> 00:21:36,400
assessments, uh all kinds of different

611
00:21:34,080 --> 00:21:38,240
applications that our users have come to

612
00:21:36,400 --> 00:21:41,039
us and asked, hey, can you build this

613
00:21:38,240 --> 00:21:42,640
model for us? And we said, hey, uh just

614
00:21:41,039 --> 00:21:44,240
give us a little time and then we'll

615
00:21:42,640 --> 00:21:46,240
have a platform that hopefully will

616
00:21:44,240 --> 00:21:48,080
enable you to build whatever you want.

617
00:21:46,240 --> 00:21:51,039
And so that's that's what we did and

618
00:21:48,080 --> 00:21:53,120
that's what we've been uh building for

619
00:21:51,039 --> 00:21:55,440
uh the last year or so. So the idea here

620
00:21:53,120 --> 00:21:57,200
is we'll have a a a model a foundation

621
00:21:55,440 --> 00:21:59,919
model that I'll describe in a second and

622
00:21:57,200 --> 00:22:02,640
it's a foundation model that can do um

623
00:21:59,919 --> 00:22:05,440
many different tasks really really well

624
00:22:02,640 --> 00:22:07,120
uh across classification segmentation

625
00:22:05,440 --> 00:22:08,720
change detection time series non-time

626
00:22:07,120 --> 00:22:10,480
series that kind of thing and then a

627
00:22:08,720 --> 00:22:12,880
platform that enables fine-tuning these

628
00:22:10,480 --> 00:22:15,919
models and deploying them. So the the

629
00:22:12,880 --> 00:22:19,039
entire uh ML life cycle here all the way

630
00:22:15,919 --> 00:22:21,840
from you know again raw data annotate

631
00:22:19,039 --> 00:22:24,080
that data deploy API now you have a

632
00:22:21,840 --> 00:22:25,280
serviceable endpoint whatever it is that

633
00:22:24,080 --> 00:22:27,440
you want maybe you want to download the

634
00:22:25,280 --> 00:22:29,280
maps maybe you want to email the maps to

635
00:22:27,440 --> 00:22:30,720
a colleague maybe you're the UN and you

636
00:22:29,280 --> 00:22:32,559
just need this kind of more from a

637
00:22:30,720 --> 00:22:35,360
policy perspective we want to do all

638
00:22:32,559 --> 00:22:37,360
those things simultaneously um so that

639
00:22:35,360 --> 00:22:39,039
users can take action so maybe it's a

640
00:22:37,360 --> 00:22:40,640
real-time use case where users just want

641
00:22:39,039 --> 00:22:42,480
to know like exactly what's going on

642
00:22:40,640 --> 00:22:45,679
right here right now and we have some

643
00:22:42,480 --> 00:22:48,320
applications that I'll describe that do

644
00:22:45,679 --> 00:22:49,760
exactly that. So Earth as I mentioned

645
00:22:48,320 --> 00:22:52,080
this is a new foundation model that we

646
00:22:49,760 --> 00:22:53,520
built. So it's it's a very multimodal so

647
00:22:52,080 --> 00:22:55,440
it combines many different satellites,

648
00:22:53,520 --> 00:22:57,600
many different sensors plus uh some

649
00:22:55,440 --> 00:23:00,000
derived maps. It's multi-mporal

650
00:22:57,600 --> 00:23:01,440
multi-mporal because we need to model

651
00:23:00,000 --> 00:23:03,679
changes over time. The earth is

652
00:23:01,440 --> 00:23:06,720
obviously extremely dynamic. It's

653
00:23:03,679 --> 00:23:08,559
flexible uh so it can run on whatever

654
00:23:06,720 --> 00:23:10,400
you have whatever users have. Users

655
00:23:08,559 --> 00:23:12,400
typically don't have every imaginable

656
00:23:10,400 --> 00:23:13,600
modality. they may have one or none or

657
00:23:12,400 --> 00:23:16,159
whatever. And so you just want to be

658
00:23:13,600 --> 00:23:17,840
flexible for them. Um it can uh it can

659
00:23:16,159 --> 00:23:19,679
run even when you have missing data,

660
00:23:17,840 --> 00:23:20,880
missing time steps. It's no problem. And

661
00:23:19,679 --> 00:23:22,960
that's actually common because in

662
00:23:20,880 --> 00:23:25,120
production settings, satellites go down

663
00:23:22,960 --> 00:23:27,280
all the time, right? They go dark, they

664
00:23:25,120 --> 00:23:29,440
whatever. So we need to be able to uh we

665
00:23:27,280 --> 00:23:30,799
need to account for that. We also

666
00:23:29,440 --> 00:23:33,679
importantly want this model to be

667
00:23:30,799 --> 00:23:35,679
extensible. So in general, this was like

668
00:23:33,679 --> 00:23:37,520
a first step. We're trying to build a

669
00:23:35,679 --> 00:23:39,039
foundation, one that can be extended to

670
00:23:37,520 --> 00:23:40,720
many different modalities, many

671
00:23:39,039 --> 00:23:42,799
different sensors, basically whatever

672
00:23:40,720 --> 00:23:45,600
users have. Uh we want to be able to

673
00:23:42,799 --> 00:23:47,120
meet them where they are. Uh we want the

674
00:23:45,600 --> 00:23:48,480
model to be fine-tunable, fine-tunable

675
00:23:47,120 --> 00:23:50,799
for many different tasks. So

676
00:23:48,480 --> 00:23:53,200
fine-tunable for uh basically whatever

677
00:23:50,799 --> 00:23:55,039
the user needs and and of course we need

678
00:23:53,200 --> 00:23:56,559
this model to be open. We want the data

679
00:23:55,039 --> 00:23:58,000
to be open. We want the model to be

680
00:23:56,559 --> 00:23:59,360
fully open. You can reproduce this

681
00:23:58,000 --> 00:24:01,671
model. You can extend it. You can do

682
00:23:59,360 --> 00:24:02,400
whatever you want with it. Um

683
00:24:01,671 --> 00:24:03,760
[clears throat]

684
00:24:02,400 --> 00:24:05,919
what does the data look like? So in

685
00:24:03,760 --> 00:24:07,600
general the data is we consider it uh

686
00:24:05,919 --> 00:24:09,280
quite multimotal. So you have visual

687
00:24:07,600 --> 00:24:11,279
infrared, you have microwave, you have

688
00:24:09,280 --> 00:24:12,960
radar. Um you also have like elevation

689
00:24:11,279 --> 00:24:14,559
data and land cover and you have many

690
00:24:12,960 --> 00:24:17,760
derived maps produced by many different

691
00:24:14,559 --> 00:24:20,000
organizations. Open street map uh uh

692
00:24:17,760 --> 00:24:22,880
European space agency world cover um

693
00:24:20,000 --> 00:24:24,559
world serial uh the US has has produced

694
00:24:22,880 --> 00:24:26,640
a bunch of crop land data masks and we

695
00:24:24,559 --> 00:24:27,840
can put all these into the model. Um in

696
00:24:26,640 --> 00:24:30,960
general it's variable spatial

697
00:24:27,840 --> 00:24:33,520
resolution. So um this can vary quite

698
00:24:30,960 --> 00:24:35,279
dramatically. uh and um we need to

699
00:24:33,520 --> 00:24:36,799
account for that. Our current data sets

700
00:24:35,279 --> 00:24:38,559
right now, the ones I'll share with you

701
00:24:36,799 --> 00:24:41,840
in a second, they're training on fairly

702
00:24:38,559 --> 00:24:45,360
modest data about 10 terabytes across uh

703
00:24:41,840 --> 00:24:48,000
these uh these sensors. Um we have maps

704
00:24:45,360 --> 00:24:49,600
for world cover, cropland data, world

705
00:24:48,000 --> 00:24:51,600
serial, open street map, and several

706
00:24:49,600 --> 00:24:52,960
others that I'll show you in a second.

707
00:24:51,600 --> 00:24:54,400
So this is what the pre-training data

708
00:24:52,960 --> 00:24:55,919
set looks like. So we have a bunch of

709
00:24:54,400 --> 00:24:58,400
satellite observations. We have these

710
00:24:55,919 --> 00:25:00,799
are all uh geo reference, so lat long

711
00:24:58,400 --> 00:25:02,799
and timestamps. And then we have a bunch

712
00:25:00,799 --> 00:25:04,480
of high quality maps and we're putting

713
00:25:02,799 --> 00:25:06,880
these into a model. This is just the

714
00:25:04,480 --> 00:25:09,360
pre-training data that we're going to

715
00:25:06,880 --> 00:25:11,600
feed into the model. And then we have

716
00:25:09,360 --> 00:25:14,640
this covering about 300,000 locations.

717
00:25:11,600 --> 00:25:19,120
So uh you can see here the sampling is

718
00:25:14,640 --> 00:25:21,120
not uniform. It's uh it's it's obviously

719
00:25:19,120 --> 00:25:25,039
biased and it's biased towards area

720
00:25:21,120 --> 00:25:27,279
where you have more data. uh and we

721
00:25:25,039 --> 00:25:28,720
certainly want to strive for even more

722
00:25:27,279 --> 00:25:31,360
data and especially in the areas that

723
00:25:28,720 --> 00:25:35,279
are uh underrepresented here. Um and

724
00:25:31,360 --> 00:25:38,240
that's um that's a

725
00:25:35,279 --> 00:25:39,679
that's a major future effort. Um here's

726
00:25:38,240 --> 00:25:40,799
approximately what the training recipe

727
00:25:39,679 --> 00:25:43,679
looks like. So I'm not going to cover

728
00:25:40,799 --> 00:25:46,000
this in detail, but uh we've uh

729
00:25:43,679 --> 00:25:47,760
published the paper a couple weeks ago

730
00:25:46,000 --> 00:25:48,960
uh and you can look at that for details.

731
00:25:47,760 --> 00:25:51,200
But in general, what we're doing is

732
00:25:48,960 --> 00:25:53,840
we're pre-training via uh latent mass

733
00:25:51,200 --> 00:25:58,320
image modeling and then we're doing kind

734
00:25:53,840 --> 00:26:00,320
of a um uh a fast version of that for

735
00:25:58,320 --> 00:26:01,520
high qual for the for the map data. So

736
00:26:00,320 --> 00:26:04,000
we're kind of combining self-s

737
00:26:01,520 --> 00:26:06,080
supervision and supervision uh in this

738
00:26:04,000 --> 00:26:09,919
uh in this setup so that we can leverage

739
00:26:06,080 --> 00:26:11,919
the uh the data from both um and that

740
00:26:09,919 --> 00:26:14,240
ends up being quite effective. So OMO

741
00:26:11,919 --> 00:26:16,640
Earth we've shown is state-of-the-art

742
00:26:14,240 --> 00:26:18,240
for a huge variety of EOT tasks. We

743
00:26:16,640 --> 00:26:21,039
evaluated more earth this this new

744
00:26:18,240 --> 00:26:22,799
foundation model against uh industry

745
00:26:21,039 --> 00:26:24,240
standard benchmarks of course uh

746
00:26:22,799 --> 00:26:26,640
research benchmarks that people have

747
00:26:24,240 --> 00:26:28,720
been using for for a while. We also

748
00:26:26,640 --> 00:26:30,880
evaluated this model against our partner

749
00:26:28,720 --> 00:26:33,279
data um real world tasks that

750
00:26:30,880 --> 00:26:36,400
organizations have given us asked us to

751
00:26:33,279 --> 00:26:38,159
uh do for them crop crop uh crop type

752
00:26:36,400 --> 00:26:41,520
mapping for example or deforestation

753
00:26:38,159 --> 00:26:43,840
cause mapping or um wildfire risk

754
00:26:41,520 --> 00:26:47,360
assessments and we've tuned these models

755
00:26:43,840 --> 00:26:49,600
for uh or we've I should say we've uh

756
00:26:47,360 --> 00:26:51,200
we've massively benefited from those

757
00:26:49,600 --> 00:26:53,279
collaborations because it's enabled us

758
00:26:51,200 --> 00:26:54,960
to make sure that our models do really

759
00:26:53,279 --> 00:26:56,559
really well not just on the research

760
00:26:54,960 --> 00:26:58,880
benchmarks which are of course quite

761
00:26:56,559 --> 00:27:01,360
important but also against these uh kind

762
00:26:58,880 --> 00:27:03,840
of maybe a little bit messier real world

763
00:27:01,360 --> 00:27:06,720
tasks and so we've been optimizing for

764
00:27:03,840 --> 00:27:10,320
both and we now have a model that

765
00:27:06,720 --> 00:27:13,840
performs really well on both. So on the

766
00:27:10,320 --> 00:27:16,000
on the left you're looking at uh this

767
00:27:13,840 --> 00:27:17,600
earth is now paro front for uh

768
00:27:16,000 --> 00:27:19,600
computational efficiency and and

769
00:27:17,600 --> 00:27:22,799
performance across this is showing the

770
00:27:19,600 --> 00:27:25,360
average on 13 uh 13 different tasks via

771
00:27:22,799 --> 00:27:27,840
KN&N and and linear probing. So here

772
00:27:25,360 --> 00:27:30,480
we're taking just the embeddings

773
00:27:27,840 --> 00:27:32,640
from the model. So no fine-tuning and

774
00:27:30,480 --> 00:27:34,960
we're just saying you know how do we

775
00:27:32,640 --> 00:27:39,600
compare to other major models in the in

776
00:27:34,960 --> 00:27:41,919
the field and uh we're doing um not bad.

777
00:27:39,600 --> 00:27:43,679
We're also doing not bad even for really

778
00:27:41,919 --> 00:27:47,840
small models. So you'll notice here that

779
00:27:43,679 --> 00:27:49,120
the vit tiny and the vit uh uh nano are

780
00:27:47,840 --> 00:27:51,600
actually quite good and they're better

781
00:27:49,120 --> 00:27:53,440
than some much larger models. And that's

782
00:27:51,600 --> 00:27:55,440
significant because if you have a small

783
00:27:53,440 --> 00:27:59,200
model, you can retrain it faster, you

784
00:27:55,440 --> 00:28:00,880
can uh iterate faster, you can um it's

785
00:27:59,200 --> 00:28:04,559
inference is much cheaper of course,

786
00:28:00,880 --> 00:28:06,399
etc., etc. On the your on the right,

787
00:28:04,559 --> 00:28:08,000
you're seeing fine-tuning. So

788
00:28:06,399 --> 00:28:09,120
fine-tuning is a bit different, right?

789
00:28:08,000 --> 00:28:11,440
There's a lot of variations in

790
00:28:09,120 --> 00:28:14,640
fine-tuning and here we're doing uh

791
00:28:11,440 --> 00:28:18,039
relatively full fine-tuning and excuse

792
00:28:14,640 --> 00:28:18,039
me one second.

793
00:28:20,960 --> 00:28:27,520
What you're seeing here is average model

794
00:28:22,480 --> 00:28:29,600
rank. So earth is on top and actually

795
00:28:27,520 --> 00:28:31,760
the vit tiny is also quite good. It's

796
00:28:29,600 --> 00:28:34,480
it's second best on these. Uh this is 18

797
00:28:31,760 --> 00:28:37,279
tasks. So this is 18 fine-tuning tasks

798
00:28:34,480 --> 00:28:39,360
covering a whole bunch of different uh

799
00:28:37,279 --> 00:28:40,960
segmentation, change detection,

800
00:28:39,360 --> 00:28:43,679
classification,

801
00:28:40,960 --> 00:28:45,120
etc., etc.

802
00:28:43,679 --> 00:28:46,799
Okay, I'm not going to ask you to look

803
00:28:45,120 --> 00:28:49,600
at this really closely. This is just to

804
00:28:46,799 --> 00:28:53,279
emphasize that we evaluated this fairly

805
00:28:49,600 --> 00:28:55,279
extensively on dozens of tasks and then

806
00:28:53,279 --> 00:28:57,440
we also evaluated every other major

807
00:28:55,279 --> 00:28:59,039
model against those same tasks. So this

808
00:28:57,440 --> 00:29:00,640
is in the paper. The point of this is

809
00:28:59,039 --> 00:29:01,760
not to have you stare at the numbers. So

810
00:29:00,640 --> 00:29:03,520
forgive me if that's what you're trying

811
00:29:01,760 --> 00:29:05,200
to do right now. It's rather just to

812
00:29:03,520 --> 00:29:08,320
show you we've really done quite

813
00:29:05,200 --> 00:29:11,360
thorough evaluation. Top is KN&N, bottom

814
00:29:08,320 --> 00:29:14,480
is SFT. We evaluated this model

815
00:29:11,360 --> 00:29:16,640
extensively and performance of these

816
00:29:14,480 --> 00:29:19,360
these models this family of models. So

817
00:29:16,640 --> 00:29:21,840
earth nano tiny base large is very good.

818
00:29:19,360 --> 00:29:24,559
It's uh generally the best or near the

819
00:29:21,840 --> 00:29:26,080
best and um and that's a good thing

820
00:29:24,559 --> 00:29:27,760
because that means that our users can

821
00:29:26,080 --> 00:29:29,200
you know leverage this model for many

822
00:29:27,760 --> 00:29:30,640
different tasks. The source code is

823
00:29:29,200 --> 00:29:32,640
available on GitHub. The weights are on

824
00:29:30,640 --> 00:29:34,159
hugging face as I mentioned. Um but you

825
00:29:32,640 --> 00:29:36,640
can also access this model within the

826
00:29:34,159 --> 00:29:38,480
north platform. Um and I just put an

827
00:29:36,640 --> 00:29:40,559
asterisk here. We we recommend using the

828
00:29:38,480 --> 00:29:42,799
base model. For most tasks, large is

829
00:29:40,559 --> 00:29:45,039
generally better, but consult this table

830
00:29:42,799 --> 00:29:46,880
uh if you're unsure and and um and if

831
00:29:45,039 --> 00:29:49,679
you have the spare compute. Um this was

832
00:29:46,880 --> 00:29:51,520
just super super brief uh and just a

833
00:29:49,679 --> 00:29:52,960
taste. The ablations and results are in

834
00:29:51,520 --> 00:29:54,799
the technical report which I'll provide

835
00:29:52,960 --> 00:29:57,200
a

836
00:29:54,799 --> 00:29:59,600
um well, if you go to earth.allenai.org,

837
00:29:57,200 --> 00:30:01,440
you can see it there. Um apologies, you

838
00:29:59,600 --> 00:30:03,440
can't you can't see the URL here. And

839
00:30:01,440 --> 00:30:05,520
then uh hugging face and GitHub, of

840
00:30:03,440 --> 00:30:08,720
course. And I just want to shout out our

841
00:30:05,520 --> 00:30:10,559
infra team. uh Beaker which uh does all

842
00:30:08,720 --> 00:30:12,480
the experimental management at AI2. So

843
00:30:10,559 --> 00:30:14,799
this is fairly hard to run all these

844
00:30:12,480 --> 00:30:16,320
experiments and they've been awesome and

845
00:30:14,799 --> 00:30:18,960
the language modeling team that's the

846
00:30:16,320 --> 00:30:21,120
open language modeling team Almo um

847
00:30:18,960 --> 00:30:23,520
they've we've we've basically based this

848
00:30:21,120 --> 00:30:25,919
these libraries off their core uh

849
00:30:23,520 --> 00:30:28,720
training code which sped us up by a huge

850
00:30:25,919 --> 00:30:30,480
amount. Um I'll briefly comment here on

851
00:30:28,720 --> 00:30:31,760
comparisons to Alpha Earth. So, Alpha

852
00:30:30,480 --> 00:30:33,840
Foundations, you might have heard about

853
00:30:31,760 --> 00:30:35,600
generated huge buzz and is probably

854
00:30:33,840 --> 00:30:39,039
largely responsible for that massive

855
00:30:35,600 --> 00:30:41,520
uptick we saw um in the in the beginning

856
00:30:39,039 --> 00:30:44,240
in Google trends. Uh so, Google came out

857
00:30:41,520 --> 00:30:47,039
with this model earlier this year, I

858
00:30:44,240 --> 00:30:49,520
think in June, something like June or

859
00:30:47,039 --> 00:30:51,120
July, and it generated a ton of interest

860
00:30:49,520 --> 00:30:52,640
and that's a really great thing. And I

861
00:30:51,120 --> 00:30:56,080
want to emphasize that you know in

862
00:30:52,640 --> 00:30:59,039
general we are thrilled that so many uh

863
00:30:56,080 --> 00:31:00,880
uh talented teams are contributing

864
00:30:59,039 --> 00:31:04,159
models to this space. It's a great thing

865
00:31:00,880 --> 00:31:06,080
for the world when uh people work on

866
00:31:04,159 --> 00:31:08,399
this kind of technology. Um we're

867
00:31:06,080 --> 00:31:10,320
thrilled to see Google work on this. Um

868
00:31:08,399 --> 00:31:11,919
there's been a lot of activity recently

869
00:31:10,320 --> 00:31:13,200
and it's generally just a great thing

870
00:31:11,919 --> 00:31:15,360
and we really don't see it as a

871
00:31:13,200 --> 00:31:17,520
competition at all. That's not um how we

872
00:31:15,360 --> 00:31:18,880
look at the space. Um we see it more as

873
00:31:17,520 --> 00:31:21,840
like what can we learn from this? this

874
00:31:18,880 --> 00:31:24,399
is a a great uh contribution to the

875
00:31:21,840 --> 00:31:26,080
world and alpha earth and our model

876
00:31:24,399 --> 00:31:27,600
earth they're quite similar in some

877
00:31:26,080 --> 00:31:29,760
respects so they draw on similar data

878
00:31:27,600 --> 00:31:31,840
sources uh if you've read the alpha

879
00:31:29,760 --> 00:31:33,440
earth paper um quite similar data

880
00:31:31,840 --> 00:31:35,600
sources and they support similar

881
00:31:33,440 --> 00:31:37,279
downstream tasks um the big difference

882
00:31:35,600 --> 00:31:39,360
is that Google released annualized

883
00:31:37,279 --> 00:31:42,000
embeddings uh and I showed you that

884
00:31:39,360 --> 00:31:43,440
performance of KN&N LP uh earlier and

885
00:31:42,000 --> 00:31:45,840
I'll show you again sort of how we

886
00:31:43,440 --> 00:31:48,000
compare to to Google in a second but the

887
00:31:45,840 --> 00:31:50,399
they released annualized embeddings uh

888
00:31:48,000 --> 00:31:53,200
rather than the model itself. AEF

889
00:31:50,399 --> 00:31:54,720
embeddings are free uh to an extent.

890
00:31:53,200 --> 00:31:57,200
There's also a request for pace bucket

891
00:31:54,720 --> 00:31:59,279
if you need better scale. Um we have not

892
00:31:57,200 --> 00:32:00,960
released embeddings yet. Uh we're

893
00:31:59,279 --> 00:32:02,960
thinking about it and we may but we

894
00:32:00,960 --> 00:32:05,440
haven't yet done so. We've released a

895
00:32:02,960 --> 00:32:07,760
model and a platform that supports kind

896
00:32:05,440 --> 00:32:10,159
of more customization, greater

897
00:32:07,760 --> 00:32:12,399
customization of these models. Why did

898
00:32:10,159 --> 00:32:14,240
we not just release embeddings? Uh we we

899
00:32:12,399 --> 00:32:15,600
we certainly could. We think our

900
00:32:14,240 --> 00:32:17,440
embeddings are generally pretty high

901
00:32:15,600 --> 00:32:20,000
quality as you've seen from the CANNLP

902
00:32:17,440 --> 00:32:22,240
chart. Full fine-tuning, we we've we've

903
00:32:20,000 --> 00:32:24,399
found that full fine-tuning can

904
00:32:22,240 --> 00:32:26,720
significantly outperform frozen

905
00:32:24,399 --> 00:32:28,240
embeddings. And in our case, that means

906
00:32:26,720 --> 00:32:30,480
uh our users are going to get just

907
00:32:28,240 --> 00:32:32,320
better performance from uh doing

908
00:32:30,480 --> 00:32:34,159
fine-tuning. Fine-tuning is of course

909
00:32:32,320 --> 00:32:35,519
not trivial. The the reason folks are

910
00:32:34,159 --> 00:32:37,919
excited about embeddings in the first

911
00:32:35,519 --> 00:32:40,559
place is that it's kind of this cached

912
00:32:37,919 --> 00:32:42,159
artifact that is easily sharable and you

913
00:32:40,559 --> 00:32:43,600
know, I can just give you embeddings and

914
00:32:42,159 --> 00:32:46,640
then you're off to the races. and

915
00:32:43,600 --> 00:32:49,679
fine-tuning is uh not exactly like that.

916
00:32:46,640 --> 00:32:52,960
It it requires a little bit more uh

917
00:32:49,679 --> 00:32:54,640
in-depth work with the model. There is a

918
00:32:52,960 --> 00:32:56,720
argument that embeddings are a lot

919
00:32:54,640 --> 00:32:58,799
cheaper than fine-tuning. And in

920
00:32:56,720 --> 00:33:01,919
general, I think that can be true. But

921
00:32:58,799 --> 00:33:04,000
when you think about the cost of of of

922
00:33:01,919 --> 00:33:06,080
of these kinds of projects, when you're

923
00:33:04,000 --> 00:33:08,080
building an application that's dependent

924
00:33:06,080 --> 00:33:09,840
on this kind of technology, you're

925
00:33:08,080 --> 00:33:11,840
generally making a pretty significant

926
00:33:09,840 --> 00:33:15,279
investment. And it's it can be in many

927
00:33:11,840 --> 00:33:18,000
cases like months to years of effort and

928
00:33:15,279 --> 00:33:20,240
that's like of FTE time and and and

929
00:33:18,000 --> 00:33:22,399
significant resources well beyond just

930
00:33:20,240 --> 00:33:24,240
like the model. So I think that in

931
00:33:22,399 --> 00:33:26,240
general from from our perspective the

932
00:33:24,240 --> 00:33:29,200
the the cost of embeddings and

933
00:33:26,240 --> 00:33:30,320
fine-tuning uh may be you know similar

934
00:33:29,200 --> 00:33:32,720
maybe embeddings are a little bit

935
00:33:30,320 --> 00:33:34,320
cheaper may maybe not um but both are

936
00:33:32,720 --> 00:33:36,000
somewhat insignificant when you compare

937
00:33:34,320 --> 00:33:38,159
to the cost of real world application

938
00:33:36,000 --> 00:33:39,440
development. So fine-tuning for example

939
00:33:38,159 --> 00:33:40,960
for the models that I'm going to show

940
00:33:39,440 --> 00:33:43,039
you in a second with our applications

941
00:33:40,960 --> 00:33:45,919
are on the order of like 24 hours of

942
00:33:43,039 --> 00:33:48,240
H100 time. So uh you know not that

943
00:33:45,919 --> 00:33:49,360
expensive and especially when you or I

944
00:33:48,240 --> 00:33:51,679
shouldn't say not that expensive

945
00:33:49,360 --> 00:33:54,159
relatively inexpensive compared to the

946
00:33:51,679 --> 00:33:56,240
cost of full application development and

947
00:33:54,159 --> 00:33:57,760
that really is what I think matters most

948
00:33:56,240 --> 00:34:00,320
at least to our users and that's why

949
00:33:57,760 --> 00:34:01,600
we've uh chosen this route. Um here's

950
00:34:00,320 --> 00:34:04,720
some performance. This is a table from

951
00:34:01,600 --> 00:34:06,640
our paper just comparing AEF and uh

952
00:34:04,720 --> 00:34:09,359
Helio. Uh this is Helios. This is an old

953
00:34:06,640 --> 00:34:13,520
name but Helios directly. So uh AEF is

954
00:34:09,359 --> 00:34:15,919
Alfred Foundations. KN&N is uh K nearest

955
00:34:13,520 --> 00:34:17,760
neighbors. So this is just embeddings uh

956
00:34:15,919 --> 00:34:18,879
just vanilla embeddings. Whatever you

957
00:34:17,760 --> 00:34:20,320
get out of the box. So you can download

958
00:34:18,879 --> 00:34:22,320
these right now from Google. They made

959
00:34:20,320 --> 00:34:24,879
them all free um covering the entire

960
00:34:22,320 --> 00:34:26,800
world. These five applications here are

961
00:34:24,879 --> 00:34:28,399
from our partners. This is data that

962
00:34:26,800 --> 00:34:30,480
they've given to us and then we've

963
00:34:28,399 --> 00:34:32,159
evaluated our models against uh their

964
00:34:30,480 --> 00:34:33,839
data. We've trained and evaluated models

965
00:34:32,159 --> 00:34:36,879
against their data. So NANDI is a crop

966
00:34:33,839 --> 00:34:38,720
type mapping in Kenya. AWF is a land use

967
00:34:36,879 --> 00:34:41,040
land cover classification from the

968
00:34:38,720 --> 00:34:43,359
African wildlife foundation. This is

969
00:34:41,040 --> 00:34:45,679
also we have ecosystem classification

970
00:34:43,359 --> 00:34:47,679
here. Uh live fuel moisture content.

971
00:34:45,679 --> 00:34:49,679
This is a measurement of wildfire risk

972
00:34:47,679 --> 00:34:52,399
and then solar farm detection. So a

973
00:34:49,679 --> 00:34:54,879
fairly wide spread of applications here

974
00:34:52,399 --> 00:34:56,240
and covering kind of various things you

975
00:34:54,879 --> 00:34:58,000
would do with geospatial foundation

976
00:34:56,240 --> 00:34:59,599
models. And we've evaluated this in a

977
00:34:58,000 --> 00:35:02,000
few different ways. Here I'm showing

978
00:34:59,599 --> 00:35:03,520
KN&N a frozen decoder setup and then

979
00:35:02,000 --> 00:35:05,520
full fine-tuning. Obviously you can't do

980
00:35:03,520 --> 00:35:07,520
fine tuning with AEF because we just

981
00:35:05,520 --> 00:35:09,520
have access to the to the embedding. So

982
00:35:07,520 --> 00:35:11,599
we're only showing you those results for

983
00:35:09,520 --> 00:35:13,119
uh for OM Earth. Just try to ignore

984
00:35:11,599 --> 00:35:16,640
Helios here and just think about OM

985
00:35:13,119 --> 00:35:18,880
Earth as an old name. Uh and um what I

986
00:35:16,640 --> 00:35:21,119
want you to kind of take home or take

987
00:35:18,880 --> 00:35:22,400
away from this is that yes embedding

988
00:35:21,119 --> 00:35:24,640
performance can be really good. If we

989
00:35:22,400 --> 00:35:26,960
look at AWF for example, the performance

990
00:35:24,640 --> 00:35:28,560
the accuracy is is in the 80s and that's

991
00:35:26,960 --> 00:35:30,640
great and that's out of the box

992
00:35:28,560 --> 00:35:34,079
performance with embeddings. But we see

993
00:35:30,640 --> 00:35:36,160
fairly significant improvement from uh

994
00:35:34,079 --> 00:35:37,760
from from full fine-tuning. And on the

995
00:35:36,160 --> 00:35:39,119
left here, I'll draw your attention to

996
00:35:37,760 --> 00:35:40,560
Nandy. So this is crop type

997
00:35:39,119 --> 00:35:44,640
classification again. So this is a

998
00:35:40,560 --> 00:35:46,560
fairly hard problem within uh within EO

999
00:35:44,640 --> 00:35:48,240
tasks. Crop type classification is

1000
00:35:46,560 --> 00:35:50,079
extremely important. It matters like

1001
00:35:48,240 --> 00:35:51,359
what we're growing. We we need to plan

1002
00:35:50,079 --> 00:35:53,520
for the future. we need to figure out

1003
00:35:51,359 --> 00:35:55,119
how climate change is going to affect uh

1004
00:35:53,520 --> 00:35:56,880
growing and so on. And so we want to do

1005
00:35:55,119 --> 00:35:58,720
this really really well. We find that

1006
00:35:56,880 --> 00:36:00,960
fine-tuning which again in this case I

1007
00:35:58,720 --> 00:36:03,520
think it was something like 12 12 hours

1008
00:36:00,960 --> 00:36:05,200
of of H100 time can generate a pretty

1009
00:36:03,520 --> 00:36:06,800
dramatic improvement in performance and

1010
00:36:05,200 --> 00:36:09,920
this could very well be the difference

1011
00:36:06,800 --> 00:36:13,680
between uh you know shipping and not

1012
00:36:09,920 --> 00:36:15,040
shipping this model.

1013
00:36:13,680 --> 00:36:17,520
We also measured the environmental

1014
00:36:15,040 --> 00:36:19,520
impact so which we think is important uh

1015
00:36:17,520 --> 00:36:21,359
to to contextualize here. So here I'm

1016
00:36:19,520 --> 00:36:24,880
just showing you the numbers uh ho how

1017
00:36:21,359 --> 00:36:27,119
many H100 hours it it took to uh to

1018
00:36:24,880 --> 00:36:29,040
train these models for both pre-training

1019
00:36:27,119 --> 00:36:30,400
and then for fine-tuning. Finetuning was

1020
00:36:29,040 --> 00:36:33,200
a mix of hardware. And so I'm not

1021
00:36:30,400 --> 00:36:35,920
showing it was it was variance of uh a

1022
00:36:33,200 --> 00:36:37,839
H100 and A100. And so we're just showing

1023
00:36:35,920 --> 00:36:39,760
you the GP hours here, the energy, the

1024
00:36:37,839 --> 00:36:42,640
carbon and the water. Uh we have a

1025
00:36:39,760 --> 00:36:45,440
cluster uh or we we do pre-training on

1026
00:36:42,640 --> 00:36:47,200
our own cluster at AI2 uh which is

1027
00:36:45,440 --> 00:36:49,520
fairly energy efficient and it's also

1028
00:36:47,200 --> 00:36:53,040
very water efficient. it's closed loop.

1029
00:36:49,520 --> 00:36:55,119
Um, and so, uh, uh, it's it's it's

1030
00:36:53,040 --> 00:36:57,280
fairly water efficient in that regard.

1031
00:36:55,119 --> 00:36:59,200
Um, but we're obviously using energy.

1032
00:36:57,280 --> 00:37:01,040
And here, just to contextualize these

1033
00:36:59,200 --> 00:37:03,200
numbers, this is about what it would

1034
00:37:01,040 --> 00:37:05,119
cost, uh, across all these models, the

1035
00:37:03,200 --> 00:37:06,880
the energy was what it would co or what

1036
00:37:05,119 --> 00:37:09,599
it would take to power an average US

1037
00:37:06,880 --> 00:37:11,359
house for 5 months or an economy ticket

1038
00:37:09,599 --> 00:37:13,839
to or the and the carbon emissions are

1039
00:37:11,359 --> 00:37:17,200
are equivalent to an economy ticket on a

1040
00:37:13,839 --> 00:37:19,119
flight from Seattle to Portugal. So this

1041
00:37:17,200 --> 00:37:20,800
is the Omar team. This is the the

1042
00:37:19,119 --> 00:37:22,720
incredible team that built these models.

1043
00:37:20,800 --> 00:37:24,640
And I just want to shout out uh all

1044
00:37:22,720 --> 00:37:28,480
these uh these very special people that

1045
00:37:24,640 --> 00:37:29,920
that built this applications. So want to

1046
00:37:28,480 --> 00:37:31,760
talk a little bit about applications.

1047
00:37:29,920 --> 00:37:33,680
But before I do, I just want to say that

1048
00:37:31,760 --> 00:37:35,280
the reason we even have applications is

1049
00:37:33,680 --> 00:37:36,800
that we have a ton of partners that

1050
00:37:35,280 --> 00:37:38,160
we've been collaborating with from the

1051
00:37:36,800 --> 00:37:40,400
beginning of this project. And these are

1052
00:37:38,160 --> 00:37:42,079
some of them. Um so in wildfire we

1053
00:37:40,400 --> 00:37:44,320
collaborated with or and for forest

1054
00:37:42,079 --> 00:37:47,040
management we collabor collaborated with

1055
00:37:44,320 --> 00:37:49,359
ACA the Amazon conservation association

1056
00:37:47,040 --> 00:37:50,880
uh and NASA JPL. Um we've also been

1057
00:37:49,359 --> 00:37:52,400
collaborating with uh uh the

1058
00:37:50,880 --> 00:37:56,400
international food policy research

1059
00:37:52,400 --> 00:37:58,640
institute um as well as the uh uh CGI

1060
00:37:56,400 --> 00:38:01,440
and more recently the United Nations uh

1061
00:37:58,640 --> 00:38:03,760
food and agriculture organization um and

1062
00:38:01,440 --> 00:38:05,200
very recently with with NASA harvest.

1063
00:38:03,760 --> 00:38:08,640
And these organizations, these

1064
00:38:05,200 --> 00:38:10,000
collaborations are were integral to the

1065
00:38:08,640 --> 00:38:12,480
work that we did throughout this

1066
00:38:10,000 --> 00:38:14,720
project. They literally are um really

1067
00:38:12,480 --> 00:38:17,520
centering and anchoring our work. Um so

1068
00:38:14,720 --> 00:38:19,280
let me show you a few examples of of of

1069
00:38:17,520 --> 00:38:21,760
wildfire and forest health. And I'm also

1070
00:38:19,280 --> 00:38:23,359
going to ask Sher how I'm doing on time.

1071
00:38:21,760 --> 00:38:25,520
It's 450. I don't know when you want me

1072
00:38:23,359 --> 00:38:28,160
to stop.

1073
00:38:25,520 --> 00:38:29,599
>> I think you can take five minutes.

1074
00:38:28,160 --> 00:38:32,079
>> Five minutes.

1075
00:38:29,599 --> 00:38:34,240
>> Okay, I'll speed. I'm gonna go faster.

1076
00:38:32,079 --> 00:38:35,760
Um,

1077
00:38:34,240 --> 00:38:37,920
just kidding. I'll just focus a few

1078
00:38:35,760 --> 00:38:40,240
examples. So, Wildfire and Forsell. So,

1079
00:38:37,920 --> 00:38:41,520
uh, so I'm going to skip this. So, we

1080
00:38:40,240 --> 00:38:43,920
can take these models, these base

1081
00:38:41,520 --> 00:38:46,000
foundation models. We can fine-tune them

1082
00:38:43,920 --> 00:38:52,880
on a bunch of, uh, of ground truth

1083
00:38:46,000 --> 00:38:56,400
reference data from, uh, DNR uh, uh, um,

1084
00:38:52,880 --> 00:38:58,960
uh, forest uh, uh, DNR employees who go

1085
00:38:56,400 --> 00:39:00,720
out into the forest and and collect

1086
00:38:58,960 --> 00:39:02,480
collect wood samples, take them back to

1087
00:39:00,720 --> 00:39:03,760
the lab. uh dehydrate them and then

1088
00:39:02,480 --> 00:39:05,839
weigh them and that's a measurement of

1089
00:39:03,760 --> 00:39:07,599
of moisture. You can imagine that that

1090
00:39:05,839 --> 00:39:10,960
process that I just mentioned doesn't

1091
00:39:07,599 --> 00:39:12,960
scale super well. Uh we discovered that

1092
00:39:10,960 --> 00:39:15,359
we can take these models that we built,

1093
00:39:12,960 --> 00:39:16,960
fine-tune on those expert samples and

1094
00:39:15,359 --> 00:39:18,640
then produce wall-to-wall coverage. So

1095
00:39:16,960 --> 00:39:20,800
entire Pacific Northwest or entire

1096
00:39:18,640 --> 00:39:23,760
United States at like literally the cost

1097
00:39:20,800 --> 00:39:26,240
of a few cents. Uh it's just a little

1098
00:39:23,760 --> 00:39:29,119
bit of H100 time. And so we've done this

1099
00:39:26,240 --> 00:39:31,119
in a few areas uh before and after fires

1100
00:39:29,119 --> 00:39:33,359
to see if they work. And the net here is

1101
00:39:31,119 --> 00:39:34,880
that it's it's about a million times

1102
00:39:33,359 --> 00:39:36,079
cheaper. You still need that reference

1103
00:39:34,880 --> 00:39:38,480
data. You cannot do this without

1104
00:39:36,079 --> 00:39:39,760
reference data. Uh you need the experts

1105
00:39:38,480 --> 00:39:42,079
going out into the field to collect this

1106
00:39:39,760 --> 00:39:45,200
data, but enables you to scale in a way

1107
00:39:42,079 --> 00:39:46,800
that is just otherwise impractical. Um

1108
00:39:45,200 --> 00:39:49,359
we've also looked at deforestation in

1109
00:39:46,800 --> 00:39:51,040
the Amazon. I mentioned this earlier. So

1110
00:39:49,359 --> 00:39:52,960
uh on the right you're seeing a map that

1111
00:39:51,040 --> 00:39:54,560
we've produced of Amazon conserv with

1112
00:39:52,960 --> 00:39:56,800
Amazon Conservation Association. So

1113
00:39:54,560 --> 00:39:58,320
we're producing deforestation maps

1114
00:39:56,800 --> 00:39:59,920
specifically what the cause of

1115
00:39:58,320 --> 00:40:01,599
deforestation was. Was it farming? Was

1116
00:39:59,920 --> 00:40:03,599
it a landslide? That kind of thing. So,

1117
00:40:01,599 --> 00:40:05,680
these are time series models. Omar was

1118
00:40:03,599 --> 00:40:07,440
trained, fine-tuned with expert data

1119
00:40:05,680 --> 00:40:10,160
from from the experts from Amazon

1120
00:40:07,440 --> 00:40:12,800
Conservation Conservation Association,

1121
00:40:10,160 --> 00:40:16,320
and we're yielding uh roughly a three

1122
00:40:12,800 --> 00:40:20,640
order of magnitude over what uh the 10

1123
00:40:16,320 --> 00:40:22,560
km norm was before. Um

1124
00:40:20,640 --> 00:40:24,160
we've done uh work with the global

1125
00:40:22,560 --> 00:40:25,440
mangrove watch with these same models

1126
00:40:24,160 --> 00:40:26,560
and we've been partnering with the

1127
00:40:25,440 --> 00:40:28,560
global mangrove watch from the

1128
00:40:26,560 --> 00:40:31,440
beginning. Actually in this case uh they

1129
00:40:28,560 --> 00:40:34,000
gave us um or we worked with them on

1130
00:40:31,440 --> 00:40:35,680
training a new model anomal earth model

1131
00:40:34,000 --> 00:40:38,800
uh so base foundation model again

1132
00:40:35,680 --> 00:40:40,800
fine-tuned on expert uh GMW data and we

1133
00:40:38,800 --> 00:40:42,880
can get about roughly similar

1134
00:40:40,800 --> 00:40:45,040
performance that they were getting um

1135
00:40:42,880 --> 00:40:46,800
with their you know five and 5.8 8

1136
00:40:45,040 --> 00:40:48,560
million training points with uh like

1137
00:40:46,800 --> 00:40:50,800
literally 10k samples and that enables

1138
00:40:48,560 --> 00:40:52,480
them to spend more time uh doing the

1139
00:40:50,800 --> 00:40:54,480
important work that they're doing less

1140
00:40:52,480 --> 00:40:57,280
time hopefully on the things that you

1141
00:40:54,480 --> 00:40:59,200
know on say data annotation um so they

1142
00:40:57,280 --> 00:41:00,960
can do their work uh we can accelerate

1143
00:40:59,200 --> 00:41:03,119
their work

1144
00:41:00,960 --> 00:41:04,880
um

1145
00:41:03,119 --> 00:41:08,079
okay one more example Sher and then I'll

1146
00:41:04,880 --> 00:41:09,280
wrap up um I want to highlight one more

1147
00:41:08,079 --> 00:41:10,720
example and this was with the

1148
00:41:09,280 --> 00:41:13,520
international food policy research

1149
00:41:10,720 --> 00:41:15,119
institute so we we need to map crops at

1150
00:41:13,520 --> 00:41:17,599
scale we need to do this really really

1151
00:41:15,119 --> 00:41:19,680
well um for a whole bunch of reasons for

1152
00:41:17,599 --> 00:41:21,280
policy for farmers for planning for

1153
00:41:19,680 --> 00:41:23,280
climate change for many different

1154
00:41:21,280 --> 00:41:26,000
reasons and currently this is like an

1155
00:41:23,280 --> 00:41:27,440
unsolved problem in the space and we

1156
00:41:26,000 --> 00:41:28,720
think you can do a pretty good job and

1157
00:41:27,440 --> 00:41:30,560
we're not the only group to do this just

1158
00:41:28,720 --> 00:41:32,480
to be clear in fact Sherry is is is one

1159
00:41:30,560 --> 00:41:34,319
of the labs that uh has done this really

1160
00:41:32,480 --> 00:41:37,280
well but we are generally trying to do

1161
00:41:34,319 --> 00:41:40,480
this well at scale with very few samples

1162
00:41:37,280 --> 00:41:41,520
um it's a really hard problem so uh we

1163
00:41:40,480 --> 00:41:43,520
were approached by the international

1164
00:41:41,520 --> 00:41:45,520
food policy re research institute they

1165
00:41:43,520 --> 00:41:47,359
say hey we all this data, can you train

1166
00:41:45,520 --> 00:41:49,119
your model on our data and see if you

1167
00:41:47,359 --> 00:41:51,040
can get good results? And we got pretty

1168
00:41:49,119 --> 00:41:52,560
good results. So on the left uh table

1169
00:41:51,040 --> 00:41:53,760
here, you're seeing a random forces from

1170
00:41:52,560 --> 00:41:56,400
iffree. On the right, you're seeing

1171
00:41:53,760 --> 00:41:59,680
literally first pass from Omo Earth. Uh

1172
00:41:56,400 --> 00:42:02,079
and the results were were quite good.

1173
00:41:59,680 --> 00:42:06,079
And now I'm going to go

1174
00:42:02,079 --> 00:42:07,359
lightning speed, Sherry. So Earth is

1175
00:42:06,079 --> 00:42:09,680
designed to close this gap from

1176
00:42:07,359 --> 00:42:11,119
foundation models to to our users. And

1177
00:42:09,680 --> 00:42:13,040
we've built a whole platform that

1178
00:42:11,119 --> 00:42:16,000
enables everything that I just said to

1179
00:42:13,040 --> 00:42:18,079
give people access to this technology.

1180
00:42:16,000 --> 00:42:20,240
So all the foundation models uh

1181
00:42:18,079 --> 00:42:23,040
applications for uh we built all of this

1182
00:42:20,240 --> 00:42:25,440
and we've uh made it available uh all

1183
00:42:23,040 --> 00:42:27,680
the way from you know data acquisition

1184
00:42:25,440 --> 00:42:30,800
through annotation labeling deployment

1185
00:42:27,680 --> 00:42:34,560
serving and we have a web app uh and

1186
00:42:30,800 --> 00:42:36,560
this has this is now available. So we

1187
00:42:34,560 --> 00:42:38,240
and we're making this all free. Uh we

1188
00:42:36,560 --> 00:42:40,079
think this should be a public good as I

1189
00:42:38,240 --> 00:42:42,720
mentioned. Um and we think we'll do

1190
00:42:40,079 --> 00:42:43,920
better by by working together. Um so

1191
00:42:42,720 --> 00:42:46,640
this is approximately what it looks

1192
00:42:43,920 --> 00:42:48,560
like. Um and I'm going to skip now to

1193
00:42:46,640 --> 00:42:50,400
the last slide

1194
00:42:48,560 --> 00:42:52,319
like I even said otherwise skip time

1195
00:42:50,400 --> 00:42:54,079
permitting.

1196
00:42:52,319 --> 00:42:56,000
Um there was a lot of interesting stuff

1197
00:42:54,079 --> 00:42:59,200
in there that will be for another time.

1198
00:42:56,000 --> 00:43:01,119
So this is kind of what I want to end or

1199
00:42:59,200 --> 00:43:05,040
or leave you with is that I think this

1200
00:43:01,119 --> 00:43:07,760
was a step in in uh a step towards open

1201
00:43:05,040 --> 00:43:09,680
accessible and you know more holistic

1202
00:43:07,760 --> 00:43:14,079
modeling of the earth. I think we have a

1203
00:43:09,680 --> 00:43:16,319
quite a long ways to go clearly and I I

1204
00:43:14,079 --> 00:43:18,400
think you know our approach here is to

1205
00:43:16,319 --> 00:43:19,760
build open artificial intelligence

1206
00:43:18,400 --> 00:43:22,240
really in close collaboration with

1207
00:43:19,760 --> 00:43:24,240
partners. Uh we of course welcome new

1208
00:43:22,240 --> 00:43:25,920
partnerships across uh research,

1209
00:43:24,240 --> 00:43:28,720
engineering, obviously fieldwork,

1210
00:43:25,920 --> 00:43:31,200
policy. Um and in general I would just

1211
00:43:28,720 --> 00:43:33,760
uh end with the the the idea that you

1212
00:43:31,200 --> 00:43:36,000
know we have a responsibility to steer

1213
00:43:33,760 --> 00:43:38,160
artificial intelligence you know for the

1214
00:43:36,000 --> 00:43:40,685
benefit of all humanity. So thank you so

1215
00:43:38,160 --> 00:43:42,705
much for your time.

1216
00:43:40,685 --> 00:43:42,705
[applause]


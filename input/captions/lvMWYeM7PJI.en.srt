1
00:00:00,000 --> 00:00:08,450

2
00:00:08,450 --> 00:00:10,820
I think we'll go ahead and
get started since we're

3
00:00:10,820 --> 00:00:11,970
starting a little bit late.

4
00:00:11,970 --> 00:00:15,140
I'm Emery Brown, I'm from BCS,
Brain and Cognitive Sciences

5
00:00:15,140 --> 00:00:16,140
Picower Institute.

6
00:00:16,140 --> 00:00:20,030
I'm going to be the moderator
for this session on brains.

7
00:00:20,030 --> 00:00:23,190
So why think about the brain?

8
00:00:23,190 --> 00:00:24,720
It's this fantastic organ.

9
00:00:24,720 --> 00:00:28,700
It only weighs 3 pounds,
but it consumes almost 20%

10
00:00:28,700 --> 00:00:32,810
of the oxygen in
the cardiac output.

11
00:00:32,810 --> 00:00:35,190
And studying the brain is a
challenge because almost--

12
00:00:35,190 --> 00:00:37,580
but what's cool about it
is that everything we learn

13
00:00:37,580 --> 00:00:40,550
can help us with new diseases
relevant to the brain.

14
00:00:40,550 --> 00:00:43,790
And the critical factors,
as was mentioned earlier

15
00:00:43,790 --> 00:00:48,800
in today's first session, is
that, just like the other areas

16
00:00:48,800 --> 00:00:50,400
of investigation
that were discussed,

17
00:00:50,400 --> 00:00:53,130
brain research and brain related
improvements in health care,

18
00:00:53,130 --> 00:00:54,838
there are three things
that converge here

19
00:00:54,838 --> 00:00:57,780
at MIT, advances in science,
engineering innovations,

20
00:00:57,780 --> 00:00:59,130
translational applications.

21
00:00:59,130 --> 00:01:01,640
And you'll hear that
today from our speakers.

22
00:01:01,640 --> 00:01:03,780
So these are our speakers.

23
00:01:03,780 --> 00:01:06,860
We're very happy to have
Ed Boyden from the Picower

24
00:01:06,860 --> 00:01:13,550
Institute, Mark Baier, also
from the Picower Institute, Josh

25
00:01:13,550 --> 00:01:15,980
McDermott from the
McGovern Institute,

26
00:01:15,980 --> 00:01:20,750
and also Evelina Fedorenko
from the McGovern Institute.

27
00:01:20,750 --> 00:01:24,230
And we just made a
little chart to show you

28
00:01:24,230 --> 00:01:27,170
that indeed, these
three areas will

29
00:01:27,170 --> 00:01:30,600
be touched throughout with the
talks that you're going to hear.

30
00:01:30,600 --> 00:01:33,800
So with that, I'll turn
it over to my colleagues.

31
00:01:33,800 --> 00:01:34,310
Ed.

32
00:01:34,310 --> 00:01:37,286
[APPLAUSE]

33
00:01:37,286 --> 00:01:43,250

34
00:01:43,250 --> 00:01:45,180
All right, yeah,
thank you so much.

35
00:01:45,180 --> 00:01:47,030
This is really a
fun day and it's

36
00:01:47,030 --> 00:01:49,340
great to see so many
convergent fields

37
00:01:49,340 --> 00:01:51,500
in this amazing, important area.

38
00:01:51,500 --> 00:01:53,570
I direct a group that
tries to confront

39
00:01:53,570 --> 00:01:57,100
through technology the spatial
and temporal complexity

40
00:01:57,100 --> 00:01:58,040
of the brain.

41
00:01:58,040 --> 00:02:00,560
And this is a great
arena for innovation.

42
00:02:00,560 --> 00:02:02,590
I mean, the brain is
a gigantic object.

43
00:02:02,590 --> 00:02:04,910
And brain cells are
gigantic objects.

44
00:02:04,910 --> 00:02:07,990
But the wiring of the
brain is nanoscale, right?

45
00:02:07,990 --> 00:02:10,389
The wiring is extremely tiny.

46
00:02:10,389 --> 00:02:12,220
And the connections
between brain cells

47
00:02:12,220 --> 00:02:14,530
are also very, very small.

48
00:02:14,530 --> 00:02:16,640
Also, we have molecules, right?

49
00:02:16,640 --> 00:02:17,870
The human genome has, what?

50
00:02:17,870 --> 00:02:21,852
30,000 or so genes encoding
for countless biomolecules.

51
00:02:21,852 --> 00:02:24,310
And we need to know what they
do and how they work together

52
00:02:24,310 --> 00:02:27,463
and how they go wrong
in disease states.

53
00:02:27,463 --> 00:02:29,380
But it's even more
complicated because there's

54
00:02:29,380 --> 00:02:31,060
a time dimension, too.

55
00:02:31,060 --> 00:02:35,800
If you think about Alzheimer's
disease or learning or aging

56
00:02:35,800 --> 00:02:39,050
or almost any process that's
important to us as people,

57
00:02:39,050 --> 00:02:44,500
there's an extended component of
time related to these functions.

58
00:02:44,500 --> 00:02:47,290
Yet, the elementary
neural codes of the brain

59
00:02:47,290 --> 00:02:50,140
are very, very brief,
millisecond timescale electrical

60
00:02:50,140 --> 00:02:51,140
pulses.

61
00:02:51,140 --> 00:02:53,740
So we build tools to try
to help neuroscientists

62
00:02:53,740 --> 00:02:58,390
conquer these differences
in space and time.

63
00:02:58,390 --> 00:02:59,660
Now, why is it important?

64
00:02:59,660 --> 00:03:01,420
Well, lots of
technologies exist.

65
00:03:01,420 --> 00:03:04,750
On the left, MRI scans,
on the right, microscopes.

66
00:03:04,750 --> 00:03:07,240
But it's very hard to
image a large object

67
00:03:07,240 --> 00:03:10,180
like a brain down to those
nanoscale dimensions.

68
00:03:10,180 --> 00:03:14,050
So in our group, we practice a
lot of creativity skills, which

69
00:03:14,050 --> 00:03:16,190
we think can be
learned and practiced,

70
00:03:16,190 --> 00:03:18,040
and one idea is to do
the opposite of what

71
00:03:18,040 --> 00:03:19,210
people are doing.

72
00:03:19,210 --> 00:03:21,220
And for literally
300 years, the way

73
00:03:21,220 --> 00:03:25,360
that biologists
magnify images of cells

74
00:03:25,360 --> 00:03:27,490
is with some kind
of lensing effect.

75
00:03:27,490 --> 00:03:28,900
We started wondering,
what if you

76
00:03:28,900 --> 00:03:31,420
could magnify cells directly?

77
00:03:31,420 --> 00:03:34,600
And so the basic idea, we
call expansion microscopy,

78
00:03:34,600 --> 00:03:37,780
we chemically install a
dense, spiderweb like mesh

79
00:03:37,780 --> 00:03:42,470
of, basically, baby diaper
polymer inside the brain.

80
00:03:42,470 --> 00:03:45,560
Not a living brain,
but a preserved one.

81
00:03:45,560 --> 00:03:50,080
And if you do it just right,
you can weave that chemical mesh

82
00:03:50,080 --> 00:03:54,000
inside cells and outside
cells, around biomolecules,

83
00:03:54,000 --> 00:03:56,850
in between biomolecules,
and you can

84
00:03:56,850 --> 00:03:58,630
magnify the brain physically.

85
00:03:58,630 --> 00:04:01,230
So in panel B here is a
piece of the mouse brain

86
00:04:01,230 --> 00:04:03,420
several millimeters on the side.

87
00:04:03,420 --> 00:04:07,170
Panel C, the same piece of
brain tissue about a day, day

88
00:04:07,170 --> 00:04:09,870
and a half later, but we've
blown it up by 100 times

89
00:04:09,870 --> 00:04:11,010
in volume.

90
00:04:11,010 --> 00:04:13,180
And the polymer starts
out super dense,

91
00:04:13,180 --> 00:04:15,490
like in the upper
left in that cartoon,

92
00:04:15,490 --> 00:04:18,269
and ends up like
in the lower left.

93
00:04:18,269 --> 00:04:21,399
Here's a little movie of a
piece of brain being expanded.

94
00:04:21,399 --> 00:04:23,620
So we formed the baby
diaper polymer earlier,

95
00:04:23,620 --> 00:04:26,680
and it's half an hour sped
up to about half a minute.

96
00:04:26,680 --> 00:04:29,548
But we add water right there.

97
00:04:29,548 --> 00:04:31,840
And I hope you can see that
this piece of brain tissue,

98
00:04:31,840 --> 00:04:34,150
which is permeated by
the baby diaper polymer,

99
00:04:34,150 --> 00:04:37,040
is physically growing right
before your very eyes.

100
00:04:37,040 --> 00:04:47,130

101
00:04:47,130 --> 00:04:47,920
That's great.

102
00:04:47,920 --> 00:04:51,340
So now, we can use
imaging tools and see

103
00:04:51,340 --> 00:04:52,860
tiny things that
are too small to be

104
00:04:52,860 --> 00:04:54,670
seen by regular technology.

105
00:04:54,670 --> 00:04:57,780
And that's important because,
again, molecules are tiny

106
00:04:57,780 --> 00:05:00,190
and the wiring of the
brain is also really tiny.

107
00:05:00,190 --> 00:05:03,720
And yet, you want to understand
it across an extended 3D spatial

108
00:05:03,720 --> 00:05:04,630
extent.

109
00:05:04,630 --> 00:05:06,880
So here's an actual
piece of brain tissue.

110
00:05:06,880 --> 00:05:08,610
This is from the
mouse hippocampus,

111
00:05:08,610 --> 00:05:10,210
which is involved
with many functions,

112
00:05:10,210 --> 00:05:13,360
including related to memory, but
lots of other things as well.

113
00:05:13,360 --> 00:05:16,780
And the brain cells are
expressing fluorescent proteins.

114
00:05:16,780 --> 00:05:19,350
So these are proteins borrowed
from jellyfish, coral,

115
00:05:19,350 --> 00:05:21,120
and other creatures.

116
00:05:21,120 --> 00:05:24,850
And it gives you a color
code or barcode, if you will,

117
00:05:24,850 --> 00:05:27,360
so you can tell the cells apart.

118
00:05:27,360 --> 00:05:30,160
We deliver the genes for
these proteins using viruses.

119
00:05:30,160 --> 00:05:32,670
We then preserve the brain
and expand it using the method

120
00:05:32,670 --> 00:05:34,350
that I told you about.

121
00:05:34,350 --> 00:05:38,400
And now, we can see the final
wiring much better than before.

122
00:05:38,400 --> 00:05:40,900
So we're going to fly through
this piece of brain right now.

123
00:05:40,900 --> 00:05:44,200
And I hope you can see that
these individual processes,

124
00:05:44,200 --> 00:05:47,130
which have distinct colors,
are much, much easier

125
00:05:47,130 --> 00:05:50,660
to see than one of my guests.

126
00:05:50,660 --> 00:05:52,850
And then, of course,
we can Zoom in and out.

127
00:05:52,850 --> 00:05:55,010
It's intrinsically
a multi-scale way

128
00:05:55,010 --> 00:05:59,592
of visualizing the
brain circuitry.

129
00:05:59,592 --> 00:06:01,550
So we're excited about
this idea and how we can

130
00:06:01,550 --> 00:06:04,535
use it to map entire brains.

131
00:06:04,535 --> 00:06:06,660
But of course, this doesn't
work on a living thing.

132
00:06:06,660 --> 00:06:08,540
And so we have to
really switch gears here

133
00:06:08,540 --> 00:06:11,240
to tackle the second
question, which is time.

134
00:06:11,240 --> 00:06:14,220
How do we control these fast
electrical pulses of the brain?

135
00:06:14,220 --> 00:06:15,650
If we could control
them, then you

136
00:06:15,650 --> 00:06:18,150
could drive certain brain cells
and figure out what they do.

137
00:06:18,150 --> 00:06:20,750
Do they trigger a
behavior or a pathology

138
00:06:20,750 --> 00:06:24,080
or perhaps the remedy
of a pathology?

139
00:06:24,080 --> 00:06:25,820
And so the idea that
we brought forth

140
00:06:25,820 --> 00:06:28,650
is this concept that we
now call optogenetics,

141
00:06:28,650 --> 00:06:31,080
because opto is about
light, and genetics,

142
00:06:31,080 --> 00:06:34,800
because we use genes to
mediate light sensitivity.

143
00:06:34,800 --> 00:06:37,490
The basic concept is
basically like this.

144
00:06:37,490 --> 00:06:39,380
Suppose you had
solar panels that

145
00:06:39,380 --> 00:06:40,950
convert light to electricity.

146
00:06:40,950 --> 00:06:43,770
If you could somehow
install them on brain cells,

147
00:06:43,770 --> 00:06:46,890
shine light on the solar
panels, convert to electricity,

148
00:06:46,890 --> 00:06:48,260
you could control the brain.

149
00:06:48,260 --> 00:06:50,370
And then, you could bring
light into the brain.

150
00:06:50,370 --> 00:06:53,060
Electrodes are brought into
the brain all the time.

151
00:06:53,060 --> 00:06:55,880
Because it doesn't feel pain
we can bring optical fibers

152
00:06:55,880 --> 00:06:58,310
in as well.

153
00:06:58,310 --> 00:06:59,960
So how do we do it?

154
00:06:59,960 --> 00:07:02,460
Well, we have to make
the neurons sense

155
00:07:02,460 --> 00:07:04,710
light, which means we have
to find those solar panels.

156
00:07:04,710 --> 00:07:06,543
And it turns out, all
over the tree of life,

157
00:07:06,543 --> 00:07:08,580
you can find molecules
that do that, right?

158
00:07:08,580 --> 00:07:11,700
So here we are looking at a
single celled green algae.

159
00:07:11,700 --> 00:07:15,140
And it has an eyespot in the
back there, which helps it

160
00:07:15,140 --> 00:07:16,770
sense light to control
those flagella,

161
00:07:16,770 --> 00:07:18,420
those tails that help it swim.

162
00:07:18,420 --> 00:07:20,570
We just zoomed in
to the eyespot,

163
00:07:20,570 --> 00:07:23,780
and it's chock full of these
proteins that convert light

164
00:07:23,780 --> 00:07:26,700
into electrical
signals, ion fluxes.

165
00:07:26,700 --> 00:07:30,110
Kind of like those solar panels
that we were just talking about.

166
00:07:30,110 --> 00:07:33,440
So what we can do is take
advantage of the fact

167
00:07:33,440 --> 00:07:34,740
that this is a protein.

168
00:07:34,740 --> 00:07:36,150
It's genetically encoded.

169
00:07:36,150 --> 00:07:38,940
It has the right temporal
and other properties.

170
00:07:38,940 --> 00:07:42,260
It's a fast response to light
because you just open up a pore

171
00:07:42,260 --> 00:07:45,050
and instantly get
ion flux across.

172
00:07:45,050 --> 00:07:46,700
And so the idea that
we brought forth

173
00:07:46,700 --> 00:07:49,370
was, let's borrow this
gene and see if we

174
00:07:49,370 --> 00:07:51,500
could put it into the brain.

175
00:07:51,500 --> 00:07:54,890
And so this is where we had
to count on serendipity.

176
00:07:54,890 --> 00:07:57,110
We're very excited now, by
the way, to try to use AI

177
00:07:57,110 --> 00:07:59,830
and other methods to do on
purpose what we did accidentally

178
00:07:59,830 --> 00:08:00,330
here.

179
00:08:00,330 --> 00:08:03,230
Can we go out and look for
treasure in the natural world

180
00:08:03,230 --> 00:08:06,420
and not just wait around
for it to show up?

181
00:08:06,420 --> 00:08:07,820
Anyway, we can
take the gene that

182
00:08:07,820 --> 00:08:09,840
encodes for this light
activated protein,

183
00:08:09,840 --> 00:08:13,070
we can install it using
a gene delivery method,

184
00:08:13,070 --> 00:08:15,780
like a gene therapy vector
into the brain cell.

185
00:08:15,780 --> 00:08:19,080
The brain cell will manufacture
the light activated protein.

186
00:08:19,080 --> 00:08:21,210
And then, again,
serendipity kicked in again.

187
00:08:21,210 --> 00:08:22,320
It was safe.

188
00:08:22,320 --> 00:08:23,370
It worked.

189
00:08:23,370 --> 00:08:24,800
It didn't have to work.

190
00:08:24,800 --> 00:08:27,240
The algae could have been a
happy home for the protein

191
00:08:27,240 --> 00:08:30,660
and the neuron could have
died or malfunctioned.

192
00:08:30,660 --> 00:08:32,780
Anyway, it was really
surprising in a pleasant way

193
00:08:32,780 --> 00:08:35,780
that when we shine light
from a laser or an LED

194
00:08:35,780 --> 00:08:38,030
on these brain cells, they
fired electrical pulses,

195
00:08:38,030 --> 00:08:40,700
not unlike the ones
happening in your own heads

196
00:08:40,700 --> 00:08:43,450
right now as I say these words.

197
00:08:43,450 --> 00:08:45,370
So there's lots of
things you can do.

198
00:08:45,370 --> 00:08:48,040
You can take different
parts of the brain,

199
00:08:48,040 --> 00:08:50,650
put these light activated
molecules in them,

200
00:08:50,650 --> 00:08:51,663
try to see what happens.

201
00:08:51,663 --> 00:08:54,080
So I'll just pick one example
because it has a nice movie.

202
00:08:54,080 --> 00:08:58,032
But dopamine is a very important
neuromodulator in the brain.

203
00:08:58,032 --> 00:09:00,490
In the popular press, it's
often called the pleasure center

204
00:09:00,490 --> 00:09:01,420
of the brain.

205
00:09:01,420 --> 00:09:04,450
Could you find out
whether reinforcing

206
00:09:04,450 --> 00:09:07,640
the activity of these neurons
also reinforces behavior?

207
00:09:07,640 --> 00:09:09,560
And so it's a very
simple experiment here.

208
00:09:09,560 --> 00:09:11,638
Mice go and poke their
nose in a little portal.

209
00:09:11,638 --> 00:09:13,180
And if they go to
the right one, they

210
00:09:13,180 --> 00:09:16,120
get a pulse of light that aims
at these dopamine neurons, which

211
00:09:16,120 --> 00:09:18,050
are expressing the
light activated protein.

212
00:09:18,050 --> 00:09:20,008
If they go to the left
portal, nothing happens.

213
00:09:20,008 --> 00:09:22,000
And so you can see the
result. Lifts its nose,

214
00:09:22,000 --> 00:09:25,820
gets the pulse of light,
does it again, does it again.

215
00:09:25,820 --> 00:09:29,290
And so this mouse is,
basically, working for light.

216
00:09:29,290 --> 00:09:30,605
So this is very widespread.

217
00:09:30,605 --> 00:09:32,480
We share all of our
tools freely, by the way.

218
00:09:32,480 --> 00:09:34,750
So expansion microscopy
that I talked about before

219
00:09:34,750 --> 00:09:37,480
is in use by thousands
of research groups,

220
00:09:37,480 --> 00:09:40,240
almost 900 experimental
results coming out already.

221
00:09:40,240 --> 00:09:42,490
Optogenetics is in use by
thousands of research groups

222
00:09:42,490 --> 00:09:43,280
as well.

223
00:09:43,280 --> 00:09:45,040
And interestingly,
these molecules

224
00:09:45,040 --> 00:09:46,790
are starting to be
used in people as well.

225
00:09:46,790 --> 00:09:48,080
So many people are blind.

226
00:09:48,080 --> 00:09:50,710
They've lost their light
sensors in their eyes.

227
00:09:50,710 --> 00:09:53,200
A team in Europe got
one of our molecules,

228
00:09:53,200 --> 00:09:58,150
discovered here at MIT, and was
able to deliver the gene for it

229
00:09:58,150 --> 00:10:01,190
into the eye of a person who
lost his normal light sensors.

230
00:10:01,190 --> 00:10:03,400
And they converted the
spared cells of the eye

231
00:10:03,400 --> 00:10:06,020
into, well, kind of a camera.

232
00:10:06,020 --> 00:10:08,510
And so he was able to
recognize household objects.

233
00:10:08,510 --> 00:10:10,100
He could see doors on a hallway.

234
00:10:10,100 --> 00:10:13,430
Not perfect vision, couldn't
recognize faces very well,

235
00:10:13,430 --> 00:10:15,980
struggled to read text,
so more work to be done.

236
00:10:15,980 --> 00:10:19,930
But still, a very
interesting advance

237
00:10:19,930 --> 00:10:24,390
in an otherwise extremely
difficult to confront condition.

238
00:10:24,390 --> 00:10:26,390
Going forward, we want
to integrate these tools.

239
00:10:26,390 --> 00:10:27,680
We've always shared
the tools freely,

240
00:10:27,680 --> 00:10:29,138
but we want to
start combining them

241
00:10:29,138 --> 00:10:31,000
towards this goal
of making computer

242
00:10:31,000 --> 00:10:32,890
simulations of the brain.

243
00:10:32,890 --> 00:10:34,640
If we could simulate
the brain, of course,

244
00:10:34,640 --> 00:10:37,265
that'd be very interesting from
an AI perspective, potentially.

245
00:10:37,265 --> 00:10:39,210
But also, we could maybe
look under the hood

246
00:10:39,210 --> 00:10:41,310
and poke around in silico--

247
00:10:41,310 --> 00:10:42,900
in software and
try to figure out

248
00:10:42,900 --> 00:10:46,150
where in a network to intervene
to help with the disease state.

249
00:10:46,150 --> 00:10:49,520
And of course, if we could
simulate brain computations

250
00:10:49,520 --> 00:10:51,270
of different kinds,
it could become a tool

251
00:10:51,270 --> 00:10:53,800
that we could use to probe
different scientific questions.

252
00:10:53,800 --> 00:10:56,425
So in the coming years, our hope
is to start with small brains,

253
00:10:56,425 --> 00:10:58,290
like fish and worms,
and start going

254
00:10:58,290 --> 00:11:00,270
to larger and larger brains.

255
00:11:00,270 --> 00:11:02,350
And this is sort of
a complicated slide,

256
00:11:02,350 --> 00:11:04,590
but it outlines one
of our ways of trying

257
00:11:04,590 --> 00:11:06,810
to put together all the
different approaches that we

258
00:11:06,810 --> 00:11:07,180
take.

259
00:11:07,180 --> 00:11:09,138
So the upper left, we
want to look at the brain

260
00:11:09,138 --> 00:11:10,650
while it's in action,
the blue part.

261
00:11:10,650 --> 00:11:12,110
In the lower left
with yellow, we're

262
00:11:12,110 --> 00:11:13,485
going to use the
expansion method

263
00:11:13,485 --> 00:11:14,890
to make maps of the brain.

264
00:11:14,890 --> 00:11:16,992
And then, the three
blocks to the right

265
00:11:16,992 --> 00:11:19,200
are ways of making different
models, machine learning

266
00:11:19,200 --> 00:11:21,863
models, biophysical
models, and so forth.

267
00:11:21,863 --> 00:11:24,030
So to conclude, we're very
excited about these tools

268
00:11:24,030 --> 00:11:26,580
we're building to see, map,
control, and understand

269
00:11:26,580 --> 00:11:27,140
the brain.

270
00:11:27,140 --> 00:11:28,390
We share them all very freely.

271
00:11:28,390 --> 00:11:29,880
But in the time to
come, we're very

272
00:11:29,880 --> 00:11:32,580
excited to try to integrate them
into a workflow that hopefully

273
00:11:32,580 --> 00:11:35,220
can help us build computational
models as well that

274
00:11:35,220 --> 00:11:37,170
can be of great use for others.

275
00:11:37,170 --> 00:11:38,358
Thank you.

276
00:11:38,358 --> 00:11:41,774
[APPLAUSE]

277
00:11:41,774 --> 00:11:47,640

278
00:11:47,640 --> 00:11:49,160
Just let me grab my jacket here.

279
00:11:49,160 --> 00:11:58,410

280
00:11:58,410 --> 00:12:02,260
All right, sounded like an
unruly classroom earlier,

281
00:12:02,260 --> 00:12:03,875
but I'm glad
everybody's calmed down.

282
00:12:03,875 --> 00:12:06,510

283
00:12:06,510 --> 00:12:12,120
A sad fact of life is that
diseases, deprivation,

284
00:12:12,120 --> 00:12:14,950
and injuries can
impair brain function,

285
00:12:14,950 --> 00:12:18,670
and it's extremely difficult
to restore brain function,

286
00:12:18,670 --> 00:12:20,260
particularly in adulthood.

287
00:12:20,260 --> 00:12:22,860
And a very classic
example of this

288
00:12:22,860 --> 00:12:26,310
is a condition called
amblyopia, which

289
00:12:26,310 --> 00:12:29,610
is a condition that is a
visual impairment that develops

290
00:12:29,610 --> 00:12:33,610
in children that don't have high
quality vision during infancy.

291
00:12:33,610 --> 00:12:35,710
And that's what's shown
here on the left side.

292
00:12:35,710 --> 00:12:38,980
This is a child that has
a cataract in one eye.

293
00:12:38,980 --> 00:12:41,700
The cataract is easily
detected and can

294
00:12:41,700 --> 00:12:43,320
be surgically
removed and replaced

295
00:12:43,320 --> 00:12:45,070
with an artificial lens.

296
00:12:45,070 --> 00:12:48,180
But as a consequence of that
altered visual experience

297
00:12:48,180 --> 00:12:51,640
during infancy, there's a
permanent visual disability.

298
00:12:51,640 --> 00:12:56,440
So there's a very severe visual
disability in the amblyopic eye,

299
00:12:56,440 --> 00:12:59,700
the eye that had been deprived,
and a loss of stereoscopic depth

300
00:12:59,700 --> 00:13:03,570
perception that has a major
impact on the child's life.

301
00:13:03,570 --> 00:13:07,570
Now, there is a treatment
for this type of disease,

302
00:13:07,570 --> 00:13:09,430
it's called patch therapy.

303
00:13:09,430 --> 00:13:11,975
It was introduced well
over 100 years ago

304
00:13:11,975 --> 00:13:13,350
and is still the
medical standard

305
00:13:13,350 --> 00:13:16,720
of care, which is something of
an embarrassment, I would say.

306
00:13:16,720 --> 00:13:19,600
But patch therapy can work.

307
00:13:19,600 --> 00:13:21,580
So the patching occurs
in the other eye,

308
00:13:21,580 --> 00:13:23,880
which we call the fellow
eye, and it forces vision

309
00:13:23,880 --> 00:13:27,360
through the eye that
had been deprived.

310
00:13:27,360 --> 00:13:29,820
The limitation of patch
therapy is that it only

311
00:13:29,820 --> 00:13:31,330
works very early in life.

312
00:13:31,330 --> 00:13:34,580
In this case, on
the left in humans,

313
00:13:34,580 --> 00:13:36,800
if the patching is not
done before the age

314
00:13:36,800 --> 00:13:40,710
of four months of age, then
there is no recovery of vision.

315
00:13:40,710 --> 00:13:43,610
So if the cataract was not
detected early enough in life

316
00:13:43,610 --> 00:13:47,360
or-- and corrected, this is
really a very poor prognosis

317
00:13:47,360 --> 00:13:48,690
for that child.

318
00:13:48,690 --> 00:13:52,140
We've been modeling this for
over 50 years in animal studies,

319
00:13:52,140 --> 00:13:55,410
and that's what's shown on the
right is just a similar story.

320
00:13:55,410 --> 00:13:59,870
This is a cat model of
deprivation amblyopia as well.

321
00:13:59,870 --> 00:14:02,540
So I didn't mention, but
the cause of amblyopia

322
00:14:02,540 --> 00:14:04,670
is an impaired
synaptic development

323
00:14:04,670 --> 00:14:07,260
in a part of the brain
called visual cortex.

324
00:14:07,260 --> 00:14:11,390
So what we'd like
to do is to harness

325
00:14:11,390 --> 00:14:15,050
the principles of experience
dependent synaptic plasticity

326
00:14:15,050 --> 00:14:17,400
to promote recovery
of brain function,

327
00:14:17,400 --> 00:14:19,610
particularly in adults.

328
00:14:19,610 --> 00:14:22,940
So over, again, the last
half century or so, we've

329
00:14:22,940 --> 00:14:25,940
learned a tremendous
amount about the mechanisms

330
00:14:25,940 --> 00:14:28,640
of synaptic
plasticity, plasticity

331
00:14:28,640 --> 00:14:31,580
at excitatory
synapses in the brain.

332
00:14:31,580 --> 00:14:35,570
We know that synapses are
bidirectionally modifiable.

333
00:14:35,570 --> 00:14:38,630
And one of the critical
triggers for this plasticity

334
00:14:38,630 --> 00:14:42,860
is a neurotransmitter--
whoops, can I go back one?

335
00:14:42,860 --> 00:14:46,950
A neurotransmitter receptor
called an NMDA receptor.

336
00:14:46,950 --> 00:14:50,450
And what we've learned is that
activation of NMDA receptors

337
00:14:50,450 --> 00:14:52,850
can trigger both
synaptic depression

338
00:14:52,850 --> 00:14:54,810
and synaptic potentiation.

339
00:14:54,810 --> 00:14:56,660
And the critical
variable is the level

340
00:14:56,660 --> 00:15:00,170
of postsynaptic response at the
same time those receptors are

341
00:15:00,170 --> 00:15:01,170
activated.

342
00:15:01,170 --> 00:15:03,560
And so what you see on
the right is a function

343
00:15:03,560 --> 00:15:08,840
where we can map the
consequences of NMDA receptor

344
00:15:08,840 --> 00:15:12,270
activation depending on the
level of postsynaptic response.

345
00:15:12,270 --> 00:15:14,870
So there's a critical site here.

346
00:15:14,870 --> 00:15:17,120
Again, go back please.

347
00:15:17,120 --> 00:15:19,490
My laser pointer doesn't work.

348
00:15:19,490 --> 00:15:22,100
One forward.

349
00:15:22,100 --> 00:15:23,450
Thank you.

350
00:15:23,450 --> 00:15:27,140
So you can see strong NMDA
receptor activation can yield

351
00:15:27,140 --> 00:15:30,910
a synaptic potentiation and weak
NMDA receptor activation yields

352
00:15:30,910 --> 00:15:32,360
synaptic depression.

353
00:15:32,360 --> 00:15:35,330
So what is controlling
this postsynaptic response?

354
00:15:35,330 --> 00:15:37,030
Well, obviously, it's
how many synapses

355
00:15:37,030 --> 00:15:39,070
are active at the
same time and what

356
00:15:39,070 --> 00:15:41,410
the strength of those
synapses is, and also,

357
00:15:41,410 --> 00:15:43,490
the concurrent level of
inhibition in the brain.

358
00:15:43,490 --> 00:15:45,280
So we'd like to
understand how we

359
00:15:45,280 --> 00:15:47,890
can promote the
conditions that will

360
00:15:47,890 --> 00:15:51,940
lead to synaptic strengthening.

361
00:15:51,940 --> 00:15:54,550
So a lot of our
work was influenced

362
00:15:54,550 --> 00:15:56,830
by a theory of
synaptic plasticity

363
00:15:56,830 --> 00:15:59,830
that was introduced
by Leon Cooper.

364
00:15:59,830 --> 00:16:02,930
Leon was a mentor, friend,
and colleague of mine.

365
00:16:02,930 --> 00:16:05,890
Sadly, he died just
a few weeks ago.

366
00:16:05,890 --> 00:16:07,970
He's a very famous physicist.

367
00:16:07,970 --> 00:16:11,180
He won the Nobel Prize for a
theory of superconductivity.

368
00:16:11,180 --> 00:16:13,690
But after that, he
went on to become

369
00:16:13,690 --> 00:16:16,730
interested in synaptic
plasticity in the brain.

370
00:16:16,730 --> 00:16:20,480
And he developed a theory that
is now called the BCM theory,

371
00:16:20,480 --> 00:16:22,310
or Bienenstock, Cooper,
and Monroe theory.

372
00:16:22,310 --> 00:16:23,960
It's a very simple idea.

373
00:16:23,960 --> 00:16:26,770
And what he proposed is
that the synaptic strength

374
00:16:26,770 --> 00:16:30,910
varies as a function of the
product of the input activity

375
00:16:30,910 --> 00:16:34,130
and a concurrent level
of postsynaptic response,

376
00:16:34,130 --> 00:16:37,100
some function of the concurrent
level of postsynaptic response.

377
00:16:37,100 --> 00:16:39,287
And that function is
shown here in the middle,

378
00:16:39,287 --> 00:16:40,870
and it should bear
a close resemblance

379
00:16:40,870 --> 00:16:41,953
to what I just showed you.

380
00:16:41,953 --> 00:16:44,440
In fact, Leon's theory
inspired the experiments

381
00:16:44,440 --> 00:16:47,050
that revealed the properties
of bidirectional synaptic

382
00:16:47,050 --> 00:16:48,620
plasticity in the brain.

383
00:16:48,620 --> 00:16:50,950
A critical variable
in Leon's theory

384
00:16:50,950 --> 00:16:53,680
was that crossover point
between synaptic depression

385
00:16:53,680 --> 00:16:56,180
and potentiation doesn't
have a fixed value.

386
00:16:56,180 --> 00:16:58,720
But rather, it's free to
slide back and forth depending

387
00:16:58,720 --> 00:17:00,560
on the average
activity of the cell.

388
00:17:00,560 --> 00:17:02,950
So in other words, the
rules of synaptic plasticity

389
00:17:02,950 --> 00:17:05,230
are themselves plastic,
and that's a property

390
00:17:05,230 --> 00:17:07,339
we now call metaplasticity.

391
00:17:07,339 --> 00:17:10,000
So the question is, can
we slide that threshold

392
00:17:10,000 --> 00:17:12,760
to the left to promote
synaptic potentiation

393
00:17:12,760 --> 00:17:14,450
and allow recovery of function?

394
00:17:14,450 --> 00:17:15,105
Next slide.

395
00:17:15,105 --> 00:17:17,633

396
00:17:17,633 --> 00:17:18,550
I guess I can do that.

397
00:17:18,550 --> 00:17:21,550
OK, so the way we
addressed this was

398
00:17:21,550 --> 00:17:23,950
to take advantage
of a neurotoxin that

399
00:17:23,950 --> 00:17:26,680
is derived from Puffer fish.

400
00:17:26,680 --> 00:17:29,800
If you've ever had fugu,
it's a delicacy in Japan.

401
00:17:29,800 --> 00:17:32,740
It's a type of sushi that is
prepared from Puffer fish,

402
00:17:32,740 --> 00:17:34,440
but it can be quite dangerous.

403
00:17:34,440 --> 00:17:38,460
Because in the liver and ovaries
of pufferfish is a lethal toxin

404
00:17:38,460 --> 00:17:39,760
called tetrodotoxin.

405
00:17:39,760 --> 00:17:42,570
The reason it's lethal is
because it blocks all action

406
00:17:42,570 --> 00:17:43,240
potentials.

407
00:17:43,240 --> 00:17:45,010
It blocks all nerve impulses.

408
00:17:45,010 --> 00:17:49,200
It can be used in experiments
to block electrical activity

409
00:17:49,200 --> 00:17:50,170
in the brain.

410
00:17:50,170 --> 00:17:52,140
So the experiment
that we conceived

411
00:17:52,140 --> 00:17:57,360
was to inject tetrodotoxin
into the eyes of an animal that

412
00:17:57,360 --> 00:18:00,840
had been rendered
amblyopic, shut off

413
00:18:00,840 --> 00:18:03,520
the activity of
the visual system,

414
00:18:03,520 --> 00:18:05,920
allow that threshold
to slide to the left,

415
00:18:05,920 --> 00:18:11,280
and then restore vision and ask,
do the synapses regain strength?

416
00:18:11,280 --> 00:18:13,750
And I wouldn't be telling
you this if it didn't work,

417
00:18:13,750 --> 00:18:15,670
and the results were
really quite dramatic.

418
00:18:15,670 --> 00:18:18,300
So this is experiments
that were done

419
00:18:18,300 --> 00:18:20,080
in a cat model of amblyopia.

420
00:18:20,080 --> 00:18:23,830
We've done the same
thing in mice as well.

421
00:18:23,830 --> 00:18:27,810
And the graph on the left
here shows the acuity

422
00:18:27,810 --> 00:18:30,690
of either the
amblyopic eye in blue

423
00:18:30,690 --> 00:18:33,250
or the fellow eye,
the good eye in green.

424
00:18:33,250 --> 00:18:37,050
And so this animal had been
deprived of vision in one eye,

425
00:18:37,050 --> 00:18:39,060
in the amblyopic eye
for a period of time.

426
00:18:39,060 --> 00:18:40,420
That eye was opened.

427
00:18:40,420 --> 00:18:42,610
There's no spontaneous
recovery of vision,

428
00:18:42,610 --> 00:18:44,440
just as the case in the humans.

429
00:18:44,440 --> 00:18:47,970
But at the time indicated with
the ttx and the downward going

430
00:18:47,970 --> 00:18:51,940
arrows, this drug was
injected into the eyes.

431
00:18:51,940 --> 00:18:54,630
And then, of course, that
shut off all the activity

432
00:18:54,630 --> 00:18:56,080
in the fellow eye.

433
00:18:56,080 --> 00:18:59,290
But now, we wait and
watch what happens.

434
00:18:59,290 --> 00:19:02,040
So when the ttx wears off,
the fellow eye response

435
00:19:02,040 --> 00:19:03,250
returns to normal.

436
00:19:03,250 --> 00:19:07,650
But amazingly, the amblyopic
eye response comes bounding back

437
00:19:07,650 --> 00:19:09,240
and goes right up
to a value that's

438
00:19:09,240 --> 00:19:10,500
comparable to the fellow eye.

439
00:19:10,500 --> 00:19:13,630
So a complete
reversal of amblyopia.

440
00:19:13,630 --> 00:19:17,610
And this experiment was done at
an age when traditional therapy

441
00:19:17,610 --> 00:19:18,940
is no longer effective.

442
00:19:18,940 --> 00:19:20,790
So that's what's shown
on the right side

443
00:19:20,790 --> 00:19:24,310
here, that downward going
arrow, that this is occurring

444
00:19:24,310 --> 00:19:25,990
at about 14 weeks
of age, which is

445
00:19:25,990 --> 00:19:29,355
well beyond that sensitive
period when patch therapy works.

446
00:19:29,355 --> 00:19:31,960

447
00:19:31,960 --> 00:19:35,240
So we were very excited
by these results.

448
00:19:35,240 --> 00:19:38,270
It seemed it was a
theoretically inspired study.

449
00:19:38,270 --> 00:19:40,190
But it really was
based on an assumption.

450
00:19:40,190 --> 00:19:43,150
And the assumption was is
that ttx actually shuts off

451
00:19:43,150 --> 00:19:45,490
activity in the visual system.

452
00:19:45,490 --> 00:19:48,280
However, more
recently, we discovered

453
00:19:48,280 --> 00:19:50,930
that if we can shut off
activity in the retinas,

454
00:19:50,930 --> 00:19:53,500
that the relay nucleus
that brings information

455
00:19:53,500 --> 00:19:57,020
from retinas to cortex
is not quieted at all.

456
00:19:57,020 --> 00:19:59,740
In fact, the activity in
that relay nucleus, which

457
00:19:59,740 --> 00:20:02,260
is called the lateral
geniculate nucleus,

458
00:20:02,260 --> 00:20:06,380
that activity starts to fire off
in bursts, spontaneous bursts,

459
00:20:06,380 --> 00:20:08,330
high frequency
bursting activity.

460
00:20:08,330 --> 00:20:11,620
And that bursting activity
occurs both in the neurons

461
00:20:11,620 --> 00:20:15,070
that are postsynaptic
to the inactivated eye

462
00:20:15,070 --> 00:20:16,640
and to the other eye as well.

463
00:20:16,640 --> 00:20:19,210
So it's a qualitative change
in the type of activity

464
00:20:19,210 --> 00:20:20,850
that's going to the cortex.

465
00:20:20,850 --> 00:20:22,780
So the question then
became was, geez,

466
00:20:22,780 --> 00:20:26,400
are these bursts really
required for this recovery?

467
00:20:26,400 --> 00:20:31,230
So I have a wonderful graduate
student, Matty [INAUDIBLE],

468
00:20:31,230 --> 00:20:34,320
who tested this by
knocking out the gene that

469
00:20:34,320 --> 00:20:37,680
was responsible for
this bursting activity

470
00:20:37,680 --> 00:20:39,160
in the lateral
geniculate nucleus.

471
00:20:39,160 --> 00:20:40,600
You can eliminate bursting.

472
00:20:40,600 --> 00:20:42,960
And when she did so, she
eliminated the recovery

473
00:20:42,960 --> 00:20:45,250
that was caused by
the ttx injection.

474
00:20:45,250 --> 00:20:47,280
So we have to
really rethink what

475
00:20:47,280 --> 00:20:49,900
the mechanism for
this recovery is.

476
00:20:49,900 --> 00:20:52,150
And I don't have a
good answer for you.

477
00:20:52,150 --> 00:20:55,980
But what we do know is that
the bursting activity sets up

478
00:20:55,980 --> 00:20:58,650
a pattern of very highly
synchronous activity

479
00:20:58,650 --> 00:21:03,100
in the brain and also impairs
inhibition in the cortex.

480
00:21:03,100 --> 00:21:06,190
So we think we've achieved
what we hoped to achieve,

481
00:21:06,190 --> 00:21:08,800
not by sliding the
threshold necessarily,

482
00:21:08,800 --> 00:21:12,790
but by evoking a stronger
postsynaptic response.

483
00:21:12,790 --> 00:21:14,580
So the mechanism is
still, obviously,

484
00:21:14,580 --> 00:21:17,035
under intensive
investigation in the lab.

485
00:21:17,035 --> 00:21:18,410
But we can already
start to think

486
00:21:18,410 --> 00:21:22,520
about how we might apply this
in a therapeutic setting.

487
00:21:22,520 --> 00:21:27,020
So the next step for us was
to go to a primate model

488
00:21:27,020 --> 00:21:29,730
of deprivation amblyopia.

489
00:21:29,730 --> 00:21:31,550
So we've repeated
these experiments now

490
00:21:31,550 --> 00:21:35,210
in monkeys that were rendered
amblyopic by early life

491
00:21:35,210 --> 00:21:36,660
monocular deprivation.

492
00:21:36,660 --> 00:21:39,180
And the results are,
again, very dramatic.

493
00:21:39,180 --> 00:21:41,870
So we can get a very
substantial improvement

494
00:21:41,870 --> 00:21:46,400
in the electrophysiological
measure of visual function

495
00:21:46,400 --> 00:21:48,230
in monkeys.

496
00:21:48,230 --> 00:21:50,570
But this also-- there's been--

497
00:21:50,570 --> 00:21:54,200
nature has provided this
experiment in humans as well.

498
00:21:54,200 --> 00:21:59,450
There are amblyopic humans
that, unfortunately,

499
00:21:59,450 --> 00:22:03,000
have suffered damage to their
fellow eye in adulthood.

500
00:22:03,000 --> 00:22:05,780
So they have relied on
their fellow eye for vision

501
00:22:05,780 --> 00:22:06,960
for their whole life.

502
00:22:06,960 --> 00:22:09,390
But then, because of
injury or disease,

503
00:22:09,390 --> 00:22:12,710
the fellow eye has to be
removed or is otherwise

504
00:22:12,710 --> 00:22:14,990
incapable of supporting vision.

505
00:22:14,990 --> 00:22:17,990
And what's observed is
that, in many cases,

506
00:22:17,990 --> 00:22:21,710
there is an unexpected recovery
of vision in the amblyopic eye.

507
00:22:21,710 --> 00:22:25,910
So this means that plasticity
is there in our brains.

508
00:22:25,910 --> 00:22:29,360
We just need to find a
way to tap into that.

509
00:22:29,360 --> 00:22:33,010
Now, losing the fellow eye
is not a therapeutic strategy

510
00:22:33,010 --> 00:22:35,090
to promote recovery
from amblyopia.

511
00:22:35,090 --> 00:22:39,130
But what is is temporarily
inactivating that fellow eye

512
00:22:39,130 --> 00:22:41,900
and, essentially, rebooting
the visual system.

513
00:22:41,900 --> 00:22:44,890
So we think this is an
exciting future ahead.

514
00:22:44,890 --> 00:22:46,800
And with that,
thank you very much.

515
00:22:46,800 --> 00:22:48,910
[APPLAUSE]

516
00:22:48,910 --> 00:22:50,715
Our next speaker
is Josh McDermott.

517
00:22:50,715 --> 00:22:54,988
[APPLAUSE]

518
00:22:54,988 --> 00:23:00,280

519
00:23:00,280 --> 00:23:02,590
Greetings, everyone.

520
00:23:02,590 --> 00:23:05,020
All right, so we
rely on our senses

521
00:23:05,020 --> 00:23:06,950
to perceive the world around us.

522
00:23:06,950 --> 00:23:10,730
But as Mark just told you,
our senses are fragile.

523
00:23:10,730 --> 00:23:13,040
So in fact, over
39 million people

524
00:23:13,040 --> 00:23:15,650
worldwide are blind and
over 70 million people

525
00:23:15,650 --> 00:23:16,537
worldwide are deaf.

526
00:23:16,537 --> 00:23:18,620
And we would love to be
able to restore the senses

527
00:23:18,620 --> 00:23:19,555
in these individuals.

528
00:23:19,555 --> 00:23:21,680
Now, certainly, the treatments
for these conditions

529
00:23:21,680 --> 00:23:23,390
have improved over
time, but we're

530
00:23:23,390 --> 00:23:27,128
far from being able to fully
restore sight and hearing.

531
00:23:27,128 --> 00:23:28,670
All right, so the
first thing you all

532
00:23:28,670 --> 00:23:30,890
need to all have
receptors in your ears

533
00:23:30,890 --> 00:23:33,860
called hair cells that are
responsible for turning sound

534
00:23:33,860 --> 00:23:36,450
into electrical signals,
and they're shown here.

535
00:23:36,450 --> 00:23:38,660
So they sit on top of
a membrane in your ear

536
00:23:38,660 --> 00:23:40,770
that vibrates in
response to sound.

537
00:23:40,770 --> 00:23:44,430
And the hairs on the cells
get bent when they move around

538
00:23:44,430 --> 00:23:47,570
and that causes changes in
their membrane potential.

539
00:23:47,570 --> 00:23:49,340
And those signals are
sent to your brain

540
00:23:49,340 --> 00:23:51,540
via the auditory nerve
that's shown there.

541
00:23:51,540 --> 00:23:55,940
Now, deafness is typically
caused by hair cell dysfunction.

542
00:23:55,940 --> 00:23:58,490
All right, the second
thing you need to know

543
00:23:58,490 --> 00:24:00,310
is that, in the last
five years, there

544
00:24:00,310 --> 00:24:02,150
have been huge
advances in our ability

545
00:24:02,150 --> 00:24:04,305
to build computer models
of sensory systems.

546
00:24:04,305 --> 00:24:05,930
And this has been
really largely driven

547
00:24:05,930 --> 00:24:08,008
by progress in artificial
neural networks.

548
00:24:08,008 --> 00:24:09,800
So when we do this in
our lab, we typically

549
00:24:09,800 --> 00:24:11,850
start with a model
of the ear that's

550
00:24:11,850 --> 00:24:14,170
rooted in everything that
we know from biology.

551
00:24:14,170 --> 00:24:16,950
And then, we put on top of that
an artificial neural network

552
00:24:16,950 --> 00:24:18,780
that gets optimized
to do different kinds

553
00:24:18,780 --> 00:24:21,990
of auditory tasks, like
recognizing words or localizing

554
00:24:21,990 --> 00:24:22,870
sounds.

555
00:24:22,870 --> 00:24:25,200
And what this long stream
of fantastic students

556
00:24:25,200 --> 00:24:27,210
has shown over and
over again is that when

557
00:24:27,210 --> 00:24:30,510
you build models in this way,
they reproduce human behavior

558
00:24:30,510 --> 00:24:33,930
to a pretty remarkable extent
across many different domains.

559
00:24:33,930 --> 00:24:35,790
And this has really
transformed our ability

560
00:24:35,790 --> 00:24:38,160
to understand and
study perception.

561
00:24:38,160 --> 00:24:42,030
So our goal now is to use these
models to understand and improve

562
00:24:42,030 --> 00:24:43,932
bionic ears and eyes.

563
00:24:43,932 --> 00:24:45,640
So our lab study is
the sense of hearing,

564
00:24:45,640 --> 00:24:47,170
so we're focused on bionic ears.

565
00:24:47,170 --> 00:24:48,545
But we think many
of the insights

566
00:24:48,545 --> 00:24:51,510
will be equally
relevant to vision.

567
00:24:51,510 --> 00:24:54,430
So the cochlear implant
is a bionic ear.

568
00:24:54,430 --> 00:24:57,580
It aims to cause hearing
via electrical stimulation.

569
00:24:57,580 --> 00:25:00,180
And it is the primary treatment
for deafness at present.

570
00:25:00,180 --> 00:25:04,140
There are over a million of
these devices in use worldwide.

571
00:25:04,140 --> 00:25:06,390
So the way this works
is there's a microphone

572
00:25:06,390 --> 00:25:09,210
outside the head and that--

573
00:25:09,210 --> 00:25:10,770
the sound signal
that gets recorded

574
00:25:10,770 --> 00:25:12,610
gets turned into
electrical signals,

575
00:25:12,610 --> 00:25:15,735
and those are sent down that
wire that goes into the cochlea

576
00:25:15,735 --> 00:25:17,610
and wraps around in that
spiral, and the wire

577
00:25:17,610 --> 00:25:19,330
has got a bunch of
electrodes on it.

578
00:25:19,330 --> 00:25:23,460
And so the key concept is
that if you have hair cell

579
00:25:23,460 --> 00:25:25,060
dysfunction that
causes deafness,

580
00:25:25,060 --> 00:25:27,840
but if the auditory nerve
that would normally convey

581
00:25:27,840 --> 00:25:30,340
signals from the hair cells to
your brain, if that's intact,

582
00:25:30,340 --> 00:25:32,290
then that can be
electrically stimulated

583
00:25:32,290 --> 00:25:34,123
and that should cause
you to hear something.

584
00:25:34,123 --> 00:25:36,760
So you bypass the hair cells to
create the sensation of sound.

585
00:25:36,760 --> 00:25:39,960
So ideally, the
electrical stimulation

586
00:25:39,960 --> 00:25:42,930
would replicate the nerve
patterns of activity

587
00:25:42,930 --> 00:25:46,232
that would normally happen
from hearing electrically.

588
00:25:46,232 --> 00:25:47,440
But that's really hard to do.

589
00:25:47,440 --> 00:25:50,170
And so although these devices
are in some sense miraculous,

590
00:25:50,170 --> 00:25:52,980
they're still not close to
restoring normal hearing.

591
00:25:52,980 --> 00:25:55,690
And so one example of
that is shown here.

592
00:25:55,690 --> 00:25:58,270
So I'll show you a number of
graphs that will look like this.

593
00:25:58,270 --> 00:26:01,350
So this graph plots how well
people can recognize speech

594
00:26:01,350 --> 00:26:01,900
in noise.

595
00:26:01,900 --> 00:26:04,960
So the y-axis is word
recognition accuracy,

596
00:26:04,960 --> 00:26:07,700
and the x-axis is the
signal to noise ratio.

597
00:26:07,700 --> 00:26:09,520
So as you move to
the right, the speech

598
00:26:09,520 --> 00:26:11,140
gets louder relative
to the noise

599
00:26:11,140 --> 00:26:12,980
and it gets easier to recognize.

600
00:26:12,980 --> 00:26:15,910
So the black curve shows how
well people with normal hearing

601
00:26:15,910 --> 00:26:17,380
can recognize words.

602
00:26:17,380 --> 00:26:20,810
And when the speech is loud
enough, they're at ceiling.

603
00:26:20,810 --> 00:26:22,870
The red curve shows
what happens in humans

604
00:26:22,870 --> 00:26:24,380
that have cochlear implants.

605
00:26:24,380 --> 00:26:28,163
OK, so on the one hand, the fact
that they can score about 60%

606
00:26:28,163 --> 00:26:30,580
correct is amazing because
these are individuals who would

607
00:26:30,580 --> 00:26:31,815
otherwise be completely deaf.

608
00:26:31,815 --> 00:26:33,190
But you can also
see that there's

609
00:26:33,190 --> 00:26:35,440
a large gap between the red
curve and the black curve,

610
00:26:35,440 --> 00:26:38,200
and that's what we'd
really like to close.

611
00:26:38,200 --> 00:26:40,550
All right, so what limits
outcomes with these devices?

612
00:26:40,550 --> 00:26:42,610
Well, there's at least
three potential factors

613
00:26:42,610 --> 00:26:43,485
that we know of.

614
00:26:43,485 --> 00:26:45,610
One is that the device
strategies are almost surely

615
00:26:45,610 --> 00:26:46,840
suboptimal.

616
00:26:46,840 --> 00:26:49,340
Another is that if you
undergo a period of deafness,

617
00:26:49,340 --> 00:26:51,700
the neurons in your
auditory system die.

618
00:26:51,700 --> 00:26:54,490
So there's neurodegeneration,
to varying extents,

619
00:26:54,490 --> 00:26:57,160
in the auditory nerve or
beyond and what we call

620
00:26:57,160 --> 00:26:58,820
the central auditory system.

621
00:26:58,820 --> 00:27:02,860
And there's also the potential
that your brain is suboptimally

622
00:27:02,860 --> 00:27:07,107
decoding the signals that
it gets from these devices.

623
00:27:07,107 --> 00:27:08,690
All right, so what
limits our research

624
00:27:08,690 --> 00:27:09,930
into understanding
these factors?

625
00:27:09,930 --> 00:27:12,222
Well, one is that we have
very limited access to what's

626
00:27:12,222 --> 00:27:14,730
actually happening in the brain
of a human implant listener.

627
00:27:14,730 --> 00:27:16,220
So it's not like you can
just look at a person

628
00:27:16,220 --> 00:27:18,230
and tell whether they
have neurodegeneration

629
00:27:18,230 --> 00:27:20,060
or tell whether their
brain is suboptimally

630
00:27:20,060 --> 00:27:21,360
decoding those signals.

631
00:27:21,360 --> 00:27:24,450
But there are two
other major obstacles.

632
00:27:24,450 --> 00:27:26,900
One is that the best
outcomes typically

633
00:27:26,900 --> 00:27:29,780
occur after somebody has lived
with an implant for a very

634
00:27:29,780 --> 00:27:31,890
extended period of
time, months to years.

635
00:27:31,890 --> 00:27:34,190
And the other issue
is that the outcomes

636
00:27:34,190 --> 00:27:35,992
are highly variable
across individuals,

637
00:27:35,992 --> 00:27:37,200
as I'll show you in a moment.

638
00:27:37,200 --> 00:27:40,010
So it's not like you can
get a new idea for a device

639
00:27:40,010 --> 00:27:43,040
and give it to one person
and then really extrapolate

640
00:27:43,040 --> 00:27:44,750
much about how it
will work in general.

641
00:27:44,750 --> 00:27:47,150
So this makes it very
challenging to experiment

642
00:27:47,150 --> 00:27:49,290
with alternative
device strategies.

643
00:27:49,290 --> 00:27:51,380
And so most of the major
implant manufacturers

644
00:27:51,380 --> 00:27:53,297
have all pretty much
been doing the same thing

645
00:27:53,297 --> 00:27:56,000
for the last 10, 20 years.

646
00:27:56,000 --> 00:27:58,130
All right, now, what
we can do nowadays

647
00:27:58,130 --> 00:28:01,670
is build very good simulations
of the nerve responses that

648
00:28:01,670 --> 00:28:03,552
would result from
a cochlear implant.

649
00:28:03,552 --> 00:28:05,510
And Anisha Banerjee is
a fantastic grad student

650
00:28:05,510 --> 00:28:07,650
in our lab who has built
one of these simulations.

651
00:28:07,650 --> 00:28:09,192
The details here
don't really matter.

652
00:28:09,192 --> 00:28:11,840
It's a computer program that
predicts the nerve responses

653
00:28:11,840 --> 00:28:13,560
from electrical stimulation.

654
00:28:13,560 --> 00:28:15,330
And so one example
is shown here.

655
00:28:15,330 --> 00:28:18,770
So the top picture shows
an example, nerve response

656
00:28:18,770 --> 00:28:19,800
from a cochlear implant.

657
00:28:19,800 --> 00:28:22,700
The different rows represent
different nerve fibers

658
00:28:22,700 --> 00:28:25,250
and the x-axis is time, OK?

659
00:28:25,250 --> 00:28:28,280
What's shown on the bottom
is an analogous simulation

660
00:28:28,280 --> 00:28:32,360
from a normal ear to the
same speech utterance.

661
00:28:32,360 --> 00:28:34,820
So the point is that the
cochlear implant is intended

662
00:28:34,820 --> 00:28:37,643
to produce nerve responses that
look like what you would get

663
00:28:37,643 --> 00:28:39,560
from the normal ear, but
you can see that they

664
00:28:39,560 --> 00:28:40,560
look really different.

665
00:28:40,560 --> 00:28:43,717
And that's probably
part of the issue.

666
00:28:43,717 --> 00:28:45,800
All right, so how can we
understand these outcomes

667
00:28:45,800 --> 00:28:48,060
with the models that
we have of the brain?

668
00:28:48,060 --> 00:28:50,420
So one other
important fact to note

669
00:28:50,420 --> 00:28:53,090
is that human implant users
improve pretty substantially

670
00:28:53,090 --> 00:28:54,060
over time.

671
00:28:54,060 --> 00:28:57,350
So this is a really cool graph
that shows word recognition

672
00:28:57,350 --> 00:29:00,500
scores as a function of
the number of months post

673
00:29:00,500 --> 00:29:01,177
activation.

674
00:29:01,177 --> 00:29:03,760
So how long someone has lived
with their device, and each line

675
00:29:03,760 --> 00:29:05,260
is a different individual.

676
00:29:05,260 --> 00:29:06,830
The different
colors don't matter.

677
00:29:06,830 --> 00:29:08,890
So you can see that
all the lines go up

678
00:29:08,890 --> 00:29:10,840
and they go up over
a period of time.

679
00:29:10,840 --> 00:29:12,435
So people are learning
to do something

680
00:29:12,435 --> 00:29:13,810
with their brains
that makes them

681
00:29:13,810 --> 00:29:16,000
better at decoding
the information they

682
00:29:16,000 --> 00:29:17,242
get from the device.

683
00:29:17,242 --> 00:29:18,700
But the other thing
to note here is

684
00:29:18,700 --> 00:29:22,023
that the asymptotic performance
is really highly variable.

685
00:29:22,023 --> 00:29:24,440
So some people end up doing
great and others much less so.

686
00:29:24,440 --> 00:29:27,100
And so what we don't know
is whether that variation is

687
00:29:27,100 --> 00:29:29,498
due to differences in
how well people can learn

688
00:29:29,498 --> 00:29:31,540
or whether, for instance,
it might be differences

689
00:29:31,540 --> 00:29:33,370
in neural degeneration
or some other factor

690
00:29:33,370 --> 00:29:34,490
that we don't know about.

691
00:29:34,490 --> 00:29:38,410
So these models that we build
using machine learning we think

692
00:29:38,410 --> 00:29:40,527
can help reveal the potential
of brain plasticity.

693
00:29:40,527 --> 00:29:42,610
So we can take these models
of the auditory system

694
00:29:42,610 --> 00:29:45,340
and build what we call a
static model of hearing

695
00:29:45,340 --> 00:29:47,140
through a cochlear
implant where you take

696
00:29:47,140 --> 00:29:48,850
a model of the normal
auditory system

697
00:29:48,850 --> 00:29:51,832
and you just give it input
from a cochlear implant.

698
00:29:51,832 --> 00:29:53,290
But we can also
build what we would

699
00:29:53,290 --> 00:29:56,650
call a plastic model, where
you completely re-optimize

700
00:29:56,650 --> 00:30:00,102
the neural network to deal with
input from a cochlear implant,

701
00:30:00,102 --> 00:30:02,560
simulating what would happen
if your brain could completely

702
00:30:02,560 --> 00:30:05,690
readapt itself to this
altered kind of input.

703
00:30:05,690 --> 00:30:09,077
We can also potentially look
at the impact of degeneration

704
00:30:09,077 --> 00:30:10,660
by looking at what
happens if you just

705
00:30:10,660 --> 00:30:13,370
delete a bunch of nerve fibers
in the input to the model

706
00:30:13,370 --> 00:30:14,660
or delete a bunch of neurons.

707
00:30:14,660 --> 00:30:16,720
All right, so what happens?

708
00:30:16,720 --> 00:30:18,560
So here's one
example of a result.

709
00:30:18,560 --> 00:30:20,170
Again, this is the
same kind of graph

710
00:30:20,170 --> 00:30:22,960
that shows word recognition
accuracy versus the signal

711
00:30:22,960 --> 00:30:24,020
to noise ratio.

712
00:30:24,020 --> 00:30:26,410
The black line shows a
model of normal hearing

713
00:30:26,410 --> 00:30:29,380
that is very similar
in its performance

714
00:30:29,380 --> 00:30:31,070
to humans with normal hearing.

715
00:30:31,070 --> 00:30:33,070
And the green
curve shows a model

716
00:30:33,070 --> 00:30:34,850
that gets input from
a cochlear implant,

717
00:30:34,850 --> 00:30:36,482
but that is fully plastic.

718
00:30:36,482 --> 00:30:38,440
So you can see that the
green curve is actually

719
00:30:38,440 --> 00:30:40,065
pretty close to the
Black curve, right?

720
00:30:40,065 --> 00:30:42,440
It's a little bit worse,
but really, pretty close.

721
00:30:42,440 --> 00:30:44,650
Now, the red curve
shows the results

722
00:30:44,650 --> 00:30:46,540
of humans that have
cochlear implants that we

723
00:30:46,540 --> 00:30:48,685
tested in our lab on the
exact same experiment.

724
00:30:48,685 --> 00:30:50,560
And you can see that
they're not doing nearly

725
00:30:50,560 --> 00:30:54,050
as well as the model of the
green curve that is, right?

726
00:30:54,050 --> 00:30:56,500
So that suggests that,
in principle, you

727
00:30:56,500 --> 00:30:58,860
could do a lot better with
the input from the implant,

728
00:30:58,860 --> 00:31:01,040
if you could fully
reoptimize your brain

729
00:31:01,040 --> 00:31:02,350
to process those signals.

730
00:31:02,350 --> 00:31:05,180

731
00:31:05,180 --> 00:31:07,770
Can we simulate the possibility
of incomplete plasticity?

732
00:31:07,770 --> 00:31:09,145
Well, one thing
we can do is just

733
00:31:09,145 --> 00:31:11,720
reoptimize some of the
parts of that neural network

734
00:31:11,720 --> 00:31:13,710
to deal with input from
the cochlear implant.

735
00:31:13,710 --> 00:31:16,170
And when you do that,
you get the blue curve,

736
00:31:16,170 --> 00:31:18,230
and that's now within
striking distance

737
00:31:18,230 --> 00:31:19,980
of what you see from humans.

738
00:31:19,980 --> 00:31:23,210
Now, by contrast, I'm
going to show you now

739
00:31:23,210 --> 00:31:28,290
what happens if you delete 50%
of the neurons in these models.

740
00:31:28,290 --> 00:31:30,120
And those are the dashed lines.

741
00:31:30,120 --> 00:31:33,210
And the effect of that is
actually remarkably modest.

742
00:31:33,210 --> 00:31:35,420
So we see huge effects of
the extent to which you

743
00:31:35,420 --> 00:31:38,690
can reoptimize your
brain for this altered

744
00:31:38,690 --> 00:31:41,280
input and really modest
effects of neurodegeneration.

745
00:31:41,280 --> 00:31:43,220
So it's consistent
with the idea that

746
00:31:43,220 --> 00:31:46,410
plasticity is a dominant
factor underlying outcomes.

747
00:31:46,410 --> 00:31:48,920
And it raises the possibility
that increasing plasticity

748
00:31:48,920 --> 00:31:50,720
in the human auditory
system, doing things

749
00:31:50,720 --> 00:31:52,640
like what Mark was
just talking about,

750
00:31:52,640 --> 00:31:55,470
could potentially
yield big benefits.

751
00:31:55,470 --> 00:31:58,020
All right, so the next steps
that we're excited about

752
00:31:58,020 --> 00:32:00,360
are to use these models
to derive new device

753
00:32:00,360 --> 00:32:02,880
strategies that could
potentially further improve

754
00:32:02,880 --> 00:32:03,790
outcomes.

755
00:32:03,790 --> 00:32:06,600
And so we think the models can
be very useful here in revealing

756
00:32:06,600 --> 00:32:09,430
the best case outcomes
for candidate devices,

757
00:32:09,430 --> 00:32:11,890
potentially enabling
large scale screening.

758
00:32:11,890 --> 00:32:13,930
So you can try out lots
of different ideas.

759
00:32:13,930 --> 00:32:15,570
And then, the most
promising options

760
00:32:15,570 --> 00:32:18,185
are things that you could
potentially explore in humans.

761
00:32:18,185 --> 00:32:19,560
So I think this
is a nice example

762
00:32:19,560 --> 00:32:21,630
of basic science
with impact where

763
00:32:21,630 --> 00:32:24,090
the models that we
build of the brain

764
00:32:24,090 --> 00:32:27,120
and refining those models
will lead to better therapies

765
00:32:27,120 --> 00:32:28,900
that we hope will help people.

766
00:32:28,900 --> 00:32:30,010
So thank you.

767
00:32:30,010 --> 00:32:33,272
[APPLAUSE]

768
00:32:33,272 --> 00:32:35,610

769
00:32:35,610 --> 00:32:38,220
And with that, it
is a great pleasure

770
00:32:38,220 --> 00:32:41,800
to introduce the world's expert
on the neural basis of language,

771
00:32:41,800 --> 00:32:43,780
my colleague, Professor
Evelina Fedorenko.

772
00:32:43,780 --> 00:32:46,450

773
00:32:46,450 --> 00:32:48,420
Thank you.

774
00:32:48,420 --> 00:32:53,880
All right, so let's
see if this works.

775
00:32:53,880 --> 00:32:56,410
So language is--
I study language,

776
00:32:56,410 --> 00:32:59,290
and language is this
incredible superpower we have.

777
00:32:59,290 --> 00:33:02,370
Using language, we can
build deep relationships

778
00:33:02,370 --> 00:33:05,320
with each other and restore
international political order.

779
00:33:05,320 --> 00:33:08,350
We can send submarines to
the bottom of the ocean,

780
00:33:08,350 --> 00:33:10,920
rockets into space,
and cure diseases.

781
00:33:10,920 --> 00:33:13,680
We can bring about
political and social change

782
00:33:13,680 --> 00:33:17,610
and record the history of
our planet and our species.

783
00:33:17,610 --> 00:33:20,920
So how do our brains achieve
this remarkable feat?

784
00:33:20,920 --> 00:33:24,010
So using studies of
patients with lesions,

785
00:33:24,010 --> 00:33:27,220
non-invasive imaging like fMRI
and intracranial recordings,

786
00:33:27,220 --> 00:33:31,618
and patients undergoing surgery
for brain tumors or epilepsy,

787
00:33:31,618 --> 00:33:33,660
we've learned that there's
a whole bunch of areas

788
00:33:33,660 --> 00:33:35,290
in your brain that
help you do this.

789
00:33:35,290 --> 00:33:38,250
And I assure you, all of these
areas are working in your brains

790
00:33:38,250 --> 00:33:40,260
as you're listening
to me right now.

791
00:33:40,260 --> 00:33:44,950
These areas look something like
this in any individual brain.

792
00:33:44,950 --> 00:33:47,850
And interestingly, they
support both comprehension

793
00:33:47,850 --> 00:33:49,090
and production.

794
00:33:49,090 --> 00:33:51,500
This makes us think that
these areas, basically,

795
00:33:51,500 --> 00:33:53,960
store our knowledge of
language, so what words mean

796
00:33:53,960 --> 00:33:55,480
and how to put words together.

797
00:33:55,480 --> 00:33:57,980
And of course, we need this
knowledge to both take a thought

798
00:33:57,980 --> 00:34:00,030
and encode it into
a word sequence,

799
00:34:00,030 --> 00:34:01,970
or process somebody
else's word sequence

800
00:34:01,970 --> 00:34:05,720
and infer the meaning
that they intended.

801
00:34:05,720 --> 00:34:09,050
What I just said should make
it clear to some of you who

802
00:34:09,050 --> 00:34:12,110
may have heard of things like
Broca's area and Wernicke's area

803
00:34:12,110 --> 00:34:13,909
that these language
areas I mentioned

804
00:34:13,909 --> 00:34:16,520
are actually different from
these areas classically

805
00:34:16,520 --> 00:34:18,480
discussed in the
neurobiology of language.

806
00:34:18,480 --> 00:34:21,440
It turns out that these Broca's
area and Wernicke's area

807
00:34:21,440 --> 00:34:22,800
are lower level areas.

808
00:34:22,800 --> 00:34:24,620
So Broca's area
is an area that's

809
00:34:24,620 --> 00:34:26,940
important for planning
speech motor movements,

810
00:34:26,940 --> 00:34:30,750
and Wernicke's area is important
for perceiving speech sounds.

811
00:34:30,750 --> 00:34:33,679
So, for example, if I now switch
to talking in a language that's

812
00:34:33,679 --> 00:34:35,719
unfamiliar to you,
your Wernicke's area

813
00:34:35,719 --> 00:34:37,280
will be working
just as hard as it's

814
00:34:37,280 --> 00:34:38,900
working right now
because it's still

815
00:34:38,900 --> 00:34:41,340
getting its preferred input,
which is speech sounds.

816
00:34:41,340 --> 00:34:43,824
But your purple areas,
your language areas,

817
00:34:43,824 --> 00:34:45,199
the activity in
them will plummet

818
00:34:45,199 --> 00:34:47,116
because you would no
longer be able to extract

819
00:34:47,116 --> 00:34:51,409
any meaningful
information from them.

820
00:34:51,409 --> 00:34:53,630
These areas, the
language areas, are also

821
00:34:53,630 --> 00:34:57,060
distinct from areas that
support thinking and reasoning,

822
00:34:57,060 --> 00:34:59,340
as my group and a few
others have shown.

823
00:34:59,340 --> 00:35:01,670
Of course, our language
system interacts closely

824
00:35:01,670 --> 00:35:04,340
with our reasoning abilities,
but nevertheless, the language

825
00:35:04,340 --> 00:35:07,530
areas are not the areas that are
doing thinking in your brain.

826
00:35:07,530 --> 00:35:09,150
And you can lose
your language system,

827
00:35:09,150 --> 00:35:11,150
as in cases of severe
aphasia, and still

828
00:35:11,150 --> 00:35:13,405
be able to think and
reason in complex ways.

829
00:35:13,405 --> 00:35:17,570

830
00:35:17,570 --> 00:35:19,170
A couple other things.

831
00:35:19,170 --> 00:35:21,710
The system seems
quite robustly similar

832
00:35:21,710 --> 00:35:23,720
across diverse languages.

833
00:35:23,720 --> 00:35:26,810
There is over 7,000 languages
spoken and signed across

834
00:35:26,810 --> 00:35:27,360
the world.

835
00:35:27,360 --> 00:35:29,370
We've tested this in
about 50 languages.

836
00:35:29,370 --> 00:35:30,470
Looks similar.

837
00:35:30,470 --> 00:35:33,590
For those of us who have
multiple language systems living

838
00:35:33,590 --> 00:35:36,150
in our brains, like bilingual
and multilingual speakers,

839
00:35:36,150 --> 00:35:40,280
they all live in that system,
and developmentally, the system

840
00:35:40,280 --> 00:35:45,350
is there and shows adult like
topography by about age three.

841
00:35:45,350 --> 00:35:47,580
Now, our focus
today is on health.

842
00:35:47,580 --> 00:35:53,230
So losing language is an
incredibly devastating

843
00:35:53,230 --> 00:35:53,930
condition.

844
00:35:53,930 --> 00:35:56,260
Not having full access to
language and development

845
00:35:56,260 --> 00:35:59,590
leads to all sorts of cognitive
delays and difficulties

846
00:35:59,590 --> 00:36:01,990
in establishing relationships
with your caretakers

847
00:36:01,990 --> 00:36:04,280
and losing language
in adulthood.

848
00:36:04,280 --> 00:36:06,380
In cases of
degeneration or stroke

849
00:36:06,380 --> 00:36:12,560
aphasia is life changing in
all sorts of horrible ways.

850
00:36:12,560 --> 00:36:16,220
So in trying to understand
language development,

851
00:36:16,220 --> 00:36:18,340
we're trying to
ask questions like,

852
00:36:18,340 --> 00:36:20,350
why is the language
system sometimes

853
00:36:20,350 --> 00:36:23,630
doesn't develop properly as,
for example, in cases of autism?

854
00:36:23,630 --> 00:36:26,330
Can we predict language
development trajectories?

855
00:36:26,330 --> 00:36:28,240
And can we intervene
in high risk cases

856
00:36:28,240 --> 00:36:30,370
to ensure that the language
system give it the best

857
00:36:30,370 --> 00:36:32,080
chance to develop typically?

858
00:36:32,080 --> 00:36:33,940
For acquired
disorders, we're asking

859
00:36:33,940 --> 00:36:36,980
questions like, in what ways
can a language system break?

860
00:36:36,980 --> 00:36:39,400
Can the language system
fix itself, to some degree,

861
00:36:39,400 --> 00:36:41,450
in cases when it
starts malfunctioning?

862
00:36:41,450 --> 00:36:44,350
And what can we do externally
to intervene on the brain

863
00:36:44,350 --> 00:36:47,570
to ensure that the language
system recovers as much as

864
00:36:47,570 --> 00:36:48,450
possible?

865
00:36:48,450 --> 00:36:51,410
So we work on both developmental
questions and questions

866
00:36:51,410 --> 00:36:53,870
of language loss in
adulthood, and I'll

867
00:36:53,870 --> 00:36:56,520
give you a glimpse of
the latter line of work.

868
00:36:56,520 --> 00:36:59,630
So this is a collaboration that
we've had going for a few years

869
00:36:59,630 --> 00:37:03,710
now with Swathi Kiran, who is at
BU leading the Center for Brain

870
00:37:03,710 --> 00:37:06,770
Recovery, and the lead junior
scientist is [INAUDIBLE], who

871
00:37:06,770 --> 00:37:09,530
is now a postdoc at Harvard.

872
00:37:09,530 --> 00:37:12,770
So understanding
recovery from aphasia

873
00:37:12,770 --> 00:37:18,540
has been going on for many
years, centuries really, now.

874
00:37:18,540 --> 00:37:21,200
So a lot of people
have focused on trying

875
00:37:21,200 --> 00:37:24,240
to understand the trajectory,
the timeline of development.

876
00:37:24,240 --> 00:37:26,360
And very consistently,
a lot of groups

877
00:37:26,360 --> 00:37:28,130
have shown that most
recovery happens

878
00:37:28,130 --> 00:37:29,550
within the first few months.

879
00:37:29,550 --> 00:37:32,060
But in many cases,
recovery does continue even

880
00:37:32,060 --> 00:37:35,930
after the first year,
although at a slower pace.

881
00:37:35,930 --> 00:37:38,900
Many other groups have
studied questions like,

882
00:37:38,900 --> 00:37:41,400
what makes some people
recover better and worse?

883
00:37:41,400 --> 00:37:45,190
And one big finding is
that the younger you are

884
00:37:45,190 --> 00:37:46,702
and the better your
brain health is

885
00:37:46,702 --> 00:37:48,910
at the time the stroke
happens, the better off you're

886
00:37:48,910 --> 00:37:49,580
going to be.

887
00:37:49,580 --> 00:37:51,790
But also, it matters
where the damage happens

888
00:37:51,790 --> 00:37:54,340
and how extensive it is.

889
00:37:54,340 --> 00:37:57,100
In our work, we've been
trying to understand

890
00:37:57,100 --> 00:38:02,870
the recovery mechanisms that
underlie recovery from aphasia.

891
00:38:02,870 --> 00:38:04,750
So to the extent that
a patient recovers,

892
00:38:04,750 --> 00:38:07,610
what's happening in the
brains of those patients?

893
00:38:07,610 --> 00:38:10,660
What are the changes that lead
to the restoration of some

894
00:38:10,660 --> 00:38:13,240
of the linguistic function?

895
00:38:13,240 --> 00:38:16,460
And there have been two big
ideas for how this might happen.

896
00:38:16,460 --> 00:38:19,490
One idea is what's
referred to as homeostasis.

897
00:38:19,490 --> 00:38:22,270
So it's basically the idea is
that you have some remaining

898
00:38:22,270 --> 00:38:24,250
parts of your language
system and they're

899
00:38:24,250 --> 00:38:27,190
trying to recover function
by somehow reorganizing

900
00:38:27,190 --> 00:38:28,940
the function among
the remaining bits.

901
00:38:28,940 --> 00:38:31,357
So you're trying to go back
as much as possible to the way

902
00:38:31,357 --> 00:38:33,670
things were before
the stroke event.

903
00:38:33,670 --> 00:38:36,350
A very different idea
is reorganization.

904
00:38:36,350 --> 00:38:38,680
So this is a more drastic
takeover of function

905
00:38:38,680 --> 00:38:41,030
by areas that weren't
doing language before,

906
00:38:41,030 --> 00:38:43,210
but are now going to
be doing language.

907
00:38:43,210 --> 00:38:46,470
And a good candidate for
this kind of takeover

908
00:38:46,470 --> 00:38:49,470
is the system that many people
call the multiple demand

909
00:38:49,470 --> 00:38:52,000
system or the executive
function system.

910
00:38:52,000 --> 00:38:54,750
It's a very cool
system you all have.

911
00:38:54,750 --> 00:38:57,180
It supports so-called
executive abilities

912
00:38:57,180 --> 00:39:00,040
like working memory,
attention, inhibitory control,

913
00:39:00,040 --> 00:39:02,220
and it's active across
many, many different kinds

914
00:39:02,220 --> 00:39:03,190
of behaviors.

915
00:39:03,190 --> 00:39:05,130
One way to think
of this system is

916
00:39:05,130 --> 00:39:07,700
it's a system that evolution
gave us to be able to adapt,

917
00:39:07,700 --> 00:39:08,200
right?

918
00:39:08,200 --> 00:39:10,742
We have all sorts of specialized
mechanisms, like for hearing

919
00:39:10,742 --> 00:39:13,080
or for vision or for
language, but we also

920
00:39:13,080 --> 00:39:15,820
have resources to be
able to deal with change.

921
00:39:15,820 --> 00:39:18,990
And this system, the idea was
that this system is flexible

922
00:39:18,990 --> 00:39:21,150
enough so that if some
specialized mechanisms get

923
00:39:21,150 --> 00:39:24,030
damaged, the system
can take over.

924
00:39:24,030 --> 00:39:25,390
Why does it matter?

925
00:39:25,390 --> 00:39:27,717
Well, if we know that it's
a language system that

926
00:39:27,717 --> 00:39:30,300
helps you recover, the remaining
parts of the language system,

927
00:39:30,300 --> 00:39:32,460
or this very
different system, we

928
00:39:32,460 --> 00:39:34,020
can intervene on these systems.

929
00:39:34,020 --> 00:39:39,030
We can either stimulate them
or do behavioral therapy that

930
00:39:39,030 --> 00:39:40,570
targets this particular system.

931
00:39:40,570 --> 00:39:43,440
So it really matters for
trying to boost the recovery

932
00:39:43,440 --> 00:39:45,310
mechanisms that are in place.

933
00:39:45,310 --> 00:39:47,580
So we tried to
evaluate these two

934
00:39:47,580 --> 00:39:51,630
ideas in a group of patients
with chronic aphasia

935
00:39:51,630 --> 00:39:53,610
and a bunch of controls.

936
00:39:53,610 --> 00:39:55,700
So what we did was record
their brain activity

937
00:39:55,700 --> 00:39:57,450
as they listened to
language to understand

938
00:39:57,450 --> 00:40:00,690
which parts of their brain
are processing language.

939
00:40:00,690 --> 00:40:02,880
And we also measured
their linguistic ability

940
00:40:02,880 --> 00:40:06,310
in all sorts of ways using
standard assessments.

941
00:40:06,310 --> 00:40:08,663
And so then, we're, basically
asking, OK, to the extent

942
00:40:08,663 --> 00:40:11,080
that these patients vary in
how good they are in language.

943
00:40:11,080 --> 00:40:13,413
What's different about how
their brains process language

944
00:40:13,413 --> 00:40:15,870
so that some are doing
better than others?

945
00:40:15,870 --> 00:40:18,372
And it turns out that
it's really homeostasis

946
00:40:18,372 --> 00:40:19,330
that's doing this work.

947
00:40:19,330 --> 00:40:21,872
So it's the same system that
was doing language in your brain

948
00:40:21,872 --> 00:40:23,490
before stroke that--

949
00:40:23,490 --> 00:40:26,520
whose ability, whose
activity is best predictive

950
00:40:26,520 --> 00:40:29,070
of how well you're
doing after a stroke.

951
00:40:29,070 --> 00:40:32,550
So now, individuals who show
most typical like patterns

952
00:40:32,550 --> 00:40:36,360
in that system are
the ones that do best.

953
00:40:36,360 --> 00:40:38,060
So what we're
doing now is trying

954
00:40:38,060 --> 00:40:39,690
to evaluate a
range of therapies,

955
00:40:39,690 --> 00:40:41,100
some based on behavior.

956
00:40:41,100 --> 00:40:43,640
So for a while, people
got really excited

957
00:40:43,640 --> 00:40:45,570
about this idea of
takeover of function.

958
00:40:45,570 --> 00:40:47,060
And a lot of
therapies got shifted

959
00:40:47,060 --> 00:40:50,800
to trying to increase general
ability, executive function

960
00:40:50,800 --> 00:40:51,300
ability.

961
00:40:51,300 --> 00:40:53,660
Let's make people
better at working memory

962
00:40:53,660 --> 00:40:55,430
or at keeping
attention in the hope

963
00:40:55,430 --> 00:40:57,930
that it helps restore
these loss functions.

964
00:40:57,930 --> 00:41:00,650
It turns out that, no, you need
to really focus on language

965
00:41:00,650 --> 00:41:02,520
and keep training the
language system up.

966
00:41:02,520 --> 00:41:05,090
We're also doing work with
electrical stimulation

967
00:41:05,090 --> 00:41:06,920
of the language
system remaining parts

968
00:41:06,920 --> 00:41:09,440
to see if it boosts recovery.

969
00:41:09,440 --> 00:41:12,380
We're also doing this very
hard thing of longitudinal

970
00:41:12,380 --> 00:41:13,820
scanning trying to--

971
00:41:13,820 --> 00:41:15,320
very little is
understood, actually,

972
00:41:15,320 --> 00:41:17,862
about the acute stage of what
happens in the first few months

973
00:41:17,862 --> 00:41:20,362
because most people don't want
to do research when they just

974
00:41:20,362 --> 00:41:21,120
suffered a stroke.

975
00:41:21,120 --> 00:41:22,495
But it's really,
really important

976
00:41:22,495 --> 00:41:25,070
to understand how things change
during those first few months

977
00:41:25,070 --> 00:41:27,110
after injury, so
we're trying that.

978
00:41:27,110 --> 00:41:28,860
And much like what
Josh was talking about,

979
00:41:28,860 --> 00:41:30,527
we're also building
computational models

980
00:41:30,527 --> 00:41:33,620
based on language models
like ChatGPT, including

981
00:41:33,620 --> 00:41:36,110
creating kind of aphasic
variants of these models

982
00:41:36,110 --> 00:41:38,450
to get a more mechanistic
level insight into how

983
00:41:38,450 --> 00:41:41,460
things can break, and
hopefully, how we can fix them.

984
00:41:41,460 --> 00:41:42,890
So thank you very much.

985
00:41:42,890 --> 00:41:46,146
[APPLAUSE]

986
00:41:46,146 --> 00:42:04,730

987
00:42:04,730 --> 00:42:05,610
Nice job.

988
00:42:05,610 --> 00:42:06,110
Thank you.

989
00:42:06,110 --> 00:42:09,110

990
00:42:09,110 --> 00:42:09,625
Empty chair.

991
00:42:09,625 --> 00:42:12,260

992
00:42:12,260 --> 00:42:15,110
It is a big chair.

993
00:42:15,110 --> 00:42:17,160
So we have time
for some questions.

994
00:42:17,160 --> 00:42:22,430
Are there any that
get it started off?

995
00:42:22,430 --> 00:42:24,260
Tony.

996
00:42:24,260 --> 00:42:25,555
Use a mic back there.

997
00:42:25,555 --> 00:42:30,440

998
00:42:30,440 --> 00:42:35,770
In animal studies,
does language have

999
00:42:35,770 --> 00:42:37,820
to exist for thinking to exist?

1000
00:42:37,820 --> 00:42:39,850
This is something you presented.

1001
00:42:39,850 --> 00:42:45,500
And I've read some studies that
say that animals actually think,

1002
00:42:45,500 --> 00:42:47,300
even if they cannot speak.

1003
00:42:47,300 --> 00:42:51,640
Is there a biological
reality to that?

1004
00:42:51,640 --> 00:42:56,890
I mean, animals certainly do
all sorts of complex cognition.

1005
00:42:56,890 --> 00:43:00,430
Whether their thinking
mechanisms are exactly the same

1006
00:43:00,430 --> 00:43:02,390
as humans, well, probably not.

1007
00:43:02,390 --> 00:43:04,480
But whether they're just
kind of-- whether humans

1008
00:43:04,480 --> 00:43:08,080
have simply bigger and better
versions of those mechanisms

1009
00:43:08,080 --> 00:43:09,873
is potentially likely.

1010
00:43:09,873 --> 00:43:11,540
And a lot of people
are working on this.

1011
00:43:11,540 --> 00:43:14,620
But Yeah, you can definitely
think without language,

1012
00:43:14,620 --> 00:43:15,560
including in animals.

1013
00:43:15,560 --> 00:43:16,060
Yeah.

1014
00:43:16,060 --> 00:43:20,090

1015
00:43:20,090 --> 00:43:20,930
Any other questions?

1016
00:43:20,930 --> 00:43:24,190

1017
00:43:24,190 --> 00:43:29,110
You mentioned something
about language development

1018
00:43:29,110 --> 00:43:30,050
with the very young.

1019
00:43:30,050 --> 00:43:33,920
And you said around three
years of age things change.

1020
00:43:33,920 --> 00:43:36,250
But previously, I've
heard a lot about much

1021
00:43:36,250 --> 00:43:40,270
later than that learning
a foreign language up

1022
00:43:40,270 --> 00:43:42,910
to age 10 or 11,
somewhere like that.

1023
00:43:42,910 --> 00:43:45,910
How do these two relate?

1024
00:43:45,910 --> 00:43:47,870
Sorry, I didn't quite
hear everything you said.

1025
00:43:47,870 --> 00:43:51,050
So how will we
learn later in life?

1026
00:43:51,050 --> 00:43:53,380
You mentioned in the
talk that around, I

1027
00:43:53,380 --> 00:43:55,930
believe it was the
age of three years,

1028
00:43:55,930 --> 00:44:01,960
that the way the language
acquisition learning was taking

1029
00:44:01,960 --> 00:44:04,730
place dropped off at that point.

1030
00:44:04,730 --> 00:44:05,920
No.

1031
00:44:05,920 --> 00:44:08,560
I was just saying that the
system I was talking about

1032
00:44:08,560 --> 00:44:10,160
is there by age three.

1033
00:44:10,160 --> 00:44:13,280
Of course, learning can
happen much later than three.

1034
00:44:13,280 --> 00:44:14,530
Yeah, it still works.

1035
00:44:14,530 --> 00:44:17,080
Because I'd heard like
10, 11 years old that--

1036
00:44:17,080 --> 00:44:19,480
Into the teenage years,
you can learn language

1037
00:44:19,480 --> 00:44:20,510
in a native like way.

1038
00:44:20,510 --> 00:44:21,010
Yeah.

1039
00:44:21,010 --> 00:44:32,110

1040
00:44:32,110 --> 00:44:34,000
I have a question.

1041
00:44:34,000 --> 00:44:37,010
In terms of the scope
of your research,

1042
00:44:37,010 --> 00:44:43,030
do you also look into
cognitive, I guess,

1043
00:44:43,030 --> 00:44:46,810
impact caused by other diseases
such as cancer entering

1044
00:44:46,810 --> 00:44:48,630
the brain, for example?

1045
00:44:48,630 --> 00:44:49,130
Thank you.

1046
00:44:49,130 --> 00:44:49,713
Good question.

1047
00:44:49,713 --> 00:44:54,700

1048
00:44:54,700 --> 00:44:57,290
I guess some of the
tools that we developed,

1049
00:44:57,290 --> 00:45:01,850
we do work with brain
cancer neurosurgeons.

1050
00:45:01,850 --> 00:45:04,960
This is not about cognition,
but our microscopy methods

1051
00:45:04,960 --> 00:45:08,057
if you can find brain tumor
cells more accurately.

1052
00:45:08,057 --> 00:45:09,640
We had a paper earlier
this year where

1053
00:45:09,640 --> 00:45:11,890
we showed that you could get
much more accurate counts

1054
00:45:11,890 --> 00:45:14,410
of aggressive brain tumor cells
with our new imaging methods

1055
00:45:14,410 --> 00:45:15,285
than with older ones.

1056
00:45:15,285 --> 00:45:17,770
So not exactly
conditioned, but the tools

1057
00:45:17,770 --> 00:45:19,040
can be definitely applied.

1058
00:45:19,040 --> 00:45:23,380
Yeah, I was more referring
to metastasis of other cancer

1059
00:45:23,380 --> 00:45:26,440
into the brain.

1060
00:45:26,440 --> 00:45:28,570
Yeah, I don't think any
of us work on that per se.

1061
00:45:28,570 --> 00:45:31,890
I mean, I'm very
generally interested

1062
00:45:31,890 --> 00:45:34,350
in what happens as people age.

1063
00:45:34,350 --> 00:45:37,740
We do a lot of work on the
consequences of hearing loss.

1064
00:45:37,740 --> 00:45:40,110
And that is also
accompanied with other kinds

1065
00:45:40,110 --> 00:45:41,970
of cognitive changes.

1066
00:45:41,970 --> 00:45:44,430
So that's one thing that's
a little bit related

1067
00:45:44,430 --> 00:45:45,430
to what you said.

1068
00:45:45,430 --> 00:45:48,210
And of course, there's things
like Alzheimer's and Parkinson's

1069
00:45:48,210 --> 00:45:49,740
that play into that as well.

1070
00:45:49,740 --> 00:45:50,300
Thank you.

1071
00:45:50,300 --> 00:45:50,800
Thank you.

1072
00:45:50,800 --> 00:45:54,000

1073
00:45:54,000 --> 00:45:58,080
So Mark, going back to your
discussion about amblyopia,

1074
00:45:58,080 --> 00:46:00,690
what's the best you
can do right now

1075
00:46:00,690 --> 00:46:03,570
for someone who has amblyopia?

1076
00:46:03,570 --> 00:46:09,900
Well, as I mentioned, patch
therapy is the standard of care.

1077
00:46:09,900 --> 00:46:12,580
The severity of amblyopia
depends on the cause.

1078
00:46:12,580 --> 00:46:15,040
So there are more benign causes.

1079
00:46:15,040 --> 00:46:16,560
More benign.

1080
00:46:16,560 --> 00:46:20,970
Less severe causes that can
be treated as late as age 8, 7

1081
00:46:20,970 --> 00:46:22,140
or 8.

1082
00:46:22,140 --> 00:46:24,370
So again, it's patch therapy.

1083
00:46:24,370 --> 00:46:26,760
But in recent years,
there's been introduction

1084
00:46:26,760 --> 00:46:30,240
of what's called dichoptic
therapy, which is using

1085
00:46:30,240 --> 00:46:32,237
binocular visual stimulation.

1086
00:46:32,237 --> 00:46:33,820
And they're getting
very good results.

1087
00:46:33,820 --> 00:46:35,850
But again, the
effects so far are

1088
00:46:35,850 --> 00:46:37,850
restricted to this early
developmental period.

1089
00:46:37,850 --> 00:46:44,550

1090
00:46:44,550 --> 00:46:46,140
Go ahead.

1091
00:46:46,140 --> 00:46:50,340
What causes a loss
of language ability

1092
00:46:50,340 --> 00:46:53,530
with age, hunting
for words, and so on?

1093
00:46:53,530 --> 00:46:58,230
And are there other ways
to recover from that?

1094
00:46:58,230 --> 00:46:59,830
That's a great question.

1095
00:46:59,830 --> 00:47:03,040
So I'm also very interested
in aging, like Josh is.

1096
00:47:03,040 --> 00:47:08,340
And we've just finished
a study looking

1097
00:47:08,340 --> 00:47:11,830
at how the language system in
the brain changes with aging.

1098
00:47:11,830 --> 00:47:15,220
And we can't find any
ways in which it changes.

1099
00:47:15,220 --> 00:47:17,460
So neurally, it
looks just as good

1100
00:47:17,460 --> 00:47:20,170
as a system in young brains.

1101
00:47:20,170 --> 00:47:22,350
It's as strongly
active, as strongly

1102
00:47:22,350 --> 00:47:24,050
lateralized to the
left hemisphere,

1103
00:47:24,050 --> 00:47:26,670
responds similarly
selective to language.

1104
00:47:26,670 --> 00:47:29,700
And so there is no
obvious changes there.

1105
00:47:29,700 --> 00:47:32,810
So I suspect a lot of the
word finding difficulties

1106
00:47:32,810 --> 00:47:34,850
that people report
with aging have

1107
00:47:34,850 --> 00:47:37,770
to do with more
general memory systems.

1108
00:47:37,770 --> 00:47:40,100
And of course, those
are very susceptible

1109
00:47:40,100 --> 00:47:42,810
to disorders like
Alzheimer's, and in general,

1110
00:47:42,810 --> 00:47:44,340
decay with healthy aging.

1111
00:47:44,340 --> 00:47:48,230
And those changes you can see
very well, even with methods

1112
00:47:48,230 --> 00:47:50,107
like non-invasive imaging.

1113
00:47:50,107 --> 00:47:51,690
I don't know if there
is more to that.

1114
00:47:51,690 --> 00:47:55,280

1115
00:47:55,280 --> 00:47:57,410
If you don't mind, I
have two questions.

1116
00:47:57,410 --> 00:47:59,310
One is, with the
cochlear implants,

1117
00:47:59,310 --> 00:48:02,030
do you find that there's more
neuroplasticity in people

1118
00:48:02,030 --> 00:48:05,000
who lost their hearing
at a later age as opposed

1119
00:48:05,000 --> 00:48:08,520
to people who never
were able to hear?

1120
00:48:08,520 --> 00:48:11,510
Do they adapt to a
cochlear implant better?

1121
00:48:11,510 --> 00:48:13,620
Yeah, it's a little
bit complicated.

1122
00:48:13,620 --> 00:48:16,730
So I mean, in general,
the best outcomes

1123
00:48:16,730 --> 00:48:21,240
happen with people who are
implanted at a very early age.

1124
00:48:21,240 --> 00:48:24,560
And one plausible
explanation for that

1125
00:48:24,560 --> 00:48:26,240
is that, in general,
the brain tends

1126
00:48:26,240 --> 00:48:30,050
to be more plastic at
younger ages, right?

1127
00:48:30,050 --> 00:48:32,360
But there are also--
there is also evidence

1128
00:48:32,360 --> 00:48:36,230
that there are benefits to
having some hearing experience.

1129
00:48:36,230 --> 00:48:40,400
And so that probably
factors in as well.

1130
00:48:40,400 --> 00:48:42,620
Yeah, that's a short answer.

1131
00:48:42,620 --> 00:48:44,720
My second question
is about language.

1132
00:48:44,720 --> 00:48:48,590
You talked about these
centers of the brain

1133
00:48:48,590 --> 00:48:53,780
are for all multi-language,
bilingual, multilingual.

1134
00:48:53,780 --> 00:48:57,210
When people lose language
and become aphasic,

1135
00:48:57,210 --> 00:48:59,700
do they always lose
all of their languages,

1136
00:48:59,700 --> 00:49:02,300
or can they lose one
of their languages

1137
00:49:02,300 --> 00:49:03,390
if they're multilingual?

1138
00:49:03,390 --> 00:49:06,300
And how does that play
into your studies?

1139
00:49:06,300 --> 00:49:07,500
That's a great question.

1140
00:49:07,500 --> 00:49:11,340
So in most cases, yes, you
lose multiple languages,

1141
00:49:11,340 --> 00:49:14,240
but there are interesting
effects where sometimes people

1142
00:49:14,240 --> 00:49:17,700
report that the language
that's not a native language,

1143
00:49:17,700 --> 00:49:19,970
you tend to preserve
a little bit better.

1144
00:49:19,970 --> 00:49:22,330
And we think we
just recently got

1145
00:49:22,330 --> 00:49:24,350
a glimpse of a possible
mechanism for that.

1146
00:49:24,350 --> 00:49:25,940
I always found this
really confusing.

1147
00:49:25,940 --> 00:49:26,660
Not making sense.

1148
00:49:26,660 --> 00:49:29,560
But one thing that we see
is that native languages

1149
00:49:29,560 --> 00:49:31,790
tend to be processed
a little more focally.

1150
00:49:31,790 --> 00:49:34,670
So they don't always
engage this whole system.

1151
00:49:34,670 --> 00:49:36,790
There is a core part
in the posterior

1152
00:49:36,790 --> 00:49:38,920
in the left temporal
cortex that seems

1153
00:49:38,920 --> 00:49:40,550
to really, really be important.

1154
00:49:40,550 --> 00:49:42,967
But for all of your later--

1155
00:49:42,967 --> 00:49:44,800
so for me, English is
a non-native language,

1156
00:49:44,800 --> 00:49:49,280
and English engages this whole
network very consistently.

1157
00:49:49,280 --> 00:49:52,490
And so if you have vocal damage
in the left temporal cortex,

1158
00:49:52,490 --> 00:49:55,160
it is more likely to wipe
out your native language,

1159
00:49:55,160 --> 00:49:57,760
and the remaining parts may
work better in the later learned

1160
00:49:57,760 --> 00:50:00,430
languages because it's just
more consistently recruited

1161
00:50:00,430 --> 00:50:01,690
in this way.

1162
00:50:01,690 --> 00:50:04,270
Fantastic.

1163
00:50:04,270 --> 00:50:05,000
Hi.

1164
00:50:05,000 --> 00:50:06,500
Thanks for sharing
your research.

1165
00:50:06,500 --> 00:50:08,260
They are fascinating.

1166
00:50:08,260 --> 00:50:11,710
I'd like to know if there
is any studies showing

1167
00:50:11,710 --> 00:50:14,030
the impacts of the use--

1168
00:50:14,030 --> 00:50:17,200
the early and frequent use
of technology, social media,

1169
00:50:17,200 --> 00:50:20,360
and generative AI by
children and teenagers

1170
00:50:20,360 --> 00:50:22,900
in core cognitive functions?

1171
00:50:22,900 --> 00:50:25,970
Because attention,
learning, memory,

1172
00:50:25,970 --> 00:50:29,710
because we've been hearing
a lot about the impacts

1173
00:50:29,710 --> 00:50:33,670
of social media and screens in
the mental health, increased

1174
00:50:33,670 --> 00:50:37,250
levels of anxiety and
eating disorders in girls,

1175
00:50:37,250 --> 00:50:39,850
but what about the
other functions?

1176
00:50:39,850 --> 00:50:43,010
Using technology can
harm in the long-term

1177
00:50:43,010 --> 00:50:47,600
our attention, language
acquisition, memory, learning.

1178
00:50:47,600 --> 00:50:50,600
Do we have any robust
evidence on that?

1179
00:50:50,600 --> 00:50:53,410
Thank you.

1180
00:50:53,410 --> 00:50:55,840
Yeah, to my knowledge,
there isn't, actually,

1181
00:50:55,840 --> 00:50:58,630
robust evidence one
way or the other.

1182
00:50:58,630 --> 00:51:02,290
I mean, there is a
literature that--

1183
00:51:02,290 --> 00:51:05,000
I mean, Ev may remember
this better than I do.

1184
00:51:05,000 --> 00:51:06,760
But there there were
a lot of studies

1185
00:51:06,760 --> 00:51:09,550
for a while showing that you
could see some advantages

1186
00:51:09,550 --> 00:51:11,770
from people that played
a lot of video games,

1187
00:51:11,770 --> 00:51:15,280
like on benefits on visual
attention, for instance.

1188
00:51:15,280 --> 00:51:18,430
And I'm not up to date on what
the current status of that is.

1189
00:51:18,430 --> 00:51:19,430
Did that stuff hold up?

1190
00:51:19,430 --> 00:51:20,138
I can't remember.

1191
00:51:20,138 --> 00:51:22,300
Yeah, and that research
program on video games

1192
00:51:22,300 --> 00:51:24,970
started because people thought
that video games are destroying

1193
00:51:24,970 --> 00:51:26,217
our children's brains.

1194
00:51:26,217 --> 00:51:28,300
And they started looking
at all sorts of functions

1195
00:51:28,300 --> 00:51:29,830
like attention, memory.

1196
00:51:29,830 --> 00:51:32,080
And it turns out everything
they looked at is actually

1197
00:51:32,080 --> 00:51:34,360
a little bit better in kids.

1198
00:51:34,360 --> 00:51:35,660
So that's where that went.

1199
00:51:35,660 --> 00:51:37,810
And yeah, I have not
heard of any research

1200
00:51:37,810 --> 00:51:41,290
other than the mental
health effects of exposure

1201
00:51:41,290 --> 00:51:43,780
to social media that it
affects attention or memory

1202
00:51:43,780 --> 00:51:46,810
in any negative way or language.

1203
00:51:46,810 --> 00:51:48,380
I still keep my kids off it.

1204
00:51:48,380 --> 00:51:51,796
[LAUGHTER]

1205
00:51:51,796 --> 00:51:54,730

1206
00:51:54,730 --> 00:51:55,240
Hi.

1207
00:51:55,240 --> 00:51:56,125
Thank you so much.

1208
00:51:56,125 --> 00:51:58,000
The brain is so amazing
because there's still

1209
00:51:58,000 --> 00:51:59,950
so much we don't know.

1210
00:51:59,950 --> 00:52:02,178
I've heard about how
people are trying to--

1211
00:52:02,178 --> 00:52:04,220
I mean, I guess all of
you guys in your own way--

1212
00:52:04,220 --> 00:52:06,740
but are trying to
map each circuit.

1213
00:52:06,740 --> 00:52:10,180
And to me, it sounds like
the kind of impossible dream

1214
00:52:10,180 --> 00:52:12,728
that we once thought mapping
the whole genome would be.

1215
00:52:12,728 --> 00:52:14,520
So do you think that's
something that we'll

1216
00:52:14,520 --> 00:52:16,562
see in any of our lifetimes?

1217
00:52:16,562 --> 00:52:19,020
I mean, just understanding how
all the different pieces fit

1218
00:52:19,020 --> 00:52:19,520
together.

1219
00:52:19,520 --> 00:52:21,670
Or is that way out there?

1220
00:52:21,670 --> 00:52:23,280
Thank you.

1221
00:52:23,280 --> 00:52:27,810
I think everybody should
take a shot at that one.

1222
00:52:27,810 --> 00:52:29,250
Go ahead.

1223
00:52:29,250 --> 00:52:32,130
Yeah, well, I think
one of the great things

1224
00:52:32,130 --> 00:52:35,110
about being here at MIT is
the technology collaborations.

1225
00:52:35,110 --> 00:52:37,750
So great engineering school,
great science school,

1226
00:52:37,750 --> 00:52:39,580
great cross-talk.

1227
00:52:39,580 --> 00:52:42,420
And the influx of everything
from nanotechnology

1228
00:52:42,420 --> 00:52:45,810
for neural interfacing to
new noninvasive strategies

1229
00:52:45,810 --> 00:52:48,720
for delivering
energy and recording

1230
00:52:48,720 --> 00:52:50,880
information from
the brain, I think

1231
00:52:50,880 --> 00:52:55,260
that's presenting a huge amount
of almost engineered serendipity

1232
00:52:55,260 --> 00:52:59,751
between different fields
that is opening up a of--

1233
00:52:59,751 --> 00:53:02,310
a bit of a Moore's law in
terms of improving our ability

1234
00:53:02,310 --> 00:53:04,450
to look at and control
brain circuits.

1235
00:53:04,450 --> 00:53:08,168
So being an engineer, maybe
it's how I think about things.

1236
00:53:08,168 --> 00:53:09,960
But I think being at
MIT, you're surrounded

1237
00:53:09,960 --> 00:53:13,170
by people who are always asking
for what the next big problem is

1238
00:53:13,170 --> 00:53:14,170
that they could work on.

1239
00:53:14,170 --> 00:53:15,850
And they may have
revolutionized one field,

1240
00:53:15,850 --> 00:53:17,230
and they're looking for
the next big challenge.

1241
00:53:17,230 --> 00:53:18,813
And for many people,
that's the brain.

1242
00:53:18,813 --> 00:53:21,930

1243
00:53:21,930 --> 00:53:23,060
Mark, any thoughts?

1244
00:53:23,060 --> 00:53:26,010

1245
00:53:26,010 --> 00:53:26,690
No thoughts.

1246
00:53:26,690 --> 00:53:28,250
[LAUGHTER]

1247
00:53:28,250 --> 00:53:28,750
No.

1248
00:53:28,750 --> 00:53:31,390
I mean, I think there's
value in simplification.

1249
00:53:31,390 --> 00:53:33,940
I'm a lumper, not a splitter.

1250
00:53:33,940 --> 00:53:38,190
And looking for
general principles

1251
00:53:38,190 --> 00:53:43,140
seems to me a lost art that
needs to be reinvigorated

1252
00:53:43,140 --> 00:53:46,350
and I hope to see that continue.

1253
00:53:46,350 --> 00:53:48,670
Yes, I think, I mean, one
thing I would say is--

1254
00:53:48,670 --> 00:53:50,400
I mean, I don't
know how realistic

1255
00:53:50,400 --> 00:53:52,080
it is to think that
we will actually

1256
00:53:52,080 --> 00:53:56,350
understand the human brain
fully at the circuit level.

1257
00:53:56,350 --> 00:53:58,155
And I'm not sure that
we will necessarily

1258
00:53:58,155 --> 00:54:00,280
need to for a lot of the
things that we want to do.

1259
00:54:00,280 --> 00:54:05,338
So for instance, if we end up
really understanding learning,

1260
00:54:05,338 --> 00:54:07,380
and if learning is the
key to a lot of the things

1261
00:54:07,380 --> 00:54:10,755
that we want to do, then
that may be sufficient.

1262
00:54:10,755 --> 00:54:12,380
And having really
detailed explanations

1263
00:54:12,380 --> 00:54:14,360
of what happens at the
circuit level, I mean,

1264
00:54:14,360 --> 00:54:17,810
may or may not be critical for
what we actually want to do.

1265
00:54:17,810 --> 00:54:20,060
So I think there will be
examples where we have really

1266
00:54:20,060 --> 00:54:21,450
circuit level
explanations for things,

1267
00:54:21,450 --> 00:54:22,730
but I'm not sure
that will generally

1268
00:54:22,730 --> 00:54:24,772
be the case for the human
brain just because it's

1269
00:54:24,772 --> 00:54:26,016
so big and so complicated.

1270
00:54:26,016 --> 00:54:33,290

1271
00:54:33,290 --> 00:54:35,480
Hello.

1272
00:54:35,480 --> 00:54:37,620
I'm from bioengineering
department,

1273
00:54:37,620 --> 00:54:42,290
and we do run the clinical trial
with the long COVID participants

1274
00:54:42,290 --> 00:54:44,010
and chronic Lyme participants.

1275
00:54:44,010 --> 00:54:47,270
And I've been always very
fascinated about the patients

1276
00:54:47,270 --> 00:54:50,000
complain about their
brain fog symptoms

1277
00:54:50,000 --> 00:54:52,650
as number one major
symptom complaints.

1278
00:54:52,650 --> 00:54:53,880
And that's why I'm here.

1279
00:54:53,880 --> 00:54:56,930
And I got very fascinated
with the language aphasia

1280
00:54:56,930 --> 00:54:57,900
presentation.

1281
00:54:57,900 --> 00:54:58,860
Thank you so much.

1282
00:54:58,860 --> 00:55:02,270
And I would love to-- because I
don't have much basic knowledge

1283
00:55:02,270 --> 00:55:03,450
in the brain science.

1284
00:55:03,450 --> 00:55:06,350
But I want to ask this
question for my patients

1285
00:55:06,350 --> 00:55:10,190
actually here that this is
all new symptoms in terms

1286
00:55:10,190 --> 00:55:12,780
of being lost in the
middle of the speech

1287
00:55:12,780 --> 00:55:14,780
when they're trying
to engage interaction

1288
00:55:14,780 --> 00:55:16,520
with the summoning conversation.

1289
00:55:16,520 --> 00:55:20,540
And the way they describe
brain fog and cognitive deficit

1290
00:55:20,540 --> 00:55:24,990
is oftentimes related to their
language of difficulties.

1291
00:55:24,990 --> 00:55:27,410
And I would love to
know your insight

1292
00:55:27,410 --> 00:55:31,860
in terms of the brain function
associated with the infection

1293
00:55:31,860 --> 00:55:34,460
triggers or source.

1294
00:55:34,460 --> 00:55:37,040
Not so much a stroke
issue, but perhaps,

1295
00:55:37,040 --> 00:55:39,540
what are the insights with
the infection triggers?

1296
00:55:39,540 --> 00:55:43,010
And can this kind of a brain
fog complaints description

1297
00:55:43,010 --> 00:55:45,200
of language difficulty
be something

1298
00:55:45,200 --> 00:55:48,300
to look at in the case of
Wernicke's or Broca's area,

1299
00:55:48,300 --> 00:55:50,720
or what are the insights
that we can look further

1300
00:55:50,720 --> 00:55:52,242
to expand our research?

1301
00:55:52,242 --> 00:55:53,700
I would love to
hear your feedback.

1302
00:55:53,700 --> 00:55:54,200
Thank you.

1303
00:55:54,200 --> 00:55:56,910
Yeah, I don't know if I have
too much to say about this.

1304
00:55:56,910 --> 00:56:00,080
I mean, from my understanding,
the brain fog like symptoms

1305
00:56:00,080 --> 00:56:03,110
in long COVID patients are not
quite specific to language.

1306
00:56:03,110 --> 00:56:04,610
The language may
be affected, but it

1307
00:56:04,610 --> 00:56:08,300
seems like it's a pretty
wide spread systemic effects

1308
00:56:08,300 --> 00:56:09,720
on multiple systems.

1309
00:56:09,720 --> 00:56:13,130
So it's possible that insights
from specific disorders,

1310
00:56:13,130 --> 00:56:17,580
like language or audition,
related things may be helpful,

1311
00:56:17,580 --> 00:56:21,230
but it seems like there is some
more global things to understand

1312
00:56:21,230 --> 00:56:21,990
there.

1313
00:56:21,990 --> 00:56:23,630
And maybe the
deficits are actually

1314
00:56:23,630 --> 00:56:27,380
in this very vulnerable system
to aging, which we mentioned

1315
00:56:27,380 --> 00:56:30,350
the system that affects
memory and is very

1316
00:56:30,350 --> 00:56:33,260
affected in Alzheimer's,
so the system that

1317
00:56:33,260 --> 00:56:36,500
has big hippocampal components.

1318
00:56:36,500 --> 00:56:39,680
But yeah, sorry, I don't
think I have anything

1319
00:56:39,680 --> 00:56:40,850
more specific than that.

1320
00:56:40,850 --> 00:56:41,940
Thank you so much.

1321
00:56:41,940 --> 00:56:44,030
So a question for
you before you leave.

1322
00:56:44,030 --> 00:56:48,460
So what do you measure to
document the patient's brain

1323
00:56:48,460 --> 00:56:48,960
fog?

1324
00:56:48,960 --> 00:56:50,585
What kind of tests
do you have them do?

1325
00:56:50,585 --> 00:56:54,530
So currently, in our study,
we do three different measures

1326
00:56:54,530 --> 00:56:55,350
that we add.

1327
00:56:55,350 --> 00:57:00,110
So typically, a day before
person comes to MIT visit

1328
00:57:00,110 --> 00:57:03,110
for study visit, we
assign the cognitive test

1329
00:57:03,110 --> 00:57:04,240
called brain check.

1330
00:57:04,240 --> 00:57:06,220
It's equivalent
version of a battery

1331
00:57:06,220 --> 00:57:07,640
that can be done remotely.

1332
00:57:07,640 --> 00:57:11,540
So it takes strobe and trail
making and memory function,

1333
00:57:11,540 --> 00:57:13,670
immediate recognition
type of testing.

1334
00:57:13,670 --> 00:57:17,630
And once they come to
MIT for study visit,

1335
00:57:17,630 --> 00:57:20,210
we do two different
neurocognitive testing.

1336
00:57:20,210 --> 00:57:24,160
One is called right eye, which
we add a visual sensitivity

1337
00:57:24,160 --> 00:57:24,890
testing.

1338
00:57:24,890 --> 00:57:26,620
So the person will--
we're going to look

1339
00:57:26,620 --> 00:57:30,280
at the eye coordination
and pursuit and saccades

1340
00:57:30,280 --> 00:57:33,640
and the brain reaction time
and physical reaction time

1341
00:57:33,640 --> 00:57:36,680
by using different images
and how quickly they react.

1342
00:57:36,680 --> 00:57:40,660
And the other one we also use
equivalent version of EEG called

1343
00:57:40,660 --> 00:57:43,280
[? Wave. ?] It's actually
a commercial testing,

1344
00:57:43,280 --> 00:57:45,350
but we look at the
brain activity,

1345
00:57:45,350 --> 00:57:49,040
look at the alpha peak wave
during the P300 testing,

1346
00:57:49,040 --> 00:57:51,640
we also do the flanker
testing as well

1347
00:57:51,640 --> 00:57:54,580
just to see the difference
in terms of reaction time.

1348
00:57:54,580 --> 00:57:56,230
Great, thanks.

1349
00:57:56,230 --> 00:57:58,070
We can learn from
the audience as well.

1350
00:57:58,070 --> 00:58:00,842
[LAUGHTER]

1351
00:58:00,842 --> 00:58:02,230

1352
00:58:02,230 --> 00:58:06,400
So Hi, I'm [INAUDIBLE], and I'm
a first year master's student

1353
00:58:06,400 --> 00:58:07,070
at Harvard.

1354
00:58:07,070 --> 00:58:09,940
So my question may be
a little bit naive.

1355
00:58:09,940 --> 00:58:13,420
So in my undergrad
study, I did projects

1356
00:58:13,420 --> 00:58:17,360
related to understanding
molecular mechanism of autism.

1357
00:58:17,360 --> 00:58:22,220
And I also have some experience
dealing with the neuroimage.

1358
00:58:22,220 --> 00:58:25,420
So my question
would be, well, it

1359
00:58:25,420 --> 00:58:28,210
is possible to have a model,
like machine learning model,

1360
00:58:28,210 --> 00:58:35,290
to actually predict both
the genomics and the--

1361
00:58:35,290 --> 00:58:39,640
I mean, the outcome of
diseases or the hearing

1362
00:58:39,640 --> 00:58:43,330
aid devices for both
genomics level and also

1363
00:58:43,330 --> 00:58:45,610
the circuit level.

1364
00:58:45,610 --> 00:58:49,960
So if that is possible,
so what is the challenge

1365
00:58:49,960 --> 00:58:52,180
that you may see in this?

1366
00:58:52,180 --> 00:58:55,720

1367
00:58:55,720 --> 00:58:58,360
So we have less
than two minutes.

1368
00:58:58,360 --> 00:58:59,910
You want to try that.

1369
00:58:59,910 --> 00:59:02,160
Josh that's you.

1370
00:59:02,160 --> 00:59:06,450
So, I mean, we're
definitely not there, right?

1371
00:59:06,450 --> 00:59:11,050
I mean, I think the means by
which genes lead to circuits,

1372
00:59:11,050 --> 00:59:15,240
I mean, that's a pretty big and
hard and complicated problem.

1373
00:59:15,240 --> 00:59:16,213
I don't know.

1374
00:59:16,213 --> 00:59:17,880
I mean, machine
learning could certainly

1375
00:59:17,880 --> 00:59:20,160
be useful probably
in understanding

1376
00:59:20,160 --> 00:59:22,080
that if you had enough data.

1377
00:59:22,080 --> 00:59:25,262
And my guess is there probably
will be lots of headway on that.

1378
00:59:25,262 --> 00:59:26,970
I mean, there's
definitely lots of people

1379
00:59:26,970 --> 00:59:29,160
who are very excited
about building

1380
00:59:29,160 --> 00:59:31,420
models of the entire brain
at the circuit level.

1381
00:59:31,420 --> 00:59:35,100
I mean, this is I think
what Ed maybe aspires to.

1382
00:59:35,100 --> 00:59:39,640
And where that's going to lead,
I think, we still don't know.

1383
00:59:39,640 --> 00:59:41,590
But it's a really
exciting direction

1384
00:59:41,590 --> 00:59:45,450
And, it could
become within reach.

1385
00:59:45,450 --> 00:59:48,000
OK, thank you.

1386
00:59:48,000 --> 00:59:50,500
So one last question.

1387
00:59:50,500 --> 00:59:51,000
Thanks.

1388
00:59:51,000 --> 00:59:52,000
Thanks for your talk.

1389
00:59:52,000 --> 00:59:52,780
I'm curious.

1390
00:59:52,780 --> 00:59:54,840
I have actually two
questions, if I might.

1391
00:59:54,840 --> 00:59:58,260
With regard to language,
are the same centers

1392
00:59:58,260 --> 01:00:01,440
for language processing
identical regardless

1393
01:00:01,440 --> 01:00:05,230
of the input via hearing,
sight, signing, et cetera?

1394
01:00:05,230 --> 01:00:08,250
Yes, Sorry, I didn't
explicitly say this.

1395
01:00:08,250 --> 01:00:09,900
They're AI model,
so it doesn't matter

1396
01:00:09,900 --> 01:00:11,910
if you're reading or
listening or processing

1397
01:00:11,910 --> 01:00:13,180
sign language if your sign.

1398
01:00:13,180 --> 01:00:16,080
OK, my second
question is, how broad

1399
01:00:16,080 --> 01:00:18,040
is the definition of language?

1400
01:00:18,040 --> 01:00:20,790
Does it encompass
situational awareness

1401
01:00:20,790 --> 01:00:24,180
when you're in traffic,
traffic lights, where

1402
01:00:24,180 --> 01:00:27,180
cars are, danger on the street?

1403
01:00:27,180 --> 01:00:29,970
Is that part of the
language function?

1404
01:00:29,970 --> 01:00:32,880
Well, so I certainly
wouldn't put--

1405
01:00:32,880 --> 01:00:35,730
I mean, language is a very
difficult construct in the sense

1406
01:00:35,730 --> 01:00:38,110
that it interacts with all
sorts of other systems.

1407
01:00:38,110 --> 01:00:41,160
But it so happens that we have
a set of these areas that are

1408
01:00:41,160 --> 01:00:42,833
quite specialized for language.

1409
01:00:42,833 --> 01:00:44,250
And then, a lot
of ongoing work is

1410
01:00:44,250 --> 01:00:46,200
trying to understand how
these language circuits work

1411
01:00:46,200 --> 01:00:47,800
with low level
audition circuits,

1412
01:00:47,800 --> 01:00:49,360
how they work with
memory circuits,

1413
01:00:49,360 --> 01:00:50,950
how they work with
attention circuits.

1414
01:00:50,950 --> 01:00:53,610
Because, of course, we use
language in its real life

1415
01:00:53,610 --> 01:00:55,590
complexity where
there's a lot of systems

1416
01:00:55,590 --> 01:00:57,960
that come together and
have to talk to each other.

1417
01:00:57,960 --> 01:01:01,010
But it does seem that there
is some sense in which there

1418
01:01:01,010 --> 01:01:04,370
is a system that's specialized
for just this encoding decoding

1419
01:01:04,370 --> 01:01:07,080
aspect between thoughts
and word sequences.

1420
01:01:07,080 --> 01:01:11,250
I guess a follow on to that is,
if I lost my language centers,

1421
01:01:11,250 --> 01:01:15,110
would I lose my ability
to understand situational?

1422
01:01:15,110 --> 01:01:16,110
No, you would not.

1423
01:01:16,110 --> 01:01:19,700
In fact, there is a large body
of work with severe aphasics

1424
01:01:19,700 --> 01:01:21,620
and their cognition--
so it relates

1425
01:01:21,620 --> 01:01:24,510
to the first question as well--
their cognition is totally fine.

1426
01:01:24,510 --> 01:01:27,240
They can navigate the world,
they can socially reason,

1427
01:01:27,240 --> 01:01:30,000
they can keep their attention,
they can play chess,

1428
01:01:30,000 --> 01:01:32,480
they just can't express
their thoughts and language

1429
01:01:32,480 --> 01:01:33,390
or understand others.

1430
01:01:33,390 --> 01:01:33,890
Thank you.

1431
01:01:33,890 --> 01:01:36,663
So to be in sync with the
remaining part of the program,

1432
01:01:36,663 --> 01:01:37,705
let's thank our speakers.

1433
01:01:37,705 --> 01:01:41,140
[APPLAUSE]

1434
01:01:41,140 --> 01:01:41,640
Thank you.

1435
01:01:41,640 --> 01:01:44,270

1436
01:01:44,270 --> 01:01:47,060
And I guess they're going
to reconvene over in the--

1437
01:01:47,060 --> 01:01:50,270
across the way
there very shortly.

1438
01:01:50,270 --> 01:01:52,510
OK, great.

1439
01:01:52,510 --> 01:01:55,000


1
00:00:06,640 --> 00:00:10,480
Hi everyone, my name is Laura Lubbert

2
00:00:08,559 --> 00:00:12,800
and I'm also a post-doctoral fellow at

3
00:00:10,480 --> 00:00:14,799
the Eric and Vanishes Center and it's my

4
00:00:12,800 --> 00:00:17,600
honor to present our next speaker,

5
00:00:14,799 --> 00:00:19,600
Professor Patrick Shu. Professor Shu is

6
00:00:17,600 --> 00:00:21,439
a co-founder and co-investigator at the

7
00:00:19,600 --> 00:00:23,920
Ark Institute as well as an assistant

8
00:00:21,439 --> 00:00:26,000
professor at Berkeley University. His

9
00:00:23,920 --> 00:00:28,560
work has been pretty influential from

10
00:00:26,000 --> 00:00:30,960
the get-go. During his PhD, he played a

11
00:00:28,560 --> 00:00:33,680
pivotal role in developing crisper cast

12
00:00:30,960 --> 00:00:36,000
9 technology. And since then, his lab

13
00:00:33,680 --> 00:00:37,920
has led groundbreaking work in genome

14
00:00:36,000 --> 00:00:41,040
editing. Amongst others, crisper

15
00:00:37,920 --> 00:00:42,960
technology that targets RNA and the

16
00:00:41,040 --> 00:00:45,680
recent discovery of a whole new class of

17
00:00:42,960 --> 00:00:48,640
guide RNAs called bridge RNAs. Together

18
00:00:45,680 --> 00:00:50,719
with Brian He, he also developed EVO 2,

19
00:00:48,640 --> 00:00:53,440
one of the largest biological foundation

20
00:00:50,719 --> 00:00:55,600
models. Uh unsurprisingly, his work has

21
00:00:53,440 --> 00:00:58,000
been awarded several accolades,

22
00:00:55,600 --> 00:01:00,079
including the NIH Early Independence

23
00:00:58,000 --> 00:01:02,800
Award, the Rainwater Prize for

24
00:01:00,079 --> 00:01:05,600
Innovative Early Career Scientists, and

25
00:01:02,800 --> 00:01:08,250
Forbes 30 under 30. Please join me in

26
00:01:05,600 --> 00:01:11,520
welcoming Professor Patrick Shu.

27
00:01:08,250 --> 00:01:14,000
[Applause]

28
00:01:11,520 --> 00:01:15,840
Awesome. Well, thanks so much uh

29
00:01:14,000 --> 00:01:17,680
Caroline and the organizers for having

30
00:01:15,840 --> 00:01:19,920
me and uh it's a real joy and privilege

31
00:01:17,680 --> 00:01:22,240
to be here today and tell you about some

32
00:01:19,920 --> 00:01:24,640
of uh our work and trying to bring

33
00:01:22,240 --> 00:01:27,040
together the fields of uh genetics and

34
00:01:24,640 --> 00:01:28,880
machine learning. Um as so so you know

35
00:01:27,040 --> 00:01:30,240
as Laura kindly introduced you know I've

36
00:01:28,880 --> 00:01:32,640
been thinking about ways that we can

37
00:01:30,240 --> 00:01:34,479
manipulate uh you know biological

38
00:01:32,640 --> 00:01:36,479
molecules directly inside of living

39
00:01:34,479 --> 00:01:38,079
cells for a long time and over the last

40
00:01:36,479 --> 00:01:40,640
few years we started to really turn our

41
00:01:38,079 --> 00:01:43,119
attention to how we could actually model

42
00:01:40,640 --> 00:01:45,040
uh these molecules as well. And so if we

43
00:01:43,119 --> 00:01:48,399
you know go to the words of Francis

44
00:01:45,040 --> 00:01:50,560
Arnold the uh original inventor of

45
00:01:48,399 --> 00:01:53,040
directed evolution right she says you

46
00:01:50,560 --> 00:01:55,439
know for today we can for all practical

47
00:01:53,040 --> 00:01:58,240
purposes rewrite and edit any sequence

48
00:01:55,439 --> 00:02:00,159
of DNA but we cannot compose it maybe we

49
00:01:58,240 --> 00:02:02,240
can cut and paste these pieces from

50
00:02:00,159 --> 00:02:04,079
nature's compositions but we don't know

51
00:02:02,240 --> 00:02:06,320
how to write the bars for a single

52
00:02:04,079 --> 00:02:08,640
enzyic passage. uh but she ends by

53
00:02:06,320 --> 00:02:10,319
saying however evolution does know how

54
00:02:08,640 --> 00:02:12,720
to do this and so we started thinking in

55
00:02:10,319 --> 00:02:15,280
the lab how can we decipher the language

56
00:02:12,720 --> 00:02:18,080
of evolution to try to compose genomic

57
00:02:15,280 --> 00:02:19,599
information. So these advances in AI as

58
00:02:18,080 --> 00:02:22,800
we all know offer this universal

59
00:02:19,599 --> 00:02:25,280
framework that leverage data and compute

60
00:02:22,800 --> 00:02:27,120
at scale to uncover higher order

61
00:02:25,280 --> 00:02:30,000
patterns in diverse domains including

62
00:02:27,120 --> 00:02:31,920
natural language uh vision or even

63
00:02:30,000 --> 00:02:33,680
embodied intelligence. Right? And of

64
00:02:31,920 --> 00:02:35,760
course we're trying to apply this

65
00:02:33,680 --> 00:02:37,840
machine learning paradigm uh to

66
00:02:35,760 --> 00:02:39,040
biological molecules. And over the past

67
00:02:37,840 --> 00:02:40,800
few years, we've seen some really

68
00:02:39,040 --> 00:02:43,519
incredible breakthroughs for protein

69
00:02:40,800 --> 00:02:45,519
structure prediction, lian docking,

70
00:02:43,519 --> 00:02:48,160
looking at the complex folds of RNA and

71
00:02:45,519 --> 00:02:50,160
so on. And that's obviously been really

72
00:02:48,160 --> 00:02:52,480
wonderful. But the problem is despite

73
00:02:50,160 --> 00:02:54,959
the immense complexity of even these

74
00:02:52,480 --> 00:02:56,959
molecules and these modeling paradigms

75
00:02:54,959 --> 00:02:59,200
so far, right? The complexity of these

76
00:02:56,959 --> 00:03:02,000
molecules is really dwarfed by the

77
00:02:59,200 --> 00:03:04,159
overall complexity of an entire cell,

78
00:03:02,000 --> 00:03:06,720
which is many orders of magnitude larger

79
00:03:04,159 --> 00:03:08,319
and more complex. And so the cell's fun

80
00:03:06,720 --> 00:03:10,239
uh structure and its function are really

81
00:03:08,319 --> 00:03:12,239
built by the diverse interactions

82
00:03:10,239 --> 00:03:14,000
between all these different molecules

83
00:03:12,239 --> 00:03:16,159
which is a staggering number of

84
00:03:14,000 --> 00:03:18,560
combinatorial possibilities um at

85
00:03:16,159 --> 00:03:20,800
multiple levels of regulation. So in

86
00:03:18,560 --> 00:03:22,640
short this is really really complicated.

87
00:03:20,800 --> 00:03:25,440
The good news is that all of this

88
00:03:22,640 --> 00:03:28,400
molecular logic fundamentally is encoded

89
00:03:25,440 --> 00:03:30,879
within DNA. That's a single sequence

90
00:03:28,400 --> 00:03:32,879
that contains all the information that

91
00:03:30,879 --> 00:03:35,519
is needed arguably to create an entire

92
00:03:32,879 --> 00:03:38,159
organism. So in fact the effects of

93
00:03:35,519 --> 00:03:40,159
evolution are actually passed down

94
00:03:38,159 --> 00:03:42,480
throughout generations of life via these

95
00:03:40,159 --> 00:03:43,760
DNA mutations. So in principle you might

96
00:03:42,480 --> 00:03:46,200
be able to learn something about

97
00:03:43,760 --> 00:03:48,879
function right or the functional

98
00:03:46,200 --> 00:03:51,440
adaptations to natural selection by

99
00:03:48,879 --> 00:03:53,840
looking at DNA alone. And so we asked

100
00:03:51,440 --> 00:03:56,640
this simple question. Can we create a

101
00:03:53,840 --> 00:03:58,159
machine that tries to learn the

102
00:03:56,640 --> 00:04:00,720
evolutionary distribution of these

103
00:03:58,159 --> 00:04:02,319
sequences from whole genomes and learn

104
00:04:00,720 --> 00:04:04,159
something about the interactions of all

105
00:04:02,319 --> 00:04:05,239
these different molecules that creates

106
00:04:04,159 --> 00:04:07,599
an entire

107
00:04:05,239 --> 00:04:10,560
organism. One of the central challenges

108
00:04:07,599 --> 00:04:12,879
in doing this is that biology uses a

109
00:04:10,560 --> 00:04:15,439
different language. It's foreign and not

110
00:04:12,879 --> 00:04:17,280
very human interpretable. So on the left

111
00:04:15,439 --> 00:04:19,759
you can see this schematic of this

112
00:04:17,280 --> 00:04:22,240
so-called central dogma of molecular

113
00:04:19,759 --> 00:04:24,560
biology where DNA is transcribed to RNA

114
00:04:22,240 --> 00:04:26,479
which is translated to proteins. Right?

115
00:04:24,560 --> 00:04:28,639
But you'll immediately see two things on

116
00:04:26,479 --> 00:04:31,400
the right. The first is that these

117
00:04:28,639 --> 00:04:33,759
sequences are continuous and

118
00:04:31,400 --> 00:04:36,400
directional. And the second from the

119
00:04:33,759 --> 00:04:39,040
bottom moving upward there's a hierarchy

120
00:04:36,400 --> 00:04:40,560
of information flow that's embedded

121
00:04:39,040 --> 00:04:42,720
across the different modes of this

122
00:04:40,560 --> 00:04:44,960
central dogma where they're predictably

123
00:04:42,720 --> 00:04:49,199
transformed uh into you know different

124
00:04:44,960 --> 00:04:51,040
types of uh sequences and codons. And so

125
00:04:49,199 --> 00:04:53,280
to try to understand this molecular

126
00:04:51,040 --> 00:04:55,840
language, you can try to, you know, port

127
00:04:53,280 --> 00:04:58,320
over the sort of auto reggressor uh auto

128
00:04:55,840 --> 00:05:00,960
reggressive uh paradigm from natural

129
00:04:58,320 --> 00:05:02,400
language modeling here to DNA where you

130
00:05:00,960 --> 00:05:04,960
know if you want to do next token

131
00:05:02,400 --> 00:05:07,440
prediction for a famous passage from the

132
00:05:04,960 --> 00:05:10,960
English literature to be or not to be,

133
00:05:07,440 --> 00:05:13,199
we all intuitively know the next token.

134
00:05:10,960 --> 00:05:16,280
We've pre-trained on talking to each

135
00:05:13,199 --> 00:05:18,960
other, right? But if I asked you GTGC

136
00:05:16,280 --> 00:05:22,479
catct, would you know what the next

137
00:05:18,960 --> 00:05:25,800
nucleotide is? Right? And to give you an

138
00:05:22,479 --> 00:05:28,639
intuition for why at massive scales of

139
00:05:25,800 --> 00:05:31,039
text, this next token prediction

140
00:05:28,639 --> 00:05:32,960
paradigm can lead to general reasoning

141
00:05:31,039 --> 00:05:35,039
and intelligence, right? It's useful to

142
00:05:32,960 --> 00:05:36,880
look at a few examples. So if you, you

143
00:05:35,039 --> 00:05:39,680
know, if I said in my free time, I like

144
00:05:36,880 --> 00:05:41,120
to code, right? Or banana. It's not

145
00:05:39,680 --> 00:05:44,160
banana, right? I I'll learn something

146
00:05:41,120 --> 00:05:46,720
about grammar or um or or even world

147
00:05:44,160 --> 00:05:49,280
knowledge. The capital of Azerbaijan is

148
00:05:46,720 --> 00:05:51,120
Baku and not London, right? Or I'm

149
00:05:49,280 --> 00:05:53,280
standing in Cambridge and not in San

150
00:05:51,120 --> 00:05:55,120
Francisco, right? But you know, you can

151
00:05:53,280 --> 00:05:57,360
you can get more complex things even

152
00:05:55,120 --> 00:05:59,600
like spatial reasoning, right? Iro went

153
00:05:57,360 --> 00:06:02,800
into the kitchen to make tea, standing

154
00:05:59,600 --> 00:06:05,039
next to Iro. Zuko pondered his destiny.

155
00:06:02,800 --> 00:06:06,960
He probably then left the kitchen and

156
00:06:05,039 --> 00:06:08,960
not the bathroom, right? And so, you

157
00:06:06,960 --> 00:06:10,840
know, kind of at massive scales of text,

158
00:06:08,960 --> 00:06:13,600
you can start to break

159
00:06:10,840 --> 00:06:15,840
apart unstructured data to find

160
00:06:13,600 --> 00:06:18,160
patterns. And this is effectively what

161
00:06:15,840 --> 00:06:20,319
we try to do in biological research,

162
00:06:18,160 --> 00:06:22,639
right? We know and learn in high school

163
00:06:20,319 --> 00:06:25,280
that we have genotype that's linked or

164
00:06:22,639 --> 00:06:27,520
underpins phenotype in some way and we

165
00:06:25,280 --> 00:06:30,240
try to use that to

166
00:06:27,520 --> 00:06:32,319
uh dulge mechanism and phenotype is in

167
00:06:30,240 --> 00:06:35,360
turn selected in order to influence

168
00:06:32,319 --> 00:06:38,880
genotype. Right? And so by looking at

169
00:06:35,360 --> 00:06:40,880
the next base or the next something in a

170
00:06:38,880 --> 00:06:42,960
biological sequence, you can start to

171
00:06:40,880 --> 00:06:45,120
learn pretty interesting and diverse

172
00:06:42,960 --> 00:06:47,120
things about complex biological

173
00:06:45,120 --> 00:06:49,520
properties. So an example would be if

174
00:06:47,120 --> 00:06:51,919
the next nucleotide in my genome is

175
00:06:49,520 --> 00:06:54,319
going to be a healthy nucleotide or it's

176
00:06:51,919 --> 00:06:57,039
going to give me a devastating genetic

177
00:06:54,319 --> 00:06:58,880
disorder. At the abstraction level of

178
00:06:57,039 --> 00:07:01,680
residues, is the next residue going to

179
00:06:58,880 --> 00:07:03,440
be a functional catalytic residue or

180
00:07:01,680 --> 00:07:06,479
it's going to be some catalytic null

181
00:07:03,440 --> 00:07:09,039
that inactivates my molecular machine?

182
00:07:06,479 --> 00:07:10,479
Or it might be if this next uh

183
00:07:09,039 --> 00:07:13,039
nucleotide is going to disrupt a

184
00:07:10,479 --> 00:07:15,520
hairpin, an RNA secondary structure that

185
00:07:13,039 --> 00:07:17,919
no longer forms the abdimer shape that

186
00:07:15,520 --> 00:07:20,720
is required to bring a co-actor in order

187
00:07:17,919 --> 00:07:22,479
to do transcriptional regulation or even

188
00:07:20,720 --> 00:07:25,360
at the abstraction level of genes. We

189
00:07:22,479 --> 00:07:27,919
know in proaryotic genomes genes that

190
00:07:25,360 --> 00:07:30,319
function together are clustered together

191
00:07:27,919 --> 00:07:33,039
in functional operons and so mod a and

192
00:07:30,319 --> 00:07:35,680
mod b is probably followed by mod c and

193
00:07:33,039 --> 00:07:38,960
not the kind of unaffiliated uh you know

194
00:07:35,680 --> 00:07:41,280
DNA repair enzyme wreck a right and so

195
00:07:38,960 --> 00:07:43,440
we try to take these intuitions to train

196
00:07:41,280 --> 00:07:44,720
initial model called evo1 this is a

197
00:07:43,440 --> 00:07:48,000
close collaboration with my arc

198
00:07:44,720 --> 00:07:50,479
colleague Brian he um where we've seen

199
00:07:48,000 --> 00:07:52,400
so far in the field lots of effort on

200
00:07:50,479 --> 00:07:55,360
creating tasks specific specific

201
00:07:52,400 --> 00:07:58,240
specialized models like ESM for protein

202
00:07:55,360 --> 00:08:01,280
language or models for regulatory DNA or

203
00:07:58,240 --> 00:08:02,560
for RNA language in particular. However,

204
00:08:01,280 --> 00:08:04,879
all of these different components

205
00:08:02,560 --> 00:08:07,280
because they're fundamentally encoded

206
00:08:04,879 --> 00:08:09,280
inside of the genome, right? By training

207
00:08:07,280 --> 00:08:11,599
a genome foundation model at long

208
00:08:09,280 --> 00:08:13,199
context, we might be able to learn all

209
00:08:11,599 --> 00:08:15,360
of these different elements, but

210
00:08:13,199 --> 00:08:17,440
importantly all of their combinatorial

211
00:08:15,360 --> 00:08:21,199
interactions as well. So we train this

212
00:08:17,440 --> 00:08:23,400
initial model at 7B 131K token context

213
00:08:21,199 --> 00:08:25,759
and show that the model is both

214
00:08:23,400 --> 00:08:27,360
multimodal because it can understand

215
00:08:25,759 --> 00:08:30,080
these different modalities of central

216
00:08:27,360 --> 00:08:31,599
dogma but that it's also multi-cale.

217
00:08:30,080 --> 00:08:33,279
I'll give you a few examples. In

218
00:08:31,599 --> 00:08:34,800
addition to designing proteins, right,

219
00:08:33,279 --> 00:08:36,719
where you're simply autocompleting some

220
00:08:34,800 --> 00:08:38,479
residue sequence, you can also design

221
00:08:36,719 --> 00:08:41,120
things like crisper systems which

222
00:08:38,479 --> 00:08:43,120
orchestrates a cast 9 protein a

223
00:08:41,120 --> 00:08:45,600
molecular scissors with a non-oding

224
00:08:43,120 --> 00:08:48,080
guide RNA. Right? Because these are

225
00:08:45,600 --> 00:08:50,959
fundamentally encoded within the genome,

226
00:08:48,080 --> 00:08:52,880
EVO understands the co-evolutionary

227
00:08:50,959 --> 00:08:56,160
relationship between these two different

228
00:08:52,880 --> 00:08:59,440
sequences and is able to make functional

229
00:08:56,160 --> 00:09:02,480
EVO designed cast 9 that are able to cut

230
00:08:59,440 --> 00:09:04,880
DNA in the test tube or inside of a

231
00:09:02,480 --> 00:09:06,640
cell. Right? That's a generation task at

232
00:09:04,880 --> 00:09:08,560
the not just molecular level, but at a

233
00:09:06,640 --> 00:09:11,680
molecular systems level. But you can

234
00:09:08,560 --> 00:09:13,600
also do predictions at the cellular or

235
00:09:11,680 --> 00:09:15,800
organismal scale. So one thing that

236
00:09:13,600 --> 00:09:18,320
we're able to do here is to efficiently

237
00:09:15,800 --> 00:09:21,519
classify essential from non-essential

238
00:09:18,320 --> 00:09:23,680
genes. Something that's the territory of

239
00:09:21,519 --> 00:09:25,680
experimental gene essentiality crisper

240
00:09:23,680 --> 00:09:27,760
screens that take months to years in the

241
00:09:25,680 --> 00:09:30,080
lab. Here we can replace that with

242
00:09:27,760 --> 00:09:33,120
forward passes of a neural network.

243
00:09:30,080 --> 00:09:37,120
Right? Even at the genome scale we can

244
00:09:33,120 --> 00:09:40,080
generate uh long sequences at a megabase

245
00:09:37,120 --> 00:09:41,760
that looks kind of like a proarotic

246
00:09:40,080 --> 00:09:44,160
genome. You'll see that there's dense

247
00:09:41,760 --> 00:09:45,920
coding architecture in both strands.

248
00:09:44,160 --> 00:09:48,160
There are genes that can be translated

249
00:09:45,920 --> 00:09:51,120
into proteins embedded within these long

250
00:09:48,160 --> 00:09:53,760
unconstrained generations. They contain

251
00:09:51,120 --> 00:09:56,080
protein structures that map to the

252
00:09:53,760 --> 00:09:58,160
distribution of naturally observed alpha

253
00:09:56,080 --> 00:10:01,200
helyses or beta sheets and their

254
00:09:58,160 --> 00:10:02,880
ontologies map to fundamental functional

255
00:10:01,200 --> 00:10:05,040
ontologies.

256
00:10:02,880 --> 00:10:08,080
They even we can even see in these

257
00:10:05,040 --> 00:10:10,720
single generations all of the tRNAs that

258
00:10:08,080 --> 00:10:13,040
you need to support protein translation

259
00:10:10,720 --> 00:10:15,200
but unfortunately we see only some of

260
00:10:13,040 --> 00:10:17,040
the rnas that you would need to make the

261
00:10:15,200 --> 00:10:18,800
ribosomes that would then in turn make

262
00:10:17,040 --> 00:10:21,600
those proteins right so we sort of think

263
00:10:18,800 --> 00:10:24,320
of this as a blurry picture of life

264
00:10:21,600 --> 00:10:26,959
right and so hopefully more scaling

265
00:10:24,320 --> 00:10:28,320
could actually get us to sharper uh

266
00:10:26,959 --> 00:10:30,480
understanding and reasoning about

267
00:10:28,320 --> 00:10:32,320
genomic content so in training this

268
00:10:30,480 --> 00:10:34,720
model we uh uncovered so-c calledled

269
00:10:32,320 --> 00:10:36,560
scaling loss for DNA, which is something

270
00:10:34,720 --> 00:10:38,000
that we've seen in the large language

271
00:10:36,560 --> 00:10:40,160
modeling space, which is that there's a

272
00:10:38,000 --> 00:10:42,640
very predictable improvement in model

273
00:10:40,160 --> 00:10:44,320
performance as you pour in more compute,

274
00:10:42,640 --> 00:10:46,880
more pre-training data or more

275
00:10:44,320 --> 00:10:49,279
parameters into the model. We see that

276
00:10:46,880 --> 00:10:50,959
type of pattern here implying that these

277
00:10:49,279 --> 00:10:54,079
are similar strategies that can be used

278
00:10:50,959 --> 00:10:57,040
to improve genomic model performance,

279
00:10:54,079 --> 00:10:58,959
right? And so EVA1 was trained on 300

280
00:10:57,040 --> 00:11:01,680
billion tokens tokenized a single

281
00:10:58,959 --> 00:11:04,079
nucleotide resolution of proaryotic and

282
00:11:01,680 --> 00:11:06,399
fagee genomes. So these are the small

283
00:11:04,079 --> 00:11:08,880
sort of single cellar organisms. And in

284
00:11:06,399 --> 00:11:11,680
the next study we wanted to move to

285
00:11:08,880 --> 00:11:13,760
understand ukarotic genomes like ours

286
00:11:11,680 --> 00:11:16,800
right which are of course much longer

287
00:11:13,760 --> 00:11:19,600
contain introns and you know uh you know

288
00:11:16,800 --> 00:11:22,480
kind of non-coding space and uh you know

289
00:11:19,600 --> 00:11:25,200
are much longer and more complex. With

290
00:11:22,480 --> 00:11:27,839
EVO 2, we scaled to over 9 trillion

291
00:11:25,200 --> 00:11:31,279
tokens of DNA across all observable

292
00:11:27,839 --> 00:11:35,920
evolution um including bacteria, archa,

293
00:11:31,279 --> 00:11:38,720
and all ukaria. Um and um and asked uh

294
00:11:35,920 --> 00:11:41,040
if we could extend from 131k context to

295
00:11:38,720 --> 00:11:44,000
a million token context if we'd be able

296
00:11:41,040 --> 00:11:46,720
to learn uh more about these sort of

297
00:11:44,000 --> 00:11:48,240
kind of ukarotic scales of biology,

298
00:11:46,720 --> 00:11:50,320
right? And so just to give you a sense

299
00:11:48,240 --> 00:11:53,200
of this, right? Individual molecules are

300
00:11:50,320 --> 00:11:54,720
of course quite small and with EVO1 we

301
00:11:53,200 --> 00:11:57,519
can fit in things like functional

302
00:11:54,720 --> 00:11:59,440
operons right in proarotic genomes where

303
00:11:57,519 --> 00:12:02,640
you have multiple different elements

304
00:11:59,440 --> 00:12:05,120
that are coded together in cy sequence

305
00:12:02,640 --> 00:12:07,440
but as you extend to ukareotic genomes

306
00:12:05,120 --> 00:12:10,240
the scale of entire yeast chromosomes

307
00:12:07,440 --> 00:12:12,160
human tads or entire bacterial genomes

308
00:12:10,240 --> 00:12:15,360
right you can actually fit all of this

309
00:12:12,160 --> 00:12:18,959
information in context um at million uh

310
00:12:15,360 --> 00:12:22,480
token context right scale this model to

311
00:12:18,959 --> 00:12:24,800
uh over 40 billion parameters um using a

312
00:12:22,480 --> 00:12:28,320
multiconvolutional hybrid architecture

313
00:12:24,800 --> 00:12:31,360
known as striped hyena. In EVO 2, uh we

314
00:12:28,320 --> 00:12:35,440
developed a new uh architecture known as

315
00:12:31,360 --> 00:12:38,480
striped hyena 2 um that uh like EVO one

316
00:12:35,440 --> 00:12:40,880
uses these uh kind of gated convolutions

317
00:12:38,480 --> 00:12:44,720
striped with 10% attention that's able

318
00:12:40,880 --> 00:12:46,880
to evaluate long context at nearlinear

319
00:12:44,720 --> 00:12:49,760
uh time uh and with improvements in

320
00:12:46,880 --> 00:12:51,519
throughput of training, right? And so,

321
00:12:49,760 --> 00:12:53,440
you know, this is essentially how we can

322
00:12:51,519 --> 00:12:56,160
try to crunch, you know, these massive

323
00:12:53,440 --> 00:12:58,320
pre-training uh databases and data mixes

324
00:12:56,160 --> 00:13:01,200
without the, you know, kind of massive

325
00:12:58,320 --> 00:13:04,240
GPU farms that you have in uh you know,

326
00:13:01,200 --> 00:13:05,920
industrial AI labs. So, you know, so

327
00:13:04,240 --> 00:13:07,680
that this is cool. Um lots of

328
00:13:05,920 --> 00:13:09,839
architecture stuff. What what does the

329
00:13:07,680 --> 00:13:11,839
model learn about biology, right? And

330
00:13:09,839 --> 00:13:13,920
so, you know, you can feed in uh

331
00:13:11,839 --> 00:13:16,480
mutations into the model and ask the

332
00:13:13,920 --> 00:13:18,320
model what's going on at that mutation,

333
00:13:16,480 --> 00:13:20,560
right? This is an entire field of

334
00:13:18,320 --> 00:13:22,800
computational biology known as variant

335
00:13:20,560 --> 00:13:24,560
effect prediction. Right? And so I'll

336
00:13:22,800 --> 00:13:26,480
give you a more concrete example.

337
00:13:24,560 --> 00:13:28,639
There's an important gene in the genome

338
00:13:26,480 --> 00:13:31,360
known as broco one. Right? It's known to

339
00:13:28,639 --> 00:13:33,760
be able to cause some breast and ovarian

340
00:13:31,360 --> 00:13:36,160
cancers. Right? If you have a causal

341
00:13:33,760 --> 00:13:38,639
mutation, right? Many patients might

342
00:13:36,160 --> 00:13:41,120
elect for a double mistctomy. If you

343
00:13:38,639 --> 00:13:43,279
have a benign mutation, you might just

344
00:13:41,120 --> 00:13:44,959
elect for an annual mammogram. The

345
00:13:43,279 --> 00:13:46,399
problem though is most people have what

346
00:13:44,959 --> 00:13:48,959
are known as variants of unknown

347
00:13:46,399 --> 00:13:50,399
significance which is fancy you know

348
00:13:48,959 --> 00:13:53,360
science jargon for we don't know what

349
00:13:50,399 --> 00:13:55,760
the hell is going on. The good news is

350
00:13:53,360 --> 00:13:58,880
again Evo has an opinion about your

351
00:13:55,760 --> 00:14:01,600
mutation. And if you uh sort of uh feed

352
00:13:58,880 --> 00:14:03,920
in all the different uh known broco one

353
00:14:01,600 --> 00:14:06,240
mutations uh derived from ClinVar, a

354
00:14:03,920 --> 00:14:08,240
gold standard NIH database, you can see

355
00:14:06,240 --> 00:14:10,880
that EVO is state-of-the-art in

356
00:14:08,240 --> 00:14:13,440
classifying non-coding mutations and

357
00:14:10,880 --> 00:14:15,360
their effects on pathogenicity and it's

358
00:14:13,440 --> 00:14:19,120
nearly state-of-the-art for coding

359
00:14:15,360 --> 00:14:21,600
mutations as well. Intriguingly, EVO in

360
00:14:19,120 --> 00:14:23,680
training has only ever seen a single

361
00:14:21,600 --> 00:14:26,160
reference human genome whereas alpha

362
00:14:23,680 --> 00:14:29,360
missense from deep mind was trained

363
00:14:26,160 --> 00:14:30,800
explicitly on human genomic variation.

364
00:14:29,360 --> 00:14:32,720
So it's very interesting that it's

365
00:14:30,800 --> 00:14:35,839
actually able to learn to this degree of

366
00:14:32,720 --> 00:14:39,279
performance by seeing primate genomes,

367
00:14:35,839 --> 00:14:41,440
zebra fish, bacteria phage, sea elegance

368
00:14:39,279 --> 00:14:43,680
and so on. Um, and you know, now we're

369
00:14:41,440 --> 00:14:46,079
trying to inject the model with explicit

370
00:14:43,680 --> 00:14:48,959
information on rare and common genetic

371
00:14:46,079 --> 00:14:51,199
variation to see if we can make a single

372
00:14:48,959 --> 00:14:53,480
generalist state-of-the-art model across

373
00:14:51,199 --> 00:14:55,880
both coding and non-coding

374
00:14:53,480 --> 00:14:57,760
mutations. These were all zeros

375
00:14:55,880 --> 00:15:00,120
predictions, but it turns out the

376
00:14:57,760 --> 00:15:02,560
embeddings of the model, it's learned

377
00:15:00,120 --> 00:15:04,959
representations have actually deeper

378
00:15:02,560 --> 00:15:07,440
information about biology. And in fact

379
00:15:04,959 --> 00:15:09,120
by training a supervised classifier on

380
00:15:07,440 --> 00:15:10,720
top of the EVO embeddings you can

381
00:15:09,120 --> 00:15:12,639
actually bring it to state-of-the-art

382
00:15:10,720 --> 00:15:14,959
performance implying that you know

383
00:15:12,639 --> 00:15:16,880
simple kind of prompt engineering or

384
00:15:14,959 --> 00:15:20,000
steering the model in token space is

385
00:15:16,880 --> 00:15:21,760
only kind of one way to improve you know

386
00:15:20,000 --> 00:15:24,240
the you know genomic language model

387
00:15:21,760 --> 00:15:26,880
performance or insights.

388
00:15:24,240 --> 00:15:28,480
One of the common criticisms of these

389
00:15:26,880 --> 00:15:31,040
large language models is that they're

390
00:15:28,480 --> 00:15:33,839
blackbox right you know the models are

391
00:15:31,040 --> 00:15:35,920
learning something but what are we right

392
00:15:33,839 --> 00:15:37,720
and so there's a sub field of ML called

393
00:15:35,920 --> 00:15:39,839
meantinurp or mechanistic

394
00:15:37,720 --> 00:15:43,040
interpretability where you can try to

395
00:15:39,839 --> 00:15:45,920
break down neural circuits from these

396
00:15:43,040 --> 00:15:48,639
large neural networks into observable

397
00:15:45,920 --> 00:15:50,480
parts right and so there's a classic

398
00:15:48,639 --> 00:15:52,320
example in the field from anthropic

399
00:15:50,480 --> 00:15:55,839
which makes the claude series of models

400
00:15:52,320 --> 00:15:58,240
where they've broken down um clawed into

401
00:15:55,839 --> 00:16:00,800
these different semantic features. One

402
00:15:58,240 --> 00:16:03,199
of which famously corresponds to the

403
00:16:00,800 --> 00:16:04,720
concept the con semantic concept of a

404
00:16:03,199 --> 00:16:06,639
Golden Gate Bridge, right? And you can

405
00:16:04,720 --> 00:16:08,399
actually see across a whole bunch of

406
00:16:06,639 --> 00:16:10,759
different languages, these semantic

407
00:16:08,399 --> 00:16:13,920
features light up in the same

408
00:16:10,759 --> 00:16:16,320
place. If you ask Claude, you know, what

409
00:16:13,920 --> 00:16:18,160
is your physical form? It will sensibly

410
00:16:16,320 --> 00:16:20,959
tell you it doesn't have one. It's

411
00:16:18,160 --> 00:16:23,519
simply an AI. But if you clamped this

412
00:16:20,959 --> 00:16:26,240
Golden Gate Bridge feature to 10x its

413
00:16:23,519 --> 00:16:29,120
weight, it now becomes obsessed with the

414
00:16:26,240 --> 00:16:31,600
idea of bridges. I'm a famous suspension

415
00:16:29,120 --> 00:16:33,199
bridge. I'm the iconic bridge itself

416
00:16:31,600 --> 00:16:35,279
with its beautiful orange color and

417
00:16:33,199 --> 00:16:37,279
sweeping suspension cables. Right? If

418
00:16:35,279 --> 00:16:40,000
you try to prompt it to ask it to do

419
00:16:37,279 --> 00:16:41,920
math, uh to ask it, uh, you know, what

420
00:16:40,000 --> 00:16:43,519
you should cook tonight for dinner, it

421
00:16:41,920 --> 00:16:46,320
will tell you you should cook the Golden

422
00:16:43,519 --> 00:16:49,600
Gate Bridge, right? And so you can try

423
00:16:46,320 --> 00:16:51,440
to take this uh type of uh you know

424
00:16:49,600 --> 00:16:54,480
paradigm of breaking down this model

425
00:16:51,440 --> 00:16:56,399
into human observable parts which is uh

426
00:16:54,480 --> 00:16:57,839
you know called sparse autoenccoders

427
00:16:56,399 --> 00:17:01,360
where you can try to break down and

428
00:16:57,839 --> 00:17:05,039
interpret the model activations onto any

429
00:17:01,360 --> 00:17:07,919
language model um including EVO. I'll

430
00:17:05,039 --> 00:17:10,000
I'll first sort of note that EVO has

431
00:17:07,919 --> 00:17:12,559
never been trained with any explicit

432
00:17:10,000 --> 00:17:14,559
biological information. It's not it's

433
00:17:12,559 --> 00:17:17,799
unanotated. It's unsupervised. you've

434
00:17:14,559 --> 00:17:20,079
only asked it to do next nucleotide

435
00:17:17,799 --> 00:17:22,319
prediction. Intriguingly, when you lay

436
00:17:20,079 --> 00:17:24,720
out the E.coli genome here, because it's

437
00:17:22,319 --> 00:17:26,240
a circular genome, uh you can see a

438
00:17:24,720 --> 00:17:28,960
bunch of different semantic features

439
00:17:26,240 --> 00:17:30,799
lighting up at different locations

440
00:17:28,960 --> 00:17:33,200
across the E.coli genome. And what we

441
00:17:30,799 --> 00:17:35,280
found was that there was a a particular

442
00:17:33,200 --> 00:17:37,520
uh feature semantic feature that

443
00:17:35,280 --> 00:17:39,600
corresponds to the idea of proage

444
00:17:37,520 --> 00:17:41,760
sequences, right? And in fact, it's

445
00:17:39,600 --> 00:17:45,200
actually doing a really great job at

446
00:17:41,760 --> 00:17:47,120
finding the boundaries of these proage

447
00:17:45,200 --> 00:17:49,520
sequences, right? And so what the sort

448
00:17:47,120 --> 00:17:51,280
of classic binatic way to do this is to

449
00:17:49,520 --> 00:17:53,120
take all these different genes, blast

450
00:17:51,280 --> 00:17:55,760
them and try to figure out which ones

451
00:17:53,120 --> 00:17:57,520
match to a fage origin, right? Those

452
00:17:55,760 --> 00:17:59,120
are, you know, tools like faster and

453
00:17:57,520 --> 00:18:00,480
others where you try to, you know, call

454
00:17:59,120 --> 00:18:03,120
the boundaries. But the model somehow

455
00:18:00,480 --> 00:18:05,360
has just learned this bottoms up, right?

456
00:18:03,120 --> 00:18:08,559
And in fact these same proage features

457
00:18:05,360 --> 00:18:10,400
fire in the spacers of crisper repeat

458
00:18:08,559 --> 00:18:12,400
arrays right where in the process of

459
00:18:10,400 --> 00:18:14,640
crisper bacterial adaptive immunity

460
00:18:12,400 --> 00:18:16,799
these fingerprints are captured from

461
00:18:14,640 --> 00:18:18,640
invading bacteria phage into these

462
00:18:16,799 --> 00:18:21,360
repeat arrays and the model again has

463
00:18:18,640 --> 00:18:24,960
sort of managed to identify specifically

464
00:18:21,360 --> 00:18:26,720
these spacers that's foreign. So if you

465
00:18:24,960 --> 00:18:29,679
zoom in on a different part of the

466
00:18:26,720 --> 00:18:32,799
genome um you can find features that

467
00:18:29,679 --> 00:18:35,600
fire on other things like open reading

468
00:18:32,799 --> 00:18:39,200
frames, intergenic regions, transfer

469
00:18:35,600 --> 00:18:41,600
RNAs, ribosomal RNAs. Um but not just

470
00:18:39,200 --> 00:18:43,720
coding and non-coding features but also

471
00:18:41,600 --> 00:18:46,160
features like the secondary structure of

472
00:18:43,720 --> 00:18:47,919
proteins because proteins are of course

473
00:18:46,160 --> 00:18:50,320
embedded in the genome. And so you can

474
00:18:47,919 --> 00:18:53,200
see features that fire selectively on

475
00:18:50,320 --> 00:18:55,520
alpha helyses or beta sheets and uh you

476
00:18:53,200 --> 00:18:57,440
know kind of even in the context of kind

477
00:18:55,520 --> 00:18:59,760
of protein known protein protein

478
00:18:57,440 --> 00:19:01,840
interactions uh embedded inside of these

479
00:18:59,760 --> 00:19:04,400
functional operons. So that's all

480
00:19:01,840 --> 00:19:07,440
proarotic genomes. But if you moved and

481
00:19:04,400 --> 00:19:10,240
looked at ukareotic genomes, uh you can

482
00:19:07,440 --> 00:19:12,640
actually see in the human genome that in

483
00:19:10,240 --> 00:19:14,720
non-coding promoters upstream of a

484
00:19:12,640 --> 00:19:17,200
transcriptional start site, you can see

485
00:19:14,720 --> 00:19:19,760
that there are these motifs or semantic

486
00:19:17,200 --> 00:19:23,280
features that fire on uh these sequence

487
00:19:19,760 --> 00:19:25,360
motifs that correspond surprisingly to

488
00:19:23,280 --> 00:19:27,919
known transcription factor binding

489
00:19:25,360 --> 00:19:30,320
motifs, right? suggesting that the model

490
00:19:27,919 --> 00:19:32,120
may have some inkling about gene

491
00:19:30,320 --> 00:19:34,640
regulation or

492
00:19:32,120 --> 00:19:37,039
binding. You can also find features that

493
00:19:34,640 --> 00:19:40,480
correspond to ukareotic gene

494
00:19:37,039 --> 00:19:43,919
architecture like uh coding sequences,

495
00:19:40,480 --> 00:19:46,480
untransated regions, but not just the

496
00:19:43,919 --> 00:19:48,640
concept of exxons, but also the leading

497
00:19:46,480 --> 00:19:50,880
and lagging edge of exxons. So, it's

498
00:19:48,640 --> 00:19:52,559
able to find those boundaries. This same

499
00:19:50,880 --> 00:19:54,880
feature can be used to look at the human

500
00:19:52,559 --> 00:19:57,200
genome but also the woolly mammoth

501
00:19:54,880 --> 00:19:59,200
genome for example which was not seen in

502
00:19:57,200 --> 00:20:01,360
pre-training showing some sense of

503
00:19:59,200 --> 00:20:02,880
generality of of these types of coding

504
00:20:01,360 --> 00:20:05,280
features.

505
00:20:02,880 --> 00:20:07,520
Macintob can also be used to look at

506
00:20:05,280 --> 00:20:10,080
computer code, right? And it can find

507
00:20:07,520 --> 00:20:11,559
errors in computer code. Um, you know,

508
00:20:10,080 --> 00:20:14,400
like mine is riddled with it, for

509
00:20:11,559 --> 00:20:16,400
example. Uh, you know, you can also find

510
00:20:14,400 --> 00:20:18,200
errors in the genetic code and there

511
00:20:16,400 --> 00:20:21,600
there are features that seem to fight

512
00:20:18,200 --> 00:20:24,200
preferentially on frame shift mutations

513
00:20:21,600 --> 00:20:26,960
um and not on, for example, synonymous

514
00:20:24,200 --> 00:20:29,919
mutations. Um and so you know we're very

515
00:20:26,960 --> 00:20:32,320
intrigued by you know the um

516
00:20:29,919 --> 00:20:34,720
opportunities here to try to understand

517
00:20:32,320 --> 00:20:36,400
and you know mechanistically interpret

518
00:20:34,720 --> 00:20:38,320
something about how these language

519
00:20:36,400 --> 00:20:41,120
models are learning about biological

520
00:20:38,320 --> 00:20:43,600
features not just for classic well-known

521
00:20:41,120 --> 00:20:45,840
features like I've shown you so far but

522
00:20:43,600 --> 00:20:48,880
potentially to discover here to for

523
00:20:45,840 --> 00:20:50,880
unknown things about the genome in

524
00:20:48,880 --> 00:20:53,360
addition to breaking down the model into

525
00:20:50,880 --> 00:20:56,559
these human parts again you can try to

526
00:20:53,360 --> 00:20:59,039
use it for generation And we tested EVO

527
00:20:56,559 --> 00:21:01,360
in three different generation tasks to

528
00:20:59,039 --> 00:21:04,200
try to make mitochondrial genomes, whole

529
00:21:01,360 --> 00:21:06,720
bacterial genomes or entire ukareotic

530
00:21:04,200 --> 00:21:08,480
chromosomes. So if you wanted to make a

531
00:21:06,720 --> 00:21:10,880
mitochondrial genome, which you of

532
00:21:08,480 --> 00:21:13,440
course we all have, right? You can see

533
00:21:10,880 --> 00:21:16,000
our version lined up here in the middle

534
00:21:13,440 --> 00:21:19,280
of the slide in a dashed box, right?

535
00:21:16,000 --> 00:21:21,520
Here are six evoggenerated mitochondrial

536
00:21:19,280 --> 00:21:23,919
genomes. And what you'll see is that

537
00:21:21,520 --> 00:21:26,240
it's not simply memorizing and

538
00:21:23,919 --> 00:21:28,080
regurgitating your mitochondrial genome.

539
00:21:26,240 --> 00:21:30,559
In fact, sometimes it'll, you know, kind

540
00:21:28,080 --> 00:21:32,919
of flip the orientation of genes or

541
00:21:30,559 --> 00:21:35,440
shift them around slightly. But

542
00:21:32,919 --> 00:21:37,360
importantly, it keeps all of the core

543
00:21:35,440 --> 00:21:40,320
genes that are in the mitochondrial

544
00:21:37,360 --> 00:21:42,159
genome and it preserves all of the key

545
00:21:40,320 --> 00:21:44,480
protein protein interactions. for

546
00:21:42,159 --> 00:21:47,440
example, the core subunits of complex

547
00:21:44,480 --> 00:21:50,080
one of this uh encoded mitochondrial

548
00:21:47,440 --> 00:21:53,120
electron transport chain.

549
00:21:50,080 --> 00:21:54,960
You can also generate uh uh you know

550
00:21:53,120 --> 00:21:58,159
things that look like entire bacterial

551
00:21:54,960 --> 00:22:01,120
genomes like the minimal uh sort of

552
00:21:58,159 --> 00:22:04,320
species myopplasma genitalium and so you

553
00:22:01,120 --> 00:22:07,440
can see with EVO one right and so here

554
00:22:04,320 --> 00:22:10,000
we're showing you in blue pam hits to

555
00:22:07,440 --> 00:22:12,159
you know the known uh sort of database

556
00:22:10,000 --> 00:22:14,480
and then you can see that you know EVO1

557
00:22:12,159 --> 00:22:16,640
generations were you know missing a lot

558
00:22:14,480 --> 00:22:18,240
of you know kind of these known proteins

559
00:22:16,640 --> 00:22:20,240
but this actually you know kind of

560
00:22:18,240 --> 00:22:23,440
significantly improves improves with EVO

561
00:22:20,240 --> 00:22:26,240
2. And to me, this kind of recalls the

562
00:22:23,440 --> 00:22:28,320
improvements in scaling of these image

563
00:22:26,240 --> 00:22:31,520
generation models where if you're trying

564
00:22:28,320 --> 00:22:34,559
to make this sort of this kangaroo in a

565
00:22:31,520 --> 00:22:35,919
hoodie with a welcome friends sign, you

566
00:22:34,559 --> 00:22:37,760
know, sort of the early version of the

567
00:22:35,919 --> 00:22:39,480
MA model gives you something that looks

568
00:22:37,760 --> 00:22:42,720
like something on the street of San

569
00:22:39,480 --> 00:22:45,360
Francisco, right? The the the sign is

570
00:22:42,720 --> 00:22:47,840
kind of unintelligible. It's not that

571
00:22:45,360 --> 00:22:50,880
cool. It looks a little sad, right? And

572
00:22:47,840 --> 00:22:53,520
you know the hope is right with EVO 3

573
00:22:50,880 --> 00:22:56,520
and EVO 4 and so on right we'll be able

574
00:22:53,520 --> 00:22:59,520
to go from these you know slightly

575
00:22:56,520 --> 00:23:01,600
sharper understandings of the genome to

576
00:22:59,520 --> 00:23:03,919
something that could potentially be

577
00:23:01,600 --> 00:23:06,080
synthesized and tested directly inside

578
00:23:03,919 --> 00:23:08,240
of living cells. I think you can already

579
00:23:06,080 --> 00:23:09,760
do so in a few shot manner. The goal is

580
00:23:08,240 --> 00:23:10,840
you know to one day be able to do this

581
00:23:09,760 --> 00:23:14,240
uh more

582
00:23:10,840 --> 00:23:16,480
zeroot. Um this extends to ukarotic

583
00:23:14,240 --> 00:23:18,159
chromosomes as well. But you know, one

584
00:23:16,480 --> 00:23:20,640
of the things that we're often asked

585
00:23:18,159 --> 00:23:22,799
with genome language models is, hey,

586
00:23:20,640 --> 00:23:26,240
this is cool. You can embed DNA, I

587
00:23:22,799 --> 00:23:29,200
guess, but what about epigenetics and

588
00:23:26,240 --> 00:23:31,520
what about RNA? And uh you know so so we

589
00:23:29,200 --> 00:23:34,640
try to you know kind of answer some of

590
00:23:31,520 --> 00:23:37,600
those questions where you can take this

591
00:23:34,640 --> 00:23:39,440
generative model a DNA model like EVO

592
00:23:37,600 --> 00:23:41,280
and try to actually score its

593
00:23:39,440 --> 00:23:43,360
generations with a model like an

594
00:23:41,280 --> 00:23:46,559
informer or boro which has been

595
00:23:43,360 --> 00:23:49,520
explicitly trained on things like DHS or

596
00:23:46,559 --> 00:23:52,720
chipsseek data and uh you can basically

597
00:23:49,520 --> 00:23:56,000
score these EVO generations based on

598
00:23:52,720 --> 00:23:59,280
predicted chromatin accessibility right

599
00:23:56,000 --> 00:24:02,080
and so in this uh uh in a sort of design

600
00:23:59,280 --> 00:24:05,760
task. You can try to ask the model to

601
00:24:02,080 --> 00:24:08,799
conform to user specified peaks, wide

602
00:24:05,760 --> 00:24:11,200
attack seek peaks or narrow attack seek

603
00:24:08,799 --> 00:24:14,799
peaks for example and by adding more

604
00:24:11,200 --> 00:24:17,279
compute into the model at uh generation

605
00:24:14,799 --> 00:24:21,120
time. What you can see is that the model

606
00:24:17,279 --> 00:24:24,400
over time with more thinking is able to

607
00:24:21,120 --> 00:24:26,480
try to generate sequences that fit these

608
00:24:24,400 --> 00:24:29,200
user design patterns with higher

609
00:24:26,480 --> 00:24:33,440
fidelity. Right? The fun thing is that

610
00:24:29,200 --> 00:24:36,400
you can encode information uh in these

611
00:24:33,440 --> 00:24:39,200
attack peaks like dots and dashes and

612
00:24:36,400 --> 00:24:42,480
write Morse code messages like ARC or

613
00:24:39,200 --> 00:24:44,400
EVO 2. And now we're installing these uh

614
00:24:42,480 --> 00:24:46,480
directly into the genomes of living

615
00:24:44,400 --> 00:24:49,200
cells and doing real attack seek on them

616
00:24:46,480 --> 00:24:52,039
to see if we're able to make those uh

617
00:24:49,200 --> 00:24:54,480
you know actual uh

618
00:24:52,039 --> 00:24:56,000
patterns. I'll sort of uh you know kind

619
00:24:54,480 --> 00:24:58,480
of motivate that I think this is

620
00:24:56,000 --> 00:25:01,279
actually very general and it's not just

621
00:24:58,480 --> 00:25:03,600
uh you know an epigenome structure

622
00:25:01,279 --> 00:25:05,760
scoring function but it could be you

623
00:25:03,600 --> 00:25:08,960
know really any generic sequence to

624
00:25:05,760 --> 00:25:11,360
function predictor that you hook on top

625
00:25:08,960 --> 00:25:13,840
of a generative model in order to be

626
00:25:11,360 --> 00:25:16,960
able to design you know more complex

627
00:25:13,840 --> 00:25:19,520
representations of biology. We think of

628
00:25:16,960 --> 00:25:22,440
this as a foundational model because it

629
00:25:19,520 --> 00:25:25,679
enables this app store of

630
00:25:22,440 --> 00:25:27,520
different applications across different

631
00:25:25,679 --> 00:25:29,679
modalities of the central dogma all the

632
00:25:27,520 --> 00:25:32,000
way up to entire seller and organismal

633
00:25:29,679 --> 00:25:34,159
scale tasks. We've shown a few examples

634
00:25:32,000 --> 00:25:36,320
of that in this study and we hope you

635
00:25:34,159 --> 00:25:38,559
know the community will be able to kind

636
00:25:36,320 --> 00:25:41,520
of build many more. Right? This is a

637
00:25:38,559 --> 00:25:43,919
fully open source model and by by fully

638
00:25:41,520 --> 00:25:47,120
open source I mean the pre-training data

639
00:25:43,919 --> 00:25:49,120
the pre-training infra and all the model

640
00:25:47,120 --> 00:25:51,279
weights are fully available the code is

641
00:25:49,120 --> 00:25:53,840
on GitHub the models hosted on hugging

642
00:25:51,279 --> 00:25:55,840
face um we have a front end called EVO

643
00:25:53,840 --> 00:25:58,720
designer which you can use to prompt and

644
00:25:55,840 --> 00:26:01,279
interpret model outputs blast sequences

645
00:25:58,720 --> 00:26:03,679
do structure prediction of the embedded

646
00:26:01,279 --> 00:26:05,520
proteins and so on and so you know we've

647
00:26:03,679 --> 00:26:07,120
been really delighted by the initial

648
00:26:05,520 --> 00:26:09,039
reception and lots of folks who are

649
00:26:07,120 --> 00:26:11,919
building with and I hope you guys do

650
00:26:09,039 --> 00:26:14,320
too. Um, I'll just sort of end by

651
00:26:11,919 --> 00:26:16,400
saying, you know, uh, you know, the

652
00:26:14,320 --> 00:26:19,279
these these models that learn, you know,

653
00:26:16,400 --> 00:26:21,440
on massive scales of DNA are just the

654
00:26:19,279 --> 00:26:23,039
beginning, right? And so, you know,

655
00:26:21,440 --> 00:26:25,360
we're very excited about ways that you

656
00:26:23,039 --> 00:26:28,320
can improve the quality of the model

657
00:26:25,360 --> 00:26:30,320
predictions and generations by uh, you

658
00:26:28,320 --> 00:26:33,120
know, kind of uh, doing lab in the loop

659
00:26:30,320 --> 00:26:36,919
with experimental feedback. And our hope

660
00:26:33,120 --> 00:26:39,440
is that by taking the ability to compose

661
00:26:36,919 --> 00:26:41,440
DNA combined with the programmable

662
00:26:39,440 --> 00:26:44,320
recominases that we reported from the

663
00:26:41,440 --> 00:26:47,440
lab last year, we'll be able to install,

664
00:26:44,320 --> 00:26:49,520
you know, kind of uh DNA directly inside

665
00:26:47,440 --> 00:26:51,520
of living cells that's been programmed

666
00:26:49,520 --> 00:26:53,679
at a higher level of abstraction than

667
00:26:51,520 --> 00:26:55,679
the sort of uh few bases that we're able

668
00:26:53,679 --> 00:26:57,360
to edit in the modern gene editing

669
00:26:55,679 --> 00:27:00,640
paradigm. Something that we're we're

670
00:26:57,360 --> 00:27:02,720
really thinking of as genome design.

671
00:27:00,640 --> 00:27:04,000
Um, you know, so I I'll just sort of end

672
00:27:02,720 --> 00:27:05,840
by saying, you know, I think scientific

673
00:27:04,000 --> 00:27:07,200
discovery is often a search problem,

674
00:27:05,840 --> 00:27:08,960
right? You know, as we all know, you

675
00:27:07,200 --> 00:27:10,799
kind of have to kind of guess and check,

676
00:27:08,960 --> 00:27:13,440
right? Where we have multiple scientific

677
00:27:10,799 --> 00:27:16,240
hypotheses and you need to recursively

678
00:27:13,440 --> 00:27:18,000
test them to see what's going on, right?

679
00:27:16,240 --> 00:27:20,559
Um, and you know, the problem is that

680
00:27:18,000 --> 00:27:22,000
this is very confusing, right? And it

681
00:27:20,559 --> 00:27:23,840
kind of feels like when you're a kid and

682
00:27:22,000 --> 00:27:26,240
you look at the night sky and you're

683
00:27:23,840 --> 00:27:28,720
trying to find that constellation, uh,

684
00:27:26,240 --> 00:27:30,640
where is the Big Dipper? And, you know,

685
00:27:28,720 --> 00:27:32,400
you have no idea. And what you really

686
00:27:30,640 --> 00:27:34,720
want is something that's much more like

687
00:27:32,400 --> 00:27:36,600
a co-pilot like the night sky app that

688
00:27:34,720 --> 00:27:40,320
could tell you where the constellations

689
00:27:36,600 --> 00:27:42,559
are across space and also at different

690
00:27:40,320 --> 00:27:43,919
points in time. Right? This is really,

691
00:27:42,559 --> 00:27:46,240
you know, kind of how biology is

692
00:27:43,919 --> 00:27:48,799
orchestrated across space and time. And

693
00:27:46,240 --> 00:27:50,799
so one of the things that is a flagship

694
00:27:48,799 --> 00:27:53,120
initiative of ours at ARC is to build

695
00:27:50,799 --> 00:27:55,840
these virtual cells that are able to

696
00:27:53,120 --> 00:27:58,080
model not just inputs of universal

697
00:27:55,840 --> 00:28:00,559
genome representations like I showed you

698
00:27:58,080 --> 00:28:02,480
today but also uh inputs from the

699
00:28:00,559 --> 00:28:03,840
environment where genotype and the

700
00:28:02,480 --> 00:28:06,559
environmental representations

701
00:28:03,840 --> 00:28:08,960
collaborate to create uh you know better

702
00:28:06,559 --> 00:28:12,320
predictions of phenotype. We're doing

703
00:28:08,960 --> 00:28:15,440
this across a variety of different uh

704
00:28:12,320 --> 00:28:18,559
tasks uh including uh curating public

705
00:28:15,440 --> 00:28:20,559
data with AI agents where we recently uh

706
00:28:18,559 --> 00:28:23,120
released the world's largest repository

707
00:28:20,559 --> 00:28:27,200
of single cell data by actually creating

708
00:28:23,120 --> 00:28:30,240
an agentic crawler over all of NCBI SR

709
00:28:27,200 --> 00:28:31,919
and uh taking kind of unstructured data

710
00:28:30,240 --> 00:28:34,640
sets being contributed across the

711
00:28:31,919 --> 00:28:37,919
community uh to uh generate over 400

712
00:28:34,640 --> 00:28:40,000
million cells. Um we're also uh you know

713
00:28:37,919 --> 00:28:42,640
in house generating uh you know

714
00:28:40,000 --> 00:28:45,279
perturbational data and then uh you know

715
00:28:42,640 --> 00:28:48,480
setting up the eval benchmarks and uh

716
00:28:45,279 --> 00:28:49,600
novel uh algorithms to try to you know

717
00:28:48,480 --> 00:28:51,279
kind of understand these cell

718
00:28:49,600 --> 00:28:53,760
representations.

719
00:28:51,279 --> 00:28:55,200
So, you know, I I I though I'll sort of,

720
00:28:53,760 --> 00:28:56,880
you know, just say I I hope I've

721
00:28:55,200 --> 00:28:58,960
convinced you today that, you know, in

722
00:28:56,880 --> 00:29:01,200
in the community, we we kind of have a

723
00:28:58,960 --> 00:29:02,960
piece the pieces to try to close this

724
00:29:01,200 --> 00:29:06,480
conceptual touring loop, right, which

725
00:29:02,960 --> 00:29:08,159
was first proposed in 1936 by the, you

726
00:29:06,480 --> 00:29:09,919
know, kind of, you know, Alan Turing,

727
00:29:08,159 --> 00:29:13,520
the computer scientist, where, you know,

728
00:29:09,919 --> 00:29:15,279
if you had a machine that can read, you

729
00:29:13,520 --> 00:29:17,120
know, kind of compute and then write

730
00:29:15,279 --> 00:29:19,200
back to tape, you could in principle

731
00:29:17,120 --> 00:29:21,600
implement any computable algorithm. And

732
00:29:19,200 --> 00:29:23,440
by digitizing biological states, you

733
00:29:21,600 --> 00:29:25,520
know, thinking about it and writing it

734
00:29:23,440 --> 00:29:28,320
back into cells, right, we can start to

735
00:29:25,520 --> 00:29:31,120
close this analogous touring loop uh for

736
00:29:28,320 --> 00:29:33,200
biology. Um, you know, this has been,

737
00:29:31,120 --> 00:29:36,480
you know, really wonderful uh, you know,

738
00:29:33,200 --> 00:29:39,279
series of collaborations um, across ARC

739
00:29:36,480 --> 00:29:42,720
with Brian Heath, Evo 1 was led by Eric

740
00:29:39,279 --> 00:29:45,200
Newan, Matt Durant, Brian Kang, Duva

741
00:29:42,720 --> 00:29:47,279
Katrickar, David Lee, and Michael Pauly.

742
00:29:45,200 --> 00:29:50,799
and uh you know uh many folks uh

743
00:29:47,279 --> 00:29:53,120
contributed to uh EVO2 across ARC our

744
00:29:50,799 --> 00:29:54,720
partner Nvidia uh university

745
00:29:53,120 --> 00:29:56,559
collaborators uh and industry

746
00:29:54,720 --> 00:29:58,640
collaborators like goodfire for our

747
00:29:56,559 --> 00:30:00,159
mechanistic interpretability work so

748
00:29:58,640 --> 00:30:01,150
yeah thanks so much I'm delighted to

749
00:30:00,159 --> 00:30:05,320
take

750
00:30:01,150 --> 00:30:09,600
[Applause]

751
00:30:05,320 --> 00:30:09,600
questions thank you so much

752
00:30:12,840 --> 00:30:18,399
questions thank you for a Great talk. So

753
00:30:15,760 --> 00:30:20,480
I think a lot about uh what information

754
00:30:18,399 --> 00:30:22,320
that might be spatially encoded in

755
00:30:20,480 --> 00:30:24,799
biological system that might not be

756
00:30:22,320 --> 00:30:27,520
encoded by sequence for example. So have

757
00:30:24,799 --> 00:30:29,360
you encountered any tasks where your

758
00:30:27,520 --> 00:30:31,120
model just cannot predict it and you

759
00:30:29,360 --> 00:30:33,120
think that it's actually because you

760
00:30:31,120 --> 00:30:35,200
don't have that three-dimensional

761
00:30:33,120 --> 00:30:37,039
information of the the fold of the DNA

762
00:30:35,200 --> 00:30:39,120
for example or do you have any such

763
00:30:37,039 --> 00:30:41,039
examples where you think that you'd need

764
00:30:39,120 --> 00:30:43,840
to encode spatial information better in

765
00:30:41,039 --> 00:30:45,520
order to perform? I think a lot right uh

766
00:30:43,840 --> 00:30:47,679
thank you for that question and I I

767
00:30:45,520 --> 00:30:50,080
think you know embedded in your question

768
00:30:47,679 --> 00:30:52,880
uh no pun intended is the question of

769
00:30:50,080 --> 00:30:54,640
what is a virtual cell right and you

770
00:30:52,880 --> 00:30:56,480
know I think it's the word that's in the

771
00:30:54,640 --> 00:30:58,240
zeitgeist today and lots of folks are

772
00:30:56,480 --> 00:31:02,159
talking about it but it's actually very

773
00:30:58,240 --> 00:31:05,120
poorly defined right and I think uh with

774
00:31:02,159 --> 00:31:07,440
with both EVO and EVO 2 we had to work

775
00:31:05,120 --> 00:31:10,080
really hard to actually just invent eval

776
00:31:07,440 --> 00:31:12,480
from scratch um that would be

777
00:31:10,080 --> 00:31:14,320
quantitative for the ML and comp bio

778
00:31:12,480 --> 00:31:16,480
community and also I think like

779
00:31:14,320 --> 00:31:18,799
conceptually interesting to the wet lab

780
00:31:16,480 --> 00:31:20,640
community in a way that folks would feel

781
00:31:18,799 --> 00:31:22,480
that these are actually useful tasks

782
00:31:20,640 --> 00:31:24,640
that I would actually care about if

783
00:31:22,480 --> 00:31:26,240
there was no AI involved whatsoever

784
00:31:24,640 --> 00:31:27,760
right and I think we'll we'll need to be

785
00:31:26,240 --> 00:31:29,200
able to do that for these single cell

786
00:31:27,760 --> 00:31:31,760
foundation models and also for the

787
00:31:29,200 --> 00:31:33,919
spatial ones right so you know I mean

788
00:31:31,760 --> 00:31:36,000
complex questions like you know

789
00:31:33,919 --> 00:31:38,320
dendritic cell activation in the tumor

790
00:31:36,000 --> 00:31:40,559
micro environment right or you know some

791
00:31:38,320 --> 00:31:42,559
sort of quorum behavior are the kinds of

792
00:31:40,559 --> 00:31:45,279
things that I think single cell models

793
00:31:42,559 --> 00:31:46,960
alone are unlikely to capture accurately

794
00:31:45,279 --> 00:31:49,760
and spatial data of course will be

795
00:31:46,960 --> 00:31:53,279
important and I think you know um you

796
00:31:49,760 --> 00:31:56,159
know like multi-scale models of biology

797
00:31:53,279 --> 00:31:58,480
right um you know biological scale span

798
00:31:56,159 --> 00:32:00,240
from atoms to ecosystems right and I

799
00:31:58,480 --> 00:32:04,000
think we'll have different modeling

800
00:32:00,240 --> 00:32:05,519
types or paradigms that will indep

801
00:32:04,000 --> 00:32:07,600
independently get developed and get

802
00:32:05,519 --> 00:32:09,360
unified over time we have these all atom

803
00:32:07,600 --> 00:32:11,519
diffusion models today that are trying

804
00:32:09,360 --> 00:32:13,600
to do structure and ligan docking we

805
00:32:11,519 --> 00:32:16,080
have these sequence to function models

806
00:32:13,600 --> 00:32:18,640
and then we have these ways of trying to

807
00:32:16,080 --> 00:32:20,880
you know embed natural language and EHR

808
00:32:18,640 --> 00:32:22,480
information and you know I think right

809
00:32:20,880 --> 00:32:25,039
now they're being developed somewhat

810
00:32:22,480 --> 00:32:27,360
independently I think with EVO what we

811
00:32:25,039 --> 00:32:29,840
saw was that there were protein and RNA

812
00:32:27,360 --> 00:32:32,320
and codon and whatsoever language models

813
00:32:29,840 --> 00:32:34,880
we tried to collapse them into a single

814
00:32:32,320 --> 00:32:37,279
uh paradigm by modeling genomes alone I

815
00:32:34,880 --> 00:32:39,360
think conceptually analogous ways of

816
00:32:37,279 --> 00:32:42,960
collapsing these other types of models

817
00:32:39,360 --> 00:32:44,720
um over time will also be needed.

818
00:32:42,960 --> 00:32:46,240
Thank you so much Patrick for the

819
00:32:44,720 --> 00:32:47,679
amazing talk. We unfortunately have to

820
00:32:46,240 --> 00:32:52,039
move on for the sake of time but thank

821
00:32:47,679 --> 00:32:52,039
you. Let's thank Patrick again.


1
00:00:03,679 --> 00:00:07,839
My name is Lauren Golden, not to be

2
00:00:05,359 --> 00:00:11,519
confused with one of our speakers today.

3
00:00:07,839 --> 00:00:13,360
Um, I'm one of the co-chairs of the MIA,

4
00:00:11,519 --> 00:00:15,599
the models, inference, and algorithms,

5
00:00:13,360 --> 00:00:17,359
uh, seminar series here at the Broad in

6
00:00:15,599 --> 00:00:19,199
the Eric and Wendy Schmidt Center. Uh,

7
00:00:17,359 --> 00:00:23,039
and it's my pleasure to, I guess, kick

8
00:00:19,199 --> 00:00:26,560
off a new semester of MIA talks. Uh I'm

9
00:00:23,039 --> 00:00:28,880
really excited here to um I know start a

10
00:00:26,560 --> 00:00:32,079
new a new semester here, a new you know

11
00:00:28,880 --> 00:00:35,040
a new academic year. Uh and I think it's

12
00:00:32,079 --> 00:00:36,399
going to be a really good time. Um we

13
00:00:35,040 --> 00:00:38,320
have a lot of interesting talks lined up

14
00:00:36,399 --> 00:00:41,520
this semester and going to be continuing

15
00:00:38,320 --> 00:00:44,480
on into the the spring as well. Uh we

16
00:00:41,520 --> 00:00:46,239
have uh our first set of speakers here

17
00:00:44,480 --> 00:00:47,840
and I'm gonna have Sebastiano introduce

18
00:00:46,239 --> 00:00:49,520
them as our host today.

19
00:00:47,840 --> 00:00:51,039
>> Hi, good morning. I'm Sebastiano

20
00:00:49,520 --> 00:00:53,440
post-docctoral fellow here at the Eric

21
00:00:51,039 --> 00:00:55,440
and Wendy Schmidt Center. So, welcome if

22
00:00:53,440 --> 00:00:57,600
you've not been to the MIA talks before.

23
00:00:55,440 --> 00:01:00,480
Uh there are two talks today. One from 9

24
00:00:57,600 --> 00:01:03,280
to 10 by David and another one from 10

25
00:01:00,480 --> 00:01:04,720
to 11 by Lauren. Um it's an interactive

26
00:01:03,280 --> 00:01:06,240
meeting. So if you feel like you have a

27
00:01:04,720 --> 00:01:07,280
question, uh raise your hand. I'm going

28
00:01:06,240 --> 00:01:08,880
to come around and give you the

29
00:01:07,280 --> 00:01:10,159
microphone. It's important you ask the

30
00:01:08,880 --> 00:01:13,600
question in the microphone for people

31
00:01:10,159 --> 00:01:15,760
online. Um and yeah, I think that's it.

32
00:01:13,600 --> 00:01:18,400
So usually, so essentially always the

33
00:01:15,760 --> 00:01:19,759
seminar runs on uh Wednesday. Next week

34
00:01:18,400 --> 00:01:21,920
actually it's an exception where the

35
00:01:19,759 --> 00:01:25,680
seminar will be run on Friday in the

36
00:01:21,920 --> 00:01:27,920
broad auditorium in the first floor. Um

37
00:01:25,680 --> 00:01:30,560
yeah so without further ado I think we

38
00:01:27,920 --> 00:01:32,240
can let David speak. So Davidid is a

39
00:01:30,560 --> 00:01:34,960
grad student at the poly techchnic of

40
00:01:32,240 --> 00:01:37,520
terin in Italy. Um he conducted a

41
00:01:34,960 --> 00:01:38,720
research stay at MIT last year for six

42
00:01:37,520 --> 00:01:40,240
months where he started collaborating

43
00:01:38,720 --> 00:01:41,840
with Lauren and with the Xvivo group

44
00:01:40,240 --> 00:01:44,560
more generally. Lauren will say a few

45
00:01:41,840 --> 00:01:45,840
words about that later. um and uh he's

46
00:01:44,560 --> 00:01:48,320
interested in deep learning both

47
00:01:45,840 --> 00:01:49,680
theoretical and more applied. Today he's

48
00:01:48,320 --> 00:01:52,799
going to cover more the applied side of

49
00:01:49,680 --> 00:01:54,079
it. Um and the title of his talk is up

50
00:01:52,799 --> 00:01:56,640
there infrastructure and modeling

51
00:01:54,079 --> 00:01:57,759
challenges in single cell omic. Um the

52
00:01:56,640 --> 00:01:59,439
floor is yours.

53
00:01:57,759 --> 00:02:01,360
>> Thank you. Thank you very much for the

54
00:01:59,439 --> 00:02:04,960
introduction. So thank you all of you

55
00:02:01,360 --> 00:02:06,560
for being here. Um yeah before before

56
00:02:04,960 --> 00:02:08,479
starting I want to thanks like my

57
00:02:06,560 --> 00:02:10,319
collaborators with which this work

58
00:02:08,479 --> 00:02:12,400
wouldn't be possible. There is Seb,

59
00:02:10,319 --> 00:02:14,720
Peton, Shri from the broad institute and

60
00:02:12,400 --> 00:02:17,520
Lauren Nava from Microsoft research. So

61
00:02:14,720 --> 00:02:21,040
these works have been done with them. Um

62
00:02:17,520 --> 00:02:22,959
so what I I will be talking about is um

63
00:02:21,040 --> 00:02:26,800
one infrastructure challenge that we

64
00:02:22,959 --> 00:02:29,760
will we have seen in deep learning for u

65
00:02:26,800 --> 00:02:31,680
single salomics and in particular about

66
00:02:29,760 --> 00:02:33,200
data loading and so I will present our

67
00:02:31,680 --> 00:02:35,360
solution which is called SC data set

68
00:02:33,200 --> 00:02:38,160
like to overcome this problem and this

69
00:02:35,360 --> 00:02:39,760
like then I will give I will do like a

70
00:02:38,160 --> 00:02:41,599
small break if you have like questions

71
00:02:39,760 --> 00:02:44,000
about this first part or even like

72
00:02:41,599 --> 00:02:45,840
interrupt me at any point and then I

73
00:02:44,000 --> 00:02:47,519
will be talking more like about uh

74
00:02:45,840 --> 00:02:49,360
modeling challenge. and I will present

75
00:02:47,519 --> 00:02:51,760
hierarchical version of across entropy

76
00:02:49,360 --> 00:02:53,200
loss for cell type annotation and then

77
00:02:51,760 --> 00:02:55,280
after that I will leave the stage to

78
00:02:53,200 --> 00:02:57,920
Lauren that will talk among other things

79
00:02:55,280 --> 00:03:00,160
about um how the size of the data and

80
00:02:57,920 --> 00:03:04,400
the type type of data can influence the

81
00:03:00,160 --> 00:03:07,360
training of um deep learning uh models.

82
00:03:04,400 --> 00:03:09,200
So why deep learning and I think the

83
00:03:07,360 --> 00:03:10,640
reason is uh we have seen in the recent

84
00:03:09,200 --> 00:03:13,120
years that deep learning is

85
00:03:10,640 --> 00:03:14,879
revolutionizing any field for example

86
00:03:13,120 --> 00:03:16,560
computer vision and now natural language

87
00:03:14,879 --> 00:03:18,560
processing. I think all of us it's

88
00:03:16,560 --> 00:03:20,800
basically using a chatbot at at a

89
00:03:18,560 --> 00:03:22,239
certain point during the day and we have

90
00:03:20,800 --> 00:03:24,640
seen deep learning also uh

91
00:03:22,239 --> 00:03:26,800
revolutionizing biology. We've seen uh

92
00:03:24,640 --> 00:03:29,120
with alpha fold and now we bolt uh

93
00:03:26,800 --> 00:03:30,799
protein structure prediction protein

94
00:03:29,120 --> 00:03:32,879
binding and all this kind of stuff.

95
00:03:30,799 --> 00:03:36,560
We've seen that we have a models for

96
00:03:32,879 --> 00:03:40,400
that now can uh process like the whole

97
00:03:36,560 --> 00:03:42,560
uh DNA sequences. And so the natural

98
00:03:40,400 --> 00:03:45,040
question is like can we expect the same

99
00:03:42,560 --> 00:03:46,959
stuff on single cell omics in particular

100
00:03:45,040 --> 00:03:48,799
we will talk in all examples about

101
00:03:46,959 --> 00:03:51,200
single cell

102
00:03:48,799 --> 00:03:53,360
but most of the things will apply to any

103
00:03:51,200 --> 00:03:55,760
kind of single salomics that we will

104
00:03:53,360 --> 00:03:57,680
that you can think of and the real

105
00:03:55,760 --> 00:04:00,560
question is why we don't have something

106
00:03:57,680 --> 00:04:02,879
so powerful on single salomics yet and I

107
00:04:00,560 --> 00:04:04,799
will try to give like two answers to

108
00:04:02,879 --> 00:04:07,680
like two of the problems that we might

109
00:04:04,799 --> 00:04:09,920
have in in this field and so the first

110
00:04:07,680 --> 00:04:13,040
one is what I call an infrastructure

111
00:04:09,920 --> 00:04:14,879
challenge and to talk about this um

112
00:04:13,040 --> 00:04:17,040
there there is a like a brief background

113
00:04:14,879 --> 00:04:19,040
which is on on the fact that we are

114
00:04:17,040 --> 00:04:20,639
using we will be talking about Python

115
00:04:19,040 --> 00:04:22,479
and PyTorch because this is basically

116
00:04:20,639 --> 00:04:24,479
the standard for deep learning and also

117
00:04:22,479 --> 00:04:27,520
we have a good suite of tools for like

118
00:04:24,479 --> 00:04:30,080
doing data analysis on on genomics data

119
00:04:27,520 --> 00:04:32,800
and on um computational bi biological

120
00:04:30,080 --> 00:04:34,800
data and so we have scampy SCVI tools

121
00:04:32,800 --> 00:04:37,600
which is a set of like um probabilistic

122
00:04:34,800 --> 00:04:40,400
models so Python is is a really nice

123
00:04:37,600 --> 00:04:42,720
scenario and in particular the de the

124
00:04:40,400 --> 00:04:44,800
developers of this like uh consortium of

125
00:04:42,720 --> 00:04:47,520
tools have developed this data format

126
00:04:44,800 --> 00:04:49,199
which is called the undata format uh

127
00:04:47,520 --> 00:04:51,440
that is very handy to have annotated

128
00:04:49,199 --> 00:04:54,880
data. So you have the x matrix which for

129
00:04:51,440 --> 00:04:56,880
example in sia seek represents uh the

130
00:04:54,880 --> 00:04:59,040
expressed genes per each cell and then

131
00:04:56,880 --> 00:05:01,520
you can annotate with like information

132
00:04:59,040 --> 00:05:04,160
about the cells information about the

133
00:05:01,520 --> 00:05:06,400
genes and so forth so on and it has some

134
00:05:04,160 --> 00:05:08,320
nice properties. It it supports like

135
00:05:06,400 --> 00:05:10,800
sparse cell by gene matrices which is

136
00:05:08,320 --> 00:05:12,560
usually the case for single cellic data.

137
00:05:10,800 --> 00:05:14,960
So we will have just a very small

138
00:05:12,560 --> 00:05:17,120
portion of genes uh measured during

139
00:05:14,960 --> 00:05:18,800
experiment. It supports on disk data

140
00:05:17,120 --> 00:05:20,160
sets which means you don't have to load

141
00:05:18,800 --> 00:05:22,160
everything in memory when you want to

142
00:05:20,160 --> 00:05:24,400
access your data and this is actually

143
00:05:22,160 --> 00:05:26,960
pretty useful for a very big data set

144
00:05:24,400 --> 00:05:28,800
and it supports sharded data set which

145
00:05:26,960 --> 00:05:30,880
means you can have different files which

146
00:05:28,800 --> 00:05:32,880
are easy to distribute in different

147
00:05:30,880 --> 00:05:34,800
systems and then you can concatenate

148
00:05:32,880 --> 00:05:37,199
them without the need of recreating a

149
00:05:34,800 --> 00:05:39,520
new file and like waiting for merging

150
00:05:37,199 --> 00:05:43,360
this kind of stuff.

151
00:05:39,520 --> 00:05:45,039
Um and if we want to do uh deep learning

152
00:05:43,360 --> 00:05:47,440
on this kind of data, we actually have

153
00:05:45,039 --> 00:05:49,120
just one native solution that works on

154
00:05:47,440 --> 00:05:50,800
top of this undata object which is

155
00:05:49,120 --> 00:05:53,600
called the unloader which was developed

156
00:05:50,800 --> 00:05:55,919
by the undata. Um the problem with this

157
00:05:53,600 --> 00:05:57,680
solution is that uh it's extremely slow

158
00:05:55,919 --> 00:05:59,280
for deep learning application to the

159
00:05:57,680 --> 00:06:01,759
point that basically all the models you

160
00:05:59,280 --> 00:06:03,759
can you can use on them consume data

161
00:06:01,759 --> 00:06:06,319
faster so process data faster than the

162
00:06:03,759 --> 00:06:07,600
time you take to fetch uh samples from

163
00:06:06,319 --> 00:06:09,280
this. in particular if you want to do

164
00:06:07,600 --> 00:06:10,639
like random sampling from disk which is

165
00:06:09,280 --> 00:06:12,800
usually the case for deep learning

166
00:06:10,639 --> 00:06:15,759
application.

167
00:06:12,800 --> 00:06:17,840
So we can um ask like a couple of

168
00:06:15,759 --> 00:06:19,360
question saying okay what could be like

169
00:06:17,840 --> 00:06:20,960
the solution to this problem. This is

170
00:06:19,360 --> 00:06:23,440
basically how we thought about the

171
00:06:20,960 --> 00:06:25,440
problem and we went through it and the

172
00:06:23,440 --> 00:06:27,919
first question is okay what if we load

173
00:06:25,440 --> 00:06:30,000
the entire data set in memory. Uh the

174
00:06:27,919 --> 00:06:32,800
problem with this solution is that

175
00:06:30,000 --> 00:06:34,880
nowadays we are getting with very big

176
00:06:32,800 --> 00:06:36,800
data sets like the last perturbation

177
00:06:34,880 --> 00:06:39,039
data set. The biggest one is the tower

178
00:06:36,800 --> 00:06:42,560
100 million data set and like it will

179
00:06:39,039 --> 00:06:45,280
take uh several like terabytes of RAM to

180
00:06:42,560 --> 00:06:46,960
do this. So maybe some like data centers

181
00:06:45,280 --> 00:06:48,639
can do this but if you want to do this

182
00:06:46,960 --> 00:06:51,120
on your laptop you definitely cannot do

183
00:06:48,639 --> 00:06:52,960
this. So this is not a viable solution

184
00:06:51,120 --> 00:06:56,319
for like small labs and people that want

185
00:06:52,960 --> 00:06:58,000
to try this stuff on its own. Um so the

186
00:06:56,319 --> 00:06:59,599
second idea is what if we stream the

187
00:06:58,000 --> 00:07:01,280
data from disk because like instead of

188
00:06:59,599 --> 00:07:03,520
sampling what we can do we just take

189
00:07:01,280 --> 00:07:05,199
continuous continuous cells from disk

190
00:07:03,520 --> 00:07:07,599
which is actually faster than sampling

191
00:07:05,199 --> 00:07:09,840
from this because of reasons that we

192
00:07:07,599 --> 00:07:13,039
will talk about later. The problem with

193
00:07:09,840 --> 00:07:15,120
this is that I will give a as an example

194
00:07:13,039 --> 00:07:17,599
like the tow 100 million data set. But

195
00:07:15,120 --> 00:07:19,280
for this data set we have that the data

196
00:07:17,599 --> 00:07:20,880
set is plate organized or in general

197
00:07:19,280 --> 00:07:22,960
when you do an experiment usually the

198
00:07:20,880 --> 00:07:25,520
data that that that you have out are

199
00:07:22,960 --> 00:07:27,120
organized by the experiment. And so in

200
00:07:25,520 --> 00:07:29,599
this case what happens is that each

201
00:07:27,120 --> 00:07:31,599
plate is composed of about like 7

202
00:07:29,599 --> 00:07:33,360
million cells. And if you train this in

203
00:07:31,599 --> 00:07:34,880
a streaming fashion, what happens that

204
00:07:33,360 --> 00:07:36,400
the basically the model will just

205
00:07:34,880 --> 00:07:38,000
remember the last plate it was trained

206
00:07:36,400 --> 00:07:39,520
on because we have a catastrophic

207
00:07:38,000 --> 00:07:41,759
forgetting and so it will erase all the

208
00:07:39,520 --> 00:07:45,039
information before that and we will

209
00:07:41,759 --> 00:07:47,360
actually see this happening later.

210
00:07:45,039 --> 00:07:49,039
Um and so the like the the third

211
00:07:47,360 --> 00:07:50,800
question could be like what if we change

212
00:07:49,039 --> 00:07:52,560
format like we've seen that data format

213
00:07:50,800 --> 00:07:54,560
is pretty nice but what if we change it

214
00:07:52,560 --> 00:07:56,800
and we have a bunch of different reason

215
00:07:54,560 --> 00:07:59,280
not to do that. The first one is it's

216
00:07:56,800 --> 00:08:01,199
pretty costly to do this conversion like

217
00:07:59,280 --> 00:08:02,560
uh if we are getting a very big data set

218
00:08:01,199 --> 00:08:05,280
it could take like several days and

219
00:08:02,560 --> 00:08:07,520
several time to do this kind of um

220
00:08:05,280 --> 00:08:09,199
transformation. Um the second one is

221
00:08:07,520 --> 00:08:11,599
that we usually increase the storage

222
00:08:09,199 --> 00:08:14,560
usage because data was like thought to

223
00:08:11,599 --> 00:08:17,919
be used for this kind of sparse data and

224
00:08:14,560 --> 00:08:21,199
for example um if we if we take the 100

225
00:08:17,919 --> 00:08:23,360
million data set uh on and data files we

226
00:08:21,199 --> 00:08:25,280
get more or less 300 gigabytes of data.

227
00:08:23,360 --> 00:08:26,479
If you transform it to the phase data

228
00:08:25,280 --> 00:08:28,240
set version which is also available

229
00:08:26,479 --> 00:08:30,240
online it's more or less two terabytes

230
00:08:28,240 --> 00:08:32,320
of data and sometimes you have also peak

231
00:08:30,240 --> 00:08:35,680
storage usage which is much higher

232
00:08:32,320 --> 00:08:39,440
during the the the conversion

233
00:08:35,680 --> 00:08:40,959
and uh even if we do that usually we

234
00:08:39,440 --> 00:08:42,959
still have slow random sampling because

235
00:08:40,959 --> 00:08:44,240
this is how the disk work but since

236
00:08:42,959 --> 00:08:45,920
you're basically doing the conversion

237
00:08:44,240 --> 00:08:47,279
some people just say okay let's do also

238
00:08:45,920 --> 00:08:48,880
a pre-shuffling while we do this

239
00:08:47,279 --> 00:08:52,080
conversion and so some people solve this

240
00:08:48,880 --> 00:08:53,519
problem like that um and finally like if

241
00:08:52,080 --> 00:08:55,680
we want to do some analysis is after

242
00:08:53,519 --> 00:08:56,800
this or like if at any point we want to

243
00:08:55,680 --> 00:08:58,640
do some transformation like

244
00:08:56,800 --> 00:09:00,720
normalization of the data we have to go

245
00:08:58,640 --> 00:09:02,720
back to and data format usually because

246
00:09:00,720 --> 00:09:04,800
like all libraries works on this kind of

247
00:09:02,720 --> 00:09:06,800
format

248
00:09:04,800 --> 00:09:08,320
and yeah just last to mention it doesn't

249
00:09:06,800 --> 00:09:09,920
work with many tools for example if you

250
00:09:08,320 --> 00:09:12,560
want to do probabilistic inference with

251
00:09:09,920 --> 00:09:14,320
SCBI tools usually it accept data format

252
00:09:12,560 --> 00:09:17,600
doesn't work with other formats or at

253
00:09:14,320 --> 00:09:19,279
least you have to to wrangle around that

254
00:09:17,600 --> 00:09:21,440
um and so like the question we were left

255
00:09:19,279 --> 00:09:23,440
with is what we if we reink the way of

256
00:09:21,440 --> 00:09:25,920
sampling from the disk

257
00:09:23,440 --> 00:09:27,680
And uh what we actually want is like a

258
00:09:25,920 --> 00:09:30,320
fast way to do random sampling for from

259
00:09:27,680 --> 00:09:32,720
disk because this is usually how SGD and

260
00:09:30,320 --> 00:09:35,200
other strategies works. But actually if

261
00:09:32,720 --> 00:09:36,800
we can do fast quasi random sampling

262
00:09:35,200 --> 00:09:38,720
where we will quantify this quasi

263
00:09:36,800 --> 00:09:40,480
randomness. Uh this is actually pretty

264
00:09:38,720 --> 00:09:43,440
good if like if we can get good

265
00:09:40,480 --> 00:09:44,800
performances with uh a good speed and to

266
00:09:43,440 --> 00:09:46,640
do that I will present you two

267
00:09:44,800 --> 00:09:49,920
strategies uh which are called block

268
00:09:46,640 --> 00:09:52,320
sampling and batch fetching.

269
00:09:49,920 --> 00:09:54,000
Um so to start with I will make just an

270
00:09:52,320 --> 00:09:56,320
example of like a training procedure.

271
00:09:54,000 --> 00:09:58,480
Usually you have your model and you set

272
00:09:56,320 --> 00:10:01,200
up set up a certain mini batch size.

273
00:09:58,480 --> 00:10:04,320
Let's say that this is 64 which is just

274
00:10:01,200 --> 00:10:06,560
a a standard um size for for training.

275
00:10:04,320 --> 00:10:09,120
Um this means that in like normal

276
00:10:06,560 --> 00:10:11,519
setting you will be sampling 64 cells

277
00:10:09,120 --> 00:10:13,920
for from 64 different location in the

278
00:10:11,519 --> 00:10:16,079
data set. Now if the data set is on disk

279
00:10:13,920 --> 00:10:18,399
this means that you have to do like 64

280
00:10:16,079 --> 00:10:21,600
random accesses to disk which is pretty

281
00:10:18,399 --> 00:10:23,839
costly. Um so what we what we thought

282
00:10:21,600 --> 00:10:25,600
about it like we thought about it and we

283
00:10:23,839 --> 00:10:27,360
introduced this block sampling and what

284
00:10:25,600 --> 00:10:30,480
we do is basically we define a block

285
00:10:27,360 --> 00:10:32,399
size and this block size um tells us how

286
00:10:30,480 --> 00:10:35,040
many contiguous cells we want to sample

287
00:10:32,399 --> 00:10:37,920
from this for example 16 and now if you

288
00:10:35,040 --> 00:10:40,240
want to um create a mini batch of like

289
00:10:37,920 --> 00:10:43,519
64 cells you can sample from four

290
00:10:40,240 --> 00:10:46,640
different locations use like taking 16

291
00:10:43,519 --> 00:10:48,399
continuous cells from this and this is

292
00:10:46,640 --> 00:10:50,160
just basically a trade-off between the

293
00:10:48,399 --> 00:10:52,320
disk throughut that you can get and

294
00:10:50,160 --> 00:10:54,480
actually the diversity of the mini batch

295
00:10:52,320 --> 00:10:58,240
that you're getting. So not not much in

296
00:10:54,480 --> 00:11:00,560
here. Um but now we can combine this

297
00:10:58,240 --> 00:11:03,040
with this other idea which we call batch

298
00:11:00,560 --> 00:11:05,600
fetching. And um the idea is that we can

299
00:11:03,040 --> 00:11:07,600
ask the disk for more data at once. So

300
00:11:05,600 --> 00:11:09,600
instead of like one mini batch or one

301
00:11:07,600 --> 00:11:12,079
cell, we can ask more than that. For

302
00:11:09,600 --> 00:11:13,920
example, we can ask for 10 mini batches.

303
00:11:12,079 --> 00:11:16,240
And why we want to do that, I will give

304
00:11:13,920 --> 00:11:18,079
you two reasons for that. So the first

305
00:11:16,240 --> 00:11:21,200
reason has to do with disk optimization

306
00:11:18,079 --> 00:11:23,440
and in particular the disk can do uh can

307
00:11:21,200 --> 00:11:25,279
serve batch requests in an optimized way

308
00:11:23,440 --> 00:11:27,440
and to give you a sense of what does it

309
00:11:25,279 --> 00:11:29,200
mean I can give you an example it's a

310
00:11:27,440 --> 00:11:30,320
simple example with with an elevator

311
00:11:29,200 --> 00:11:32,399
this is just one of the many

312
00:11:30,320 --> 00:11:33,680
optimization that this can do for

313
00:11:32,399 --> 00:11:35,519
example let's suppose we have three

314
00:11:33,680 --> 00:11:37,760
people that have to take an elevator and

315
00:11:35,519 --> 00:11:39,200
the first one has to go to floor two the

316
00:11:37,760 --> 00:11:41,680
second one to floor eight and the third

317
00:11:39,200 --> 00:11:44,240
one to floor five now we can serve those

318
00:11:41,680 --> 00:11:46,320
people sequentially and what happens

319
00:11:44,240 --> 00:11:48,399
that we first go to floor two then to

320
00:11:46,320 --> 00:11:50,959
floor to floor eight and then back to

321
00:11:48,399 --> 00:11:52,320
floor five or like even if we can take

322
00:11:50,959 --> 00:11:53,839
one person at a time we have to go back

323
00:11:52,320 --> 00:11:56,560
to floor zero each time which is even

324
00:11:53,839 --> 00:12:00,560
worse. Um and with this strategy we

325
00:11:56,560 --> 00:12:04,399
basically travel 11 floors um in total.

326
00:12:00,560 --> 00:12:06,320
Now if the elevator knows that he can he

327
00:12:04,399 --> 00:12:08,560
has to go to all these three location

328
00:12:06,320 --> 00:12:11,040
before what he can do he can stop at at

329
00:12:08,560 --> 00:12:12,720
floor five middle way and like serve all

330
00:12:11,040 --> 00:12:14,639
three people and now we just traveled

331
00:12:12,720 --> 00:12:17,200
eight floors and then there is basically

332
00:12:14,639 --> 00:12:18,880
a similar idea for disk if you know all

333
00:12:17,200 --> 00:12:20,639
the data that you have to access it can

334
00:12:18,880 --> 00:12:23,279
optimize the way he accesses it and

335
00:12:20,639 --> 00:12:26,000
serve you the request

336
00:12:23,279 --> 00:12:28,639
and the second uh reason is what we call

337
00:12:26,000 --> 00:12:30,639
in memory shuffling and um the idea as

338
00:12:28,639 --> 00:12:33,519
we said is for example we want 10 mini

339
00:12:30,639 --> 00:12:36,480
batches worth of cells instead of one.

340
00:12:33,519 --> 00:12:39,120
So we are actually asking for um 640

341
00:12:36,480 --> 00:12:41,440
cells at a time. Uh and we are still

342
00:12:39,120 --> 00:12:43,519
using the idea of like block size of 16.

343
00:12:41,440 --> 00:12:47,200
So now we are accessing 40 different

344
00:12:43,519 --> 00:12:48,959
random location in the disk. Um but now

345
00:12:47,200 --> 00:12:50,320
that we have the cells in memory, so

346
00:12:48,959 --> 00:12:53,360
like we suppose that we have enough

347
00:12:50,320 --> 00:12:55,120
memory to handle like 600 640 cells. Now

348
00:12:53,360 --> 00:12:56,639
we we can shuffle the cells in memory

349
00:12:55,120 --> 00:12:59,360
which is pretty cheap because everything

350
00:12:56,639 --> 00:13:01,760
is in memory and we can rebuild the mini

351
00:12:59,360 --> 00:13:03,440
batches after that. So now each mini

352
00:13:01,760 --> 00:13:05,519
batch instead of having cells coming

353
00:13:03,440 --> 00:13:08,000
from four location we'll have many more

354
00:13:05,519 --> 00:13:10,560
location like 35 36 depending on like

355
00:13:08,000 --> 00:13:12,880
how many how many mini batches you you

356
00:13:10,560 --> 00:13:14,639
choose to start with.

357
00:13:12,880 --> 00:13:16,079
And so what we're actually doing is

358
00:13:14,639 --> 00:13:18,240
basically trading the memory consumption

359
00:13:16,079 --> 00:13:19,760
of your uh of your computing system for

360
00:13:18,240 --> 00:13:22,320
an increased throughput for the batch

361
00:13:19,760 --> 00:13:25,760
request and for for more mini batch

362
00:13:22,320 --> 00:13:27,360
diversity with this inmemory shot.

363
00:13:25,760 --> 00:13:29,760
And this is basically the full picture

364
00:13:27,360 --> 00:13:31,519
of the whole algorithm. We have um a

365
00:13:29,760 --> 00:13:33,279
certain data set. We generate just the

366
00:13:31,519 --> 00:13:36,000
indices of those data set which are

367
00:13:33,279 --> 00:13:38,560
integers. So they can stay on disk on on

368
00:13:36,000 --> 00:13:40,480
in memory. We can then split in blocks

369
00:13:38,560 --> 00:13:42,720
that we define with a certain block

370
00:13:40,480 --> 00:13:44,800
size. We can shuffle them. And now we're

371
00:13:42,720 --> 00:13:47,680
shuffing just the indices not the actual

372
00:13:44,800 --> 00:13:49,680
data set. And we can reconcate them in a

373
00:13:47,680 --> 00:13:53,120
single vector. And then we can split

374
00:13:49,680 --> 00:13:55,440
them based on the on the um on the size

375
00:13:53,120 --> 00:13:57,279
that we want to fetch from disk which we

376
00:13:55,440 --> 00:13:59,519
call fetch factor. So mini batch time

377
00:13:57,279 --> 00:14:01,920
fetch factor. And then we can just ask

378
00:13:59,519 --> 00:14:04,320
the data from disk shuffle the resulting

379
00:14:01,920 --> 00:14:06,160
data in memory splitting mini batches in

380
00:14:04,320 --> 00:14:09,120
memory and return the split batches.

381
00:14:06,160 --> 00:14:11,600
This is the whole algorithm.

382
00:14:09,120 --> 00:14:15,279
And then the question is okay how does

383
00:14:11,600 --> 00:14:17,600
this algorithm perform and um this is

384
00:14:15,279 --> 00:14:20,240
basically a plot of the throughput of

385
00:14:17,600 --> 00:14:23,040
the algorithm um compared to like the

386
00:14:20,240 --> 00:14:27,600
choice of block size and fetch factor.

387
00:14:23,040 --> 00:14:29,680
And on the bottom on the on the black um

388
00:14:27,600 --> 00:14:31,920
dotted line you can see unloader which

389
00:14:29,680 --> 00:14:34,399
is more or less 20 samples per second

390
00:14:31,920 --> 00:14:36,720
which is not not that much for deploying

391
00:14:34,399 --> 00:14:40,160
application. And like in this plot if

392
00:14:36,720 --> 00:14:43,040
you go up to 64 um fetch a fetch factor

393
00:14:40,160 --> 00:14:45,760
of 64 and a block size of 64 we can get

394
00:14:43,040 --> 00:14:51,040
almost uh a thousand samples per second.

395
00:14:45,760 --> 00:14:54,480
So this is actually a um 4 480 400 sorry

396
00:14:51,040 --> 00:14:56,639
48 times speed up in single core set.

397
00:14:54,480 --> 00:14:58,240
Now the other thing is that unloader

398
00:14:56,639 --> 00:15:00,480
doesn't support very easily

399
00:14:58,240 --> 00:15:03,279
multipprocessing. you have to like uh

400
00:15:00,480 --> 00:15:05,120
wringle with the source code while in in

401
00:15:03,279 --> 00:15:07,279
our solution you can use multiprocessing

402
00:15:05,120 --> 00:15:09,120
in PyTorch data loader. So we also

403
00:15:07,279 --> 00:15:11,519
compare to that and we have basically

404
00:15:09,120 --> 00:15:13,120
more than two order of magnitude phase

405
00:15:11,519 --> 00:15:15,360
and what does it actually mean for

406
00:15:13,120 --> 00:15:17,360
example for the tow 100 million data set

407
00:15:15,360 --> 00:15:19,199
it means that just to go through the

408
00:15:17,360 --> 00:15:21,680
data set without any training with

409
00:15:19,199 --> 00:15:23,440
downloader you will take two months and

410
00:15:21,680 --> 00:15:25,600
with this solution you just take 11

411
00:15:23,440 --> 00:15:28,000
hours and this is without training and

412
00:15:25,600 --> 00:15:30,639
anything else

413
00:15:28,000 --> 00:15:32,959
and uh like previously we talked about

414
00:15:30,639 --> 00:15:35,839
this uh quasi randomness in in the

415
00:15:32,959 --> 00:15:37,839
process and we quantify this with this

416
00:15:35,839 --> 00:15:40,079
term like mini batch diversity and we

417
00:15:37,839 --> 00:15:42,639
did two things. The first thing is uh

418
00:15:40,079 --> 00:15:44,720
compute this in a mathematical way which

419
00:15:42,639 --> 00:15:47,920
uh which is mini batch entropy. So what

420
00:15:44,720 --> 00:15:49,680
we did is again considering the 100

421
00:15:47,920 --> 00:15:52,079
million data set as we said this is

422
00:15:49,680 --> 00:15:54,639
plate organized. So we have 7 million

423
00:15:52,079 --> 00:15:56,720
contiguous cells per plate. So we

424
00:15:54,639 --> 00:15:59,600
basically took the plate labels of each

425
00:15:56,720 --> 00:16:01,600
cell and we measured the average entropy

426
00:15:59,600 --> 00:16:04,399
of the mini batch that we were creating.

427
00:16:01,600 --> 00:16:06,560
So mini batch of 64. Now if you do a

428
00:16:04,399 --> 00:16:08,880
standard streaming strategy basically

429
00:16:06,560 --> 00:16:11,680
you will take cells coming always from

430
00:16:08,880 --> 00:16:14,160
the same from the same plate except for

431
00:16:11,680 --> 00:16:15,759
like 13 times on the on basically on the

432
00:16:14,160 --> 00:16:18,480
change of from one plate to the other.

433
00:16:15,759 --> 00:16:20,160
So the average entropy will be zero. Uh

434
00:16:18,480 --> 00:16:21,920
well if you take random sampling you

435
00:16:20,160 --> 00:16:23,360
actually computed

436
00:16:21,920 --> 00:16:25,440
like the average entropy of random

437
00:16:23,360 --> 00:16:28,639
sampling with mini batch size of 64 and

438
00:16:25,440 --> 00:16:30,399
you get a 3.63.

439
00:16:28,639 --> 00:16:32,480
Um

440
00:16:30,399 --> 00:16:34,320
and now what we did is okay let's

441
00:16:32,480 --> 00:16:36,480
compare our solution with this these

442
00:16:34,320 --> 00:16:39,360
values. So you can see on top the

443
00:16:36,480 --> 00:16:41,360
performance of of uh random sampling and

444
00:16:39,360 --> 00:16:43,680
you can see on the on the very bottom

445
00:16:41,360 --> 00:16:45,360
the performance of basically streaming

446
00:16:43,680 --> 00:16:48,320
because this is not really streaming but

447
00:16:45,360 --> 00:16:50,560
is uh a mini batch size of 64 with a

448
00:16:48,320 --> 00:16:52,959
block size of 64. So we are taking 64

449
00:16:50,560 --> 00:16:54,800
continuous cells. So that's again a

450
00:16:52,959 --> 00:16:56,880
batch entropy of zero. But you can see

451
00:16:54,800 --> 00:16:59,040
that as we increase slightly the fetch

452
00:16:56,880 --> 00:17:00,880
factor, we can actually achieve almost

453
00:16:59,040 --> 00:17:02,880
the same batch entropy that we will get

454
00:17:00,880 --> 00:17:06,000
with random

455
00:17:02,880 --> 00:17:08,079
um sampling. And yeah, so and this is

456
00:17:06,000 --> 00:17:10,640
just a mathematical way to like quantify

457
00:17:08,079 --> 00:17:12,880
this. It's completely test agnostic. You

458
00:17:10,640 --> 00:17:14,880
can like you can validate this with with

459
00:17:12,880 --> 00:17:17,600
any data set. But we also tried to do

460
00:17:14,880 --> 00:17:19,520
some real world uh evaluation on this.

461
00:17:17,600 --> 00:17:22,160
Uh and we did it on the tower 100

462
00:17:19,520 --> 00:17:24,000
million data set. So what we did we

463
00:17:22,160 --> 00:17:26,160
trained a simple linear model. We didn't

464
00:17:24,000 --> 00:17:28,000
want to like have conf confounding

465
00:17:26,160 --> 00:17:29,600
effect from like a parameter tuning the

466
00:17:28,000 --> 00:17:31,360
choice of the model or anything else. So

467
00:17:29,600 --> 00:17:33,679
just a simple linear model and we

468
00:17:31,360 --> 00:17:36,080
evaluated the F1 score on four different

469
00:17:33,679 --> 00:17:38,160
tasks. The simplest one we can think of

470
00:17:36,080 --> 00:17:39,840
set line classification. Oh just like

471
00:17:38,160 --> 00:17:41,600
just to mention the power 100 million

472
00:17:39,840 --> 00:17:44,160
data set is just this perturbation data

473
00:17:41,600 --> 00:17:46,320
set where you have 50 cell lines 400

474
00:17:44,160 --> 00:17:48,080
drugs then you have also doages with

475
00:17:46,320 --> 00:17:49,919
that we ignored and you have all

476
00:17:48,080 --> 00:17:54,000
combination and see how the perturbation

477
00:17:49,919 --> 00:17:57,679
perform. Um so we basically just took uh

478
00:17:54,000 --> 00:18:00,320
like the SERNA seek of each uh of each

479
00:17:57,679 --> 00:18:02,320
cell and we classified the cell line was

480
00:18:00,320 --> 00:18:04,240
coming from the drug and the mechanism

481
00:18:02,320 --> 00:18:06,480
of action which is basically a broader

482
00:18:04,240 --> 00:18:08,960
classification of like the drug effect

483
00:18:06,480 --> 00:18:12,559
and this is was like the the labels were

484
00:18:08,960 --> 00:18:15,760
done by the authors of the 100 million

485
00:18:12,559 --> 00:18:17,520
data set and those are the performances.

486
00:18:15,760 --> 00:18:19,280
So we actually compared four different

487
00:18:17,520 --> 00:18:21,120
solutions. The first one is streaming

488
00:18:19,280 --> 00:18:23,440
that we presented. The second one is

489
00:18:21,120 --> 00:18:25,840
streaming with buffer where buffer here

490
00:18:23,440 --> 00:18:28,000
means we can also have a a kind of

491
00:18:25,840 --> 00:18:29,679
buffer as we presented for the inmemory

492
00:18:28,000 --> 00:18:31,200
shuffling for the streaming strategy.

493
00:18:29,679 --> 00:18:32,960
It's just that all cells will come

494
00:18:31,200 --> 00:18:35,120
continuously and this is actually a

495
00:18:32,960 --> 00:18:36,799
solution that some libraries uh do for

496
00:18:35,120 --> 00:18:40,400
example a phase have a streaming with

497
00:18:36,799 --> 00:18:42,400
buffer strategy. Um so you can shuffle

498
00:18:40,400 --> 00:18:44,080
locally the cells but actually we know

499
00:18:42,400 --> 00:18:46,799
that if we don't want this effect of

500
00:18:44,080 --> 00:18:49,120
plate we will need a buffer of 7 million

501
00:18:46,799 --> 00:18:51,679
cells or more. So this is just a buffer

502
00:18:49,120 --> 00:18:54,640
I think of a thousand or 10,000 I don't

503
00:18:51,679 --> 00:18:56,480
remember by heart. Um and then on the

504
00:18:54,640 --> 00:18:58,240
far right we have the random sampling

505
00:18:56,480 --> 00:18:59,840
and then we have one of our solution

506
00:18:58,240 --> 00:19:02,160
which is block size four and patch

507
00:18:59,840 --> 00:19:04,080
factor 16 which is actually the solution

508
00:19:02,160 --> 00:19:07,520
where where before we presented an

509
00:19:04,080 --> 00:19:09,600
improvement of of two um order of

510
00:19:07,520 --> 00:19:12,640
magnitude. So we can even go higher than

511
00:19:09,600 --> 00:19:14,240
two order of magnitude but we will get

512
00:19:12,640 --> 00:19:15,679
less performance. So we we took

513
00:19:14,240 --> 00:19:18,000
basically the best solution for from

514
00:19:15,679 --> 00:19:20,000
both and you can see that like

515
00:19:18,000 --> 00:19:21,360
regardless of the actual performances

516
00:19:20,000 --> 00:19:23,520
you can see that the streaming and the

517
00:19:21,360 --> 00:19:25,120
streaming with buffer basically go go

518
00:19:23,520 --> 00:19:26,799
hand by hand and then we have the random

519
00:19:25,120 --> 00:19:28,720
sampling that goes well with our

520
00:19:26,799 --> 00:19:30,720
solution. Those are the pairing of the

521
00:19:28,720 --> 00:19:33,200
performances

522
00:19:30,720 --> 00:19:35,200
and yeah uh so we put everything

523
00:19:33,200 --> 00:19:37,520
together in a package. You can access

524
00:19:35,200 --> 00:19:40,160
the GitHub on on the right with a QR

525
00:19:37,520 --> 00:19:43,120
code. We called it FC data set and this

526
00:19:40,160 --> 00:19:45,120
is basically a drop in solution that can

527
00:19:43,120 --> 00:19:46,960
go on top of any collection like we

528
00:19:45,120 --> 00:19:48,320
thought about it for the anda format. It

529
00:19:46,960 --> 00:19:50,960
actually work with any collection. you

530
00:19:48,320 --> 00:19:53,440
can work with uh aphase and there is

531
00:19:50,960 --> 00:19:55,520
also this Nvidia biono which is another

532
00:19:53,440 --> 00:19:58,080
uh solution from from the Nvidia team to

533
00:19:55,520 --> 00:20:00,559
work with uh within data format and the

534
00:19:58,080 --> 00:20:05,520
way we we went to work with any solution

535
00:20:00,559 --> 00:20:06,960
is just we um exposed for for methods uh

536
00:20:05,520 --> 00:20:09,039
that basically give you the opportunity

537
00:20:06,960 --> 00:20:12,000
to index your data set however you like

538
00:20:09,039 --> 00:20:13,679
it there is a function called fetch

539
00:20:12,000 --> 00:20:15,280
callback and batch call back and then

540
00:20:13,679 --> 00:20:16,720
you can transform also the data on the

541
00:20:15,280 --> 00:20:18,480
fly so you can define everything you

542
00:20:16,720 --> 00:20:21,039
want for the data set you can install

543
00:20:18,480 --> 00:20:23,440
with standard pip. So pip install SC

544
00:20:21,039 --> 00:20:25,600
data set and we also compare this

545
00:20:23,440 --> 00:20:28,559
solution to those other loading

546
00:20:25,600 --> 00:20:30,960
solution. So the to a phase which where

547
00:20:28,559 --> 00:20:33,360
like you can get the power 100 million

548
00:20:30,960 --> 00:20:35,440
data set on a game face and then to this

549
00:20:33,360 --> 00:20:39,120
Nvidia solution that was specifically

550
00:20:35,440 --> 00:20:40,640
meant for like uh single cell data and

551
00:20:39,120 --> 00:20:42,960
so on the right you can see that

552
00:20:40,640 --> 00:20:45,039
basically the standard throughut is 20

553
00:20:42,960 --> 00:20:47,280
sample per second for a loader. Then you

554
00:20:45,039 --> 00:20:49,440
have a eight times speed up with dug in

555
00:20:47,280 --> 00:20:52,159
phase over unloader and you have a 12

556
00:20:49,440 --> 00:20:54,480
speed up uh of biono overloader while we

557
00:20:52,159 --> 00:20:56,080
get a 48 speed up. But as we said this

558
00:20:54,480 --> 00:20:57,919
can be used on top of any collection. So

559
00:20:56,080 --> 00:21:00,240
you can even combine like a phase with

560
00:20:57,919 --> 00:21:01,760
the data set and get even more. It's

561
00:21:00,240 --> 00:21:04,400
just that you will lose a bunch of

562
00:21:01,760 --> 00:21:06,400
things. For example, um in case of

563
00:21:04,400 --> 00:21:08,880
aining phase and bionimo, those are not

564
00:21:06,400 --> 00:21:10,880
undata like we wanted to maintain the

565
00:21:08,880 --> 00:21:13,679
compatibility and also like the handling

566
00:21:10,880 --> 00:21:17,360
of metadata is much harder to do within

567
00:21:13,679 --> 00:21:19,039
phase and biono while for for unloader

568
00:21:17,360 --> 00:21:20,799
also for our data set. You can actually

569
00:21:19,039 --> 00:21:22,480
return undata object. You can return

570
00:21:20,799 --> 00:21:25,600
pytorch tensor. You can return whatever

571
00:21:22,480 --> 00:21:26,960
you like for your task and like now we

572
00:21:25,600 --> 00:21:28,240
support also weight as sampling. That's

573
00:21:26,960 --> 00:21:30,240
something that a lot of people asked

574
00:21:28,240 --> 00:21:32,320
for. So you can also train on imbalanced

575
00:21:30,240 --> 00:21:34,960
data sets and you will get uh the same

576
00:21:32,320 --> 00:21:38,640
performances you get now.

577
00:21:34,960 --> 00:21:40,640
Um yeah so just to recap like we wanted

578
00:21:38,640 --> 00:21:43,120
to handle this problem of like having

579
00:21:40,640 --> 00:21:44,960
data loading uh like handling the data

580
00:21:43,120 --> 00:21:47,679
loading bottleneck for large scale deep

581
00:21:44,960 --> 00:21:50,640
learning and so we think about this we

582
00:21:47,679 --> 00:21:52,400
proposed this SC data set um solution.

583
00:21:50,640 --> 00:21:55,360
So now you can train on this large data

584
00:21:52,400 --> 00:21:57,760
set on your laptop basically. And uh how

585
00:21:55,360 --> 00:21:59,360
we went for it, we basically trade pure

586
00:21:57,760 --> 00:22:02,080
random sampling with quasi random

587
00:21:59,360 --> 00:22:04,799
sampling and we show that basically with

588
00:22:02,080 --> 00:22:06,240
um uh if you choose the parameter well

589
00:22:04,799 --> 00:22:07,600
you basically get the same performance

590
00:22:06,240 --> 00:22:10,159
of random sampling but you have two

591
00:22:07,600 --> 00:22:12,480
order of magnitude improvement.

592
00:22:10,159 --> 00:22:14,080
So I think this is a good time to stop

593
00:22:12,480 --> 00:22:17,640
if you have any questions about the

594
00:22:14,080 --> 00:22:17,640
first part. Yeah.

595
00:22:19,200 --> 00:22:24,159
Hi. Um, nice to meet you. Great talk.

596
00:22:21,840 --> 00:22:25,679
It's really, really interesting. So, um,

597
00:22:24,159 --> 00:22:27,120
I'm from a pharma company. We worked on

598
00:22:25,679 --> 00:22:30,159
a lot of data sets, single cell data

599
00:22:27,120 --> 00:22:35,600
sets coming from, uh, clinical or real

600
00:22:30,159 --> 00:22:37,840
patients. Um, so, um, while and it is

601
00:22:35,600 --> 00:22:39,520
great that you can actually get to load

602
00:22:37,840 --> 00:22:41,200
sort of very big data set that we're

603
00:22:39,520 --> 00:22:43,280
getting. However, I'm just slightly

604
00:22:41,200 --> 00:22:48,080
concerned whether the way that you

605
00:22:43,280 --> 00:22:50,559
quantify entropy assumes um

606
00:22:48,080 --> 00:22:52,720
a level of sort of diversity between the

607
00:22:50,559 --> 00:22:54,400
plates for which has been tried to be

608
00:22:52,720 --> 00:22:55,360
experimentally controlled. So the tower

609
00:22:54,400 --> 00:22:57,039
data set they're trying to

610
00:22:55,360 --> 00:22:59,280
experimentally make it as similar as

611
00:22:57,039 --> 00:23:00,960
possible with the least plate effects.

612
00:22:59,280 --> 00:23:03,280
So have you tried in a data set where

613
00:23:00,960 --> 00:23:04,960
has you know patient samples in which

614
00:23:03,280 --> 00:23:06,480
the sort of the batch effect between

615
00:23:04,960 --> 00:23:07,919
patients will be kind of at a very

616
00:23:06,480 --> 00:23:10,559
different distribution? Do you think

617
00:23:07,919 --> 00:23:12,640
that the sort of the fetch the ability

618
00:23:10,559 --> 00:23:14,640
to use the quaseron and sampling won't

619
00:23:12,640 --> 00:23:17,200
make the batch effect worse?

620
00:23:14,640 --> 00:23:19,039
>> Um so we didn't try any other data set

621
00:23:17,200 --> 00:23:21,840
because like we we did the setup for

622
00:23:19,039 --> 00:23:26,080
this large scale data set. Uh I think

623
00:23:21,840 --> 00:23:28,080
that uh um like even in this data set

624
00:23:26,080 --> 00:23:29,440
even if it was controlled there was some

625
00:23:28,080 --> 00:23:31,679
technical artifact because we can see

626
00:23:29,440 --> 00:23:34,080
the difference in performance. If the

627
00:23:31,679 --> 00:23:37,760
like if this uh artifact is even more

628
00:23:34,080 --> 00:23:39,760
pronounced one one what what one can do

629
00:23:37,760 --> 00:23:42,559
is just like increase for example the

630
00:23:39,760 --> 00:23:44,640
fetch um the fetch factor and so you

631
00:23:42,559 --> 00:23:46,559
will use more memory or or you will slow

632
00:23:44,640 --> 00:23:48,960
down a little bit the throughput and

633
00:23:46,559 --> 00:23:52,000
like you will handle this in this way.

634
00:23:48,960 --> 00:23:55,039
would you suggest um sort of quantifying

635
00:23:52,000 --> 00:23:56,240
the entropy factor before sort of

636
00:23:55,039 --> 00:23:58,960
addressing? So

637
00:23:56,240 --> 00:24:00,000
>> exactly like for like it's very easy to

638
00:23:58,960 --> 00:24:01,760
quantify because it's just a

639
00:24:00,000 --> 00:24:04,000
mathematical formula. We use the label

640
00:24:01,760 --> 00:24:06,320
entropies um like the plate label

641
00:24:04,000 --> 00:24:08,159
entropy because like we knew that the

642
00:24:06,320 --> 00:24:09,600
data set were were organized by plate.

643
00:24:08,159 --> 00:24:11,600
But if you have any other way of

644
00:24:09,600 --> 00:24:13,840
organizing your data maybe by cell line

645
00:24:11,600 --> 00:24:15,520
then you can use the cell line label or

646
00:24:13,840 --> 00:24:17,760
something like that. It's just that it's

647
00:24:15,520 --> 00:24:20,000
not super easy to like find a universal

648
00:24:17,760 --> 00:24:22,400
way to measure like how quasi random you

649
00:24:20,000 --> 00:24:24,080
are doing. So it's either on downstream

650
00:24:22,400 --> 00:24:26,480
task which depends on the model and the

651
00:24:24,080 --> 00:24:28,080
task or it's with a mathematical formula

652
00:24:26,480 --> 00:24:31,240
on some labels of the data.

653
00:24:28,080 --> 00:24:31,240
>> Thank you.

654
00:24:31,600 --> 00:24:37,760
>> Um yeah thanks for the talk. In my

655
00:24:34,640 --> 00:24:41,440
experience the bottleneck was always GPU

656
00:24:37,760 --> 00:24:43,679
calculation. So you you you of course

657
00:24:41,440 --> 00:24:47,200
everyone always monitors their GPU usage

658
00:24:43,679 --> 00:24:51,120
while training uh their models and um

659
00:24:47,200 --> 00:24:53,279
using multiple workers per GPU. Um it is

660
00:24:51,120 --> 00:24:55,919
I I didn't found it hard to keep the

661
00:24:53,279 --> 00:24:59,520
usage at 100%.

662
00:24:55,919 --> 00:25:01,520
Um so I I don't know why I have a

663
00:24:59,520 --> 00:25:05,120
different experience so that data

664
00:25:01,520 --> 00:25:08,720
fetching was not a bottleneck for me. Uh

665
00:25:05,120 --> 00:25:11,760
related question I have is in your test

666
00:25:08,720 --> 00:25:16,240
uh in the Tahoe data set did you measure

667
00:25:11,760 --> 00:25:18,799
real u real time of the training of the

668
00:25:16,240 --> 00:25:21,760
model like in these bar plots you showed

669
00:25:18,799 --> 00:25:23,200
with random sampling uh block fetching

670
00:25:21,760 --> 00:25:25,360
>> and streaming. Okay, so

671
00:25:23,200 --> 00:25:28,159
>> what's the difference in time it took?

672
00:25:25,360 --> 00:25:30,480
>> So this this was just about the loading

673
00:25:28,159 --> 00:25:32,880
um of the data. We actually have tests

674
00:25:30,480 --> 00:25:35,600
on like training a model on top of them

675
00:25:32,880 --> 00:25:37,120
and the the the like the time that

676
00:25:35,600 --> 00:25:39,520
doesn't change because like in our

677
00:25:37,120 --> 00:25:41,679
experiment the GPU basically had zero

678
00:25:39,520 --> 00:25:43,600
utilization most of the time. So even if

679
00:25:41,679 --> 00:25:44,880
you put on top a training of the model

680
00:25:43,600 --> 00:25:46,960
just get the same performance.

681
00:25:44,880 --> 00:25:48,880
>> I see because the model is small.

682
00:25:46,960 --> 00:25:51,440
>> Yeah, we didn't use like a very large

683
00:25:48,880 --> 00:25:54,440
big model. Yeah, that's also the case.

684
00:25:51,440 --> 00:25:54,440
Also

685
00:25:55,919 --> 00:26:00,000
um just to add on that I think it also

686
00:25:57,760 --> 00:26:01,840
depends on the server that you're using

687
00:26:00,000 --> 00:26:03,360
for example because we have been other

688
00:26:01,840 --> 00:26:06,080
people where instead of having a

689
00:26:03,360 --> 00:26:08,159
baseline of 20 cells per second they had

690
00:26:06,080 --> 00:26:10,400
200 cells per second. So maybe 200 cells

691
00:26:08,159 --> 00:26:12,320
per second with a very large I don't

692
00:26:10,400 --> 00:26:14,640
know foundation model the transformer

693
00:26:12,320 --> 00:26:16,240
model maybe it can work like that. So it

694
00:26:14,640 --> 00:26:17,840
depends also on the system you're but

695
00:26:16,240 --> 00:26:21,799
for example in a laptop is pretty hard

696
00:26:17,840 --> 00:26:21,799
that you will get this

697
00:26:22,400 --> 00:26:26,640
>> on a

698
00:26:24,640 --> 00:26:27,600
laptop GPU isn't enough to train a

699
00:26:26,640 --> 00:26:29,760
foundation model.

700
00:26:27,600 --> 00:26:31,679
>> Yeah. Uh I mean we will also talk about

701
00:26:29,760 --> 00:26:33,919
like do we really need foundation models

702
00:26:31,679 --> 00:26:35,200
and stuff like that. So yeah this is

703
00:26:33,919 --> 00:26:36,880
just a way of like if you want to

704
00:26:35,200 --> 00:26:39,279
experiment with some models even if it's

705
00:26:36,880 --> 00:26:41,760
not that big you can do it and even with

706
00:26:39,279 --> 00:26:44,240
bigger models we don't want the the data

707
00:26:41,760 --> 00:26:45,600
loading being the bottle. So like in our

708
00:26:44,240 --> 00:26:47,919
cases if you want I don't know if you

709
00:26:45,600 --> 00:26:49,039
trained on and data format or you change

710
00:26:47,919 --> 00:26:52,240
format but

711
00:26:49,039 --> 00:26:54,559
>> I use data but I didn't use end loader I

712
00:26:52,240 --> 00:26:55,600
always write a custom data loader in

713
00:26:54,559 --> 00:26:57,919
>> okay yeah that's also another

714
00:26:55,600 --> 00:27:00,720
>> and then I use multiple workers per GPU

715
00:26:57,919 --> 00:27:03,520
set it to four if it's not 100 uh set it

716
00:27:00,720 --> 00:27:05,440
to eight and then it's it always uh

717
00:27:03,520 --> 00:27:08,480
>> yeah yeah so like what we did is

718
00:27:05,440 --> 00:27:10,159
actually we wrote a custom solution but

719
00:27:08,480 --> 00:27:12,080
since basically every developer is now

720
00:27:10,159 --> 00:27:13,520
writing its own custom solution we said

721
00:27:12,080 --> 00:27:13,840
okay let's make this accessible for

722
00:27:13,520 --> 00:27:14,400
everyone.

723
00:27:13,840 --> 00:27:15,840
>> That makes sense.

724
00:27:14,400 --> 00:27:18,799
>> But yeah, you you had to write your own

725
00:27:15,840 --> 00:27:20,720
data load. Makes sense now. Okay.

726
00:27:18,799 --> 00:27:23,760
>> So, which this which type of disk did

727
00:27:20,720 --> 00:27:26,320
you test did you use in this test?

728
00:27:23,760 --> 00:27:26,799
>> Sorry. Which which disc did you use this

729
00:27:26,320 --> 00:27:30,080
experiment?

730
00:27:26,799 --> 00:27:32,960
>> Oh, this is basically uh an uh ride of

731
00:27:30,080 --> 00:27:35,440
five SSD. So, this is done on solid

732
00:27:32,960 --> 00:27:37,039
state disk. Uh we didn't try on our disc

733
00:27:35,440 --> 00:27:39,360
because we didn't have them on the

734
00:27:37,039 --> 00:27:40,799
server. we expect even larger difference

735
00:27:39,360 --> 00:27:44,559
in performance because their disc

736
00:27:40,799 --> 00:27:46,799
actually have a physical um latency. So

737
00:27:44,559 --> 00:27:48,720
this is actually the the worst case

738
00:27:46,799 --> 00:27:51,760
scenario to show improvement to this.

739
00:27:48,720 --> 00:27:53,760
>> Yeah. And why uh second question why so

740
00:27:51,760 --> 00:27:56,080
I didn't understand why you get a speed

741
00:27:53,760 --> 00:27:59,840
up when you turn on like parallel

742
00:27:56,080 --> 00:28:02,080
computation is if this is IO bound why

743
00:27:59,840 --> 00:28:05,360
does it give you improvement? Oh,

744
00:28:02,080 --> 00:28:08,799
because probably we can uh um probably

745
00:28:05,360 --> 00:28:10,880
because we can go

746
00:28:08,799 --> 00:28:12,640
uh where is it?

747
00:28:10,880 --> 00:28:14,080
Like probably we can go even higher with

748
00:28:12,640 --> 00:28:16,720
them and so you don't have to use

749
00:28:14,080 --> 00:28:18,320
multiprocess like if you increase even

750
00:28:16,720 --> 00:28:20,080
more the block size and you increase

751
00:28:18,320 --> 00:28:21,760
even more the fetch factor probably you

752
00:28:20,080 --> 00:28:23,679
can go even a little bit higher. So

753
00:28:21,760 --> 00:28:25,279
that's and probably you will get this

754
00:28:23,679 --> 00:28:27,600
like you can get this on single core if

755
00:28:25,279 --> 00:28:29,279
you increase this number enough probably

756
00:28:27,600 --> 00:28:31,039
the pro the problem is for example for

757
00:28:29,279 --> 00:28:33,600
the fetch factor this will actually use

758
00:28:31,039 --> 00:28:38,240
a lot of memory in the tower we have

759
00:28:33,600 --> 00:28:40,799
6,000 um um measurement for each cell if

760
00:28:38,240 --> 00:28:44,720
you have a batch size of 64 then is 64x

761
00:28:40,799 --> 00:28:47,520
64 by 60,000 so if you if you start

762
00:28:44,720 --> 00:28:50,799
getting higher you will use a lot of RAM

763
00:28:47,520 --> 00:28:52,720
so there is also this um uh this issue

764
00:28:50,799 --> 00:28:55,279
but yeah I think that in single core you

765
00:28:52,720 --> 00:28:58,320
can you can get it there like doing this

766
00:28:55,279 --> 00:28:59,760
stuff. The other advantage advantage of

767
00:28:58,320 --> 00:29:02,399
using multiprocessing is that for

768
00:28:59,760 --> 00:29:04,080
example PyTorch use this prefetching. So

769
00:29:02,399 --> 00:29:05,440
you have multiple worker that prefetch

770
00:29:04,080 --> 00:29:07,600
and organize your data. If you have a

771
00:29:05,440 --> 00:29:10,880
transformation that takes time whatever

772
00:29:07,600 --> 00:29:14,399
it is like uh it will do it in parallel.

773
00:29:10,880 --> 00:29:16,720
So there is also this this thing

774
00:29:14,399 --> 00:29:18,640
we basically with this number we it like

775
00:29:16,720 --> 00:29:21,640
also the CPU bound of doing this

776
00:29:18,640 --> 00:29:21,640
operation.

777
00:29:22,880 --> 00:29:28,720
Okay, I think we can move on and then

778
00:29:24,720 --> 00:29:31,279
leave other questions for the end. Um,

779
00:29:28,720 --> 00:29:32,720
okay. So now I want to talk like about

780
00:29:31,279 --> 00:29:35,440
uh one modeling challenge that we

781
00:29:32,720 --> 00:29:38,720
encountered and like uh our little

782
00:29:35,440 --> 00:29:40,880
success story on that. Um like the

783
00:29:38,720 --> 00:29:43,360
general idea is like we really want

784
00:29:40,880 --> 00:29:46,399
those foundation model or single cell

785
00:29:43,360 --> 00:29:50,399
omix data or on biological data but so

786
00:29:46,399 --> 00:29:52,080
far we didn't see a really um like good

787
00:29:50,399 --> 00:29:54,960
models on that in the sense that there

788
00:29:52,080 --> 00:29:57,919
are a lot of works showing that linear

789
00:29:54,960 --> 00:30:00,000
baselines or some very simple uh model

790
00:29:57,919 --> 00:30:03,200
actually outperform those very big

791
00:30:00,000 --> 00:30:05,840
foundation model trains for uh for days.

792
00:30:03,200 --> 00:30:08,960
Um and so we asked the question of why

793
00:30:05,840 --> 00:30:10,960
this is happening and one of the many

794
00:30:08,960 --> 00:30:12,480
answer that you can get is uh basically

795
00:30:10,960 --> 00:30:14,399
we want to actually harness the

796
00:30:12,480 --> 00:30:16,480
structure of the biological task we're

797
00:30:14,399 --> 00:30:19,039
trying to model and the problem with

798
00:30:16,480 --> 00:30:21,360
most of these models is that they are uh

799
00:30:19,039 --> 00:30:23,200
like at at least at this like two years

800
00:30:21,360 --> 00:30:24,640
ago they were blindly inherited from

801
00:30:23,200 --> 00:30:28,159
other fields. Now we are moving towards

802
00:30:24,640 --> 00:30:31,039
this um these more biological um

803
00:30:28,159 --> 00:30:32,720
meaningful models and for example we can

804
00:30:31,039 --> 00:30:36,159
take the transformer architecture from

805
00:30:32,720 --> 00:30:37,919
like NLP and like if you want to do out

806
00:30:36,159 --> 00:30:39,679
an auto reggressive framework what you

807
00:30:37,919 --> 00:30:41,440
have to do with genes you have to order

808
00:30:39,679 --> 00:30:43,039
like you have to give an ordering of the

809
00:30:41,440 --> 00:30:45,440
genes that you usually don't have and

810
00:30:43,039 --> 00:30:47,120
then you maybe predict like the next mo

811
00:30:45,440 --> 00:30:49,200
most expressed gene but this is not

812
00:30:47,120 --> 00:30:52,480
actually the like the way you should you

813
00:30:49,200 --> 00:30:54,720
would model the task. Um so we actually

814
00:30:52,480 --> 00:30:56,880
want to build model that the structure

815
00:30:54,720 --> 00:30:58,720
and uh we took this idea and we applied

816
00:30:56,880 --> 00:30:59,919
to a very simple example which is cell

817
00:30:58,720 --> 00:31:01,760
annotation which is actually a

818
00:30:59,919 --> 00:31:03,919
downstream task that most people do like

819
00:31:01,760 --> 00:31:05,679
to test if everything works out and also

820
00:31:03,919 --> 00:31:08,640
most lab want to do like to annotate

821
00:31:05,679 --> 00:31:10,720
their cells. Um so what is cell

822
00:31:08,640 --> 00:31:12,720
annotation in particular automated cell

823
00:31:10,720 --> 00:31:15,120
annotation. The idea is that you have a

824
00:31:12,720 --> 00:31:18,799
data set and as we said before we will

825
00:31:15,120 --> 00:31:21,520
think about measurement and you want to

826
00:31:18,799 --> 00:31:24,240
put a label for each measurement of some

827
00:31:21,520 --> 00:31:25,919
kind. Uh and like to do this in an

828
00:31:24,240 --> 00:31:28,960
automated way what we can do is we can

829
00:31:25,919 --> 00:31:31,360
use some deep learning model to do this.

830
00:31:28,960 --> 00:31:34,320
And so what we will consider now is auto

831
00:31:31,360 --> 00:31:36,720
scale cell annotation.

832
00:31:34,320 --> 00:31:39,760
And in particular we will focus on the

833
00:31:36,720 --> 00:31:42,640
uh um Celix gene atlas.

834
00:31:39,760 --> 00:31:45,600
And in this case basically what we have

835
00:31:42,640 --> 00:31:47,120
is this uh wonderful work that tried to

836
00:31:45,600 --> 00:31:48,559
basically benchmark a lot of different

837
00:31:47,120 --> 00:31:51,279
methods on this annotation which is

838
00:31:48,559 --> 00:31:53,360
called SCAB. And what they what they did

839
00:31:51,279 --> 00:31:55,279
they they took their own model which

840
00:31:53,360 --> 00:31:57,600
which was the best one which is called

841
00:31:55,279 --> 00:31:59,679
it's basically a a different version of

842
00:31:57,600 --> 00:32:01,919
tubnet and they compared to a lot of

843
00:31:59,679 --> 00:32:03,519
different models a linear one an MLP and

844
00:32:01,919 --> 00:32:06,880
also like some foundational model

845
00:32:03,519 --> 00:32:08,880
fine-tuned for to do cell annotation um

846
00:32:06,880 --> 00:32:11,279
and so when when we've seen the results

847
00:32:08,880 --> 00:32:14,880
of a sit basically two things uh

848
00:32:11,279 --> 00:32:18,000
actually uh catched our attention um the

849
00:32:14,880 --> 00:32:19,760
first one is that um the difference

850
00:32:18,000 --> 00:32:22,320
between the linear

851
00:32:19,760 --> 00:32:26,000
model and the tablet model is basically

852
00:32:22,320 --> 00:32:27,679
four four percentage points which is

853
00:32:26,000 --> 00:32:30,720
very small because we are not even like

854
00:32:27,679 --> 00:32:33,039
near the one. So this task is not even

855
00:32:30,720 --> 00:32:35,519
solved is not even solved. We are around

856
00:32:33,039 --> 00:32:37,200
0.8 and there is this little difference

857
00:32:35,519 --> 00:32:39,120
between a simple linear model and the

858
00:32:37,200 --> 00:32:41,760
transformer architecture which was their

859
00:32:39,120 --> 00:32:43,519
best best performing model. Uh the

860
00:32:41,760 --> 00:32:45,440
actual linear model also perform like

861
00:32:43,519 --> 00:32:48,159
some foundation models fine-tuned on the

862
00:32:45,440 --> 00:32:49,600
task. Um so that's the first thing and

863
00:32:48,159 --> 00:32:50,960
the second thing is the way they did

864
00:32:49,600 --> 00:32:53,200
this split which we called

865
00:32:50,960 --> 00:32:54,880
indistribution test set. So what they

866
00:32:53,200 --> 00:32:57,679
did is basically they divided the data

867
00:32:54,880 --> 00:32:59,360
set in uh different patients. So you

868
00:32:57,679 --> 00:33:00,799
partition for patient you will have some

869
00:32:59,360 --> 00:33:03,279
patient in training and some patient

870
00:33:00,799 --> 00:33:04,960
test. Now if you want to do annotation

871
00:33:03,279 --> 00:33:06,640
in a real lab what will happen is that

872
00:33:04,960 --> 00:33:08,720
you will have your own data set and you

873
00:33:06,640 --> 00:33:11,440
will you would annotate all of it. You

874
00:33:08,720 --> 00:33:13,120
don't train on a portion of it before.

875
00:33:11,440 --> 00:33:15,679
So we actually wanted to consider a more

876
00:33:13,120 --> 00:33:18,960
like realistic scenario which we called

877
00:33:15,679 --> 00:33:21,840
out of distribution data set where we

878
00:33:18,960 --> 00:33:24,320
actually took whole new studies to like

879
00:33:21,840 --> 00:33:27,039
annotate and so what we did we we kept

880
00:33:24,320 --> 00:33:29,760
the original data set that SCAB used and

881
00:33:27,039 --> 00:33:31,360
we added a bunch of studies. Now those

882
00:33:29,760 --> 00:33:33,120
studies was was chosen with the same

883
00:33:31,360 --> 00:33:35,279
rules of SCAB. So we have the same

884
00:33:33,120 --> 00:33:36,880
sequencing technology and we have a

885
00:33:35,279 --> 00:33:38,960
subset of the original cell types

886
00:33:36,880 --> 00:33:41,919
because we didn't have the chance to

887
00:33:38,960 --> 00:33:44,960
cover all of them. And so we have 21 new

888
00:33:41,919 --> 00:33:46,640
studies and like we we basically found

889
00:33:44,960 --> 00:33:49,039
out two things. The first thing is that

890
00:33:46,640 --> 00:33:52,399
the performance of every model dropped a

891
00:33:49,039 --> 00:33:54,640
lot like from 25 to 32%. And the second

892
00:33:52,399 --> 00:33:56,320
thing is that in this scenario uh the

893
00:33:54,640 --> 00:33:59,279
linear model actually outperformed the

894
00:33:56,320 --> 00:34:01,679
tabet model. So like like we also seen

895
00:33:59,279 --> 00:34:03,440
before with other papers like those

896
00:34:01,679 --> 00:34:05,519
those very big models doesn't seem to

897
00:34:03,440 --> 00:34:09,359
perform really well when you test them

898
00:34:05,519 --> 00:34:11,440
in um in some scenarios. And so um we

899
00:34:09,359 --> 00:34:13,839
actually asked like why is it this the

900
00:34:11,440 --> 00:34:16,560
case and to understand this we we first

901
00:34:13,839 --> 00:34:18,879
need to understand how uh we do the

902
00:34:16,560 --> 00:34:21,119
prediction and what is considered a

903
00:34:18,879 --> 00:34:23,440
correct prediction.

904
00:34:21,119 --> 00:34:25,440
So in the in this cell annotation task

905
00:34:23,440 --> 00:34:28,639
what we have is basically we have a cell

906
00:34:25,440 --> 00:34:30,960
ontology of labels and what what happens

907
00:34:28,639 --> 00:34:33,679
uh especially for atlases even if those

908
00:34:30,960 --> 00:34:36,720
are basically harmonized is that one lab

909
00:34:33,679 --> 00:34:39,440
maybe put a more broader uh label on a

910
00:34:36,720 --> 00:34:41,440
on a cell and some other labs put a more

911
00:34:39,440 --> 00:34:43,919
granular label. So some labs maybe it's

912
00:34:41,440 --> 00:34:45,440
not really interested in lymphocytes and

913
00:34:43,919 --> 00:34:47,040
specifically lymphosy. So you just put

914
00:34:45,440 --> 00:34:48,879
lymphocytes and some others like

915
00:34:47,040 --> 00:34:51,440
distinguish between T- cell and B cell.

916
00:34:48,879 --> 00:34:54,560
Some others like for CD4 positive T cell

917
00:34:51,440 --> 00:34:56,240
CD4 CD8 positive and so on so forth so

918
00:34:54,560 --> 00:34:58,400
on. So we actually have this kind of

919
00:34:56,240 --> 00:35:00,320
hierarchy that we want to learn and so

920
00:34:58,400 --> 00:35:04,079
let's let's make an example. Let's say

921
00:35:00,320 --> 00:35:06,960
that we have um uh a true label given by

922
00:35:04,079 --> 00:35:09,839
our data set which is a lymphocy. That's

923
00:35:06,960 --> 00:35:11,280
that's all we know. Now what we can

924
00:35:09,839 --> 00:35:13,359
consider a good like a correct

925
00:35:11,280 --> 00:35:15,520
prediction from a model that learns on

926
00:35:13,359 --> 00:35:17,440
this kind of hierarchy. Of course it if

927
00:35:15,520 --> 00:35:20,560
it predicts that it's a lymphocy this is

928
00:35:17,440 --> 00:35:22,480
a correct prediction. Now if it predicts

929
00:35:20,560 --> 00:35:24,000
any of the subtype we have to consider

930
00:35:22,480 --> 00:35:25,839
this right because we don't have the

931
00:35:24,000 --> 00:35:28,079
knowledge to say it's wrong because we

932
00:35:25,839 --> 00:35:30,160
just have the more broader prediction.

933
00:35:28,079 --> 00:35:32,079
Uh and anything else is basically wrong.

934
00:35:30,160 --> 00:35:34,079
If we predict something broader or

935
00:35:32,079 --> 00:35:35,920
something different is just wrong. So

936
00:35:34,079 --> 00:35:39,280
this is basically the set thing we are

937
00:35:35,920 --> 00:35:41,520
we're into. uh and so what we actually

938
00:35:39,280 --> 00:35:43,440
want to do is learn on those directly

939
00:35:41,520 --> 00:35:45,599
graph that represent the structure of uh

940
00:35:43,440 --> 00:35:47,440
of labels in particular those labels are

941
00:35:45,599 --> 00:35:49,359
basically set inclusion. So you have

942
00:35:47,440 --> 00:35:52,960
that when you have a an arrow you say

943
00:35:49,359 --> 00:35:56,560
that uh you have a subtype which is uh a

944
00:35:52,960 --> 00:35:58,880
subtype of of the of the parent uh node.

945
00:35:56,560 --> 00:36:01,040
So we know that uh annotations have

946
00:35:58,880 --> 00:36:04,240
different granularity but what what have

947
00:36:01,040 --> 00:36:06,320
been done so far is that uh we treated

948
00:36:04,240 --> 00:36:08,560
this task as a classical like uh

949
00:36:06,320 --> 00:36:10,240
classification task and so we trained it

950
00:36:08,560 --> 00:36:11,920
with cross entropy even like in this

951
00:36:10,240 --> 00:36:15,520
study they trained it with with cross

952
00:36:11,920 --> 00:36:17,119
entropy loss. Yeah really quick question

953
00:36:15,520 --> 00:36:20,000
uh if you could go back to the hierarchy

954
00:36:17,119 --> 00:36:23,040
there. uh you you note that you you

955
00:36:20,000 --> 00:36:24,800
don't like uh you consider Luca site to

956
00:36:23,040 --> 00:36:26,560
be the the more general label to be

957
00:36:24,800 --> 00:36:28,320
incorrect but the more specific label to

958
00:36:26,560 --> 00:36:30,320
be correct and I'm I just want to note

959
00:36:28,320 --> 00:36:32,400
that I think that like or I mean I I've

960
00:36:30,320 --> 00:36:34,240
had to deal with this problem myself and

961
00:36:32,400 --> 00:36:36,880
I've had to come to the think to myself

962
00:36:34,240 --> 00:36:39,440
like when do I do I think actually a

963
00:36:36,880 --> 00:36:41,200
more general or a more specific label is

964
00:36:39,440 --> 00:36:44,320
more correct or not and I could imagine

965
00:36:41,200 --> 00:36:46,000
a situation where if you don't know a

966
00:36:44,320 --> 00:36:48,560
specific label you would prefer

967
00:36:46,000 --> 00:36:50,720
something more general where like

968
00:36:48,560 --> 00:36:52,240
>> or a if you label something a T- cell

969
00:36:50,720 --> 00:36:54,160
and it's actually a B cell that might be

970
00:36:52,240 --> 00:36:56,000
worse than labeling it as something more

971
00:36:54,160 --> 00:36:58,400
general. So I was curious how you if you

972
00:36:56,000 --> 00:36:59,040
could comment on you know that sort of

973
00:36:58,400 --> 00:37:00,880
value structure.

974
00:36:59,040 --> 00:37:02,720
>> Oh yeah. So I mean there are a couple of

975
00:37:00,880 --> 00:37:05,359
reasons. The first one is that uh also

976
00:37:02,720 --> 00:37:07,040
for example I set up did did it this way

977
00:37:05,359 --> 00:37:08,400
and the other reason is that like you

978
00:37:07,040 --> 00:37:11,520
have a model and the model will just

979
00:37:08,400 --> 00:37:13,680
take a like

980
00:37:11,520 --> 00:37:16,720
six sequence and it will have to give

981
00:37:13,680 --> 00:37:18,880
you a a label. Now this label that it

982
00:37:16,720 --> 00:37:21,119
will give you cannot depend on the on

983
00:37:18,880 --> 00:37:23,920
the label that you've put on. Like if it

984
00:37:21,119 --> 00:37:26,240
is a T- cell and it knows that that it

985
00:37:23,920 --> 00:37:28,480
learns that is a T cell you you may have

986
00:37:26,240 --> 00:37:30,720
end up with a lymphocy because you you

987
00:37:28,480 --> 00:37:33,920
didn't want to to go deeper but the

988
00:37:30,720 --> 00:37:36,480
model cannot know that. So uh like from

989
00:37:33,920 --> 00:37:38,720
like the classification task that we're

990
00:37:36,480 --> 00:37:40,320
trying to model we have to give the

991
00:37:38,720 --> 00:37:42,800
benefit of the DP to the model because

992
00:37:40,320 --> 00:37:44,800
we we don't have a more more specific

993
00:37:42,800 --> 00:37:46,560
label. The other solution is just

994
00:37:44,800 --> 00:37:48,240
basically throw away all the broader

995
00:37:46,560 --> 00:37:50,560
errors.

996
00:37:48,240 --> 00:37:52,880
But what what we'll we will actually see

997
00:37:50,560 --> 00:37:54,480
is that even if we focus just on the

998
00:37:52,880 --> 00:37:56,240
leaves, we actually get better

999
00:37:54,480 --> 00:38:00,280
performances with this method. But yeah,

1000
00:37:56,240 --> 00:38:00,280
that's a good question. Thank you.

1001
00:38:01,280 --> 00:38:04,480
>> I think that what they're implying is

1002
00:38:02,800 --> 00:38:05,839
that sort of uh and this might be an

1003
00:38:04,480 --> 00:38:08,720
analyst step, but you might want to

1004
00:38:05,839 --> 00:38:11,119
penalize the wrong label in a different

1005
00:38:08,720 --> 00:38:13,200
way and just wrong and right. So from a

1006
00:38:11,119 --> 00:38:16,000
bological standpoint again it's not part

1007
00:38:13,200 --> 00:38:17,440
of this but it's essentially the the if

1008
00:38:16,000 --> 00:38:20,160
if you can insert penalty in whatever

1009
00:38:17,440 --> 00:38:21,760
training you do um there are there are

1010
00:38:20,160 --> 00:38:23,520
biological penalties that you can sort

1011
00:38:21,760 --> 00:38:23,839
of see who's worse than others that's

1012
00:38:23,520 --> 00:38:26,240
all.

1013
00:38:23,839 --> 00:38:28,720
>> Oh yeah actually this is the point of

1014
00:38:26,240 --> 00:38:30,960
what we want to to discuss. So this is

1015
00:38:28,720 --> 00:38:32,480
just how do we evaluate things. So this

1016
00:38:30,960 --> 00:38:34,240
is basically how do we compute the

1017
00:38:32,480 --> 00:38:35,760
accuracy of the system. Now we will

1018
00:38:34,240 --> 00:38:38,560
discuss like how do we penalize the

1019
00:38:35,760 --> 00:38:40,079
model to do that. uh and basically the

1020
00:38:38,560 --> 00:38:43,280
standard strategy is that you treat

1021
00:38:40,079 --> 00:38:44,640
everything independently. And so if you

1022
00:38:43,280 --> 00:38:46,480
if you have a T- cell and you are

1023
00:38:44,640 --> 00:38:48,720
predicting it with a B cell would be

1024
00:38:46,480 --> 00:38:51,520
considered wrong but also if if you have

1025
00:38:48,720 --> 00:38:53,280
a more specific subtype of a T cell and

1026
00:38:51,520 --> 00:38:55,280
you predict that but your label is T

1027
00:38:53,280 --> 00:38:57,359
cell will be considered wrong because in

1028
00:38:55,280 --> 00:38:59,280
a classical cross entropy loss you don't

1029
00:38:57,359 --> 00:39:00,880
have any kind of structure in the data.

1030
00:38:59,280 --> 00:39:02,640
So for the model everything is

1031
00:39:00,880 --> 00:39:05,520
independent and that's basically the

1032
00:39:02,640 --> 00:39:07,520
problem that we are having. Um so our

1033
00:39:05,520 --> 00:39:09,440
solution to that was actually reflect

1034
00:39:07,520 --> 00:39:12,480
the kind of structure that we have in

1035
00:39:09,440 --> 00:39:14,240
the evaluation task. So we like if you

1036
00:39:12,480 --> 00:39:16,800
now look at all the nodes you don't have

1037
00:39:14,240 --> 00:39:18,480
a real probability distribution anymore.

1038
00:39:16,800 --> 00:39:21,119
But what what we wanted to achieve is

1039
00:39:18,480 --> 00:39:23,760
basically if you have some kind of um

1040
00:39:21,119 --> 00:39:26,240
probability scores on on some uh on some

1041
00:39:23,760 --> 00:39:27,920
nodes then your parenting category need

1042
00:39:26,240 --> 00:39:30,160
to have at least the same probability

1043
00:39:27,920 --> 00:39:32,480
distribution. uh you can make it equal

1044
00:39:30,160 --> 00:39:34,560
or you can make up make it at least like

1045
00:39:32,480 --> 00:39:36,079
having a little bit of room for like

1046
00:39:34,560 --> 00:39:38,320
something that you haven't seen or some

1047
00:39:36,079 --> 00:39:40,079
something else but basically this is um

1048
00:39:38,320 --> 00:39:43,920
this is the strategy. So we want to make

1049
00:39:40,079 --> 00:39:46,880
sure that uh if we put 0.5

1050
00:39:43,920 --> 00:39:48,320
uh probability on on gamma delta t cell

1051
00:39:46,880 --> 00:39:51,200
then we have at least that's for a

1052
00:39:48,320 --> 00:39:53,200
general t cell. Then when you train with

1053
00:39:51,200 --> 00:39:54,720
this kind of objective what happens is

1054
00:39:53,200 --> 00:39:56,400
that the interpretation of the vector

1055
00:39:54,720 --> 00:39:58,880
you are getting is different like you

1056
00:39:56,400 --> 00:40:01,040
are still predicting over the whole all

1057
00:39:58,880 --> 00:40:02,240
the nodes but now when you look at the

1058
00:40:01,040 --> 00:40:03,920
row probabilities without this

1059
00:40:02,240 --> 00:40:05,760
aggregation the interpretation is that

1060
00:40:03,920 --> 00:40:08,400
if you have some probability over a T-

1061
00:40:05,760 --> 00:40:10,320
cell you should interpret this as this

1062
00:40:08,400 --> 00:40:12,160
is a probability of being a T- cell and

1063
00:40:10,320 --> 00:40:13,760
not being any of the childs because

1064
00:40:12,160 --> 00:40:15,440
otherwise the model would have put

1065
00:40:13,760 --> 00:40:17,200
probability on that well in the

1066
00:40:15,440 --> 00:40:19,680
classical way you cannot give this

1067
00:40:17,200 --> 00:40:19,680
interpretation.

1068
00:40:20,000 --> 00:40:24,000
Uh I will I will actually show you an

1069
00:40:22,079 --> 00:40:26,800
example of synthetic data. You can

1070
00:40:24,000 --> 00:40:28,720
actually follow the the notebook on on

1071
00:40:26,800 --> 00:40:32,400
the link. You can download it. Do

1072
00:40:28,720 --> 00:40:36,079
whatever you like. Um so we just come up

1073
00:40:32,400 --> 00:40:38,079
with a random uh custom uh direct graph.

1074
00:40:36,079 --> 00:40:40,400
We make sure that it wasn't simply a

1075
00:40:38,079 --> 00:40:42,560
tree. And we have five leaves in this

1076
00:40:40,400 --> 00:40:45,200
hierarchy. Four on the on the same line

1077
00:40:42,560 --> 00:40:47,040
and one slightly before. And basically

1078
00:40:45,200 --> 00:40:49,680
what we did we generated some synthetic

1079
00:40:47,040 --> 00:40:53,520
data where basically each spot

1080
00:40:49,680 --> 00:40:55,920
correspond to one leave. Um and then

1081
00:40:53,520 --> 00:40:58,480
what we did is basically um the color

1082
00:40:55,920 --> 00:41:01,680
assigned to to to each cell was either

1083
00:40:58,480 --> 00:41:03,760
the leave or any of its ancestor.

1084
00:41:01,680 --> 00:41:05,920
So uh the actual generation process is

1085
00:41:03,760 --> 00:41:07,760
that each of those five spot correspond

1086
00:41:05,920 --> 00:41:09,760
to one of the leaves. But we we puted

1087
00:41:07,760 --> 00:41:11,680
labels following the hierarchy. So for

1088
00:41:09,760 --> 00:41:14,720
example in one spot you can have both

1089
00:41:11,680 --> 00:41:16,880
the label of like the leave eight the

1090
00:41:14,720 --> 00:41:20,400
leaf eight or even like its parent four

1091
00:41:16,880 --> 00:41:22,079
or one or zero but not the other

1092
00:41:20,400 --> 00:41:24,240
and what we did we trained a very simple

1093
00:41:22,079 --> 00:41:26,640
model it's actually a two layer MLP the

1094
00:41:24,240 --> 00:41:29,920
simplest you can get with a cross center

1095
00:41:26,640 --> 00:41:33,040
and hard no parameter tuning like it's

1096
00:41:29,920 --> 00:41:36,000
just like I think 100

1097
00:41:33,040 --> 00:41:38,480
100 um uh parameter model something very

1098
00:41:36,000 --> 00:41:41,200
easy and what we get out of this is with

1099
00:41:38,480 --> 00:41:43,760
cross entropy you an accuracy of um 0

1100
00:41:41,200 --> 00:41:45,760
almost 0.6 when hierarchal cross center

1101
00:41:43,760 --> 00:41:47,359
you almost get one. But the cool thing

1102
00:41:45,760 --> 00:41:49,359
about the to example we can actually

1103
00:41:47,359 --> 00:41:52,480
easily visualize what does it mean from

1104
00:41:49,359 --> 00:41:54,800
in the in the trudy space and so what

1105
00:41:52,480 --> 00:41:57,119
happens in the cross entropy case is

1106
00:41:54,800 --> 00:41:59,280
that since all labels are basically

1107
00:41:57,119 --> 00:42:01,280
independent one from another uh the

1108
00:41:59,280 --> 00:42:03,440
model get confused and doesn't know

1109
00:42:01,280 --> 00:42:05,440
which label assigned to each spot. So

1110
00:42:03,440 --> 00:42:07,359
maybe if you if you get more of one

1111
00:42:05,440 --> 00:42:11,839
label than the other probably this will

1112
00:42:07,359 --> 00:42:13,280
take um um this will take the whole spot

1113
00:42:11,839 --> 00:42:14,960
since the model is very simple. You can

1114
00:42:13,280 --> 00:42:17,680
go more granular but basically you will

1115
00:42:14,960 --> 00:42:20,079
never be able to like assign the correct

1116
00:42:17,680 --> 00:42:23,440
probabilities. While in our case what

1117
00:42:20,079 --> 00:42:27,520
what what you will see is basically each

1118
00:42:23,440 --> 00:42:30,240
spot get the label corresponding to the

1119
00:42:27,520 --> 00:42:33,599
corresponding leave uh leaf and the

1120
00:42:30,240 --> 00:42:35,359
reason for that is that if I give in the

1121
00:42:33,599 --> 00:42:37,920
model a high probability for example to

1122
00:42:35,359 --> 00:42:40,480
the leaf eight I'm also giving the same

1123
00:42:37,920 --> 00:42:46,040
probability to the leaf to the node four

1124
00:42:40,480 --> 00:42:46,040
one and zero because we are up yes

1125
00:42:47,359 --> 00:42:51,760
okay because we are basically up pro

1126
00:42:50,160 --> 00:42:53,359
propagating this probability. So now the

1127
00:42:51,760 --> 00:42:55,680
model doesn't get confused anymore and

1128
00:42:53,359 --> 00:42:59,000
basically almost every prediction falls

1129
00:42:55,680 --> 00:42:59,000
down to the

1130
00:42:59,200 --> 00:43:04,640
um okay and now like yeah now we can

1131
00:43:02,720 --> 00:43:09,200
show some results on on the actual like

1132
00:43:04,640 --> 00:43:10,880
uh atlas scale um data set and so first

1133
00:43:09,200 --> 00:43:12,400
of all those are the results of three

1134
00:43:10,880 --> 00:43:13,920
model those three models are deep

1135
00:43:12,400 --> 00:43:17,520
learning models that are trained end to

1136
00:43:13,920 --> 00:43:19,280
end from the SCAB study we kept exactly

1137
00:43:17,520 --> 00:43:21,359
the same upper parameters that they

1138
00:43:19,280 --> 00:43:23,280
found optimal we just changed change the

1139
00:43:21,359 --> 00:43:25,280
loss. We didn't run another

1140
00:43:23,280 --> 00:43:28,000
hyperparameter optimization. So those

1141
00:43:25,280 --> 00:43:29,839
can be also sub-optimal as results. So

1142
00:43:28,000 --> 00:43:34,160
you can see on the on the gray bar the

1143
00:43:29,839 --> 00:43:36,079
the cross entropy um um performance

1144
00:43:34,160 --> 00:43:38,720
which was the one dropped by basically

1145
00:43:36,079 --> 00:43:40,800
25 points and then on the right the

1146
00:43:38,720 --> 00:43:44,319
hierarchical cross entropy performance

1147
00:43:40,800 --> 00:43:46,160
which is basically 12 to 15% more

1148
00:43:44,319 --> 00:43:48,160
performant than the than the

1149
00:43:46,160 --> 00:43:50,160
corresponding cross entropy loss. Then

1150
00:43:48,160 --> 00:43:52,160
what we did we also analyzed like how

1151
00:43:50,160 --> 00:43:54,000
does it like this is basically a bulk

1152
00:43:52,160 --> 00:43:55,760
measurement per model. We actually

1153
00:43:54,000 --> 00:43:59,359
wanted to see how does it work for

1154
00:43:55,760 --> 00:44:01,280
example for each cell type. Uh so those

1155
00:43:59,359 --> 00:44:03,280
results are for the MLP model. This and

1156
00:44:01,280 --> 00:44:04,800
the next one all for the MLP model. We

1157
00:44:03,280 --> 00:44:06,640
have very similar results also for the

1158
00:44:04,800 --> 00:44:08,960
other models. So what we can see is

1159
00:44:06,640 --> 00:44:11,119
basically so those are the 80 cell types

1160
00:44:08,960 --> 00:44:14,000
that we found in the out of distribution

1161
00:44:11,119 --> 00:44:16,720
setting and every um significant

1162
00:44:14,000 --> 00:44:18,400
improvement is basically an every every

1163
00:44:16,720 --> 00:44:21,280
significant change is an improvement

1164
00:44:18,400 --> 00:44:23,680
over the the cross standard cross

1165
00:44:21,280 --> 00:44:26,240
entropy. We just found one of two cases

1166
00:44:23,680 --> 00:44:28,079
for the linear model where there is a a

1167
00:44:26,240 --> 00:44:29,839
sign like statistically significant

1168
00:44:28,079 --> 00:44:32,480
decline. But we also have to say that

1169
00:44:29,839 --> 00:44:34,000
the linear model is very simple. But for

1170
00:44:32,480 --> 00:44:36,160
the MLP and the tablet, every

1171
00:44:34,000 --> 00:44:38,960
improvement, every statistical change is

1172
00:44:36,160 --> 00:44:41,200
an improvement. This is for cell type

1173
00:44:38,960 --> 00:44:43,119
and also we looked at the at actual

1174
00:44:41,200 --> 00:44:44,880
studies since what you want to do is

1175
00:44:43,119 --> 00:44:46,480
just give you a new study and so we

1176
00:44:44,880 --> 00:44:47,839
wanted to see if for each study we

1177
00:44:46,480 --> 00:44:49,680
actually get an improvement and that's

1178
00:44:47,839 --> 00:44:51,760
also the case like every statistical

1179
00:44:49,680 --> 00:44:56,319
change is actually an improvement over

1180
00:44:51,760 --> 00:44:58,000
the the previous um result and I think

1181
00:44:56,319 --> 00:45:01,119
that's it that's a summary you can look

1182
00:44:58,000 --> 00:45:02,960
at the paper on the on the QR code and

1183
00:45:01,119 --> 00:45:04,720
yeah like we proposed this hierarchal

1184
00:45:02,960 --> 00:45:06,880
cross entropy loss and we have shown

1185
00:45:04,720 --> 00:45:08,000
that this improves out of distribution

1186
00:45:06,880 --> 00:45:10,079
generalization

1187
00:45:08,000 --> 00:45:12,640
on every cell type of any study. We also

1188
00:45:10,079 --> 00:45:15,040
have um some other plots on like tissues

1189
00:45:12,640 --> 00:45:17,040
disease. We basically have uh uniform

1190
00:45:15,040 --> 00:45:19,200
improvement over any kind of

1191
00:45:17,040 --> 00:45:20,960
categorization you you will get. And

1192
00:45:19,200 --> 00:45:22,880
also this idea can be extended to any

1193
00:45:20,960 --> 00:45:25,440
scenario. Uh there are not many

1194
00:45:22,880 --> 00:45:27,520
scenarios out there outside of biology.

1195
00:45:25,440 --> 00:45:29,440
But if you have some labels even for

1196
00:45:27,520 --> 00:45:31,359
like image classification where you have

1197
00:45:29,440 --> 00:45:33,359
this kind of set inclusion relationship,

1198
00:45:31,359 --> 00:45:35,359
you can also do that. like if you have a

1199
00:45:33,359 --> 00:45:38,960
a label that is an animal then you can

1200
00:45:35,359 --> 00:45:42,560
do this kind of uh play with like cat

1201
00:45:38,960 --> 00:45:44,720
and dog belonging both to animal. Um and

1202
00:45:42,560 --> 00:45:46,400
this is in general a big opportunity for

1203
00:45:44,720 --> 00:45:47,839
designing new architecture and training

1204
00:45:46,400 --> 00:45:49,280
strategies for biological task because

1205
00:45:47,839 --> 00:45:51,200
we have shown that no matter the

1206
00:45:49,280 --> 00:45:54,240
architecture you choose like a simple

1207
00:45:51,200 --> 00:45:56,160
linear or more complex transformer you

1208
00:45:54,240 --> 00:45:59,680
basically get improvement if you model

1209
00:45:56,160 --> 00:46:04,000
the task correct and I think that's it.

1210
00:45:59,680 --> 00:46:08,359
Yeah, thank you m Thank you very much.

1211
00:46:04,000 --> 00:46:08,359
>> Thank you David. Time for questions.

1212
00:46:11,440 --> 00:46:16,640
>> Um hi again great great work. Um and I

1213
00:46:14,640 --> 00:46:18,240
I'm I'm very very happy that people are

1214
00:46:16,640 --> 00:46:19,760
starting incorporating biological sort

1215
00:46:18,240 --> 00:46:21,680
of thinking and how they actually model

1216
00:46:19,760 --> 00:46:24,720
it because it will make a huge

1217
00:46:21,680 --> 00:46:26,000
difference. Um I guess what I have one

1218
00:46:24,720 --> 00:46:28,000
question about sort of your comment

1219
00:46:26,000 --> 00:46:32,400
about the fact that you can only reach

1220
00:46:28,000 --> 00:46:34,000
only reach about 84 um% accuracy. Um one

1221
00:46:32,400 --> 00:46:35,760
of one of the issues that we practical

1222
00:46:34,000 --> 00:46:37,359
issue that we're having is that you know

1223
00:46:35,760 --> 00:46:40,079
we need to find a ground truth when you

1224
00:46:37,359 --> 00:46:42,560
look at a cell access is like somebody

1225
00:46:40,079 --> 00:46:45,599
annotating that cell. So you're

1226
00:46:42,560 --> 00:46:47,839
basically uh using the ground truth on

1227
00:46:45,599 --> 00:46:49,839
partial truth and like it's literally

1228
00:46:47,839 --> 00:46:51,760
partial truth. So I even doubt that you

1229
00:46:49,839 --> 00:46:54,480
ever get 100% because you'd have to sort

1230
00:46:51,760 --> 00:46:57,200
of verify multiple wrong I say. So

1231
00:46:54,480 --> 00:46:59,520
that's that's one thing. Um and two I

1232
00:46:57,200 --> 00:47:02,560
think uh you know we practically

1233
00:46:59,520 --> 00:47:05,119
speaking um we actually use a signature

1234
00:47:02,560 --> 00:47:07,359
based nonAI model to annotate the cells

1235
00:47:05,119 --> 00:47:08,960
in which you basically use but we use

1236
00:47:07,359 --> 00:47:10,480
hierarchical

1237
00:47:08,960 --> 00:47:12,319
cell annotation which basically means

1238
00:47:10,480 --> 00:47:13,920
that every cell that we annotate doesn't

1239
00:47:12,319 --> 00:47:16,079
have one label which is flat but

1240
00:47:13,920 --> 00:47:17,920
actually has like a tree annotation.

1241
00:47:16,079 --> 00:47:19,599
Yeah. Um is there any way you can train

1242
00:47:17,920 --> 00:47:21,760
on that first of all?

1243
00:47:19,599 --> 00:47:23,520
>> Uh I think it depends on how do you do

1244
00:47:21,760 --> 00:47:25,920
you implement that. Uh I think that in

1245
00:47:23,520 --> 00:47:27,920
SCB paper they they compare to cell

1246
00:47:25,920 --> 00:47:29,359
typist which I think works like that.

1247
00:47:27,920 --> 00:47:32,240
I'm not sure but I think those are

1248
00:47:29,359 --> 00:47:34,400
basically um logistic regret like a tree

1249
00:47:32,240 --> 00:47:36,000
of logistic regressors. So you do you do

1250
00:47:34,400 --> 00:47:38,000
this kind of job and they show that

1251
00:47:36,000 --> 00:47:40,800
basically they outperform also that in

1252
00:47:38,000 --> 00:47:42,079
their study. Uh I mean one can think of

1253
00:47:40,800 --> 00:47:43,839
training or something like that depends

1254
00:47:42,079 --> 00:47:45,760
on how you define the model I guess. And

1255
00:47:43,839 --> 00:47:46,960
secondly, I know this this goes all into

1256
00:47:45,760 --> 00:47:48,800
the biological expertise and maybe this

1257
00:47:46,960 --> 00:47:50,640
is outside of your realm of interest,

1258
00:47:48,800 --> 00:47:52,480
but for example, one of the one of the

1259
00:47:50,640 --> 00:47:55,280
uh sort of improvement that you show in

1260
00:47:52,480 --> 00:47:57,359
the last was like T17 cells if I saw

1261
00:47:55,280 --> 00:47:58,880
correctly. And I think I mean from a

1262
00:47:57,359 --> 00:48:00,319
from an application point of view, it'

1263
00:47:58,880 --> 00:48:03,200
be really really interesting if you're

1264
00:48:00,319 --> 00:48:04,800
actually able to prove that those cells

1265
00:48:03,200 --> 00:48:06,800
have the phenotype that you're looking

1266
00:48:04,800 --> 00:48:08,160
for. Uh so that you kind of like you

1267
00:48:06,800 --> 00:48:09,520
kind of run an experiment in which you

1268
00:48:08,160 --> 00:48:12,079
do single cell sequencing and you do

1269
00:48:09,520 --> 00:48:13,920
cytoine labels or cytoine measurements

1270
00:48:12,079 --> 00:48:15,760
and then you run your and then you try

1271
00:48:13,920 --> 00:48:17,440
to identify them and see whether you can

1272
00:48:15,760 --> 00:48:19,599
actually tell apart like the functional

1273
00:48:17,440 --> 00:48:21,920
state which is what's really sort of um

1274
00:48:19,599 --> 00:48:24,079
hard to define in these com in these

1275
00:48:21,920 --> 00:48:26,000
very sort of fine grained sort of T

1276
00:48:24,079 --> 00:48:26,720
cells and B cell states.

1277
00:48:26,000 --> 00:48:29,280
>> Anyway, great job.

1278
00:48:26,720 --> 00:48:30,880
>> Yeah, thank you for the suggestion

1279
00:48:29,280 --> 00:48:33,760
>> over here. Thank you so much. It's a

1280
00:48:30,880 --> 00:48:35,839
very very cool topic. Um

1281
00:48:33,760 --> 00:48:38,960
some of what we've seen in in the lab is

1282
00:48:35,839 --> 00:48:40,640
that it's very hard to uh annotate cells

1283
00:48:38,960 --> 00:48:42,000
that are have very low cell numbers

1284
00:48:40,640 --> 00:48:43,440
especially with the cross entropy. Do

1285
00:48:42,000 --> 00:48:44,800
you see the biggest improvements here in

1286
00:48:43,440 --> 00:48:46,400
the performance of the model in those

1287
00:48:44,800 --> 00:48:47,680
cells that have very few numbers in the

1288
00:48:46,400 --> 00:48:49,119
the training set?

1289
00:48:47,680 --> 00:48:51,520
>> Um have to look at that.

1290
00:48:49,119 --> 00:48:52,640
>> Uh so you mean like rare cell type get

1291
00:48:51,520 --> 00:48:53,359
better improvement?

1292
00:48:52,640 --> 00:48:55,760
>> Correct.

1293
00:48:53,359 --> 00:48:57,440
>> Um I think it's uh we had some plot I

1294
00:48:55,760 --> 00:48:59,920
think it's pretty independent on on the

1295
00:48:57,440 --> 00:49:01,680
rarity of the sub type. uh it has more

1296
00:48:59,920 --> 00:49:05,440
to do. So basically when you when you

1297
00:49:01,680 --> 00:49:08,000
have this um uh

1298
00:49:05,440 --> 00:49:09,680
hierarchy that that is basically derived

1299
00:49:08,000 --> 00:49:10,960
from like the cell types that you have

1300
00:49:09,680 --> 00:49:12,240
it's just basically you take the

1301
00:49:10,960 --> 00:49:15,359
celltology and then you take the

1302
00:49:12,240 --> 00:49:17,119
subgraph uh induced by those cells. It

1303
00:49:15,359 --> 00:49:19,200
uh it actually happens that some cells

1304
00:49:17,119 --> 00:49:20,960
are disconnected from this graph because

1305
00:49:19,200 --> 00:49:23,440
you don't have maybe the parents in the

1306
00:49:20,960 --> 00:49:24,720
the annotations. So we saw the biggest

1307
00:49:23,440 --> 00:49:26,160
improvement where you actually have

1308
00:49:24,720 --> 00:49:28,160
distraction like for example for the

1309
00:49:26,160 --> 00:49:29,359
isolated nodes you don't get much

1310
00:49:28,160 --> 00:49:30,559
improvement because it doesn't make

1311
00:49:29,359 --> 00:49:33,839
really a difference because you don't

1312
00:49:30,559 --> 00:49:35,680
have this um this hierarchy but for

1313
00:49:33,839 --> 00:49:38,640
other things I would say is pretty

1314
00:49:35,680 --> 00:49:41,800
independent for example the

1315
00:49:38,640 --> 00:49:41,800
>> thank you

1316
00:49:46,319 --> 00:49:50,800
>> do you think if you trained on a mixture

1317
00:49:48,319 --> 00:49:53,280
of let's say coarse and fine labels but

1318
00:49:50,800 --> 00:49:55,680
then only evaluate ated on the finest

1319
00:49:53,280 --> 00:49:58,240
grain labels you had, you would still

1320
00:49:55,680 --> 00:49:59,599
see the same lift with the hierarchical

1321
00:49:58,240 --> 00:50:01,119
loss compared to the same

1322
00:49:59,599 --> 00:50:02,640
>> would you still see the same boost from

1323
00:50:01,119 --> 00:50:03,119
the hierarchical loss compared to the

1324
00:50:02,640 --> 00:50:05,359
standard?

1325
00:50:03,119 --> 00:50:09,040
>> Uh yeah, I would say so. Uh so we also

1326
00:50:05,359 --> 00:50:11,760
have like the kind of um plot of the um

1327
00:50:09,040 --> 00:50:14,160
like like 2D plot of how the cells are

1328
00:50:11,760 --> 00:50:16,160
organized. uh as I said this is also

1329
00:50:14,160 --> 00:50:17,760
independent mostly independent I mean

1330
00:50:16,160 --> 00:50:19,440
there is a little bit of skewess but

1331
00:50:17,760 --> 00:50:21,680
mostly independent from leaves or

1332
00:50:19,440 --> 00:50:24,240
internal nodes and basically as you can

1333
00:50:21,680 --> 00:50:25,680
see we have where is it we have

1334
00:50:24,240 --> 00:50:27,200
basically an improvement over all cell

1335
00:50:25,680 --> 00:50:29,200
types this also includes the leaves

1336
00:50:27,200 --> 00:50:31,839
which are most of them I would say like

1337
00:50:29,200 --> 00:50:33,280
half of them will be leaves so yeah you

1338
00:50:31,839 --> 00:50:35,440
I don't know if it would be exactly the

1339
00:50:33,280 --> 00:50:37,200
same maybe maybe two points less two

1340
00:50:35,440 --> 00:50:38,559
points more but basically you will see

1341
00:50:37,200 --> 00:50:40,559
>> the reason why I asked is I'm thinking

1342
00:50:38,559 --> 00:50:42,640
about the case where your label is

1343
00:50:40,559 --> 00:50:44,880
lymphosy in the training data and the

1344
00:50:42,640 --> 00:50:47,119
model predicts T- cell but the true cell

1345
00:50:44,880 --> 00:50:49,839
is a B cell and they can become overly

1346
00:50:47,119 --> 00:50:52,319
confident in its predictions at the

1347
00:50:49,839 --> 00:50:54,319
finer grained labels I could see that

1348
00:50:52,319 --> 00:50:57,119
maybe hurting performance at certain

1349
00:50:54,319 --> 00:50:59,680
levels of the hierarchy at test time

1350
00:50:57,119 --> 00:51:00,800
yeah but like what's the alternative in

1351
00:50:59,680 --> 00:51:03,760
the sense that like with the cross

1352
00:51:00,800 --> 00:51:05,680
entropy it even if it doesn't get like

1353
00:51:03,760 --> 00:51:08,400
overconfident if you predicts the

1354
00:51:05,680 --> 00:51:10,960
broader one is still not correct for

1355
00:51:08,400 --> 00:51:12,079
from our point of view like from the

1356
00:51:10,960 --> 00:51:13,760
>> yeah

1357
00:51:12,079 --> 00:51:15,359
in its sense of what the finer grain

1358
00:51:13,760 --> 00:51:18,559
labels are, those points end up becoming

1359
00:51:15,359 --> 00:51:19,920
like noise, right? Because it see it

1360
00:51:18,559 --> 00:51:21,280
predicts a T- cell and it thinks it's

1361
00:51:19,920 --> 00:51:23,680
correct even when it's actually a B

1362
00:51:21,280 --> 00:51:26,720
cell. So that test you're only focusing

1363
00:51:23,680 --> 00:51:28,800
on the finer grain cells than I could

1364
00:51:26,720 --> 00:51:31,599
say maybe being less certain about the

1365
00:51:28,800 --> 00:51:32,559
finer grained classifications.

1366
00:51:31,599 --> 00:51:34,319
>> I'm not sure.

1367
00:51:32,559 --> 00:51:36,640
>> I I can see the point. I would say like

1368
00:51:34,319 --> 00:51:38,400
what we have served is that like on

1369
00:51:36,640 --> 00:51:39,359
specifically siblings usually you get

1370
00:51:38,400 --> 00:51:43,480
better performance.

1371
00:51:39,359 --> 00:51:43,480
>> Okay. Interesting. Okay. Cool. Any

1372
00:51:45,280 --> 00:51:50,400
other question for David?

1373
00:51:47,839 --> 00:51:53,359
>> I actually have one. Uh you mentioned

1374
00:51:50,400 --> 00:51:54,880
briefly that your uh you said the the

1375
00:51:53,359 --> 00:51:56,000
linear model showed I think maybe the

1376
00:51:54,880 --> 00:51:57,280
least improvement or something like

1377
00:51:56,000 --> 00:51:58,960
that. And I was curious about that

1378
00:51:57,280 --> 00:52:00,400
because one of the things that I I like

1379
00:51:58,960 --> 00:52:01,680
to do sometimes is I like to have a

1380
00:52:00,400 --> 00:52:03,040
linear model for things because you can

1381
00:52:01,680 --> 00:52:05,040
just check and see what it is. Like why

1382
00:52:03,040 --> 00:52:07,359
does it think this? Um they're very

1383
00:52:05,040 --> 00:52:08,880
interpretable and I was you know so I I

1384
00:52:07,359 --> 00:52:10,240
like to try and give them some credit

1385
00:52:08,880 --> 00:52:12,000
whenever I can. I was curious if you

1386
00:52:10,240 --> 00:52:14,160
could comment on you know the the

1387
00:52:12,000 --> 00:52:17,760
failure mode there a little bit more.

1388
00:52:14,160 --> 00:52:20,160
>> Uh I think we didn't really um analyze

1389
00:52:17,760 --> 00:52:22,240
that. So what you're saying is that for

1390
00:52:20,160 --> 00:52:24,400
example in this case the linear model

1391
00:52:22,240 --> 00:52:24,880
without proenter is outperforming the

1392
00:52:24,400 --> 00:52:26,480
tablet

1393
00:52:24,880 --> 00:52:28,480
>> or I mean I think you mentioned at some

1394
00:52:26,480 --> 00:52:32,079
point that you saw more declines.

1395
00:52:28,480 --> 00:52:34,160
>> Oh yeah yeah. So yeah it's basically the

1396
00:52:32,079 --> 00:52:36,240
same but probably here it's easier to

1397
00:52:34,160 --> 00:52:37,760
see. Yeah, like when you evaluate an out

1398
00:52:36,240 --> 00:52:40,640
of distribution, you basically see that

1399
00:52:37,760 --> 00:52:43,119
the tablet drops 32% in performance and

1400
00:52:40,640 --> 00:52:45,520
linear 25. We actually didn't analyze

1401
00:52:43,119 --> 00:52:48,319
like the model failure like we didn't

1402
00:52:45,520 --> 00:52:50,160
check into the linear model. But like if

1403
00:52:48,319 --> 00:52:52,960
I have to guess why this is happening is

1404
00:52:50,160 --> 00:52:55,839
because the tabet model can pick up like

1405
00:52:52,960 --> 00:52:58,640
um biases in the data more easily. So

1406
00:52:55,839 --> 00:53:01,040
maybe pick up like lab specific

1407
00:52:58,640 --> 00:53:03,040
technical like technical artifacts and

1408
00:53:01,040 --> 00:53:05,680
so this can be translated from patient

1409
00:53:03,040 --> 00:53:07,440
to patient while in the linear model

1410
00:53:05,680 --> 00:53:09,200
maybe you cannot do that. So in out of

1411
00:53:07,440 --> 00:53:13,480
distribution this drops performance more

1412
00:53:09,200 --> 00:53:13,480
than the other but we didn't really look

1413
00:53:14,640 --> 00:53:18,490
right okay so let's give David a round

1414
00:53:17,040 --> 00:53:20,720
of applause.

1415
00:53:18,490 --> 00:53:23,760
[Applause]

1416
00:53:20,720 --> 00:53:25,359
Um so I suggest we take a five minutes

1417
00:53:23,760 --> 00:53:27,680
break and we start again at 10 with

1418
00:53:25,359 --> 00:53:30,839
Lauren's talk. Um so yeah see you in

1419
00:53:27,680 --> 00:53:30,839
five minutes.

1420
00:53:32,480 --> 00:53:36,880
So it's my pleasure to introduce uh

1421
00:53:34,319 --> 00:53:39,920
Lauren Crawford principal researcher at

1422
00:53:36,880 --> 00:53:41,839
Microsoft who co-directs a group here

1423
00:53:39,920 --> 00:53:42,960
also up the broad called project Xvivo

1424
00:53:41,839 --> 00:53:45,599
is going to tell us a little bit more

1425
00:53:42,960 --> 00:53:47,440
about it. Um and today the title of his

1426
00:53:45,599 --> 00:53:48,800
talk is when more isn't better

1427
00:53:47,440 --> 00:53:50,559
rethinking scale in single cell

1428
00:53:48,800 --> 00:53:50,880
foundation models. Lauren, the floor is

1429
00:53:50,559 --> 00:53:52,640
yours.

1430
00:53:50,880 --> 00:53:55,440
>> Awesome. Uh, thanks everyone for coming

1431
00:53:52,640 --> 00:53:57,440
and hanging out for the extra hour. Um,

1432
00:53:55,440 --> 00:53:58,559
so a couple things. Um, I hope this talk

1433
00:53:57,440 --> 00:54:00,319
is a little bit of everything. A little

1434
00:53:58,559 --> 00:54:02,079
bit of like shameless plugs for our

1435
00:54:00,319 --> 00:54:04,880
group. Uh, a little bit of, uh,

1436
00:54:02,079 --> 00:54:08,079
internship calls for MSR. Uh, and then

1437
00:54:04,880 --> 00:54:09,920
also science. Um, the title is a new

1438
00:54:08,079 --> 00:54:11,920
working title that I decided to use just

1439
00:54:09,920 --> 00:54:13,760
for this talk. Um, there's going to be

1440
00:54:11,920 --> 00:54:15,119
some negative results, but I don't want

1441
00:54:13,760 --> 00:54:17,440
you to take this as like I don't like

1442
00:54:15,119 --> 00:54:20,480
foundation models. Um, I hope you see it

1443
00:54:17,440 --> 00:54:22,240
as a a a place for opportunity, let's

1444
00:54:20,480 --> 00:54:24,319
call it that, for for future development

1445
00:54:22,240 --> 00:54:25,680
stuff. Um, so for those who don't know,

1446
00:54:24,319 --> 00:54:27,040
I'm a I'm a researcher at Microsoft

1447
00:54:25,680 --> 00:54:28,400
Research. I always kind of start these

1448
00:54:27,040 --> 00:54:29,680
talks particularly in groups like this

1449
00:54:28,400 --> 00:54:32,559
because I don't know if everyone knows

1450
00:54:29,680 --> 00:54:35,200
what MSR is. Um, Microsoft Research is a

1451
00:54:32,559 --> 00:54:38,720
global organization. Uh, we have labs

1452
00:54:35,200 --> 00:54:40,000
stationed all over uh the globe. Um, and

1453
00:54:38,720 --> 00:54:41,520
you might ask like what is it that

1454
00:54:40,000 --> 00:54:42,800
people at Microsoft Research do? And the

1455
00:54:41,520 --> 00:54:44,559
answer to that question is like kind of

1456
00:54:42,800 --> 00:54:47,440
a lot of stuff, almost like everything.

1457
00:54:44,559 --> 00:54:48,880
Um there are people who are in yes

1458
00:54:47,440 --> 00:54:51,040
computer science but also people like

1459
00:54:48,880 --> 00:54:52,720
myself in in biology. Uh there are also

1460
00:54:51,040 --> 00:54:55,520
people like in in quantum physics and

1461
00:54:52,720 --> 00:54:58,400
things like this. Um I am part of what

1462
00:54:55,520 --> 00:55:01,280
they call uh the bioml machine learning

1463
00:54:58,400 --> 00:55:03,119
group. Uh which is a subgroup of a thing

1464
00:55:01,280 --> 00:55:05,599
called health futures which is a the

1465
00:55:03,119 --> 00:55:08,160
life sciences and biological arm of

1466
00:55:05,599 --> 00:55:11,599
Microsoft. Uh people primarily stationed

1467
00:55:08,160 --> 00:55:13,040
in uh Redmond but also in uh uh here in

1468
00:55:11,599 --> 00:55:16,640
Cambridge and then also in in real

1469
00:55:13,040 --> 00:55:20,000
Cambridge, UK. Um and so the biomel team

1470
00:55:16,640 --> 00:55:21,680
uh is uh kind of spread out across

1471
00:55:20,000 --> 00:55:24,240
different uh both roles and also

1472
00:55:21,680 --> 00:55:27,040
disciplines. Um so you have people who

1473
00:55:24,240 --> 00:55:28,800
are uh both applied scientists, people

1474
00:55:27,040 --> 00:55:30,800
are researchers and we also have an an

1475
00:55:28,800 --> 00:55:32,000
RA program uh for people who are just

1476
00:55:30,800 --> 00:55:35,599
coming out of undergrad which is also

1477
00:55:32,000 --> 00:55:38,640
really nice. Um so what is it that we

1478
00:55:35,599 --> 00:55:41,599
all kind of do? Uh so you know broadly

1479
00:55:38,640 --> 00:55:43,440
speaking uh bioml kind of covers

1480
00:55:41,599 --> 00:55:45,200
different scales of biology if you will.

1481
00:55:43,440 --> 00:55:46,800
You have people like Kevin Yang who are

1482
00:55:45,200 --> 00:55:49,119
working on protein language based models

1483
00:55:46,800 --> 00:55:51,359
on this like kind of molecule stack. Uh

1484
00:55:49,119 --> 00:55:54,400
people like myself working in cells. Uh

1485
00:55:51,359 --> 00:55:56,640
people like uh uh Kristen Severson and

1486
00:55:54,400 --> 00:55:58,799
uh uh Alex Lou working on this like kind

1487
00:55:56,640 --> 00:56:00,319
of tissue level thing with things like

1488
00:55:58,799 --> 00:56:02,079
histopathology. There's also like things

1489
00:56:00,319 --> 00:56:04,160
like microscopy and they also have

1490
00:56:02,079 --> 00:56:06,960
people uh working on this kind of uh

1491
00:56:04,160 --> 00:56:08,559
patient uh stack here. Um for my for

1492
00:56:06,960 --> 00:56:11,280
myself I'm a my background is I'm a

1493
00:56:08,559 --> 00:56:14,160
statistician by training. I was uh I

1494
00:56:11,280 --> 00:56:16,160
worked uh kind of on interpretable

1495
00:56:14,160 --> 00:56:17,359
machine learning. My research program is

1496
00:56:16,160 --> 00:56:19,040
kind of this idea of how do you

1497
00:56:17,359 --> 00:56:20,400
understand how non-additive variation

1498
00:56:19,040 --> 00:56:22,319
plays a role in complex traits and

1499
00:56:20,400 --> 00:56:24,319
diseases. Um you can think about that in

1500
00:56:22,319 --> 00:56:26,319
statistical genetics. So this idea of

1501
00:56:24,319 --> 00:56:28,240
you know I can study how gene A's effect

1502
00:56:26,319 --> 00:56:30,160
plus gene B gives rise to a trait but

1503
00:56:28,240 --> 00:56:32,960
also how gene AA's effect times gene B

1504
00:56:30,160 --> 00:56:35,599
gives rise to a trait. Um and can we use

1505
00:56:32,960 --> 00:56:36,880
uh ML to kind of look over large search

1506
00:56:35,599 --> 00:56:39,119
spaces to understand where these

1507
00:56:36,880 --> 00:56:41,200
interactions occur or don't occur. Um, I

1508
00:56:39,119 --> 00:56:42,640
was also co-advised uh and some by

1509
00:56:41,200 --> 00:56:44,640
someone in pharmacology cancer biology

1510
00:56:42,640 --> 00:56:45,839
through my PhD at Duke. And so I've kind

1511
00:56:44,640 --> 00:56:46,880
of gotten back to my roots and really

1512
00:56:45,839 --> 00:56:48,720
thinking about this on this cancer

1513
00:56:46,880 --> 00:56:51,440
stack. So thinking about problems in in

1514
00:56:48,720 --> 00:56:53,680
cell biology very similar style of

1515
00:56:51,440 --> 00:56:55,599
questions this idea of now not gene A's

1516
00:56:53,680 --> 00:56:57,599
affect gene and plus gene B on a complex

1517
00:56:55,599 --> 00:56:58,880
trait for patients on the patient scale

1518
00:56:57,599 --> 00:57:00,960
for things like heightened body mass

1519
00:56:58,880 --> 00:57:02,640
index but things like uh how do I

1520
00:57:00,960 --> 00:57:04,079
understand how interaction between genes

1521
00:57:02,640 --> 00:57:07,920
or pathways play a role in my

1522
00:57:04,079 --> 00:57:09,440
therapeutic resistance. Okay. Um, so a

1523
00:57:07,920 --> 00:57:11,760
little bit of background about like what

1524
00:57:09,440 --> 00:57:13,599
our group does. Uh, our group being this

1525
00:57:11,760 --> 00:57:15,599
idea of like project Xvivo. I'll kind of

1526
00:57:13,599 --> 00:57:16,720
give a a shameless plug about our group.

1527
00:57:15,599 --> 00:57:19,520
You know, we're really thinking about

1528
00:57:16,720 --> 00:57:20,720
ways to move beyond um, you know, DNA

1529
00:57:19,520 --> 00:57:23,200
based measurements and really thinking

1530
00:57:20,720 --> 00:57:25,040
about cell state as a marker for cancer

1531
00:57:23,200 --> 00:57:26,720
therapeutics. So for those who may not

1532
00:57:25,040 --> 00:57:28,240
work directly in this area, you know,

1533
00:57:26,720 --> 00:57:30,240
DNA is kind of the cornerstone of

1534
00:57:28,240 --> 00:57:31,760
precision cancer medicine, right? this

1535
00:57:30,240 --> 00:57:33,599
idea of you know a lot of patients

1536
00:57:31,760 --> 00:57:35,920
tumors have you know diverse backgrounds

1537
00:57:33,599 --> 00:57:37,680
that are kind of measured by uh DNA for

1538
00:57:35,920 --> 00:57:39,760
v these patient alterations when it

1539
00:57:37,680 --> 00:57:41,520
comes to drug discovery uh you know we

1540
00:57:39,760 --> 00:57:44,160
use a lot of patient models uh cell

1541
00:57:41,520 --> 00:57:45,839
lines and organoids uh where we we study

1542
00:57:44,160 --> 00:57:47,760
the fidelity of these models based on

1543
00:57:45,839 --> 00:57:50,160
also DNA and then when I think about how

1544
00:57:47,760 --> 00:57:52,079
to stratify patients right I also think

1545
00:57:50,160 --> 00:57:54,640
about this with relationship to uh

1546
00:57:52,079 --> 00:57:56,559
whether or not a a a drug might be

1547
00:57:54,640 --> 00:57:59,359
actionable or not actionable based on

1548
00:57:56,559 --> 00:58:01,200
again these like DNA uh uh mutations and

1549
00:57:59,359 --> 00:58:04,400
so This idea is that this pipeline sort

1550
00:58:01,200 --> 00:58:06,000
of works really well um only if we think

1551
00:58:04,400 --> 00:58:10,240
about the future that's relevant to drug

1552
00:58:06,000 --> 00:58:12,960
response being DNA based encoded right

1553
00:58:10,240 --> 00:58:14,240
um so you know how well have we kind of

1554
00:58:12,960 --> 00:58:15,359
done in this paradigm well there have

1555
00:58:14,240 --> 00:58:16,640
been a lot of cases where this has kind

1556
00:58:15,359 --> 00:58:18,640
of been a success right we think about

1557
00:58:16,640 --> 00:58:20,000
leukemia's breast cancer being one of

1558
00:58:18,640 --> 00:58:22,480
these but there are a lot of challenges

1559
00:58:20,000 --> 00:58:24,079
in this space as we currently uh sit

1560
00:58:22,480 --> 00:58:26,000
right there are only 40% of patients

1561
00:58:24,079 --> 00:58:27,839
that kind of uh fall within this regime

1562
00:58:26,000 --> 00:58:30,079
where m majority of patients still have

1563
00:58:27,839 --> 00:58:32,720
like an actionable single alteration

1564
00:58:30,079 --> 00:58:33,920
Right. And the big challenge here is

1565
00:58:32,720 --> 00:58:35,520
that you know there's we have limited

1566
00:58:33,920 --> 00:58:37,200
responses due to both heterogeneity and

1567
00:58:35,520 --> 00:58:38,960
or development of resistance that can

1568
00:58:37,200 --> 00:58:40,240
happen both because of genetic mechanism

1569
00:58:38,960 --> 00:58:42,720
but also something that might be non-

1570
00:58:40,240 --> 00:58:43,680
genetic right and so we as these

1571
00:58:42,720 --> 00:58:45,680
patients like how many of these

1572
00:58:43,680 --> 00:58:49,680
dependencies are can be explained by

1573
00:58:45,680 --> 00:58:51,520
just like single individual features.

1574
00:58:49,680 --> 00:58:53,680
Um

1575
00:58:51,520 --> 00:58:55,040
and so you know if I think about this

1576
00:58:53,680 --> 00:58:57,520
you know cancer phenotypes kind of have

1577
00:58:55,040 --> 00:58:59,119
this really diverse set of inputs right

1578
00:58:57,520 --> 00:59:00,400
um you know I just kind of gave this

1579
00:58:59,119 --> 00:59:02,240
notion that we kind of sit here on this

1580
00:59:00,400 --> 00:59:04,799
DNA uh code you can think about that as

1581
00:59:02,240 --> 00:59:06,000
like this static mutated blueprint right

1582
00:59:04,799 --> 00:59:08,079
what's really interesting though as you

1583
00:59:06,000 --> 00:59:09,359
kind of move down uh this trajectory

1584
00:59:08,079 --> 00:59:10,880
here you kind of have this idea of you

1585
00:59:09,359 --> 00:59:12,319
know RNA is kind of this dynamic

1586
00:59:10,880 --> 00:59:14,640
interpretation of what happens with the

1587
00:59:12,319 --> 00:59:17,119
cells right it kind of captures in some

1588
00:59:14,640 --> 00:59:19,440
uh sort of tagged way or correlated way

1589
00:59:17,119 --> 00:59:20,640
you get some sort of idea of you know a

1590
00:59:19,440 --> 00:59:21,839
little bit of measurement that kind of

1591
00:59:20,640 --> 00:59:24,000
is correlated with what's happening on

1592
00:59:21,839 --> 00:59:25,599
the DNA mutation scale also things that

1593
00:59:24,000 --> 00:59:27,040
are happening epigenetically but also

1594
00:59:25,599 --> 00:59:29,839
things that kind of interact with our

1595
00:59:27,040 --> 00:59:31,520
environment right and so if I think

1596
00:59:29,839 --> 00:59:33,119
about uh you know where we are you know

1597
00:59:31,520 --> 00:59:35,119
we can kind of think about this idea of

1598
00:59:33,119 --> 00:59:37,440
cell state being these groups of genes

1599
00:59:35,119 --> 00:59:39,280
that uh are expressed by a cell that

1600
00:59:37,440 --> 00:59:40,720
kind of capture both you know cell

1601
00:59:39,280 --> 00:59:43,760
function as well as like an

1602
00:59:40,720 --> 00:59:45,440
environmental uh phenotype and so the

1603
00:59:43,760 --> 00:59:46,880
current pipelines are here but what you

1604
00:59:45,440 --> 00:59:48,720
know what we're asking in our group in

1605
00:59:46,880 --> 00:59:51,280
Xvivo is really this idea of can we

1606
00:59:48,720 --> 00:59:54,480
search for state based lethality on this

1607
00:59:51,280 --> 00:59:57,119
uh uh via this uh cell state like based

1608
00:59:54,480 --> 00:59:58,559
measurement right and so for a little

1609
00:59:57,119 --> 01:00:00,720
bit of background again shameless plug

1610
00:59:58,559 --> 01:00:02,079
about our our our group you know we have

1611
01:00:00,720 --> 01:00:03,520
great tools to do this but we're really

1612
01:00:02,079 --> 01:00:06,000
asking questions like how do we measure

1613
01:00:03,520 --> 01:00:08,720
complex cell state attributes and so

1614
01:00:06,000 --> 01:00:12,480
XDivo is a is a collaboration between

1615
01:00:08,720 --> 01:00:14,000
Microsoft and and the broad um with a

1616
01:00:12,480 --> 01:00:15,920
close collaboration with people at Dana

1617
01:00:14,000 --> 01:00:18,480
Farber where we're really trying to

1618
01:00:15,920 --> 01:00:20,559
bridge this gap between biology and

1619
01:00:18,480 --> 01:00:22,160
machine learning um with a diverse group

1620
01:00:20,559 --> 01:00:24,079
of both experimentalists, computation

1621
01:00:22,160 --> 01:00:26,160
biologists and also AI and ML experts,

1622
01:00:24,079 --> 01:00:28,640
right? And it's co-led by myself and Ava

1623
01:00:26,160 --> 01:00:31,119
Amini at at Microsoft as well as uh

1624
01:00:28,640 --> 01:00:35,200
collaboration with leadership from Peter

1625
01:00:31,119 --> 01:00:37,200
and industry um in this audience here

1626
01:00:35,200 --> 01:00:38,799
just and a lot of lab members actually

1627
01:00:37,200 --> 01:00:40,799
throughout here um that are that are

1628
01:00:38,799 --> 01:00:42,880
more than happy to chat with um we

1629
01:00:40,799 --> 01:00:45,040
actually are we have we're coll-located

1630
01:00:42,880 --> 01:00:46,799
in terms of of of both geographic but

1631
01:00:45,040 --> 01:00:48,079
also like in space. So, for those who

1632
01:00:46,799 --> 01:00:49,760
don't know, Microsoft Research is

1633
01:00:48,079 --> 01:00:51,680
actually down the street. I have no idea

1634
01:00:49,760 --> 01:00:54,640
which way we're facing, but we're on One

1635
01:00:51,680 --> 01:00:56,559
Memorial. Um, and so we're not that far

1636
01:00:54,640 --> 01:00:58,400
away. Uh, we also have lab space here at

1637
01:00:56,559 --> 01:01:00,400
the Broad on the fifth and and sixth

1638
01:00:58,400 --> 01:01:02,559
floor. And I'm sure people like uh Pete

1639
01:01:00,400 --> 01:01:03,599
and Shri and and also Andrew and others

1640
01:01:02,559 --> 01:01:05,200
will be more than happy to take you

1641
01:01:03,599 --> 01:01:08,960
around that space if if anyone's ever

1642
01:01:05,200 --> 01:01:11,280
interested. Um, and so XV kind of has

1643
01:01:08,960 --> 01:01:13,760
two broad aims if I were to put them in

1644
01:01:11,280 --> 01:01:16,799
different buckets. Um you know the first

1645
01:01:13,760 --> 01:01:19,680
is this idea of what's the real fidelity

1646
01:01:16,799 --> 01:01:21,119
of of cancer cell states. You know one

1647
01:01:19,680 --> 01:01:22,720
question that we kind of ask is like how

1648
01:01:21,119 --> 01:01:25,280
does the environment affect cell state

1649
01:01:22,720 --> 01:01:26,880
and therapeutic response. Um and the

1650
01:01:25,280 --> 01:01:29,440
other aim which is a big part of this is

1651
01:01:26,880 --> 01:01:30,960
this idea of building foundational AI

1652
01:01:29,440 --> 01:01:32,160
maps or these like kind of stateto

1653
01:01:30,960 --> 01:01:33,760
function maps. I'll get into that a

1654
01:01:32,160 --> 01:01:35,280
little bit. Um and really asking this

1655
01:01:33,760 --> 01:01:38,720
like fundamental question which is like

1656
01:01:35,280 --> 01:01:42,240
can we learn a foundational uh AI model

1657
01:01:38,720 --> 01:01:43,520
of cell state? Okay. Um there are really

1658
01:01:42,240 --> 01:01:45,359
cool stories that kind of happen with

1659
01:01:43,520 --> 01:01:47,200
both of these aims because it's the MIA

1660
01:01:45,359 --> 01:01:51,520
talk. We'll just focus on this latter

1661
01:01:47,200 --> 01:01:53,040
half right. Um so in this talk today

1662
01:01:51,520 --> 01:01:54,720
what we're going to focus a lot on is is

1663
01:01:53,040 --> 01:01:57,040
this idea of single cell uh

1664
01:01:54,720 --> 01:01:58,400
measurements. Um so you know instead of

1665
01:01:57,040 --> 01:01:59,599
thinking about a bulk who people are

1666
01:01:58,400 --> 01:02:01,280
working in space instead of thinking

1667
01:01:59,599 --> 01:02:03,280
about like an average expression readout

1668
01:02:01,280 --> 01:02:05,440
from a given sample we'll think about

1669
01:02:03,280 --> 01:02:06,640
sequencing across uh individual cells to

1670
01:02:05,440 --> 01:02:08,720
get this idea of like cell type

1671
01:02:06,640 --> 01:02:09,839
heterogeneity. Right? So for those who

1672
01:02:08,720 --> 01:02:11,440
are more quantitative, you could think

1673
01:02:09,839 --> 01:02:13,839
about this as like a large scale matrix

1674
01:02:11,440 --> 01:02:15,520
where the my rows are different cells

1675
01:02:13,839 --> 01:02:17,520
and then my columns are the expression

1676
01:02:15,520 --> 01:02:18,799
values of those goodness. Right? And so

1677
01:02:17,520 --> 01:02:20,400
this idea is like we want to build

1678
01:02:18,799 --> 01:02:22,559
integrative approaches to measure and

1679
01:02:20,400 --> 01:02:26,319
understand biology um at this single

1680
01:02:22,559 --> 01:02:29,280
cell resolution. Okay? Now what's really

1681
01:02:26,319 --> 01:02:32,160
cool about this uh era that we're in now

1682
01:02:29,280 --> 01:02:33,599
uh is that you know I there was a point

1683
01:02:32,160 --> 01:02:35,440
in time where getting single cell data

1684
01:02:33,599 --> 01:02:36,720
was was really hard to find and and and

1685
01:02:35,440 --> 01:02:38,319
you had different sources that were kind

1686
01:02:36,720 --> 01:02:39,920
of scattered all over the place. Now you

1687
01:02:38,319 --> 01:02:42,400
have these like atlas scale level

1688
01:02:39,920 --> 01:02:45,040
efforts where you can get these data um

1689
01:02:42,400 --> 01:02:47,040
at at uh high throughput. What's really

1690
01:02:45,040 --> 01:02:48,960
nice is that this problem of working

1691
01:02:47,040 --> 01:02:51,040
with single cell biology is both equal

1692
01:02:48,960 --> 01:02:52,640
parts computation is also like and also

1693
01:02:51,040 --> 01:02:54,559
biology. So for the again more

1694
01:02:52,640 --> 01:02:56,640
quantitative people in the room you know

1695
01:02:54,559 --> 01:02:58,079
some calculations that we used to do

1696
01:02:56,640 --> 01:02:59,760
back to the envelope is like this idea

1697
01:02:58,079 --> 01:03:01,040
of like for in terms of data points you

1698
01:02:59,760 --> 01:03:03,200
know if I think about this from like a

1699
01:03:01,040 --> 01:03:04,960
multiomic uh study you know if I just

1700
01:03:03,200 --> 01:03:08,799
were able to get data on DNA mutations

1701
01:03:04,960 --> 01:03:10,319
for 500 cells across 225 uh genes as

1702
01:03:08,799 --> 01:03:12,160
well as thinking about RNA expression

1703
01:03:10,319 --> 01:03:13,520
across 500 cells and all 20,000 genes

1704
01:03:12,160 --> 01:03:15,280
and I had some kind of idea of

1705
01:03:13,520 --> 01:03:17,440
interactions across environment you know

1706
01:03:15,280 --> 01:03:18,799
your data space can explode quite a bit

1707
01:03:17,440 --> 01:03:20,799
where you could be working with like up

1708
01:03:18,799 --> 01:03:23,520
to like 44 million data points like per

1709
01:03:20,799 --> 01:03:25,440
per biopsy And so these tools that like

1710
01:03:23,520 --> 01:03:27,039
valve presented earlier are are quite

1711
01:03:25,440 --> 01:03:29,520
useful in thinking about one how you

1712
01:03:27,039 --> 01:03:30,559
load data in at a scalable way um but

1713
01:03:29,520 --> 01:03:32,400
also making sure that you don't just

1714
01:03:30,559 --> 01:03:35,359
have to be at a place like Microsoft to

1715
01:03:32,400 --> 01:03:38,559
make an impact in this space right um

1716
01:03:35,359 --> 01:03:40,720
and so with all this data uh sets kind

1717
01:03:38,559 --> 01:03:41,599
of exploding in nature you know one

1718
01:03:40,720 --> 01:03:43,520
thing that people have really been

1719
01:03:41,599 --> 01:03:45,359
started thinking about is like you know

1720
01:03:43,520 --> 01:03:47,680
obviously like how do I start to apply

1721
01:03:45,359 --> 01:03:50,400
AI to these types of methods right and

1722
01:03:47,680 --> 01:03:51,839
to these types of data sets and so we'll

1723
01:03:50,400 --> 01:03:53,680
kind of go through a little bit across

1724
01:03:51,839 --> 01:03:55,440
like some of these uh AI def models and

1725
01:03:53,680 --> 01:03:57,520
then we'll kind of see what we've found

1726
01:03:55,440 --> 01:04:00,160
in working with these methods um in our

1727
01:03:57,520 --> 01:04:02,319
own in our own group. So just take a

1728
01:04:00,160 --> 01:04:04,319
step back you know this term foundation

1729
01:04:02,319 --> 01:04:06,079
model has kind of popped up everywhere

1730
01:04:04,319 --> 01:04:07,599
for those who may not know what this is

1731
01:04:06,079 --> 01:04:09,119
effectively means you know foundation

1732
01:04:07,599 --> 01:04:10,640
models are just effectively AI models

1733
01:04:09,119 --> 01:04:12,799
that can do a a diverse set of

1734
01:04:10,640 --> 01:04:14,400
downstream tasks. So, you know, very

1735
01:04:12,799 --> 01:04:16,400
fundamentally, you know, I might have

1736
01:04:14,400 --> 01:04:17,920
some data set. I might train an AI

1737
01:04:16,400 --> 01:04:19,920
model. You're going to hear me say these

1738
01:04:17,920 --> 01:04:22,960
terms quite a bit throughout this uh

1739
01:04:19,920 --> 01:04:25,200
over the next uh 45ish or 40 minutes is

1740
01:04:22,960 --> 01:04:26,640
thinking about this idea of uh you have

1741
01:04:25,200 --> 01:04:28,720
you split task into two different

1742
01:04:26,640 --> 01:04:31,119
regimes. Uh we'll start with the bottom

1743
01:04:28,720 --> 01:04:32,960
this idea of zero shot. So, what we mean

1744
01:04:31,119 --> 01:04:36,319
when we say zero shot is I take a data

1745
01:04:32,960 --> 01:04:38,079
set, I uh train an AI model with it. I

1746
01:04:36,319 --> 01:04:38,960
take that model, I freeze its weights.

1747
01:04:38,079 --> 01:04:40,559
weights were just trained on a

1748
01:04:38,960 --> 01:04:42,400
pre-training data set and I apply it to

1749
01:04:40,559 --> 01:04:44,160
something out of distribution or some

1750
01:04:42,400 --> 01:04:45,359
downstream task without ever updating

1751
01:04:44,160 --> 01:04:46,400
these model weights. So that's zero

1752
01:04:45,359 --> 01:04:49,039
shot, right? I've trained on something

1753
01:04:46,400 --> 01:04:50,240
and I try it down stream. Uh finetuning

1754
01:04:49,039 --> 01:04:52,799
is a little bit different. Fine-tuning

1755
01:04:50,240 --> 01:04:54,640
says I train AI model and then I take a

1756
01:04:52,799 --> 01:04:56,880
little bit of data from maybe the task

1757
01:04:54,640 --> 01:04:58,799
of interest. So I'll take a little a

1758
01:04:56,880 --> 01:05:01,280
subset of that data. I'll update my

1759
01:04:58,799 --> 01:05:03,280
weights with respect to this uh uh data

1760
01:05:01,280 --> 01:05:05,280
that has my um task that I'm trying to

1761
01:05:03,280 --> 01:05:07,119
do. And then I'll then I'll train that

1762
01:05:05,280 --> 01:05:08,880
take that updated model uh and then

1763
01:05:07,119 --> 01:05:11,280
apply it to my prediction. s idea like

1764
01:05:08,880 --> 01:05:13,119
fine tune, right? And you can imagine in

1765
01:05:11,280 --> 01:05:15,200
a lot of different areas of science, you

1766
01:05:13,119 --> 01:05:17,760
know, where both fine-tuned prediction

1767
01:05:15,200 --> 01:05:21,039
and also zero uh zeroot uh discovery

1768
01:05:17,760 --> 01:05:24,400
capabilities are like are wanted, right?

1769
01:05:21,039 --> 01:05:26,640
Um and so, you know, let's you know, how

1770
01:05:24,400 --> 01:05:28,559
do these models kind of work? So, if you

1771
01:05:26,640 --> 01:05:30,640
think about a model like GPT, just again

1772
01:05:28,559 --> 01:05:32,400
so everybody's on on the same page, you

1773
01:05:30,640 --> 01:05:34,559
know, um a lot of these use what they

1774
01:05:32,400 --> 01:05:36,640
call a mask language uh uh modeling

1775
01:05:34,559 --> 01:05:38,160
pre-training objective. Okay, what that

1776
01:05:36,640 --> 01:05:40,079
means effectively is I take a sequence.

1777
01:05:38,160 --> 01:05:41,520
So let's say a set of text, we'll call

1778
01:05:40,079 --> 01:05:43,599
this like let's say like learning about

1779
01:05:41,520 --> 01:05:45,760
AI is awesome. What you'll do is you'll

1780
01:05:43,599 --> 01:05:47,200
kind of tokenize this sequence. So

1781
01:05:45,760 --> 01:05:50,240
effectively what you do is you'll you'll

1782
01:05:47,200 --> 01:05:52,240
take uh you'll find some representation

1783
01:05:50,240 --> 01:05:54,640
with respect to like an encoding for

1784
01:05:52,240 --> 01:05:56,160
each part of the sequence. Um the

1785
01:05:54,640 --> 01:05:57,920
masking part means I'll just go in and

1786
01:05:56,160 --> 01:06:00,960
I'll mask part of the sequence and I'll

1787
01:05:57,920 --> 01:06:02,480
throw the masked tokens into my model

1788
01:06:00,960 --> 01:06:04,240
and I'll ask the model to then fill in

1789
01:06:02,480 --> 01:06:05,920
the gaps basically, right? And I'll

1790
01:06:04,240 --> 01:06:07,920
judge how well it does. is based on some

1791
01:06:05,920 --> 01:06:09,039
sort of loss. And so we heard David do

1792
01:06:07,920 --> 01:06:10,880
talk about earlier about this idea of

1793
01:06:09,039 --> 01:06:12,319
cross entropy and I'll ask how good was

1794
01:06:10,880 --> 01:06:13,599
the model at making the prediction and

1795
01:06:12,319 --> 01:06:15,839
fill in these given gaps and I'll do

1796
01:06:13,599 --> 01:06:17,440
this all over again. Now the same kind

1797
01:06:15,839 --> 01:06:18,799
of regime of kind of the background of

1798
01:06:17,440 --> 01:06:20,640
what's happening in all of our phones

1799
01:06:18,799 --> 01:06:22,160
and things like this now is what we try

1800
01:06:20,640 --> 01:06:23,520
to do is take the same kind of regime

1801
01:06:22,160 --> 01:06:25,839
and apply directly to single cell

1802
01:06:23,520 --> 01:06:27,599
biology. We can we'll talk through like

1803
01:06:25,839 --> 01:06:29,119
why we think this is great or not great

1804
01:06:27,599 --> 01:06:30,960
but effectively you could do the same

1805
01:06:29,119 --> 01:06:33,839
sort of thing naively with something

1806
01:06:30,960 --> 01:06:36,240
with single cell. Um so I could do is I

1807
01:06:33,839 --> 01:06:38,240
could take a set of genes and their uh

1808
01:06:36,240 --> 01:06:41,359
and their expression values the same

1809
01:06:38,240 --> 01:06:44,000
sort of idea. I can mask

1810
01:06:41,359 --> 01:06:45,280
a part of the gene and its uh expression

1811
01:06:44,000 --> 01:06:47,839
and I'll ask the model to kind of fill

1812
01:06:45,280 --> 01:06:49,119
in the gaps with this given uh um thing

1813
01:06:47,839 --> 01:06:50,640
and I'll ask the same kind of questions

1814
01:06:49,119 --> 01:06:52,480
how well was it able to do in fill in

1815
01:06:50,640 --> 01:06:53,839
this thing of a given sequence. Now

1816
01:06:52,480 --> 01:06:55,200
naturally if you're thinking about this

1817
01:06:53,839 --> 01:06:57,520
about the difference between this

1818
01:06:55,200 --> 01:07:00,240
setting and this setting is naturally uh

1819
01:06:57,520 --> 01:07:01,599
I have order and sequences here where

1820
01:07:00,240 --> 01:07:04,240
you might ask this question like how do

1821
01:07:01,599 --> 01:07:05,839
I think about how to nicely order genes

1822
01:07:04,240 --> 01:07:07,119
and again these are these are to be

1823
01:07:05,839 --> 01:07:08,880
modeling choices that people are

1824
01:07:07,119 --> 01:07:10,960
starting to do but naively we don't

1825
01:07:08,880 --> 01:07:12,799
necessarily have that nice structure to

1826
01:07:10,960 --> 01:07:16,720
to to naturally think about how to do

1827
01:07:12,799 --> 01:07:20,079
this uh um well so you know where has

1828
01:07:16,720 --> 01:07:22,400
has AI kind of had a lot of success

1829
01:07:20,079 --> 01:07:24,319
um in our space well you in a few

1830
01:07:22,400 --> 01:07:26,559
different places, right? Um, and so if I

1831
01:07:24,319 --> 01:07:28,319
think about different bi uh biological

1832
01:07:26,559 --> 01:07:29,520
modalities, you know, the first things

1833
01:07:28,319 --> 01:07:31,599
that kind of come to mind are things

1834
01:07:29,520 --> 01:07:33,760
that kind of have natural sequence like

1835
01:07:31,599 --> 01:07:35,760
structure in terms of their data, right?

1836
01:07:33,760 --> 01:07:37,280
So if I can think about uh DNA sequences

1837
01:07:35,760 --> 01:07:38,400
or protein sequences, there are a few

1838
01:07:37,280 --> 01:07:40,000
things I want people to take away from

1839
01:07:38,400 --> 01:07:41,599
this slide. One is this natural idea of

1840
01:07:40,000 --> 01:07:43,760
going from text to sequences. It's nice

1841
01:07:41,599 --> 01:07:45,599
to have this nice ordering of my data.

1842
01:07:43,760 --> 01:07:47,680
Um, there's another thing that's quite

1843
01:07:45,599 --> 01:07:50,160
important is this idea of the reference

1844
01:07:47,680 --> 01:07:51,440
training data sets. So one if you think

1845
01:07:50,160 --> 01:07:52,640
about particularly like with protein

1846
01:07:51,440 --> 01:07:54,079
sequences and you think about the

1847
01:07:52,640 --> 01:07:57,440
success of something like alpha fold and

1848
01:07:54,079 --> 01:07:59,200
others is you know I have uh both real

1849
01:07:57,440 --> 01:08:01,119
data sets where I can think about uh

1850
01:07:59,200 --> 01:08:03,760
where to pull millions and millions of

1851
01:08:01,119 --> 01:08:06,000
sequences from but I also can leverage

1852
01:08:03,760 --> 01:08:07,680
synthetic data as well uh because I

1853
01:08:06,000 --> 01:08:09,200
understand the biological processes that

1854
01:08:07,680 --> 01:08:11,680
kind of generates nice sequences and so

1855
01:08:09,200 --> 01:08:14,000
I compare both uh uh real sequences and

1856
01:08:11,680 --> 01:08:15,839
synthetic sequences uh to to train

1857
01:08:14,000 --> 01:08:17,040
models with with high accuracy. So

1858
01:08:15,839 --> 01:08:19,759
that's the first kind of thing is like

1859
01:08:17,040 --> 01:08:21,600
this training data set scale is massive.

1860
01:08:19,759 --> 01:08:24,319
The second thing is that the underlying

1861
01:08:21,600 --> 01:08:26,880
task and function are often tied to uh

1862
01:08:24,319 --> 01:08:28,640
biology and things that I can also uh

1863
01:08:26,880 --> 01:08:30,159
test and also that people who are

1864
01:08:28,640 --> 01:08:31,920
internally like really care about,

1865
01:08:30,159 --> 01:08:33,440
right? This idea of like in protein uh

1866
01:08:31,920 --> 01:08:35,040
language models, the idea of like can I

1867
01:08:33,440 --> 01:08:37,679
generate models that can now identify

1868
01:08:35,040 --> 01:08:39,679
new antibodies or new enzymes, right? Um

1869
01:08:37,679 --> 01:08:41,040
in DNA language models, a lot of times

1870
01:08:39,679 --> 01:08:42,880
we ask questions like can you find

1871
01:08:41,040 --> 01:08:44,560
enhancer regions around the genomes? Can

1872
01:08:42,880 --> 01:08:46,319
you identify promoter regions, exxons,

1873
01:08:44,560 --> 01:08:47,600
so on and so forth? And so we had these

1874
01:08:46,319 --> 01:08:48,799
really nice underlying function and

1875
01:08:47,600 --> 01:08:51,040
tasks that kind of like are also

1876
01:08:48,799 --> 01:08:53,199
biologically driven.

1877
01:08:51,040 --> 01:08:54,880
Single cell is not necessarily or

1878
01:08:53,199 --> 01:08:58,239
expression is not exactly in this same

1879
01:08:54,880 --> 01:09:01,120
exact space. Um we have a growing set of

1880
01:08:58,239 --> 01:09:03,120
training data sets. Um you know we can

1881
01:09:01,120 --> 01:09:05,359
have geneontologies and gene sets. We

1882
01:09:03,120 --> 01:09:06,960
have this idea of single atlases. Uh we

1883
01:09:05,359 --> 01:09:09,759
can leverage pathway information from

1884
01:09:06,960 --> 01:09:11,199
different databases. Um and we have

1885
01:09:09,759 --> 01:09:12,640
different tasks that people kind of do.

1886
01:09:11,199 --> 01:09:14,880
So if you split out the different tasks,

1887
01:09:12,640 --> 01:09:17,199
the three majorish tasks that people

1888
01:09:14,880 --> 01:09:19,359
think about or again I left one out here

1889
01:09:17,199 --> 01:09:20,719
which is if I think about fourth is you

1890
01:09:19,359 --> 01:09:22,719
know we can annotate new cell types

1891
01:09:20,719 --> 01:09:23,920
which is the idea of what what David

1892
01:09:22,719 --> 01:09:25,600
went through earlier in this in this

1893
01:09:23,920 --> 01:09:27,279
talk. You have this idea of batch effect

1894
01:09:25,600 --> 01:09:29,600
correction. So this idea of like can I

1895
01:09:27,279 --> 01:09:31,920
use uh uh foundation models to kind of

1896
01:09:29,600 --> 01:09:33,120
integrate across different data sets and

1897
01:09:31,920 --> 01:09:34,960
you also wanted this idea of

1898
01:09:33,120 --> 01:09:36,960
perturbation effect prediction right

1899
01:09:34,960 --> 01:09:39,440
this idea if I've trained a model on

1900
01:09:36,960 --> 01:09:42,000
cells from one tissue can I then predict

1901
01:09:39,440 --> 01:09:44,560
its effect right in an unseen tissue or

1902
01:09:42,000 --> 01:09:46,239
unseen state right or if I' if I've

1903
01:09:44,560 --> 01:09:48,239
trained a model on a given drug can I

1904
01:09:46,239 --> 01:09:50,080
predict in a in a tissue can I predict

1905
01:09:48,239 --> 01:09:53,120
the effect of a different drug right on

1906
01:09:50,080 --> 01:09:56,000
that same tissue right and these are not

1907
01:09:53,120 --> 01:09:58,239
necessarily the same as as some of these

1908
01:09:56,000 --> 01:09:59,920
you know, a lot of these uh analyses, as

1909
01:09:58,239 --> 01:10:01,679
a lot of you pointed out in the last in

1910
01:09:59,920 --> 01:10:03,280
the last talk, is this idea of like, you

1911
01:10:01,679 --> 01:10:05,840
know, how well will I ever be able to do

1912
01:10:03,280 --> 01:10:08,080
this when the idea that the labels that

1913
01:10:05,840 --> 01:10:11,600
I now train on are coming from human

1914
01:10:08,080 --> 01:10:13,280
annotated uh uh labs, right? Um and so

1915
01:10:11,600 --> 01:10:14,800
some of these tasks are are quite hard

1916
01:10:13,280 --> 01:10:16,080
and as a lot of people have kind of

1917
01:10:14,800 --> 01:10:17,679
point out, we'll get back to a little

1918
01:10:16,080 --> 01:10:19,600
bit, this perturbation effect prediction

1919
01:10:17,679 --> 01:10:20,800
question is like quite challenging. Even

1920
01:10:19,600 --> 01:10:22,080
though I think that actually might be

1921
01:10:20,800 --> 01:10:24,880
like the gold standard that we're all

1922
01:10:22,080 --> 01:10:26,719
trying to work towards.

1923
01:10:24,880 --> 01:10:28,480
Cool. But, you know, despite all of

1924
01:10:26,719 --> 01:10:31,840
these uh uh things that hasn't stopped

1925
01:10:28,480 --> 01:10:33,760
our field from trying um like we've been

1926
01:10:31,840 --> 01:10:35,040
trying um that there's probably a new

1927
01:10:33,760 --> 01:10:36,320
foundation model that came out this

1928
01:10:35,040 --> 01:10:37,840
morning that I haven't seen yet, right?

1929
01:10:36,320 --> 01:10:39,520
Like every single day there's a new

1930
01:10:37,840 --> 01:10:40,880
group that claims that we have a

1931
01:10:39,520 --> 01:10:42,560
foundation model biology. So, I just

1932
01:10:40,880 --> 01:10:44,560
picked four here. Sorry if I left off

1933
01:10:42,560 --> 01:10:46,080
your favorite one. Um but there are a

1934
01:10:44,560 --> 01:10:48,480
few things that I kind of want to uh get

1935
01:10:46,080 --> 01:10:49,679
at. versus I picked four different

1936
01:10:48,480 --> 01:10:51,520
models here that are all kind of

1937
01:10:49,679 --> 01:10:53,600
different in terms of how they end up

1938
01:10:51,520 --> 01:10:56,080
doing their their model architecture and

1939
01:10:53,600 --> 01:10:58,560
their training, right? Um the gene

1940
01:10:56,080 --> 01:11:01,040
former has a different scheme uh where

1941
01:10:58,560 --> 01:11:03,280
it chooses the order and it sequences

1942
01:11:01,040 --> 01:11:05,199
based on uh uh sequences of genes based

1943
01:11:03,280 --> 01:11:07,120
on like the uh the magnitude of an

1944
01:11:05,199 --> 01:11:09,840
expression uh vector and that's how it

1945
01:11:07,120 --> 01:11:11,679
does its ordering. um UC kind of tries

1946
01:11:09,840 --> 01:11:15,760
to leverage it has like a universal cell

1947
01:11:11,679 --> 01:11:18,480
embedding idea that leverages um uh uh

1948
01:11:15,760 --> 01:11:20,159
both uh expression data as well as data

1949
01:11:18,480 --> 01:11:24,480
that comes from uh protein language

1950
01:11:20,159 --> 01:11:26,159
models um uh embeddings SCGPT has a

1951
01:11:24,480 --> 01:11:27,280
different architecture SC foundation a

1952
01:11:26,159 --> 01:11:29,120
different architecture so the things

1953
01:11:27,280 --> 01:11:30,480
like SC similarity and every model

1954
01:11:29,120 --> 01:11:31,920
claims to be foundational in the way

1955
01:11:30,480 --> 01:11:34,800
that they they do things in terms of

1956
01:11:31,920 --> 01:11:35,760
performance so it's hard to kind of uh

1957
01:11:34,800 --> 01:11:37,679
for those who are thinking about

1958
01:11:35,760 --> 01:11:39,520
research it's hard to to gauge who's

1959
01:11:37,679 --> 01:11:42,080
better and who also because not every

1960
01:11:39,520 --> 01:11:43,280
model is publicly available. So like if

1961
01:11:42,080 --> 01:11:44,719
you you kind of have to take things at

1962
01:11:43,280 --> 01:11:46,560
face value because people don't always

1963
01:11:44,719 --> 01:11:48,320
release code to then end up going and

1964
01:11:46,560 --> 01:11:49,520
and retraining their models to really

1965
01:11:48,320 --> 01:11:51,840
have this kind of really head-to-head

1966
01:11:49,520 --> 01:11:54,320
comparison. The second thing I think is

1967
01:11:51,840 --> 01:11:56,320
like also quite important is is this

1968
01:11:54,320 --> 01:11:57,679
number here. It's the number of cells

1969
01:11:56,320 --> 01:11:59,199
that each of these models actually

1970
01:11:57,679 --> 01:12:00,480
trained on. And I'm going to circle back

1971
01:11:59,199 --> 01:12:02,320
to this but I kind of want to put this

1972
01:12:00,480 --> 01:12:04,800
bug in your ear. The first thing is that

1973
01:12:02,320 --> 01:12:06,640
you know uh you know gene corpus uh for

1974
01:12:04,800 --> 01:12:10,800
gene the gene corpus for gene former was

1975
01:12:06,640 --> 01:12:14,000
trained on 30 million UC was on 35 or 36

1976
01:12:10,800 --> 01:12:15,280
million here SCPT 33 million SC

1977
01:12:14,000 --> 01:12:16,480
foundation was 50 million there was

1978
01:12:15,280 --> 01:12:18,880
actually a recent paper that was trained

1979
01:12:16,480 --> 01:12:20,800
on over 100 million cells right so the

1980
01:12:18,880 --> 01:12:23,760
the size of these training corpuses

1981
01:12:20,800 --> 01:12:25,920
continue to grow um and the size of

1982
01:12:23,760 --> 01:12:27,040
these models also continue to get bigger

1983
01:12:25,920 --> 01:12:28,400
right and so there's one kind of

1984
01:12:27,040 --> 01:12:30,239
question I put in bug in your ear which

1985
01:12:28,400 --> 01:12:32,080
is like why do we keep doing this but

1986
01:12:30,239 --> 01:12:35,280
I'll we'll We'll get back to that in a

1987
01:12:32,080 --> 01:12:36,560
second. Um, so one thing that we started

1988
01:12:35,280 --> 01:12:38,239
asking ourselves and I'll take you

1989
01:12:36,560 --> 01:12:39,520
through the story of how we got here is

1990
01:12:38,239 --> 01:12:41,600
a couple years ago we started asking

1991
01:12:39,520 --> 01:12:43,120
ourselves like what is the actual zeros

1992
01:12:41,600 --> 01:12:44,480
capabilities of these models? I can

1993
01:12:43,120 --> 01:12:46,320
imagine if I trained a model on

1994
01:12:44,480 --> 01:12:48,000
something and then I fine-tuned it with

1995
01:12:46,320 --> 01:12:49,600
respect to a given data set that was

1996
01:12:48,000 --> 01:12:51,199
that was kind of aligned with the task I

1997
01:12:49,600 --> 01:12:52,480
wanted to do. I can see a model doing

1998
01:12:51,199 --> 01:12:53,840
kind of well there. But what if the

1999
01:12:52,480 --> 01:12:55,840
model is actually zero shock capability?

2000
01:12:53,840 --> 01:12:57,360
if I train it on a a certain data set

2001
01:12:55,840 --> 01:12:59,679
and I tested it on another data set

2002
01:12:57,360 --> 01:13:01,040
where I could no longer find fine-tune

2003
01:12:59,679 --> 01:13:03,040
like how good are these zeros

2004
01:13:01,040 --> 01:13:04,640
capabilities and so a couple years ago

2005
01:13:03,040 --> 01:13:06,000
we had this idea of like let's start

2006
01:13:04,640 --> 01:13:10,080
asking these questions and this was kind

2007
01:13:06,000 --> 01:13:11,679
of led by um an intern at our um MSR um

2008
01:13:10,080 --> 01:13:14,000
Kasha who asked these like kind of three

2009
01:13:11,679 --> 01:13:15,440
fundamental questions one which is do

2010
01:13:14,000 --> 01:13:18,800
these models learn the distribution of

2011
01:13:15,440 --> 01:13:21,360
data well do the embeddings uh capture

2012
01:13:18,800 --> 01:13:22,800
desired biological variation um from

2013
01:13:21,360 --> 01:13:24,880
these models and do these models from

2014
01:13:22,800 --> 01:13:26,400
these embeddings correct for undesired

2015
01:13:24,880 --> 01:13:27,440
technical variation when they come from

2016
01:13:26,400 --> 01:13:32,159
different studies or different

2017
01:13:27,440 --> 01:13:34,000
technologies. Okay. Um and so here's

2018
01:13:32,159 --> 01:13:35,840
this first kind of result that we did

2019
01:13:34,000 --> 01:13:39,040
that kind of started us down this this

2020
01:13:35,840 --> 01:13:41,360
path. Um so here's an example from SCGPT

2021
01:13:39,040 --> 01:13:43,520
where we're looking at its uh uh

2022
01:13:41,360 --> 01:13:47,440
pre-trained objective where the idea is

2023
01:13:43,520 --> 01:13:50,719
to predict uh uh unseen genes and it's

2024
01:13:47,440 --> 01:13:52,400
um mass objective. Okay. So uh this side

2025
01:13:50,719 --> 01:13:54,239
is going to be where we do this when we

2026
01:13:52,400 --> 01:13:55,840
look at just the uh training data set

2027
01:13:54,239 --> 01:13:58,400
with respect to mass gene expression

2028
01:13:55,840 --> 01:13:59,360
prediction. Um and here on the right

2029
01:13:58,400 --> 01:14:00,880
hand side what you're going to see is

2030
01:13:59,360 --> 01:14:02,960
the same thing but we do predictions

2031
01:14:00,880 --> 01:14:04,560
from using just cell embeddings right

2032
01:14:02,960 --> 01:14:07,120
and ideally if you were to do this

2033
01:14:04,560 --> 01:14:09,600
really well what what SGPT does actually

2034
01:14:07,120 --> 01:14:11,280
is it takes to make it kind of discreet

2035
01:14:09,600 --> 01:14:13,280
it takes the expression of every data

2036
01:14:11,280 --> 01:14:15,280
set um aligns them and then puts them in

2037
01:14:13,280 --> 01:14:17,360
these bins. And so what it's actually

2038
01:14:15,280 --> 01:14:19,199
doing is predicting these bins. And

2039
01:14:17,360 --> 01:14:20,640
ideally what you would see is a nice uh

2040
01:14:19,199 --> 01:14:22,239
diagonal, right? That if I was

2041
01:14:20,640 --> 01:14:25,280
predicting, well, I would have low bends

2042
01:14:22,239 --> 01:14:27,040
for these uh uh uh these cases uh here

2043
01:14:25,280 --> 01:14:29,040
for the lowly expressed things and it

2044
01:14:27,040 --> 01:14:30,159
kind of scale up for for the highly

2045
01:14:29,040 --> 01:14:32,320
expressed ones. And what you're kind of

2046
01:14:30,159 --> 01:14:33,520
seeing is not this at all. Um I'm kind

2047
01:14:32,320 --> 01:14:35,280
of just here just like kind of

2048
01:14:33,520 --> 01:14:37,040
predicting this sort of mean. And here

2049
01:14:35,280 --> 01:14:39,440
on this other side, if I do with cell

2050
01:14:37,040 --> 01:14:40,719
embeddings, I'm I'm I'm not doing so

2051
01:14:39,440 --> 01:14:42,159
well here for these lowly expressed

2052
01:14:40,719 --> 01:14:44,239
things and a little bit better for the

2053
01:14:42,159 --> 01:14:46,480
for the highly expressed So you might

2054
01:14:44,239 --> 01:14:48,000
ask like how does this now translate to

2055
01:14:46,480 --> 01:14:50,400
performance?

2056
01:14:48,000 --> 01:14:51,600
Um and so here's an example of what we

2057
01:14:50,400 --> 01:14:54,880
kind of did where we thought about

2058
01:14:51,600 --> 01:14:57,440
training data sets um where we wanted to

2059
01:14:54,880 --> 01:14:59,040
uh uh uh predict gene expression using

2060
01:14:57,440 --> 01:15:02,400
these uh this different model. Here

2061
01:14:59,040 --> 01:15:04,480
we're going to focus on um SC GPT uh

2062
01:15:02,400 --> 01:15:06,000
trained on uh different types of data

2063
01:15:04,480 --> 01:15:08,000
sets.

2064
01:15:06,000 --> 01:15:09,920
The uh this is the light axis is going

2065
01:15:08,000 --> 01:15:12,640
to be mean squareed error. So a lower

2066
01:15:09,920 --> 01:15:14,080
number means uh better performance. The

2067
01:15:12,640 --> 01:15:16,400
first model you're seeing is our

2068
01:15:14,080 --> 01:15:18,159
baseline. So what we do here is I we

2069
01:15:16,400 --> 01:15:20,480
what Kasha did here is she just took the

2070
01:15:18,159 --> 01:15:22,080
mean of every single cell in my data set

2071
01:15:20,480 --> 01:15:25,199
and that's my model. There's no

2072
01:15:22,080 --> 01:15:28,000
training. Okay. And that's how well uh

2073
01:15:25,199 --> 01:15:31,440
that model does. Now what we could do is

2074
01:15:28,000 --> 01:15:33,440
now I can say what if I gave uh um SGBT

2075
01:15:31,440 --> 01:15:35,199
just straight noise like I gave it like

2076
01:15:33,440 --> 01:15:36,880
random numbers like there's no there's

2077
01:15:35,199 --> 01:15:38,960
no real data here and I train it on just

2078
01:15:36,880 --> 01:15:39,920
like random data and then I as a predict

2079
01:15:38,960 --> 01:15:41,920
did you just un expression

2080
01:15:39,920 --> 01:15:43,280
reconstruction? does quite poorly with

2081
01:15:41,920 --> 01:15:44,239
that when I feed it noise which makes a

2082
01:15:43,280 --> 01:15:46,800
lot of sense right I didn't actually

2083
01:15:44,239 --> 01:15:48,159
give any train data sets the rest of it

2084
01:15:46,800 --> 01:15:51,040
actually is when I give the data the

2085
01:15:48,159 --> 01:15:54,640
model actually real data so what happens

2086
01:15:51,040 --> 01:15:56,000
when I train the model on uh on on cells

2087
01:15:54,640 --> 01:15:57,600
coming from the kidney cells coming from

2088
01:15:56,000 --> 01:16:00,320
the blood or cells coming from just

2089
01:15:57,600 --> 01:16:02,000
humans so regardless of tissue um and

2090
01:16:00,320 --> 01:16:04,239
you can kind of see none of these models

2091
01:16:02,000 --> 01:16:07,520
are that much better than me just using

2092
01:16:04,239 --> 01:16:11,760
the mean this like mean model as my uh

2093
01:16:07,520 --> 01:16:13,280
predictive model Um so then okay not

2094
01:16:11,760 --> 01:16:14,159
great. So then the question becomes

2095
01:16:13,280 --> 01:16:15,679
again we're we're looking for

2096
01:16:14,159 --> 01:16:17,760
opportunity. This is not a bad thing

2097
01:16:15,679 --> 01:16:19,440
about these models. Um there's a chance

2098
01:16:17,760 --> 01:16:21,520
to grow right. So then we start asking

2099
01:16:19,440 --> 01:16:23,760
the second question which is okay what

2100
01:16:21,520 --> 01:16:27,360
about the the other kind of thing of

2101
01:16:23,760 --> 01:16:28,640
annotation by cell type or uh am I doing

2102
01:16:27,360 --> 01:16:30,320
well of getting rid of technical

2103
01:16:28,640 --> 01:16:32,640
variation. So for the first case you can

2104
01:16:30,320 --> 01:16:35,120
kind of guess based on talk how well

2105
01:16:32,640 --> 01:16:37,840
this is going to go. Um not fantastic

2106
01:16:35,120 --> 01:16:39,520
for some of these models. So um on the

2107
01:16:37,840 --> 01:16:41,920
on the far left hand side what you're

2108
01:16:39,520 --> 01:16:45,199
going to see is um all these genes from

2109
01:16:41,920 --> 01:16:49,199
this corpus um kind of annotated by uh

2110
01:16:45,199 --> 01:16:50,400
uh uh different uh cell types. And u on

2111
01:16:49,199 --> 01:16:52,320
here you're going to see is a highly

2112
01:16:50,400 --> 01:16:54,080
variable gene model. That's a kind of

2113
01:16:52,320 --> 01:16:56,320
baseline where we take just the highly

2114
01:16:54,080 --> 01:16:58,560
variable genes as our our model and say

2115
01:16:56,320 --> 01:17:00,400
how well is this at predicting a given

2116
01:16:58,560 --> 01:17:01,600
cell type. And you can see how well you

2117
01:17:00,400 --> 01:17:02,880
can kind of do by kind of getting this

2118
01:17:01,600 --> 01:17:05,120
nice clustering and this embedding on

2119
01:17:02,880 --> 01:17:07,600
this map of um certain cell types

2120
01:17:05,120 --> 01:17:08,560
together. Um here we use harmony which

2121
01:17:07,600 --> 01:17:09,920
is again it's like kind of data

2122
01:17:08,560 --> 01:17:12,480
integration one. Harmony does quite well

2123
01:17:09,920 --> 01:17:14,960
at this task. SCVI which is a basic

2124
01:17:12,480 --> 01:17:17,840
autoenccoder also does this uh uh very

2125
01:17:14,960 --> 01:17:20,800
well and then gene former and SCGPT

2126
01:17:17,840 --> 01:17:22,560
struggle a little bit in uh in uh

2127
01:17:20,800 --> 01:17:24,560
dissecting different cell types. Again

2128
01:17:22,560 --> 01:17:25,600
not surprising given our last talk but

2129
01:17:24,560 --> 01:17:27,360
you might have this question of what it

2130
01:17:25,600 --> 01:17:28,480
is that that gene former and SCGP are

2131
01:17:27,360 --> 01:17:30,320
actually learning. So let's look at the

2132
01:17:28,480 --> 01:17:33,280
same plot but now let's color code by

2133
01:17:30,320 --> 01:17:34,880
sequencing technology. Um so again on

2134
01:17:33,280 --> 01:17:37,120
the lefth hand side you have this idea

2135
01:17:34,880 --> 01:17:39,040
where uh everything here is separated

2136
01:17:37,120 --> 01:17:40,480
out by sequencing tech. The idea if

2137
01:17:39,040 --> 01:17:42,000
you're really good at integration is you

2138
01:17:40,480 --> 01:17:43,920
should look something like harmony where

2139
01:17:42,000 --> 01:17:45,920
I have the all these tech technologies

2140
01:17:43,920 --> 01:17:48,239
kind of integrated together. You see how

2141
01:17:45,920 --> 01:17:50,320
well uh harmony does and SCVI is not

2142
01:17:48,239 --> 01:17:52,719
terrible at this task and effectively

2143
01:17:50,320 --> 01:17:55,280
gene former uh as a as a stark example

2144
01:17:52,719 --> 01:17:57,199
is like just learning batch.

2145
01:17:55,280 --> 01:18:00,320
Um so it's just learning sequencing

2146
01:17:57,199 --> 01:18:02,800
tech. And so what we started to think

2147
01:18:00,320 --> 01:18:04,560
about was okay well out of these three

2148
01:18:02,800 --> 01:18:06,400
things that Kasha kind of showed you

2149
01:18:04,560 --> 01:18:08,159
know how well is this model like

2150
01:18:06,400 --> 01:18:10,480
learning the distribution very well like

2151
01:18:08,159 --> 01:18:11,840
it's not doing so great at that is it

2152
01:18:10,480 --> 01:18:14,239
are these embeddings capturing

2153
01:18:11,840 --> 01:18:16,000
biological variation like somewhat and

2154
01:18:14,239 --> 01:18:18,000
you know really these embeddings are

2155
01:18:16,000 --> 01:18:19,040
just kind of correcting for they're not

2156
01:18:18,000 --> 01:18:21,040
really correcting for undesired

2157
01:18:19,040 --> 01:18:23,760
technical variation at all and so we

2158
01:18:21,040 --> 01:18:26,159
started and we put this paper out and um

2159
01:18:23,760 --> 01:18:28,320
I was kind of nervous about it um but I

2160
01:18:26,159 --> 01:18:29,760
I ironically other people had also

2161
01:18:28,320 --> 01:18:31,679
identified very similar things actually

2162
01:18:29,760 --> 01:18:33,040
people in this building on right below

2163
01:18:31,679 --> 01:18:34,640
us right where there have been a lot of

2164
01:18:33,040 --> 01:18:36,480
papers since then that have come out

2165
01:18:34,640 --> 01:18:38,560
which have kind of noticed very similar

2166
01:18:36,480 --> 01:18:40,480
things right that you know single

2167
01:18:38,560 --> 01:18:42,640
cellation models tend to not do so well

2168
01:18:40,480 --> 01:18:43,440
as well as as linear methods um

2169
01:18:42,640 --> 01:18:45,520
particularly if you think about

2170
01:18:43,440 --> 01:18:49,440
perturbation prediction I like this idea

2171
01:18:45,520 --> 01:18:51,040
of one PCA kind of rules them all um

2172
01:18:49,440 --> 01:18:52,640
there's the recent papers that came out

2173
01:18:51,040 --> 01:18:54,159
even this year in nature methods this

2174
01:18:52,640 --> 01:18:57,199
idea of like I could just take a linear

2175
01:18:54,159 --> 01:18:58,800
model and and um uh that tends to be a

2176
01:18:57,199 --> 01:19:00,400
better model than than having all these

2177
01:18:58,800 --> 01:19:01,840
other type of methods. Actually, we'll

2178
01:19:00,400 --> 01:19:03,440
circle back to the finding of this paper

2179
01:19:01,840 --> 01:19:06,800
that we actually see in our studies as

2180
01:19:03,440 --> 01:19:08,000
well. Um and and and there have been

2181
01:19:06,800 --> 01:19:09,600
more papers that have come out since

2182
01:19:08,000 --> 01:19:11,840
then. Uh kind of all kind of around

2183
01:19:09,600 --> 01:19:13,920
similar ideas. Now, if you think about

2184
01:19:11,840 --> 01:19:15,679
this, one thing you could ask is how do

2185
01:19:13,920 --> 01:19:16,880
I fix the architecture of these models?

2186
01:19:15,679 --> 01:19:19,120
And that's one question that we could

2187
01:19:16,880 --> 01:19:20,800
talk about. But one question came kind

2188
01:19:19,120 --> 01:19:23,520
of came to mind to me is going back to

2189
01:19:20,800 --> 01:19:25,520
this data question. Um so I have this

2190
01:19:23,520 --> 01:19:27,600
kind of reality here. But one thing I

2191
01:19:25,520 --> 01:19:29,360
kind of asked is is data abundance or

2192
01:19:27,600 --> 01:19:30,960
diversity somehow bottlenecking these

2193
01:19:29,360 --> 01:19:32,640
things like is training data kind of the

2194
01:19:30,960 --> 01:19:34,320
issue like is it not the architecture

2195
01:19:32,640 --> 01:19:35,600
what we're actually training the data on

2196
01:19:34,320 --> 01:19:36,960
you can think about this this idea of

2197
01:19:35,600 --> 01:19:38,000
like I like to think about this in three

2198
01:19:36,960 --> 01:19:40,159
different parts where it comes to these

2199
01:19:38,000 --> 01:19:41,520
different methods you know I have a I

2200
01:19:40,159 --> 01:19:43,920
have the architecture which to me is

2201
01:19:41,520 --> 01:19:45,280
kind of the car itself I have the data

2202
01:19:43,920 --> 01:19:46,640
which is kind of the gas I put in the

2203
01:19:45,280 --> 01:19:48,400
car and I have the task which is like

2204
01:19:46,640 --> 01:19:50,080
what I drive the car on in terms of road

2205
01:19:48,400 --> 01:19:51,840
and challenges and I really thought

2206
01:19:50,080 --> 01:19:53,760
about this idea of like are we putting

2207
01:19:51,840 --> 01:19:55,920
the right data right gas in the car to

2208
01:19:53,760 --> 01:19:57,280
really make this thing go. And so we

2209
01:19:55,920 --> 01:19:59,280
really asked this question of like can

2210
01:19:57,280 --> 01:20:00,719
we construct nice training corpuses to

2211
01:19:59,280 --> 01:20:02,400
do this? And if you remember I said that

2212
01:20:00,719 --> 01:20:05,280
all these models were trained on 50

2213
01:20:02,400 --> 01:20:07,600
million cells, 30 30 million cells, 100

2214
01:20:05,280 --> 01:20:08,480
million cells. There was someone um I

2215
01:20:07,600 --> 01:20:09,760
didn't maybe hear this that said they

2216
01:20:08,480 --> 01:20:12,400
were going to create a corpus that had

2217
01:20:09,760 --> 01:20:14,320
500 million cells and it was like whoa.

2218
01:20:12,400 --> 01:20:17,360
Um but like how much information are we

2219
01:20:14,320 --> 01:20:18,560
getting per cell, right? And so we asked

2220
01:20:17,360 --> 01:20:21,120
this question and this was kind of

2221
01:20:18,560 --> 01:20:24,159
co-led by a student of mine um Allan as

2222
01:20:21,120 --> 01:20:27,280
well as uh Mattie Hughes and and AA

2223
01:20:24,159 --> 01:20:28,880
who's now a scientist here um where we

2224
01:20:27,280 --> 01:20:31,360
asked this question of can we kind of

2225
01:20:28,880 --> 01:20:33,679
think about how much these data kind of

2226
01:20:31,360 --> 01:20:35,040
saturate or or kind of like scaling laws

2227
01:20:33,679 --> 01:20:36,880
with respect to data in these different

2228
01:20:35,040 --> 01:20:39,440
corpuses. So what we did is like three

2229
01:20:36,880 --> 01:20:40,400
different experiments that or a lot more

2230
01:20:39,440 --> 01:20:42,960
experiments and I'll show you a little

2231
01:20:40,400 --> 01:20:44,800
bit but the idea of this was if I took a

2232
01:20:42,960 --> 01:20:47,840
model if I took data sets from SCAB so

2233
01:20:44,800 --> 01:20:50,640
SCAB has 22 million cells and I

2234
01:20:47,840 --> 01:20:52,480
downsampled them to a fraction of their

2235
01:20:50,640 --> 01:20:55,360
sizes. So I took all 22 million cells

2236
01:20:52,480 --> 01:20:57,679
and I downsample it to have 1% 10% 25 50

2237
01:20:55,360 --> 01:20:59,440
and 75% of its data and I do this in

2238
01:20:57,679 --> 01:21:00,880
three different ways. Right? The first

2239
01:20:59,440 --> 01:21:02,320
way I'm going to do is just uniform down

2240
01:21:00,880 --> 01:21:03,360
sampling. So I'm going to take all 22

2241
01:21:02,320 --> 01:21:05,679
million cells and I'm just going to down

2242
01:21:03,360 --> 01:21:07,040
sample to these different fractions. The

2243
01:21:05,679 --> 01:21:09,199
second way I'm going to do is just try

2244
01:21:07,040 --> 01:21:10,880
to preserve some sort of diversity. So

2245
01:21:09,199 --> 01:21:12,400
the and the and the second way I'm going

2246
01:21:10,880 --> 01:21:13,600
to do is I'm going to down sample but

2247
01:21:12,400 --> 01:21:15,440
we're going to try to preserve the

2248
01:21:13,600 --> 01:21:16,880
labels that I know these these cells

2249
01:21:15,440 --> 01:21:18,080
have. So if I have a different cell type

2250
01:21:16,880 --> 01:21:20,000
I'm going to try to keep the proportion

2251
01:21:18,080 --> 01:21:21,840
of cell types as in the original data

2252
01:21:20,000 --> 01:21:24,239
set but just down sample them so that I

2253
01:21:21,840 --> 01:21:26,640
have 1% 10 all the way to 75% of the

2254
01:21:24,239 --> 01:21:28,400
data. Okay. The third idea I'm going to

2255
01:21:26,640 --> 01:21:29,920
do the same kind of downsampling but I'm

2256
01:21:28,400 --> 01:21:31,920
not going to use the annotated labels

2257
01:21:29,920 --> 01:21:33,120
from the data. I'm going to use uh like

2258
01:21:31,920 --> 01:21:35,600
I'm going to use what we call geometric

2259
01:21:33,120 --> 01:21:37,280
sketching which is this idea where I can

2260
01:21:35,600 --> 01:21:38,960
uh do like effectively clustering and

2261
01:21:37,280 --> 01:21:40,880
I'm going try to preserve around the

2262
01:21:38,960 --> 01:21:43,679
centroidids of each cluster a certain

2263
01:21:40,880 --> 01:21:44,560
proportion of each cell. Okay. Now on

2264
01:21:43,679 --> 01:21:46,080
the right hand side what I'm going to

2265
01:21:44,560 --> 01:21:48,239
show you is a result of running a model

2266
01:21:46,080 --> 01:21:50,560
on these different fractions. So on the

2267
01:21:48,239 --> 01:21:53,520
x axis you're going to see an increasing

2268
01:21:50,560 --> 01:21:54,400
proportionate data size. On the y- axis

2269
01:21:53,520 --> 01:21:56,000
what you're going to see is model

2270
01:21:54,400 --> 01:21:58,400
performance. And what you expect to see

2271
01:21:56,000 --> 01:22:00,880
is that if I see more data that problem

2272
01:21:58,400 --> 01:22:03,840
performance should go up. Right? That's

2273
01:22:00,880 --> 01:22:05,440
not exactly what you see. So what you

2274
01:22:03,840 --> 01:22:07,040
see on the lefth hand side is uh so

2275
01:22:05,440 --> 01:22:09,440
these are my different schemes all kind

2276
01:22:07,040 --> 01:22:11,360
of colorcoded together. Uh this is by

2277
01:22:09,440 --> 01:22:13,040
running gene former. What you can see is

2278
01:22:11,360 --> 01:22:16,560
a very clear story. This model kind of

2279
01:22:13,040 --> 01:22:18,000
saturates at 1% of the data.

2280
01:22:16,560 --> 01:22:20,000
You might ask like okay how much does

2281
01:22:18,000 --> 01:22:21,520
this actually replicate across different

2282
01:22:20,000 --> 01:22:22,880
things. So what we do is we take the

2283
01:22:21,520 --> 01:22:24,400
study we're going to do this in many

2284
01:22:22,880 --> 01:22:26,239
different ways. So I'm going to take

2285
01:22:24,400 --> 01:22:28,159
these 22 million cells. We're going to

2286
01:22:26,239 --> 01:22:29,360
do these kind of random down sampling

2287
01:22:28,159 --> 01:22:31,120
schemes across these different

2288
01:22:29,360 --> 01:22:32,719
percentages. We're going to do this over

2289
01:22:31,120 --> 01:22:35,199
many different models and increasing

2290
01:22:32,719 --> 01:22:37,520
complexity. So models going from just if

2291
01:22:35,199 --> 01:22:38,719
I just had if I did my model was PCA all

2292
01:22:37,520 --> 01:22:41,360
the way down to something more complex

2293
01:22:38,719 --> 01:22:45,280
like similarity, right? And we're going

2294
01:22:41,360 --> 01:22:46,960
to do this um over uh uh different

2295
01:22:45,280 --> 01:22:48,719
parameter sizes and different inputs,

2296
01:22:46,960 --> 01:22:51,120
right?

2297
01:22:48,719 --> 01:22:53,199
Um we have four different tasks that

2298
01:22:51,120 --> 01:22:55,440
we're going to run.

2299
01:22:53,199 --> 01:22:56,560
Um the first are a set of zeroot tasks

2300
01:22:55,440 --> 01:22:57,760
where we're going to think about cell

2301
01:22:56,560 --> 01:23:00,480
type classification and batch

2302
01:22:57,760 --> 01:23:02,000
integration on uh these different data

2303
01:23:00,480 --> 01:23:02,960
sets

2304
01:23:02,000 --> 01:23:05,440
and we're also going to have a set of

2305
01:23:02,960 --> 01:23:06,800
fine-tuned tasks. Uh one be cell type

2306
01:23:05,440 --> 01:23:08,159
classification and the other being

2307
01:23:06,800 --> 01:23:09,760
perturbation prediction where I'm going

2308
01:23:08,159 --> 01:23:10,800
to take we're going to take Tahoe and

2309
01:23:09,760 --> 01:23:13,520
split it up into four different

2310
01:23:10,800 --> 01:23:14,880
fractions based on different drugs and

2311
01:23:13,520 --> 01:23:18,239
different tissues within all these

2312
01:23:14,880 --> 01:23:20,480
different drugs. Right? Um and in total

2313
01:23:18,239 --> 01:23:21,920
we're going to have about 6,400 total

2314
01:23:20,480 --> 01:23:24,320
experiments across all these different

2315
01:23:21,920 --> 01:23:27,199
things. This is a this is this is pure

2316
01:23:24,320 --> 01:23:28,639
review. Um basically

2317
01:23:27,199 --> 01:23:30,159
uh so we're going to do this over many

2318
01:23:28,639 --> 01:23:31,920
different experiments or and then there

2319
01:23:30,159 --> 01:23:33,199
are some uh side experiments I'm not

2320
01:23:31,920 --> 01:23:36,480
going to show. We'll just we'll show

2321
01:23:33,199 --> 01:23:38,320
results for for a lot of these. Okay. So

2322
01:23:36,480 --> 01:23:39,840
the idea of like the saturation idea was

2323
01:23:38,320 --> 01:23:41,199
really this this idea of like if I take

2324
01:23:39,840 --> 01:23:43,520
a pre-trained model and I have an

2325
01:23:41,199 --> 01:23:45,520
evaluation data can I identify a

2326
01:23:43,520 --> 01:23:47,520
saturation point? Effectively what we're

2327
01:23:45,520 --> 01:23:49,280
going to ask is at what percent of the

2328
01:23:47,520 --> 01:23:50,960
data do I see that the model is no

2329
01:23:49,280 --> 01:23:53,840
longer kind of increasing in performance

2330
01:23:50,960 --> 01:23:56,080
anymore? like it's saturated, right?

2331
01:23:53,840 --> 01:23:57,840
So, we do this on a bunch of zeroot

2332
01:23:56,080 --> 01:23:59,360
classification tasks. So, here what

2333
01:23:57,840 --> 01:24:01,360
you're seeing are our different

2334
01:23:59,360 --> 01:24:03,280
subsampling schemes, the uniform random

2335
01:24:01,360 --> 01:24:05,840
case, geometric sketching, cell type

2336
01:24:03,280 --> 01:24:07,760
reeated. Um, you're going to see these

2337
01:24:05,840 --> 01:24:09,360
different data sets on each fraction

2338
01:24:07,760 --> 01:24:11,440
here across every single different

2339
01:24:09,360 --> 01:24:13,280
model. And what you can see is that

2340
01:24:11,440 --> 01:24:15,760
overwhelmingly a lot of times models

2341
01:24:13,280 --> 01:24:17,679
tend to saturate at at 1% of the data

2342
01:24:15,760 --> 01:24:19,280
and I don't think any more than than

2343
01:24:17,679 --> 01:24:21,360
25%.

2344
01:24:19,280 --> 01:24:23,360
On this given uh cell type annotation

2345
01:24:21,360 --> 01:24:25,120
task if you want to fine-tune it's like

2346
01:24:23,360 --> 01:24:28,480
way worse like I don't need any data

2347
01:24:25,120 --> 01:24:30,400
really like I just need 1%. Right? Um

2348
01:24:28,480 --> 01:24:31,760
and in some cases I might need 10% but

2349
01:24:30,400 --> 01:24:33,040
most cases for a lot of these models

2350
01:24:31,760 --> 01:24:35,440
particularly the more complicated ones

2351
01:24:33,040 --> 01:24:37,440
like G4 similarity I just need 1% of the

2352
01:24:35,440 --> 01:24:38,880
data.

2353
01:24:37,440 --> 01:24:41,360
perturbation prediction is actually

2354
01:24:38,880 --> 01:24:42,480
really interesting one. Um I kind of

2355
01:24:41,360 --> 01:24:44,159
want to take a little bit of time to

2356
01:24:42,480 --> 01:24:45,840
walk through this. So we also did some

2357
01:24:44,159 --> 01:24:48,239
perturbation prediction. So here you're

2358
01:24:45,840 --> 01:24:52,080
looking at R squar. So a few things. So

2359
01:24:48,239 --> 01:24:54,639
this is R squar. Um the dotted line here

2360
01:24:52,080 --> 01:24:56,960
is no is a no change model. It's the

2361
01:24:54,639 --> 01:24:58,639
model that says like what if I just my

2362
01:24:56,960 --> 01:25:00,239
perturbation prediction was like I just

2363
01:24:58,639 --> 01:25:03,840
predicted like no change from the other

2364
01:25:00,239 --> 01:25:06,080
state. Um what you're seeing here are

2365
01:25:03,840 --> 01:25:07,679
the different colors here. So the these

2366
01:25:06,080 --> 01:25:10,000
different color schemes are like the

2367
01:25:07,679 --> 01:25:12,880
cell type reweed geometric sketching and

2368
01:25:10,000 --> 01:25:14,719
then random. This non-p pre-trained

2369
01:25:12,880 --> 01:25:16,560
thing is me just saying what if we just

2370
01:25:14,719 --> 01:25:17,920
like randomly initialized the weights

2371
01:25:16,560 --> 01:25:19,120
and then we just did fine-tune

2372
01:25:17,920 --> 01:25:20,880
classification on this randomly

2373
01:25:19,120 --> 01:25:22,480
initialized model. And that kind of gets

2374
01:25:20,880 --> 01:25:25,120
you like most of the way in terms of

2375
01:25:22,480 --> 01:25:27,679
like the ultimate model performance,

2376
01:25:25,120 --> 01:25:29,199
right? Um again if you want to ask like

2377
01:25:27,679 --> 01:25:30,639
where does things saturate across all

2378
01:25:29,199 --> 01:25:31,840
these different things, the answer again

2379
01:25:30,639 --> 01:25:35,520
is pretty overwhelming. it just

2380
01:25:31,840 --> 01:25:37,120
saturates a lot. Um, so we had a we had

2381
01:25:35,520 --> 01:25:38,400
a we had actually really great reviewers

2382
01:25:37,120 --> 01:25:39,440
here that kind of pushed us on like

2383
01:25:38,400 --> 01:25:40,639
these different tasks and these

2384
01:25:39,440 --> 01:25:42,239
different questions across these

2385
01:25:40,639 --> 01:25:44,000
different experiments asking like, well,

2386
01:25:42,239 --> 01:25:45,600
could it be this, could it be that? Oh,

2387
01:25:44,000 --> 01:25:47,600
yeah.

2388
01:25:45,600 --> 01:25:49,440
>> Uh, quick question. So, it seems like

2389
01:25:47,600 --> 01:25:52,000
you started out as the smallest data

2390
01:25:49,440 --> 01:25:53,760
fraction you subsampled as 1%. So, did

2391
01:25:52,000 --> 01:25:54,320
you try subsampling kind of below this

2392
01:25:53,760 --> 01:25:56,960
and seeing

2393
01:25:54,320 --> 01:25:58,719
>> at 0%? Yeah. like taking like no data

2394
01:25:56,960 --> 01:26:00,639
like let's just like randomly initialize

2395
01:25:58,719 --> 01:26:02,400
just like random like

2396
01:26:00,639 --> 01:26:03,600
>> yeah I guess for this one it had

2397
01:26:02,400 --> 01:26:06,000
comparable performance but you can

2398
01:26:03,600 --> 01:26:07,440
imagine that like for 0.1% or like 0.01

2399
01:26:06,000 --> 01:26:09,520
01 right that's

2400
01:26:07,440 --> 01:26:12,080
>> we stopped at 1% because every time I

2401
01:26:09,520 --> 01:26:13,360
did a new fraction it like it ballooned

2402
01:26:12,080 --> 01:26:15,360
in number of things but that's a good

2403
01:26:13,360 --> 01:26:17,520
question like how low could we have gone

2404
01:26:15,360 --> 01:26:19,920
we do we have a set of experiments in

2405
01:26:17,520 --> 01:26:21,199
the new sample which is like not an

2406
01:26:19,920 --> 01:26:23,760
archive but I'm happy to send you these

2407
01:26:21,199 --> 01:26:25,760
results that are on like we do a 0%

2408
01:26:23,760 --> 01:26:27,760
thing where we include like no data

2409
01:26:25,760 --> 01:26:29,280
which was a a suggestion that a reviewer

2410
01:26:27,760 --> 01:26:30,800
gave us um and I'm happy to send you

2411
01:26:29,280 --> 01:26:37,080
those uh as like where they kind of

2412
01:26:30,800 --> 01:26:37,080
compare on those cool yeah thanks Yeah.

2413
01:26:38,639 --> 01:26:42,080
>> Oh, this is exploding. Yeah. Yeah.

2414
01:26:40,159 --> 01:26:44,400
>> Uh sorry, just on the last slide, um for

2415
01:26:42,080 --> 01:26:47,440
the pipation prediction task,

2416
01:26:44,400 --> 01:26:49,520
>> um it says hel held out cell types. So

2417
01:26:47,440 --> 01:26:52,719
you validated on cells that you like

2418
01:26:49,520 --> 01:26:55,679
cell types or distribution cell. Did you

2419
01:26:52,719 --> 01:26:57,760
also do it for like seen cell types or

2420
01:26:55,679 --> 01:26:59,120
>> uh not seen? So we try. Yeah. So there's

2421
01:26:57,760 --> 01:27:00,480
there are some that are seen. So we do

2422
01:26:59,120 --> 01:27:03,280
this in like a few different ways. So

2423
01:27:00,480 --> 01:27:04,800
what we do in Tahoe is Tahoe has a bunch

2424
01:27:03,280 --> 01:27:06,880
of different small molecules that are

2425
01:27:04,800 --> 01:27:09,920
trained on um across different cell

2426
01:27:06,880 --> 01:27:12,320
lines. What we do is that we Tahoe is

2427
01:27:09,920 --> 01:27:14,320
kind of tough because again place for

2428
01:27:12,320 --> 01:27:15,920
opportunity. Uh Taho is kind of tough

2429
01:27:14,320 --> 01:27:17,280
because a lot of these cell lines don't

2430
01:27:15,920 --> 01:27:19,840
actually see any effect across any

2431
01:27:17,280 --> 01:27:21,760
drugs. So we do is we try to hand we

2432
01:27:19,840 --> 01:27:25,120
cherrypicked a little bit where we look

2433
01:27:21,760 --> 01:27:27,520
figure four shows E distance between the

2434
01:27:25,120 --> 01:27:31,120
untreated and treated cells. We took the

2435
01:27:27,520 --> 01:27:34,000
four topmost of those and then we looked

2436
01:27:31,120 --> 01:27:36,639
at which cell lines those drugs actually

2437
01:27:34,000 --> 01:27:39,120
had an effect in. And then what we do is

2438
01:27:36,639 --> 01:27:41,600
we train on the drug where had some sort

2439
01:27:39,120 --> 01:27:44,080
of large effect and held out a random of

2440
01:27:41,600 --> 01:27:44,719
the other like four in that group.

2441
01:27:44,080 --> 01:27:46,400
>> Um

2442
01:27:44,719 --> 01:27:47,520
>> you hold out like an entire cell line.

2443
01:27:46,400 --> 01:27:49,440
>> Oh well entire cell line.

2444
01:27:47,520 --> 01:27:51,040
>> Okay. So that's even harder then. Yeah.

2445
01:27:49,440 --> 01:27:52,800
So is there a version of the task where

2446
01:27:51,040 --> 01:27:54,400
you can like hold out a portion of the

2447
01:27:52,800 --> 01:27:55,280
cells from the cell line and I think

2448
01:27:54,400 --> 01:27:56,960
that's way easier.

2449
01:27:55,280 --> 01:27:58,960
>> Yeah. Yeah. We didn't do that here. We

2450
01:27:56,960 --> 01:28:00,880
did the the extreme case again for this

2451
01:27:58,960 --> 01:28:02,320
like data explosion kind of question.

2452
01:28:00,880 --> 01:28:03,679
But I would imagine that you would see

2453
01:28:02,320 --> 01:28:04,400
these things kind of go up if you were

2454
01:28:03,679 --> 01:28:05,760
to do Yeah.

2455
01:28:04,400 --> 01:28:07,760
>> Yeah.

2456
01:28:05,760 --> 01:28:09,440
>> We picked the hardest of the the task of

2457
01:28:07,760 --> 01:28:11,679
like if I were an ideal setting, could

2458
01:28:09,440 --> 01:28:12,320
we can we mirror that like ideal kind of

2459
01:28:11,679 --> 01:28:14,560
setting?

2460
01:28:12,320 --> 01:28:14,880
>> Yeah.

2461
01:28:14,560 --> 01:28:15,760
>> Learn.

2462
01:28:14,880 --> 01:28:19,199
>> Yeah.

2463
01:28:15,760 --> 01:28:22,320
>> So they're all basically uh a flat line

2464
01:28:19,199 --> 01:28:24,800
around R square of 7. I assume that's

2465
01:28:22,320 --> 01:28:26,960
the similarity between the average

2466
01:28:24,800 --> 01:28:28,639
training cell type and the held out cell

2467
01:28:26,960 --> 01:28:29,199
type, right?

2468
01:28:28,639 --> 01:28:31,679
>> Yeah.

2469
01:28:29,199 --> 01:28:34,480
>> So that's um Yeah. So you don't need a

2470
01:28:31,679 --> 01:28:37,199
model for that.

2471
01:28:34,480 --> 01:28:39,199
>> And and when you're training cell types

2472
01:28:37,199 --> 01:28:41,520
are closer to your test cell type, then

2473
01:28:39,199 --> 01:28:43,280
the line will shift up and when it's

2474
01:28:41,520 --> 01:28:45,199
>> I'm going to get to some sort of that.

2475
01:28:43,280 --> 01:28:46,239
Yeah. But you should see it like shift

2476
01:28:45,199 --> 01:28:47,280
up a little bit and we're going to get

2477
01:28:46,239 --> 01:28:49,280
to a little bit. I'm going to go back to

2478
01:28:47,280 --> 01:28:52,560
training days in a little bit, but

2479
01:28:49,280 --> 01:28:52,560
>> real quick. Yeah.

2480
01:28:56,400 --> 01:29:00,320
Is the no change baseline when you're

2481
01:28:58,400 --> 01:29:02,880
computing these means is it using the

2482
01:29:00,320 --> 01:29:03,120
same test train split same test split.

2483
01:29:02,880 --> 01:29:04,639
Yeah.

2484
01:29:03,120 --> 01:29:06,560
>> So it's only using one like as you go

2485
01:29:04,639 --> 01:29:10,679
along it's using 1% to 100%.

2486
01:29:06,560 --> 01:29:10,679
>> Yeah. Yeah. just choosing the same

2487
01:29:15,760 --> 01:29:20,880
>> uh some of the ML field like people

2488
01:29:18,320 --> 01:29:23,520
argue that the value of training this

2489
01:29:20,880 --> 01:29:25,920
foundation model is really to learn is a

2490
01:29:23,520 --> 01:29:28,880
this universal embedding and to be able

2491
01:29:25,920 --> 01:29:31,280
to do some unseen perturbations. So for

2492
01:29:28,880 --> 01:29:35,360
the baseline being compared I think one

2493
01:29:31,280 --> 01:29:38,560
limitation is that they cannot be

2494
01:29:35,360 --> 01:29:40,639
transferred to the ancertibbations. So I

2495
01:29:38,560 --> 01:29:42,719
wonder do you have any insight about

2496
01:29:40,639 --> 01:29:45,280
whether their claim is true or not

2497
01:29:42,719 --> 01:29:47,199
whether they can really perform an

2498
01:29:45,280 --> 01:29:50,239
perturbation wells for the foundation.

2499
01:29:47,199 --> 01:29:52,239
>> Yeah my hunch is my hunch is hard. My

2500
01:29:50,239 --> 01:29:53,920
hunch is like no. I I'll get to like

2501
01:29:52,239 --> 01:29:55,520
some idea of like where I think we can

2502
01:29:53,920 --> 01:29:56,800
go for this. Actually this is a really

2503
01:29:55,520 --> 01:29:58,400
good segue. I don't know if anyone has

2504
01:29:56,800 --> 01:30:00,560
like any burning questions, but maybe

2505
01:29:58,400 --> 01:30:02,320
it's a really good segue of like where I

2506
01:30:00,560 --> 01:30:06,400
think there are opportunities for for

2507
01:30:02,320 --> 01:30:08,239
this. Um, so we saw this saturation one

2508
01:30:06,400 --> 01:30:09,760
one thing that a that a reviewer asked

2509
01:30:08,239 --> 01:30:11,600
us to do is like okay for the models

2510
01:30:09,760 --> 01:30:12,719
that you can completely mess with their

2511
01:30:11,600 --> 01:30:14,080
architectures. How much does

2512
01:30:12,719 --> 01:30:15,199
architecture play a role? This is

2513
01:30:14,080 --> 01:30:17,520
actually quite important for like this

2514
01:30:15,199 --> 01:30:20,560
question which is you know if I were to

2515
01:30:17,520 --> 01:30:23,040
take something like SCBI and scale it.

2516
01:30:20,560 --> 01:30:25,280
Um, so one thing that we do here is I we

2517
01:30:23,040 --> 01:30:29,280
take the number of layers and parameters

2518
01:30:25,280 --> 01:30:32,080
in SCVI and either cut it in half or

2519
01:30:29,280 --> 01:30:35,199
scale it up to be double its size and

2520
01:30:32,080 --> 01:30:37,120
four times its size. Um, and these were

2521
01:30:35,199 --> 01:30:39,120
the baselines that some of these models

2522
01:30:37,120 --> 01:30:41,679
were struggling to to beat before the

2523
01:30:39,120 --> 01:30:42,719
HVG baseline, the PCA baseline. One

2524
01:30:41,679 --> 01:30:44,480
thing that's really interesting, again,

2525
01:30:42,719 --> 01:30:46,960
this is on cell type annotation. So take

2526
01:30:44,480 --> 01:30:47,920
this with, you know, uh uh we didn't

2527
01:30:46,960 --> 01:30:49,520
want to we wanted to do something that

2528
01:30:47,920 --> 01:30:51,520
was zero shot and and not something that

2529
01:30:49,520 --> 01:30:53,040
was fine-tuned. Um but you do see this

2530
01:30:51,520 --> 01:30:56,880
nice kind of scaling thing that kind of

2531
01:30:53,040 --> 01:30:59,600
happens with SCVI. Um with a caveat that

2532
01:30:56,880 --> 01:31:01,360
at some point with with model size are

2533
01:30:59,600 --> 01:31:03,199
saturation still kind of occurs with

2534
01:31:01,360 --> 01:31:05,199
this idea that like once I go from like

2535
01:31:03,199 --> 01:31:07,920
two to four, I don't really see any more

2536
01:31:05,199 --> 01:31:10,480
like real benefit from moving like too

2537
01:31:07,920 --> 01:31:12,239
large of a scale. So there are a few

2538
01:31:10,480 --> 01:31:14,719
questions that one could think about

2539
01:31:12,239 --> 01:31:16,639
going from here. The first is what David

2540
01:31:14,719 --> 01:31:18,480
and and just talked about before with

2541
01:31:16,639 --> 01:31:20,719
the work with Seb, right? The idea is

2542
01:31:18,480 --> 01:31:23,199
like maybe if I think about biological

2543
01:31:20,719 --> 01:31:24,639
priors or biological architectures, that

2544
01:31:23,199 --> 01:31:25,920
could be one case. So for those who are

2545
01:31:24,639 --> 01:31:27,600
a little bit new that weren't here

2546
01:31:25,920 --> 01:31:29,199
before, you know, David talked about

2547
01:31:27,600 --> 01:31:30,880
earlier about this idea of like if I

2548
01:31:29,199 --> 01:31:32,239
move out of distribution, at least for

2549
01:31:30,880 --> 01:31:33,840
the cell type annotation setting, you

2550
01:31:32,239 --> 01:31:35,280
see this drop off in performance. And

2551
01:31:33,840 --> 01:31:36,719
one thing that I could think about in

2552
01:31:35,280 --> 01:31:39,360
terms of recovering that performance is

2553
01:31:36,719 --> 01:31:41,360
having more of like a biologically uh uh

2554
01:31:39,360 --> 01:31:44,320
driven training opt uh objective

2555
01:31:41,360 --> 01:31:45,440
function, right? Um, and so this idea of

2556
01:31:44,320 --> 01:31:48,639
moving from just think about cross

2557
01:31:45,440 --> 01:31:50,239
entropy to something that's more uh um

2558
01:31:48,639 --> 01:31:51,600
uh you know this like treel like

2559
01:31:50,239 --> 01:31:53,440
structure where I think about this

2560
01:31:51,600 --> 01:31:55,199
hierarchal cross entropy might be able

2561
01:31:53,440 --> 01:31:56,400
to be a solution to improving model

2562
01:31:55,199 --> 01:31:58,480
performance across all of these

2563
01:31:56,400 --> 01:32:00,719
different methods right and one thing

2564
01:31:58,480 --> 01:32:02,000
that uh that I talked about was this

2565
01:32:00,719 --> 01:32:03,760
idea like you know if I can see this

2566
01:32:02,000 --> 01:32:06,480
nice improvement across the cell types

2567
01:32:03,760 --> 01:32:08,560
where does that improvement come from um

2568
01:32:06,480 --> 01:32:10,080
and one thing I want to highlight here

2569
01:32:08,560 --> 01:32:11,920
is it really kind of comes from this

2570
01:32:10,080 --> 01:32:13,360
idea of like connectedness across is

2571
01:32:11,920 --> 01:32:14,400
different true right so one thing I

2572
01:32:13,360 --> 01:32:15,920
thought I didn't talk about was this

2573
01:32:14,400 --> 01:32:18,000
idea that like you know where you see

2574
01:32:15,920 --> 01:32:19,600
drop offs in performance tend to be

2575
01:32:18,000 --> 01:32:21,440
these places where I have little

2576
01:32:19,600 --> 01:32:22,880
information about the connectedness

2577
01:32:21,440 --> 01:32:24,159
across the different cell types I think

2578
01:32:22,880 --> 01:32:26,000
someone had asked this earlier about

2579
01:32:24,159 --> 01:32:27,280
where I see this massive drop off a lot

2580
01:32:26,000 --> 01:32:29,679
of times it happens where I have these

2581
01:32:27,280 --> 01:32:31,360
isolated points so there's this one

2582
01:32:29,679 --> 01:32:32,159
question of like how do I recover that

2583
01:32:31,360 --> 01:32:34,000
well where there could be some

2584
01:32:32,159 --> 01:32:35,520
architectural someone gave a really good

2585
01:32:34,000 --> 01:32:38,159
suggestion about like a treel like

2586
01:32:35,520 --> 01:32:39,600
method um when I think about uh even

2587
01:32:38,159 --> 01:32:42,480
building these models from the very

2588
01:32:39,600 --> 01:32:43,679
get-go but But one thing that um at

2589
01:32:42,480 --> 01:32:44,560
least like when Pete and I looked at

2590
01:32:43,679 --> 01:32:46,159
this, the one thing that we thought

2591
01:32:44,560 --> 01:32:47,360
about was this idea of like well the

2592
01:32:46,159 --> 01:32:48,880
other thing that really is a cool

2593
01:32:47,360 --> 01:32:50,639
opportunity here is like the more data

2594
01:32:48,880 --> 01:32:52,320
we collect so that this tree become this

2595
01:32:50,639 --> 01:32:53,760
tree structure becomes more connected.

2596
01:32:52,320 --> 01:32:55,199
So I know how different cell types are

2597
01:32:53,760 --> 01:32:56,800
related to each other, the better these

2598
01:32:55,199 --> 01:32:58,719
models can also get. There's also like a

2599
01:32:56,800 --> 01:33:00,239
data driven question here as well which

2600
01:32:58,719 --> 01:33:02,400
is like data can also start to think

2601
01:33:00,239 --> 01:33:03,440
about improving these different models.

2602
01:33:02,400 --> 01:33:05,760
One thing I think is very

2603
01:33:03,440 --> 01:33:08,639
underappreciated about like s like uh

2604
01:33:05,760 --> 01:33:10,719
chat GPT is this training training

2605
01:33:08,639 --> 01:33:13,199
corpus, right? like everyone kind of has

2606
01:33:10,719 --> 01:33:14,400
a lot of the same architectures now. We

2607
01:33:13,199 --> 01:33:15,600
all know like what architecture are

2608
01:33:14,400 --> 01:33:18,000
available. The one thing that's kind of

2609
01:33:15,600 --> 01:33:19,440
like a secret sauce is this idea of what

2610
01:33:18,000 --> 01:33:20,880
training data sets go in different

2611
01:33:19,440 --> 01:33:23,360
models. And that tends to actually be a

2612
01:33:20,880 --> 01:33:25,199
big separator for a lot of data sets.

2613
01:33:23,360 --> 01:33:28,080
One thing that people think quite a bit

2614
01:33:25,199 --> 01:33:30,320
about in in language models is you want

2615
01:33:28,080 --> 01:33:33,280
data in your training corpus that are

2616
01:33:30,320 --> 01:33:34,960
both related but also have unique

2617
01:33:33,280 --> 01:33:36,800
information so that your model can kind

2618
01:33:34,960 --> 01:33:39,840
of teslate across like these different

2619
01:33:36,800 --> 01:33:42,159
uh uh uh types of knowledge and this

2620
01:33:39,840 --> 01:33:43,920
idea of how you upweight and downweight

2621
01:33:42,159 --> 01:33:46,320
certain resources so that a model can

2622
01:33:43,920 --> 01:33:48,000
then learn and then uh uh generalize out

2623
01:33:46,320 --> 01:33:49,760
of distribution. That's like a just a

2624
01:33:48,000 --> 01:33:50,880
true like AI is a science like this is a

2625
01:33:49,760 --> 01:33:52,800
true science that kind of goes into a

2626
01:33:50,880 --> 01:33:56,000
lot of these methods. So, if you take

2627
01:33:52,800 --> 01:33:57,440
that that idea, you can think about,

2628
01:33:56,000 --> 01:33:59,120
well, what do I need to maybe think

2629
01:33:57,440 --> 01:34:00,639
about when it comes to to training

2630
01:33:59,120 --> 01:34:04,320
corpuses? And and we thought about this

2631
01:34:00,639 --> 01:34:07,840
last summer uh with this student um uh

2632
01:34:04,320 --> 01:34:10,239
Aay who who interned with us uh also uh

2633
01:34:07,840 --> 01:34:13,760
um from the area. We thought about can

2634
01:34:10,239 --> 01:34:15,199
we leverage like biological uh knowledge

2635
01:34:13,760 --> 01:34:17,360
to really think about how to build

2636
01:34:15,199 --> 01:34:18,880
training corpuses where I have it's not

2637
01:34:17,360 --> 01:34:20,560
about the number of cells, the

2638
01:34:18,880 --> 01:34:24,159
information per cell. So what you want

2639
01:34:20,560 --> 01:34:26,239
in your data set are cells that have uh

2640
01:34:24,159 --> 01:34:27,920
uh large sources of information per

2641
01:34:26,239 --> 01:34:29,120
cell. Like a bit of information per cell

2642
01:34:27,920 --> 01:34:31,040
is the measure that we should be

2643
01:34:29,120 --> 01:34:32,560
thinking about. And so as one example of

2644
01:34:31,040 --> 01:34:34,080
this to kind of show how we might build

2645
01:34:32,560 --> 01:34:36,000
really good training corpuses, we took

2646
01:34:34,080 --> 01:34:38,400
this really big example. It's a really

2647
01:34:36,000 --> 01:34:40,719
baby example where we said if I took a

2648
01:34:38,400 --> 01:34:42,239
data set that was trained on just blood

2649
01:34:40,719 --> 01:34:44,320
cells

2650
01:34:42,239 --> 01:34:46,000
um and then I took another uh and I

2651
01:34:44,320 --> 01:34:48,159
trained a model on that and I took

2652
01:34:46,000 --> 01:34:49,920
another model that was trained on half

2653
01:34:48,159 --> 01:34:51,840
of these blood cells but also half of

2654
01:34:49,920 --> 01:34:54,080
this uh data set coming from this uh

2655
01:34:51,840 --> 01:34:56,560
transcription factor at so the same size

2656
01:34:54,080 --> 01:34:58,080
of data but I just split in terms of how

2657
01:34:56,560 --> 01:35:00,000
much data is represented across these

2658
01:34:58,080 --> 01:35:02,080
two groups. How well do these models

2659
01:35:00,000 --> 01:35:04,400
train or how well models perform out of

2660
01:35:02,080 --> 01:35:06,719
distribution. So let's do a very simple

2661
01:35:04,400 --> 01:35:08,080
example. If I want to predict if I take

2662
01:35:06,719 --> 01:35:10,239
these two models and I say let's now

2663
01:35:08,080 --> 01:35:11,920
predict the expression of blood cells

2664
01:35:10,239 --> 01:35:14,560
these models both should perform kind of

2665
01:35:11,920 --> 01:35:16,800
the same right so the x ax the y axis

2666
01:35:14,560 --> 01:35:19,040
you're seeing here is reconstruction uh

2667
01:35:16,800 --> 01:35:20,560
uh correlation these r squared values

2668
01:35:19,040 --> 01:35:22,400
again we have the blood model and the

2669
01:35:20,560 --> 01:35:24,080
blood plus tf model train on different

2670
01:35:22,400 --> 01:35:25,520
data sets but kind of performed exactly

2671
01:35:24,080 --> 01:35:28,960
the same but that's because this this

2672
01:35:25,520 --> 01:35:30,560
data is actually in distribution right

2673
01:35:28,960 --> 01:35:32,800
now I can ask this question all right

2674
01:35:30,560 --> 01:35:34,560
what happens if I train on neurons so a

2675
01:35:32,800 --> 01:35:36,239
set of data that this model has not seen

2676
01:35:34,560 --> 01:35:37,360
out different cell type that's far out

2677
01:35:36,239 --> 01:35:39,040
distribution how well this model

2678
01:35:37,360 --> 01:35:41,360
performed and you get something that

2679
01:35:39,040 --> 01:35:43,679
kind of looks like this. Now, two things

2680
01:35:41,360 --> 01:35:45,760
to kind of recognize. The R squar is bad

2681
01:35:43,679 --> 01:35:47,199
for both models, but you can see that

2682
01:35:45,760 --> 01:35:49,360
magnitude of difference that I kind of

2683
01:35:47,199 --> 01:35:51,520
get as almost this like value ad that I

2684
01:35:49,360 --> 01:35:53,520
have from having a set of diverse data

2685
01:35:51,520 --> 01:35:55,199
again very small but of the same size

2686
01:35:53,520 --> 01:35:58,159
versus just having something of all one

2687
01:35:55,199 --> 01:35:59,760
type, right? And so they started asking

2688
01:35:58,159 --> 01:36:02,080
us like, you know, what if you were able

2689
01:35:59,760 --> 01:36:04,400
to now build data sets where I knew I

2690
01:36:02,080 --> 01:36:06,400
was kind of like information poor and I

2691
01:36:04,400 --> 01:36:08,480
started to build data sets that now have

2692
01:36:06,400 --> 01:36:10,400
have extreme value. again not thinking

2693
01:36:08,480 --> 01:36:12,400
about size but a bit of information per

2694
01:36:10,400 --> 01:36:14,000
cell. So you might ask like how well

2695
01:36:12,400 --> 01:36:15,440
does this does this kind of finding

2696
01:36:14,000 --> 01:36:17,600
generalize out of distribution and it

2697
01:36:15,440 --> 01:36:19,679
actually generalizes quite well this

2698
01:36:17,600 --> 01:36:21,199
idea like whether I trained and tested

2699
01:36:19,679 --> 01:36:23,280
uh those data sets on like something

2700
01:36:21,199 --> 01:36:25,920
that came from the heart or the kidney

2701
01:36:23,280 --> 01:36:27,520
or or again the set of neurons having

2702
01:36:25,920 --> 01:36:30,400
this like data sets that are more

2703
01:36:27,520 --> 01:36:33,600
diverse against effectively these TF

2704
01:36:30,400 --> 01:36:35,280
atlases tend to express data uh express

2705
01:36:33,600 --> 01:36:36,800
uh cells that have that just express

2706
01:36:35,280 --> 01:36:38,080
different types of genes. So we can

2707
01:36:36,800 --> 01:36:40,960
think about this as like a proxy for

2708
01:36:38,080 --> 01:36:43,520
more information, right? That value add

2709
01:36:40,960 --> 01:36:45,360
of having that TF atlas is is quite nice

2710
01:36:43,520 --> 01:36:49,440
and you can kind of do um this was

2711
01:36:45,360 --> 01:36:51,199
trained with a linear uh um decoder. So

2712
01:36:49,440 --> 01:36:53,440
you can actually go back to the model

2713
01:36:51,199 --> 01:36:55,679
and ask are there parts of the latent

2714
01:36:53,440 --> 01:36:58,000
space that I just can't reconstruct with

2715
01:36:55,679 --> 01:36:59,280
a neuron uh in these neurons that I can

2716
01:36:58,000 --> 01:37:00,960
just reconstruct with these blood cells.

2717
01:36:59,280 --> 01:37:02,800
And there's actually a lot of it where

2718
01:37:00,960 --> 01:37:04,960
the transcription factor atlas kind of

2719
01:37:02,800 --> 01:37:06,719
has high explanability that is lowly

2720
01:37:04,960 --> 01:37:08,239
explained by just this blood model. And

2721
01:37:06,719 --> 01:37:09,760
so you can kind of start to get this

2722
01:37:08,239 --> 01:37:12,159
notion of like where I should start to

2723
01:37:09,760 --> 01:37:14,239
think about different things. Now to tie

2724
01:37:12,159 --> 01:37:15,119
this all back to Xvivbo actually like

2725
01:37:14,239 --> 01:37:16,320
this is what the kind of stuff that

2726
01:37:15,119 --> 01:37:17,520
we're thinking about. So you might ask

2727
01:37:16,320 --> 01:37:19,600
this question like can I start to

2728
01:37:17,520 --> 01:37:21,280
engineer state heterogeneity for cancer

2729
01:37:19,600 --> 01:37:25,040
knowing these value ads that you get

2730
01:37:21,280 --> 01:37:27,199
from data for um uh for AI models and

2731
01:37:25,040 --> 01:37:29,280
the answer is that you that you can. So

2732
01:37:27,199 --> 01:37:30,239
you know what we're doing in in XDivo is

2733
01:37:29,280 --> 01:37:31,520
doing these kind of like stateto

2734
01:37:30,239 --> 01:37:33,760
function mapping ideas where we're kind

2735
01:37:31,520 --> 01:37:35,119
of engineering heterogeneity right this

2736
01:37:33,760 --> 01:37:36,880
idea of like you know we're taking these

2737
01:37:35,119 --> 01:37:38,239
like transcription factor libraries

2738
01:37:36,880 --> 01:37:40,080
across different cell lines screening

2739
01:37:38,239 --> 01:37:41,840
across different perturbations assessing

2740
01:37:40,080 --> 01:37:43,440
things like fitness and we're trying to

2741
01:37:41,840 --> 01:37:44,719
identify both common and tissue specific

2742
01:37:43,440 --> 01:37:46,800
cell states and how they map to

2743
01:37:44,719 --> 01:37:50,159
different perturbations. Right? And so

2744
01:37:46,800 --> 01:37:51,760
we kind of have this like nice uh uh uh

2745
01:37:50,159 --> 01:37:54,159
uh different axis if you will where you

2746
01:37:51,760 --> 01:37:56,239
think about um as we traverses these

2747
01:37:54,159 --> 01:37:57,760
different planes of engineered hogenity

2748
01:37:56,239 --> 01:37:59,040
across different hallmark perturbations

2749
01:37:57,760 --> 01:38:01,840
and how this might scale across

2750
01:37:59,040 --> 01:38:05,199
different tissues. Now if you if you're

2751
01:38:01,840 --> 01:38:06,639
like if you're looking at this um you

2752
01:38:05,199 --> 01:38:08,400
know we want to build these AI models

2753
01:38:06,639 --> 01:38:09,600
that kind of learn across all these

2754
01:38:08,400 --> 01:38:12,159
different data. If you're looking at

2755
01:38:09,600 --> 01:38:14,000
this, the ideal case um when we first

2756
01:38:12,159 --> 01:38:16,400
started thinking about Xvivo and first

2757
01:38:14,000 --> 01:38:18,800
started pitching this um if you are you

2758
01:38:16,400 --> 01:38:20,080
know a leader at at uh at Microsoft

2759
01:38:18,800 --> 01:38:23,280
looking to support this or someone you

2760
01:38:20,080 --> 01:38:25,840
might say like do you have to build data

2761
01:38:23,280 --> 01:38:27,840
that that basically for every cell

2762
01:38:25,840 --> 01:38:30,159
across every plane here? Do I have to

2763
01:38:27,840 --> 01:38:33,360
have a data set for everything here?

2764
01:38:30,159 --> 01:38:34,880
That seems like a lot of money. Um is

2765
01:38:33,360 --> 01:38:37,440
that the ideal state that we're going to

2766
01:38:34,880 --> 01:38:39,840
that we're going to do? Interestingly

2767
01:38:37,440 --> 01:38:41,119
enough, that's actually not exactly what

2768
01:38:39,840 --> 01:38:43,440
we've learned is that that's not exactly

2769
01:38:41,119 --> 01:38:47,040
what you need. So, one one key finding

2770
01:38:43,440 --> 01:38:50,080
from AJ's paper was that you can learn

2771
01:38:47,040 --> 01:38:51,679
parts about one side of this plane and

2772
01:38:50,080 --> 01:38:54,000
that'll give you a lot of information

2773
01:38:51,679 --> 01:38:56,239
about another. Right? So here here's the

2774
01:38:54,000 --> 01:38:58,000
full table of all of AJ's experiments

2775
01:38:56,239 --> 01:39:00,159
where he took these different models

2776
01:38:58,000 --> 01:39:03,600
trained all on either using like a blood

2777
01:39:00,159 --> 01:39:05,360
baseline model and then uh thought about

2778
01:39:03,600 --> 01:39:08,159
uh if I train a model just on blood or

2779
01:39:05,360 --> 01:39:10,400
just on bone marrow or can bone cancer

2780
01:39:08,159 --> 01:39:12,560
perturbed seek and TF atlas but then I

2781
01:39:10,400 --> 01:39:14,000
also combine them. So I trained it I

2782
01:39:12,560 --> 01:39:16,880
combined these different data sets each

2783
01:39:14,000 --> 01:39:18,960
with blood. how well does it do in in in

2784
01:39:16,880 --> 01:39:21,520
testing the uh generating the expression

2785
01:39:18,960 --> 01:39:23,280
for things coming from neurons uh uh uh

2786
01:39:21,520 --> 01:39:24,960
different cancers uh bone marrow and

2787
01:39:23,280 --> 01:39:27,600
also in blood. And so what you're seeing

2788
01:39:24,960 --> 01:39:29,280
here is uh the relative logful change of

2789
01:39:27,600 --> 01:39:31,600
each of these models with respect to

2790
01:39:29,280 --> 01:39:33,040
this blood model, right? And for a lot

2791
01:39:31,600 --> 01:39:35,199
of these you get this really interesting

2792
01:39:33,040 --> 01:39:37,440
point where you know if I train on just

2793
01:39:35,199 --> 01:39:38,719
blood and I add other data sets like

2794
01:39:37,440 --> 01:39:40,639
they're not actually going to be better

2795
01:39:38,719 --> 01:39:41,920
than me just doing this distribution.

2796
01:39:40,639 --> 01:39:43,920
And we also got some very interesting

2797
01:39:41,920 --> 01:39:45,199
ones which are like if I train on uh

2798
01:39:43,920 --> 01:39:46,719
blood and I want to test on certain

2799
01:39:45,199 --> 01:39:49,199
cancers. This is healthy blood I train

2800
01:39:46,719 --> 01:39:51,600
on uh and I test on cancers. I actually

2801
01:39:49,199 --> 01:39:53,199
do kind of well with just the blood on

2802
01:39:51,600 --> 01:39:54,159
its own. And then there are some cases

2803
01:39:53,199 --> 01:39:55,520
where I'm just totally out of

2804
01:39:54,159 --> 01:39:57,679
distribution where like the blood model

2805
01:39:55,520 --> 01:40:00,000
has no shot and I have to add a like

2806
01:39:57,679 --> 01:40:02,960
unique data sets in order to improve,

2807
01:40:00,000 --> 01:40:04,800
right? And so you you can take uh

2808
01:40:02,960 --> 01:40:06,639
settings from this with coupled with the

2809
01:40:04,800 --> 01:40:08,480
idea that we can actually like engineer

2810
01:40:06,639 --> 01:40:10,320
representations of of models to

2811
01:40:08,480 --> 01:40:12,000
represent certain cancer models where

2812
01:40:10,320 --> 01:40:13,920
you know the transcription factor idea

2813
01:40:12,000 --> 01:40:15,440
was this idea like I can take these uh

2814
01:40:13,920 --> 01:40:18,320
orphs and kind of overexpress certain

2815
01:40:15,440 --> 01:40:20,880
transcription factors to to basically

2816
01:40:18,320 --> 01:40:22,800
engineer uh uh cells that express a

2817
01:40:20,880 --> 01:40:25,840
certain signature of a state that I have

2818
01:40:22,800 --> 01:40:27,360
desired. And we can do this uh across,

2819
01:40:25,840 --> 01:40:29,040
you know, uh uh many different

2820
01:40:27,360 --> 01:40:30,800
transcription factors and have this idea

2821
01:40:29,040 --> 01:40:32,800
of like how close is a given

2822
01:40:30,800 --> 01:40:35,280
transcription factor getting me to a a

2823
01:40:32,800 --> 01:40:36,719
certain phenotype of interest. And you

2824
01:40:35,280 --> 01:40:39,679
can couple that with something that we

2825
01:40:36,719 --> 01:40:41,360
that we've done with AJ's work. So if I

2826
01:40:39,679 --> 01:40:45,119
go back, you know, this this looks like

2827
01:40:41,360 --> 01:40:46,239
a scary uh uh uh uh endeavor where we

2828
01:40:45,119 --> 01:40:49,440
have to do a lot of different

2829
01:40:46,239 --> 01:40:51,679
experiments and I and I don't pipet um

2830
01:40:49,440 --> 01:40:53,360
and so uh so how do we actually get

2831
01:40:51,679 --> 01:40:54,960
information from here? But what we

2832
01:40:53,360 --> 01:40:56,639
learned from AJ's work is that you know

2833
01:40:54,960 --> 01:40:58,000
there are a lot of cases where I might

2834
01:40:56,639 --> 01:40:59,520
load something about one sort of

2835
01:40:58,000 --> 01:41:01,280
perturbation in a certain state and it

2836
01:40:59,520 --> 01:41:03,840
actually might give me information free

2837
01:41:01,280 --> 01:41:05,440
about something in another place. And so

2838
01:41:03,840 --> 01:41:09,199
if we can kind of learn how to traverse

2839
01:41:05,440 --> 01:41:10,880
this plot uh in a in a uh you know more

2840
01:41:09,199 --> 01:41:12,000
computationally uh nice way which is

2841
01:41:10,880 --> 01:41:13,679
stuff that we're doing now thinking

2842
01:41:12,000 --> 01:41:15,520
about how to actually quantify where I

2843
01:41:13,679 --> 01:41:17,920
might be information for you know we can

2844
01:41:15,520 --> 01:41:19,679
do this in a much more efficient way and

2845
01:41:17,920 --> 01:41:21,679
effectively that's what XVivo's whole

2846
01:41:19,679 --> 01:41:23,199
thing is about um kind of tie this whole

2847
01:41:21,679 --> 01:41:24,320
thing up together you know we're

2848
01:41:23,199 --> 01:41:27,520
thinking about how to build these

2849
01:41:24,320 --> 01:41:29,040
different um uh uh maps uh create new

2850
01:41:27,520 --> 01:41:30,320
data and the really important thing that

2851
01:41:29,040 --> 01:41:31,840
we're doing in our group is thinking

2852
01:41:30,320 --> 01:41:33,600
about not using all of it because I

2853
01:41:31,840 --> 01:41:35,679
don't actually need all of it triaging

2854
01:41:33,600 --> 01:41:37,600
the things that just help us the best,

2855
01:41:35,679 --> 01:41:39,119
train models, learn about them, and

2856
01:41:37,600 --> 01:41:40,719
interpret them. And that should lead us

2857
01:41:39,119 --> 01:41:42,400
to our next best experiment, and we can

2858
01:41:40,719 --> 01:41:44,239
continue this cycle all with this idea

2859
01:41:42,400 --> 01:41:46,960
of eventually trying to think about uh

2860
01:41:44,239 --> 01:41:48,320
state-based therapeutics. Um, so to wrap

2861
01:41:46,960 --> 01:41:50,000
up in the last couple minutes, I'm happy

2862
01:41:48,320 --> 01:41:51,440
to take all the questions that you have.

2863
01:41:50,000 --> 01:41:53,920
Um, you know, we have these two

2864
01:41:51,440 --> 01:41:55,440
different aims. Um, really what we're

2865
01:41:53,920 --> 01:41:56,960
doing in the first aim is really how to

2866
01:41:55,440 --> 01:41:59,280
learn and optimize in silicone and

2867
01:41:56,960 --> 01:42:00,480
engineer corresponding XV models. And

2868
01:41:59,280 --> 01:42:02,800
the second is really thinking about how

2869
01:42:00,480 --> 01:42:04,400
to build out these uh new states of uh

2870
01:42:02,800 --> 01:42:07,679
function data sets to learn effective

2871
01:42:04,400 --> 01:42:09,360
foundation models um in the future. Um

2872
01:42:07,679 --> 01:42:10,960
so with that um there are a lot of

2873
01:42:09,360 --> 01:42:12,639
people that are involved. I'm sure I

2874
01:42:10,960 --> 01:42:14,560
don't have all the names that I should

2875
01:42:12,639 --> 01:42:16,080
have on here and I apologize for that.

2876
01:42:14,560 --> 01:42:18,480
Um but people have been nice enough to

2877
01:42:16,080 --> 01:42:20,239
give us money and support and I'm happy

2878
01:42:18,480 --> 01:42:23,239
to take any questions that you have.

2879
01:42:20,239 --> 01:42:23,239
Thanks.

2880
01:42:25,440 --> 01:42:28,960
Oh, and here are some references in case

2881
01:42:26,880 --> 01:42:30,800
you want to. Yeah,

2882
01:42:28,960 --> 01:42:32,400
>> thanks for the great talk. Uh, so I had

2883
01:42:30,800 --> 01:42:34,480
a question about your batch effect

2884
01:42:32,400 --> 01:42:37,280
correct uh correction evaluation with

2885
01:42:34,480 --> 01:42:39,280
the umaps that you were showing. Um, so

2886
01:42:37,280 --> 01:42:40,800
I was wondering if you've looked at

2887
01:42:39,280 --> 01:42:42,560
embeddings from different layers, but

2888
01:42:40,800 --> 01:42:44,960
you so you could imagine that certain

2889
01:42:42,560 --> 01:42:46,880
layers learn things about bats, certain

2890
01:42:44,960 --> 01:42:48,320
layers learn about cell type. Um, so

2891
01:42:46,880 --> 01:42:50,639
yeah, I'm curious if you've

2892
01:42:48,320 --> 01:42:52,480
>> Yeah, we did that with gene former. Um,

2893
01:42:50,639 --> 01:42:54,080
so if on the gene former plot, you will

2894
01:42:52,480 --> 01:42:56,159
see this thing that has like gene

2895
01:42:54,080 --> 01:42:57,679
former-6L that looks like that that

2896
01:42:56,159 --> 01:42:59,360
particular layer. We did that with other

2897
01:42:57,679 --> 01:43:00,800
layers and saw very similar type of

2898
01:42:59,360 --> 01:43:02,560
results. We didn't do that for all

2899
01:43:00,800 --> 01:43:04,960
different models, but you're right,

2900
01:43:02,560 --> 01:43:06,480
there could be questions where certain

2901
01:43:04,960 --> 01:43:07,440
layers correct for certain things or are

2902
01:43:06,480 --> 01:43:12,080
better at certain things. That's a

2903
01:43:07,440 --> 01:43:14,000
that's a really really good caveat.

2904
01:43:12,080 --> 01:43:14,400
>> Some of the questions we had online.

2905
01:43:14,000 --> 01:43:17,840
>> Yeah.

2906
01:43:14,400 --> 01:43:20,320
>> Um, so one question we had was um from

2907
01:43:17,840 --> 01:43:22,639
uh Stephen Fleming. What do we mean by

2908
01:43:20,320 --> 01:43:25,119
perturbation effect prediction using

2909
01:43:22,639 --> 01:43:26,320
SCVI? I was not aware that SCBI did

2910
01:43:25,119 --> 01:43:28,159
perturbation effect prediction.

2911
01:43:26,320 --> 01:43:30,000
>> Doesn't it's fine-tuned. So we take the

2912
01:43:28,159 --> 01:43:32,320
embeddings from SCVI and train a model

2913
01:43:30,000 --> 01:43:34,880
on top of it. And then uh yeah.

2914
01:43:32,320 --> 01:43:36,239
>> All right. Thank you.

2915
01:43:34,880 --> 01:43:39,119
>> Hi Lauren. Uh thanks a lot for the

2916
01:43:36,239 --> 01:43:41,360
wonderful work and uh your team shows

2917
01:43:39,119 --> 01:43:43,679
that uh the data saturates at 1% for

2918
01:43:41,360 --> 01:43:46,000
these foundation models and uh showing

2919
01:43:43,679 --> 01:43:48,560
that the gas is enough. But I I want to

2920
01:43:46,000 --> 01:43:51,280
hear your insights on this is like uh is

2921
01:43:48,560 --> 01:43:53,199
the car actually designed to take this

2922
01:43:51,280 --> 01:43:55,040
type of gas pretty well. What if we are

2923
01:43:53,199 --> 01:43:57,040
pouring this gas into a Tesla while a

2924
01:43:55,040 --> 01:43:59,600
U-Haul truck or a Ferrari can actually

2925
01:43:57,040 --> 01:44:01,760
do the work? And because actually the

2926
01:43:59,600 --> 01:44:03,520
scaling law probably exists but the

2927
01:44:01,760 --> 01:44:06,239
current this transformer-based

2928
01:44:03,520 --> 01:44:08,400
foundation model was designed poorly not

2929
01:44:06,239 --> 01:44:11,440
even optimal to take this type of single

2930
01:44:08,400 --> 01:44:14,719
cell RNC data right bing ranking

2931
01:44:11,440 --> 01:44:17,600
discretiz discretizing the originally

2932
01:44:14,719 --> 01:44:19,040
sparse data further so uh what do you

2933
01:44:17,600 --> 01:44:20,880
think it's like if we find another

2934
01:44:19,040 --> 01:44:23,840
better architecture maybe we still can

2935
01:44:20,880 --> 01:44:26,239
scale better and considering that GPD

2936
01:44:23,840 --> 01:44:28,880
actually the miracle happens after 3.5

2937
01:44:26,239 --> 01:44:31,760
after taking million of parameters.

2938
01:44:28,880 --> 01:44:33,920
>> Yeah. Okay. I have two two like thoughts

2939
01:44:31,760 --> 01:44:35,920
here. The first is yes. Is a transformer

2940
01:44:33,920 --> 01:44:37,280
the best architecture? Um sorry if

2941
01:44:35,920 --> 01:44:38,159
anyone loves transformers. I'm not sure

2942
01:44:37,280 --> 01:44:39,440
if transformers are the best

2943
01:44:38,159 --> 01:44:40,400
architecture for a single cell data.

2944
01:44:39,440 --> 01:44:42,560
Actually there have been there's been

2945
01:44:40,400 --> 01:44:43,760
work on this floor I think from people

2946
01:44:42,560 --> 01:44:46,000
who have thought about alternative

2947
01:44:43,760 --> 01:44:47,920
architectures that could be uh better

2948
01:44:46,000 --> 01:44:48,800
and have shown like really promising

2949
01:44:47,920 --> 01:44:50,080
performance from that. I think

2950
01:44:48,800 --> 01:44:52,239
Caroline's group has thought a lot about

2951
01:44:50,080 --> 01:44:54,080
this this question. Um, the second thing

2952
01:44:52,239 --> 01:44:56,800
that I've thought about a lot is like

2953
01:44:54,080 --> 01:45:00,239
are these tasks too simple in the

2954
01:44:56,800 --> 01:45:01,679
setting of like are we saturating a lot

2955
01:45:00,239 --> 01:45:04,480
just because we're not actually take

2956
01:45:01,679 --> 01:45:06,560
advantage of we're not we're we're not

2957
01:45:04,480 --> 01:45:08,480
posing questions or tasks that are hard

2958
01:45:06,560 --> 01:45:10,880
enough. Like there's a there's a there's

2959
01:45:08,480 --> 01:45:13,360
a task complexity idea here that like

2960
01:45:10,880 --> 01:45:16,880
with the right complex enough task,

2961
01:45:13,360 --> 01:45:19,119
you'll hit something that now activates

2962
01:45:16,880 --> 01:45:21,360
needing a very complex model. And cell

2963
01:45:19,119 --> 01:45:24,719
type annotation or some of these other

2964
01:45:21,360 --> 01:45:27,119
questions just aren't that. And so we're

2965
01:45:24,719 --> 01:45:29,119
like not really aligning task with like

2966
01:45:27,119 --> 01:45:30,320
how complex the models are. And so

2967
01:45:29,119 --> 01:45:31,840
there's a question of like we had an

2968
01:45:30,320 --> 01:45:33,840
intern think about this last sum this

2969
01:45:31,840 --> 01:45:36,239
past summer which is like can I start to

2970
01:45:33,840 --> 01:45:38,000
think about task complexity and should I

2971
01:45:36,239 --> 01:45:40,639
think about scaling laws with respect to

2972
01:45:38,000 --> 01:45:41,760
like to that um and I don't I think that

2973
01:45:40,639 --> 01:45:44,800
might be a I think that's a really

2974
01:45:41,760 --> 01:45:46,560
underexplored um area of like can you

2975
01:45:44,800 --> 01:45:48,880
align with more biologically difficult

2976
01:45:46,560 --> 01:45:51,679
things um yeah

2977
01:45:48,880 --> 01:45:51,679
>> thank you so much

2978
01:45:52,159 --> 01:45:54,880
>> I think that might have addressed some

2979
01:45:53,520 --> 01:45:58,480
of the other questions we had online

2980
01:45:54,880 --> 01:46:02,080
recently so one

2981
01:45:58,480 --> 01:46:03,199
Uh one was uh from Sam Zimmerman um

2982
01:46:02,080 --> 01:46:04,880
essentially asking you know if these

2983
01:46:03,199 --> 01:46:06,320
models did better on their tasks would

2984
01:46:04,880 --> 01:46:08,000
you see that the models perform better

2985
01:46:06,320 --> 01:46:10,639
the more data it has? Do you expect to

2986
01:46:08,000 --> 01:46:13,840
see this an improved data scaling when

2987
01:46:10,639 --> 01:46:15,600
you if if you were to have a um a more

2988
01:46:13,840 --> 01:46:18,320
complex task? And a related question

2989
01:46:15,600 --> 01:46:19,440
from uh Brian Plowski, would it be fair

2990
01:46:18,320 --> 01:46:20,560
to say that this is another way of

2991
01:46:19,440 --> 01:46:22,800
confirming that these models don't

2992
01:46:20,560 --> 01:46:24,560
perform better than the mean? Or for a

2993
01:46:22,800 --> 01:46:26,239
model that is actually better than uh

2994
01:46:24,560 --> 01:46:27,440
than the mean at perturbation

2995
01:46:26,239 --> 01:46:28,800
prediction, would you expect the same

2996
01:46:27,440 --> 01:46:31,440
type of saturation?

2997
01:46:28,800 --> 01:46:35,199
>> Yeah, I Okay, that's a good question. I

2998
01:46:31,440 --> 01:46:36,960
don't know about the mean model. um the

2999
01:46:35,199 --> 01:46:38,719
the no change model is probably as close

3000
01:46:36,960 --> 01:46:40,719
to that. Again I want to be I want to be

3001
01:46:38,719 --> 01:46:42,400
optimistic here and say like maybe this

3002
01:46:40,719 --> 01:46:46,400
that you can see something there have

3003
01:46:42,400 --> 01:46:48,000
been interesting so so um um Alain's

3004
01:46:46,400 --> 01:46:49,360
group at Harvard had this paper where

3005
01:46:48,000 --> 01:46:52,159
they show so two things I think are

3006
01:46:49,360 --> 01:46:54,560
interesting about scale of qual scale of

3007
01:46:52,159 --> 01:46:56,719
of data and and model scaling with

3008
01:46:54,560 --> 01:46:58,159
respect to that data is Alain's group

3009
01:46:56,719 --> 01:47:02,080
had a paper that showed that there was a

3010
01:46:58,159 --> 01:47:04,239
data squaling scaling uh uh feature with

3011
01:47:02,080 --> 01:47:05,760
respect to data quality and they kind of

3012
01:47:04,239 --> 01:47:07,520
had some measure of data quality and

3013
01:47:05,760 --> 01:47:09,119
showed that as data quality went up

3014
01:47:07,520 --> 01:47:11,280
according to the measure. You did some

3015
01:47:09,119 --> 01:47:14,960
you did see some sort of scaling law.

3016
01:47:11,280 --> 01:47:18,800
One uh underappreciated p uh figure that

3017
01:47:14,960 --> 01:47:20,800
I thought was in Fabian Ty's group uh

3018
01:47:18,800 --> 01:47:23,119
with uh Till Richard who interned with

3019
01:47:20,800 --> 01:47:25,280
me last summer. he thought about um he

3020
01:47:23,119 --> 01:47:27,119
has this paper called uh self-supervised

3021
01:47:25,280 --> 01:47:28,719
learning and there's an underrated

3022
01:47:27,119 --> 01:47:30,159
figure to me but I think a reviewer

3023
01:47:28,719 --> 01:47:31,840
asked him to put in and it's like this

3024
01:47:30,159 --> 01:47:33,840
really small panel but they show like

3025
01:47:31,840 --> 01:47:36,400
this scaling law with respect to donor

3026
01:47:33,840 --> 01:47:39,520
diversity that I think is like also kind

3027
01:47:36,400 --> 01:47:41,119
of an underrated thing this idea of like

3028
01:47:39,520 --> 01:47:43,760
moving up in scale and thinking about

3029
01:47:41,119 --> 01:47:45,600
diversity across donors whether just

3030
01:47:43,760 --> 01:47:47,119
like individual cells that you kind of

3031
01:47:45,600 --> 01:47:49,679
get across this thing might be a really

3032
01:47:47,119 --> 01:47:51,520
good feature to kind of index on um and

3033
01:47:49,679 --> 01:47:52,960
so yeah I think there's there paths

3034
01:47:51,520 --> 01:47:54,560
forward, but I don't know if we've done

3035
01:47:52,960 --> 01:47:58,679
enough research to be comprehensive

3036
01:47:54,560 --> 01:47:58,679
about it. Um, but yeah,

3037
01:48:06,480 --> 01:48:09,600
so I was wondering I wanted to follow up

3038
01:48:08,080 --> 01:48:12,719
on the question from the other

3039
01:48:09,600 --> 01:48:14,239
gentlemen. So, so, so one explanation

3040
01:48:12,719 --> 01:48:15,360
also could be that the data is somehow

3041
01:48:14,239 --> 01:48:17,280
redundant,

3042
01:48:15,360 --> 01:48:19,440
>> right? That the subsampling. But it

3043
01:48:17,280 --> 01:48:21,520
seems kind of that your answer to him is

3044
01:48:19,440 --> 01:48:23,440
it was suggestive of that you believe

3045
01:48:21,520 --> 01:48:25,520
that somehow we can't detect or we can't

3046
01:48:23,440 --> 01:48:28,960
really reap the benefits of this large

3047
01:48:25,520 --> 01:48:30,800
data. So c can we somehow be sure that

3048
01:48:28,960 --> 01:48:32,400
the data is not redundant that just 1%

3049
01:48:30,800 --> 01:48:33,760
is not containing all the information

3050
01:48:32,400 --> 01:48:35,600
that there is?

3051
01:48:33,760 --> 01:48:37,920
>> So okay yeah it's a great question. I

3052
01:48:35,600 --> 01:48:40,480
think so I think there is some level of

3053
01:48:37,920 --> 01:48:41,280
okay this is actually really nice. So

3054
01:48:40,480 --> 01:48:42,719
>> we need more data.

3055
01:48:41,280 --> 01:48:44,960
>> No we've been thinking about this a

3056
01:48:42,719 --> 01:48:46,800
little bit. Um I've been thinking about

3057
01:48:44,960 --> 01:48:49,679
this in a multimodal setting with with

3058
01:48:46,800 --> 01:48:53,040
till. Um so there have been some really

3059
01:48:49,679 --> 01:48:54,320
interesting work uh of people in u other

3060
01:48:53,040 --> 01:48:57,280
areas of machine learning thinking about

3061
01:48:54,320 --> 01:48:58,960
this idea of which data sets do you get

3062
01:48:57,280 --> 01:49:01,280
where you get like unique information

3063
01:48:58,960 --> 01:49:02,960
versus redundant versus synergistic. And

3064
01:49:01,280 --> 01:49:04,800
I do think there are methods for which

3065
01:49:02,960 --> 01:49:07,040
you can really start to think about how

3066
01:49:04,800 --> 01:49:08,239
to quantify that a little bit better. I

3067
01:49:07,040 --> 01:49:09,600
think what we've been doing thus far

3068
01:49:08,239 --> 01:49:11,679
have been using like these metadata

3069
01:49:09,600 --> 01:49:13,280
labels as a way to think about oh we've

3070
01:49:11,679 --> 01:49:14,639
seen enough of this. do I need to see

3071
01:49:13,280 --> 01:49:17,040
more of this? And I don't think that's

3072
01:49:14,639 --> 01:49:19,760
like the right scale to do that with. So

3073
01:49:17,040 --> 01:49:22,400
I do So I will say that the way that we

3074
01:49:19,760 --> 01:49:24,880
did the 1% down sampling may not be

3075
01:49:22,400 --> 01:49:26,639
reflective of this idea of like truly

3076
01:49:24,880 --> 01:49:28,400
trying to preserve like unique

3077
01:49:26,639 --> 01:49:30,159
information. It may not be as simple as

3078
01:49:28,400 --> 01:49:34,159
looking across clusters or looking

3079
01:49:30,159 --> 01:49:35,199
across um uh cell type labels. So it was

3080
01:49:34,159 --> 01:49:36,639
just in the way that we did the

3081
01:49:35,199 --> 01:49:41,280
downsampling. I do think there are other

3082
01:49:36,639 --> 01:49:43,199
ways to preserve uniqueness um uh or in

3083
01:49:41,280 --> 01:49:44,719
some cases like increasing like the

3084
01:49:43,199 --> 01:49:46,239
interaction so the synergy across

3085
01:49:44,719 --> 01:49:48,080
different data sets to improve model

3086
01:49:46,239 --> 01:49:49,520
performance we just didn't think about

3087
01:49:48,080 --> 01:49:50,960
it in this kind of framework this is

3088
01:49:49,520 --> 01:49:53,360
like more like recent work that we've

3089
01:49:50,960 --> 01:49:54,960
been thinking about but yeah um I I

3090
01:49:53,360 --> 01:49:57,280
think they're paths forward we just in

3091
01:49:54,960 --> 01:50:00,400
that work we didn't uh quantify it in

3092
01:49:57,280 --> 01:50:00,400
that way

3093
01:50:01,600 --> 01:50:06,239
>> I have another question from uh the zoom

3094
01:50:03,679 --> 01:50:07,920
chat uh we have from Amaro in a setting

3095
01:50:06,239 --> 01:50:10,080
where most perturbations don't do

3096
01:50:07,920 --> 01:50:13,119
anything. I think it's not possible to

3097
01:50:10,080 --> 01:50:15,760
learn uh a model that does well because

3098
01:50:13,119 --> 01:50:17,920
most of the gradients are computed from

3099
01:50:15,760 --> 01:50:20,239
changes in cells that are random or not

3100
01:50:17,920 --> 01:50:22,000
related to the perturbation. Uh I guess

3101
01:50:20,239 --> 01:50:22,960
that's more of a comment, but I can also

3102
01:50:22,000 --> 01:50:25,280
phrase that as a question.

3103
01:50:22,960 --> 01:50:27,119
>> Yeah, I yeah I no I I totally agree.

3104
01:50:25,280 --> 01:50:29,600
We've we've also thought about this idea

3105
01:50:27,119 --> 01:50:31,920
of the difference from the idea that

3106
01:50:29,600 --> 01:50:34,320
like you know a lot of drugs might do

3107
01:50:31,920 --> 01:50:36,880
something and so you have like you kind

3108
01:50:34,320 --> 01:50:38,480
of kind of discern between this idea

3109
01:50:36,880 --> 01:50:41,600
like things change versus things that

3110
01:50:38,480 --> 01:50:44,800
like meaningfully change and so um you

3111
01:50:41,600 --> 01:50:46,719
know that's another question of like you

3112
01:50:44,800 --> 01:50:48,080
know can we start to generate data sets

3113
01:50:46,719 --> 01:50:49,280
where you have this sort of meaningful

3114
01:50:48,080 --> 01:50:50,400
change and kind of detecting that I

3115
01:50:49,280 --> 01:50:53,600
think that's more of a biological

3116
01:50:50,400 --> 01:50:56,000
question um that you know we are working

3117
01:50:53,600 --> 01:50:58,320
closely with our XVO to start to try to

3118
01:50:56,000 --> 01:50:59,840
define. But um yeah, a lot of these

3119
01:50:58,320 --> 01:51:01,760
things end up being noise, which again,

3120
01:50:59,840 --> 01:51:03,520
I don't think it's a place like Taho's

3121
01:51:01,760 --> 01:51:04,880
fault, right? Like I think if you had to

3122
01:51:03,520 --> 01:51:06,239
start somewhere, you're like, I'll try

3123
01:51:04,880 --> 01:51:08,239
to perturb a bunch of different things

3124
01:51:06,239 --> 01:51:10,080
at scale and kind of see what happens. I

3125
01:51:08,239 --> 01:51:11,760
think that's just kind of the result of

3126
01:51:10,080 --> 01:51:15,080
um yeah, you don't get a lot of signal

3127
01:51:11,760 --> 01:51:15,080
from somebody.

3128
01:51:15,119 --> 01:51:20,480
>> Your evaluations seem to be at the level

3129
01:51:17,280 --> 01:51:22,800
of of pseudo bulk, but you also look at

3130
01:51:20,480 --> 01:51:24,639
the scaling with respect to cells. You

3131
01:51:22,800 --> 01:51:26,159
think maybe that is also a fallacy given

3132
01:51:24,639 --> 01:51:30,159
that information you get from single

3133
01:51:26,159 --> 01:51:32,400
cell is at the distributional level

3134
01:51:30,159 --> 01:51:34,480
>> uh suitable in what way sorry

3135
01:51:32,400 --> 01:51:35,920
>> you do r squared which I assume is at a

3136
01:51:34,480 --> 01:51:38,400
suitable level same with setup

3137
01:51:35,920 --> 01:51:40,719
annotations right these are um not

3138
01:51:38,400 --> 01:51:41,920
considering the whole distribution well

3139
01:51:40,719 --> 01:51:43,679
>> oh yeah that's a great question yeah

3140
01:51:41,920 --> 01:51:45,760
that's a great point yeah I mean I don't

3141
01:51:43,679 --> 01:51:47,360
I would argue that I don't know if R squ

3142
01:51:45,760 --> 01:51:48,880
is the greatest I think what you really

3143
01:51:47,360 --> 01:51:51,040
want when you think about like

3144
01:51:48,880 --> 01:51:54,000
perturbation prediction effect is like a

3145
01:51:51,040 --> 01:51:55,520
more distributional based like metric I

3146
01:51:54,000 --> 01:51:57,119
seven and I talk about this like all the

3147
01:51:55,520 --> 01:51:59,119
time like yeah it's just the one that

3148
01:51:57,119 --> 01:52:01,440
people always think about and people use

3149
01:51:59,119 --> 01:52:02,960
a lot but I agree like this idea of R

3150
01:52:01,440 --> 01:52:05,040
square can be conflated or deflated

3151
01:52:02,960 --> 01:52:06,639
based on like how well you're doing on

3152
01:52:05,040 --> 01:52:08,239
the cells that change or if you're

3153
01:52:06,639 --> 01:52:11,599
overindexing on the cells that don't

3154
01:52:08,239 --> 01:52:14,639
change and so you can have a misaligned

3155
01:52:11,599 --> 01:52:16,239
uh metric in terms of performance versus

3156
01:52:14,639 --> 01:52:18,880
like what the model is actually doing

3157
01:52:16,239 --> 01:52:20,480
across individual cells. Yeah, I think

3158
01:52:18,880 --> 01:52:22,800
about that. I mean if you have a thought

3159
01:52:20,480 --> 01:52:25,599
there um but I know people have been

3160
01:52:22,800 --> 01:52:27,599
thinking about better metrics for to

3161
01:52:25,599 --> 01:52:29,679
kind of capture the more individual cell

3162
01:52:27,599 --> 01:52:31,760
type thing. Yeah,

3163
01:52:29,679 --> 01:52:34,000
>> I have one last question from the uh

3164
01:52:31,760 --> 01:52:36,080
Zoom chat. Uh could a hybrid model uh

3165
01:52:34,000 --> 01:52:38,719
from Anthony uh could a hybrid model

3166
01:52:36,080 --> 01:52:40,960
that trains on both genes and expression

3167
01:52:38,719 --> 01:52:42,480
value and base pairs themselves unlock

3168
01:52:40,960 --> 01:52:43,840
some of the limitations of expression

3169
01:52:42,480 --> 01:52:45,920
ccentric models or are these two data

3170
01:52:43,840 --> 01:52:46,719
types just too different to be useful in

3171
01:52:45,920 --> 01:52:48,320
pre-training?

3172
01:52:46,719 --> 01:52:49,520
>> I mean maybe I think that's a really

3173
01:52:48,320 --> 01:52:51,280
good point. I mean like I get this

3174
01:52:49,520 --> 01:52:53,040
question a lot which is like do we like

3175
01:52:51,280 --> 01:52:54,400
at XV people think RNA is everything or

3176
01:52:53,040 --> 01:52:56,080
the end all beall like I think no I

3177
01:52:54,400 --> 01:52:58,000
think multimodal things are the way that

3178
01:52:56,080 --> 01:52:59,520
everyone's kind of moving the really the

3179
01:52:58,000 --> 01:53:02,320
real big question is how you start to

3180
01:52:59,520 --> 01:53:04,560
integrate across modalities right and

3181
01:53:02,320 --> 01:53:07,040
like one one strategy people have had is

3182
01:53:04,560 --> 01:53:09,440
I can just take one model trained on one

3183
01:53:07,040 --> 01:53:11,440
thing and then train a model on top of

3184
01:53:09,440 --> 01:53:12,719
that I think UC sort of leverages some

3185
01:53:11,440 --> 01:53:14,480
of this kind of strategy I don't know if

3186
01:53:12,719 --> 01:53:15,760
that's the way to kind of go because you

3187
01:53:14,480 --> 01:53:17,040
kind of lose what you really want to do

3188
01:53:15,760 --> 01:53:18,880
is capture the interaction across

3189
01:53:17,040 --> 01:53:20,560
modalities which I think is like the

3190
01:53:18,880 --> 01:53:23,280
challenge like how do you do that? But I

3191
01:53:20,560 --> 01:53:26,159
do agree like I think in incorporating

3192
01:53:23,280 --> 01:53:27,679
um other modes is is to get a more

3193
01:53:26,159 --> 01:53:30,000
holistic view of what you think cell

3194
01:53:27,679 --> 01:53:33,480
state might represent is yeah a a good

3195
01:53:30,000 --> 01:53:33,480
pathway forward.


1
00:00:01,469 --> 00:00:04,302
(logo whooshing)

2
00:00:05,760 --> 00:00:07,050
- Hello everyone.

3
00:00:07,050 --> 00:00:09,660
Welcome back to CSAIL Office Hours.

4
00:00:09,660 --> 00:00:12,060
I'm Daniela Rus, Director
of the Computer Science

5
00:00:12,060 --> 00:00:16,230
and Artificial Intelligence
Laboratory at MIT CSAIL,

6
00:00:16,230 --> 00:00:17,370
and today we are going

7
00:00:17,370 --> 00:00:20,370
to talk about all things generative AI.

8
00:00:20,370 --> 00:00:23,292
I'm joined by some brilliant researchers

9
00:00:23,292 --> 00:00:27,540
and colleagues at CSAIL
as well as Greg Huang,

10
00:00:27,540 --> 00:00:30,090
business editor at the Boston Globe.

11
00:00:30,090 --> 00:00:32,550
- So today we'll be exploring
the cutting edge-field

12
00:00:32,550 --> 00:00:33,660
of generative AI.

13
00:00:33,660 --> 00:00:35,759
This is artificial intelligence systems

14
00:00:35,759 --> 00:00:39,510
that can generate new content
like text, coding, images

15
00:00:39,510 --> 00:00:42,270
and videos from scratch or with inputs.

16
00:00:42,270 --> 00:00:44,130
Now work on generative AI

17
00:00:44,130 --> 00:00:47,610
as deep roots here at MIT
dating back to the 1960s,

18
00:00:47,610 --> 00:00:50,040
today we're gonna get into
the cutting-edge research

19
00:00:50,040 --> 00:00:51,540
that's happening in this field.

20
00:00:51,540 --> 00:00:54,900
We've seen a lot of rapid
progress in recent years,

21
00:00:54,900 --> 00:00:58,410
systems that can write
stories, code software,

22
00:00:58,410 --> 00:01:01,860
generate photorealistic
images, videos, and more.

23
00:01:01,860 --> 00:01:04,380
So to discuss the latest
research in this area,

24
00:01:04,380 --> 00:01:07,680
I'm joined by five experts from MIT CSAIL

25
00:01:07,680 --> 00:01:10,110
whose work spans different aspects

26
00:01:10,110 --> 00:01:13,260
of generative AI including
robotics, language models,

27
00:01:13,260 --> 00:01:16,170
coding, images, and video generation.

28
00:01:16,170 --> 00:01:19,770
Before we dive in, we can
do a quick round of intros.

29
00:01:19,770 --> 00:01:21,960
- Sure, I am Armando Solar-Lezama

30
00:01:21,960 --> 00:01:26,760
and I work at the intersection
of programming systems

31
00:01:26,760 --> 00:01:30,723
and AI, particularly focused
on programming technology.

32
00:01:31,908 --> 00:01:33,390
- I'm Jacob Andreas.

33
00:01:33,390 --> 00:01:35,280
I work on natural language processing

34
00:01:35,280 --> 00:01:36,690
and computational linguistics.

35
00:01:36,690 --> 00:01:37,530
- Hi, I am Yoon Kim.

36
00:01:37,530 --> 00:01:40,800
I work on natural language
processing and machine learning.

37
00:01:40,800 --> 00:01:42,000
- Hi, I'm Philip Isola

38
00:01:42,000 --> 00:01:45,120
and I work on computer
vision and machine learning.

39
00:01:45,120 --> 00:01:47,700
- As you all know, generative AI has seen

40
00:01:47,700 --> 00:01:49,620
rapid progress in recent years.

41
00:01:49,620 --> 00:01:53,610
So leading to systems that
can write creative stories,

42
00:01:53,610 --> 00:01:57,450
code software from natural
language descriptions,

43
00:01:57,450 --> 00:02:00,720
generate photorealistic images and videos

44
00:02:00,720 --> 00:02:03,330
and much more, it's
also led to a reshaping

45
00:02:03,330 --> 00:02:05,250
of the global tech landscape.

46
00:02:05,250 --> 00:02:06,900
You know, with the rise of open AI,

47
00:02:06,900 --> 00:02:11,160
Nvidia and just billions of
dollars being poured into chips,

48
00:02:11,160 --> 00:02:13,860
cloud servers, software development

49
00:02:13,860 --> 00:02:15,990
and just really a war on talent.

50
00:02:15,990 --> 00:02:17,940
We're joined by people

51
00:02:17,940 --> 00:02:19,620
who know the most about
what's happening here

52
00:02:19,620 --> 00:02:22,080
in Gen AI at CSAIL.

53
00:02:22,080 --> 00:02:24,750
And your work all spans
these different areas, right?

54
00:02:24,750 --> 00:02:28,380
So from language and coding to images

55
00:02:28,380 --> 00:02:29,760
and robotics even.

56
00:02:29,760 --> 00:02:31,650
So I'm gonna just jump
in with some questions

57
00:02:31,650 --> 00:02:34,688
because the LLMs have been such,

58
00:02:34,688 --> 00:02:35,521
this a huge, you know,

59
00:02:35,521 --> 00:02:37,020
explosion and interest in recent years.

60
00:02:37,020 --> 00:02:38,730
I'm gonna start with
the language guys here.

61
00:02:38,730 --> 00:02:41,310
So Jacob, your work on these compositional

62
00:02:41,310 --> 00:02:43,590
and grounded language understanding.

63
00:02:43,590 --> 00:02:46,440
It's like it's demonstrated
the ability to translate

64
00:02:46,440 --> 00:02:49,110
between natural language and
structured representation.

65
00:02:49,110 --> 00:02:51,000
Maybe you can talk a little
bit about what that means.

66
00:02:51,000 --> 00:02:54,600
But how do you build these
generative AI systems

67
00:02:54,600 --> 00:02:57,360
that can generate these
natural language descriptions?

68
00:02:57,360 --> 00:02:59,910
- One of the interesting things
to see has been, you know,

69
00:02:59,910 --> 00:03:02,280
when we started working
kind of at the intersection

70
00:03:02,280 --> 00:03:04,530
of like language and vision especially,

71
00:03:04,530 --> 00:03:05,820
it was all about getting these sort

72
00:03:05,820 --> 00:03:09,420
of carefully curated data sets
of, you know, images paired

73
00:03:09,420 --> 00:03:11,280
with captions and natural language

74
00:03:11,280 --> 00:03:13,320
or images paired with
questions and language

75
00:03:13,320 --> 00:03:14,670
and answers to those questions.

76
00:03:14,670 --> 00:03:17,610
And thinking very carefully
about the design of kind

77
00:03:17,610 --> 00:03:20,400
of specific neural network
architectures that could map,

78
00:03:20,400 --> 00:03:22,680
you know, directly from images to text

79
00:03:22,680 --> 00:03:24,210
or from text images or whatever.

80
00:03:24,210 --> 00:03:27,060
And I think the biggest
thing that's changed now is

81
00:03:27,060 --> 00:03:30,900
just that what research looks
like is much less about,

82
00:03:30,900 --> 00:03:32,670
you know, how you specifically design

83
00:03:32,670 --> 00:03:34,590
some specific neural network
for this little task.

84
00:03:34,590 --> 00:03:35,790
Or even how you go out

85
00:03:35,790 --> 00:03:39,810
and collect, you know, paired
data just for some target task

86
00:03:39,810 --> 00:03:41,130
of interest like image generation

87
00:03:41,130 --> 00:03:42,630
or image captioning or whatever.

88
00:03:42,630 --> 00:03:45,840
And much more about, you know,
I think on the data side,

89
00:03:45,840 --> 00:03:49,590
thinking about the kinds of, you know,

90
00:03:49,590 --> 00:03:52,590
general data sources and
properties and structures

91
00:03:52,590 --> 00:03:55,860
and data sets that induce
shared representations

92
00:03:55,860 --> 00:03:57,450
in these models of, you know,

93
00:03:57,450 --> 00:03:58,830
not just language and not just vision,

94
00:03:58,830 --> 00:04:01,047
but also kind of the world
that underlies these things.

95
00:04:01,047 --> 00:04:03,180
And this is something that
I know Philip is thinking

96
00:04:03,180 --> 00:04:05,190
a lot about lately as well.

97
00:04:05,190 --> 00:04:06,930
But yeah, I mean really just less about

98
00:04:06,930 --> 00:04:08,430
how you solve any individual problem

99
00:04:08,430 --> 00:04:10,170
and more about how you
collect the kind of data

100
00:04:10,170 --> 00:04:11,580
that gives you the
kinds of representations

101
00:04:11,580 --> 00:04:13,872
that really let you do anything.

102
00:04:13,872 --> 00:04:17,070
Talking about starting to generate text,

103
00:04:17,070 --> 00:04:18,660
generate images, things like that,

104
00:04:18,660 --> 00:04:22,470
I think one of the other big
challenges now actually has

105
00:04:22,470 --> 00:04:24,090
less to do with the machine
learning side of things

106
00:04:24,090 --> 00:04:26,416
and more with just kind of the
human facing side of things

107
00:04:26,416 --> 00:04:28,980
and that, you know, because
LLMs are so powerful

108
00:04:28,980 --> 00:04:30,060
and because we, you know,

109
00:04:30,060 --> 00:04:32,640
have such a good like language
processing toolkit now,

110
00:04:32,640 --> 00:04:34,500
I think everyone's kind
of adopted this paradigm

111
00:04:34,500 --> 00:04:36,510
where you try to describe
whatever it is that you're trying

112
00:04:36,510 --> 00:04:38,580
to accomplish in natural language.

113
00:04:38,580 --> 00:04:42,330
And sometimes language is a
great medium for specifying,

114
00:04:42,330 --> 00:04:43,650
you know, what you want
a picture to look like

115
00:04:43,650 --> 00:04:45,270
or what you want a piece of code to do.

116
00:04:45,270 --> 00:04:46,770
Sometimes it's not the right tool at all.

117
00:04:46,770 --> 00:04:48,390
And I think we're still
figuring out just like

118
00:04:48,390 --> 00:04:52,740
what the human interaction
story should be here

119
00:04:52,740 --> 00:04:54,960
and what the right way of communicating

120
00:04:54,960 --> 00:04:57,960
with these sorts of generative models is.

121
00:04:57,960 --> 00:05:01,590
- And you, I mean, being
a language expert as well,

122
00:05:01,590 --> 00:05:02,471
how do you react to that

123
00:05:02,471 --> 00:05:04,020
and then how do you improve things?

124
00:05:04,020 --> 00:05:06,660
- Just to react to
that, I think when Jacob

125
00:05:06,660 --> 00:05:08,130
and I were PhD students,

126
00:05:08,130 --> 00:05:10,080
there was a lot of work on like you wanted

127
00:05:10,080 --> 00:05:11,880
to model the translation process.

128
00:05:11,880 --> 00:05:14,280
You wanted to do a natural
language processing task

129
00:05:14,280 --> 00:05:16,740
called semantic pausing,
and you would craft models

130
00:05:16,740 --> 00:05:19,410
and data sets for this task
of interest with the hope

131
00:05:19,410 --> 00:05:21,611
that it'll be useful for downstream task

132
00:05:21,611 --> 00:05:23,610
of interest in the future.

133
00:05:23,610 --> 00:05:26,910
But now we have these systems
actually working in practice,

134
00:05:26,910 --> 00:05:29,850
large language model-based
systems that are, you know,

135
00:05:29,850 --> 00:05:32,760
monolithic data-driven models,
trained on lots of data sets,

136
00:05:32,760 --> 00:05:35,400
but they're working well
enough that they're being sort

137
00:05:35,400 --> 00:05:39,390
of like a core part of major
AI-based services today.

138
00:05:39,390 --> 00:05:43,737
As you think about how
these systems sort of like,

139
00:05:43,737 --> 00:05:46,920
the entire pipeline of their
systems from data collection,

140
00:05:46,920 --> 00:05:49,915
from the systems on which they're
trained, how they're used,

141
00:05:49,915 --> 00:05:52,890
how the outputs of these
systems are sort of presented

142
00:05:52,890 --> 00:05:54,180
to the actual users.

143
00:05:54,180 --> 00:05:56,730
I think there's a rich sort of set

144
00:05:56,730 --> 00:06:00,000
of research questions that sort of like,

145
00:06:00,000 --> 00:06:02,610
weren't really a cool part of NLPIC

146
00:06:02,610 --> 00:06:04,560
until these technologies came along.

147
00:06:04,560 --> 00:06:06,650
And I think that's where a lot

148
00:06:06,650 --> 00:06:08,730
of the interesting research questions are.

149
00:06:08,730 --> 00:06:11,040
- To me, the fact that you can put AI

150
00:06:11,040 --> 00:06:13,260
in the pockets of everyone

151
00:06:13,260 --> 00:06:17,400
with the use of natural
language processing

152
00:06:17,400 --> 00:06:19,980
and large language models
is absolutely extraordinary.

153
00:06:19,980 --> 00:06:22,950
We have truly democratized AI.

154
00:06:22,950 --> 00:06:25,920
But I'd like to follow
up on Greg's question

155
00:06:25,920 --> 00:06:29,220
and ask you what do you see

156
00:06:29,220 --> 00:06:31,200
as the most interesting

157
00:06:31,200 --> 00:06:35,490
or exciting applications,
especially in business?

158
00:06:35,490 --> 00:06:38,970
I know that for the past
year companies have struggled

159
00:06:38,970 --> 00:06:42,028
to understand how they can get value

160
00:06:42,028 --> 00:06:44,520
from these new technologies.

161
00:06:44,520 --> 00:06:47,610
And in particular on the language side.

162
00:06:47,610 --> 00:06:50,550
- I think one application is extracting

163
00:06:50,550 --> 00:06:53,610
structured information
from unstructured data

164
00:06:53,610 --> 00:06:57,060
with which to do further modeling,

165
00:06:57,060 --> 00:06:59,820
further conversion into
sort of relevant services.

166
00:06:59,820 --> 00:07:02,820
In the past, if you, for
example, had clinical notes

167
00:07:02,820 --> 00:07:03,960
or like contracts

168
00:07:03,960 --> 00:07:06,030
and you wanted to extract
information out of them

169
00:07:06,030 --> 00:07:09,000
to do stuff with them, like
build a chat bot on top of,

170
00:07:09,000 --> 00:07:11,910
or have a machine learning
model to give outputs,

171
00:07:11,910 --> 00:07:16,910
then that was a very sort
of a burdensome process.

172
00:07:17,010 --> 00:07:18,630
But now it's not perfect.

173
00:07:18,630 --> 00:07:20,280
But if you have a large language model

174
00:07:20,280 --> 00:07:22,290
and you give it, for
example, some examples

175
00:07:22,290 --> 00:07:25,440
of extracting structured
data, it'll get you started.

176
00:07:25,440 --> 00:07:27,540
Of course this will
need further refinement

177
00:07:27,540 --> 00:07:30,193
and every sort of application
should be mindful of,

178
00:07:30,193 --> 00:07:32,640
you know, "What's the risk
of getting this wrong?"

179
00:07:32,640 --> 00:07:36,120
But I think that's sort of
a very prominent application

180
00:07:36,120 --> 00:07:39,183
where I think LLMs will
get you from zero to one.

181
00:07:40,320 --> 00:07:41,610
- What do you think Jacob?

182
00:07:41,610 --> 00:07:45,180
- In the, I guess, pre-LLM era,

183
00:07:45,180 --> 00:07:46,590
you know, this business

184
00:07:46,590 --> 00:07:48,750
of how do you do structured
information extraction?

185
00:07:48,750 --> 00:07:51,780
How do you parse a document,
how do you do good web search?

186
00:07:51,780 --> 00:07:55,530
You know, these were entire
sort of major areas of research

187
00:07:55,530 --> 00:07:57,600
and people built these same
kinds of specialized models

188
00:07:57,600 --> 00:07:59,910
that we were talking about
and they kind of worked

189
00:07:59,910 --> 00:08:01,530
and that was really kind

190
00:08:01,530 --> 00:08:03,090
of like the cutting edge
of what you could do.

191
00:08:03,090 --> 00:08:06,180
And now we live in this world
where, you know, you can kind

192
00:08:06,180 --> 00:08:07,740
of sort of do all of
these incredible things

193
00:08:07,740 --> 00:08:10,470
like code generation and
long-form document generation,

194
00:08:10,470 --> 00:08:12,420
you know, and I think
maybe part of the reason

195
00:08:12,420 --> 00:08:15,630
that the business world has
struggled to adopt these things,

196
00:08:15,630 --> 00:08:17,460
which are the things that people
are really excited about is

197
00:08:17,460 --> 00:08:20,700
'cause there's still a lot
of, you know, work to do

198
00:08:20,700 --> 00:08:22,860
and things to iron out to
make them really like safe

199
00:08:22,860 --> 00:08:24,180
and robust and reliable.

200
00:08:24,180 --> 00:08:26,430
But all that stuff that we
were trying to do, you know,

201
00:08:26,430 --> 00:08:28,740
before the LLMs happened is just, I mean,

202
00:08:28,740 --> 00:08:29,760
it's solved essentially.

203
00:08:29,760 --> 00:08:32,342
And I think there's actually,
you know, we haven't even yet

204
00:08:32,342 --> 00:08:36,240
like, really adapted to living
in a world where, you know,

205
00:08:36,240 --> 00:08:40,260
late 2000s era NLP technology
works really, really well,

206
00:08:40,260 --> 00:08:43,491
much less to living in
a world where, you know,

207
00:08:43,491 --> 00:08:45,180
LLMs can reliably do all the things

208
00:08:45,180 --> 00:08:46,980
that we're trying to get
them to do right now.

209
00:08:46,980 --> 00:08:50,172
- How does your research, like right now,

210
00:08:50,172 --> 00:08:53,010
how does it inform, you know, the next GPT

211
00:08:53,010 --> 00:08:54,840
or whatever model, you
know, we're seeing out there

212
00:08:54,840 --> 00:08:56,610
or you know, how Google does there?

213
00:08:56,610 --> 00:08:58,770
Things you see when you
start to do a Google search.

214
00:08:58,770 --> 00:09:00,897
Like, how close are you to that

215
00:09:00,897 --> 00:09:03,810
and what's the kind of process
for getting in that pipeline?

216
00:09:03,810 --> 00:09:06,660
- So a lot of my current
research is focused

217
00:09:06,660 --> 00:09:09,750
on making LLMs useful through
making them more efficient,

218
00:09:09,750 --> 00:09:11,370
interpretable and controllable.

219
00:09:11,370 --> 00:09:15,150
And I think Daniela, you
know, said that it's amazing

220
00:09:15,150 --> 00:09:17,520
that we can access ChatGPT on our phones

221
00:09:17,520 --> 00:09:20,280
and have this have access to
this incredible technology.

222
00:09:20,280 --> 00:09:23,100
So we have democratized
access to these technologies

223
00:09:23,100 --> 00:09:26,010
to an extent, but if we think about like,

224
00:09:26,010 --> 00:09:29,790
who really has the resources
to develop these models,

225
00:09:29,790 --> 00:09:32,340
adapt them to various tasks of interest,

226
00:09:32,340 --> 00:09:34,290
I think there's still
like a lot of barrier

227
00:09:34,290 --> 00:09:36,510
to really working with these models.

228
00:09:36,510 --> 00:09:39,817
And I think part of the
problem is everything related

229
00:09:39,817 --> 00:09:42,180
to these models, architectures

230
00:09:42,180 --> 00:09:44,100
and algorithms are inefficient.

231
00:09:44,100 --> 00:09:45,510
They require a lot of resources.

232
00:09:45,510 --> 00:09:46,950
They contribute non-trivial

233
00:09:46,950 --> 00:09:48,900
to the carbon footprint in general.

234
00:09:48,900 --> 00:09:50,370
And I think that's what motivates

235
00:09:50,370 --> 00:09:52,500
a lot of my current
research on efficiency.

236
00:09:52,500 --> 00:09:56,400
- Right now, you can run ChatGPT

237
00:09:56,400 --> 00:09:59,940
or your language model
of choice on your phone,

238
00:09:59,940 --> 00:10:03,900
but in fact the computation
has to happen on server farms

239
00:10:03,900 --> 00:10:08,010
and only big corporations
have the resources

240
00:10:08,010 --> 00:10:10,170
to access the server farms.

241
00:10:10,170 --> 00:10:12,870
Additionally, when a company wants

242
00:10:12,870 --> 00:10:17,790
to instantiate a language
model for their own needs,

243
00:10:17,790 --> 00:10:20,400
right now, either they get a server farm

244
00:10:20,400 --> 00:10:23,940
or they send their data
to one of the providers

245
00:10:23,940 --> 00:10:25,170
of these huge models

246
00:10:25,170 --> 00:10:29,100
and that has some privacy
issues associated with that.

247
00:10:29,100 --> 00:10:34,100
So, the research to make
foundational models able to run

248
00:10:36,408 --> 00:10:39,360
on small devices like enterprise computers

249
00:10:39,360 --> 00:10:42,240
and phones is very important.

250
00:10:42,240 --> 00:10:45,210
- Well, let's shift gears to
the whole programming side

251
00:10:45,210 --> 00:10:48,780
of things and you read
stories in New Yorker

252
00:10:48,780 --> 00:10:50,490
or Wall Street Journal or Boston Globe

253
00:10:50,490 --> 00:10:53,400
about software developers,
jobs being, you know,

254
00:10:53,400 --> 00:10:54,960
not threatened, but you know,

255
00:10:54,960 --> 00:10:57,630
it's changing how coding happens.

256
00:10:57,630 --> 00:11:00,227
Maybe you could Armando speak a bit

257
00:11:00,227 --> 00:11:03,210
about your research on that
front and kind of what you see

258
00:11:03,210 --> 00:11:04,830
happening there at the cutting edge.

259
00:11:04,830 --> 00:11:06,810
- For a lot of routine tasks

260
00:11:06,810 --> 00:11:09,990
and especially for a lot of
tasks that involve heavy use

261
00:11:09,990 --> 00:11:13,830
of widely used APIs, for example,

262
00:11:13,830 --> 00:11:15,390
these kind of tools can make

263
00:11:15,390 --> 00:11:17,880
an enormous productivity difference.

264
00:11:17,880 --> 00:11:22,260
And especially for people who don't have

265
00:11:22,260 --> 00:11:24,360
kind of that deep knowledge

266
00:11:24,360 --> 00:11:26,523
of these APIs at their fingertips,

267
00:11:27,360 --> 00:11:31,470
allowing them to work
at the rate of people

268
00:11:31,470 --> 00:11:34,860
with much more experience than themselves.

269
00:11:34,860 --> 00:11:37,230
I think there is the question of like,

270
00:11:37,230 --> 00:11:39,834
what kind of impact can we expect

271
00:11:39,834 --> 00:11:43,830
from these kind of technology?

272
00:11:43,830 --> 00:11:46,680
So on the one hand it's
sort of very well known

273
00:11:46,680 --> 00:11:49,230
in the software industry
that the amount of time

274
00:11:49,230 --> 00:11:52,140
that one spends actually
typing in the code

275
00:11:52,140 --> 00:11:55,440
that goes into a product
is a tiny fraction

276
00:11:55,440 --> 00:12:00,090
of the overall effort
required to design and build

277
00:12:00,090 --> 00:12:02,250
and then maintain software product.

278
00:12:02,250 --> 00:12:04,410
And I think we're still
very far from the point

279
00:12:04,410 --> 00:12:08,255
where AI can really help with
all of those different tasks

280
00:12:08,255 --> 00:12:13,170
that are part of a general
software development framework.

281
00:12:13,170 --> 00:12:16,410
The other thing is, as an
industry software is I think

282
00:12:16,410 --> 00:12:19,650
quite different from
many other industries.

283
00:12:19,650 --> 00:12:22,740
On the one hand, you know,
today we see like, wow,

284
00:12:22,740 --> 00:12:25,320
this is a big change
in how people program,

285
00:12:25,320 --> 00:12:29,220
but we've seen really big
changes in how people program.

286
00:12:29,220 --> 00:12:33,390
Many times, even over
the course of my career,

287
00:12:33,390 --> 00:12:36,900
for example, when we moved
towards managed languages

288
00:12:36,900 --> 00:12:38,820
where suddenly it was possible

289
00:12:38,820 --> 00:12:40,440
to build really rich functionality

290
00:12:40,440 --> 00:12:43,680
just by grabbing libraries
from all over the place.

291
00:12:43,680 --> 00:12:47,850
Like, that was a huge shift
in the way people developed

292
00:12:47,850 --> 00:12:50,550
software and a huge
productivity boost, right?

293
00:12:50,550 --> 00:12:53,400
That's what made it
possible for, you know,

294
00:12:53,400 --> 00:12:55,710
suddenly startups with two or three people

295
00:12:55,710 --> 00:12:58,542
to very quickly build up infrastructure

296
00:12:58,542 --> 00:13:02,220
and deploy services used by millions.

297
00:13:02,220 --> 00:13:06,270
And so we're an industry that is very used

298
00:13:06,270 --> 00:13:09,860
to that kind of change.

299
00:13:09,860 --> 00:13:11,370
At the same time, you know,

300
00:13:11,370 --> 00:13:14,820
when it comes to the question
of jobs, for example,

301
00:13:14,820 --> 00:13:19,020
if you have, you know, a
construction industry, right?

302
00:13:19,020 --> 00:13:22,680
Let's say that suddenly builders became

303
00:13:22,680 --> 00:13:24,720
ten times more efficient

304
00:13:24,720 --> 00:13:28,440
in their use of labor to produce a house.

305
00:13:28,440 --> 00:13:30,210
Well, in order to produce a house,

306
00:13:30,210 --> 00:13:32,880
you don't just need labor, you need land,

307
00:13:32,880 --> 00:13:35,850
you need raw materials, it's pretty likely

308
00:13:35,850 --> 00:13:37,470
that you would need now one tenth

309
00:13:37,470 --> 00:13:39,480
as many construction workers

310
00:13:39,480 --> 00:13:41,580
because you're not gonna
get ten times more land.

311
00:13:41,580 --> 00:13:45,048
You're not gonna get ten
times more building materials.

312
00:13:45,048 --> 00:13:48,750
With software, you basically need people,

313
00:13:48,750 --> 00:13:50,190
you need skilled people.

314
00:13:50,190 --> 00:13:52,680
If you can get twice
as many skilled people,

315
00:13:52,680 --> 00:13:55,680
you can design twice as much software,

316
00:13:55,680 --> 00:13:59,280
you don't quite have the
same set of constraints.

317
00:13:59,280 --> 00:14:03,630
And we have these huge
unmet need of applications

318
00:14:03,630 --> 00:14:05,820
that would be awesome if they existed,

319
00:14:05,820 --> 00:14:08,130
but maybe not at the price point

320
00:14:08,130 --> 00:14:09,840
that it takes to build them.

321
00:14:09,840 --> 00:14:14,400
Or applications that exist
in a way that is vulnerable

322
00:14:14,400 --> 00:14:18,300
to exploit, that is hard to use,

323
00:14:18,300 --> 00:14:19,830
that is insecure.

324
00:14:19,830 --> 00:14:23,340
So we have a huge unmet demand
for software development

325
00:14:23,340 --> 00:14:24,750
that I think we're very, very far

326
00:14:24,750 --> 00:14:27,540
from running out of things to program.

327
00:14:27,540 --> 00:14:29,130
- You're talking about software
that's gonna, you know,

328
00:14:29,130 --> 00:14:30,630
run airplanes and so forth, right?

329
00:14:30,630 --> 00:14:34,050
So, in your research,
are you finding ways to-

330
00:14:34,050 --> 00:14:35,730
Or how do you get over that?

331
00:14:35,730 --> 00:14:37,470
How do you make it actually work?

332
00:14:37,470 --> 00:14:40,800
- So for us, this is a very
important area of research

333
00:14:40,800 --> 00:14:42,540
that we're very focused on, which is

334
00:14:42,540 --> 00:14:44,850
how do you combine the style of reasoning

335
00:14:44,850 --> 00:14:48,690
that you get from an LLM that's able

336
00:14:48,690 --> 00:14:52,500
to draw from these amount of experience

337
00:14:52,500 --> 00:14:55,260
from having seen basically all the code

338
00:14:55,260 --> 00:14:57,660
that is available on the internet,

339
00:14:57,660 --> 00:15:02,580
but how do you combine it with the need

340
00:15:02,580 --> 00:15:05,250
and the ability to read logically

341
00:15:05,250 --> 00:15:08,700
about what the code is
actually doing to recent

342
00:15:08,700 --> 00:15:12,060
about how different pieces
of code are going to interact

343
00:15:12,060 --> 00:15:13,350
with each other.

344
00:15:13,350 --> 00:15:16,800
And this is something
that LLMs have proven

345
00:15:16,800 --> 00:15:18,270
to be not very good at

346
00:15:18,270 --> 00:15:23,270
or reasoning about the
low level details of code.

347
00:15:23,640 --> 00:15:27,900
At the same time, we do
have a lot of techniques

348
00:15:27,900 --> 00:15:31,230
and a lot of tools for doing very precise,

349
00:15:31,230 --> 00:15:34,707
automated reasoning over code.

350
00:15:34,707 --> 00:15:36,407
And the question of how do you get

351
00:15:37,476 --> 00:15:40,740
those two very different
technologies to work together

352
00:15:40,740 --> 00:15:42,270
so that you can have the level

353
00:15:42,270 --> 00:15:43,920
of reliability that is needed

354
00:15:43,920 --> 00:15:47,760
for many of these really important
applications that I think

355
00:15:47,760 --> 00:15:50,190
that's one of the big
open questions right now.

356
00:15:50,190 --> 00:15:53,040
- There are so many
safety critical systems

357
00:15:53,040 --> 00:15:58,040
where hallucinations and
errors are just not acceptable.

358
00:15:58,320 --> 00:16:03,060
And so at the same time
we have an entire field

359
00:16:03,060 --> 00:16:06,420
called verification whose
job it is to make sure

360
00:16:06,420 --> 00:16:09,613
that the software that we build is correct

361
00:16:09,613 --> 00:16:13,500
and will execute
according to expectations.

362
00:16:13,500 --> 00:16:17,010
Can you say a few words about
where we are with respect

363
00:16:17,010 --> 00:16:20,370
to bringing verification
into machine learning?

364
00:16:20,370 --> 00:16:24,240
- We do have this possibility
of accessing ground truth

365
00:16:24,240 --> 00:16:29,240
by verifying the actual
behavior of the code.

366
00:16:29,580 --> 00:16:32,970
The field of verification
has made enormous leaps

367
00:16:32,970 --> 00:16:35,700
over the past ten years to the point

368
00:16:35,700 --> 00:16:40,700
where today we have some
really compelling examples

369
00:16:40,899 --> 00:16:43,590
of systems level software

370
00:16:43,590 --> 00:16:47,190
that has been fully
verified to prove that,

371
00:16:47,190 --> 00:16:51,270
it's completely absent of
bugs, that it's going to behave

372
00:16:51,270 --> 00:16:52,770
exactly as people expect

373
00:16:52,770 --> 00:16:57,770
even against adversarial
attacks, for example.

374
00:16:58,720 --> 00:17:00,487
One of the big questions is,

375
00:17:00,487 --> 00:17:04,650
"How do we get the cost of building

376
00:17:04,650 --> 00:17:07,410
that kind of software down?"

377
00:17:07,410 --> 00:17:10,770
Because right now these
kind of efforts are

378
00:17:10,770 --> 00:17:15,570
one of a kind very, very
challenging development efforts.

379
00:17:15,570 --> 00:17:16,863
The big question is,

380
00:17:17,823 --> 00:17:22,680
"Can LLMs, can AI in
general help democratize

381
00:17:22,680 --> 00:17:24,030
these kind of technology?"

382
00:17:24,030 --> 00:17:27,570
So that it's not just, you know,

383
00:17:27,570 --> 00:17:30,780
very well-funded research level efforts,

384
00:17:30,780 --> 00:17:34,440
but it's every programmer writing software

385
00:17:34,440 --> 00:17:36,690
for embedded devices, for example.

386
00:17:36,690 --> 00:17:40,110
Every small or medium-sized
company building

387
00:17:40,110 --> 00:17:43,890
internet-of-things devices
that can actually have access

388
00:17:43,890 --> 00:17:45,750
to this kind of technology.

389
00:17:45,750 --> 00:17:49,830
One of the challenges in doing this is

390
00:17:49,830 --> 00:17:53,190
that on the one hand,
we don't have the kind

391
00:17:53,190 --> 00:17:57,780
of enormous data sets of
verified code compared to,

392
00:17:57,780 --> 00:18:00,330
you know, all the giant
data sets that we have

393
00:18:00,330 --> 00:18:02,220
for things like Python.

394
00:18:02,220 --> 00:18:06,570
We also don't quite know how to automate

395
00:18:06,570 --> 00:18:11,570
a lot of the clever
insights that go into making

396
00:18:12,210 --> 00:18:17,010
many of these verification feeds possible.

397
00:18:17,010 --> 00:18:21,090
So this is right now an area
that's really just starting

398
00:18:21,090 --> 00:18:24,510
to take off in the research community.

399
00:18:24,510 --> 00:18:26,940
But we do expect, I think,

400
00:18:26,940 --> 00:18:30,090
some compelling results
in the near future.

401
00:18:30,090 --> 00:18:32,100
- Is scalability a problem?

402
00:18:32,100 --> 00:18:34,470
- A lot of these things work

403
00:18:34,470 --> 00:18:38,850
by breaking the big problem
into individual chunks

404
00:18:38,850 --> 00:18:43,850
and verifying small pieces
of software at a time.

405
00:18:44,190 --> 00:18:47,670
But it's actually a
bit of an art right now

406
00:18:47,670 --> 00:18:51,750
to do things in such a
way that when you put

407
00:18:51,750 --> 00:18:53,790
all of these verified components together,

408
00:18:53,790 --> 00:18:56,340
you can make these end-to-end claims

409
00:18:56,340 --> 00:19:00,120
about the reliability and the security

410
00:19:00,120 --> 00:19:02,280
of the overall system.

411
00:19:02,280 --> 00:19:04,590
- You're working on among
other things, you know,

412
00:19:04,590 --> 00:19:07,800
image generation creation
with all kinds of application

413
00:19:07,800 --> 00:19:09,750
that I just wanna get
you started on, you know,

414
00:19:09,750 --> 00:19:12,630
what are you seeing that's
exciting on your research front?

415
00:19:12,630 --> 00:19:13,740
- So image generation

416
00:19:13,740 --> 00:19:16,590
and video generation is
one of the other big areas

417
00:19:16,590 --> 00:19:19,710
along with language models and code models

418
00:19:19,710 --> 00:19:22,110
where generative AI has
made a huge difference

419
00:19:22,110 --> 00:19:26,520
and it's just dramatically
improved over the last few years.

420
00:19:26,520 --> 00:19:27,930
So it's very exciting.

421
00:19:27,930 --> 00:19:30,120
I've been interested in that.

422
00:19:30,120 --> 00:19:33,090
I think that one angle that might not be

423
00:19:33,090 --> 00:19:35,280
fully appreciated yet, but it's the angle

424
00:19:35,280 --> 00:19:36,810
that I'm most excited about is

425
00:19:36,810 --> 00:19:41,810
that the goal of computer
vision has been stated

426
00:19:41,850 --> 00:19:44,790
as to, you know, recognize objects

427
00:19:44,790 --> 00:19:47,430
to make a self-driving car
that can follow a lane,

428
00:19:47,430 --> 00:19:49,110
but there's kind of a
bigger goal behind that,

429
00:19:49,110 --> 00:19:52,680
which is you want to be able to generate

430
00:19:52,680 --> 00:19:54,660
a model of the world around you,

431
00:19:54,660 --> 00:19:57,060
understand where everything
is, how it's moving,

432
00:19:57,060 --> 00:19:58,800
what it is, what it's going to do next.

433
00:19:58,800 --> 00:20:01,320
You kind of wanna have this
model in your head of the world

434
00:20:01,320 --> 00:20:06,240
around you and generative AI
techniques are getting closer

435
00:20:06,240 --> 00:20:08,640
and closer to that,
especially when it comes

436
00:20:08,640 --> 00:20:10,920
to video generation, which
is one of the, you know,

437
00:20:10,920 --> 00:20:13,260
very rapidly moving areas right now.

438
00:20:13,260 --> 00:20:16,770
If I can generate a video of the world,

439
00:20:16,770 --> 00:20:18,727
if I can look at a picture and say,

440
00:20:18,727 --> 00:20:21,870
"Here's what it might
look like if, you know,

441
00:20:21,870 --> 00:20:24,150
the car turned left or
if it started raining."

442
00:20:24,150 --> 00:20:26,550
And I can hallucinate that
and I can generate that.

443
00:20:26,550 --> 00:20:28,590
This is a more positive use
of the word hallucination.

444
00:20:28,590 --> 00:20:29,910
I can imagine that.

445
00:20:29,910 --> 00:20:31,800
Then I've really understood something

446
00:20:31,800 --> 00:20:34,920
about the world and how would
I be able to make those types

447
00:20:34,920 --> 00:20:36,990
of predictions and think

448
00:20:36,990 --> 00:20:38,610
about what might happen if I didn't have

449
00:20:38,610 --> 00:20:40,410
that model of the world around me.

450
00:20:40,410 --> 00:20:43,470
So video models right now
have some ability to do that

451
00:20:43,470 --> 00:20:46,050
and it's only partially there so far,

452
00:20:46,050 --> 00:20:48,720
but that's aspect I'm most excited about.

453
00:20:48,720 --> 00:20:49,860
Having a model of the world

454
00:20:49,860 --> 00:20:52,260
that you can actually
imagine counter-factuals.

455
00:20:52,260 --> 00:20:55,170
What would happen if I were to look left?

456
00:20:55,170 --> 00:20:58,650
What would happen if the car
were to dart in front of me?

457
00:20:58,650 --> 00:21:00,000
Would I have to stop?

458
00:21:00,000 --> 00:21:02,880
And then how can this lead
to more intelligent agents

459
00:21:02,880 --> 00:21:04,650
and robots that can anticipate

460
00:21:04,650 --> 00:21:06,720
those futures and react to them?

461
00:21:06,720 --> 00:21:09,000
- How close are we to the matrix?

462
00:21:09,000 --> 00:21:09,833
- Yes, exactly.

463
00:21:09,833 --> 00:21:11,040
This is basically the matrix.

464
00:21:11,040 --> 00:21:12,870
We're far, I would say.

465
00:21:12,870 --> 00:21:15,300
So we have right now video models

466
00:21:15,300 --> 00:21:18,270
and image models that look
almost photorealistic,

467
00:21:18,270 --> 00:21:21,600
but the kind of the physics
behind them is not quite there.

468
00:21:21,600 --> 00:21:24,330
So if you look at the, you
know, very latest video models,

469
00:21:24,330 --> 00:21:26,580
like there's one from OpenAI called Sora.

470
00:21:26,580 --> 00:21:28,590
Every frame is almost perfect,

471
00:21:28,590 --> 00:21:32,370
but there's a famous example
of people digging a hole

472
00:21:32,370 --> 00:21:36,330
on the beach and pulling up
a beach chair outta that hole

473
00:21:36,330 --> 00:21:38,310
and the sand is kind of
flowing around the beach chair,

474
00:21:38,310 --> 00:21:42,630
but then the beach chair is
kind of congealing out of sand

475
00:21:42,630 --> 00:21:44,430
and an extra leg is being formed

476
00:21:44,430 --> 00:21:45,900
and then it's just not physical.

477
00:21:45,900 --> 00:21:47,550
So every frame is almost right,

478
00:21:47,550 --> 00:21:49,500
but the actual world is
not physically modeled

479
00:21:49,500 --> 00:21:51,783
accurately enough that you could really,

480
00:21:52,620 --> 00:21:55,890
you know, make predictions
that are the robustness

481
00:21:55,890 --> 00:21:57,990
and quality necessary for control.

482
00:21:57,990 --> 00:21:59,160
So I don't think we're at the point

483
00:21:59,160 --> 00:22:01,200
where you could train
a robot in the matrix,

484
00:22:01,200 --> 00:22:03,360
but we're heading there pretty rapidly.

485
00:22:03,360 --> 00:22:06,540
- Well, right now the methods we have

486
00:22:06,540 --> 00:22:10,470
for generative AI are
primarily statistically-driven

487
00:22:10,470 --> 00:22:13,050
and this means they do
not understand physics.

488
00:22:13,050 --> 00:22:15,450
So, what is the community doing

489
00:22:15,450 --> 00:22:18,360
to bring physics into these models?

490
00:22:18,360 --> 00:22:20,160
- There's a lot of interest in this.

491
00:22:20,160 --> 00:22:24,390
I think one approach is
just to say, well, big data

492
00:22:24,390 --> 00:22:27,120
and big compute solved a lot of things

493
00:22:27,120 --> 00:22:28,260
that we didn't expect it to solve.

494
00:22:28,260 --> 00:22:31,350
So maybe if you just scale
up statistics even more,

495
00:22:31,350 --> 00:22:36,180
eventually a causal model
will pop out somehow

496
00:22:36,180 --> 00:22:38,520
and that can happen in
certain circumstances.

497
00:22:38,520 --> 00:22:41,280
But you know, one,
there's more speculative,

498
00:22:41,280 --> 00:22:43,530
we haven't seen that fully happen yet.

499
00:22:43,530 --> 00:22:46,380
Another approach is to inject

500
00:22:46,380 --> 00:22:48,720
some kind of physical constraints

501
00:22:48,720 --> 00:22:51,990
and mechanisms into your
modeling assumptions.

502
00:22:51,990 --> 00:22:55,350
And one of the areas I'm kind
of interested in right now is

503
00:22:55,350 --> 00:22:57,570
take some classical physics simulator,

504
00:22:57,570 --> 00:23:00,090
like a computer graphics
engine, a video game

505
00:23:00,090 --> 00:23:02,160
and augment it with generative AI.

506
00:23:02,160 --> 00:23:03,510
So you have this hybrid system

507
00:23:03,510 --> 00:23:05,070
that has an underlying physics engine,

508
00:23:05,070 --> 00:23:06,630
which we understand very well,

509
00:23:06,630 --> 00:23:08,670
but it's been rendered with generative AI

510
00:23:08,670 --> 00:23:10,320
to make it show more diversity

511
00:23:10,320 --> 00:23:13,080
and use all the power of
data-driven methods as well.

512
00:23:13,080 --> 00:23:15,633
- The other thing you can do
is you can take the output

513
00:23:15,633 --> 00:23:19,170
of a generative AI system
and pass it through-

514
00:23:19,170 --> 00:23:20,233
- Yes.

515
00:23:20,233 --> 00:23:24,480
- A simulator that verifies
whether the physical constraints

516
00:23:24,480 --> 00:23:28,770
of the task or of the query have been met.

517
00:23:28,770 --> 00:23:31,020
- Yeah, definitely and that
connects back to Armando

518
00:23:31,020 --> 00:23:33,090
with code verification.

519
00:23:33,090 --> 00:23:35,580
You could verify with
classical simulation.

520
00:23:35,580 --> 00:23:38,610
You could also verify by having an agent

521
00:23:38,610 --> 00:23:39,600
that interacts in the world.

522
00:23:39,600 --> 00:23:42,930
So you know, if the hope
is that we will have robots

523
00:23:42,930 --> 00:23:44,880
that have models of the world around them,

524
00:23:44,880 --> 00:23:46,920
then one way to verify
if the model's correct is

525
00:23:46,920 --> 00:23:49,200
the robot takes an action
and it sees what happened

526
00:23:49,200 --> 00:23:51,210
and it gets feedback as to
whether it's predictions

527
00:23:51,210 --> 00:23:52,560
and model were correct.

528
00:23:52,560 --> 00:23:54,960
- Is the big, you know, I don't know,

529
00:23:54,960 --> 00:23:55,980
killer application here,

530
00:23:55,980 --> 00:23:59,040
is it in entertainment
like video games, AR, VR?

531
00:23:59,040 --> 00:24:01,680
Or is it on the robotic
side or what are you seeing?

532
00:24:01,680 --> 00:24:05,997
- Yeah, I think that the current
color app is entertainment

533
00:24:05,997 --> 00:24:08,760
and that's been the case for a few years.

534
00:24:08,760 --> 00:24:10,830
Everybody had a lot of fun making images

535
00:24:10,830 --> 00:24:13,530
of their making storybooks
for their children

536
00:24:13,530 --> 00:24:15,540
or sharing funny photos online.

537
00:24:15,540 --> 00:24:18,180
And I think there's a lot of
applications in entertainment

538
00:24:18,180 --> 00:24:19,890
and Hollywood and video games.

539
00:24:19,890 --> 00:24:22,140
But the one that is a little
bit more future looking

540
00:24:22,140 --> 00:24:25,530
and that I'm even more excited
about is using these models

541
00:24:25,530 --> 00:24:28,860
of the world as a substrate
for intelligent agents,

542
00:24:28,860 --> 00:24:30,780
for robotics, for systems

543
00:24:30,780 --> 00:24:33,960
that really understand
physicality, causality

544
00:24:33,960 --> 00:24:36,472
that are not just statistical
correlation machines,

545
00:24:36,472 --> 00:24:39,072
but actually have a deeper
understanding of reality.

546
00:24:39,930 --> 00:24:44,930
- And perhaps a closer
opportunity is in manufacturing

547
00:24:45,720 --> 00:24:49,050
in using these approaches to do design

548
00:24:49,050 --> 00:24:52,440
and fabrication using AI methods.

549
00:24:52,440 --> 00:24:54,570
That's the one I'm very excited about.

550
00:24:54,570 --> 00:24:56,340
- Yeah, definitely.

551
00:24:56,340 --> 00:24:58,860
- Any reactions to kind
of, what's the timeframe

552
00:24:58,860 --> 00:25:01,650
for this being big in robotics?

553
00:25:01,650 --> 00:25:06,240
- It's already transforming
robotics in big ways.

554
00:25:06,240 --> 00:25:09,270
I mean we used to think about intelligence

555
00:25:09,270 --> 00:25:11,460
as connecting perception

556
00:25:11,460 --> 00:25:15,570
and action going from pixels to control,

557
00:25:15,570 --> 00:25:18,780
but now with large
language models we have,

558
00:25:18,780 --> 00:25:20,940
and especially multimodal models

559
00:25:20,940 --> 00:25:24,150
that have both vision components

560
00:25:24,150 --> 00:25:26,100
and language components.

561
00:25:26,100 --> 00:25:30,450
We are moving fast forward.

562
00:25:30,450 --> 00:25:32,073
So, what do I mean by this?

563
00:25:33,030 --> 00:25:35,850
You can train a robot

564
00:25:35,850 --> 00:25:38,970
to associate pixels with action.

565
00:25:38,970 --> 00:25:43,970
For instance, you can train
a robot car to avoid trees

566
00:25:44,100 --> 00:25:46,830
by showing it a lot of pictures of trees

567
00:25:46,830 --> 00:25:50,490
and then the car will learn
how to go around the trees.

568
00:25:50,490 --> 00:25:52,860
Now in the past, if you wanted that robot

569
00:25:52,860 --> 00:25:57,000
to also avoid benches
and people and buildings,

570
00:25:57,000 --> 00:26:00,000
you'd have to show the
robot a lot of pictures

571
00:26:00,000 --> 00:26:02,130
of benches and pictures of trees

572
00:26:02,130 --> 00:26:05,610
and pictures of buildings.

573
00:26:05,610 --> 00:26:08,520
But now with language, we don't have to go

574
00:26:08,520 --> 00:26:11,310
through this additional training step.

575
00:26:11,310 --> 00:26:15,180
We can say, okay, you have
learned how to avoid trees,

576
00:26:15,180 --> 00:26:17,940
now also avoid people and buildings

577
00:26:17,940 --> 00:26:21,000
and benches and animals
and anything you want.

578
00:26:21,000 --> 00:26:24,780
And this actually gives us much faster way

579
00:26:24,780 --> 00:26:26,430
of training models.

580
00:26:26,430 --> 00:26:29,850
And it also gives us a wider set

581
00:26:29,850 --> 00:26:34,440
of generalizable actions
that are available to robots

582
00:26:34,440 --> 00:26:38,880
through the use of multimodal models.

583
00:26:38,880 --> 00:26:41,970
It's not just about morphology

584
00:26:41,970 --> 00:26:45,180
and angles, it's also
about forces and torques

585
00:26:45,180 --> 00:26:48,810
and what is needed to have the
interaction with the world.

586
00:26:48,810 --> 00:26:50,430
And so for this reason,

587
00:26:50,430 --> 00:26:54,240
watching videos only will
not take us to a world

588
00:26:54,240 --> 00:26:56,010
where robots will know for sure

589
00:26:56,010 --> 00:26:58,230
how to interact with the world.

590
00:26:58,230 --> 00:27:00,930
We would need force data, torque data.

591
00:27:00,930 --> 00:27:03,690
We would need to know
exactly if you pick up

592
00:27:03,690 --> 00:27:06,150
a picture of water, what are those forces

593
00:27:06,150 --> 00:27:10,410
and torques that are on your
joints and on your muscles.

594
00:27:10,410 --> 00:27:14,130
And because without that we
can generate fantastical videos

595
00:27:14,130 --> 00:27:16,260
that show the correct kinematics,

596
00:27:16,260 --> 00:27:18,300
but do not have the correct dynamics.

597
00:27:18,300 --> 00:27:20,730
And so when it comes to
learning the dynamics

598
00:27:20,730 --> 00:27:24,990
of interaction, we have
extraordinary possibilities,

599
00:27:24,990 --> 00:27:29,250
but also challenges because
there isn't enough data.

600
00:27:29,250 --> 00:27:32,520
However, we are beginning
to see research groups

601
00:27:32,520 --> 00:27:35,910
that are forming the kind
of comprehensive data sets

602
00:27:35,910 --> 00:27:39,510
that will really help
us get robots to learn

603
00:27:39,510 --> 00:27:43,920
how to be in the world in
a dynamically coherent way.

604
00:27:43,920 --> 00:27:45,600
- How to use the right data,

605
00:27:45,600 --> 00:27:47,940
especially now that AI is
generating its own data

606
00:27:47,940 --> 00:27:48,930
in some ways?

607
00:27:48,930 --> 00:27:52,230
- We have technical solutions
for de-biasing data sets.

608
00:27:52,230 --> 00:27:54,750
We can apply algorithms to dataset

609
00:27:54,750 --> 00:27:58,560
and decide whether the data
set is biased with respect

610
00:27:58,560 --> 00:28:02,670
to a certain range of parameters or not.

611
00:28:02,670 --> 00:28:07,110
And so, then you can have a
data set that is not biased.

612
00:28:07,110 --> 00:28:10,400
- I agree, I think one of the
really interesting promises

613
00:28:10,400 --> 00:28:13,740
of synthetic data, so generative
models, they make this new,

614
00:28:13,740 --> 00:28:16,770
you know, fake data and
sometimes it comes across

615
00:28:16,770 --> 00:28:19,800
as that it's gonna be some worst version

616
00:28:19,800 --> 00:28:21,270
of the original data
that you started with.

617
00:28:21,270 --> 00:28:23,820
It's gonna be a cheap proxy,
it's gonna have artifacts,

618
00:28:23,820 --> 00:28:25,680
hallucinations, and that can be true.

619
00:28:25,680 --> 00:28:26,880
There can be these downsides.

620
00:28:26,880 --> 00:28:30,570
But one thing I'm excited about
is that by modeling the data

621
00:28:30,570 --> 00:28:33,510
and producing new data
from it, you can intervene

622
00:28:33,510 --> 00:28:36,240
and change the data distribution.

623
00:28:36,240 --> 00:28:38,130
And I think this is exactly
what Daniela was talking about.

624
00:28:38,130 --> 00:28:41,280
You can remove certain
biases by intervening

625
00:28:41,280 --> 00:28:44,130
and we have technical tools
that can help us there.

626
00:28:44,130 --> 00:28:47,340
You can say that there's
a rare part of the data

627
00:28:47,340 --> 00:28:49,560
that you want to represent better.

628
00:28:49,560 --> 00:28:50,730
Maybe it's a rare disease

629
00:28:50,730 --> 00:28:52,020
and you really wanna study that disease

630
00:28:52,020 --> 00:28:54,810
and you can over sample that
part of the distribution.

631
00:28:54,810 --> 00:28:57,630
So by synthetic data to me is data

632
00:28:57,630 --> 00:28:59,190
that has more opportunity.

633
00:28:59,190 --> 00:29:01,830
You can change it, you
can make it less toxic

634
00:29:01,830 --> 00:29:03,960
if that's what matters
for your application.

635
00:29:03,960 --> 00:29:05,190
- The field has produced

636
00:29:05,190 --> 00:29:09,780
all of these different technical
tools that each can be used

637
00:29:09,780 --> 00:29:11,940
to push the model in certain directions

638
00:29:11,940 --> 00:29:14,340
to achieve particular kinds of balance.

639
00:29:14,340 --> 00:29:17,010
But at the end of the day
for a lot of these questions,

640
00:29:17,010 --> 00:29:20,227
there is this deeper
higher-level question of,

641
00:29:20,227 --> 00:29:22,710
"What are you actually
trying to achieve, right?"

642
00:29:22,710 --> 00:29:26,083
And what is the thing that you're trying

643
00:29:26,083 --> 00:29:28,680
to optimize the model for?

644
00:29:28,680 --> 00:29:30,543
And I think making sure that,

645
00:29:31,877 --> 00:29:35,880
when higher-level applications
are being designed,

646
00:29:35,880 --> 00:29:38,028
it's not just about
having all of these tools

647
00:29:38,028 --> 00:29:42,217
at your fingertips, it's
about deciding, you know,

648
00:29:42,217 --> 00:29:44,460
"What are the parameters
that are really important

649
00:29:44,460 --> 00:29:45,780
for these applications?

650
00:29:45,780 --> 00:29:48,720
What are the possible failure modes?"

651
00:29:48,720 --> 00:29:52,440
And traditionally the way we've thought

652
00:29:52,440 --> 00:29:56,370
of computer systems is as,
you know, the kind of system

653
00:29:56,370 --> 00:29:59,460
where you have a specification
and you can design it

654
00:29:59,460 --> 00:30:02,790
and you produce something that
satisfies the specification

655
00:30:02,790 --> 00:30:05,460
and then, you know, it works.

656
00:30:05,460 --> 00:30:08,730
With a lot of these
learning-based systems,

657
00:30:08,730 --> 00:30:11,550
I think there's a much
bigger need of the kind

658
00:30:11,550 --> 00:30:13,620
of empirical validation

659
00:30:13,620 --> 00:30:17,370
and empirical testing that
oftentimes doesn't come quite

660
00:30:17,370 --> 00:30:20,400
as natural to people in our community,

661
00:30:20,400 --> 00:30:24,330
but it is absolutely essential
to make sure that the systems

662
00:30:24,330 --> 00:30:26,940
that get deployed actually
do what they're supposed

663
00:30:26,940 --> 00:30:30,420
to do when they're out
in the world being used

664
00:30:30,420 --> 00:30:32,130
by real people.

665
00:30:32,130 --> 00:30:33,870
- Just quick question on deep fakes.

666
00:30:33,870 --> 00:30:37,470
So are you doing anything
to protect us from this?

667
00:30:37,470 --> 00:30:38,310
- Two things have changed.

668
00:30:38,310 --> 00:30:41,003
So one is that the synthetic images

669
00:30:41,003 --> 00:30:43,740
and videos now have
gotten so good that a lot

670
00:30:43,740 --> 00:30:46,350
of the techniques that we were
developing a few years ago

671
00:30:46,350 --> 00:30:48,240
just don't work on the current models.

672
00:30:48,240 --> 00:30:50,100
And so it's a constant arms races

673
00:30:50,100 --> 00:30:51,810
and I do think that it's important

674
00:30:51,810 --> 00:30:52,830
that people keep up with that.

675
00:30:52,830 --> 00:30:54,990
We have detectors for the latest models,

676
00:30:54,990 --> 00:30:57,630
but it was kind of a grind
to keep going through that.

677
00:30:57,630 --> 00:31:00,990
And the other thing that was
has been interesting is that,

678
00:31:00,990 --> 00:31:03,780
even though these deep
fakes have the potential

679
00:31:03,780 --> 00:31:05,880
for creating a lot of misinformation

680
00:31:05,880 --> 00:31:09,330
and for us losing, you
know, touch with reality,

681
00:31:09,330 --> 00:31:11,880
it seems like we've as a society started

682
00:31:11,880 --> 00:31:15,990
to develop other types
of, you know, antidotes

683
00:31:15,990 --> 00:31:18,810
to some of that by maybe not trusting

684
00:31:18,810 --> 00:31:19,890
as much what we see online.

685
00:31:19,890 --> 00:31:22,020
I know that people still
probably trust too much

686
00:31:22,020 --> 00:31:24,810
what they see online, but I currently feel

687
00:31:24,810 --> 00:31:28,230
that socio-technical and
policy-level interventions are

688
00:31:28,230 --> 00:31:29,760
probably gonna be more effective

689
00:31:29,760 --> 00:31:31,710
at dealing with the advent of deep fakes.

690
00:31:31,710 --> 00:31:34,603
And we might have to, you
know, look at the signature

691
00:31:34,603 --> 00:31:38,010
of a piece of media and
not just trust the pixels,

692
00:31:38,010 --> 00:31:40,170
you know, seen as not
necessarily gonna be believing.

693
00:31:40,170 --> 00:31:42,000
And so even though there
are some technical solutions

694
00:31:42,000 --> 00:31:44,600
on detecting deep fakes
algorithmically, it might be

695
00:31:44,600 --> 00:31:47,340
that socio-technical and
policy-level interventions are

696
00:31:47,340 --> 00:31:48,173
more effective.

697
00:31:49,170 --> 00:31:52,680
- It's such an exciting
moment for generative AI

698
00:31:52,680 --> 00:31:54,720
and for AI in general.

699
00:31:54,720 --> 00:31:58,800
And the research that is
happening at CSAIL covers

700
00:31:58,800 --> 00:32:02,010
a lot of the foundational
aspects of AI that need

701
00:32:02,010 --> 00:32:04,650
to be developed in order
for this technology

702
00:32:04,650 --> 00:32:07,770
to be applicable to its full potential.

703
00:32:07,770 --> 00:32:10,710
At the same time, it's
important for us to remember

704
00:32:10,710 --> 00:32:14,310
that generative AI is just one component

705
00:32:14,310 --> 00:32:18,870
of the AI ecosystem.

706
00:32:18,870 --> 00:32:22,050
In AI, we have predictive
and classifying AI.

707
00:32:22,050 --> 00:32:23,535
We have generative AI,

708
00:32:23,535 --> 00:32:25,950
we have optimizing AI.

709
00:32:25,950 --> 00:32:27,810
We have deciding AI

710
00:32:27,810 --> 00:32:30,990
and most business problems
are at the intersection

711
00:32:30,990 --> 00:32:35,910
of solutions across these
different set of techniques.

712
00:32:35,910 --> 00:32:38,370
And we will talk more about this

713
00:32:38,370 --> 00:32:42,240
and about how generative AI
combines with other kinds

714
00:32:42,240 --> 00:32:45,630
of AI at the future Office Hours.

715
00:32:45,630 --> 00:32:48,480
For now, thank you very
much for joining us

716
00:32:48,480 --> 00:32:51,333
and see you at the next
CSAIL Office Hours.


1
00:00:13,519 --> 00:00:19,680
All right, we'll get started. Um, what I

2
00:00:16,880 --> 00:00:22,560
wanted to do today was to make sure we

3
00:00:19,680 --> 00:00:25,519
thoroughly cover the theory and

4
00:00:22,560 --> 00:00:31,840
application of regression modeling. And

5
00:00:25,519 --> 00:00:35,600
so um to begin there's a recap which is

6
00:00:31,840 --> 00:00:38,600
the theory for if we have linear

7
00:00:35,600 --> 00:00:38,600
regression

8
00:00:42,000 --> 00:00:47,440
and we have in particular

9
00:00:45,280 --> 00:00:51,680
a normal

10
00:00:47,440 --> 00:00:57,120
linear regression model. Then uh we have

11
00:00:51,680 --> 00:01:00,800
these properties of uh beta hat being

12
00:00:57,120 --> 00:01:03,359
distributed as a multi-normal

13
00:01:00,800 --> 00:01:07,040
random

14
00:01:03,359 --> 00:01:09,760
uh variable with mean the true

15
00:01:07,040 --> 00:01:15,200
regression parameter and coariance

16
00:01:09,760 --> 00:01:18,000
matrix given by the xrpose x inverse

17
00:01:15,200 --> 00:01:21,840
multiplied by sigma squared.

18
00:01:18,000 --> 00:01:24,320
And we also have that epsilon hat is a

19
00:01:21,840 --> 00:01:26,960
multinnormal distribution.

20
00:01:24,320 --> 00:01:31,840
It's actually not a full rank but it's

21
00:01:26,960 --> 00:01:34,960
in n dimensions with mean zero a zero

22
00:01:31,840 --> 00:01:39,200
vector. And the covariance matrix is

23
00:01:34,960 --> 00:01:44,960
sigma squar times the identity minus the

24
00:01:39,200 --> 00:01:49,840
hat matrix. And with these properties

25
00:01:44,960 --> 00:01:52,000
um we can show that they are independent

26
00:01:49,840 --> 00:01:54,720
random variables if we have the normal

27
00:01:52,000 --> 00:01:57,119
model assumption. So these are

28
00:01:54,720 --> 00:02:03,799
independent

29
00:01:57,119 --> 00:02:03,799
if the error vector is multinnormal.

30
00:02:05,119 --> 00:02:10,479
And

31
00:02:06,640 --> 00:02:14,160
with that um we're able to get an

32
00:02:10,479 --> 00:02:18,959
estimate of the error variance very

33
00:02:14,160 --> 00:02:22,640
easily from the residual vector. uh the

34
00:02:18,959 --> 00:02:25,440
sum of squares of the residual vector

35
00:02:22,640 --> 00:02:28,879
can be solved for having expectation

36
00:02:25,440 --> 00:02:32,239
equal to n minus p sigma^ 2 and that

37
00:02:28,879 --> 00:02:34,160
leads to dividing the sum of squared

38
00:02:32,239 --> 00:02:37,440
residuals by n minus p to get an

39
00:02:34,160 --> 00:02:39,200
unbiased estimate. Now what's

40
00:02:37,440 --> 00:02:44,080
interesting

41
00:02:39,200 --> 00:02:47,440
uh mathematically is that um because

42
00:02:44,080 --> 00:02:50,080
this estimate of the error variance

43
00:02:47,440 --> 00:02:53,840
depends on the residuals which are

44
00:02:50,080 --> 00:02:57,760
independent of beta hat. We can then use

45
00:02:53,840 --> 00:03:03,920
this information to construct tstistics

46
00:02:57,760 --> 00:03:07,920
for the le squares estimates. So we have

47
00:03:03,920 --> 00:03:10,920
uh t statistics

48
00:03:07,920 --> 00:03:10,920
for

49
00:03:11,040 --> 00:03:18,319
the j component

50
00:03:15,760 --> 00:03:22,640
of the le squares estimate. So beta hat

51
00:03:18,319 --> 00:03:25,120
subj minus beta j

52
00:03:22,640 --> 00:03:27,440
divided by

53
00:03:25,120 --> 00:03:29,519
sigma hat

54
00:03:27,440 --> 00:03:37,440
cj

55
00:03:29,519 --> 00:03:41,280
where cj is the uh jth diagonal entry of

56
00:03:37,440 --> 00:03:43,360
the variance inverse variance and

57
00:03:41,280 --> 00:03:47,680
actually this cj

58
00:03:43,360 --> 00:03:52,400
should be equal to the square root

59
00:03:47,680 --> 00:03:55,360
of xrpose x inverse subj.

60
00:03:52,400 --> 00:03:58,319
So there's a square root missing there.

61
00:03:55,360 --> 00:04:00,879
Um and

62
00:03:58,319 --> 00:04:04,560
this distribution

63
00:04:00,879 --> 00:04:08,000
under the normal linear model has or

64
00:04:04,560 --> 00:04:09,519
this test this formula has a t

65
00:04:08,000 --> 00:04:12,159
distribution.

66
00:04:09,519 --> 00:04:16,400
So this is distributed

67
00:04:12,159 --> 00:04:19,120
as a t distribution with n minus p

68
00:04:16,400 --> 00:04:22,560
degrees of freedom.

69
00:04:19,120 --> 00:04:25,199
Degrees of freedom equal to n minus p.

70
00:04:22,560 --> 00:04:28,400
And this is true

71
00:04:25,199 --> 00:04:30,560
if we plug in the true

72
00:04:28,400 --> 00:04:34,479
beta j.

73
00:04:30,560 --> 00:04:37,440
So normal or or centering our le squares

74
00:04:34,479 --> 00:04:42,960
estimate at beta j allows us to write

75
00:04:37,440 --> 00:04:44,960
that out. So if we look at our beta hat

76
00:04:42,960 --> 00:04:47,680
value

77
00:04:44,960 --> 00:04:50,479
and consider it

78
00:04:47,680 --> 00:04:54,960
around the true beta j, we basically

79
00:04:50,479 --> 00:04:58,479
have a t distribution for the outcome.

80
00:04:54,960 --> 00:05:01,440
And why this becomes very useful is that

81
00:04:58,479 --> 00:05:04,960
if we want to test the hypothesis that

82
00:05:01,440 --> 00:05:09,039
beta j is equal to zero

83
00:05:04,960 --> 00:05:10,800
then if this is

84
00:05:09,039 --> 00:05:14,479
zero

85
00:05:10,800 --> 00:05:17,520
um we can basically define

86
00:05:14,479 --> 00:05:20,240
a an interval

87
00:05:17,520 --> 00:05:24,759
around zero

88
00:05:20,240 --> 00:05:24,759
and consider rejecting

89
00:05:25,039 --> 00:05:33,039
the null hypothesis if our t hat with

90
00:05:29,360 --> 00:05:35,840
beta j equaling zero in magnitude is

91
00:05:33,039 --> 00:05:38,160
greater than some critical value say

92
00:05:35,840 --> 00:05:43,759
some constant c

93
00:05:38,160 --> 00:05:47,919
and um so so this t statistic is

94
00:05:43,759 --> 00:05:50,080
commonly applied uh in judging different

95
00:05:47,919 --> 00:05:52,400
regression models

96
00:05:50,080 --> 00:05:55,280
of particular interest is whether

97
00:05:52,400 --> 00:05:56,800
factors can be excluded from the

98
00:05:55,280 --> 00:06:00,160
regression.

99
00:05:56,800 --> 00:06:02,080
So if a beta j component is equal to

100
00:06:00,160 --> 00:06:03,759
zero that means we can just exclude the

101
00:06:02,080 --> 00:06:08,479
variable.

102
00:06:03,759 --> 00:06:10,800
Now interestingly if we want to test

103
00:06:08,479 --> 00:06:14,880
whether

104
00:06:10,800 --> 00:06:18,240
multiple beta js are equal to zero. A

105
00:06:14,880 --> 00:06:23,199
special case of that is just to say

106
00:06:18,240 --> 00:06:25,440
let's assume that the first k beta j's

107
00:06:23,199 --> 00:06:28,160
are non zero.

108
00:06:25,440 --> 00:06:32,560
We'll just assume that that's true. But

109
00:06:28,160 --> 00:06:36,479
let's test whether the beta js for j

110
00:06:32,560 --> 00:06:40,319
above k are equal to zero. And what we

111
00:06:36,479 --> 00:06:43,199
can do is calculate

112
00:06:40,319 --> 00:06:46,560
residuals under

113
00:06:43,199 --> 00:06:50,880
the two hypotheses.

114
00:06:46,560 --> 00:06:53,840
First assuming that they're all nonzero,

115
00:06:50,880 --> 00:06:57,039
we get an RSS1.

116
00:06:53,840 --> 00:07:00,400
But if we assume the submodel is true,

117
00:06:57,039 --> 00:07:02,160
we can get a second set of residuals.

118
00:07:00,400 --> 00:07:08,319
And

119
00:07:02,160 --> 00:07:11,199
because the full model is more um sort

120
00:07:08,319 --> 00:07:13,840
of it minimizes the sum of squares

121
00:07:11,199 --> 00:07:16,800
further, we can look at the difference

122
00:07:13,840 --> 00:07:20,400
in residual sum of squares.

123
00:07:16,800 --> 00:07:23,120
Normalize that by p minus k and compare

124
00:07:20,400 --> 00:07:25,840
that with the residual sum of squares

125
00:07:23,120 --> 00:07:28,319
under the full model divided by n minus

126
00:07:25,840 --> 00:07:31,120
p. So this is an estimate of sigma

127
00:07:28,319 --> 00:07:33,599
squared using the full model. This

128
00:07:31,120 --> 00:07:37,520
numerator is also an estimate of sigma

129
00:07:33,599 --> 00:07:39,440
squared based on the uh null hypothesis

130
00:07:37,520 --> 00:07:43,680
being true.

131
00:07:39,440 --> 00:07:47,520
Now um what's interesting to highlight

132
00:07:43,680 --> 00:07:52,639
is that the F test

133
00:07:47,520 --> 00:07:56,000
when K the number of non zero

134
00:07:52,639 --> 00:07:58,800
coefficients is P minus one then this F

135
00:07:56,000 --> 00:08:03,280
test corresponds to testing whether the

136
00:07:58,800 --> 00:08:06,080
P beta J is equal to zero. And so it

137
00:08:03,280 --> 00:08:10,560
turns out that

138
00:08:06,080 --> 00:08:15,440
um if we have t

139
00:08:10,560 --> 00:08:18,479
sorry t hat yeah p of beta

140
00:08:15,440 --> 00:08:23,360
uh of the true beta

141
00:08:18,479 --> 00:08:25,680
the beta with beta p equal to zero.

142
00:08:23,360 --> 00:08:28,720
um this

143
00:08:25,680 --> 00:08:31,720
squared is actually equal to this F

144
00:08:28,720 --> 00:08:31,720
statistic.

145
00:08:33,519 --> 00:08:39,360
Um I'm just going to

146
00:08:37,120 --> 00:08:43,519
there's a huge rumbling in the room

147
00:08:39,360 --> 00:08:45,360
right now and uh if anyone finds out

148
00:08:43,519 --> 00:08:48,160
that it's something serious we should be

149
00:08:45,360 --> 00:08:50,800
thinking about please let me know or let

150
00:08:48,160 --> 00:08:53,680
the whole class know.

151
00:08:50,800 --> 00:08:56,000
It sort of sounds like an earthquake. uh

152
00:08:53,680 --> 00:08:58,880
which which I experienced when I was at

153
00:08:56,000 --> 00:09:01,200
UC Berkeley. Um

154
00:08:58,880 --> 00:09:03,279
anyway, all right. Well, we'll I'll

155
00:09:01,200 --> 00:09:06,000
continue unless I get warnings from you

156
00:09:03,279 --> 00:09:08,160
all. Anyway, it turns out that this T

157
00:09:06,000 --> 00:09:12,399
squared statistic is actually equal to

158
00:09:08,160 --> 00:09:14,800
the F test formalized here. So, F tests

159
00:09:12,399 --> 00:09:18,160
um are very useful in special cases.

160
00:09:14,800 --> 00:09:19,920
They're equivalent to uh the square of a

161
00:09:18,160 --> 00:09:24,880
t

162
00:09:19,920 --> 00:09:29,360
a t test statistic. Now let's see

163
00:09:24,880 --> 00:09:34,720
with um the notes from last time we went

164
00:09:29,360 --> 00:09:39,920
through these um we uh highlighted

165
00:09:34,720 --> 00:09:42,720
how um with generalized le squares

166
00:09:39,920 --> 00:09:46,279
this is another key takeaway in

167
00:09:42,720 --> 00:09:46,279
regression modeling.

168
00:09:46,560 --> 00:09:51,200
So,

169
00:09:48,480 --> 00:09:53,680
so generalized

170
00:09:51,200 --> 00:09:57,680
le squares

171
00:09:53,680 --> 00:10:01,279
with generalized le squares we have an

172
00:09:57,680 --> 00:10:06,000
error vector which is not

173
00:10:01,279 --> 00:10:09,519
uh a a diagonal identity

174
00:10:06,000 --> 00:10:11,200
time sigma squared but

175
00:10:09,519 --> 00:10:15,200
it's

176
00:10:11,200 --> 00:10:17,200
some base matrix sigma times little

177
00:10:15,200 --> 00:10:20,959
sigma squared

178
00:10:17,200 --> 00:10:26,399
And with this setup, we can actually

179
00:10:20,959 --> 00:10:28,720
transform this regression model into one

180
00:10:26,399 --> 00:10:30,240
which satisfies our Gaus Marov

181
00:10:28,720 --> 00:10:35,200
assumptions.

182
00:10:30,240 --> 00:10:40,079
And then so with xstar and yar being the

183
00:10:35,200 --> 00:10:44,079
model equation multiplied by the inverse

184
00:10:40,079 --> 00:10:46,800
square root of sigma then

185
00:10:44,079 --> 00:10:50,160
this model satisfies the gaus markov

186
00:10:46,800 --> 00:10:53,120
assumptions zero mean constant variance

187
00:10:50,160 --> 00:10:56,000
and so this estimator

188
00:10:53,120 --> 00:10:59,360
uh with the x stars and y stars but the

189
00:10:56,000 --> 00:11:02,880
same beta gives us our best estimate of

190
00:10:59,360 --> 00:11:04,959
the beta a hat best in terms of minimum

191
00:11:02,880 --> 00:11:07,440
being unbiased and having smallest

192
00:11:04,959 --> 00:11:12,160
variance.

193
00:11:07,440 --> 00:11:14,399
Okay. Well, uh, a next

194
00:11:12,160 --> 00:11:17,600
important

195
00:11:14,399 --> 00:11:19,680
aspect of regression model modeling is

196
00:11:17,600 --> 00:11:22,680
looking at maximum likelihood

197
00:11:19,680 --> 00:11:22,680
estimation,

198
00:11:25,519 --> 00:11:33,760
MLE.

199
00:11:28,480 --> 00:11:37,440
And for maximum likelihood estimation we

200
00:11:33,760 --> 00:11:42,480
use the probability model

201
00:11:37,440 --> 00:11:46,000
of the regression which in this case is

202
00:11:42,480 --> 00:11:48,480
normal linear regression models. So if

203
00:11:46,000 --> 00:11:54,480
we have normal

204
00:11:48,480 --> 00:12:00,320
normal epsilon vector um then we compute

205
00:11:54,480 --> 00:12:04,240
the density of our data y given the

206
00:12:00,320 --> 00:12:06,079
explanatory variables in x and the beta

207
00:12:04,240 --> 00:12:09,680
uh

208
00:12:06,079 --> 00:12:14,560
regression parameter uh beta that should

209
00:12:09,680 --> 00:12:17,279
be a beta there and uh we simply

210
00:12:14,560 --> 00:12:21,360
identify by those parameter values that

211
00:12:17,279 --> 00:12:23,839
maximize this probability. So we're

212
00:12:21,360 --> 00:12:26,959
looking at the parameter values that

213
00:12:23,839 --> 00:12:28,480
make the data we observed the most

214
00:12:26,959 --> 00:12:31,839
likely

215
00:12:28,480 --> 00:12:34,560
and intuitively that's may be a

216
00:12:31,839 --> 00:12:36,880
reasonable thing. If you take

217
00:12:34,560 --> 00:12:39,760
mathematical statistics

218
00:12:36,880 --> 00:12:44,639
next term, you'll learn that that in

219
00:12:39,760 --> 00:12:48,079
fact is an optimal estimator in terms of

220
00:12:44,639 --> 00:12:51,120
having smallest variance

221
00:12:48,079 --> 00:12:54,639
in large samples as large as the sample

222
00:12:51,120 --> 00:12:58,240
size the number of cases n increases uh

223
00:12:54,639 --> 00:13:01,040
this will lead to the best estimator and

224
00:12:58,240 --> 00:13:03,920
this MLE

225
00:13:01,040 --> 00:13:07,519
for the best or the the best estimator

226
00:13:03,920 --> 00:13:10,000
being the MLE will be true for different

227
00:13:07,519 --> 00:13:13,120
distributions as well. We're going to

228
00:13:10,000 --> 00:13:14,880
show what it is for the Gaussian

229
00:13:13,120 --> 00:13:19,760
distribution.

230
00:13:14,880 --> 00:13:23,279
And what we can see on this slide is

231
00:13:19,760 --> 00:13:25,839
that the log of the likelihood

232
00:13:23,279 --> 00:13:27,519
is the log of this density on the top

233
00:13:25,839 --> 00:13:31,920
line.

234
00:13:27,519 --> 00:13:37,519
It can be equal to minus n /2 log sigma^

235
00:13:31,920 --> 00:13:40,720
2 minus a half sigma^ 2 q of beta where

236
00:13:37,519 --> 00:13:43,839
q of beta is our le squares criterion.

237
00:13:40,720 --> 00:13:46,639
So maximum likelihood estimation for

238
00:13:43,839 --> 00:13:50,320
normal linear regression models can

239
00:13:46,639 --> 00:13:56,160
proceed in two steps.

240
00:13:50,320 --> 00:13:58,399
First we can see that the beta

241
00:13:56,160 --> 00:14:02,399
regression coefficient enters in only

242
00:13:58,399 --> 00:14:05,839
through a factor of Q of beta. So

243
00:14:02,399 --> 00:14:08,320
minimizing Q of beta gives us the MLE

244
00:14:05,839 --> 00:14:11,760
for beta.

245
00:14:08,320 --> 00:14:15,440
And then once we have the MLE for beta,

246
00:14:11,760 --> 00:14:17,600
we can plug that into the likelihood,

247
00:14:15,440 --> 00:14:21,839
the log likelihood

248
00:14:17,600 --> 00:14:26,000
or the likelihood um for varying sigma

249
00:14:21,839 --> 00:14:31,440
squared. And when we do this, we

250
00:14:26,000 --> 00:14:35,680
actually can just maximize this uh sort

251
00:14:31,440 --> 00:14:38,560
of partial likelihood with beta fixed at

252
00:14:35,680 --> 00:14:40,720
beta hat. maximize that over sigma

253
00:14:38,560 --> 00:14:43,920
squared. And that turns out to be a very

254
00:14:40,720 --> 00:14:49,600
easy computation calculating the first

255
00:14:43,920 --> 00:14:52,240
order equation for the uh log likelihood

256
00:14:49,600 --> 00:14:55,279
and we get the maximum likelihood

257
00:14:52,240 --> 00:14:59,360
estimate is simply the sum of squared

258
00:14:55,279 --> 00:15:01,360
residuals divided by n. Now with maximum

259
00:14:59,360 --> 00:15:04,000
likelihood

260
00:15:01,360 --> 00:15:09,040
in this case we have actually a biased

261
00:15:04,000 --> 00:15:11,680
estimate of this error variance and um

262
00:15:09,040 --> 00:15:14,320
it's important just to to note that

263
00:15:11,680 --> 00:15:19,199
that's the case.

264
00:15:14,320 --> 00:15:25,040
All right. Um well what's interesting

265
00:15:19,199 --> 00:15:27,920
to generalize is to find estimators

266
00:15:25,040 --> 00:15:30,720
which minimize

267
00:15:27,920 --> 00:15:34,720
a Q function which may be different from

268
00:15:30,720 --> 00:15:39,199
least squares or sum of squares. And so

269
00:15:34,720 --> 00:15:44,639
we can consider a Q function which

270
00:15:39,199 --> 00:15:52,079
minimizes the sum of a function H

271
00:15:44,639 --> 00:15:54,800
evaluated at case I. So let's see here

272
00:15:52,079 --> 00:15:57,519
this down.

273
00:15:54,800 --> 00:16:00,519
So so

274
00:15:57,519 --> 00:16:00,519
with

275
00:16:01,360 --> 00:16:06,240
with generalized

276
00:16:04,320 --> 00:16:09,560
With generalized

277
00:16:06,240 --> 00:16:09,560
M estimators,

278
00:16:09,759 --> 00:16:16,800
we think of Q of beta being the sum one

279
00:16:13,199 --> 00:16:18,639
to N of H of Yi

280
00:16:16,800 --> 00:16:20,639
the Xi

281
00:16:18,639 --> 00:16:25,199
beta

282
00:16:20,639 --> 00:16:28,079
and sigma squared I guess. Um and the

283
00:16:25,199 --> 00:16:32,480
choice of H. Well, if we choose h to

284
00:16:28,079 --> 00:16:36,160
just be the square of the linear

285
00:16:32,480 --> 00:16:40,320
estimate of y given x i that's le

286
00:16:36,160 --> 00:16:43,839
squares. There's no reason in principle

287
00:16:40,320 --> 00:16:47,680
why we should use squares. We could use

288
00:16:43,839 --> 00:16:52,079
absolute deviations and sum those.

289
00:16:47,680 --> 00:16:53,680
And if we wanted maximum likelihood

290
00:16:52,079 --> 00:16:56,399
estimates,

291
00:16:53,680 --> 00:16:59,040
we could choose H to be minus the log of

292
00:16:56,399 --> 00:17:01,120
the density.

293
00:16:59,040 --> 00:17:03,519
And

294
00:17:01,120 --> 00:17:08,160
there are robust estimators in

295
00:17:03,519 --> 00:17:13,039
statistics. And these uh robust

296
00:17:08,160 --> 00:17:17,600
estimators uh con consider variations

297
00:17:13,039 --> 00:17:20,319
basically of lease squares and

298
00:17:17,600 --> 00:17:23,120
mean absolute deviations

299
00:17:20,319 --> 00:17:26,720
um as special cases that yield

300
00:17:23,120 --> 00:17:29,919
estimators that are robust. Now what's

301
00:17:26,720 --> 00:17:34,640
to me very interesting is that if we

302
00:17:29,919 --> 00:17:37,280
were to know what the density is of the

303
00:17:34,640 --> 00:17:40,640
errors then maximum likelihood

304
00:17:37,280 --> 00:17:44,000
estimation would say use that.

305
00:17:40,640 --> 00:17:47,600
When we don't know the distribution

306
00:17:44,000 --> 00:17:51,760
then these others may be

307
00:17:47,600 --> 00:17:56,000
very useful as alternatives and

308
00:17:51,760 --> 00:17:59,919
robust estimators um were originally

309
00:17:56,000 --> 00:18:02,960
proposed for models where we may have a

310
00:17:59,919 --> 00:18:06,000
normal distribution most of the time but

311
00:18:02,960 --> 00:18:09,200
some contamination distribution with

312
00:18:06,000 --> 00:18:11,760
large errors uh a small percentage of

313
00:18:09,200 --> 00:18:15,760
the time.

314
00:18:11,760 --> 00:18:19,600
Now um and another interesting example

315
00:18:15,760 --> 00:18:21,200
of this generalized M estimator is the

316
00:18:19,600 --> 00:18:23,120
quantile

317
00:18:21,200 --> 00:18:26,480
estimator

318
00:18:23,120 --> 00:18:28,240
where we consider sort of mean absolute

319
00:18:26,480 --> 00:18:34,400
deviation

320
00:18:28,240 --> 00:18:37,120
but we scale that for positive residuals

321
00:18:34,400 --> 00:18:41,440
by a factor tow

322
00:18:37,120 --> 00:18:45,200
and for negative values of the residual

323
00:18:41,440 --> 00:18:48,679
ual we scale the absolute deviation by 1

324
00:18:45,200 --> 00:18:48,679
minus toao.

325
00:18:50,160 --> 00:18:57,280
This uh h function

326
00:18:53,840 --> 00:19:03,200
uh basically is equivalent to

327
00:18:57,280 --> 00:19:05,919
the uh mean absolute deviation when tao

328
00:19:03,200 --> 00:19:09,360
is equal to 0.5.

329
00:19:05,919 --> 00:19:14,320
But when tow um

330
00:19:09,360 --> 00:19:17,120
is uh if we have h

331
00:19:14,320 --> 00:19:19,520
let's see

332
00:19:17,120 --> 00:19:25,440
so h of yx

333
00:19:19,520 --> 00:19:27,360
when this is equal to um to yi minus x i

334
00:19:25,440 --> 00:19:31,360
beta

335
00:19:27,360 --> 00:19:34,360
um when this is

336
00:19:31,360 --> 00:19:34,360
positive

337
00:19:34,480 --> 00:19:41,240
and it's equal to 1 minus toao when this

338
00:19:38,240 --> 00:19:41,240
is

339
00:19:41,520 --> 00:19:48,880
actually it's equal to uh minus this

340
00:19:46,000 --> 00:19:51,440
when this is less than zero.

341
00:19:48,880 --> 00:19:54,320
Then

342
00:19:51,440 --> 00:19:58,559
for example when TOAO is equal to 0.9

343
00:19:54,320 --> 00:20:02,480
this turns out to be um a a quantile

344
00:19:58,559 --> 00:20:06,000
estimate that is try working to estimate

345
00:20:02,480 --> 00:20:09,280
the 90th sort of percentile

346
00:20:06,000 --> 00:20:11,919
of outcomes. So when we have a

347
00:20:09,280 --> 00:20:17,120
regression model

348
00:20:11,919 --> 00:20:19,200
and we are sort of um it just if we have

349
00:20:17,120 --> 00:20:22,480
a bunch of points

350
00:20:19,200 --> 00:20:26,559
and we consider a linear regression

351
00:20:22,480 --> 00:20:28,880
model this would be you know y uh equal

352
00:20:26,559 --> 00:20:31,360
to

353
00:20:28,880 --> 00:20:34,880
or y hat equal to sort of the mean

354
00:20:31,360 --> 00:20:37,520
absolute deviation estimate.

355
00:20:34,880 --> 00:20:41,280
um we actually

356
00:20:37,520 --> 00:20:45,840
can get estimates of the 90th percentile

357
00:20:41,280 --> 00:20:48,640
of outcomes of the uh regression model.

358
00:20:45,840 --> 00:20:50,320
Now um

359
00:20:48,640 --> 00:20:51,840
what's

360
00:20:50,320 --> 00:20:56,080
interesting

361
00:20:51,840 --> 00:20:58,320
mathematically is um how how would one

362
00:20:56,080 --> 00:21:01,919
calculate sort of the mean absolute

363
00:20:58,320 --> 00:21:03,440
deviation estimate or this quantile

364
00:21:01,919 --> 00:21:06,880
estimator?

365
00:21:03,440 --> 00:21:11,440
Well, we would want to minimize

366
00:21:06,880 --> 00:21:15,520
the sum of these h functions.

367
00:21:11,440 --> 00:21:18,320
And these h functions actually are

368
00:21:15,520 --> 00:21:20,480
convex.

369
00:21:18,320 --> 00:21:22,799
So, um, as James Shepard said, you know,

370
00:21:20,480 --> 00:21:26,159
this is like a bowl-shaped problem, but

371
00:21:22,799 --> 00:21:29,520
it's a bowl with sort of square or with

372
00:21:26,159 --> 00:21:34,320
with straight edges around around it.

373
00:21:29,520 --> 00:21:38,880
And so if we take this Q function with

374
00:21:34,320 --> 00:21:42,480
this H um we can't minimize it by

375
00:21:38,880 --> 00:21:46,799
solving the first order equations.

376
00:21:42,480 --> 00:21:51,360
So um if we have q equal to the sum 1 to

377
00:21:46,799 --> 00:21:54,080
n of h of the arguments we can't solve

378
00:21:51,360 --> 00:21:58,320
this

379
00:21:54,080 --> 00:22:02,000
uh we can't solve for this equaling zero

380
00:21:58,320 --> 00:22:04,400
but we can solve for what the derivative

381
00:22:02,000 --> 00:22:10,240
is at any guesses

382
00:22:04,400 --> 00:22:12,400
and we can move our guess to a lower

383
00:22:10,240 --> 00:22:15,280
value of the q function.

384
00:22:12,400 --> 00:22:20,240
uh with that and that's in fact how we

385
00:22:15,280 --> 00:22:22,559
learn that the median of a sample

386
00:22:20,240 --> 00:22:26,480
is the

387
00:22:22,559 --> 00:22:31,240
best estimate of the center of the data

388
00:22:26,480 --> 00:22:31,240
if we consider mean absolute deviations.

389
00:22:31,280 --> 00:22:36,159
Okay.

390
00:22:33,760 --> 00:22:42,960
Well, let's um consider another

391
00:22:36,159 --> 00:22:44,960
extension of uh regression. uh it's

392
00:22:42,960 --> 00:22:48,720
famous enough to have its own name ridge

393
00:22:44,960 --> 00:22:52,000
regression. And so with ridge regression

394
00:22:48,720 --> 00:22:55,960
we are estimating

395
00:22:52,000 --> 00:22:55,960
the regression parameters

396
00:22:57,440 --> 00:23:04,400
where we have um

397
00:23:00,400 --> 00:23:07,400
basically it's sort of le squares plus a

398
00:23:04,400 --> 00:23:07,400
penalty

399
00:23:08,320 --> 00:23:12,640
for our criterion.

400
00:23:10,799 --> 00:23:14,880
So

401
00:23:12,640 --> 00:23:17,760
the left argument

402
00:23:14,880 --> 00:23:20,720
of this uh

403
00:23:17,760 --> 00:23:23,200
expression is simply the sum of squared

404
00:23:20,720 --> 00:23:25,039
residuals. But then we're adding to that

405
00:23:23,200 --> 00:23:28,320
a penalty

406
00:23:25,039 --> 00:23:32,080
depending upon the squared length of the

407
00:23:28,320 --> 00:23:34,960
beta vector. And so

408
00:23:32,080 --> 00:23:38,159
in order for this to be

409
00:23:34,960 --> 00:23:44,240
a reasonable

410
00:23:38,159 --> 00:23:48,080
thing to do um we actually need to or

411
00:23:44,240 --> 00:23:50,400
it's we don't need to but it's useful to

412
00:23:48,080 --> 00:23:55,919
consider standardizing

413
00:23:50,400 --> 00:23:58,799
our independent variables X making them

414
00:23:55,919 --> 00:24:02,400
have mean zero

415
00:23:58,799 --> 00:24:06,640
and also centering y.

416
00:24:02,400 --> 00:24:10,400
Um, and then consider the regression

417
00:24:06,640 --> 00:24:13,919
where we rescale the

418
00:24:10,400 --> 00:24:17,520
columns of the predictor matrix

419
00:24:13,919 --> 00:24:20,960
as centered with the inverse of the

420
00:24:17,520 --> 00:24:28,480
coariance matrix between those.

421
00:24:20,960 --> 00:24:33,440
So in this formulation this is the uh uh

422
00:24:28,480 --> 00:24:35,279
the statement of uh how the ridge

423
00:24:33,440 --> 00:24:40,480
regression parameter estimate is

424
00:24:35,279 --> 00:24:42,880
specified. Now the centering of the

425
00:24:40,480 --> 00:24:45,360
independent variables and scaling them

426
00:24:42,880 --> 00:24:49,360
to have unit variance

427
00:24:45,360 --> 00:24:51,600
is important because it places all of

428
00:24:49,360 --> 00:24:54,799
the variables all of the predictor

429
00:24:51,600 --> 00:24:59,200
variables on an equal footing.

430
00:24:54,799 --> 00:25:01,600
If we are looking at the sum of squared

431
00:24:59,200 --> 00:25:04,799
beta js

432
00:25:01,600 --> 00:25:09,440
then if we just use different units we

433
00:25:04,799 --> 00:25:13,760
could make any j beta beta j as large as

434
00:25:09,440 --> 00:25:15,760
we want. Um but with this uh

435
00:25:13,760 --> 00:25:18,480
standardization

436
00:25:15,760 --> 00:25:21,440
uh we basically eliminate uh that

437
00:25:18,480 --> 00:25:24,640
aspect. So there's no dependence on the

438
00:25:21,440 --> 00:25:27,120
original units of X.

439
00:25:24,640 --> 00:25:29,919
And

440
00:25:27,120 --> 00:25:32,480
let's see with this ridge regression.

441
00:25:29,919 --> 00:25:37,919
The notes go through how we compute

442
00:25:32,480 --> 00:25:40,799
these. Um I want to uh

443
00:25:37,919 --> 00:25:45,520
highlight though how this ridge

444
00:25:40,799 --> 00:25:48,640
regression is actually related to basian

445
00:25:45,520 --> 00:25:50,240
models where we would assume a prior

446
00:25:48,640 --> 00:25:54,080
distribution

447
00:25:50,240 --> 00:25:57,760
on our regression parameters.

448
00:25:54,080 --> 00:26:01,360
And so the uh

449
00:25:57,760 --> 00:26:03,679
the if we consider a B

450
00:26:01,360 --> 00:26:06,240
prior

451
00:26:03,679 --> 00:26:10,520
on beta

452
00:26:06,240 --> 00:26:10,520
and that

453
00:26:11,120 --> 00:26:18,880
B prior is uh basically multi-normal

454
00:26:16,320 --> 00:26:21,039
in P dimensions

455
00:26:18,880 --> 00:26:24,240
with

456
00:26:21,039 --> 00:26:27,360
a mean vector of zero.

457
00:26:24,240 --> 00:26:29,200
and a covariance matrix

458
00:26:27,360 --> 00:26:30,720
that

459
00:26:29,200 --> 00:26:34,960
is

460
00:26:30,720 --> 00:26:37,440
um let's see I'll call it omega and

461
00:26:34,960 --> 00:26:39,919
omega is proportional to the identity

462
00:26:37,440 --> 00:26:42,799
matrix

463
00:26:39,919 --> 00:26:48,440
with in p dimensions

464
00:26:42,799 --> 00:26:48,440
then what we've done is

465
00:26:48,799 --> 00:26:56,159
we have a criterion that corresponds to

466
00:26:51,200 --> 00:26:59,039
the exponential part of the log

467
00:26:56,159 --> 00:27:01,600
likelihood for

468
00:26:59,039 --> 00:27:06,559
plus the log likelihood of the prior

469
00:27:01,600 --> 00:27:11,200
density. So, so this ridge regression

470
00:27:06,559 --> 00:27:15,840
is is interpretable as putting a ba a

471
00:27:11,200 --> 00:27:21,039
prior distribution on the betas that

472
00:27:15,840 --> 00:27:24,240
have this form mean zero and co-variance

473
00:27:21,039 --> 00:27:27,520
proportional to the identity matrix and

474
00:27:24,240 --> 00:27:31,520
what that suggests op priori is that

475
00:27:27,520 --> 00:27:34,240
sort of any direction in that pd-

476
00:27:31,520 --> 00:27:37,840
dimensional space is equally likely as

477
00:27:34,240 --> 00:27:40,400
any other for characterizing the

478
00:27:37,840 --> 00:27:44,320
regression parameters

479
00:27:40,400 --> 00:27:47,279
and this beta hat which minimizes this

480
00:27:44,320 --> 00:27:49,840
argument ends up being the mode of the

481
00:27:47,279 --> 00:27:53,360
posterior distribution.

482
00:27:49,840 --> 00:27:55,200
So that's a neat connection uh to be

483
00:27:53,360 --> 00:27:58,960
aware of.

484
00:27:55,200 --> 00:28:04,640
Um the notes here go through with ridge

485
00:27:58,960 --> 00:28:06,640
regression how we compute them. Um the

486
00:28:04,640 --> 00:28:10,320
minimization

487
00:28:06,640 --> 00:28:12,720
basically leads to formulas for the

488
00:28:10,320 --> 00:28:14,960
ridge regression estimate that look

489
00:28:12,720 --> 00:28:17,520
almost like le squares except we have

490
00:28:14,960 --> 00:28:20,960
this additional factor lambda times the

491
00:28:17,520 --> 00:28:23,039
identity inside that braces before we

492
00:28:20,960 --> 00:28:27,120
take the inverse.

493
00:28:23,039 --> 00:28:31,760
And with ridge regression, we can look

494
00:28:27,120 --> 00:28:35,360
at the singular value decomposition

495
00:28:31,760 --> 00:28:40,559
of our independent variables that have

496
00:28:35,360 --> 00:28:45,919
been centered and standardized.

497
00:28:40,559 --> 00:28:51,200
And when we do that um we basically have

498
00:28:45,919 --> 00:28:56,799
these this final formula for the

499
00:28:51,200 --> 00:28:58,880
ridge regression. Um and uh we end up

500
00:28:56,799 --> 00:29:02,799
basically having

501
00:28:58,880 --> 00:29:06,720
the fitted values y hat

502
00:29:02,799 --> 00:29:15,279
just being equal to

503
00:29:06,720 --> 00:29:17,600
a sum of factors times cj uj where these

504
00:29:15,279 --> 00:29:20,720
factors

505
00:29:17,600 --> 00:29:23,440
are one when lambda is zero. So when

506
00:29:20,720 --> 00:29:27,200
lambda is zero least ridge is equal to

507
00:29:23,440 --> 00:29:30,399
le squares and so the least squares

508
00:29:27,200 --> 00:29:32,559
fitted values are given here but with

509
00:29:30,399 --> 00:29:35,440
ridge regression

510
00:29:32,559 --> 00:29:39,440
we have shrinkage

511
00:29:35,440 --> 00:29:41,679
and what's curious is that there's less

512
00:29:39,440 --> 00:29:46,159
shrinkage

513
00:29:41,679 --> 00:29:48,480
for the larger squared singular values

514
00:29:46,159 --> 00:29:50,480
and there's more shrinkage for the

515
00:29:48,480 --> 00:29:53,200
smaller ones.

516
00:29:50,480 --> 00:29:56,080
So if we think of the independent

517
00:29:53,200 --> 00:29:58,960
variables or predictor variables being

518
00:29:56,080 --> 00:30:01,520
in pd- dimensional space

519
00:29:58,960 --> 00:30:05,039
then

520
00:30:01,520 --> 00:30:07,600
ridge regression will

521
00:30:05,039 --> 00:30:09,360
not shrink much those regression

522
00:30:07,600 --> 00:30:13,840
coefficients

523
00:30:09,360 --> 00:30:16,240
that are correspond to

524
00:30:13,840 --> 00:30:18,799
regressor variables that are along sort

525
00:30:16,240 --> 00:30:23,360
of the first principal component axis.

526
00:30:18,799 --> 00:30:25,120
is and there's much more shrinkage in

527
00:30:23,360 --> 00:30:28,480
those dimensions where there is very

528
00:30:25,120 --> 00:30:31,520
little variation. So, so these are

529
00:30:28,480 --> 00:30:33,200
actually connected to principal

530
00:30:31,520 --> 00:30:36,320
components

531
00:30:33,200 --> 00:30:42,399
variables which is actually covered sort

532
00:30:36,320 --> 00:30:45,039
of in the next uh section. Um so you

533
00:30:42,399 --> 00:30:46,880
know it was we introduced ridge

534
00:30:45,039 --> 00:30:51,520
regression using the singular value

535
00:30:46,880 --> 00:30:55,120
decomposition of x but um we can

536
00:30:51,520 --> 00:30:56,960
motivate principal components regression

537
00:30:55,120 --> 00:30:58,960
using the same singular value

538
00:30:56,960 --> 00:31:02,240
decomposition.

539
00:30:58,960 --> 00:31:06,880
So with our data

540
00:31:02,240 --> 00:31:09,919
predictor matrix X um we consider the

541
00:31:06,880 --> 00:31:11,760
sample covariance matrix of those row

542
00:31:09,919 --> 00:31:14,559
vectors

543
00:31:11,760 --> 00:31:18,080
um and

544
00:31:14,559 --> 00:31:21,520
we can compute the igen value IGEN

545
00:31:18,080 --> 00:31:27,039
vector decomposition of that

546
00:31:21,520 --> 00:31:31,360
and with these IGEN vectors which are

547
00:31:27,039 --> 00:31:36,159
normalized to have length one. We simply

548
00:31:31,360 --> 00:31:38,559
multiply our matrix X by the J igen

549
00:31:36,159 --> 00:31:41,760
vector and we get our J principal

550
00:31:38,559 --> 00:31:45,039
component variable.

551
00:31:41,760 --> 00:31:48,080
So this is familiar to us in terms of

552
00:31:45,039 --> 00:31:50,799
how principal components sort of manipul

553
00:31:48,080 --> 00:31:52,880
uh computations work.

554
00:31:50,799 --> 00:31:57,120
And

555
00:31:52,880 --> 00:32:00,159
with principal components regression,

556
00:31:57,120 --> 00:32:02,720
one has

557
00:32:00,159 --> 00:32:06,159
principal component variables which are

558
00:32:02,720 --> 00:32:08,880
orthogonal to each other.

559
00:32:06,159 --> 00:32:13,919
And so the computation

560
00:32:08,880 --> 00:32:17,039
of their coefficients is very simple.

561
00:32:13,919 --> 00:32:20,640
We can calculate them separately

562
00:32:17,039 --> 00:32:23,840
and we can consider using maybe just the

563
00:32:20,640 --> 00:32:25,919
first m principal component variables in

564
00:32:23,840 --> 00:32:29,200
our regression.

565
00:32:25,919 --> 00:32:31,360
And so if we do this

566
00:32:29,200 --> 00:32:34,799
um we

567
00:32:31,360 --> 00:32:36,320
can see some easy formulas for the

568
00:32:34,799 --> 00:32:38,240
estimates.

569
00:32:36,320 --> 00:32:43,919
Um

570
00:32:38,240 --> 00:32:46,320
ultimately uh we get fitted values

571
00:32:43,919 --> 00:32:49,120
of y from principal components

572
00:32:46,320 --> 00:32:51,200
regression which are a projection of the

573
00:32:49,120 --> 00:32:56,559
y vector

574
00:32:51,200 --> 00:33:00,799
onto the space spanned by the first

575
00:32:56,559 --> 00:33:03,440
in this case the first uh m uh principal

576
00:33:00,799 --> 00:33:05,039
component directions.

577
00:33:03,440 --> 00:33:08,720
And

578
00:33:05,039 --> 00:33:10,960
what's curious is just how these three

579
00:33:08,720 --> 00:33:14,720
methods le squares ridge and principal

580
00:33:10,960 --> 00:33:17,919
components regression are estimating

581
00:33:14,720 --> 00:33:21,360
the uh response variable or dependent

582
00:33:17,919 --> 00:33:26,320
variable using essentially the same

583
00:33:21,360 --> 00:33:31,200
fundamental pieces the CJ and U.js J's

584
00:33:26,320 --> 00:33:34,640
but are um either sort of skipping the

585
00:33:31,200 --> 00:33:38,399
last P minus M for principal components

586
00:33:34,640 --> 00:33:41,919
shrinking those based on the size of the

587
00:33:38,399 --> 00:33:44,919
igen values for ridge or using all of

588
00:33:41,919 --> 00:33:44,919
them.

589
00:33:45,919 --> 00:33:54,399
Now uh as you might expect um

590
00:33:51,360 --> 00:33:58,640
researchers have extended

591
00:33:54,399 --> 00:34:01,279
u estimation methods uh beyond these. Uh

592
00:33:58,640 --> 00:34:04,799
the lasso regression

593
00:34:01,279 --> 00:34:10,480
model uh or regression estimate is one

594
00:34:04,799 --> 00:34:13,599
where instead of having the uh penalty

595
00:34:10,480 --> 00:34:16,800
be the sum of squared

596
00:34:13,599 --> 00:34:21,839
beta js or the length of the beta j.

597
00:34:16,800 --> 00:34:26,000
It's the sum of the absolute values.

598
00:34:21,839 --> 00:34:29,679
Um and this penalty is a really

599
00:34:26,000 --> 00:34:32,639
interesting one. Um, and some of let's

600
00:34:29,679 --> 00:34:34,879
say I'm sure some people here have

601
00:34:32,639 --> 00:34:38,399
perhaps used lasso regression. Has

602
00:34:34,879 --> 00:34:42,000
anyone here used lasso regression?

603
00:34:38,399 --> 00:34:46,159
Nobody. That's fine. That means this

604
00:34:42,000 --> 00:34:49,119
isn't a sort of repeat information. But

605
00:34:46,159 --> 00:34:50,800
um it turns out that

606
00:34:49,119 --> 00:34:54,000
um

607
00:34:50,800 --> 00:34:58,400
well let me just draw this uh suppose we

608
00:34:54,000 --> 00:35:02,400
have beta 1 versus beta 2

609
00:34:58,400 --> 00:35:04,720
and we're considering

610
00:35:02,400 --> 00:35:08,400
penalties.

611
00:35:04,720 --> 00:35:11,760
Um so the sum of the beta j squares

612
00:35:08,400 --> 00:35:15,160
equal to a constant. This is the sort of

613
00:35:11,760 --> 00:35:15,160
ridge penalty.

614
00:35:17,520 --> 00:35:26,160
So um

615
00:35:20,720 --> 00:35:28,720
and so if uh if we have a beta hat

616
00:35:26,160 --> 00:35:31,839
say a beta hat here

617
00:35:28,720 --> 00:35:34,800
point that we observe um it basically is

618
00:35:31,839 --> 00:35:37,359
sort of shrunk towards zero

619
00:35:34,800 --> 00:35:40,000
or we have beta hat

620
00:35:37,359 --> 00:35:43,000
and the beta hat ridge

621
00:35:40,000 --> 00:35:43,000
will

622
00:35:43,440 --> 00:35:47,839
be shrunk towards this sort of prior

623
00:35:46,320 --> 00:35:54,280
mean

624
00:35:47,839 --> 00:35:54,280
some amount. With the uh lasso penalty,

625
00:35:55,920 --> 00:36:02,640
we have the sum of the magnitudes of the

626
00:35:58,960 --> 00:36:04,320
beta js is equal to a constant.

627
00:36:02,640 --> 00:36:07,359
Then

628
00:36:04,320 --> 00:36:09,920
we basically have

629
00:36:07,359 --> 00:36:14,000
sort of diamonds

630
00:36:09,920 --> 00:36:17,680
where along each of these diamond edges

631
00:36:14,000 --> 00:36:21,839
the penalty is the same magnitude.

632
00:36:17,680 --> 00:36:24,320
And so with lasso regression, we

633
00:36:21,839 --> 00:36:26,000
basically consider

634
00:36:24,320 --> 00:36:30,480
finding

635
00:36:26,000 --> 00:36:36,160
an estimate that is minimizes the least

636
00:36:30,480 --> 00:36:40,480
squares but also is constrained

637
00:36:36,160 --> 00:36:43,680
uh to have sort of sum of absolute

638
00:36:40,480 --> 00:36:47,839
magnitudes that's smaller. And so this

639
00:36:43,680 --> 00:36:51,359
kind of uh penalty ends up

640
00:36:47,839 --> 00:36:52,880
actually leading to

641
00:36:51,359 --> 00:36:55,200
uh

642
00:36:52,880 --> 00:36:59,599
sort of shrinkage which tends to

643
00:36:55,200 --> 00:37:03,520
concentrate at the vertices of this

644
00:36:59,599 --> 00:37:06,560
uh penalty function. So um so what we

645
00:37:03,520 --> 00:37:09,599
end up getting often is

646
00:37:06,560 --> 00:37:12,160
a lasso estimate that has some null

647
00:37:09,599 --> 00:37:15,680
parameters zero valued parameters. So,

648
00:37:12,160 --> 00:37:18,400
it's a way of excluding variables from

649
00:37:15,680 --> 00:37:21,400
the regression depending on what lambda

650
00:37:18,400 --> 00:37:21,400
is.

651
00:37:22,079 --> 00:37:27,040
All right. Um,

652
00:37:24,160 --> 00:37:31,200
well, let's see. There's this uh ETF

653
00:37:27,040 --> 00:37:35,560
case study that I posted

654
00:37:31,200 --> 00:37:35,560
um which

655
00:37:35,680 --> 00:37:43,599
it's sort of a long document to sift

656
00:37:39,040 --> 00:37:45,920
through but I guess what's important

657
00:37:43,599 --> 00:37:48,160
is just to look at the table of contents

658
00:37:45,920 --> 00:37:53,200
to see what's of interest to check out

659
00:37:48,160 --> 00:37:58,000
in this. And um what I set up as a

660
00:37:53,200 --> 00:38:03,040
problem was to consider collecting

661
00:37:58,000 --> 00:38:05,040
uh prices on exchange traded funds that

662
00:38:03,040 --> 00:38:07,119
correspond to different sectors in the

663
00:38:05,040 --> 00:38:10,400
US market.

664
00:38:07,119 --> 00:38:12,880
And so in the US market there are about

665
00:38:10,400 --> 00:38:16,000
10 sectors

666
00:38:12,880 --> 00:38:20,079
consumer staples, energy, financials,

667
00:38:16,000 --> 00:38:24,079
health and so forth. And then um there

668
00:38:20,079 --> 00:38:27,440
are also um exchangeraded funds that

669
00:38:24,079 --> 00:38:33,280
correspond to market indexes like the

670
00:38:27,440 --> 00:38:38,000
S&P 500 or the Dow Jones Industrial or

671
00:38:33,280 --> 00:38:41,200
the NASDAQ market. And uh

672
00:38:38,000 --> 00:38:44,720
I consider

673
00:38:41,200 --> 00:38:47,680
regressing a sector ETF on the index

674
00:38:44,720 --> 00:38:53,119
ETFs. Now,

675
00:38:47,680 --> 00:38:58,079
why would we be interested in regressing

676
00:38:53,119 --> 00:39:03,480
a sector index on these

677
00:38:58,079 --> 00:39:03,480
um market index ETFs?

678
00:39:12,000 --> 00:39:17,520
Well, let me just uh

679
00:39:14,880 --> 00:39:20,240
go through here, okay? or this this

680
00:39:17,520 --> 00:39:23,599
document goes through listing the

681
00:39:20,240 --> 00:39:27,079
symbols for all of these different ETFs,

682
00:39:23,599 --> 00:39:27,079
plotting them

683
00:39:32,079 --> 00:39:39,520
and actually then converting

684
00:39:35,280 --> 00:39:41,280
the prices to weekly returns

685
00:39:39,520 --> 00:39:44,720
and then looking at how they're

686
00:39:41,280 --> 00:39:46,720
correlated with each other. So in this

687
00:39:44,720 --> 00:39:50,240
example,

688
00:39:46,720 --> 00:39:53,680
I believe it was the uh consumer staples

689
00:39:50,240 --> 00:39:57,040
sector fund that

690
00:39:53,680 --> 00:39:59,920
I'm thinking of regressing on the SPY

691
00:39:57,040 --> 00:40:04,720
which corresponds to the S&P 500, MDY,

692
00:39:59,920 --> 00:40:07,119
which is a midcap U index, QQQ and the

693
00:40:04,720 --> 00:40:09,359
diamonds.

694
00:40:07,119 --> 00:40:12,960
And if we look at these sort of

695
00:40:09,359 --> 00:40:15,200
cumulative returns of these different

696
00:40:12,960 --> 00:40:18,400
ETFs, you know, here's the cumulative

697
00:40:15,200 --> 00:40:23,680
return over a I don't know 14-year

698
00:40:18,400 --> 00:40:26,079
period or something. Um, well, any other

699
00:40:23,680 --> 00:40:30,960
any any any more thoughts on why we

700
00:40:26,079 --> 00:40:33,040
might want to regress this on these

701
00:40:30,960 --> 00:40:35,760
indexes? AJ

702
00:40:33,040 --> 00:40:37,760
>> the index return should be the entire

703
00:40:35,760 --> 00:40:41,359
variant should be explained by their

704
00:40:37,760 --> 00:40:45,760
sectors like assuming not everything you

705
00:40:41,359 --> 00:40:47,920
generates is contained within

706
00:40:45,760 --> 00:40:50,920
market index they should explain

707
00:40:47,920 --> 00:40:50,920
perfectly

708
00:40:51,040 --> 00:40:54,240
>> right okay so that's looking at almost

709
00:40:52,800 --> 00:40:59,839
the other way around if we were looking

710
00:40:54,240 --> 00:41:03,599
at the ex index ETF as a function of the

711
00:40:59,839 --> 00:41:06,000
sectors we should have almost a perfect

712
00:41:03,599 --> 00:41:09,440
explanation of that in a regression

713
00:41:06,000 --> 00:41:13,520
model. What can be useful with this

714
00:41:09,440 --> 00:41:17,760
regression is if we wanted to invest in

715
00:41:13,520 --> 00:41:21,839
consumer staples but we wanted to have

716
00:41:17,760 --> 00:41:24,160
our investment be hedged against the

717
00:41:21,839 --> 00:41:30,079
sort of market risk

718
00:41:24,160 --> 00:41:32,560
that is um large. And uh and so if if we

719
00:41:30,079 --> 00:41:36,319
could eliminate the dependence on the

720
00:41:32,560 --> 00:41:39,680
S&P 500, eliminate the dependence on the

721
00:41:36,319 --> 00:41:41,680
midcap and the QQQs,

722
00:41:39,680 --> 00:41:45,200
then

723
00:41:41,680 --> 00:41:48,720
our sort of hedged investment, we'd be

724
00:41:45,200 --> 00:41:51,280
less concerned about major drops in the

725
00:41:48,720 --> 00:41:54,160
market. So we'd be reducing the market

726
00:41:51,280 --> 00:41:57,440
risk. So this is where it can it can be

727
00:41:54,160 --> 00:42:00,480
very useful. Now

728
00:41:57,440 --> 00:42:03,760
this kind of approach

729
00:42:00,480 --> 00:42:06,160
has also been used to try and mimic uh

730
00:42:03,760 --> 00:42:10,079
hedge fund strategies.

731
00:42:06,160 --> 00:42:13,440
And so there's uh some papers out there

732
00:42:10,079 --> 00:42:17,599
on hedge fund replication where hedge

733
00:42:13,440 --> 00:42:21,040
funds basically may be have most of

734
00:42:17,599 --> 00:42:25,280
their returns attributable to

735
00:42:21,040 --> 00:42:26,960
um liquid market instruments that one

736
00:42:25,280 --> 00:42:31,760
can trade

737
00:42:26,960 --> 00:42:33,359
um in a portfolio. And so uh hedge fund

738
00:42:31,760 --> 00:42:35,440
replication

739
00:42:33,359 --> 00:42:37,680
methods have actually done that kind of

740
00:42:35,440 --> 00:42:42,640
regression as well.

741
00:42:37,680 --> 00:42:47,760
Anyway, with this um with this uh setup,

742
00:42:42,640 --> 00:42:54,319
we can just regress this XLP on the

743
00:42:47,760 --> 00:42:57,920
index ETFs and we get this regression

744
00:42:54,319 --> 00:43:01,520
coefficient table here. Um what's

745
00:42:57,920 --> 00:43:03,040
important to see is

746
00:43:01,520 --> 00:43:05,760
whether

747
00:43:03,040 --> 00:43:07,760
the regression coefficients are

748
00:43:05,760 --> 00:43:09,359
significantly different from zero or

749
00:43:07,760 --> 00:43:11,920
not.

750
00:43:09,359 --> 00:43:15,599
And

751
00:43:11,920 --> 00:43:18,160
the t value and p value columns

752
00:43:15,599 --> 00:43:21,119
basically tell us that that all of these

753
00:43:18,160 --> 00:43:23,119
uh explanatory factors are are useful

754
00:43:21,119 --> 00:43:28,960
here.

755
00:43:23,119 --> 00:43:30,480
And let's see when we um when we study

756
00:43:28,960 --> 00:43:32,880
uh

757
00:43:30,480 --> 00:43:36,160
the uh

758
00:43:32,880 --> 00:43:38,560
let's see when we study uh the

759
00:43:36,160 --> 00:43:42,319
regression model okay we have the R

760
00:43:38,560 --> 00:43:45,200
squared of this multiple regression

761
00:43:42,319 --> 00:43:48,720
the correlation of the fitted and actual

762
00:43:45,200 --> 00:43:52,079
values is given by uh or the square of

763
00:43:48,720 --> 00:43:54,319
that is given by the R squared

764
00:43:52,079 --> 00:43:58,480
And we can do various regression

765
00:43:54,319 --> 00:44:00,720
diagnostics which are used here. What

766
00:43:58,480 --> 00:44:02,800
I'll let you go through these details.

767
00:44:00,720 --> 00:44:06,640
Uh this a bit repetitive from what we

768
00:44:02,800 --> 00:44:09,760
talked about in the last lecture. But um

769
00:44:06,640 --> 00:44:11,280
let's see we can also

770
00:44:09,760 --> 00:44:15,599
model

771
00:44:11,280 --> 00:44:19,119
the uh independent variables

772
00:44:15,599 --> 00:44:20,960
um or do a principal components analysis

773
00:44:19,119 --> 00:44:23,359
of those.

774
00:44:20,960 --> 00:44:26,560
And if we compute a principal component

775
00:44:23,359 --> 00:44:31,119
analysis of our independent variables in

776
00:44:26,560 --> 00:44:34,720
this case the index sector uh exchange

777
00:44:31,119 --> 00:44:36,319
traded funds. We then have

778
00:44:34,720 --> 00:44:40,240
a

779
00:44:36,319 --> 00:44:42,720
sort of decomposition of variability

780
00:44:40,240 --> 00:44:44,720
um which indicates that the first

781
00:44:42,720 --> 00:44:48,240
principal component variable explains

782
00:44:44,720 --> 00:44:51,359
90% of the variability in these data.

783
00:44:48,240 --> 00:44:53,440
the first two 97%.

784
00:44:51,359 --> 00:44:57,119
So we're actually explaining a lot of

785
00:44:53,440 --> 00:45:00,720
variability with just the first two. Now

786
00:44:57,119 --> 00:45:05,520
um in looking at

787
00:45:00,720 --> 00:45:07,520
the regression on the PC variables

788
00:45:05,520 --> 00:45:10,839
um

789
00:45:07,520 --> 00:45:10,839
let's see

790
00:45:12,800 --> 00:45:16,119
we can

791
00:45:17,119 --> 00:45:21,520
consider well each of these PC variables

792
00:45:20,160 --> 00:45:24,960
principal component variables are

793
00:45:21,520 --> 00:45:28,880
orthogonal to each other. So in

794
00:45:24,960 --> 00:45:31,520
estimating the regression coefficients,

795
00:45:28,880 --> 00:45:33,200
we can do so with simple linear

796
00:45:31,520 --> 00:45:34,720
regressions

797
00:45:33,200 --> 00:45:41,119
of

798
00:45:34,720 --> 00:45:45,359
the ETF uh fund um

799
00:45:41,119 --> 00:45:48,720
y on that on each variable. And so the

800
00:45:45,359 --> 00:45:52,160
first principal component variable has

801
00:45:48,720 --> 00:45:55,040
an R squar of 0.545.

802
00:45:52,160 --> 00:45:56,960
Um

803
00:45:55,040 --> 00:45:58,800
and the second principal component

804
00:45:56,960 --> 00:46:02,000
variable

805
00:45:58,800 --> 00:46:07,119
has almost no correlation.

806
00:46:02,000 --> 00:46:10,400
And so it's um while it's almost none,

807
00:46:07,119 --> 00:46:11,760
its p value is still 0.0518,

808
00:46:10,400 --> 00:46:14,400
which is almost statistically

809
00:46:11,760 --> 00:46:18,240
significant. With very large samples,

810
00:46:14,400 --> 00:46:20,720
we're able to judge small correlations

811
00:46:18,240 --> 00:46:23,680
as being statistically significant, but

812
00:46:20,720 --> 00:46:26,480
maybe it's not practically significant.

813
00:46:23,680 --> 00:46:31,040
And then the third

814
00:46:26,480 --> 00:46:37,280
has um a small R squar as well. And the

815
00:46:31,040 --> 00:46:41,839
fourth again rather small but what's um

816
00:46:37,280 --> 00:46:46,079
what's of interest um is

817
00:46:41,839 --> 00:46:47,839
whether the uh or basically just how

818
00:46:46,079 --> 00:46:50,880
statistically significant are the

819
00:46:47,839 --> 00:46:54,319
principal component variables. And in

820
00:46:50,880 --> 00:46:56,319
this sort of updated example,

821
00:46:54,319 --> 00:47:00,040
um

822
00:46:56,319 --> 00:47:00,040
the uh

823
00:47:01,200 --> 00:47:05,760
let's see here.

824
00:47:03,839 --> 00:47:08,640
Well, if we consider the regression

825
00:47:05,760 --> 00:47:10,400
parameter based on only the first three

826
00:47:08,640 --> 00:47:14,319
variables,

827
00:47:10,400 --> 00:47:20,240
um we basically get these results. Now,

828
00:47:14,319 --> 00:47:24,560
when I did this um a few years ago, it

829
00:47:20,240 --> 00:47:28,960
ended up being the case that the

830
00:47:24,560 --> 00:47:32,000
uh p values for I think it was the

831
00:47:28,960 --> 00:47:35,760
second principal component variable was

832
00:47:32,000 --> 00:47:37,920
not significant at all. And so in

833
00:47:35,760 --> 00:47:42,400
choosing to

834
00:47:37,920 --> 00:47:45,280
um in in choosing what factors to

835
00:47:42,400 --> 00:47:48,560
include in the model, the principal

836
00:47:45,280 --> 00:47:52,880
components regression approach of

837
00:47:48,560 --> 00:47:56,240
basically including successive

838
00:47:52,880 --> 00:48:00,160
high uh en value principal component

839
00:47:56,240 --> 00:48:06,079
variables in uh successively so long as

840
00:48:00,160 --> 00:48:07,920
they're significant. um that actually uh

841
00:48:06,079 --> 00:48:10,160
sort of

842
00:48:07,920 --> 00:48:13,119
doesn't doesn't include really

843
00:48:10,160 --> 00:48:16,560
necessarily the important regressors in

844
00:48:13,119 --> 00:48:19,680
in the model. So we can have

845
00:48:16,560 --> 00:48:23,200
statistically significant high order

846
00:48:19,680 --> 00:48:25,920
principal component variables that don't

847
00:48:23,200 --> 00:48:29,280
have much variability in them but they

848
00:48:25,920 --> 00:48:31,280
actually are explaining uh significant

849
00:48:29,280 --> 00:48:33,040
uh factors affecting the response

850
00:48:31,280 --> 00:48:36,480
variable.

851
00:48:33,040 --> 00:48:40,240
So anyway, this uh this note goes

852
00:48:36,480 --> 00:48:43,760
through and uh

853
00:48:40,240 --> 00:48:46,960
in additionally uh considers ridge

854
00:48:43,760 --> 00:48:50,960
regression and less so regression. And

855
00:48:46,960 --> 00:48:53,839
so with the ridge regression

856
00:48:50,960 --> 00:48:58,559
uh results,

857
00:48:53,839 --> 00:49:03,040
the display of regression parameters

858
00:48:58,559 --> 00:49:09,280
um is traced out as we consider

859
00:49:03,040 --> 00:49:14,720
different constraints on the uh

860
00:49:09,280 --> 00:49:19,119
L1 or on the well on the L2 norm. Um and

861
00:49:14,720 --> 00:49:23,280
uh if we look at the L1 norm of these

862
00:49:19,119 --> 00:49:29,200
estimates, one can see basically how as

863
00:49:23,280 --> 00:49:31,440
one sort of decreases the penalty for

864
00:49:29,200 --> 00:49:34,960
the complexity of the regression

865
00:49:31,440 --> 00:49:37,680
parameters, we get final estimates given

866
00:49:34,960 --> 00:49:41,359
by these

867
00:49:37,680 --> 00:49:43,680
ending values. But if we increase the

868
00:49:41,359 --> 00:49:47,520
penalty on those then they basically are

869
00:49:43,680 --> 00:49:49,200
shrinking towards zero uh although the

870
00:49:47,520 --> 00:49:52,079
shrinkage isn't necessarily in a

871
00:49:49,200 --> 00:49:55,119
monotone manner.

872
00:49:52,079 --> 00:49:56,800
And then if we look at the lasso

873
00:49:55,119 --> 00:50:02,000
regression

874
00:49:56,800 --> 00:50:06,000
with a same L1 norm sort of scaling, one

875
00:50:02,000 --> 00:50:11,920
can see how as that lambda parameter

876
00:50:06,000 --> 00:50:15,040
associated with the penalty is increased

877
00:50:11,920 --> 00:50:18,160
um we basically have

878
00:50:15,040 --> 00:50:22,079
the L1 norm getting smaller

879
00:50:18,160 --> 00:50:24,240
of the resulting estimates. And this

880
00:50:22,079 --> 00:50:27,760
shows you how

881
00:50:24,240 --> 00:50:32,079
I guess the third variable is the first

882
00:50:27,760 --> 00:50:36,800
to be excluded. Uh then the second and

883
00:50:32,079 --> 00:50:39,359
then uh finally uh the fourth.

884
00:50:36,800 --> 00:50:41,520
So um

885
00:50:39,359 --> 00:50:45,760
all right. So, so anyway, so this note

886
00:50:41,520 --> 00:50:48,640
goes through an illustration of lesso

887
00:50:45,760 --> 00:50:52,400
and principal components regression

888
00:50:48,640 --> 00:50:56,480
and it also provided a comparison of

889
00:50:52,400 --> 00:51:01,200
different coefficients by method.

890
00:50:56,480 --> 00:51:05,920
And what this uh final sort of chart

891
00:51:01,200 --> 00:51:10,000
shows is the comparison of

892
00:51:05,920 --> 00:51:12,640
beta estimates by method. And one can

893
00:51:10,000 --> 00:51:15,920
see that most of the methods give

894
00:51:12,640 --> 00:51:18,240
similar results but using just the first

895
00:51:15,920 --> 00:51:22,000
three principal component variables

896
00:51:18,240 --> 00:51:26,640
gives us a very different estimates of

897
00:51:22,000 --> 00:51:29,680
regression parameters. So um the uh so

898
00:51:26,640 --> 00:51:36,000
there's sensitivity of

899
00:51:29,680 --> 00:51:38,720
the estimators um to the data and

900
00:51:36,000 --> 00:51:42,559
it's perhaps

901
00:51:38,720 --> 00:51:45,680
useful to um

902
00:51:42,559 --> 00:51:47,839
let's see well it's useful to consider

903
00:51:45,680 --> 00:51:49,920
these alternatives with very large

904
00:51:47,839 --> 00:51:52,240
sample sizes you generally don't get

905
00:51:49,920 --> 00:51:53,599
much difference in the ridge or the less

906
00:51:52,240 --> 00:51:55,760
cell results.

907
00:51:53,599 --> 00:51:59,040
It's usually in smaller sample sizes

908
00:51:55,760 --> 00:52:03,200
that that you get differences. Um with

909
00:51:59,040 --> 00:52:05,920
the principal components regression, um

910
00:52:03,200 --> 00:52:08,400
in this example, the first three

911
00:52:05,920 --> 00:52:11,119
principal component variables

912
00:52:08,400 --> 00:52:13,280
um end up giving estimates that are in

913
00:52:11,119 --> 00:52:15,520
the yellow.

914
00:52:13,280 --> 00:52:17,839
But if we chose which principal

915
00:52:15,520 --> 00:52:21,839
component variables to include based on

916
00:52:17,839 --> 00:52:27,280
their statistical significance,

917
00:52:21,839 --> 00:52:31,119
then the uh the more significant uh

918
00:52:27,280 --> 00:52:35,520
principal component variables ended up u

919
00:52:31,119 --> 00:52:39,599
leading to this green values which are

920
00:52:35,520 --> 00:52:43,200
comparable to the others. So, so this

921
00:52:39,599 --> 00:52:45,599
suggests that um

922
00:52:43,200 --> 00:52:47,440
well actually in this case the the green

923
00:52:45,599 --> 00:52:51,200
values

924
00:52:47,440 --> 00:52:52,800
are equal to le squares um just because

925
00:52:51,200 --> 00:52:56,400
all the principal component variables

926
00:52:52,800 --> 00:52:58,880
were statistically significant.

927
00:52:56,400 --> 00:53:05,119
All right. Um

928
00:52:58,880 --> 00:53:07,119
well the next uh thing I wanted to

929
00:53:05,119 --> 00:53:10,480
go through

930
00:53:07,119 --> 00:53:13,760
um is

931
00:53:10,480 --> 00:53:16,559
this linear regression modeling for the

932
00:53:13,760 --> 00:53:20,079
capital asset pricing model.

933
00:53:16,559 --> 00:53:23,440
And in this note,

934
00:53:20,079 --> 00:53:25,599
um, we first review what the capital

935
00:53:23,440 --> 00:53:29,200
asset pricing model is, how it relates

936
00:53:25,599 --> 00:53:31,440
to, uh, returns on stocks and returns on

937
00:53:29,200 --> 00:53:35,760
a market index.

938
00:53:31,440 --> 00:53:39,440
And what we're going to do is go through

939
00:53:35,760 --> 00:53:42,240
the computation

940
00:53:39,440 --> 00:53:44,640
computations involved with an empirical

941
00:53:42,240 --> 00:53:46,640
analysis of this capital asset pricing

942
00:53:44,640 --> 00:53:50,160
model.

943
00:53:46,640 --> 00:53:53,839
and then consider testing hypotheses

944
00:53:50,160 --> 00:53:57,839
about individual uh coefficients

945
00:53:53,839 --> 00:54:01,920
and then conclude with actually fitting

946
00:53:57,839 --> 00:54:05,839
this capital asset pricing model to

947
00:54:01,920 --> 00:54:08,880
all stocks in the S&P 500 index and

948
00:54:05,839 --> 00:54:12,880
comparing the results of the capital

949
00:54:08,880 --> 00:54:15,680
asset pricing model parameters for that.

950
00:54:12,880 --> 00:54:20,319
So with this

951
00:54:15,680 --> 00:54:23,280
we begin with basically a description of

952
00:54:20,319 --> 00:54:25,119
what the capital asset pricing model is.

953
00:54:23,280 --> 00:54:29,440
We went through this I think in our

954
00:54:25,119 --> 00:54:34,880
third lecture which says that in an

955
00:54:29,440 --> 00:54:39,440
efficient market the expected return of

956
00:54:34,880 --> 00:54:44,880
a stock asset J should equal the

957
00:54:39,440 --> 00:54:50,319
risk-free return plus a beta factor

958
00:54:44,880 --> 00:54:57,520
times the excess return of the market.

959
00:54:50,319 --> 00:55:03,200
And so beta j is the uh sort of the the

960
00:54:57,520 --> 00:55:07,040
market risk factor. Um and the excess

961
00:55:03,200 --> 00:55:10,400
return of the market portfolio is simply

962
00:55:07,040 --> 00:55:13,760
how much bigger that market return is

963
00:55:10,400 --> 00:55:17,119
compared with the risk-free rate. Now

964
00:55:13,760 --> 00:55:20,240
with this with these parameters,

965
00:55:17,119 --> 00:55:25,280
if we have

966
00:55:20,240 --> 00:55:27,920
data consisting of empirical returns R

967
00:55:25,280 --> 00:55:30,960
for stocks J at different times T,

968
00:55:27,920 --> 00:55:36,720
different values over T of the risk-free

969
00:55:30,960 --> 00:55:40,319
rate, and we consider the excess return

970
00:55:36,720 --> 00:55:42,079
of each asset and the excess return of

971
00:55:40,319 --> 00:55:45,040
the market.

972
00:55:42,079 --> 00:55:49,680
Then this

973
00:55:45,040 --> 00:55:53,040
data can be used to specify

974
00:55:49,680 --> 00:55:56,160
a linear regression model

975
00:55:53,040 --> 00:56:00,720
where we have an intercept

976
00:55:56,160 --> 00:56:04,559
alpha j and a slope beta j

977
00:56:00,720 --> 00:56:07,359
for the regression. So,

978
00:56:04,559 --> 00:56:10,240
so we're looking here at

979
00:56:07,359 --> 00:56:12,960
RAR market

980
00:56:10,240 --> 00:56:15,839
and this is R*

981
00:56:12,960 --> 00:56:19,119
J.

982
00:56:15,839 --> 00:56:21,280
And we'll plot

983
00:56:19,119 --> 00:56:25,440
values

984
00:56:21,280 --> 00:56:27,920
over time T of

985
00:56:25,440 --> 00:56:30,960
these excess returns.

986
00:56:27,920 --> 00:56:32,720
And we can basically fit a regression

987
00:56:30,960 --> 00:56:36,640
model

988
00:56:32,720 --> 00:56:43,200
where we have y hat or rstar

989
00:56:36,640 --> 00:56:45,440
jt is equal to alpha j + beta j r star

990
00:56:43,200 --> 00:56:47,599
mt.

991
00:56:45,440 --> 00:56:51,440
And

992
00:56:47,599 --> 00:56:55,200
if the capital asset pricing model holds

993
00:56:51,440 --> 00:56:57,200
then the alpha js

994
00:56:55,200 --> 00:57:01,040
should be zero

995
00:56:57,200 --> 00:57:05,119
because the alpha js if we take the

996
00:57:01,040 --> 00:57:09,119
expectation in this equation with

997
00:57:05,119 --> 00:57:13,280
residuals that are mean zero constant

998
00:57:09,119 --> 00:57:15,440
variance then um we get the capital

999
00:57:13,280 --> 00:57:20,720
asset pricing model equation. when the

1000
00:57:15,440 --> 00:57:25,040
alpha j is equal to zero. Um so what we

1001
00:57:20,720 --> 00:57:27,599
can do with real data is fit this model

1002
00:57:25,040 --> 00:57:29,359
and then test whether alpha j is zero or

1003
00:57:27,599 --> 00:57:31,359
not.

1004
00:57:29,359 --> 00:57:35,359
And

1005
00:57:31,359 --> 00:57:40,160
if if it is consistent with a zero value

1006
00:57:35,359 --> 00:57:44,000
then the pricing of the asset can be

1007
00:57:40,160 --> 00:57:46,079
judged to be sort of in an equilibrium

1008
00:57:44,000 --> 00:57:51,040
um described by the capital asset

1009
00:57:46,079 --> 00:57:55,359
pricing model. Um, and so let's take a

1010
00:57:51,040 --> 00:57:59,599
look. I think what's perhaps useful is

1011
00:57:55,359 --> 00:58:03,040
just to see the code for

1012
00:57:59,599 --> 00:58:05,839
doing these computations that's included

1013
00:58:03,040 --> 00:58:09,359
uh in the note here.

1014
00:58:05,839 --> 00:58:11,440
But if we pick a particular stock

1015
00:58:09,359 --> 00:58:14,640
GE stock

1016
00:58:11,440 --> 00:58:18,319
and fit the regression model,

1017
00:58:14,640 --> 00:58:21,040
um we basically in this code the only

1018
00:58:18,319 --> 00:58:24,799
thing we need to do is specify the

1019
00:58:21,040 --> 00:58:29,520
symbol for the stock

1020
00:58:24,799 --> 00:58:33,839
and then extract from our data

1021
00:58:29,520 --> 00:58:37,359
object the uh excess

1022
00:58:33,839 --> 00:58:39,200
uh market return and the excess asset

1023
00:58:37,359 --> 00:58:41,359
return

1024
00:58:39,200 --> 00:58:44,720
and then fit that regression and we get

1025
00:58:41,359 --> 00:58:47,920
this coefficients table here. Now in

1026
00:58:44,720 --> 00:58:50,000
this example,

1027
00:58:47,920 --> 00:58:53,760
the intercept

1028
00:58:50,000 --> 00:58:58,160
coefficient is the estimate of alpha.

1029
00:58:53,760 --> 00:59:00,559
And if GE is being priced consistent

1030
00:58:58,160 --> 00:59:03,920
with the capital asset pricing model,

1031
00:59:00,559 --> 00:59:07,200
then that estimate should be consistent

1032
00:59:03,920 --> 00:59:10,079
with the null value. And the p value for

1033
00:59:07,200 --> 00:59:13,359
testing whether that intercept is zero

1034
00:59:10,079 --> 00:59:16,400
or not gives us evidence supporting the

1035
00:59:13,359 --> 00:59:19,520
capital asset pricing model.

1036
00:59:16,400 --> 00:59:22,240
Now the market

1037
00:59:19,520 --> 00:59:25,599
the excess return of the market has an

1038
00:59:22,240 --> 00:59:27,520
estimate that's about one with some

1039
00:59:25,599 --> 00:59:31,119
standard error. It has a huge t value

1040
00:59:27,520 --> 00:59:35,280
and a huge p value. Those

1041
00:59:31,119 --> 00:59:37,680
values being large or a huge t value and

1042
00:59:35,280 --> 00:59:40,319
very small p value are not surprising at

1043
00:59:37,680 --> 00:59:43,920
all just because they're correlated and

1044
00:59:40,319 --> 00:59:46,880
a zero value for the slope is sort of

1045
00:59:43,920 --> 00:59:51,920
meaningless here. What could be useful

1046
00:59:46,880 --> 00:59:55,200
is testing whether our beta coefficient

1047
00:59:51,920 --> 01:00:00,240
is consistent with sort of the average

1048
00:59:55,200 --> 01:00:04,799
market risk of beta equal to one or not.

1049
01:00:00,240 --> 01:00:07,680
Um but here's uh basically a plot of the

1050
01:00:04,799 --> 01:00:12,240
linear regression model for GE

1051
01:00:07,680 --> 01:00:16,640
and a discussion just of getting

1052
01:00:12,240 --> 01:00:20,559
comfortable with R squared values and

1053
01:00:16,640 --> 01:00:22,799
calibrating our views of scatter plots

1054
01:00:20,559 --> 01:00:24,799
to those values.

1055
01:00:22,799 --> 01:00:28,400
Um

1056
01:00:24,799 --> 01:00:31,760
and then there's residuals analysis that

1057
01:00:28,400 --> 01:00:33,280
is very important as I introduced

1058
01:00:31,760 --> 01:00:37,359
at the beginning of our regression

1059
01:00:33,280 --> 01:00:41,359
study. Um we make assumptions about our

1060
01:00:37,359 --> 01:00:43,520
model and we then once we fit the model

1061
01:00:41,359 --> 01:00:46,640
we check our assumptions to see whether

1062
01:00:43,520 --> 01:00:51,920
those are satisfied or not. And in this

1063
01:00:46,640 --> 01:00:55,680
case, um, we might assume that the

1064
01:00:51,920 --> 01:00:57,599
residuals are normally distributed.

1065
01:00:55,680 --> 01:01:01,040
And here's

1066
01:00:57,599 --> 01:01:05,440
a histogram of the residuals from this

1067
01:01:01,040 --> 01:01:08,480
GE uh, regression. And there actually

1068
01:01:05,440 --> 01:01:12,319
are two bell-shaped curves here. There's

1069
01:01:08,480 --> 01:01:15,280
one that's in green that corresponds to

1070
01:01:12,319 --> 01:01:18,960
the maximum likelihood estimate of the

1071
01:01:15,280 --> 01:01:23,760
mean and variance of that normal.

1072
01:01:18,960 --> 01:01:28,480
Um, but there's also a blue curve which

1073
01:01:23,760 --> 01:01:32,000
corresponds to a robust estimator of the

1074
01:01:28,480 --> 01:01:34,720
normal distribution parameters. So, and

1075
01:01:32,000 --> 01:01:36,960
we just talked a bit about normal linear

1076
01:01:34,720 --> 01:01:39,200
regressions and there being optimal.

1077
01:01:36,960 --> 01:01:42,000
Well, they're optimal so long as the

1078
01:01:39,200 --> 01:01:47,680
normal distribution is applied

1079
01:01:42,000 --> 01:01:51,920
and one can calculate what's called a QQ

1080
01:01:47,680 --> 01:01:55,920
plot of the residuals

1081
01:01:51,920 --> 01:02:00,960
where the theoretical distribution is

1082
01:01:55,920 --> 01:02:03,119
normal. We can think of ordered samples

1083
01:02:00,960 --> 01:02:05,599
of normals

1084
01:02:03,119 --> 01:02:08,000
from smallest to largest and pair those

1085
01:02:05,599 --> 01:02:11,200
with our ordered residuals from smallest

1086
01:02:08,000 --> 01:02:15,200
to largest. And this plot will look like

1087
01:02:11,200 --> 01:02:16,720
a straight line if the residuals are

1088
01:02:15,200 --> 01:02:18,480
Gaussian.

1089
01:02:16,720 --> 01:02:23,520
And

1090
01:02:18,480 --> 01:02:27,280
the green line corresponds to the MLE

1091
01:02:23,520 --> 01:02:29,839
fit of the Gaussian basically.

1092
01:02:27,280 --> 01:02:32,400
the slope will equal the standard

1093
01:02:29,839 --> 01:02:35,760
deviation of the distribution and the

1094
01:02:32,400 --> 01:02:41,440
median roughly will correspond to the

1095
01:02:35,760 --> 01:02:45,920
mean value. Um but what we have is uh a

1096
01:02:41,440 --> 01:02:48,880
robust estimate of the standard

1097
01:02:45,920 --> 01:02:52,559
deviation of the residuals

1098
01:02:48,880 --> 01:02:56,480
um gives us this blue line and the

1099
01:02:52,559 --> 01:02:59,280
robust estimate of the residual variance

1100
01:02:56,480 --> 01:03:03,119
is based on the interquartile range of

1101
01:02:59,280 --> 01:03:05,280
the residuals. So the middle 50% you

1102
01:03:03,119 --> 01:03:09,760
know what kind of standard deviation

1103
01:03:05,280 --> 01:03:11,440
would match the middle 50% range of the

1104
01:03:09,760 --> 01:03:16,319
residuals.

1105
01:03:11,440 --> 01:03:20,640
And uh there's an argument that um this

1106
01:03:16,319 --> 01:03:23,359
robust estimate might in fact be better.

1107
01:03:20,640 --> 01:03:27,920
And another way of evaluating the

1108
01:03:23,359 --> 01:03:31,200
residuals is to compute

1109
01:03:27,920 --> 01:03:37,440
fitted percentiles under the residual

1110
01:03:31,200 --> 01:03:40,240
model. So if we observe an epsilon hat

1111
01:03:37,440 --> 01:03:42,960
with mean mu hat and standard deviation

1112
01:03:40,240 --> 01:03:46,319
sigma hat,

1113
01:03:42,960 --> 01:03:49,520
we can do the probab the inverse of the

1114
01:03:46,319 --> 01:03:52,400
probability integral transform

1115
01:03:49,520 --> 01:03:57,359
and get the

1116
01:03:52,400 --> 01:04:01,599
percentile of that outcome.

1117
01:03:57,359 --> 01:04:03,440
And so uh it turns out that these

1118
01:04:01,599 --> 01:04:06,640
percentiles

1119
01:04:03,440 --> 01:04:09,200
should be uniformly distributed from

1120
01:04:06,640 --> 01:04:12,559
like 1 to 99.

1121
01:04:09,200 --> 01:04:17,039
um if the if this normal model is

1122
01:04:12,559 --> 01:04:20,640
correct and so we can actually consider

1123
01:04:17,039 --> 01:04:23,039
different estimates of sigma hat from

1124
01:04:20,640 --> 01:04:26,960
robust to

1125
01:04:23,039 --> 01:04:29,839
uh MLE and with the MLE here's the

1126
01:04:26,960 --> 01:04:33,440
histogram of the

1127
01:04:29,839 --> 01:04:37,119
uh fitted percentiles

1128
01:04:33,440 --> 01:04:39,200
it's basically underestimating

1129
01:04:37,119 --> 01:04:41,680
percentiles

1130
01:04:39,200 --> 01:04:43,200
that are close to the mean or the

1131
01:04:41,680 --> 01:04:47,599
median.

1132
01:04:43,200 --> 01:04:50,240
And um and so it really isn't fitting

1133
01:04:47,599 --> 01:04:54,240
the residuals very well across the whole

1134
01:04:50,240 --> 01:04:57,440
range. And if instead we consider fitted

1135
01:04:54,240 --> 01:05:02,000
percentiles from the robust

1136
01:04:57,440 --> 01:05:03,920
estimate of the variance, then the

1137
01:05:02,000 --> 01:05:06,000
residuals

1138
01:05:03,920 --> 01:05:09,599
fitted the fitted percentiles of the

1139
01:05:06,000 --> 01:05:13,599
residuals is consistent with uniform

1140
01:05:09,599 --> 01:05:17,839
in the middle of the data except in the

1141
01:05:13,599 --> 01:05:22,079
top 1% and the bottom 1%. So it's very

1142
01:05:17,839 --> 01:05:24,319
possible that our data has a non-normal

1143
01:05:22,079 --> 01:05:28,480
uh residual distribution or error

1144
01:05:24,319 --> 01:05:30,400
distribution. Um and perhaps that

1145
01:05:28,480 --> 01:05:34,640
non-normal distribution could be well

1146
01:05:30,400 --> 01:05:38,000
modeled with uh a mixture model.

1147
01:05:34,640 --> 01:05:40,400
Now um okay, there's regression

1148
01:05:38,000 --> 01:05:44,839
diagnostics which I'll let you read

1149
01:05:40,400 --> 01:05:44,839
through. Um,

1150
01:05:45,760 --> 01:05:50,079
and then there's this section on testing

1151
01:05:47,760 --> 01:05:52,319
hypotheses about individual model

1152
01:05:50,079 --> 01:05:55,920
coefficients.

1153
01:05:52,319 --> 01:05:57,760
Let's see. If you have this on your

1154
01:05:55,920 --> 01:05:59,520
computer, you can probably see it a

1155
01:05:57,760 --> 01:06:03,680
little better than seeing this this

1156
01:05:59,520 --> 01:06:06,480
screen here. But with the normal or with

1157
01:06:03,680 --> 01:06:08,160
our uh testing of individual

1158
01:06:06,480 --> 01:06:12,160
coefficients

1159
01:06:08,160 --> 01:06:14,480
um we basically use the fact that our le

1160
01:06:12,160 --> 01:06:18,000
squares estimator

1161
01:06:14,480 --> 01:06:21,599
is multivariant normal with mean equal

1162
01:06:18,000 --> 01:06:24,480
to the true beta vector and covariance

1163
01:06:21,599 --> 01:06:28,960
matrix given here.

1164
01:06:24,480 --> 01:06:32,400
So, so we can make various tests

1165
01:06:28,960 --> 01:06:35,440
uh of different regression parameters.

1166
01:06:32,400 --> 01:06:40,000
So, we have the t statistics for testing

1167
01:06:35,440 --> 01:06:43,680
whether a parameter value is zero or not

1168
01:06:40,000 --> 01:06:46,160
and use the t distribution to judge how

1169
01:06:43,680 --> 01:06:48,559
statistically significant that is. In

1170
01:06:46,160 --> 01:06:50,319
our capital asset pricing model case, we

1171
01:06:48,559 --> 01:06:54,960
actually are interested in testing

1172
01:06:50,319 --> 01:06:58,480
whether the alphas are zero or not.

1173
01:06:54,960 --> 01:07:00,799
And um one could also consider testing

1174
01:06:58,480 --> 01:07:03,520
for whether the beta factor is equal to

1175
01:07:00,799 --> 01:07:05,520
one or not. One for the beta is actually

1176
01:07:03,520 --> 01:07:08,400
what the average beta is across all

1177
01:07:05,520 --> 01:07:12,319
stocks in the market. And so one can

1178
01:07:08,400 --> 01:07:15,599
consider judging whether var whether

1179
01:07:12,319 --> 01:07:19,760
assets sort of have significantly high

1180
01:07:15,599 --> 01:07:24,559
risk high betas or low betas.

1181
01:07:19,760 --> 01:07:26,640
uh using a test of whether the uh

1182
01:07:24,559 --> 01:07:29,920
estimated regression coefficient is

1183
01:07:26,640 --> 01:07:35,039
significantly different from one or not.

1184
01:07:29,920 --> 01:07:38,559
And so um with this I've basically uh

1185
01:07:35,039 --> 01:07:43,200
computed this for GE

1186
01:07:38,559 --> 01:07:47,440
and it turns out that

1187
01:07:43,200 --> 01:07:51,359
um I guess the

1188
01:07:47,440 --> 01:07:56,160
t stat for uh

1189
01:07:51,359 --> 01:07:58,799
GE which corresponds to a beta of 1.083.

1190
01:07:56,160 --> 01:08:00,640
That's fairly close to one in terms of

1191
01:07:58,799 --> 01:08:03,680
absolute magnitude but it's actually a

1192
01:08:00,640 --> 01:08:07,520
bit it's statistically significant

1193
01:08:03,680 --> 01:08:13,280
according to the arguments given here.

1194
01:08:07,520 --> 01:08:16,319
Now um there are uh many packages in R

1195
01:08:13,280 --> 01:08:18,960
but one of them is the car package which

1196
01:08:16,319 --> 01:08:22,000
allows one to conduct tests of linear

1197
01:08:18,960 --> 01:08:23,759
hypotheses like these. And so it goes

1198
01:08:22,000 --> 01:08:28,080
through

1199
01:08:23,759 --> 01:08:31,600
and performs the same kinds of tests for

1200
01:08:28,080 --> 01:08:34,319
whether the intercept is zero or not.

1201
01:08:31,600 --> 01:08:37,600
And in implementing these hypothesis

1202
01:08:34,319 --> 01:08:39,679
tests, this car package uses the sort of

1203
01:08:37,600 --> 01:08:44,400
F test

1204
01:08:39,679 --> 01:08:48,880
approach. So one has results that give

1205
01:08:44,400 --> 01:08:50,799
us different residual sum of squares and

1206
01:08:48,880 --> 01:08:53,440
F statistics

1207
01:08:50,799 --> 01:08:55,920
um and P values for the F statistics

1208
01:08:53,440 --> 01:09:00,799
corresponding to these.

1209
01:08:55,920 --> 01:09:03,440
Now um let's see with

1210
01:09:00,799 --> 01:09:07,359
let's see before showing the results for

1211
01:09:03,440 --> 01:09:09,679
all the stocks in the S&P 500 there's

1212
01:09:07,359 --> 01:09:12,719
another note

1213
01:09:09,679 --> 01:09:16,719
um on regression

1214
01:09:12,719 --> 01:09:18,480
analysis hypothesis testing

1215
01:09:16,719 --> 01:09:20,000
and

1216
01:09:18,480 --> 01:09:23,679
what's

1217
01:09:20,000 --> 01:09:26,560
interesting to think about is

1218
01:09:23,679 --> 01:09:29,679
we can consider testing

1219
01:09:26,560 --> 01:09:33,600
whether a submodel, a model with out as

1220
01:09:29,679 --> 01:09:36,719
many factors in it is suitable.

1221
01:09:33,600 --> 01:09:41,600
But one can also test for whether

1222
01:09:36,719 --> 01:09:44,799
there's a change in model parameters

1223
01:09:41,600 --> 01:09:48,719
with a regime. So that maybe there's an

1224
01:09:44,799 --> 01:09:52,400
initial period with a given set of model

1225
01:09:48,719 --> 01:09:54,880
parameters and then a regime shift

1226
01:09:52,400 --> 01:09:58,560
following that where the parameter

1227
01:09:54,880 --> 01:10:01,440
values have changed. And so

1228
01:09:58,560 --> 01:10:06,000
the mathematical theory for this is

1229
01:10:01,440 --> 01:10:08,719
covered in section three and one can

1230
01:10:06,000 --> 01:10:11,280
consider testing with the capital asset

1231
01:10:08,719 --> 01:10:13,360
pricing model maybe whether there's a

1232
01:10:11,280 --> 01:10:16,640
change in regression parameters over

1233
01:10:13,360 --> 01:10:18,719
over our entire period. And so what I

1234
01:10:16,640 --> 01:10:23,440
want to

1235
01:10:18,719 --> 01:10:27,280
just uh go to is the results. Actually

1236
01:10:23,440 --> 01:10:32,560
the linear algebra for these uh

1237
01:10:27,280 --> 01:10:34,239
hypothesis testing methods um is very

1238
01:10:32,560 --> 01:10:36,640
straightforward

1239
01:10:34,239 --> 01:10:41,199
and I encourage you to read through

1240
01:10:36,640 --> 01:10:44,480
these just to see how they play out. Um

1241
01:10:41,199 --> 01:10:48,400
but um

1242
01:10:44,480 --> 01:10:52,159
let's see what's interesting I guess is

1243
01:10:48,400 --> 01:10:54,880
with this change between two periods if

1244
01:10:52,159 --> 01:10:58,239
we consider sort of an original

1245
01:10:54,880 --> 01:11:00,719
regression model y = x beta plus epsilon

1246
01:10:58,239 --> 01:11:03,360
for a very long period.

1247
01:11:00,719 --> 01:11:06,320
um we might consider splitting it up

1248
01:11:03,360 --> 01:11:09,840
into the first part period A and the

1249
01:11:06,320 --> 01:11:12,640
second part period B and have two

1250
01:11:09,840 --> 01:11:14,239
equations for the respective sets of

1251
01:11:12,640 --> 01:11:18,560
data.

1252
01:11:14,239 --> 01:11:20,800
And in thinking about

1253
01:11:18,560 --> 01:11:26,239
the two periods,

1254
01:11:20,800 --> 01:11:27,920
um, we basically can test whether the

1255
01:11:26,239 --> 01:11:29,840
regression parameters for the second

1256
01:11:27,920 --> 01:11:33,840
period are the same as the regression

1257
01:11:29,840 --> 01:11:38,400
parameters for the first period.

1258
01:11:33,840 --> 01:11:43,080
And we can write out the model equations

1259
01:11:38,400 --> 01:11:43,080
uh with appropriate matrices.

1260
01:11:43,840 --> 01:11:51,760
And then uh we basically have an F test

1261
01:11:47,520 --> 01:11:54,800
statistic for seeing whether these

1262
01:11:51,760 --> 01:11:56,719
regression parameters um are different

1263
01:11:54,800 --> 01:11:59,719
or not.

1264
01:11:56,719 --> 01:11:59,719
And

1265
01:12:00,159 --> 01:12:06,560
one can also instead of considering

1266
01:12:04,320 --> 01:12:11,120
separate parameters

1267
01:12:06,560 --> 01:12:15,760
for each period, one can consider

1268
01:12:11,120 --> 01:12:19,280
a beta value here for

1269
01:12:15,760 --> 01:12:21,120
the entire period.

1270
01:12:19,280 --> 01:12:25,600
and then

1271
01:12:21,120 --> 01:12:28,880
use that beta value together with the

1272
01:12:25,600 --> 01:12:33,199
change in parameter values

1273
01:12:28,880 --> 01:12:37,199
in period B from period A. And so one

1274
01:12:33,199 --> 01:12:40,239
can set up the regression model where

1275
01:12:37,199 --> 01:12:44,880
one is interested in whether this change

1276
01:12:40,239 --> 01:12:48,800
parameter delta is equal to zero or not.

1277
01:12:44,880 --> 01:12:53,520
And so mathematically we get f test from

1278
01:12:48,800 --> 01:12:58,719
that. Now with the um GE stock

1279
01:12:53,520 --> 01:13:02,640
I subjectively chose this period

1280
01:12:58,719 --> 01:13:06,480
split for A from B. If we look at the

1281
01:13:02,640 --> 01:13:09,840
cumulative sum of uh standardized

1282
01:13:06,480 --> 01:13:14,239
residuals from the regression model,

1283
01:13:09,840 --> 01:13:17,040
then we basically have residuals that

1284
01:13:14,239 --> 01:13:18,560
are consistently negative

1285
01:13:17,040 --> 01:13:22,000
accumulating

1286
01:13:18,560 --> 01:13:26,880
to a lower value around 2019 and then

1287
01:13:22,000 --> 01:13:30,159
later expanding beyond that. So this

1288
01:13:26,880 --> 01:13:33,440
sort of time series of

1289
01:13:30,159 --> 01:13:35,600
cumulated residuals sort of highlights

1290
01:13:33,440 --> 01:13:39,920
that there's strong time dependence in

1291
01:13:35,600 --> 01:13:42,239
the residuals. Um but if we fit the

1292
01:13:39,920 --> 01:13:44,640
regression models to these uh separate

1293
01:13:42,239 --> 01:13:47,360
regression models to these two periods,

1294
01:13:44,640 --> 01:13:50,880
we end up getting

1295
01:13:47,360 --> 01:13:53,199
highly significant results for

1296
01:13:50,880 --> 01:13:55,520
the change in the two periods. There's

1297
01:13:53,199 --> 01:13:58,159
basically an intercept which is the

1298
01:13:55,520 --> 01:14:02,320
alpha which changes from negative to

1299
01:13:58,159 --> 01:14:04,719
positive and the market risk uh

1300
01:14:02,320 --> 01:14:08,480
basically changes

1301
01:14:04,719 --> 01:14:15,360
um from 77

1302
01:14:08,480 --> 01:14:17,840
3 beta uh in the uh first period to 773

1303
01:14:15,360 --> 01:14:21,120
plus 3537

1304
01:14:17,840 --> 01:14:24,239
in the second period. So

1305
01:14:21,120 --> 01:14:26,960
these capital asset pricing models are

1306
01:14:24,239 --> 01:14:30,719
not expected perhaps to hold over really

1307
01:14:26,960 --> 01:14:34,480
really long periods of time and if we

1308
01:14:30,719 --> 01:14:36,880
wanted to uh apply them we'd likely sort

1309
01:14:34,480 --> 01:14:39,360
of choose a rolling window approach

1310
01:14:36,880 --> 01:14:41,120
perhaps which then leads to questions of

1311
01:14:39,360 --> 01:14:44,320
how do we decide on what rolling window

1312
01:14:41,120 --> 01:14:48,480
is appropriate opens up other issues to

1313
01:14:44,320 --> 01:14:52,159
study. So um

1314
01:14:48,480 --> 01:14:56,000
anyway, so with with that background for

1315
01:14:52,159 --> 01:14:59,360
hypothesis testing, let's go back to

1316
01:14:56,000 --> 01:15:03,199
the uh fitting the capital asset pricing

1317
01:14:59,360 --> 01:15:05,120
model to all stocks in the S&P 500.

1318
01:15:03,199 --> 01:15:08,400
Um

1319
01:15:05,120 --> 01:15:10,400
let's see the code here basically fits

1320
01:15:08,400 --> 01:15:12,880
this capital asset pricing model

1321
01:15:10,400 --> 01:15:16,400
regression

1322
01:15:12,880 --> 01:15:19,679
for um all the stocks

1323
01:15:16,400 --> 01:15:23,600
that have data going back several years.

1324
01:15:19,679 --> 01:15:25,120
So there were I think around 380 or 400

1325
01:15:23,600 --> 01:15:30,080
stocks

1326
01:15:25,120 --> 01:15:35,199
and they're grouped by sector and we can

1327
01:15:30,080 --> 01:15:40,080
see how the R squares of the regressions

1328
01:15:35,199 --> 01:15:44,640
vary from 0 to one. Um they typically

1329
01:15:40,080 --> 01:15:48,560
are above 02. So there's some reasonable

1330
01:15:44,640 --> 01:15:50,159
uh R squar relationships that are being

1331
01:15:48,560 --> 01:15:55,440
explained.

1332
01:15:50,159 --> 01:15:57,520
Um and if we look at the alphas

1333
01:15:55,440 --> 01:16:01,600
by sector,

1334
01:15:57,520 --> 01:16:05,520
um here's sort of parallel box plots of

1335
01:16:01,600 --> 01:16:10,159
the alphas, the alpha estimates within

1336
01:16:05,520 --> 01:16:15,800
each of the sectors. And so this

1337
01:16:10,159 --> 01:16:15,800
highlights how uh some

1338
01:16:16,880 --> 01:16:26,000
let's see some sectors like uh I guess

1339
01:16:21,199 --> 01:16:28,800
construction sort of had positive alphas

1340
01:16:26,000 --> 01:16:30,480
as did computer technology.

1341
01:16:28,800 --> 01:16:33,600
Um

1342
01:16:30,480 --> 01:16:37,040
let's see the conglomerates uh tended to

1343
01:16:33,600 --> 01:16:43,199
have negative alphas there.

1344
01:16:37,040 --> 01:16:45,440
And we can calculate uh the p values for

1345
01:16:43,199 --> 01:16:49,920
testing whether the alphas are

1346
01:16:45,440 --> 01:16:53,199
consistent with zero or not. And this

1347
01:16:49,920 --> 01:16:55,679
graph here shows

1348
01:16:53,199 --> 01:16:59,440
how the p values

1349
01:16:55,679 --> 01:17:01,040
for almost all the stocks

1350
01:16:59,440 --> 01:17:04,719
exceed

1351
01:17:01,040 --> 01:17:07,120
the p value threshold of 0.05.

1352
01:17:04,719 --> 01:17:09,120
So if we

1353
01:17:07,120 --> 01:17:13,120
can't reject

1354
01:17:09,120 --> 01:17:16,560
the null hypothesis of alpha

1355
01:17:13,120 --> 01:17:18,320
equaling zero, the p value is above

1356
01:17:16,560 --> 01:17:22,320
0.05.

1357
01:17:18,320 --> 01:17:25,360
And one can see that there's basically

1358
01:17:22,320 --> 01:17:30,080
sort of a handful or a couple of handful

1359
01:17:25,360 --> 01:17:33,840
of stocks that have a significant alpha.

1360
01:17:30,080 --> 01:17:36,880
And if we use a 5% threshold, well, we'd

1361
01:17:33,840 --> 01:17:39,440
expect 5% of the results to be

1362
01:17:36,880 --> 01:17:42,159
statistically significant when there's

1363
01:17:39,440 --> 01:17:44,880
no statistical significance. And so

1364
01:17:42,159 --> 01:17:47,520
maybe these in fact are consistent with

1365
01:17:44,880 --> 01:17:49,440
um the capital asset pricing model

1366
01:17:47,520 --> 01:17:52,400
pretty well.

1367
01:17:49,440 --> 01:17:56,480
Now um

1368
01:17:52,400 --> 01:17:58,880
let's see one can plot um the alpha

1369
01:17:56,480 --> 01:18:01,920
versus the beta across all the stocks

1370
01:17:58,880 --> 01:18:05,120
and get this result um which suggests

1371
01:18:01,920 --> 01:18:09,040
that when you have higher beta you may

1372
01:18:05,120 --> 01:18:12,480
get higher alpha as well. Um and when

1373
01:18:09,040 --> 01:18:16,080
you have very low beta, maybe the low

1374
01:18:12,480 --> 01:18:17,840
beta is partly due to a lower alpha

1375
01:18:16,080 --> 01:18:23,920
potential.

1376
01:18:17,840 --> 01:18:26,480
Um but this chart doesn't show how alpha

1377
01:18:23,920 --> 01:18:29,760
varies by sector.

1378
01:18:26,480 --> 01:18:32,960
And so if we

1379
01:18:29,760 --> 01:18:35,040
try to look at alpha by sector, we get

1380
01:18:32,960 --> 01:18:38,800
sort of different fits for different

1381
01:18:35,040 --> 01:18:41,840
sectors, which is too complex really to

1382
01:18:38,800 --> 01:18:44,320
interpret as graphed here. But um it

1383
01:18:41,840 --> 01:18:47,199
sort of as a first step at trying to

1384
01:18:44,320 --> 01:18:51,520
understand how alphas might vary within

1385
01:18:47,199 --> 01:18:54,960
different sectors. Um

1386
01:18:51,520 --> 01:18:57,360
perhaps interestingly, here's the beta

1387
01:18:54,960 --> 01:18:59,440
coefficient.

1388
01:18:57,360 --> 01:19:02,320
by sector.

1389
01:18:59,440 --> 01:19:06,080
And here one can see that certain

1390
01:19:02,320 --> 01:19:08,960
sectors like consumer staples

1391
01:19:06,080 --> 01:19:13,199
have much lower beta

1392
01:19:08,960 --> 01:19:16,320
values and other sectors like computer

1393
01:19:13,199 --> 01:19:18,719
and technology have very high betas. So

1394
01:19:16,320 --> 01:19:22,239
in terms of identifying those sectors

1395
01:19:18,719 --> 01:19:25,679
that will have low market risk or high

1396
01:19:22,239 --> 01:19:29,040
market risk, these these uh properties,

1397
01:19:25,679 --> 01:19:30,640
you know, play out quite well.

1398
01:19:29,040 --> 01:19:33,040
And

1399
01:19:30,640 --> 01:19:38,400
let's see in terms of looking at the top

1400
01:19:33,040 --> 01:19:40,800
and bottom stocks by beta. Um

1401
01:19:38,400 --> 01:19:44,719
well we have consumer discretionary

1402
01:19:40,800 --> 01:19:47,679
computer technology sector stocks are

1403
01:19:44,719 --> 01:19:50,400
the have are the sectors where the top

1404
01:19:47,679 --> 01:19:53,120
10 betas are. And if we look at the

1405
01:19:50,400 --> 01:19:56,640
lowest betas

1406
01:19:53,120 --> 01:20:01,000
ranging from 37 down to 0.18, most of

1407
01:19:56,640 --> 01:20:01,000
these are in consumer staples.

1408
01:20:01,600 --> 01:20:09,920
Finally, if we look at the top 10 stocks

1409
01:20:05,920 --> 01:20:13,199
with significant alphas, okay, here is

1410
01:20:09,920 --> 01:20:17,600
the table of alpha values that were

1411
01:20:13,199 --> 01:20:19,840
highest and one was in oils and energy

1412
01:20:17,600 --> 01:20:27,280
sector ENPH

1413
01:20:19,840 --> 01:20:30,080
U with the alpha value of 0.003.

1414
01:20:27,280 --> 01:20:33,679
Let's see here's

1415
01:20:30,080 --> 01:20:36,560
so if we have an alpha value

1416
01:20:33,679 --> 01:20:38,560
of 0.003 03

1417
01:20:36,560 --> 01:20:42,400
it's actually

1418
01:20:38,560 --> 01:20:45,199
that's it to three whatever

1419
01:20:42,400 --> 01:20:48,600
I won't have the extra but but this is a

1420
01:20:45,199 --> 01:20:48,600
daily alpha

1421
01:20:52,159 --> 01:20:58,360
um if we wanted to annualize this daily

1422
01:20:55,360 --> 01:20:58,360
alpha

1423
01:20:58,400 --> 01:21:04,719
what would that annual how would we

1424
01:21:00,400 --> 01:21:04,719
compute that annualized alpha

1425
01:21:10,560 --> 01:21:17,199
If you're earning this alpha every day,

1426
01:21:14,800 --> 01:21:22,320
it sort of is an increment of return

1427
01:21:17,199 --> 01:21:26,800
that you're expecting to get every day.

1428
01:21:22,320 --> 01:21:29,920
And so if we have 1 + alpha hat to the

1429
01:21:26,800 --> 01:21:34,159
number of days

1430
01:21:29,920 --> 01:21:38,000
there's roughly 252 days per year

1431
01:21:34,159 --> 01:21:41,840
um and then subtract one

1432
01:21:38,000 --> 01:21:44,239
then we end up getting

1433
01:21:41,840 --> 01:21:47,520
let's see

1434
01:21:44,239 --> 01:21:52,080
I computed this

1435
01:21:47,520 --> 01:21:55,120
it's it's uh 2.12 two minus one

1436
01:21:52,080 --> 01:21:58,400
basically. So this is like a 100%. So

1437
01:21:55,120 --> 01:22:02,560
this stock happened to just deliver huge

1438
01:21:58,400 --> 01:22:04,480
amount of returns. Um but um what's

1439
01:22:02,560 --> 01:22:06,800
interesting to see though is that this

1440
01:22:04,480 --> 01:22:09,040
relatively simple model the capital

1441
01:22:06,800 --> 01:22:11,840
asset pricing model appears to be

1442
01:22:09,040 --> 01:22:15,360
consistent with the stocks over a long

1443
01:22:11,840 --> 01:22:19,440
period of time. That being said, um you

1444
01:22:15,360 --> 01:22:23,360
know the uh more complex models are um

1445
01:22:19,440 --> 01:22:26,639
warranted and um the data

1446
01:22:23,360 --> 01:22:30,400
collection phase of this our project um

1447
01:22:26,639 --> 01:22:32,639
included importing FMA French factors

1448
01:22:30,400 --> 01:22:34,800
that are extensions of sort of the

1449
01:22:32,639 --> 01:22:38,440
market risk that can be used in these

1450
01:22:34,800 --> 01:22:38,440
models. So,


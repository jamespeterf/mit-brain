1
00:00:08,160 --> 00:00:12,240
So I'll be sharing some work that my

2
00:00:10,559 --> 00:00:15,040
group has been doing over the past few

3
00:00:12,240 --> 00:00:16,440
years in uh in computational topology.

4
00:00:15,040 --> 00:00:19,039
Here are my

5
00:00:16,440 --> 00:00:20,320
disclosures. Um and this is just a list

6
00:00:19,039 --> 00:00:21,680
of everything I'll be talking about

7
00:00:20,320 --> 00:00:23,920
today in case you want to go back and

8
00:00:21,680 --> 00:00:25,920
look at some of these studies later. So

9
00:00:23,920 --> 00:00:28,560
my group predominantly focuses on

10
00:00:25,920 --> 00:00:32,079
computational pathology. So when uh

11
00:00:28,560 --> 00:00:34,079
glass slides are are are digitized

12
00:00:32,079 --> 00:00:36,559
um they look something like this. So

13
00:00:34,079 --> 00:00:38,800
large images that are hierarchical uh

14
00:00:36,559 --> 00:00:40,640
and harbor information at many many

15
00:00:38,800 --> 00:00:43,360
different scales. They're more like

16
00:00:40,640 --> 00:00:44,879
satellite images uh something you know

17
00:00:43,360 --> 00:00:49,120
similar to what you would see on on

18
00:00:44,879 --> 00:00:51,200
Google maps or Google Earth. Um and uh

19
00:00:49,120 --> 00:00:52,960
these information the the these slides

20
00:00:51,200 --> 00:00:55,199
harbor a lot of a lot of information.

21
00:00:52,960 --> 00:00:58,079
The interesting thing about pathology is

22
00:00:55,199 --> 00:01:00,079
that it's one of the oldest uh

23
00:00:58,079 --> 00:01:02,320
diagnostic modalities but it's also one

24
00:01:00,079 --> 00:01:04,720
of the oldest research modalities. So so

25
00:01:02,320 --> 00:01:07,680
it's been around for a very very long

26
00:01:04,720 --> 00:01:10,479
time. uh as everyone here knows it's

27
00:01:07,680 --> 00:01:13,280
used for very fundamental biological

28
00:01:10,479 --> 00:01:17,119
research but on on human animal all

29
00:01:13,280 --> 00:01:19,280
kinds of tissue uh but also for uh for

30
00:01:17,119 --> 00:01:23,119
clinical uh clinical diagnostics right

31
00:01:19,280 --> 00:01:24,400
so um but a caveat is that this is

32
00:01:23,119 --> 00:01:26,799
despite being one of the oldest

33
00:01:24,400 --> 00:01:28,080
modalities is also also a modality

34
00:01:26,799 --> 00:01:29,840
that's only recently began to be

35
00:01:28,080 --> 00:01:34,159
digitized I think the first scanner came

36
00:01:29,840 --> 00:01:36,000
about about 20 years ago and still most

37
00:01:34,159 --> 00:01:38,079
hospitals in the country are not

38
00:01:36,000 --> 00:01:40,000
entirely digital and the standard of

39
00:01:38,079 --> 00:01:42,640
care remains looking at glass slides

40
00:01:40,000 --> 00:01:44,560
under under a microscope. All the other

41
00:01:42,640 --> 00:01:46,240
modalities that came about later like

42
00:01:44,560 --> 00:01:48,479
genomics and other kinds of information

43
00:01:46,240 --> 00:01:50,960
that we can extract from tissue are by

44
00:01:48,479 --> 00:01:53,119
default digital and computational. So we

45
00:01:50,960 --> 00:01:55,439
still haven't incorporated uh

46
00:01:53,119 --> 00:01:57,200
information from this modality into our

47
00:01:55,439 --> 00:01:59,439
diagnostic prognostic therapeutic

48
00:01:57,200 --> 00:02:00,520
response or resistance prediction

49
00:01:59,439 --> 00:02:02,040
prediction

50
00:02:00,520 --> 00:02:05,840
paradigms.

51
00:02:02,040 --> 00:02:07,920
Um and uh so what we predominantly do is

52
00:02:05,840 --> 00:02:09,759
that we essentially try to analyze these

53
00:02:07,920 --> 00:02:11,039
images using computational machine

54
00:02:09,759 --> 00:02:12,640
learning tools to get to everything in

55
00:02:11,039 --> 00:02:14,239
the red box here whether it's early

56
00:02:12,640 --> 00:02:15,840
diagnosis, prognosis, response to

57
00:02:14,239 --> 00:02:17,920
treatment, patient stratification and so

58
00:02:15,840 --> 00:02:19,840
forth. Essentially discovery from this

59
00:02:17,920 --> 00:02:21,120
this kind of data but we also

60
00:02:19,840 --> 00:02:22,959
incorporate information from other

61
00:02:21,120 --> 00:02:25,040
modalities where necessary to try to f

62
00:02:22,959 --> 00:02:27,520
fulfill some of those objectives. Um, so

63
00:02:25,040 --> 00:02:29,680
I'll be talking mostly about the the

64
00:02:27,520 --> 00:02:31,280
work that my my lab does in in human

65
00:02:29,680 --> 00:02:33,280
pathology, but we also do a lot of work

66
00:02:31,280 --> 00:02:36,000
in pre-clinical drug screening and

67
00:02:33,280 --> 00:02:39,680
toxicology and how to make those uh

68
00:02:36,000 --> 00:02:42,080
processes more efficient. Uh, and uh, a

69
00:02:39,680 --> 00:02:43,599
lot of those uh, questions essentially

70
00:02:42,080 --> 00:02:45,440
require the same computational tools

71
00:02:43,599 --> 00:02:47,840
that we that we build. But I won't be

72
00:02:45,440 --> 00:02:50,080
talking a lot about that aspect uh,

73
00:02:47,840 --> 00:02:51,440
today. So the history of the field is

74
00:02:50,080 --> 00:02:54,239
very interesting and I always like to

75
00:02:51,440 --> 00:02:56,480
talk about it. So Judith Prevette uh was

76
00:02:54,239 --> 00:02:58,000
a real pioneer in this field and she's

77
00:02:56,480 --> 00:02:59,920
really an unsung hero because some of

78
00:02:58,000 --> 00:03:02,560
the work that she was doing in the 60s

79
00:02:59,920 --> 00:03:04,720
and 70s is phenomenal around how she was

80
00:03:02,560 --> 00:03:06,560
thinking about this uh about this

81
00:03:04,720 --> 00:03:08,720
problem. She worked at the University of

82
00:03:06,560 --> 00:03:10,400
Pennsylvania then at NIH and finally at

83
00:03:08,720 --> 00:03:12,239
the university university of Upsala

84
00:03:10,400 --> 00:03:14,480
where she had access to large mainframe

85
00:03:12,239 --> 00:03:16,400
computers. uh but this this study from

86
00:03:14,480 --> 00:03:18,640
1963 and in particular this study from

87
00:03:16,400 --> 00:03:20,959
1965 if you look at how she was

88
00:03:18,640 --> 00:03:22,400
analyzing these images so so she

89
00:03:20,959 --> 00:03:24,560
realized that these images are very very

90
00:03:22,400 --> 00:03:26,080
large she was chopping them up into

91
00:03:24,560 --> 00:03:27,680
smaller patches we still do this today

92
00:03:26,080 --> 00:03:30,560
because we can't fit these mega images

93
00:03:27,680 --> 00:03:33,760
into in in in into GPU memory at least

94
00:03:30,560 --> 00:03:34,760
not to do uh the kind of training we do

95
00:03:33,760 --> 00:03:38,159
and

96
00:03:34,760 --> 00:03:39,680
um storing these in magnetic uh tape

97
00:03:38,159 --> 00:03:41,440
using optical density and then using

98
00:03:39,680 --> 00:03:43,280
very fundamental line profiles to assess

99
00:03:41,440 --> 00:03:45,280
whether an image is is deemed to be

100
00:03:43,280 --> 00:03:47,120
positive or negative. What a lot of

101
00:03:45,280 --> 00:03:50,480
people don't know is that this became

102
00:03:47,120 --> 00:03:53,040
the basis of the very first FDA approved

103
00:03:50,480 --> 00:03:57,840
um pathology algorithm was called uh

104
00:03:53,040 --> 00:04:01,840
autoap uh for papsmears in the 19 1990s

105
00:03:57,840 --> 00:04:04,000
and uh uh has has been used since to

106
00:04:01,840 --> 00:04:06,319
reduce workload to triage out negative

107
00:04:04,000 --> 00:04:08,480
cases and is one of the only uh

108
00:04:06,319 --> 00:04:10,959
pathology based algorithms that is

109
00:04:08,480 --> 00:04:12,879
approved for primary diagnosis such that

110
00:04:10,959 --> 00:04:14,720
the pathologist does not have to go back

111
00:04:12,879 --> 00:04:16,400
and look at that particular

112
00:04:14,720 --> 00:04:18,720
particular image. And then you know with

113
00:04:16,400 --> 00:04:20,400
the all the in more recent times there's

114
00:04:18,720 --> 00:04:23,199
been a lot of work using handcrafted

115
00:04:20,400 --> 00:04:25,759
features essentially reflecting how we

116
00:04:23,199 --> 00:04:28,000
perceive these images uh and coming up

117
00:04:25,759 --> 00:04:30,720
with features that would be reflective

118
00:04:28,000 --> 00:04:32,880
of those uh uh of that perception. And

119
00:04:30,720 --> 00:04:35,520
then post 2015 the utility of

120
00:04:32,880 --> 00:04:38,400
convolutional neural networks uh and

121
00:04:35,520 --> 00:04:41,199
this was predominantly achieved by uh

122
00:04:38,400 --> 00:04:43,199
pixel level uh annotation on these on

123
00:04:41,199 --> 00:04:45,759
these slides. However, this is very far

124
00:04:43,199 --> 00:04:47,280
removed from how this data is available

125
00:04:45,759 --> 00:04:48,800
and collected clinically. So,

126
00:04:47,280 --> 00:04:51,680
clinically, we don't collect any pixel

127
00:04:48,800 --> 00:04:53,120
level annotations on these uh on these

128
00:04:51,680 --> 00:04:54,400
images. Once you have these annotations,

129
00:04:53,120 --> 00:04:57,040
you can, you know, separate that data

130
00:04:54,400 --> 00:04:58,800
into buckets and use very fundamental

131
00:04:57,040 --> 00:05:01,600
deep learning algorithms to classify

132
00:04:58,800 --> 00:05:04,639
cancer, normal, subtype, grade,

133
00:05:01,600 --> 00:05:07,919
anything. But, uh the the issue is the

134
00:05:04,639 --> 00:05:10,800
labels. we don't have uh pixel level

135
00:05:07,919 --> 00:05:12,240
annotations uh as part of the regular

136
00:05:10,800 --> 00:05:14,160
clinical workflow and that's where we

137
00:05:12,240 --> 00:05:15,520
all all these weekly supervised methods

138
00:05:14,160 --> 00:05:18,000
that have been developed for this kind

139
00:05:15,520 --> 00:05:20,000
of data come in and uh the two most

140
00:05:18,000 --> 00:05:21,360
common ones are the utility of using

141
00:05:20,000 --> 00:05:22,960
graph convolutional neural networks

142
00:05:21,360 --> 00:05:24,720
where you can segment all the all the

143
00:05:22,960 --> 00:05:27,039
cells and build a build a cell graph on

144
00:05:24,720 --> 00:05:29,120
top of it. Um that can be quite

145
00:05:27,039 --> 00:05:31,199
computationally complex especially given

146
00:05:29,120 --> 00:05:33,680
that each case can have a multitude of

147
00:05:31,199 --> 00:05:35,600
slides. the average slides per case are

148
00:05:33,680 --> 00:05:38,720
between 8 to nine but but a single case

149
00:05:35,600 --> 00:05:41,360
can have up to 100 100 gigapixel uh

150
00:05:38,720 --> 00:05:43,120
slides. So uh the most common approach

151
00:05:41,360 --> 00:05:44,639
which would you know which comes to mind

152
00:05:43,120 --> 00:05:46,000
from from a machine learning point of

153
00:05:44,639 --> 00:05:48,080
view is is the utility of multiple

154
00:05:46,000 --> 00:05:49,840
instance learning right because you you

155
00:05:48,080 --> 00:05:51,600
have large images maybe you can split

156
00:05:49,840 --> 00:05:53,280
them into smaller smaller patches and

157
00:05:51,600 --> 00:05:56,320
per case you also have multitude of

158
00:05:53,280 --> 00:05:58,400
images. So whenever you have lots of uh

159
00:05:56,320 --> 00:06:00,720
lots of instances you can use multiple

160
00:05:58,400 --> 00:06:02,560
instance learning assuming that uh a

161
00:06:00,720 --> 00:06:04,400
slide is a bag of many many small

162
00:06:02,560 --> 00:06:07,440
patches and if you if you're using a max

163
00:06:04,400 --> 00:06:09,360
pulling based aggregation function um

164
00:06:07,440 --> 00:06:10,720
the the assumption would be that even if

165
00:06:09,360 --> 00:06:12,560
one of those patches is positive the

166
00:06:10,720 --> 00:06:15,520
entire slide would be considered to be

167
00:06:12,560 --> 00:06:16,880
to to to be positive. Um an issue with

168
00:06:15,520 --> 00:06:19,440
this approach is that this makes this

169
00:06:16,880 --> 00:06:21,759
setup inherently data inefficient

170
00:06:19,440 --> 00:06:24,000
because uh the weights and biases of the

171
00:06:21,759 --> 00:06:26,240
model could be updated using a single

172
00:06:24,000 --> 00:06:28,720
256 x 256 patch. And this is what was

173
00:06:26,240 --> 00:06:30,400
articulated in this 2019 really seinal

174
00:06:28,720 --> 00:06:32,560
study was published at the Memorial

175
00:06:30,400 --> 00:06:34,880
Sloan Ketering Cancer Center where they

176
00:06:32,560 --> 00:06:37,280
showed that you needed about 10,000

177
00:06:34,880 --> 00:06:38,560
pulses to get the same level of

178
00:06:37,280 --> 00:06:41,520
performance you would get with slide

179
00:06:38,560 --> 00:06:42,880
level labels. This is back in 2019 and

180
00:06:41,520 --> 00:06:45,759
they're focusing on targeting very

181
00:06:42,880 --> 00:06:48,479
fundamental problems like like detection

182
00:06:45,759 --> 00:06:51,759
uh subtyping grading uh and

183
00:06:48,479 --> 00:06:53,360
prognostication, right? But but we we

184
00:06:51,759 --> 00:06:55,039
really wanted to see if there's a

185
00:06:53,360 --> 00:06:56,880
there's a more data efficient way to do

186
00:06:55,039 --> 00:07:00,560
this and we started working in this area

187
00:06:56,880 --> 00:07:02,720
around around the same time in 200 2019.

188
00:07:00,560 --> 00:07:05,280
Uh so we can target the more interesting

189
00:07:02,720 --> 00:07:07,199
problems in pathology like rare cancers,

190
00:07:05,280 --> 00:07:10,400
clinical trials, patient stratification.

191
00:07:07,199 --> 00:07:12,800
So uh in 2021 we published this study

192
00:07:10,400 --> 00:07:16,000
and it's called the method clustering

193
00:07:12,800 --> 00:07:17,039
constraint attention mal and it used a

194
00:07:16,000 --> 00:07:18,960
number of different bells and whistles

195
00:07:17,039 --> 00:07:20,400
that were that were developed for

196
00:07:18,960 --> 00:07:22,639
computer vision. We brought them into

197
00:07:20,400 --> 00:07:24,160
pathology and this included uh attention

198
00:07:22,639 --> 00:07:25,919
based multiple instance learning the

199
00:07:24,160 --> 00:07:27,840
utility of pre-trained encoders and and

200
00:07:25,919 --> 00:07:29,440
using clustering as a mechanism to

201
00:07:27,840 --> 00:07:30,960
cluster together similar morphologic

202
00:07:29,440 --> 00:07:32,800
regions within the slide. So a slide

203
00:07:30,960 --> 00:07:36,160
would have lots of normal regions lots

204
00:07:32,800 --> 00:07:38,400
of u uh disease positive tumor regions.

205
00:07:36,160 --> 00:07:40,560
So, so clustering can potentially help

206
00:07:38,400 --> 00:07:42,560
uh associate similar regions together

207
00:07:40,560 --> 00:07:44,160
across entire entire cohorts. And we

208
00:07:42,560 --> 00:07:47,120
made this tool publicly available and

209
00:07:44,160 --> 00:07:49,360
over time this has sort of become uh

210
00:07:47,120 --> 00:07:52,000
very widely used and has been applied to

211
00:07:49,360 --> 00:07:55,120
almost every every disease model that's

212
00:07:52,000 --> 00:07:57,280
tackled using uh human uh human for for

213
00:07:55,120 --> 00:07:58,879
human pathology. Um so so the basic

214
00:07:57,280 --> 00:08:00,800
workflow is is is actually very very

215
00:07:58,879 --> 00:08:02,560
simple. It's it's you have whole slide

216
00:08:00,800 --> 00:08:04,240
images. You scan them. Once they're

217
00:08:02,560 --> 00:08:06,400
scanned, you have a whole uh you you you

218
00:08:04,240 --> 00:08:07,919
you have a large hierarchical image. You

219
00:08:06,400 --> 00:08:09,440
can segment the tissue, patch it into

220
00:08:07,919 --> 00:08:10,800
smaller patches, and then you can

221
00:08:09,440 --> 00:08:12,319
extract features, right? So, so there

222
00:08:10,800 --> 00:08:14,000
was a lot of work that was training this

223
00:08:12,319 --> 00:08:16,879
end to end, but but but that can be

224
00:08:14,000 --> 00:08:18,720
inherently slow uh computationally

225
00:08:16,879 --> 00:08:20,160
limiting. But if you use a pre-trained

226
00:08:18,720 --> 00:08:21,599
uh encoder in the beginning, we were

227
00:08:20,160 --> 00:08:25,360
just using a resnet that was trained on

228
00:08:21,599 --> 00:08:28,080
imageet features. uh so you standard uh

229
00:08:25,360 --> 00:08:29,199
uh between 2019 and and up until

230
00:08:28,080 --> 00:08:31,520
recently when we started using

231
00:08:29,199 --> 00:08:32,800
self-supervised learning it was really

232
00:08:31,520 --> 00:08:34,880
just a resnet that was trained on

233
00:08:32,800 --> 00:08:36,080
imageet features you have eventually get

234
00:08:34,880 --> 00:08:37,839
to a patch embedding there's there's

235
00:08:36,080 --> 00:08:39,519
some aggregation and then the slide

236
00:08:37,839 --> 00:08:41,120
level embedding gets fed into a

237
00:08:39,519 --> 00:08:42,640
predictor and you can pose this as being

238
00:08:41,120 --> 00:08:44,000
any kind of machine learning problem

239
00:08:42,640 --> 00:08:45,760
this could be a classification problem

240
00:08:44,000 --> 00:08:48,800
targeting you know disease detection

241
00:08:45,760 --> 00:08:51,120
subtyping grading or it could be a a

242
00:08:48,800 --> 00:08:53,040
prognostication problem where uh you're

243
00:08:51,120 --> 00:08:54,800
you're essentially solving a or a

244
00:08:53,040 --> 00:08:56,480
ranking problem, ranking patients into

245
00:08:54,800 --> 00:08:57,760
distinct risk groups or it could be

246
00:08:56,480 --> 00:09:00,160
treatment response, anything anything

247
00:08:57,760 --> 00:09:01,920
that you practically have a label

248
00:09:00,160 --> 00:09:03,839
available for. So a number of different

249
00:09:01,920 --> 00:09:05,600
applications we targeted back in we

250
00:09:03,839 --> 00:09:06,640
started it started this in 2019. I'll

251
00:09:05,600 --> 00:09:08,000
just say a little bit about those

252
00:09:06,640 --> 00:09:10,560
applications. So we we looked into

253
00:09:08,000 --> 00:09:11,920
cancers of unknown primary when I think

254
00:09:10,560 --> 00:09:13,680
most people here are familiar when

255
00:09:11,920 --> 00:09:15,839
cancer metastasizes it often becomes

256
00:09:13,680 --> 00:09:17,360
unclear what the origin of the tumor

257
00:09:15,839 --> 00:09:20,320
might be and most treatments are based

258
00:09:17,360 --> 00:09:21,440
off of the origin. So this is this is a

259
00:09:20,320 --> 00:09:24,560
critical problem. These patients

260
00:09:21,440 --> 00:09:26,800
typically undergo large workups of of uh

261
00:09:24,560 --> 00:09:29,080
not not only diagnostic pathology but

262
00:09:26,800 --> 00:09:31,360
also radiology

263
00:09:29,080 --> 00:09:33,360
endoscopy, repeated molecular testing to

264
00:09:31,360 --> 00:09:35,680
try to see if if the origin can be

265
00:09:33,360 --> 00:09:37,200
determined and and uh if an origin is

266
00:09:35,680 --> 00:09:39,440
not determined, the patient often cannot

267
00:09:37,200 --> 00:09:42,000
enroll in clinical trials either. So in

268
00:09:39,440 --> 00:09:43,760
this study from 2021, the the primary

269
00:09:42,000 --> 00:09:46,000
question we tried to answer is that can

270
00:09:43,760 --> 00:09:47,839
we use conventional H& images to

271
00:09:46,000 --> 00:09:49,440
determine what the origin might be? And

272
00:09:47,839 --> 00:09:51,040
we believe this would be possible

273
00:09:49,440 --> 00:09:52,680
because there's lots of studies showing

274
00:09:51,040 --> 00:09:55,040
that you can predict molecular

275
00:09:52,680 --> 00:09:56,320
alterations or or or essentially proving

276
00:09:55,040 --> 00:09:58,240
that there are there there are more

277
00:09:56,320 --> 00:10:00,399
morphologic correlates to molecular

278
00:09:58,240 --> 00:10:01,760
alterations within the hisystologology

279
00:10:00,399 --> 00:10:04,160
hisystology image. And we showed that

280
00:10:01,760 --> 00:10:06,560
you know you you could predict what the

281
00:10:04,160 --> 00:10:08,240
what the origin is. uh you know

282
00:10:06,560 --> 00:10:09,760
effectively solving first a binary

283
00:10:08,240 --> 00:10:11,279
problem whether whether the case is

284
00:10:09,760 --> 00:10:14,480
primary versus metastatic and then then

285
00:10:11,279 --> 00:10:17,600
an 18 classification problem about what

286
00:10:14,480 --> 00:10:19,880
the origin origin might be and then uh

287
00:10:17,600 --> 00:10:21,839
looking at the top three top five

288
00:10:19,880 --> 00:10:23,680
predictions was was critical because it

289
00:10:21,839 --> 00:10:25,920
can give you an essential hint for what

290
00:10:23,680 --> 00:10:28,640
the origin might be and you can order

291
00:10:25,920 --> 00:10:30,880
ancillary tests like IC's to confirm to

292
00:10:28,640 --> 00:10:32,399
confirm that that that origin that that

293
00:10:30,880 --> 00:10:34,959
reduces time and this is something that

294
00:10:32,399 --> 00:10:37,600
we have implemented at at at MGH that

295
00:10:34,959 --> 00:10:40,320
for every metastatic case we're able to

296
00:10:37,600 --> 00:10:42,240
look at what the possible origins might

297
00:10:40,320 --> 00:10:43,920
be and then already order those those

298
00:10:42,240 --> 00:10:45,519
ancillary tests before a physician

299
00:10:43,920 --> 00:10:47,200
starts looking at it before a

300
00:10:45,519 --> 00:10:49,519
pathologist starts looking at it. More

301
00:10:47,200 --> 00:10:51,200
recently we have also used the all the

302
00:10:49,519 --> 00:10:52,800
molecular data that we had available

303
00:10:51,200 --> 00:10:55,920
that was available to us from the Dina

304
00:10:52,800 --> 00:10:57,279
Farber profile cohort uh and we have

305
00:10:55,920 --> 00:10:58,959
tried to combine hisystologology and

306
00:10:57,279 --> 00:11:01,360
molecular data using very fundamental

307
00:10:58,959 --> 00:11:03,040
form of form of fusion. This this was a

308
00:11:01,360 --> 00:11:04,720
study that really started a while ago

309
00:11:03,040 --> 00:11:06,640
but then you know the amount of

310
00:11:04,720 --> 00:11:08,800
validation that was that that was needed

311
00:11:06,640 --> 00:11:10,240
to to do this took took several years

312
00:11:08,800 --> 00:11:11,600
because we needed to get data from other

313
00:11:10,240 --> 00:11:13,839
other institutions and it's very

314
00:11:11,600 --> 00:11:16,000
difficult to get uh cancers of unknown

315
00:11:13,839 --> 00:11:17,279
primary cases where the origin was

316
00:11:16,000 --> 00:11:18,480
already determined but this will be

317
00:11:17,279 --> 00:11:20,160
coming out in the next couple of weeks

318
00:11:18,480 --> 00:11:21,600
where we try to combine hisystologology

319
00:11:20,160 --> 00:11:24,560
and molecular data to see if we can

320
00:11:21,600 --> 00:11:28,320
improve origin origin prediction. uh and

321
00:11:24,560 --> 00:11:29,440
we basically assess that um how well can

322
00:11:28,320 --> 00:11:31,120
you predict the origin just from

323
00:11:29,440 --> 00:11:32,240
molecular data from histologology and

324
00:11:31,120 --> 00:11:34,560
what happens when you combine

325
00:11:32,240 --> 00:11:36,720
histologology and uh and molecular data.

326
00:11:34,560 --> 00:11:38,240
Another application we targeted using

327
00:11:36,720 --> 00:11:40,880
the same sort of paradigm was around

328
00:11:38,240 --> 00:11:42,320
endomyioardial biopsy assessments after

329
00:11:40,880 --> 00:11:44,959
heart transplants. Patients often

330
00:11:42,320 --> 00:11:47,279
undergo repeated endomyiocardial uh

331
00:11:44,959 --> 00:11:48,640
biopsies or heart biopsies to to

332
00:11:47,279 --> 00:11:50,399
determine if the donor heart is being

333
00:11:48,640 --> 00:11:51,839
rejected by the recipient. This is a

334
00:11:50,399 --> 00:11:53,360
problem where there's a large intra and

335
00:11:51,839 --> 00:11:55,120
intraobserver variability and we wanted

336
00:11:53,360 --> 00:11:56,880
to see if it's possible for us to

337
00:11:55,120 --> 00:11:58,320
standardize this a little bit more using

338
00:11:56,880 --> 00:12:00,640
using these machine learning techniques.

339
00:11:58,320 --> 00:12:01,920
This was a study from back in 2022. I

340
00:12:00,640 --> 00:12:04,880
mean I wouldn't go into the details but

341
00:12:01,920 --> 00:12:07,120
there's a lot of uh analysis around what

342
00:12:04,880 --> 00:12:08,880
happens when you use do do when you have

343
00:12:07,120 --> 00:12:12,320
human in the loop uh assessments for

344
00:12:08,880 --> 00:12:13,920
these biopsies. So uh another as another

345
00:12:12,320 --> 00:12:15,760
sort of application was trying to see if

346
00:12:13,920 --> 00:12:18,000
we can combine uh hisystologology and

347
00:12:15,760 --> 00:12:20,480
molecular data to improve prognostic

348
00:12:18,000 --> 00:12:22,639
models. So we know that molecular data

349
00:12:20,480 --> 00:12:23,680
is is is directly very prognostic. There

350
00:12:22,639 --> 00:12:25,760
are a number of these commercially

351
00:12:23,680 --> 00:12:32,760
available prognostic assays like Pigma

352
00:12:25,760 --> 00:12:34,800
Alpype DX. Um all of them are uh uh

353
00:12:32,760 --> 00:12:36,399
they're they're good to a degree.

354
00:12:34,800 --> 00:12:38,880
They're they're they're imperfect but

355
00:12:36,399 --> 00:12:40,079
but but they do work. So but but we

356
00:12:38,880 --> 00:12:41,440
basically wanted to answer two

357
00:12:40,079 --> 00:12:44,399
questions. Is it possible for us to

358
00:12:41,440 --> 00:12:45,920
combine histologology data with the

359
00:12:44,399 --> 00:12:47,519
molecular information to see if we can

360
00:12:45,920 --> 00:12:49,200
improve prognostication? because

361
00:12:47,519 --> 00:12:50,800
histologology data is relatively free,

362
00:12:49,200 --> 00:12:52,160
right? It's it's always there and it's

363
00:12:50,800 --> 00:12:54,320
it's available, it's very it's a very

364
00:12:52,160 --> 00:12:56,160
cheap modality. So if you can

365
00:12:54,320 --> 00:12:58,480
prognosticate patients by combining it

366
00:12:56,160 --> 00:13:01,120
with with with molecular data, why not?

367
00:12:58,480 --> 00:13:04,560
Um and the other question would be that

368
00:13:01,120 --> 00:13:07,040
can we predict uh similar uh patient

369
00:13:04,560 --> 00:13:08,240
separation uh just from the

370
00:13:07,040 --> 00:13:10,480
hisystologology hisystologology alone.

371
00:13:08,240 --> 00:13:12,639
And the third one was effectively around

372
00:13:10,480 --> 00:13:13,600
looking at uh once we have made these

373
00:13:12,639 --> 00:13:15,519
predictions, they're all done in a

374
00:13:13,600 --> 00:13:17,200
weekly supervised manner. And can can we

375
00:13:15,519 --> 00:13:18,880
go back and look at what's important in

376
00:13:17,200 --> 00:13:21,200
the molecular profile, what's important

377
00:13:18,880 --> 00:13:23,839
in the in the morphologic profile in an

378
00:13:21,200 --> 00:13:26,079
attempt to make uh assessments, you

379
00:13:23,839 --> 00:13:27,519
know, discover new markers and and we

380
00:13:26,079 --> 00:13:28,880
did a lot of analysis on the 14

381
00:13:27,519 --> 00:13:30,560
different cancer types that were that

382
00:13:28,880 --> 00:13:32,800
were assessed. And we have since made

383
00:13:30,560 --> 00:13:33,839
the all of that publicly available and

384
00:13:32,800 --> 00:13:36,160
people have found all kinds of

385
00:13:33,839 --> 00:13:38,560
morphologic features uh that are

386
00:13:36,160 --> 00:13:40,639
consistent across uh across across

387
00:13:38,560 --> 00:13:43,040
patients. This was a cancer cell article

388
00:13:40,639 --> 00:13:46,320
from back in 2022.

389
00:13:43,040 --> 00:13:47,839
Um so coming back to the uh ML paradigm

390
00:13:46,320 --> 00:13:50,399
that we're effectively using. So it

391
00:13:47,839 --> 00:13:52,000
became clear that the uh feature

392
00:13:50,399 --> 00:13:53,200
extraction component is is the most

393
00:13:52,000 --> 00:13:54,480
important component to me. Started

394
00:13:53,200 --> 00:13:55,760
experimenting with self-supervised

395
00:13:54,480 --> 00:13:57,680
learning as it was becoming popular

396
00:13:55,760 --> 00:14:00,000
initially with by using contrasted

397
00:13:57,680 --> 00:14:01,680
predictive coding back in 2021. It was a

398
00:14:00,000 --> 00:14:03,519
new article where we showed that you can

399
00:14:01,680 --> 00:14:05,519
use contrasted predictive coding to

400
00:14:03,519 --> 00:14:07,680
improve feature presentation for these

401
00:14:05,519 --> 00:14:11,839
uh large multiple instance learning uh

402
00:14:07,680 --> 00:14:13,440
problems. In 2022, we uh we developed

403
00:14:11,839 --> 00:14:14,880
something that we call hierarchical

404
00:14:13,440 --> 00:14:16,399
image pyramid transformer that makes

405
00:14:14,880 --> 00:14:19,519
makes use of the inherent hierarchy in

406
00:14:16,399 --> 00:14:21,199
the in the in in the pathology image to

407
00:14:19,519 --> 00:14:22,800
and and uses self-supervised learning on

408
00:14:21,199 --> 00:14:25,040
top of it to improve representation at

409
00:14:22,800 --> 00:14:28,920
at at various different hierarchical

410
00:14:25,040 --> 00:14:31,839
scales. That's a CVPR study from 2020 uh

411
00:14:28,920 --> 00:14:33,680
2022. Um and then uh last year we

412
00:14:31,839 --> 00:14:36,720
published these two foundation models.

413
00:14:33,680 --> 00:14:38,800
uh and and I think that the the critical

414
00:14:36,720 --> 00:14:40,720
inflection point was that when uh Meta

415
00:14:38,800 --> 00:14:42,240
showed in their Dynino V2 study that the

416
00:14:40,720 --> 00:14:43,440
diversity of data is much more important

417
00:14:42,240 --> 00:14:45,600
than the quantity of data, something

418
00:14:43,440 --> 00:14:49,519
that we you know we we always knew but

419
00:14:45,600 --> 00:14:51,040
but it was like a proof. Um uh we that

420
00:14:49,519 --> 00:14:52,800
gave us an opening that that we we don't

421
00:14:51,040 --> 00:14:54,320
effectively need to scan every single

422
00:14:52,800 --> 00:14:55,680
slide through our history to develop a

423
00:14:54,320 --> 00:14:58,880
foundation model for pathology. We could

424
00:14:55,680 --> 00:15:01,199
we could potentially go back our archive

425
00:14:58,880 --> 00:15:03,360
um and look at what are the most diverse

426
00:15:01,199 --> 00:15:05,199
cases, pull those diverse the most the

427
00:15:03,360 --> 00:15:07,120
most diverse cases and scan those and

428
00:15:05,199 --> 00:15:09,440
potentially that would be good enough to

429
00:15:07,120 --> 00:15:12,320
develop a develop a foundation model

430
00:15:09,440 --> 00:15:14,000
representing human pathology. Um so to

431
00:15:12,320 --> 00:15:15,920
test that hypothesis we basically did

432
00:15:14,000 --> 00:15:18,000
exactly that. We look through Brigham

433
00:15:15,920 --> 00:15:19,920
and M MGH archives looking at all the

434
00:15:18,000 --> 00:15:23,360
pathology reports finding what are the

435
00:15:19,920 --> 00:15:25,760
most unique uh cases and pull those

436
00:15:23,360 --> 00:15:27,040
cases scan them uh and then you know

437
00:15:25,760 --> 00:15:28,880
develop these models. The other one was

438
00:15:27,040 --> 00:15:30,399
a vision language model and these models

439
00:15:28,880 --> 00:15:33,040
were made publicly available and have

440
00:15:30,399 --> 00:15:34,639
since been downloaded over 1.4 million

441
00:15:33,040 --> 00:15:36,639
times and they've been out for about a

442
00:15:34,639 --> 00:15:38,000
year and we're still investigating what

443
00:15:36,639 --> 00:15:40,079
the impact has been but they've already

444
00:15:38,000 --> 00:15:42,399
been used in over 400 different studies.

445
00:15:40,079 --> 00:15:45,360
And I think one key aspect is that

446
00:15:42,399 --> 00:15:48,000
pathology data is so fundamental to uh

447
00:15:45,360 --> 00:15:50,240
everything we do in biio medicine in in

448
00:15:48,000 --> 00:15:52,240
general. But there's never been sort of

449
00:15:50,240 --> 00:15:54,000
a clear way on how to incorporate this

450
00:15:52,240 --> 00:15:56,800
data. It's large, complex, all of that,

451
00:15:54,000 --> 00:15:59,040
right? It exists. But but if but if you

452
00:15:56,800 --> 00:16:00,320
can have uh you know lower dimensional

453
00:15:59,040 --> 00:16:02,000
representations of that data, it's it's

454
00:16:00,320 --> 00:16:03,360
it's it's quite easy to incorporate that

455
00:16:02,000 --> 00:16:07,920
into any question that you might be

456
00:16:03,360 --> 00:16:09,360
might be on asking. Um, so, uh, sorry,

457
00:16:07,920 --> 00:16:11,199
could you define what you mean when you

458
00:16:09,360 --> 00:16:14,079
say like looking for the most unique

459
00:16:11,199 --> 00:16:15,680
pathology images? Like, is that by

460
00:16:14,079 --> 00:16:18,399
defined by a pathologist or is there

461
00:16:15,680 --> 00:16:20,240
some sort of metric for diversity? We we

462
00:16:18,399 --> 00:16:22,079
looked at a number of different uh ways.

463
00:16:20,240 --> 00:16:23,920
I mean, I mean, you could just embed all

464
00:16:22,079 --> 00:16:26,240
the pathology reports and see in feature

465
00:16:23,920 --> 00:16:27,759
space uh how they separate. That's what

466
00:16:26,240 --> 00:16:30,000
we initially did because we have, you

467
00:16:27,759 --> 00:16:32,880
know, 22 million pathology reports. So,

468
00:16:30,000 --> 00:16:34,240
so how do you figure out uh so we we

469
00:16:32,880 --> 00:16:37,120
started looking at all the pathology

470
00:16:34,240 --> 00:16:39,600
reports then you know uh embedding them

471
00:16:37,120 --> 00:16:42,160
and then so the reports are images and

472
00:16:39,600 --> 00:16:44,800
text or just images just just text just

473
00:16:42,160 --> 00:16:46,880
text okay reports are just text no image

474
00:16:44,800 --> 00:16:49,199
so so they typically so so there's a lot

475
00:16:46,880 --> 00:16:50,880
of diversity across the reports uh they

476
00:16:49,199 --> 00:16:53,199
have diagnostic information grade

477
00:16:50,880 --> 00:16:56,240
information clinical correlations and it

478
00:16:53,199 --> 00:16:57,920
varies a lot across pathologists so so

479
00:16:56,240 --> 00:16:59,600
pathologists in community hospitals

480
00:16:57,920 --> 00:17:01,839
would often write a detailed report with

481
00:16:59,600 --> 00:17:04,400
morphologic description and everything

482
00:17:01,839 --> 00:17:05,760
in there leading up to the diagnosis. A

483
00:17:04,400 --> 00:17:07,199
lot of pathologists in more advanced

484
00:17:05,760 --> 00:17:08,880
centers would just say well you know

485
00:17:07,199 --> 00:17:13,120
this is renal cell carcinoma full stop

486
00:17:08,880 --> 00:17:15,039
and right so so there's there's culture

487
00:17:13,120 --> 00:17:18,799
um but they would always have

488
00:17:15,039 --> 00:17:20,880
information about uh diagnosis uh if

489
00:17:18,799 --> 00:17:24,480
there's any prognostic indication such

490
00:17:20,880 --> 00:17:25,919
as grade um so so there's some some

491
00:17:24,480 --> 00:17:27,439
standardization to it and then there's

492
00:17:25,919 --> 00:17:28,880
also synoptic reports so we didn't look

493
00:17:27,439 --> 00:17:31,280
at synoptic reports we just looked at

494
00:17:28,880 --> 00:17:34,080
the descriptive reports embedded them

495
00:17:31,280 --> 00:17:37,760
and look looking at it in feature case.

496
00:17:34,080 --> 00:17:40,480
Uh uh that was one way. Uh but we also

497
00:17:37,760 --> 00:17:42,960
looked at just by looking at the

498
00:17:40,480 --> 00:17:44,640
diagnosis how diverse it is. Uh and then

499
00:17:42,960 --> 00:17:47,360
there was some existing data that we had

500
00:17:44,640 --> 00:17:49,280
collected in in the past for other for

501
00:17:47,360 --> 00:17:51,120
other projects that was also that was

502
00:17:49,280 --> 00:17:52,559
also used and in in often cases some of

503
00:17:51,120 --> 00:17:54,080
the data that we're collecting was very

504
00:17:52,559 --> 00:17:55,799
diverse to begin with because dealing

505
00:17:54,080 --> 00:17:59,000
with rare disease and other kinds of

506
00:17:55,799 --> 00:18:03,679
indications. Yeah. So

507
00:17:59,000 --> 00:18:05,600
uh um so in this uh so it was around

508
00:18:03,679 --> 00:18:07,600
100,000 cases. We have 100 million

509
00:18:05,600 --> 00:18:09,440
pathology images from 100,000 cases.

510
00:18:07,600 --> 00:18:11,480
This was the initial version of the uh

511
00:18:09,440 --> 00:18:14,320
of the model and it used the Dino V2

512
00:18:11,480 --> 00:18:15,919
framework for for training and at the

513
00:18:14,320 --> 00:18:17,120
time we compared it with a number of

514
00:18:15,919 --> 00:18:18,960
other models as well as just the

515
00:18:17,120 --> 00:18:22,080
baseline ResNet 50 trained on imageet

516
00:18:18,960 --> 00:18:24,640
that was the most commonly used um

517
00:18:22,080 --> 00:18:27,360
encoder for for pathology images and it

518
00:18:24,640 --> 00:18:29,600
was applied to you know 33 clinical

519
00:18:27,360 --> 00:18:31,520
tasks downstream. The radar plot is a

520
00:18:29,600 --> 00:18:33,280
terrible way to look at it, but uh it

521
00:18:31,520 --> 00:18:34,559
does capture all the all the different

522
00:18:33,280 --> 00:18:36,640
tasks that were done and what the

523
00:18:34,559 --> 00:18:38,720
comparative analysis is with other other

524
00:18:36,640 --> 00:18:40,880
kinds of models including looking at

525
00:18:38,720 --> 00:18:43,919
classification, retrieval or image

526
00:18:40,880 --> 00:18:45,679
search uh segmentation and uh and both

527
00:18:43,919 --> 00:18:47,760
at original level and at a slide level.

528
00:18:45,679 --> 00:18:49,919
So these are just some results for slide

529
00:18:47,760 --> 00:18:52,559
level classification and it it has very

530
00:18:49,919 --> 00:18:55,200
difficult tasks and and also relatively

531
00:18:52,559 --> 00:18:56,960
easy easy tasks and we can see what the

532
00:18:55,200 --> 00:18:58,480
performance difference is for example

533
00:18:56,960 --> 00:19:01,120
with a ResNet baseline which was

534
00:18:58,480 --> 00:19:02,400
typically used before we we we put these

535
00:19:01,120 --> 00:19:04,880
studies out there. There's there's been

536
00:19:02,400 --> 00:19:06,240
a lot of uh foundation models since and

537
00:19:04,880 --> 00:19:08,320
then the performance of these models has

538
00:19:06,240 --> 00:19:10,880
began to saturate but uh it's important

539
00:19:08,320 --> 00:19:13,039
to also see that fshot uh performance

540
00:19:10,880 --> 00:19:15,120
has improved significantly o over the

541
00:19:13,039 --> 00:19:18,320
years. I mean, back in 2019, we're

542
00:19:15,120 --> 00:19:21,360
looking at you using 10,000 slides to

543
00:19:18,320 --> 00:19:22,400
try to uh capture performance that that

544
00:19:21,360 --> 00:19:23,760
one would get with pixel level

545
00:19:22,400 --> 00:19:25,280
annotations all the way up to more

546
00:19:23,760 --> 00:19:27,280
recently where you can use a few slides

547
00:19:25,280 --> 00:19:30,640
in a few shot manner and still get

548
00:19:27,280 --> 00:19:33,360
clinically useful uh useful performance.

549
00:19:30,640 --> 00:19:35,600
Um so in parallel, we also uh worked on

550
00:19:33,360 --> 00:19:37,039
this study where we tried to see if we

551
00:19:35,600 --> 00:19:38,799
can contrast with text to improve

552
00:19:37,039 --> 00:19:40,960
representation. I think this study sort

553
00:19:38,799 --> 00:19:42,559
of started this basically observing

554
00:19:40,960 --> 00:19:43,600
everything that's going on in in machine

555
00:19:42,559 --> 00:19:45,679
learning where we're seeing that

556
00:19:43,600 --> 00:19:47,760
contrasting across data multiple kinds

557
00:19:45,679 --> 00:19:49,520
of data is is has the capability of

558
00:19:47,760 --> 00:19:51,520
improved representation and and this is

559
00:19:49,520 --> 00:19:52,960
great for for pathology because there's

560
00:19:51,520 --> 00:19:54,960
a lot of morphologic description that's

561
00:19:52,960 --> 00:19:57,200
available for pathology and and and

562
00:19:54,960 --> 00:19:58,880
these kind of contrasting contrastive

563
00:19:57,200 --> 00:20:00,480
models make use of the redundancy across

564
00:19:58,880 --> 00:20:03,039
modalities to improve representation for

565
00:20:00,480 --> 00:20:04,799
each individual individual modality. Uh

566
00:20:03,039 --> 00:20:06,640
in this case this was more of a proof of

567
00:20:04,799 --> 00:20:08,799
concept where we used 1.1 million image

568
00:20:06,640 --> 00:20:10,559
caption pairs from the PubMed open

569
00:20:08,799 --> 00:20:12,400
access database. I mean a lot of people

570
00:20:10,559 --> 00:20:13,840
have asked us why have we not used the

571
00:20:12,400 --> 00:20:15,120
entire PubMed database. There's no way

572
00:20:13,840 --> 00:20:16,720
for us to do that. There's there are

573
00:20:15,120 --> 00:20:18,480
licensing issues and that data is also

574
00:20:16,720 --> 00:20:19,600
not you know just readily readily

575
00:20:18,480 --> 00:20:22,240
available. Also it was limited to the

576
00:20:19,600 --> 00:20:26,240
PubMed open access database and we sort

577
00:20:22,240 --> 00:20:28,159
of uh um just used human tissue and then

578
00:20:26,240 --> 00:20:33,120
used morphologic description that is

579
00:20:28,159 --> 00:20:34,640
corresponding uh the the image and uh by

580
00:20:33,120 --> 00:20:37,120
contrasting between the two this is this

581
00:20:34,640 --> 00:20:38,720
is a distribution for where all all the

582
00:20:37,120 --> 00:20:40,240
organ systems that were that were used

583
00:20:38,720 --> 00:20:42,120
we we showed that you could improve

584
00:20:40,240 --> 00:20:45,360
improve representation and

585
00:20:42,120 --> 00:20:47,919
there's a lot of analysis around uh how

586
00:20:45,360 --> 00:20:49,600
this compares to image only uh this this

587
00:20:47,919 --> 00:20:52,320
example is for for for fus shot learning

588
00:20:49,600 --> 00:20:54,240
and we we we can already begin to get

589
00:20:52,320 --> 00:20:58,480
clinically useful performance using

590
00:20:54,240 --> 00:21:00,080
about eight uh eight or nine u slides.

591
00:20:58,480 --> 00:21:01,919
There's been quite a lot of independent

592
00:21:00,080 --> 00:21:03,440
validation of these of these models.

593
00:21:01,919 --> 00:21:06,320
Here's some validation that that came

594
00:21:03,440 --> 00:21:07,919
from Jacob Cather's group in uh in in

595
00:21:06,320 --> 00:21:09,679
Dresston and there's also some

596
00:21:07,919 --> 00:21:11,120
validation from Thomas Hux's group at

597
00:21:09,679 --> 00:21:14,559
the Memorial Stone Catering Cancer

598
00:21:11,120 --> 00:21:17,120
Center and from Mount Si. they've used

599
00:21:14,559 --> 00:21:19,400
this on their own uh their own data and

600
00:21:17,120 --> 00:21:22,000
I think that there's lots of models

601
00:21:19,400 --> 00:21:23,200
around for for pathology now lots of

602
00:21:22,000 --> 00:21:25,360
different foundation models they've all

603
00:21:23,200 --> 00:21:28,320
kind of saturated in in performance but

604
00:21:25,360 --> 00:21:30,320
one key key aspect is that uh because we

605
00:21:28,320 --> 00:21:32,240
really focused on diversifying the data

606
00:21:30,320 --> 00:21:34,640
the models continue to be uh

607
00:21:32,240 --> 00:21:37,120
state-of-the-art and we we we have uh

608
00:21:34,640 --> 00:21:40,480
put out additional models that use more

609
00:21:37,120 --> 00:21:42,880
data um and have also answered some some

610
00:21:40,480 --> 00:21:44,559
fundamental questions around how how to

611
00:21:42,880 --> 00:21:48,159
build these models in a in in an

612
00:21:44,559 --> 00:21:51,600
effective manner. So the next step next

613
00:21:48,159 --> 00:21:53,679
obvious step for us was to see how can

614
00:21:51,600 --> 00:21:55,760
we get to a slide level uh

615
00:21:53,679 --> 00:21:57,520
representation. So uni and con both of

616
00:21:55,760 --> 00:21:59,280
those models give you patch origin level

617
00:21:57,520 --> 00:22:01,919
representation but but it would be nice

618
00:21:59,280 --> 00:22:03,440
to have a representation at the level of

619
00:22:01,919 --> 00:22:05,280
the slide. So a single feature vector

620
00:22:03,440 --> 00:22:06,400
representing the entire slide. If you

621
00:22:05,280 --> 00:22:08,400
have that of course your learning

622
00:22:06,400 --> 00:22:12,080
problems on top of it would would become

623
00:22:08,400 --> 00:22:13,919
uh easy but also uh we have to make make

624
00:22:12,080 --> 00:22:15,760
sure that the single vector representing

625
00:22:13,919 --> 00:22:17,360
a gigapixel slide is sensitive enough of

626
00:22:15,760 --> 00:22:20,000
the morphology within the within within

627
00:22:17,360 --> 00:22:22,640
the slide. So uh we started by looking

628
00:22:20,000 --> 00:22:25,679
at sort of this these very obvious

629
00:22:22,640 --> 00:22:27,840
things like uh well we we have all these

630
00:22:25,679 --> 00:22:30,159
morphologies can we look use something

631
00:22:27,840 --> 00:22:31,760
like gauian mixture models to just come

632
00:22:30,159 --> 00:22:33,280
up with a slide level slide level

633
00:22:31,760 --> 00:22:35,600
representation and we did that and

634
00:22:33,280 --> 00:22:37,280
showed that this this is possible I mean

635
00:22:35,600 --> 00:22:39,440
these are just some examples in survival

636
00:22:37,280 --> 00:22:42,720
outcome outcome prediction. This was a

637
00:22:39,440 --> 00:22:44,720
CVPR study from 2023. Uh more recently

638
00:22:42,720 --> 00:22:47,440
we've expanded this into a much larger

639
00:22:44,720 --> 00:22:49,679
effort and we call this uh this this

640
00:22:47,440 --> 00:22:51,360
model Titan it's a slide level model and

641
00:22:49,679 --> 00:22:55,039
it trains at three levels. The first

642
00:22:51,360 --> 00:22:57,440
level is at the um at at just the just

643
00:22:55,039 --> 00:23:00,000
the image level where we use ibot

644
00:22:57,440 --> 00:23:02,240
self-supervised training and we sort of

645
00:23:00,000 --> 00:23:03,919
brought in uh concepts that are

646
00:23:02,240 --> 00:23:06,080
typically used for large language models

647
00:23:03,919 --> 00:23:07,919
like train short test long typically

648
00:23:06,080 --> 00:23:09,280
used to develop these you know large

649
00:23:07,919 --> 00:23:10,880
language models or multimodal large

650
00:23:09,280 --> 00:23:12,960
language models where you're training on

651
00:23:10,880 --> 00:23:14,720
a shorter shorter context and then and

652
00:23:12,960 --> 00:23:16,320
then testing on a larger context. So in

653
00:23:14,720 --> 00:23:18,880
this case in this case we were training

654
00:23:16,320 --> 00:23:21,440
on AK by AK and then testing at at the

655
00:23:18,880 --> 00:23:23,840
entire slide level to get a slide level

656
00:23:21,440 --> 00:23:25,919
uh representation uh but also by

657
00:23:23,840 --> 00:23:28,240
contrasting with two kinds of text

658
00:23:25,919 --> 00:23:30,159
information. So the first one was uh is

659
00:23:28,240 --> 00:23:32,720
morphologic description that's generated

660
00:23:30,159 --> 00:23:34,720
using our uh generative model that I'll

661
00:23:32,720 --> 00:23:36,799
talk about in a second but also by

662
00:23:34,720 --> 00:23:38,799
contrasting with pathology pathology

663
00:23:36,799 --> 00:23:40,720
reports and the contrastive uh learning

664
00:23:38,799 --> 00:23:42,240
approach uh helps us improve

665
00:23:40,720 --> 00:23:44,799
representation. So as these models are

666
00:23:42,240 --> 00:23:49,360
getting better, our benchmarks are also

667
00:23:44,799 --> 00:23:51,760
u improving. So uh we don't show results

668
00:23:49,360 --> 00:23:53,600
here for basic subtyping or grading and

669
00:23:51,760 --> 00:23:56,080
because it's saturated in performance

670
00:23:53,600 --> 00:23:57,679
for all of them in in this case we're

671
00:23:56,080 --> 00:24:00,000
showing much more complex benchmarks

672
00:23:57,679 --> 00:24:01,520
like you know 108 class rare disease

673
00:24:00,000 --> 00:24:02,880
prediction. But key results here is that

674
00:24:01,520 --> 00:24:05,120
you can look at the scaling laws what

675
00:24:02,880 --> 00:24:07,039
happens when you increase the num number

676
00:24:05,120 --> 00:24:08,480
of data points used for training. But

677
00:24:07,039 --> 00:24:12,960
you can also look at what happens with

678
00:24:08,480 --> 00:24:15,360
with image contrasting. So, so how the

679
00:24:12,960 --> 00:24:17,360
uh representation improves. So, sorry

680
00:24:15,360 --> 00:24:20,159
text contrasting when you contrast with

681
00:24:17,360 --> 00:24:23,799
morphologic descriptions uh to to

682
00:24:20,159 --> 00:24:26,000
improve the the the the image image

683
00:24:23,799 --> 00:24:28,559
representation. And of course you can

684
00:24:26,000 --> 00:24:30,640
look at few shot uh performance on all

685
00:24:28,559 --> 00:24:32,400
of these different tasks as well uh by

686
00:24:30,640 --> 00:24:34,799
using very very few labels which really

687
00:24:32,400 --> 00:24:36,880
is very important in pathology because a

688
00:24:34,799 --> 00:24:38,240
lot of very interesting questions that

689
00:24:36,880 --> 00:24:39,760
we want to answer that what's the next

690
00:24:38,240 --> 00:24:42,000
patient that's best to enroll in a

691
00:24:39,760 --> 00:24:44,159
particular clinical trial uh rare

692
00:24:42,000 --> 00:24:45,600
disease all are effectively few shot

693
00:24:44,159 --> 00:24:48,559
problems we don't have lots of data

694
00:24:45,600 --> 00:24:50,640
available for them anyways um and then

695
00:24:48,559 --> 00:24:52,400
retrieval and similar slide search so so

696
00:24:50,640 --> 00:24:57,279
this is something that's inherently done

697
00:24:52,400 --> 00:25:00,240
in uh pathology ology um u for rare

698
00:24:57,279 --> 00:25:01,760
disease. So the the typical workflow

699
00:25:00,240 --> 00:25:04,480
unfortunately is still that every major

700
00:25:01,760 --> 00:25:06,720
pathology department would have somebody

701
00:25:04,480 --> 00:25:08,960
who specializes in these kinds of rare

702
00:25:06,720 --> 00:25:11,120
diseases and they would look at a case

703
00:25:08,960 --> 00:25:13,279
and try to compare it with an existing

704
00:25:11,120 --> 00:25:15,440
case or a case that existed long time

705
00:25:13,279 --> 00:25:17,679
ago and and that comparative analysis

706
00:25:15,440 --> 00:25:19,039
would then lead to lead to a diagnosis.

707
00:25:17,679 --> 00:25:20,000
And here we try to do it computitionally

708
00:25:19,039 --> 00:25:21,520
because we have slide level

709
00:25:20,000 --> 00:25:23,760
representation. It's very very easy to

710
00:25:21,520 --> 00:25:25,440
build a database find what the most

711
00:25:23,760 --> 00:25:27,760
closest slide would be in in feature

712
00:25:25,440 --> 00:25:29,760
space and could help diagnose uh

713
00:25:27,760 --> 00:25:32,559
diagnose rare disease and then we assess

714
00:25:29,760 --> 00:25:35,039
this on large amounts of internal cancer

715
00:25:32,559 --> 00:25:39,279
data as well as on on external external

716
00:25:35,039 --> 00:25:40,720
data. So the if if we uh just just recap

717
00:25:39,279 --> 00:25:42,159
some of the some of the story that I

718
00:25:40,720 --> 00:25:43,520
have that I've told that multiple

719
00:25:42,159 --> 00:25:46,640
instance learning is the most commonly

720
00:25:43,520 --> 00:25:49,360
used paradigm for um processing uh

721
00:25:46,640 --> 00:25:51,840
pathology whole slide images into um

722
00:25:49,360 --> 00:25:53,360
some kind of meaningful uh learning

723
00:25:51,840 --> 00:25:54,960
paradigm and and feature representation

724
00:25:53,360 --> 00:25:56,720
is important. You can use cells

725
00:25:54,960 --> 00:25:59,039
supervision to improve feature feature

726
00:25:56,720 --> 00:26:00,400
representation um and then contrasting

727
00:25:59,039 --> 00:26:02,559
with additional modalities improved

728
00:26:00,400 --> 00:26:05,360
improves image representation as well.

729
00:26:02,559 --> 00:26:08,880
So uh just in light of that there's a

730
00:26:05,360 --> 00:26:10,720
lot of other data uh in pathology that

731
00:26:08,880 --> 00:26:12,080
you could be contrasting with right so

732
00:26:10,720 --> 00:26:13,679
we show that you can you can contrast

733
00:26:12,080 --> 00:26:16,000
with text to improve representation but

734
00:26:13,679 --> 00:26:20,159
there's also you know uh morphologic

735
00:26:16,000 --> 00:26:22,960
data uh so sorry molecular data and also

736
00:26:20,159 --> 00:26:24,400
u iminostic chemistry radiology other

737
00:26:22,960 --> 00:26:25,440
kinds of data that you can contrast with

738
00:26:24,400 --> 00:26:27,279
to potentially improve image

739
00:26:25,440 --> 00:26:29,840
representation. So we we tried to test

740
00:26:27,279 --> 00:26:32,640
this hypothesis uh in a number of the

741
00:26:29,840 --> 00:26:35,600
different studies. So this is from ECCV

742
00:26:32,640 --> 00:26:38,880
last year where we contrast H& images

743
00:26:35,600 --> 00:26:41,600
with IHC images and special stains and

744
00:26:38,880 --> 00:26:43,120
by contrasting with IC images and

745
00:26:41,600 --> 00:26:44,640
special stains we effectively show that

746
00:26:43,120 --> 00:26:49,200
you can improve image representation

747
00:26:44,640 --> 00:26:50,799
both for the H& and for the IC and uh we

748
00:26:49,200 --> 00:26:52,480
applied it to a number of different

749
00:26:50,799 --> 00:26:54,720
downstream tasks. If we can contrast

750
00:26:52,480 --> 00:26:56,480
with with imminent chemistry we can also

751
00:26:54,720 --> 00:26:59,679
contrast with molecular data. Right? So

752
00:26:56,480 --> 00:27:02,240
contrasting with molecular data um and

753
00:26:59,679 --> 00:27:04,080
and this study is is from CBPR last year

754
00:27:02,240 --> 00:27:07,880
where we where we're contrasting with

755
00:27:04,080 --> 00:27:10,799
molecular data to improve image uh

756
00:27:07,880 --> 00:27:15,440
representation and uh what's important

757
00:27:10,799 --> 00:27:16,279
is that um we found that uh contrasting

758
00:27:15,440 --> 00:27:19,279
with

759
00:27:16,279 --> 00:27:22,320
transcripttoics this was a sort of a toy

760
00:27:19,279 --> 00:27:23,919
uh study just done on the TCGA to assess

761
00:27:22,320 --> 00:27:25,840
this hypothesis that contrasting with

762
00:27:23,919 --> 00:27:27,520
transcrytoics would do better and

763
00:27:25,840 --> 00:27:30,000
contrasting with for example text. So

764
00:27:27,520 --> 00:27:31,919
text is very subjective but

765
00:27:30,000 --> 00:27:34,240
transcrytoics is much more objective. So

766
00:27:31,919 --> 00:27:36,159
so so if it's true that it relies on

767
00:27:34,240 --> 00:27:37,760
what's common across these these

768
00:27:36,159 --> 00:27:39,360
multiple modalities to improve image

769
00:27:37,760 --> 00:27:41,919
representation we should get a much

770
00:27:39,360 --> 00:27:43,919
richer uh slide level representation by

771
00:27:41,919 --> 00:27:45,600
contrasting with transcrytoics and

772
00:27:43,919 --> 00:27:47,120
that's what we found. So for the three

773
00:27:45,600 --> 00:27:49,520
different cases that were studied in

774
00:27:47,120 --> 00:27:52,720
this small study, we found that few shot

775
00:27:49,520 --> 00:27:55,039
uh performance improved substantially

776
00:27:52,720 --> 00:27:57,039
um when when contrasting with molecular

777
00:27:55,039 --> 00:27:58,640
data. So so this was first indication

778
00:27:57,039 --> 00:28:00,480
that this is this aspect should be

779
00:27:58,640 --> 00:28:02,799
scaled. So that's what we did in this

780
00:28:00,480 --> 00:28:05,279
study that we call threads and uh this

781
00:28:02,799 --> 00:28:06,559
is we have a preprint for this and this

782
00:28:05,279 --> 00:28:07,679
will be coming out soon but but we

783
00:28:06,559 --> 00:28:10,080
basically contrasted with all the

784
00:28:07,679 --> 00:28:13,039
molecular data that was available to us

785
00:28:10,080 --> 00:28:15,520
from the uh Dana Farber Bighgam profile

786
00:28:13,039 --> 00:28:16,799
cohort as well as from from MGH and

787
00:28:15,520 --> 00:28:19,200
because this is contrasting and not

788
00:28:16,799 --> 00:28:21,360
fusion we can have separate heads uh for

789
00:28:19,200 --> 00:28:23,360
for for each type of molecular data that

790
00:28:21,360 --> 00:28:25,520
is that is included. So the goal is not

791
00:28:23,360 --> 00:28:26,960
to fuse this information to get to a

792
00:28:25,520 --> 00:28:29,279
particular answer but the goal is to

793
00:28:26,960 --> 00:28:31,559
contrast across this information such

794
00:28:29,279 --> 00:28:33,840
that to improve image image uh

795
00:28:31,559 --> 00:28:35,039
representation and we found that by by

796
00:28:33,840 --> 00:28:36,240
doing that we were able to improve

797
00:28:35,039 --> 00:28:39,120
performance in a number of very

798
00:28:36,240 --> 00:28:40,240
difficult tasks that are that are um

799
00:28:39,120 --> 00:28:41,760
that are quite challenging like

800
00:28:40,240 --> 00:28:44,240
treatment response prediction like like

801
00:28:41,760 --> 00:28:45,520
here there there are all these different

802
00:28:44,240 --> 00:28:46,480
uh drugs and we're predicting treatment

803
00:28:45,520 --> 00:28:48,000
response directly from the

804
00:28:46,480 --> 00:28:49,919
hisystologology hisystologology image

805
00:28:48,000 --> 00:28:52,320
and there's a there for some of these

806
00:28:49,919 --> 00:28:54,880
there's the drastic improvement when

807
00:28:52,320 --> 00:28:57,440
using uh this model that was trained uh

808
00:28:54,880 --> 00:28:59,440
by contrasting between histologology and

809
00:28:57,440 --> 00:29:00,960
uh and molecular data. So we're we're

810
00:28:59,440 --> 00:29:03,120
still scaling this with more data from

811
00:29:00,960 --> 00:29:05,919
other other institutions and see how how

812
00:29:03,120 --> 00:29:08,399
far how far we can go we can go. Other

813
00:29:05,919 --> 00:29:09,679
people have uh also indicated to us that

814
00:29:08,399 --> 00:29:11,679
that this is sort of a proof of concept

815
00:29:09,679 --> 00:29:13,279
that we can contrast against lots of

816
00:29:11,679 --> 00:29:14,880
modalities and improve representations

817
00:29:13,279 --> 00:29:17,440
for each one of those individual

818
00:29:14,880 --> 00:29:19,520
individual modalities. So everything

819
00:29:17,440 --> 00:29:20,880
that I've discussed so far is about

820
00:29:19,520 --> 00:29:22,880
improving image representation in

821
00:29:20,880 --> 00:29:25,440
pathology that can then be made more

822
00:29:22,880 --> 00:29:27,200
specific to lots of downstream tasks

823
00:29:25,440 --> 00:29:29,200
answering specific questions. But if you

824
00:29:27,200 --> 00:29:31,600
have rich representation from these

825
00:29:29,200 --> 00:29:34,640
images, one obvious thing we can do with

826
00:29:31,600 --> 00:29:36,360
this is to build uh a co-pilot or a

827
00:29:34,640 --> 00:29:39,840
generative model that you can

828
00:29:36,360 --> 00:29:41,919
then use uh to answer to answer

829
00:29:39,840 --> 00:29:43,679
questions. So what what would we need to

830
00:29:41,919 --> 00:29:45,039
do to build a multimodal large language

831
00:29:43,679 --> 00:29:46,960
model that would cater to all of human

832
00:29:45,039 --> 00:29:49,039
pathology? You would basically need rich

833
00:29:46,960 --> 00:29:50,960
image representations which we already

834
00:29:49,039 --> 00:29:53,039
have using some of the foundation models

835
00:29:50,960 --> 00:29:55,279
that we had developed but we also need

836
00:29:53,039 --> 00:29:58,799
uh representation but we also need uh

837
00:29:55,279 --> 00:30:00,720
instructions. So um the the philosophy

838
00:29:58,799 --> 00:30:02,480
behind creating instructions is that you

839
00:30:00,720 --> 00:30:04,000
know pathology data is hierarchical

840
00:30:02,480 --> 00:30:07,440
harbors information at many different

841
00:30:04,000 --> 00:30:09,039
scales. A good uh chatbot or a

842
00:30:07,440 --> 00:30:11,679
multimodel large language model should

843
00:30:09,039 --> 00:30:15,120
be able to answer questions at any level

844
00:30:11,679 --> 00:30:17,520
of uh uh of of abstraction. uh but we

845
00:30:15,120 --> 00:30:18,960
don't have uh that morphologic

846
00:30:17,520 --> 00:30:20,399
description readily available to us. The

847
00:30:18,960 --> 00:30:23,679
only thing we have is pathogenous

848
00:30:20,399 --> 00:30:25,360
reports corresponding the the entire

849
00:30:23,679 --> 00:30:27,679
slide. So so we needed to create lots of

850
00:30:25,360 --> 00:30:29,279
instructions. Uh so we started to do

851
00:30:27,679 --> 00:30:30,480
that manually and created managed to

852
00:30:29,279 --> 00:30:32,080
create quite a lot of instructions

853
00:30:30,480 --> 00:30:34,480
manually but over time it became clear

854
00:30:32,080 --> 00:30:36,640
that this was sort of a very difficult

855
00:30:34,480 --> 00:30:38,240
difficult task. So we made use of a lot

856
00:30:36,640 --> 00:30:41,039
of training materials that exist at

857
00:30:38,240 --> 00:30:43,279
Harvard hospitals and other institutions

858
00:30:41,039 --> 00:30:45,760
um other collaborators who contributed

859
00:30:43,279 --> 00:30:47,520
training training materials effectively

860
00:30:45,760 --> 00:30:49,440
using the same materials that are used

861
00:30:47,520 --> 00:30:51,679
to train residents and pathologists to

862
00:30:49,440 --> 00:30:54,559
train this multimodal multimodal large

863
00:30:51,679 --> 00:30:56,880
language large language model. Um and

864
00:30:54,559 --> 00:30:59,039
once we had the

865
00:30:56,880 --> 00:31:00,960
um the model trained we could then you

866
00:30:59,039 --> 00:31:02,720
know go in start asking questions about

867
00:31:00,960 --> 00:31:03,919
about regions within the pathology

868
00:31:02,720 --> 00:31:05,360
image. In the beginning we're targeting

869
00:31:03,919 --> 00:31:07,760
very fundamental and simple questions

870
00:31:05,360 --> 00:31:10,399
and over time uh this has become like a

871
00:31:07,760 --> 00:31:14,399
large uh large effort to really scale

872
00:31:10,399 --> 00:31:16,000
scale this. We could also uh just couple

873
00:31:14,399 --> 00:31:17,520
a cell phone to a microscope. It's very

874
00:31:16,000 --> 00:31:21,360
common to do this in lower resource

875
00:31:17,520 --> 00:31:23,120
settings uh and pathologists often send

876
00:31:21,360 --> 00:31:25,279
their colleagues in more resourcerich

877
00:31:23,120 --> 00:31:28,559
settings images that are taken in this

878
00:31:25,279 --> 00:31:30,960
manner. So we can get uh responses uh

879
00:31:28,559 --> 00:31:32,559
right away. Some foundations that we do

880
00:31:30,960 --> 00:31:34,880
some work with are very interested in in

881
00:31:32,559 --> 00:31:37,919
in using this in lower resource settings

882
00:31:34,880 --> 00:31:39,360
to get immediate answers because um it's

883
00:31:37,919 --> 00:31:41,279
typically quite difficult for them to

884
00:31:39,360 --> 00:31:43,440
track the patient back once they've left

885
00:31:41,279 --> 00:31:45,679
the left the city where where the

886
00:31:43,440 --> 00:31:48,159
hospital is. Uh they can't just send the

887
00:31:45,679 --> 00:31:50,720
report over their phone. Um so so this

888
00:31:48,159 --> 00:31:54,559
is also of of interest in in in low

889
00:31:50,720 --> 00:31:57,200
resource settings. Um but the but the

890
00:31:54,559 --> 00:31:58,720
real proof is uh you know in in the

891
00:31:57,200 --> 00:32:00,080
assessment. So we did a lot of initial

892
00:31:58,720 --> 00:32:02,399
assessment that was based on multiple

893
00:32:00,080 --> 00:32:06,080
choice questions comparing with more

894
00:32:02,399 --> 00:32:07,679
general models like GPD4. Um and then uh

895
00:32:06,080 --> 00:32:08,960
we also asked a panel of seven board

896
00:32:07,679 --> 00:32:10,480
certified pathologists to compare

897
00:32:08,960 --> 00:32:12,960
responses from this model versus other

898
00:32:10,480 --> 00:32:15,519
models and how well uh this approach

899
00:32:12,960 --> 00:32:20,480
does for diagnosis and morphologic

900
00:32:15,519 --> 00:32:22,480
description. Um so uh this has sort of

901
00:32:20,480 --> 00:32:23,840
been uh licensed to a startup and

902
00:32:22,480 --> 00:32:26,080
they've taken it further and they

903
00:32:23,840 --> 00:32:27,360
recently got uh FDA breakthrough device

904
00:32:26,080 --> 00:32:30,000
designation and we'll be running a

905
00:32:27,360 --> 00:32:32,000
clinical trial to try to see if it can

906
00:32:30,000 --> 00:32:35,279
improve workflows for for triage,

907
00:32:32,000 --> 00:32:37,919
automatic test ordering and for

908
00:32:35,279 --> 00:32:39,519
um for report synthesis synthesis as

909
00:32:37,919 --> 00:32:41,200
well. The next thing I want to touch

910
00:32:39,519 --> 00:32:43,919
upon is you know I guess everyone's

911
00:32:41,200 --> 00:32:45,600
talking about uh AI agents. So we have

912
00:32:43,919 --> 00:32:47,960
been trying to build some of these

913
00:32:45,600 --> 00:32:50,799
agents for uh for computational

914
00:32:47,960 --> 00:32:52,960
pathology. Um and since then it's been

915
00:32:50,799 --> 00:32:54,960
expanded to more of agents that would do

916
00:32:52,960 --> 00:32:57,200
any kind of analysis with the with with

917
00:32:54,960 --> 00:32:58,960
tissues. Um but the idea is that of

918
00:32:57,200 --> 00:33:01,279
course AI agents do do things for you

919
00:32:58,960 --> 00:33:04,480
and everything that we're doing back in

920
00:33:01,279 --> 00:33:07,120
2019 2020 can be done by these agents

921
00:33:04,480 --> 00:33:08,480
more or less on their own. So the the

922
00:33:07,120 --> 00:33:10,159
effective benefit would be that you can

923
00:33:08,480 --> 00:33:11,519
reduce the barrier who could for who

924
00:33:10,159 --> 00:33:14,559
could be developing these kinds of

925
00:33:11,519 --> 00:33:19,279
models and quite often uh people who

926
00:33:14,559 --> 00:33:21,120
work in domain specific u pathology or

927
00:33:19,279 --> 00:33:22,880
um you know oncologists they they often

928
00:33:21,120 --> 00:33:24,480
have the right questions to that they

929
00:33:22,880 --> 00:33:26,480
want to answer. So maybe they don't need

930
00:33:24,480 --> 00:33:29,360
to go to a computational person, someone

931
00:33:26,480 --> 00:33:30,960
like us to to run these uh run these

932
00:33:29,360 --> 00:33:34,799
experiments. Maybe they can run them run

933
00:33:30,960 --> 00:33:36,320
it on their own. And in in uh Agentic AI

934
00:33:34,799 --> 00:33:38,240
is really ripe for computational biome

935
00:33:36,320 --> 00:33:40,000
medicine in general because generative

936
00:33:38,240 --> 00:33:41,600
models have become quite good. So if you

937
00:33:40,000 --> 00:33:42,519
if you have a text prompt, you could

938
00:33:41,600 --> 00:33:45,679
easily

939
00:33:42,519 --> 00:33:48,640
prompt you could easily generate a plan

940
00:33:45,679 --> 00:33:50,159
from that text prompt. So the current uh

941
00:33:48,640 --> 00:33:52,320
large language models from OpenAI

942
00:33:50,159 --> 00:33:53,840
anthropic are very good at doing this.

943
00:33:52,320 --> 00:33:55,360
um and it can create a plan for you and

944
00:33:53,840 --> 00:33:57,360
then the agentic aspect of this would be

945
00:33:55,360 --> 00:33:59,039
that you can then schedule and and guess

946
00:33:57,360 --> 00:34:00,880
access all those tools and it would go

947
00:33:59,039 --> 00:34:02,320
run those experiments for you and you

948
00:34:00,880 --> 00:34:03,679
would effectively be able to communicate

949
00:34:02,320 --> 00:34:05,919
across it. So, so we started building

950
00:34:03,679 --> 00:34:08,879
this agent initially was just an effort

951
00:34:05,919 --> 00:34:11,119
that was centered around uh around

952
00:34:08,879 --> 00:34:12,800
pathology and as the studies were sort

953
00:34:11,119 --> 00:34:15,440
of going through the review process and

954
00:34:12,800 --> 00:34:17,040
you know we had requests that can we add

955
00:34:15,440 --> 00:34:19,119
other kinds of tissue analysis in there

956
00:34:17,040 --> 00:34:20,800
besides just looking at pathology images

957
00:34:19,119 --> 00:34:23,119
can we look at spatial transctoics can

958
00:34:20,800 --> 00:34:25,040
we look at you know uh radiology and

959
00:34:23,119 --> 00:34:26,800
other other kinds of data so so we that

960
00:34:25,040 --> 00:34:28,720
that's what we have effectively focused

961
00:34:26,800 --> 00:34:30,879
on and and while we were building this

962
00:34:28,720 --> 00:34:34,480
we there was also lots of development

963
00:34:30,879 --> 00:34:36,560
that's happening coding is becoming uh

964
00:34:34,480 --> 00:34:39,280
you know from text prompts to to to to

965
00:34:36,560 --> 00:34:42,879
effective code is becoming uh better and

966
00:34:39,280 --> 00:34:44,480
better and then the our patch model has

967
00:34:42,879 --> 00:34:46,399
also improved quite a lot so we can do

968
00:34:44,480 --> 00:34:48,800
good good morphologic descriptions and

969
00:34:46,399 --> 00:34:52,399
then openAI also released deep research

970
00:34:48,800 --> 00:34:54,000
so we can also go go back and do uh more

971
00:34:52,399 --> 00:34:56,639
generic scientific research and then

972
00:34:54,000 --> 00:35:00,720
come back with with generated hypotheses

973
00:34:56,639 --> 00:35:02,079
so if you put it all all together uh I a

974
00:35:00,720 --> 00:35:03,520
lot of these experiments could run

975
00:35:02,079 --> 00:35:06,240
effectively on their own. This is just

976
00:35:03,520 --> 00:35:08,160
one uh one example of it where the user

977
00:35:06,240 --> 00:35:10,359
is giving it some metadata and saying

978
00:35:08,160 --> 00:35:13,520
that I have a chord of responders versus

979
00:35:10,359 --> 00:35:15,200
non-responders and uh uh can we look at

980
00:35:13,520 --> 00:35:16,960
what are the morphologic different

981
00:35:15,200 --> 00:35:20,079
differences and then maybe conduct some

982
00:35:16,960 --> 00:35:21,599
analysis on top of it. So um the

983
00:35:20,079 --> 00:35:23,920
generative aspect of this is that it can

984
00:35:21,599 --> 00:35:25,520
make a plan and the agentic aspect is

985
00:35:23,920 --> 00:35:28,079
that that it can then go and execute

986
00:35:25,520 --> 00:35:30,160
that plan. So, so in this case it's very

987
00:35:28,079 --> 00:35:32,560
simple but it's a starting point where

988
00:35:30,160 --> 00:35:34,400
you can segment all segment the tissue

989
00:35:32,560 --> 00:35:35,760
patch it extract features once those

990
00:35:34,400 --> 00:35:37,680
features are extracted you can train a

991
00:35:35,760 --> 00:35:39,760
model on top of it once the model is

992
00:35:37,680 --> 00:35:42,359
trained this video is is is sped up

993
00:35:39,760 --> 00:35:45,359
because training process takes time and

994
00:35:42,359 --> 00:35:48,560
the once you have the have the model

995
00:35:45,359 --> 00:35:50,880
trained you can look at the the AU for

996
00:35:48,560 --> 00:35:54,240
for how separable the responders from

997
00:35:50,880 --> 00:35:56,480
non-responders are so a 0.855 855 maybe

998
00:35:54,240 --> 00:35:58,000
not clinically useful but it does give

999
00:35:56,480 --> 00:35:59,200
an indication that there's a morphologic

1000
00:35:58,000 --> 00:36:01,359
difference between the responders and

1001
00:35:59,200 --> 00:36:03,440
non-responders. So then you might want

1002
00:36:01,359 --> 00:36:05,040
to investigate what those differences

1003
00:36:03,440 --> 00:36:06,400
are and you can look at some form of

1004
00:36:05,040 --> 00:36:08,560
interpretability and you can look at

1005
00:36:06,400 --> 00:36:10,160
these heat maps which don't tell you too

1006
00:36:08,560 --> 00:36:12,160
much but it does give you an idea for

1007
00:36:10,160 --> 00:36:16,079
what what the model used in making its

1008
00:36:12,160 --> 00:36:17,359
predictive uh determinations. Um and uh

1009
00:36:16,079 --> 00:36:18,720
another thing we could do because we

1010
00:36:17,359 --> 00:36:21,240
have the generative model, we can ask

1011
00:36:18,720 --> 00:36:23,440
the model to we can ask the agent to

1012
00:36:21,240 --> 00:36:26,720
effectively look at the highest attended

1013
00:36:23,440 --> 00:36:29,599
regions in all of these uh slides in

1014
00:36:26,720 --> 00:36:31,200
your test set and give a morphologic

1015
00:36:29,599 --> 00:36:32,800
description for what's common across

1016
00:36:31,200 --> 00:36:34,240
across this. And it does that and it

1017
00:36:32,800 --> 00:36:36,440
tells you well it's looking at

1018
00:36:34,240 --> 00:36:38,800
inflammatory response, necrosis,

1019
00:36:36,440 --> 00:36:40,480
fibrosis. Uh and then maybe you want

1020
00:36:38,800 --> 00:36:41,839
some more enhanced interpretability. You

1021
00:36:40,480 --> 00:36:44,720
can say with within your high attention

1022
00:36:41,839 --> 00:36:46,720
regions can you segment all the cells

1023
00:36:44,720 --> 00:36:49,680
extract handcrafted features and and

1024
00:36:46,720 --> 00:36:52,480
give me you know uh differences between

1025
00:36:49,680 --> 00:36:55,280
responders and non-responders in a more

1026
00:36:52,480 --> 00:36:56,720
um uh more more clear manner and you can

1027
00:36:55,280 --> 00:36:58,240
you can do that too. So so there there

1028
00:36:56,720 --> 00:37:01,599
are other examples of this that we that

1029
00:36:58,240 --> 00:37:03,760
we have out there um but we'll we'll

1030
00:37:01,599 --> 00:37:07,119
have more to say about this uh in in the

1031
00:37:03,760 --> 00:37:08,560
coming months. Um I also want to say a

1032
00:37:07,119 --> 00:37:10,160
little bit about transitioning from 2D

1033
00:37:08,560 --> 00:37:12,400
to 3D pathology. piece of pathology

1034
00:37:10,160 --> 00:37:15,280
today is inherently two-dimensional. So

1035
00:37:12,400 --> 00:37:17,520
human tissue is threedimensional and uh

1036
00:37:15,280 --> 00:37:19,839
clinically and for other applications we

1037
00:37:17,520 --> 00:37:21,359
typically look at a really sampled view

1038
00:37:19,839 --> 00:37:23,920
of the tissue and for many disease

1039
00:37:21,359 --> 00:37:26,400
indications this works just just fine.

1040
00:37:23,920 --> 00:37:29,359
But for others it has been shown that as

1041
00:37:26,400 --> 00:37:32,720
you cut additional images from a tissue

1042
00:37:29,359 --> 00:37:35,200
block the diagnosis changes uh as more

1043
00:37:32,720 --> 00:37:37,760
and more data is is is sort of observed

1044
00:37:35,200 --> 00:37:40,720
from this uh from this piece of piece of

1045
00:37:37,760 --> 00:37:43,359
tissue. And uh over the past few years

1046
00:37:40,720 --> 00:37:45,920
there has been just uh an immense amount

1047
00:37:43,359 --> 00:37:48,160
of effort devoted to making

1048
00:37:45,920 --> 00:37:52,160
threedimensional imaging easier. And

1049
00:37:48,160 --> 00:37:54,079
this includes you know methods that uh

1050
00:37:52,160 --> 00:37:56,640
could include serial sectioning of

1051
00:37:54,079 --> 00:37:58,800
tissue and then registration or using

1052
00:37:56,640 --> 00:38:01,599
microCT scanners which is the relatively

1053
00:37:58,800 --> 00:38:03,119
easy way of doing it or using open top

1054
00:38:01,599 --> 00:38:05,920
light sheet microscopy which gives you

1055
00:38:03,119 --> 00:38:08,560
very high resolution but uh it takes a

1056
00:38:05,920 --> 00:38:11,359
little bit more a little bit more uh

1057
00:38:08,560 --> 00:38:12,960
time and requires tissue clearing but

1058
00:38:11,359 --> 00:38:14,560
there's no uh good computational

1059
00:38:12,960 --> 00:38:16,320
pipelines that I can just directly use

1060
00:38:14,560 --> 00:38:18,079
on threedimen threedimensional data and

1061
00:38:16,320 --> 00:38:19,920
this data is a very large and complex

1062
00:38:18,079 --> 00:38:22,160
whole flat images are already you know

1063
00:38:19,920 --> 00:38:24,000
can can be 100,000 by 100,000 pixels and

1064
00:38:22,160 --> 00:38:25,839
you add another dimension to it it

1065
00:38:24,000 --> 00:38:28,240
becomes very very complex and the other

1066
00:38:25,839 --> 00:38:29,920
aspect is that if you are if we are able

1067
00:38:28,240 --> 00:38:32,760
to image this tissue in 3D and

1068
00:38:29,920 --> 00:38:35,520
pathologists are looking at this um

1069
00:38:32,760 --> 00:38:38,720
using just their eyes there it's it will

1070
00:38:35,520 --> 00:38:40,880
be impossible to cater to the patient

1071
00:38:38,720 --> 00:38:42,640
workload and it it's also difficult to

1072
00:38:40,880 --> 00:38:44,160
discover from this data for for

1073
00:38:42,640 --> 00:38:46,160
discovery we're effectively interested

1074
00:38:44,160 --> 00:38:47,599
in finding common morphologic features

1075
00:38:46,160 --> 00:38:48,880
across large amounts of patients that

1076
00:38:47,599 --> 00:38:50,640
correlate with either response or

1077
00:38:48,880 --> 00:38:52,480
resistance to treatment or just to

1078
00:38:50,640 --> 00:38:54,000
separate them into distinct uh distinct

1079
00:38:52,480 --> 00:38:58,400
risk groups which is also difficult to

1080
00:38:54,000 --> 00:39:00,800
do manually. Um so uh we we try to

1081
00:38:58,400 --> 00:39:03,359
develop uh computational pipelines for

1082
00:39:00,800 --> 00:39:05,280
for three-dimensional pathology data of

1083
00:39:03,359 --> 00:39:07,920
course this data is just very very

1084
00:39:05,280 --> 00:39:07,920
computationally

1085
00:39:09,560 --> 00:39:14,880
complex very very large large images.

1086
00:39:13,040 --> 00:39:17,200
This this is uh these are prostate

1087
00:39:14,880 --> 00:39:18,640
cancer cases. They were imaged at at

1088
00:39:17,200 --> 00:39:21,599
Harvard using data from the Brighamin

1089
00:39:18,640 --> 00:39:23,839
Women's Hospital uh using a microCT CT

1090
00:39:21,599 --> 00:39:25,760
scanner. But we also had another cohort

1091
00:39:23,839 --> 00:39:29,040
that came from an open top light sheet

1092
00:39:25,760 --> 00:39:32,079
microscope uh from Jonathan Lu's group

1093
00:39:29,040 --> 00:39:34,560
at the University of uh Washington. And

1094
00:39:32,079 --> 00:39:36,160
we expanded uh multiple instance

1095
00:39:34,560 --> 00:39:38,720
learning into into a third dimension

1096
00:39:36,160 --> 00:39:40,960
which was just complex and it it it

1097
00:39:38,720 --> 00:39:43,520
requires a lot of computing resources to

1098
00:39:40,960 --> 00:39:46,240
train uh train models like this. But but

1099
00:39:43,520 --> 00:39:48,240
basically we we managed to scale this uh

1100
00:39:46,240 --> 00:39:50,400
and and it follows a similar kind of a

1101
00:39:48,240 --> 00:39:52,800
paradigm where we extract features, we

1102
00:39:50,400 --> 00:39:55,280
aggregate and then we pose the problem

1103
00:39:52,800 --> 00:39:57,040
that we're trying to trying to solve. uh

1104
00:39:55,280 --> 00:39:58,560
this was a cell article from last year

1105
00:39:57,040 --> 00:40:00,800
where we where we managed to show that

1106
00:39:58,560 --> 00:40:02,400
as you use more of the tissue region

1107
00:40:00,800 --> 00:40:05,440
you're able to separate patients into

1108
00:40:02,400 --> 00:40:07,599
distinct risk groups um in in a much

1109
00:40:05,440 --> 00:40:09,839
better way. Uh and since then we've been

1110
00:40:07,599 --> 00:40:11,359
expanding this to other uh other

1111
00:40:09,839 --> 00:40:13,920
applications and we'll have more to say

1112
00:40:11,359 --> 00:40:15,680
about that in in in the coming coming

1113
00:40:13,920 --> 00:40:17,280
months. But you're you're able to go

1114
00:40:15,680 --> 00:40:19,520
back and look at what are the regions

1115
00:40:17,280 --> 00:40:22,160
that are important within the uh within

1116
00:40:19,520 --> 00:40:24,200
within this large uh piece of uh piece

1117
00:40:22,160 --> 00:40:27,440
of tissue.

1118
00:40:24,200 --> 00:40:28,880
Um sorry trying to okay so so another

1119
00:40:27,440 --> 00:40:31,359
question so as we're doing this there

1120
00:40:28,880 --> 00:40:33,720
were was multiple of our collaborators

1121
00:40:31,359 --> 00:40:37,200
have asked us this question that can we

1122
00:40:33,720 --> 00:40:39,520
infer spatial transcripttoics in 3D now

1123
00:40:37,200 --> 00:40:41,280
that we have uh you know lots of spatial

1124
00:40:39,520 --> 00:40:42,640
transcripttoic data available and thus

1125
00:40:41,280 --> 00:40:45,040
that can be used for pre-training. So

1126
00:40:42,640 --> 00:40:46,960
the basic idea is and and and this idea

1127
00:40:45,040 --> 00:40:49,119
is is not unique to us it's been it's

1128
00:40:46,960 --> 00:40:51,440
it's being explored by many other

1129
00:40:49,119 --> 00:40:53,920
people. Also we have tissue uh which you

1130
00:40:51,440 --> 00:40:55,359
can image using any kind of 3D 3D

1131
00:40:53,920 --> 00:40:58,000
imaging technique. In this case we

1132
00:40:55,359 --> 00:41:00,240
relied on microctt scanning because it's

1133
00:40:58,000 --> 00:41:02,640
a good trade-off between resolution and

1134
00:41:00,240 --> 00:41:05,839
how how quickly can you image these

1135
00:41:02,640 --> 00:41:07,839
image these cases and then do few

1136
00:41:05,839 --> 00:41:10,000
dimensional spatial transcripttoic

1137
00:41:07,839 --> 00:41:11,520
sections on on this piece of tissue

1138
00:41:10,000 --> 00:41:12,800
followed by using a pre-trained model

1139
00:41:11,520 --> 00:41:13,920
that might have been might have been

1140
00:41:12,800 --> 00:41:15,960
trained on lots of paired

1141
00:41:13,920 --> 00:41:18,400
hisystologology and uh spatial

1142
00:41:15,960 --> 00:41:20,720
transcripttoic data. So it it's learned

1143
00:41:18,400 --> 00:41:23,280
that basic morphologic correlation and

1144
00:41:20,720 --> 00:41:25,280
then fine-tuning inpatient fine-tuning

1145
00:41:23,280 --> 00:41:28,440
on samples that actually came from

1146
00:41:25,280 --> 00:41:31,119
within that piece of tissue to then uh

1147
00:41:28,440 --> 00:41:34,160
infer spatial transcripttoics in 3D and

1148
00:41:31,119 --> 00:41:36,480
now this is uh you know uh of course

1149
00:41:34,160 --> 00:41:39,599
it's we try to do a proof of concept of

1150
00:41:36,480 --> 00:41:41,200
this and it works to to a degree but we

1151
00:41:39,599 --> 00:41:44,240
are trying to validate this further. We

1152
00:41:41,200 --> 00:41:45,520
we we sort of used every architectural

1153
00:41:44,240 --> 00:41:47,359
combination that we could including

1154
00:41:45,520 --> 00:41:48,880
using multiple sections all kinds of

1155
00:41:47,359 --> 00:41:50,319
different architectures on the machine

1156
00:41:48,880 --> 00:41:52,160
learning side as well as all kinds of

1157
00:41:50,319 --> 00:41:53,920
different validation that we could we

1158
00:41:52,160 --> 00:41:56,880
could do both on the pre-training end

1159
00:41:53,920 --> 00:41:59,680
and on the post post inpatient uh

1160
00:41:56,880 --> 00:42:02,079
fine-tuning end to see if we can improve

1161
00:41:59,680 --> 00:42:04,400
uh improve predictability as well as

1162
00:42:02,079 --> 00:42:05,760
validation by doing lots of multiple uh

1163
00:42:04,400 --> 00:42:07,280
multiple sections and spatial

1164
00:42:05,760 --> 00:42:08,839
transcripttoics on it. This was limited

1165
00:42:07,280 --> 00:42:11,280
to prostate

1166
00:42:08,839 --> 00:42:13,680
cancer and they have since expanded this

1167
00:42:11,280 --> 00:42:16,960
and we're also expanding this this to

1168
00:42:13,680 --> 00:42:18,640
use um uh open top light microscopy

1169
00:42:16,960 --> 00:42:20,960
which gives us a much higher resolution

1170
00:42:18,640 --> 00:42:22,480
view of uh of this. We have a pre-print

1171
00:42:20,960 --> 00:42:24,319
for this and this the study is currently

1172
00:42:22,480 --> 00:42:27,040
in review but we will be making all the

1173
00:42:24,319 --> 00:42:29,599
code and everything publicly available

1174
00:42:27,040 --> 00:42:31,280
so people can experiment this with with

1175
00:42:29,599 --> 00:42:32,880
this sort of concept further because it

1176
00:42:31,280 --> 00:42:35,680
will take a while before it's actually

1177
00:42:32,880 --> 00:42:38,560
perfect or or gets even close to being

1178
00:42:35,680 --> 00:42:41,119
perfect if if it ever will. Um but you

1179
00:42:38,560 --> 00:42:43,119
can go in and you know this is just fun

1180
00:42:41,119 --> 00:42:45,119
images where you can go in and look at

1181
00:42:43,119 --> 00:42:46,319
uh what what it what it's effectively

1182
00:42:45,119 --> 00:42:48,800
looking at and then draw some

1183
00:42:46,319 --> 00:42:51,119
conclusions from it uh if if possible.

1184
00:42:48,800 --> 00:42:52,560
We also have efforts to look at more

1185
00:42:51,119 --> 00:42:55,400
sort of treatment response related

1186
00:42:52,560 --> 00:42:57,920
questions in uh in in in three

1187
00:42:55,400 --> 00:43:01,280
dimensions. Um and that's sort of

1188
00:42:57,920 --> 00:43:03,200
ongoing ongoing work. Um we're obviously

1189
00:43:01,280 --> 00:43:05,520
very interested in applying machine

1190
00:43:03,200 --> 00:43:08,400
learning to real world settings and one

1191
00:43:05,520 --> 00:43:10,240
aspect of this is that uh how does how

1192
00:43:08,400 --> 00:43:11,839
do these models perform when we

1193
00:43:10,240 --> 00:43:14,000
individually analyze them on on

1194
00:43:11,839 --> 00:43:16,640
protected subgroups of uh of of

1195
00:43:14,000 --> 00:43:18,520
patients. So we wanted to see if uh

1196
00:43:16,640 --> 00:43:20,640
there's anything in the model

1197
00:43:18,520 --> 00:43:23,359
architecture what modeling choices can

1198
00:43:20,640 --> 00:43:26,000
we make such that there will be minimal

1199
00:43:23,359 --> 00:43:27,280
bias in the uh in these models. So this

1200
00:43:26,000 --> 00:43:28,880
study from last year focused on

1201
00:43:27,280 --> 00:43:31,520
analyzing some of this. So we trained

1202
00:43:28,880 --> 00:43:33,760
some of these models on large public

1203
00:43:31,520 --> 00:43:35,200
data like TCGA other large public core

1204
00:43:33,760 --> 00:43:36,720
subathology data that was available and

1205
00:43:35,200 --> 00:43:38,880
then assessed these models on data from

1206
00:43:36,720 --> 00:43:41,520
Brigham and MGH which was stratified by

1207
00:43:38,880 --> 00:43:44,079
protected subgroups whether it was race

1208
00:43:41,520 --> 00:43:45,599
income groups or whether the patient had

1209
00:43:44,079 --> 00:43:47,680
insurance or not and we found that there

1210
00:43:45,599 --> 00:43:49,119
there can be large disparities but we

1211
00:43:47,680 --> 00:43:50,640
also looked at what modeling choices

1212
00:43:49,119 --> 00:43:52,160
could mitigate those disparities and

1213
00:43:50,640 --> 00:43:54,720
found that feature representation is is

1214
00:43:52,160 --> 00:43:56,480
the most comp most important component

1215
00:43:54,720 --> 00:43:57,839
uh but just feature representation

1216
00:43:56,480 --> 00:43:59,440
improving feature representation does

1217
00:43:57,839 --> 00:44:02,079
not eliminate all of those disparities

1218
00:43:59,440 --> 00:44:03,680
and you know we're investigating why uh

1219
00:44:02,079 --> 00:44:05,920
why they exist. Sometimes it could be

1220
00:44:03,680 --> 00:44:07,440
very obvious. Uh an example would be

1221
00:44:05,920 --> 00:44:09,599
that patients with soio economic

1222
00:44:07,440 --> 00:44:13,359
disparities might just be diagnosed late

1223
00:44:09,599 --> 00:44:15,920
and there might be limited uh advanced

1224
00:44:13,359 --> 00:44:20,800
cases in within your

1225
00:44:15,920 --> 00:44:22,800
um within your uh test set. Um the last

1226
00:44:20,800 --> 00:44:26,880
thing I want to touch upon is what are

1227
00:44:22,800 --> 00:44:30,160
we working on next? So we uh have been

1228
00:44:26,880 --> 00:44:32,240
building a model that uh uses uh lots of

1229
00:44:30,160 --> 00:44:35,680
data from uh Brigham and MGH is

1230
00:44:32,240 --> 00:44:37,200
multimodel uses um all the modalities

1231
00:44:35,680 --> 00:44:38,960
that we that we have available and is

1232
00:44:37,200 --> 00:44:40,119
also temporally aligned such that we

1233
00:44:38,960 --> 00:44:42,480
will get a single patient level

1234
00:44:40,119 --> 00:44:44,480
representation for every patient that

1235
00:44:42,480 --> 00:44:46,400
can be dynamically and temporally

1236
00:44:44,480 --> 00:44:48,960
updated. So the idea would be that that

1237
00:44:46,400 --> 00:44:50,480
every event that occurs about about the

1238
00:44:48,960 --> 00:44:52,880
patient whether it's a visit, it's a

1239
00:44:50,480 --> 00:44:54,960
phone call uh once it gets logged either

1240
00:44:52,880 --> 00:44:58,480
in electronic medical records um a

1241
00:44:54,960 --> 00:45:01,119
radiology scan or a pathology report or

1242
00:44:58,480 --> 00:45:03,119
um a clinical laboratory test would

1243
00:45:01,119 --> 00:45:05,680
update a dynamic patient level

1244
00:45:03,119 --> 00:45:07,280
embedding. So this effectively includes

1245
00:45:05,680 --> 00:45:09,280
using self-supervised models for each

1246
00:45:07,280 --> 00:45:11,839
individual modality to embed them uh

1247
00:45:09,280 --> 00:45:14,640
followed by uh a temporally aligned uh

1248
00:45:11,839 --> 00:45:16,800
embedding. So, so with every visit you

1249
00:45:14,640 --> 00:45:19,599
your your embedding would effectively uh

1250
00:45:16,800 --> 00:45:23,119
update and uh you would have this this

1251
00:45:19,599 --> 00:45:24,960
sort of change across uh across time uh

1252
00:45:23,119 --> 00:45:26,319
recorded which you can then apply to a

1253
00:45:24,960 --> 00:45:28,079
host of different downstream

1254
00:45:26,319 --> 00:45:29,839
applications like early diagnosis,

1255
00:45:28,079 --> 00:45:31,760
treatment response, bio medical

1256
00:45:29,839 --> 00:45:33,680
discovery, dynamic risk scores, clinical

1257
00:45:31,760 --> 00:45:36,960
trial matching and population health or

1258
00:45:33,680 --> 00:45:38,880
just some some examples. Um we are

1259
00:45:36,960 --> 00:45:40,160
beginning to get uh some early results

1260
00:45:38,880 --> 00:45:42,720
for this and we'll have more to say

1261
00:45:40,160 --> 00:45:45,200
about this in in the coming um coming

1262
00:45:42,720 --> 00:45:48,240
months. I want to end by showing this

1263
00:45:45,200 --> 00:45:50,079
poem from Judith Prevett uh uh that I

1264
00:45:48,240 --> 00:45:51,599
think she she wrote something that is

1265
00:45:50,079 --> 00:45:53,680
very relevant today and this was written

1266
00:45:51,599 --> 00:45:55,280
in 1979. She writes that optical

1267
00:45:53,680 --> 00:45:56,480
illusions can deceive the subjective eye

1268
00:45:55,280 --> 00:45:58,880
but objective measurements and

1269
00:45:56,480 --> 00:46:00,640
algorithms are assumed not to lie. It's

1270
00:45:58,880 --> 00:46:02,640
often said that medicine could use such

1271
00:46:00,640 --> 00:46:05,440
objectivity and thought this this

1272
00:46:02,640 --> 00:46:07,040
justifies machine intelligence activity.

1273
00:46:05,440 --> 00:46:08,480
Artificial intelligence is another craze

1274
00:46:07,040 --> 00:46:10,640
that uses computers to cope with the

1275
00:46:08,480 --> 00:46:12,000
diagnostic maze. Though the criteria for

1276
00:46:10,640 --> 00:46:13,440
intelligence has never been resolved,

1277
00:46:12,000 --> 00:46:15,440
paper after paper claims that the

1278
00:46:13,440 --> 00:46:17,760
problem has already been solved. So I

1279
00:46:15,440 --> 00:46:20,000
find it fascinating how relevant our

1280
00:46:17,760 --> 00:46:22,640
words are uh are today. So we really

1281
00:46:20,000 --> 00:46:24,240
have ways to go before uh you know

1282
00:46:22,640 --> 00:46:26,560
everything we do and others do in the

1283
00:46:24,240 --> 00:46:28,800
field could actually make make a true

1284
00:46:26,560 --> 00:46:30,800
impact on the on on on the clinical and

1285
00:46:28,800 --> 00:46:32,640
discovery discovery side. It's beginning

1286
00:46:30,800 --> 00:46:34,800
to show but but it will take take more

1287
00:46:32,640 --> 00:46:37,280
time. I want to thank all the PhD

1288
00:46:34,800 --> 00:46:39,359
students posttos and all the support

1289
00:46:37,280 --> 00:46:40,640
staff who have contributed to all of

1290
00:46:39,359 --> 00:46:42,960
this effort as well as all the funding

1291
00:46:40,640 --> 00:46:44,640
that we received to to to do some of

1292
00:46:42,960 --> 00:46:47,640
this work. Thank you so much. I'll be

1293
00:46:44,640 --> 00:46:47,640
happy


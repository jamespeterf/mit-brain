1
00:00:02,200 --> 00:00:08,840
hello everyone my name is Emily Nez I'm

2
00:00:04,319 --> 00:00:11,080
co-founder and CEO of deline um I am a

3
00:00:08,840 --> 00:00:13,040
PhD candidate in biological engineering

4
00:00:11,080 --> 00:00:15,120
in seale and I have about seven years

5
00:00:13,040 --> 00:00:17,359
experience Building Systems pharmacology

6
00:00:15,120 --> 00:00:20,920
models at companies like fizer and

7
00:00:17,359 --> 00:00:22,760
astroica my co-founder Jad ikbal is an

8
00:00:20,920 --> 00:00:25,720
is an expert on digital transformation

9
00:00:22,760 --> 00:00:28,039
Solutions and Ai and delineate is a

10
00:00:25,720 --> 00:00:30,279
multidisciplinary team it's growing we

11
00:00:28,039 --> 00:00:33,600
have about 20 plus engineers and

12
00:00:30,279 --> 00:00:36,320
researchers dedicated to applying AI to

13
00:00:33,600 --> 00:00:38,879
accelerate analysis

14
00:00:36,320 --> 00:00:40,320
workflows so computational analysis can

15
00:00:38,879 --> 00:00:41,960
be really powerful this can look

16
00:00:40,320 --> 00:00:44,200
different in different fields it can be

17
00:00:41,960 --> 00:00:46,680
building AI models it can be doing more

18
00:00:44,200 --> 00:00:48,440
traditional statistical modeling um but

19
00:00:46,680 --> 00:00:50,640
it has a really big problem in that the

20
00:00:48,440 --> 00:00:53,280
workflow is really scattered it takes a

21
00:00:50,640 --> 00:00:55,879
lot of manual effort to put together

22
00:00:53,280 --> 00:00:58,399
structured clean data sets from very

23
00:00:55,879 --> 00:01:00,600
many disperate sources um so we work a

24
00:00:58,399 --> 00:01:02,519
lot in the biofarma space

25
00:01:00,600 --> 00:01:04,799
um and talking with our customers it can

26
00:01:02,519 --> 00:01:07,880
take teenss of scientists months to put

27
00:01:04,799 --> 00:01:10,000
together a single data set so delineates

28
00:01:07,880 --> 00:01:12,360
goal is to make that faster using our

29
00:01:10,000 --> 00:01:14,640
custom trained models to process all of

30
00:01:12,360 --> 00:01:17,119
this unstructured information into

31
00:01:14,640 --> 00:01:20,079
insightful assets um so we work a lot

32
00:01:17,119 --> 00:01:22,360
with research papers um specifically the

33
00:01:20,079 --> 00:01:26,119
plots and graphs getting that numerical

34
00:01:22,360 --> 00:01:28,920
information out um but we also process

35
00:01:26,119 --> 00:01:31,360
websites and databases we use our models

36
00:01:28,920 --> 00:01:33,280
to structure this to to clean it um and

37
00:01:31,360 --> 00:01:36,200
deliver data sets that are fit for

38
00:01:33,280 --> 00:01:38,880
purpose but also code to generate um

39
00:01:36,200 --> 00:01:40,759
those models to analyze that data and we

40
00:01:38,880 --> 00:01:43,479
can also generate

41
00:01:40,759 --> 00:01:45,640
reports so we're building an all-in-one

42
00:01:43,479 --> 00:01:48,320
research web tool um that starts from

43
00:01:45,640 --> 00:01:50,680
search so AI enhanced search to help you

44
00:01:48,320 --> 00:01:53,079
find uh those documents that have the

45
00:01:50,680 --> 00:01:56,159
data that you need um all of that gets

46
00:01:53,079 --> 00:01:58,759
put into one place and then um of course

47
00:01:56,159 --> 00:02:00,360
the the meat of our of our tool our

48
00:01:58,759 --> 00:02:02,159
really core competency is that

49
00:02:00,360 --> 00:02:04,439
extraction of the data getting that

50
00:02:02,159 --> 00:02:06,159
numerical information out but combining

51
00:02:04,439 --> 00:02:09,200
that with a contextual understanding of

52
00:02:06,159 --> 00:02:11,319
where that data came from and we also

53
00:02:09,200 --> 00:02:14,400
have a platform where you can analyze

54
00:02:11,319 --> 00:02:16,599
the data um inside that same Tool uh

55
00:02:14,400 --> 00:02:18,560
using our AI assistant so the right

56
00:02:16,599 --> 00:02:21,480
model with the right

57
00:02:18,560 --> 00:02:23,760
data so as a case study we were able to

58
00:02:21,480 --> 00:02:26,440
generate a data set for AI model

59
00:02:23,760 --> 00:02:29,200
training for a top Pharma company so we

60
00:02:26,440 --> 00:02:31,840
processed over 900 research papers uh

61
00:02:29,200 --> 00:02:34,160
using our custom computer vision methods

62
00:02:31,840 --> 00:02:36,920
we extracted the numerical information

63
00:02:34,160 --> 00:02:39,920
behind all the graphs combine that with

64
00:02:36,920 --> 00:02:41,360
our llm agents that gave a contextual

65
00:02:39,920 --> 00:02:43,959
understanding of how that data was

66
00:02:41,360 --> 00:02:45,400
collected and that was packaged into a

67
00:02:43,959 --> 00:02:47,519
data set that was essentially plug-

68
00:02:45,400 --> 00:02:51,800
Inplay for their AI model so we

69
00:02:47,519 --> 00:02:55,000
generated uh 23,000 data points for for

70
00:02:51,800 --> 00:02:57,519
them so what's really different about us

71
00:02:55,000 --> 00:03:00,120
versus other Solutions you could go to

72
00:02:57,519 --> 00:03:01,920
um so really we're fit for purpose data

73
00:03:00,120 --> 00:03:04,319
extraction any data set that you can

74
00:03:01,920 --> 00:03:07,400
think of we can help you build so the

75
00:03:04,319 --> 00:03:10,159
inputs to this would be a semantic um

76
00:03:07,400 --> 00:03:12,560
description of the goal of your analysis

77
00:03:10,159 --> 00:03:15,799
and the data criteria so what should the

78
00:03:12,560 --> 00:03:17,799
columns look like and then um The Source

79
00:03:15,799 --> 00:03:19,360
the sources get processed using that so

80
00:03:17,799 --> 00:03:22,000
delineate will extract the relevant

81
00:03:19,360 --> 00:03:24,599
information from across the text tables

82
00:03:22,000 --> 00:03:27,439
and figures um and then put it together

83
00:03:24,599 --> 00:03:30,040
in this analysis ready data

84
00:03:27,439 --> 00:03:32,560
set so really you know we have these

85
00:03:30,040 --> 00:03:34,200
fine-tuned models for data extraction

86
00:03:32,560 --> 00:03:37,000
that really is another thing that sets

87
00:03:34,200 --> 00:03:39,680
us apart um we're all in one place which

88
00:03:37,000 --> 00:03:42,000
simplifies the workflow saves time um

89
00:03:39,680 --> 00:03:43,920
and we're also 100% auditable so you can

90
00:03:42,000 --> 00:03:48,360
see exactly where every data point came

91
00:03:43,920 --> 00:03:50,879
from um you know why a line of code was

92
00:03:48,360 --> 00:03:52,799
created so we've made a lot of traction

93
00:03:50,879 --> 00:03:54,720
to date I'm really proud of what our

94
00:03:52,799 --> 00:03:57,120
team has accomplished so we have data

95
00:03:54,720 --> 00:03:58,840
service contracts with two top 10 Pharma

96
00:03:57,120 --> 00:04:01,000
companies and we're going to be

97
00:03:58,840 --> 00:04:03,159
acknowledged in some of their upcoming

98
00:04:01,000 --> 00:04:05,280
Publications um we recently became a

99
00:04:03,159 --> 00:04:08,000
preferred vendor of data sets for one

100
00:04:05,280 --> 00:04:09,840
top 10 Pharma company um we're going to

101
00:04:08,000 --> 00:04:11,560
speak at the American Society of

102
00:04:09,840 --> 00:04:14,439
clinical pharmacology and Therapeutics

103
00:04:11,560 --> 00:04:17,239
soon um and we received early acceptance

104
00:04:14,439 --> 00:04:18,840
to why combinators winner 2025 batch so

105
00:04:17,239 --> 00:04:21,479
that will be starting

106
00:04:18,840 --> 00:04:22,919
soon and we're really looking to partner

107
00:04:21,479 --> 00:04:24,680
really with any companies that have

108
00:04:22,919 --> 00:04:27,759
needs related to Data Mining and

109
00:04:24,680 --> 00:04:29,080
structuring of complex information um

110
00:04:27,759 --> 00:04:31,520
but you know we have a lot of traction

111
00:04:29,080 --> 00:04:34,160
in biofarm so we would really love to uh

112
00:04:31,520 --> 00:04:36,680
talk to anyone in biofarma as well um

113
00:04:34,160 --> 00:04:37,800
please uh reach out to us in our email

114
00:04:36,680 --> 00:04:40,560
um or you can find us on the table

115
00:04:37,800 --> 00:04:43,560
outside thank you thank you so much

116
00:04:40,560 --> 00:04:43,560
Emily


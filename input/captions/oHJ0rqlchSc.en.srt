1
00:00:05,359 --> 00:00:08,720
Um good morning. Uh my name is

2
00:00:07,200 --> 00:00:10,160
Sebastiano. I'm a first year

3
00:00:08,720 --> 00:00:11,920
post-docctoral fellow at the Eric and

4
00:00:10,160 --> 00:00:14,000
Wendish center. And it's my pleasure to

5
00:00:11,920 --> 00:00:17,119
introduce our next speaker, Jean Philip

6
00:00:14,000 --> 00:00:20,480
Ve. Um Jean Philip is the chief R&D

7
00:00:17,119 --> 00:00:22,720
officer at Okin AI biotech company using

8
00:00:20,480 --> 00:00:25,199
machine learning to discover and develop

9
00:00:22,720 --> 00:00:27,039
treatments for unmet medical needs. He's

10
00:00:25,199 --> 00:00:29,519
also the co-founder and executive

11
00:00:27,039 --> 00:00:32,960
chairman of Boptimus and professor at

12
00:00:29,519 --> 00:00:34,880
the ecoldin in Paris. Um his research

13
00:00:32,960 --> 00:00:36,800
focuses on the theory and pract and

14
00:00:34,880 --> 00:00:38,719
practice of statistical machine learning

15
00:00:36,800 --> 00:00:42,160
and its applications to computational

16
00:00:38,719 --> 00:00:45,040
biology and medicine. JP has earned his

17
00:00:42,160 --> 00:00:46,480
PhD in mathematics and has held roles at

18
00:00:45,040 --> 00:00:48,760
Google brain as well as academic

19
00:00:46,480 --> 00:00:51,520
positions at the caldermin and

20
00:00:48,760 --> 00:00:53,680
institute. His contribution to the field

21
00:00:51,520 --> 00:00:56,000
has led Jean Philip to to several awards

22
00:00:53,680 --> 00:00:58,559
including a major science prize from the

23
00:00:56,000 --> 00:01:00,000
Institute of France. JP, we're very

24
00:00:58,559 --> 00:01:02,640
excited to have you here and we're very

25
00:01:00,000 --> 00:01:02,640
excited for your

26
00:01:07,080 --> 00:01:11,439
talk. Well, thank you. Thank you for the

27
00:01:09,600 --> 00:01:14,159
intro and and the invitation to be here.

28
00:01:11,439 --> 00:01:16,080
It's a real pleasure and it's always so

29
00:01:14,159 --> 00:01:19,360
I mean these are my best workshops you

30
00:01:16,080 --> 00:01:21,520
know we're not too big with real AI real

31
00:01:19,360 --> 00:01:24,080
biologist meeting together this is where

32
00:01:21,520 --> 00:01:25,680
things happen so uh I'm going to give

33
00:01:24,080 --> 00:01:26,960
presentation which comes you know

34
00:01:25,680 --> 00:01:29,360
compared to a previous one a bit more

35
00:01:26,960 --> 00:01:32,720
from the AI viewpoint

36
00:01:29,360 --> 00:01:34,960
um because you know this is me I cannot

37
00:01:32,720 --> 00:01:37,119
pretend I'm a biologist and I'm going to

38
00:01:34,960 --> 00:01:39,600
discuss you know the the a topic which I

39
00:01:37,119 --> 00:01:41,360
think is is is really mainstream now

40
00:01:39,600 --> 00:01:44,960
which is the national foundation models

41
00:01:41,360 --> 00:01:47,840
and how the latest AI technologies could

42
00:01:44,960 --> 00:01:51,680
contribute to different ways or new ways

43
00:01:47,840 --> 00:01:54,399
to uh to understand simulate biology.

44
00:01:51,680 --> 00:01:56,640
uh first let let me mention because you

45
00:01:54,399 --> 00:01:59,119
know so I have academic position but I'm

46
00:01:56,640 --> 00:02:01,280
now in the industry just you know for

47
00:01:59,119 --> 00:02:03,040
all of you maybe not of you not all of

48
00:02:01,280 --> 00:02:05,439
you are aware of you know what what all

49
00:02:03,040 --> 00:02:07,040
of this means uh in industry you know

50
00:02:05,439 --> 00:02:08,720
lots of biology especially in this in

51
00:02:07,040 --> 00:02:10,000
such an institute is is geared toward

52
00:02:08,720 --> 00:02:12,640
developing new treatments better

53
00:02:10,000 --> 00:02:14,480
treating patients and so I must say that

54
00:02:12,640 --> 00:02:17,920
already today and it's been the case for

55
00:02:14,480 --> 00:02:21,560
the last few years AI is used and deeply

56
00:02:17,920 --> 00:02:24,239
used in many aspects of of drug

57
00:02:21,560 --> 00:02:26,239
discovery, development, diagnostics,

58
00:02:24,239 --> 00:02:28,160
etc. Forget about the details of that

59
00:02:26,239 --> 00:02:31,200
slide. This is just a slide taken from

60
00:02:28,160 --> 00:02:33,760
Arin. Uh but it shows that you know Arin

61
00:02:31,200 --> 00:02:36,640
is using AI in order to solve the

62
00:02:33,760 --> 00:02:40,000
problems in in drug development and

63
00:02:36,640 --> 00:02:42,560
really uh machine learning computation

64
00:02:40,000 --> 00:02:44,480
budget is used from the beginning. So

65
00:02:42,560 --> 00:02:47,280
you know uh developing a drug means

66
00:02:44,480 --> 00:02:49,680
understanding biology. This is mostly

67
00:02:47,280 --> 00:02:51,840
what is done in academic labs, right? to

68
00:02:49,680 --> 00:02:54,800
understand the cancer for example

69
00:02:51,840 --> 00:02:56,480
identifying processes targets. Then once

70
00:02:54,800 --> 00:02:59,440
so this involves also computational

71
00:02:56,480 --> 00:03:01,200
approaches. Then the second step often

72
00:02:59,440 --> 00:03:02,640
called you know drug discovery in these

73
00:03:01,200 --> 00:03:05,120
in these approaches. Once you have a

74
00:03:02,640 --> 00:03:06,879
target design a good drug a good it

75
00:03:05,120 --> 00:03:08,640
could be a small molecule could be

76
00:03:06,879 --> 00:03:11,200
antibbody this kind of things. So

77
00:03:08,640 --> 00:03:14,239
obviously today genai is heavily used

78
00:03:11,200 --> 00:03:15,760
already to to design candidate drugs but

79
00:03:14,239 --> 00:03:17,120
then it's not the end of the game. Of

80
00:03:15,760 --> 00:03:19,440
course once you have a candidate drug

81
00:03:17,120 --> 00:03:22,720
you optimize it and there is all this

82
00:03:19,440 --> 00:03:25,440
translational work which is where should

83
00:03:22,720 --> 00:03:27,760
I use my drug to which patients which uh

84
00:03:25,440 --> 00:03:29,599
which are the likely responders etc. And

85
00:03:27,760 --> 00:03:31,840
here again it's a you can think of it as

86
00:03:29,599 --> 00:03:33,360
a massive you know collaborative

87
00:03:31,840 --> 00:03:35,200
filtering problem where you have

88
00:03:33,360 --> 00:03:36,799
patients you have candidate drugs or

89
00:03:35,200 --> 00:03:39,440
candidate targets and you want to find a

90
00:03:36,799 --> 00:03:40,959
good match. So just for you to know and

91
00:03:39,440 --> 00:03:43,200
you know each of these topics could

92
00:03:40,959 --> 00:03:45,760
involve uh you know a full day of

93
00:03:43,200 --> 00:03:48,319
seminar but AI is already used and and

94
00:03:45,760 --> 00:03:51,440
with you know some success. However,

95
00:03:48,319 --> 00:03:54,159
it's fair to say that in spite of you

96
00:03:51,440 --> 00:03:56,959
know all the smart people you doing that

97
00:03:54,159 --> 00:04:00,640
all the great data we have uh the

98
00:03:56,959 --> 00:04:02,879
statistics are not very very good and uh

99
00:04:00,640 --> 00:04:04,560
typically you know after years of uh

100
00:04:02,879 --> 00:04:06,720
development of a new treatment finding

101
00:04:04,560 --> 00:04:09,200
the best science the best antibbody the

102
00:04:06,720 --> 00:04:11,680
best molecule optimize you test it in

103
00:04:09,200 --> 00:04:14,000
clinical trial meaning you test it on on

104
00:04:11,680 --> 00:04:16,880
humans to test if you will save lives

105
00:04:14,000 --> 00:04:19,359
and we're still today at the stage where

106
00:04:16,880 --> 00:04:21,840
uh Nine out of 10 drugs that are tested

107
00:04:19,359 --> 00:04:24,400
in clinical trials don't make it to the

108
00:04:21,840 --> 00:04:26,479
market either because they are toxic or

109
00:04:24,400 --> 00:04:29,360
because they have no effect they don't

110
00:04:26,479 --> 00:04:32,240
treat the patients or other you know

111
00:04:29,360 --> 00:04:34,000
less uh more business reasons but so

112
00:04:32,240 --> 00:04:36,639
something is missing and you know my the

113
00:04:34,000 --> 00:04:39,040
the whole by the way this is very high

114
00:04:36,639 --> 00:04:40,800
level but this means that in spite of

115
00:04:39,040 --> 00:04:42,400
the great science that we have we are so

116
00:04:40,800 --> 00:04:44,080
far away from other fields like in

117
00:04:42,400 --> 00:04:46,800
physics where you know we have equations

118
00:04:44,080 --> 00:04:49,280
and we can fly rockets to the moon Most

119
00:04:46,800 --> 00:04:52,400
here in biology we are still probably

120
00:04:49,280 --> 00:04:54,960
missing deep understanding and capacity

121
00:04:52,400 --> 00:04:58,240
computational simulations uh prediction

122
00:04:54,960 --> 00:05:01,440
models that that translate from research

123
00:04:58,240 --> 00:05:04,320
to real patients. Okay. So I would

124
00:05:01,440 --> 00:05:05,919
summarize my my presentation by okay

125
00:05:04,320 --> 00:05:08,080
this is a fight you know we have lots of

126
00:05:05,919 --> 00:05:10,160
knowledge lot lots of experience but no

127
00:05:08,080 --> 00:05:12,240
real computational simulation that would

128
00:05:10,160 --> 00:05:15,520
allow us to just say well developing a

129
00:05:12,240 --> 00:05:18,160
drug is easy you know you just uh find a

130
00:05:15,520 --> 00:05:20,080
target uh and then your your computer

131
00:05:18,160 --> 00:05:23,080
would simulate if the target works on a

132
00:05:20,080 --> 00:05:26,960
patient and it would today does

133
00:05:23,080 --> 00:05:30,320
not okay um in that so in that field

134
00:05:26,960 --> 00:05:32,560
this AI is a help um there are many ways

135
00:05:30,320 --> 00:05:34,240
to to to introduce it but all of you

136
00:05:32,560 --> 00:05:36,880
have heard and and probably maybe have

137
00:05:34,240 --> 00:05:39,199
developed or are working on things like

138
00:05:36,880 --> 00:05:40,880
Alpha Fall. This is a big game changer.

139
00:05:39,199 --> 00:05:43,759
I just mentioned it because it's popular

140
00:05:40,880 --> 00:05:45,759
and also just to illustrate again if it

141
00:05:43,759 --> 00:05:47,759
was not obvious to all of you that

142
00:05:45,759 --> 00:05:50,000
something has happened in the field.

143
00:05:47,759 --> 00:05:52,479
This is a specific problem in biology

144
00:05:50,000 --> 00:05:55,039
here. We're talking of predicting the 3D

145
00:05:52,479 --> 00:05:57,360
structure of a protein from its amino

146
00:05:55,039 --> 00:05:59,199
acid sequence. And that's a field that

147
00:05:57,360 --> 00:06:01,360
where again there there has been lots of

148
00:05:59,199 --> 00:06:03,919
smart people developing smart ideas over

149
00:06:01,360 --> 00:06:05,440
the years but where the performance of

150
00:06:03,919 --> 00:06:07,199
the prediction was plateauing has been

151
00:06:05,440 --> 00:06:09,360
plateauing for more or less know couple

152
00:06:07,199 --> 00:06:11,919
of decades and then came a different

153
00:06:09,360 --> 00:06:14,240
approach AI based approach big neural

154
00:06:11,919 --> 00:06:16,160
networks which borrows ID of course from

155
00:06:14,240 --> 00:06:17,960
what was done before but pushes it to a

156
00:06:16,160 --> 00:06:20,000
new scale and and with a few new

157
00:06:17,960 --> 00:06:21,840
technologies that really changed the

158
00:06:20,000 --> 00:06:25,039
field suddenly the performance is better

159
00:06:21,840 --> 00:06:27,360
and turns out to be useful.

160
00:06:25,039 --> 00:06:29,520
uh something important uh is that when

161
00:06:27,360 --> 00:06:31,440
when I talk of new approaches of AI and

162
00:06:29,520 --> 00:06:34,639
this is uh this is what I will now

163
00:06:31,440 --> 00:06:36,800
discuss in my talk uh there is something

164
00:06:34,639 --> 00:06:39,520
that is interesting which is that a lot

165
00:06:36,800 --> 00:06:42,720
of the recent progress in AI in biology

166
00:06:39,520 --> 00:06:44,479
like alpha fold and beyond is based on

167
00:06:42,720 --> 00:06:46,240
approaches that are slightly different

168
00:06:44,479 --> 00:06:49,400
from what machine learning was 10 years

169
00:06:46,240 --> 00:06:53,280
ago and it's really a lot of emphasize

170
00:06:49,400 --> 00:06:55,039
on purely datadriven AI meaning if you

171
00:06:53,280 --> 00:06:57,800
have lots of data

172
00:06:55,039 --> 00:07:00,080
then it's possible we discovered ways to

173
00:06:57,800 --> 00:07:03,039
train neural networks so machine

174
00:07:00,080 --> 00:07:04,560
learning models in a unsupervised way so

175
00:07:03,039 --> 00:07:06,479
I can call that self-supervised or

176
00:07:04,560 --> 00:07:10,240
unsupervised but meaning with no human

177
00:07:06,479 --> 00:07:12,319
annotation with no specific you know uh

178
00:07:10,240 --> 00:07:14,080
objective function in mind to solve a

179
00:07:12,319 --> 00:07:17,160
problem just looking at data and

180
00:07:14,080 --> 00:07:18,960
managing to learn from data a good

181
00:07:17,160 --> 00:07:21,440
representation you know a good

182
00:07:18,960 --> 00:07:24,080
simulation of the data so that then it

183
00:07:21,440 --> 00:07:26,080
can be fine-tuned or used to to solve a

184
00:07:24,080 --> 00:07:28,160
variety of tasks. Right? So this thing

185
00:07:26,080 --> 00:07:30,319
is is you know my definition of a

186
00:07:28,160 --> 00:07:31,840
foundation model. Foundation model is

187
00:07:30,319 --> 00:07:35,039
really something so neural network

188
00:07:31,840 --> 00:07:36,800
typically that is uh that has that is

189
00:07:35,039 --> 00:07:39,120
typically very complicated. So it's not

190
00:07:36,800 --> 00:07:40,720
like a few simple equations. It's really

191
00:07:39,120 --> 00:07:44,000
billions of parameters which are

192
00:07:40,720 --> 00:07:46,000
optimized but trained just to look at

193
00:07:44,000 --> 00:07:48,319
data a bit like you know biologists have

194
00:07:46,000 --> 00:07:52,639
done and you know a scientists have done

195
00:07:48,319 --> 00:07:54,720
forever. look at data then eventually do

196
00:07:52,639 --> 00:07:57,120
hypothesis do experiments look at more

197
00:07:54,720 --> 00:07:59,440
data and aggregate this knowledge into

198
00:07:57,120 --> 00:08:01,520
your brain today we try to do the same

199
00:07:59,440 --> 00:08:04,919
but the aggregation of knowledge is done

200
00:08:01,520 --> 00:08:08,560
in a computational system

201
00:08:04,919 --> 00:08:11,039
okay so u of course this idea u maybe

202
00:08:08,560 --> 00:08:12,560
five years ago would have been uh well

203
00:08:11,039 --> 00:08:14,800
you know it's a cool idea but it will

204
00:08:12,560 --> 00:08:17,680
never work I think all of us here

205
00:08:14,800 --> 00:08:22,720
probably every day you use some some LLM

206
00:08:17,680 --> 00:08:24,479
some uh Jim MNI, GPT, etc. And suddenly,

207
00:08:22,720 --> 00:08:26,639
you know, something that that sounded

208
00:08:24,479 --> 00:08:29,120
crazy five years ago is not crazy

209
00:08:26,639 --> 00:08:32,479
anymore. An LLM is just a foundation

210
00:08:29,120 --> 00:08:34,000
model of language. So, GPT, Gemini, all

211
00:08:32,479 --> 00:08:37,200
these things. They are just systems

212
00:08:34,000 --> 00:08:39,039
which have read texts taken from the web

213
00:08:37,200 --> 00:08:41,680
with no specific things made. But I've

214
00:08:39,039 --> 00:08:44,159
tried to learn to speak just looking at

215
00:08:41,680 --> 00:08:45,760
at at raw text. And what we realize

216
00:08:44,159 --> 00:08:47,760
today is that they speak pretty well.

217
00:08:45,760 --> 00:08:49,920
It's not perfect. you know I won't enter

218
00:08:47,760 --> 00:08:52,800
into the question of whether this is

219
00:08:49,920 --> 00:08:54,959
intelligence or not but at least it's a

220
00:08:52,800 --> 00:08:57,839
very powerful system that just from our

221
00:08:54,959 --> 00:09:00,240
data has learned to answer questions has

222
00:08:57,839 --> 00:09:01,800
learned to generate text etc. So the

223
00:09:00,240 --> 00:09:06,080
question is could we do the same in

224
00:09:01,800 --> 00:09:08,240
biology like uh and this is you know it

225
00:09:06,080 --> 00:09:11,279
could be a bit provocative to say well

226
00:09:08,240 --> 00:09:13,760
maybe we don't need so much humans there

227
00:09:11,279 --> 00:09:16,560
maybe if you just collect lots of data

228
00:09:13,760 --> 00:09:19,920
and find a way to train this equivalent

229
00:09:16,560 --> 00:09:21,760
of LLM but from raw data what could they

230
00:09:19,920 --> 00:09:23,600
learn and could they build a system

231
00:09:21,760 --> 00:09:26,160
computational system that then can be

232
00:09:23,600 --> 00:09:28,160
queried can be used you know to address

233
00:09:26,160 --> 00:09:29,839
many questions uh the previous talk I

234
00:09:28,160 --> 00:09:31,920
think gave a few examples of how this

235
00:09:29,839 --> 00:09:34,240
can be done if you want to identify

236
00:09:31,920 --> 00:09:35,920
structures in a cell. But maybe we could

237
00:09:34,240 --> 00:09:39,600
pre-train a system that then could be

238
00:09:35,920 --> 00:09:41,600
queried uh up to can you design me a

239
00:09:39,600 --> 00:09:44,320
good drug for these patients. We don't

240
00:09:41,600 --> 00:09:46,480
know. Okay. So we are not there yet at

241
00:09:44,320 --> 00:09:48,399
all. It's very hard to know whether we

242
00:09:46,480 --> 00:09:50,399
will get there but I think there's lots

243
00:09:48,399 --> 00:09:52,080
of progress being made. something more

244
00:09:50,399 --> 00:09:54,440
complicated in biology that in in

245
00:09:52,080 --> 00:09:56,880
language is that you know

246
00:09:54,440 --> 00:09:58,640
language language at least there is one

247
00:09:56,880 --> 00:10:01,760
modality which is text which is the

248
00:09:58,640 --> 00:10:02,959
modality used to train LLMs in biology

249
00:10:01,760 --> 00:10:05,279
as soon as you say let's train a

250
00:10:02,959 --> 00:10:07,440
foundation model of biology first

251
00:10:05,279 --> 00:10:08,880
question is okay what is biology what

252
00:10:07,440 --> 00:10:12,560
are we talking about are we talking

253
00:10:08,880 --> 00:10:15,440
about molecules cells tissues organisms

254
00:10:12,560 --> 00:10:16,800
ecosystems etc so there's uh you know

255
00:10:15,440 --> 00:10:19,200
lots of levels there's lots of

256
00:10:16,800 --> 00:10:23,200
modalities it's a mix of images genomics

257
00:10:19,200 --> 00:10:26,079
etc So it's a broad field uh where you

258
00:10:23,200 --> 00:10:28,640
know I have my you know me and my teams

259
00:10:26,079 --> 00:10:31,360
we we explore it but it's like there is

260
00:10:28,640 --> 00:10:32,480
an endless uh combination of things we

261
00:10:31,360 --> 00:10:34,760
could try and I think this is going to

262
00:10:32,480 --> 00:10:37,279
be a very exciting topic in the years to

263
00:10:34,760 --> 00:10:39,519
come. Uh it already started you know I

264
00:10:37,279 --> 00:10:41,360
mentioned alpha fall but I think these

265
00:10:39,519 --> 00:10:43,920
days if if you if you follow you know

266
00:10:41,360 --> 00:10:46,320
bioarchchive etc every week you have new

267
00:10:43,920 --> 00:10:48,640
foundation models. uh I would say that

268
00:10:46,320 --> 00:10:50,560
as of today most of the foundation

269
00:10:48,640 --> 00:10:53,279
models and and most of the publications

270
00:10:50,560 --> 00:10:56,399
that come out uh tend to be on on

271
00:10:53,279 --> 00:10:59,040
specific modalities specific levels. So

272
00:10:56,399 --> 00:11:01,200
you have I I will go through a few

273
00:10:59,040 --> 00:11:03,839
examples but we hear a lot about

274
00:11:01,200 --> 00:11:06,640
foundation models for small molecules

275
00:11:03,839 --> 00:11:10,399
for proteins for single cells for

276
00:11:06,640 --> 00:11:12,079
tissues etc. Uh by the way you know the

277
00:11:10,399 --> 00:11:13,760
field is really growing fast. there are

278
00:11:12,079 --> 00:11:16,640
hundreds of citations. So I show a few

279
00:11:13,760 --> 00:11:18,720
examples but please uh please pardon me

280
00:11:16,640 --> 00:11:21,200
if you're not work there. They're just

281
00:11:18,720 --> 00:11:22,959
you know it's just a mini sample but

282
00:11:21,200 --> 00:11:24,640
just to say that these high impact

283
00:11:22,959 --> 00:11:27,040
publications are coming and there they

284
00:11:24,640 --> 00:11:29,200
really have you know each of them is

285
00:11:27,040 --> 00:11:30,640
really bringing lots of of novelties and

286
00:11:29,200 --> 00:11:33,279
and when you look at the results at

287
00:11:30,640 --> 00:11:36,160
least for specific tasks we see that

288
00:11:33,279 --> 00:11:39,120
this approach seems to be working in

289
00:11:36,160 --> 00:11:40,720
maybe not yet in all dimensions but I I

290
00:11:39,120 --> 00:11:42,000
will give a few examples of where it

291
00:11:40,720 --> 00:11:44,000
really brings a new performance

292
00:11:42,000 --> 00:11:46,440
improvement. Okay. So foundation models

293
00:11:44,000 --> 00:11:49,279
of budge are coming.

294
00:11:46,440 --> 00:11:51,440
uh let me deep dive to a few of them

295
00:11:49,279 --> 00:11:54,560
before then coming back to how we build

296
00:11:51,440 --> 00:11:56,480
a more unified view of biology. So I

297
00:11:54,560 --> 00:11:58,320
would just mention and again I take

298
00:11:56,480 --> 00:12:00,000
risks here especially in in front of

299
00:11:58,320 --> 00:12:01,839
this audience because I will cite some

300
00:12:00,000 --> 00:12:03,839
work which are not mine at all which I

301
00:12:01,839 --> 00:12:05,920
found interesting a bit a bit outdated

302
00:12:03,839 --> 00:12:08,480
by the way just to show that it's it's

303
00:12:05,920 --> 00:12:10,560
it's already there. So proteins maybe

304
00:12:08,480 --> 00:12:13,839
has been the the first you know there

305
00:12:10,560 --> 00:12:16,000
was alpha fold and then lots of work uh

306
00:12:13,839 --> 00:12:18,480
training LLMs on proteins. One good

307
00:12:16,000 --> 00:12:21,360
reason being that you know we know how

308
00:12:18,480 --> 00:12:24,079
to train large language models on on

309
00:12:21,360 --> 00:12:26,320
human language. If you replace a text by

310
00:12:24,079 --> 00:12:27,839
a DNA sequence or an amino acid

311
00:12:26,320 --> 00:12:30,120
sequence, you more or less can use

312
00:12:27,839 --> 00:12:32,959
exactly the same architecture, the same

313
00:12:30,120 --> 00:12:35,040
transformer. Click the button, it learns

314
00:12:32,959 --> 00:12:37,680
to speak not the language of humans, but

315
00:12:35,040 --> 00:12:39,519
the language of biology. And and so this

316
00:12:37,680 --> 00:12:41,680
you know this uh this work I mentioned

317
00:12:39,519 --> 00:12:43,680
here are a bit old already in that

318
00:12:41,680 --> 00:12:45,440
field. But they demonstrated that in

319
00:12:43,680 --> 00:12:47,600
principle just doing that gave new

320
00:12:45,440 --> 00:12:49,440
capacities like generating proteins you

321
00:12:47,600 --> 00:12:52,160
can query proteins you can predict the

322
00:12:49,440 --> 00:12:55,760
impact of mutation etc to some level

323
00:12:52,160 --> 00:12:57,519
okay so this is already uh coming of

324
00:12:55,760 --> 00:13:00,240
course there's this super exciting field

325
00:12:57,519 --> 00:13:02,079
of single cell genomics uh and I'm sorry

326
00:13:00,240 --> 00:13:04,639
again I see only one paper out of

327
00:13:02,079 --> 00:13:06,480
hundreds I know the the broad and many

328
00:13:04,639 --> 00:13:08,560
people here are deeply involved in that

329
00:13:06,480 --> 00:13:11,839
field but the fact that we have access

330
00:13:08,560 --> 00:13:14,240
now to the capacity to generate large

331
00:13:11,839 --> 00:13:16,240
volumes of single cell transcripttomies

332
00:13:14,240 --> 00:13:18,480
for example we're talking of tens or

333
00:13:16,240 --> 00:13:20,560
hundreds of millions of single cells

334
00:13:18,480 --> 00:13:23,519
suggests that we can learn the biology

335
00:13:20,560 --> 00:13:24,880
of single cells or try to build a

336
00:13:23,519 --> 00:13:27,079
foundation model of single cells that

337
00:13:24,880 --> 00:13:30,000
could allow us to have a virtual single

338
00:13:27,079 --> 00:13:32,320
cell one strain maybe allowing it to

339
00:13:30,000 --> 00:13:34,079
predict the evolution of cells you know

340
00:13:32,320 --> 00:13:36,720
time evolutions or the response to

341
00:13:34,079 --> 00:13:37,920
pertubation etc etc so there's lots of

342
00:13:36,720 --> 00:13:40,160
work and there are many people in this

343
00:13:37,920 --> 00:13:42,800
room much better than me in that in that

344
00:13:40,160 --> 00:13:45,600
field but this is really, you know, a

345
00:13:42,800 --> 00:13:48,839
great example of how the current AI

346
00:13:45,600 --> 00:13:52,480
technology can really match the current

347
00:13:48,839 --> 00:13:55,120
biotechnology and biology topics. New

348
00:13:52,480 --> 00:13:56,639
technologies, lots of data and and and a

349
00:13:55,120 --> 00:13:57,399
great object to study in this case,

350
00:13:56,639 --> 00:14:00,079
singing

351
00:13:57,399 --> 00:14:02,720
also. Now let me spend a little bit more

352
00:14:00,079 --> 00:14:04,800
time on on what's what's beyond cells

353
00:14:02,720 --> 00:14:06,839
because understanding one cell is good

354
00:14:04,800 --> 00:14:09,360
but you know if you work in cancer for

355
00:14:06,839 --> 00:14:11,600
example everybody knows that it's the

356
00:14:09,360 --> 00:14:13,680
interaction of cells uh complex

357
00:14:11,600 --> 00:14:16,000
interactions tumor micro environment etc

358
00:14:13,680 --> 00:14:17,760
which which matter probably more than

359
00:14:16,000 --> 00:14:21,360
understanding what one cell does in a

360
00:14:17,760 --> 00:14:23,600
petetro dish. Uh so how do you go from

361
00:14:21,360 --> 00:14:25,600
one cell to many cells to interactions

362
00:14:23,600 --> 00:14:27,680
between cells? uh here there are many

363
00:14:25,600 --> 00:14:30,320
technologies but uh you know when you

364
00:14:27,680 --> 00:14:34,000
think of how to get large volumes of

365
00:14:30,320 --> 00:14:36,320
data um it's often no there is single

366
00:14:34,000 --> 00:14:39,040
cell genomics for single cell but for

367
00:14:36,320 --> 00:14:41,279
tissues uh something that is quite

368
00:14:39,040 --> 00:14:43,800
common and for which it's very easy to

369
00:14:41,279 --> 00:14:46,639
get lots of data are images in

370
00:14:43,800 --> 00:14:48,320
particular these types of images in

371
00:14:46,639 --> 00:14:51,199
hisystopathology because this is what's

372
00:14:48,320 --> 00:14:53,120
used in in in many clinics in the world

373
00:14:51,199 --> 00:14:55,360
right as soon as you have a suspicion of

374
00:14:53,120 --> 00:14:57,600
cancer you do a biopsy you look it under

375
00:14:55,360 --> 00:14:59,440
the microscope and if you have a scanner

376
00:14:57,600 --> 00:15:02,480
then you can make it digital and

377
00:14:59,440 --> 00:15:04,000
suddenly collect millions of of images.

378
00:15:02,480 --> 00:15:05,600
So of course the depth of the

379
00:15:04,000 --> 00:15:08,000
information maybe is a bit shallow

380
00:15:05,600 --> 00:15:11,040
because it's only an image but remember

381
00:15:08,000 --> 00:15:14,000
this is these types of images are what

382
00:15:11,040 --> 00:15:16,160
is used today by most uh clinicians to

383
00:15:14,000 --> 00:15:17,680
do a diagnostics and often to to sell a

384
00:15:16,160 --> 00:15:19,920
treatment right so there is information

385
00:15:17,680 --> 00:15:22,320
there. So a question is if you have this

386
00:15:19,920 --> 00:15:25,839
this data well can you you know could

387
00:15:22,320 --> 00:15:27,440
you uh build a foundation model on that

388
00:15:25,839 --> 00:15:29,279
that would mimic in a sense what

389
00:15:27,440 --> 00:15:31,279
pathologists are are learning right you

390
00:15:29,279 --> 00:15:32,959
look at total lots of images to

391
00:15:31,279 --> 00:15:35,199
understand the diversity the patterns

392
00:15:32,959 --> 00:15:40,160
that you can have and maybe then from an

393
00:15:35,199 --> 00:15:43,920
image do a lot of uh prediction tasks

394
00:15:40,160 --> 00:15:46,880
u maybe I just skip that so just to uh

395
00:15:43,920 --> 00:15:48,959
just to anchor again these um this

396
00:15:46,880 --> 00:15:51,199
comment in the real for this is one

397
00:15:48,959 --> 00:15:53,440
example out of many of systems that

398
00:15:51,199 --> 00:15:57,519
already exist and already use foundation

399
00:15:53,440 --> 00:16:00,000
models uh to help patients. That's one

400
00:15:57,519 --> 00:16:01,680
system which is actually uh that was

401
00:16:00,000 --> 00:16:03,519
developed by aren. So which is used in

402
00:16:01,680 --> 00:16:07,279
the clinics for one task in this case

403
00:16:03,519 --> 00:16:10,440
it's in coloral cancer from the image to

404
00:16:07,279 --> 00:16:14,000
predict uh the status of microatellite

405
00:16:10,440 --> 00:16:17,120
instability which is a good predictor of

406
00:16:14,000 --> 00:16:19,839
response to imunotherapy. So this is

407
00:16:17,120 --> 00:16:21,920
something that you know is is important

408
00:16:19,839 --> 00:16:24,720
for clinics. There is a genetic test

409
00:16:21,920 --> 00:16:28,240
that is the the standard to to decide of

410
00:16:24,720 --> 00:16:31,120
the MSI status but uh adding to the

411
00:16:28,240 --> 00:16:34,000
genetic test a pre-screening phase by

412
00:16:31,120 --> 00:16:36,480
images can be a way to accelerate right

413
00:16:34,000 --> 00:16:38,720
the filtering out patients who are

414
00:16:36,480 --> 00:16:40,320
likely to be positive or negative. So

415
00:16:38,720 --> 00:16:41,759
that's the kind of thing that you know

416
00:16:40,320 --> 00:16:43,839
that finds its way in the in the

417
00:16:41,759 --> 00:16:45,600
clinical protocol and this thing is just

418
00:16:43,839 --> 00:16:49,040
one machine learning application where

419
00:16:45,600 --> 00:16:51,360
you have an image as input uh you know

420
00:16:49,040 --> 00:16:53,199
uh a prediction to be made MSI positive

421
00:16:51,360 --> 00:16:54,720
or negative and that's typically the

422
00:16:53,199 --> 00:16:56,639
kind of things which already today

423
00:16:54,720 --> 00:16:59,360
benefit a lot from these foundation

424
00:16:56,639 --> 00:17:02,399
models. I will I will show some results

425
00:16:59,360 --> 00:17:04,400
but uh in the same way as once so one

426
00:17:02,399 --> 00:17:06,559
it's a machine learning problem but

427
00:17:04,400 --> 00:17:08,480
boosted by the recent approach the the

428
00:17:06,559 --> 00:17:10,880
modern AI approach to say if you can

429
00:17:08,480 --> 00:17:13,360
pre-train a model on millions of

430
00:17:10,880 --> 00:17:16,079
histopathology slides then you can also

431
00:17:13,360 --> 00:17:18,640
improve the performance of downstream

432
00:17:16,079 --> 00:17:20,600
tasks like this task which which is

433
00:17:18,640 --> 00:17:22,760
already in the

434
00:17:20,600 --> 00:17:25,880
clinics. Okay. So

435
00:17:22,760 --> 00:17:28,799
uh how do you train foundation models?

436
00:17:25,880 --> 00:17:32,559
uh if if you're I mean uh I know this is

437
00:17:28,799 --> 00:17:34,960
a mixed audience uh in LLMs like in

438
00:17:32,559 --> 00:17:37,280
protein sequence natural language most

439
00:17:34,960 --> 00:17:38,720
people know that uh it's just trained by

440
00:17:37,280 --> 00:17:40,640
predicting the next word from the

441
00:17:38,720 --> 00:17:43,280
context so you see lots of text and you

442
00:17:40,640 --> 00:17:44,720
train a statistical model to you know to

443
00:17:43,280 --> 00:17:46,080
say well if you have seen this thing

444
00:17:44,720 --> 00:17:48,160
what is the next word and if you know

445
00:17:46,080 --> 00:17:50,960
how to predict that you get an LM of

446
00:17:48,160 --> 00:17:52,480
course for images it's a bit more more

447
00:17:50,960 --> 00:17:55,120
different because there is no notion of

448
00:17:52,480 --> 00:17:57,440
sequence but just for information you

449
00:17:55,120 --> 00:17:59,360
you know the field has tried many ideas

450
00:17:57,440 --> 00:18:01,840
has converged to a few that seem to be

451
00:17:59,360 --> 00:18:03,840
working so FYI the kind of thing that

452
00:18:01,840 --> 00:18:06,880
seems to be working today is to mix so

453
00:18:03,840 --> 00:18:09,679
it's again it's self-supervised meaning

454
00:18:06,880 --> 00:18:11,320
here I'm just talking of suppose you

455
00:18:09,679 --> 00:18:13,440
give me millions of

456
00:18:11,320 --> 00:18:15,520
images what could be an objective

457
00:18:13,440 --> 00:18:17,440
function for neural network when it sees

458
00:18:15,520 --> 00:18:19,600
the images to optimize the way to do

459
00:18:17,440 --> 00:18:21,679
something okay and the things that that

460
00:18:19,600 --> 00:18:25,360
seem to make sense that seem to work at

461
00:18:21,679 --> 00:18:27,679
least uh is as of today mostly a of two

462
00:18:25,360 --> 00:18:30,240
main ideas. One is called contrastive

463
00:18:27,679 --> 00:18:33,200
learning. So is ide to say if you have

464
00:18:30,240 --> 00:18:34,799
an image of a tumor then by yourselves

465
00:18:33,200 --> 00:18:36,960
or through you know through different

466
00:18:34,799 --> 00:18:40,240
measurements you can take a picture of

467
00:18:36,960 --> 00:18:41,679
the same patient or the same tumor but

468
00:18:40,240 --> 00:18:43,200
changing the color changing the

469
00:18:41,679 --> 00:18:46,640
orientation changing the bit the

470
00:18:43,200 --> 00:18:48,640
geometry and just constrain so teach you

471
00:18:46,640 --> 00:18:51,200
know let the neural network learn that

472
00:18:48,640 --> 00:18:52,720
it's the same tumor right so in a sense

473
00:18:51,200 --> 00:18:55,160
learning the biology and not the

474
00:18:52,720 --> 00:18:57,840
artifacts of the thing this is one key

475
00:18:55,160 --> 00:18:59,840
ID the second key ID which is quite

476
00:18:57,840 --> 00:19:02,960
similar to what's done in autogressive

477
00:18:59,840 --> 00:19:05,600
LLMs except that it's not a sequence.

478
00:19:02,960 --> 00:19:07,440
It's just what's called generative

479
00:19:05,600 --> 00:19:09,760
learning. So you take an image, you you

480
00:19:07,440 --> 00:19:12,559
hide part of the image and you train the

481
00:19:09,760 --> 00:19:14,640
neural network to reconstruct the hidden

482
00:19:12,559 --> 00:19:16,080
part. This can be done without human

483
00:19:14,640 --> 00:19:17,840
intervention because it's pretty

484
00:19:16,080 --> 00:19:20,559
computer that takes an image, removes

485
00:19:17,840 --> 00:19:22,400
part of it and trace a model to you know

486
00:19:20,559 --> 00:19:23,919
to predict what it has removed. So this

487
00:19:22,400 --> 00:19:26,080
is really this notion of self-s

488
00:19:23,919 --> 00:19:28,080
supervision where no human intervention

489
00:19:26,080 --> 00:19:32,320
the computer can do it by itself and do

490
00:19:28,080 --> 00:19:34,960
it at scale. Okay. So when you do that

491
00:19:32,320 --> 00:19:37,679
and uh then you can train a foundation

492
00:19:34,960 --> 00:19:39,200
model of of pathology and once you have

493
00:19:37,679 --> 00:19:41,120
done that you know what what it is at

494
00:19:39,200 --> 00:19:44,080
the end I mean there are many ways to to

495
00:19:41,120 --> 00:19:46,480
query to use it but one of them is that

496
00:19:44,080 --> 00:19:49,200
the model has learned to represent

497
00:19:46,480 --> 00:19:51,840
images. So it can read an image and map

498
00:19:49,200 --> 00:19:54,400
an image to a representation in numbers

499
00:19:51,840 --> 00:19:56,480
right fixed vector representation often

500
00:19:54,400 --> 00:19:59,120
roughly about a thousand numbers and

501
00:19:56,480 --> 00:20:02,080
then from this representation you can

502
00:19:59,120 --> 00:20:04,799
fine-tune it to solve tasks. So for

503
00:20:02,080 --> 00:20:07,039
example I mentioned the MSI prediction

504
00:20:04,799 --> 00:20:09,360
is one such task meaning if you have a

505
00:20:07,039 --> 00:20:11,600
smaller set of images with annotation

506
00:20:09,360 --> 00:20:15,120
you can fine-tune your model so that it

507
00:20:11,600 --> 00:20:17,200
can predict MSI. Um here I show one one

508
00:20:15,120 --> 00:20:18,960
work so I think it was one of the early

509
00:20:17,200 --> 00:20:22,160
work one of the first foundation models

510
00:20:18,960 --> 00:20:23,799
for pathology which was done at alken in

511
00:20:22,160 --> 00:20:26,799
23 it's called

512
00:20:23,799 --> 00:20:29,440
ficon and uh so we developed here you

513
00:20:26,799 --> 00:20:32,559
know it was a foundation model for

514
00:20:29,440 --> 00:20:35,360
pathology trained on tcgi data basically

515
00:20:32,559 --> 00:20:37,760
public data so not not big but not super

516
00:20:35,360 --> 00:20:40,159
big I would say uh but already when we

517
00:20:37,760 --> 00:20:42,880
tested it uh after fetuning on a number

518
00:20:40,159 --> 00:20:44,799
of tasks and here I won't go to details

519
00:20:42,880 --> 00:20:48,120
But it's a mix of from an image you can

520
00:20:44,799 --> 00:20:50,960
predict a variety of genomic alterations

521
00:20:48,120 --> 00:20:53,600
like bracka bracka mutation in breast

522
00:20:50,960 --> 00:20:56,720
cancer for example or you can find to

523
00:20:53,600 --> 00:20:59,280
predict survival so for prognosis or

524
00:20:56,720 --> 00:21:01,039
predicted uh predict molecular subtypes

525
00:20:59,280 --> 00:21:02,880
systematically we got some big

526
00:21:01,039 --> 00:21:04,480
improvement compared to what was done

527
00:21:02,880 --> 00:21:06,480
before which is more standard machine

528
00:21:04,480 --> 00:21:08,480
learning and by the way you know just to

529
00:21:06,480 --> 00:21:10,559
uh to to go beyond internal validation

530
00:21:08,480 --> 00:21:12,480
we also tested it on the kagle challenge

531
00:21:10,559 --> 00:21:14,159
so I I really like you know challenges

532
00:21:12,480 --> 00:21:17,760
is like Caroline mentioned this is how

533
00:21:14,159 --> 00:21:20,000
the field can uh you know progress by

534
00:21:17,760 --> 00:21:21,520
step because after a challenge everyone

535
00:21:20,000 --> 00:21:23,039
observes what works what doesn't work

536
00:21:21,520 --> 00:21:24,960
and we we can follow up on the best

537
00:21:23,039 --> 00:21:27,440
ideas and so there was at the time there

538
00:21:24,960 --> 00:21:29,679
was one challenge on breast cancer

539
00:21:27,440 --> 00:21:32,840
cancer subtype classification organized

540
00:21:29,679 --> 00:21:35,280
by UBC that we won actually with quite a

541
00:21:32,840 --> 00:21:36,559
margin uh and basically the main

542
00:21:35,280 --> 00:21:38,159
difference between our approach and the

543
00:21:36,559 --> 00:21:40,880
others were the use of this foundation

544
00:21:38,159 --> 00:21:43,440
model so much less impact than alpha

545
00:21:40,880 --> 00:21:45,760
fold but in a sense similar pattern to

546
00:21:43,440 --> 00:21:48,400
say well if suddenly you decide to take

547
00:21:45,760 --> 00:21:49,919
a different approach uh build foundation

548
00:21:48,400 --> 00:21:51,840
model and check them they just improve

549
00:21:49,919 --> 00:21:53,559
the field right so and it's systematic

550
00:21:51,840 --> 00:21:56,000
across a lots of

551
00:21:53,559 --> 00:21:57,760
application now on once we were there of

552
00:21:56,000 --> 00:21:59,200
course there was this uh exciting

553
00:21:57,760 --> 00:22:02,400
question say well we have trained a

554
00:21:59,200 --> 00:22:04,720
model on CGA but all the LM field tells

555
00:22:02,400 --> 00:22:06,880
us that if you grow your model if you

556
00:22:04,720 --> 00:22:09,679
have more data then maybe the

557
00:22:06,880 --> 00:22:11,039
performance will improve again uh which

558
00:22:09,679 --> 00:22:13,280
is something we don't understand

559
00:22:11,039 --> 00:22:15,120
perfectly Why? But it's intuitively the

560
00:22:13,280 --> 00:22:18,159
case that the foundation models benefit

561
00:22:15,120 --> 00:22:19,440
from volumes of data. Okay, so that's

562
00:22:18,159 --> 00:22:21,120
what we did and this is one of the

563
00:22:19,440 --> 00:22:23,280
reasons why by the way we created this

564
00:22:21,120 --> 00:22:25,200
new company by Optimus which is solely

565
00:22:23,280 --> 00:22:27,280
focused on developing foundation models

566
00:22:25,200 --> 00:22:30,159
for biology. It requires some you know

567
00:22:27,280 --> 00:22:32,720
capital. It's expensive. Therefore the

568
00:22:30,159 --> 00:22:36,000
the idea to have obviously you know some

569
00:22:32,720 --> 00:22:37,760
some capital but so so we released um

570
00:22:36,000 --> 00:22:39,360
last year some models but more recently

571
00:22:37,760 --> 00:22:40,799
last month a model which we call H

572
00:22:39,360 --> 00:22:44,080
Optimus one. And just to give you an

573
00:22:40,799 --> 00:22:46,520
idea of the scale where we are today, um

574
00:22:44,080 --> 00:22:50,480
this is a model that instead of you know

575
00:22:46,520 --> 00:22:53,280
5,000 images from TCGA is trained on

576
00:22:50,480 --> 00:22:55,679
more than 1 million. Uh and importantly

577
00:22:53,280 --> 00:22:57,600
coming from many patients, right? So to

578
00:22:55,679 --> 00:22:59,200
get patients we did partnerships with a

579
00:22:57,600 --> 00:23:02,799
variety of labs. We worked with more

580
00:22:59,200 --> 00:23:04,640
than 4,000 clinical practices. So we are

581
00:23:02,799 --> 00:23:07,280
the you know I'm sure we can go beyond

582
00:23:04,640 --> 00:23:10,000
but already we move from thousands to

583
00:23:07,280 --> 00:23:11,679
millions. uh something uh if you're in

584
00:23:10,000 --> 00:23:14,400
the machine learning field important is

585
00:23:11,679 --> 00:23:16,960
that here we're talking each image is

586
00:23:14,400 --> 00:23:18,880
very large. It's a gigapixel image. So

587
00:23:16,960 --> 00:23:22,480
in fact to train the model we cut each

588
00:23:18,880 --> 00:23:24,960
image into thousands of smaller patches.

589
00:23:22,480 --> 00:23:27,360
So the the number of small image that

590
00:23:24,960 --> 00:23:29,720
the the the computer sees to train the

591
00:23:27,360 --> 00:23:32,480
model is in the billions.

592
00:23:29,720 --> 00:23:35,919
Okay. Uh so we did that. It's available

593
00:23:32,480 --> 00:23:39,520
on face if you want to try it. Um and

594
00:23:35,919 --> 00:23:39,520
and does it work? Well, you know, we we

595
00:23:39,799 --> 00:23:44,559
we played the, you know, we tried. So,

596
00:23:42,799 --> 00:23:46,880
by the way, I just mentioned our work,

597
00:23:44,559 --> 00:23:49,360
but that's a field that is booming as

598
00:23:46,880 --> 00:23:51,200
well. There are there are lots of other

599
00:23:49,360 --> 00:23:53,280
very nice nice models that have been

600
00:23:51,200 --> 00:23:54,960
proposed over the years. Uh, but just

601
00:23:53,280 --> 00:23:56,480
this is this is some of the results. So

602
00:23:54,960 --> 00:23:58,400
I won't go to you know there there's a

603
00:23:56,480 --> 00:24:01,600
link to where the results are detailed

604
00:23:58,400 --> 00:24:04,000
but this is a summary of 18 tasks where

605
00:24:01,600 --> 00:24:07,039
you say I have trained a model and I use

606
00:24:04,000 --> 00:24:09,280
it to predict a genomic alteration

607
00:24:07,039 --> 00:24:11,440
prognosis classification etc. Then you

608
00:24:09,280 --> 00:24:13,200
can measure the performance if it works

609
00:24:11,440 --> 00:24:17,120
well or not. And here this these slides

610
00:24:13,200 --> 00:24:18,400
aggregate the performance right AU u I

611
00:24:17,120 --> 00:24:21,760
think there are a couple of things to to

612
00:24:18,400 --> 00:24:24,480
be said here. So one is every you know

613
00:24:21,760 --> 00:24:26,960
every every column is is a different

614
00:24:24,480 --> 00:24:30,159
model. The one I presented earlier that

615
00:24:26,960 --> 00:24:32,120
one kaggle last year which is you know

616
00:24:30,159 --> 00:24:34,799
quite important

617
00:24:32,120 --> 00:24:38,159
is it's not even here is a predecessor

618
00:24:34,799 --> 00:24:40,559
of falcon v2 uh it was falcon v1 right

619
00:24:38,159 --> 00:24:43,200
which is much below there. So first

620
00:24:40,559 --> 00:24:46,880
comment is that between 20 end of 23 and

621
00:24:43,200 --> 00:24:49,520
25 you know we move from uh let's say

622
00:24:46,880 --> 00:24:51,440
80ish to 85ish

623
00:24:49,520 --> 00:24:54,400
uh by just changing the foundation model

624
00:24:51,440 --> 00:24:56,400
right no other innovation you just

625
00:24:54,400 --> 00:24:58,559
change one component of your system all

626
00:24:56,400 --> 00:25:00,799
the all the rest is the same and you see

627
00:24:58,559 --> 00:25:03,520
that we're in a in a in a field where

628
00:25:00,799 --> 00:25:06,159
the the progression in performance of on

629
00:25:03,520 --> 00:25:08,880
task that matter uh can be in the range

630
00:25:06,159 --> 00:25:10,640
of five 10% easily just by changing the

631
00:25:08,880 --> 00:25:12,240
fundamentals So I think it's not the

632
00:25:10,640 --> 00:25:14,240
end. I don't know if how far it can go

633
00:25:12,240 --> 00:25:18,000
if it's a question of more data, bigger

634
00:25:14,240 --> 00:25:19,440
models, other modities etc. But uh as we

635
00:25:18,000 --> 00:25:21,039
speak and this is what I was saying

636
00:25:19,440 --> 00:25:23,200
where I said every week there is a new

637
00:25:21,039 --> 00:25:25,120
model, a new publication. We're in a

638
00:25:23,200 --> 00:25:28,760
very active field where we see progress

639
00:25:25,120 --> 00:25:32,480
which hopefully impact the patient.

640
00:25:28,760 --> 00:25:34,880
Um this maybe I can skip

641
00:25:32,480 --> 00:25:37,720
uh because now I'd like to you know to

642
00:25:34,880 --> 00:25:40,400
uh to take the the last five minutes to

643
00:25:37,720 --> 00:25:41,840
discuss what's next. So I insisted on on

644
00:25:40,400 --> 00:25:43,760
foundation models for images. I

645
00:25:41,840 --> 00:25:45,919
mentioned many people are doing things.

646
00:25:43,760 --> 00:25:48,400
Now the real question the real exciting

647
00:25:45,919 --> 00:25:51,120
question that I'm sure many people share

648
00:25:48,400 --> 00:25:53,039
uh is okay suppose we have a virtual

649
00:25:51,120 --> 00:25:55,520
cell we have a virtual tissue we have a

650
00:25:53,039 --> 00:25:57,919
virtual protein how they fit together

651
00:25:55,520 --> 00:26:01,120
and remember that on the application

652
00:25:57,919 --> 00:26:04,240
side the real question we care are how

653
00:26:01,120 --> 00:26:06,799
can you design a drug for a patient so

654
00:26:04,240 --> 00:26:08,400
it has to be a good protein that changes

655
00:26:06,799 --> 00:26:09,919
a cell in the correct way in such a way

656
00:26:08,400 --> 00:26:12,080
that in the tissue in the tumor micro

657
00:26:09,919 --> 00:26:14,000
environment it ends up with benefits at

658
00:26:12,080 --> 00:26:16,200
the clinics right So these things are

659
00:26:14,000 --> 00:26:20,080
connected. They have to be

660
00:26:16,200 --> 00:26:22,480
connected. Um this is so this is uh

661
00:26:20,080 --> 00:26:24,240
exciting and hard. Uh I can quickly

662
00:26:22,480 --> 00:26:26,720
share some of the avenues we've taken

663
00:26:24,240 --> 00:26:28,240
already. So you know to go across

664
00:26:26,720 --> 00:26:30,000
modalities there are questions of how do

665
00:26:28,240 --> 00:26:32,400
you get data that connects scales and

666
00:26:30,000 --> 00:26:34,159
modalities. Something that in terms of

667
00:26:32,400 --> 00:26:35,919
existing technologies that we that we

668
00:26:34,159 --> 00:26:37,679
started working on is special

669
00:26:35,919 --> 00:26:40,320
transcripttoics which is a good bridge

670
00:26:37,679 --> 00:26:42,640
between single cell genomics single cell

671
00:26:40,320 --> 00:26:44,480
transistomics and you know tissue

672
00:26:42,640 --> 00:26:46,480
organization.

673
00:26:44,480 --> 00:26:49,039
uh and in particular you know one thing

674
00:26:46,480 --> 00:26:51,600
that you could decide as a task is

675
00:26:49,039 --> 00:26:53,360
suppose you observe an image can you can

676
00:26:51,600 --> 00:26:54,960
your con can your system could you

677
00:26:53,360 --> 00:26:56,799
design a system that allows just from

678
00:26:54,960 --> 00:26:59,360
the image to reconstruct the genomics so

679
00:26:56,799 --> 00:27:01,679
that eventually you know the idea to go

680
00:26:59,360 --> 00:27:04,480
that way is that because this is the

681
00:27:01,679 --> 00:27:07,360
pathology is cheap and in large volumes

682
00:27:04,480 --> 00:27:09,120
if we had a way to from the image

683
00:27:07,360 --> 00:27:11,520
reconstruct much more than the image but

684
00:27:09,120 --> 00:27:14,480
maybe some some gene expression etc then

685
00:27:11,520 --> 00:27:17,120
suddenly we could map millions of images

686
00:27:14,480 --> 00:27:20,000
to that genetic level that would allow

687
00:27:17,120 --> 00:27:22,240
us to investigate a correlation between

688
00:27:20,000 --> 00:27:23,480
organization of of gene expression and

689
00:27:22,240 --> 00:27:28,000
response for

690
00:27:23,480 --> 00:27:29,760
example. So um you know we we worked on

691
00:27:28,000 --> 00:27:32,480
that and it turns out I don't know if

692
00:27:29,760 --> 00:27:34,799
FAL is in the room maybe but uh there's

693
00:27:32,480 --> 00:27:37,520
been a great actually a great paper at

694
00:27:34,799 --> 00:27:40,240
at newips last year which is a benchmark

695
00:27:37,520 --> 00:27:42,480
super useful not not a challenge I mean

696
00:27:40,240 --> 00:27:44,640
similar to a challenge that proposes one

697
00:27:42,480 --> 00:27:47,039
such task which is uh you know

698
00:27:44,640 --> 00:27:48,480
collecting images and among other tasks

699
00:27:47,039 --> 00:27:51,520
from an image can you predict gene

700
00:27:48,480 --> 00:27:53,760
expression. uh we did test our models

701
00:27:51,520 --> 00:27:56,720
they work very well again these are many

702
00:27:53,760 --> 00:27:59,679
models uh fon is here you see this was

703
00:27:56,720 --> 00:28:02,000
top-notch two years ago now it's quite

704
00:27:59,679 --> 00:28:04,000
quite behind for the phis I think there

705
00:28:02,000 --> 00:28:07,880
are two comments here one is that again

706
00:28:04,000 --> 00:28:11,200
in two years you know we go from 36% to

707
00:28:07,880 --> 00:28:13,840
42% performance I skip the details the

708
00:28:11,200 --> 00:28:15,520
performance here is a correlation

709
00:28:13,840 --> 00:28:18,240
coefficient between the predicted and

710
00:28:15,520 --> 00:28:20,360
the real expression average over many uh

711
00:28:18,240 --> 00:28:23,360
many many cancers But so there is big

712
00:28:20,360 --> 00:28:26,240
progress. Uh still I must say that the

713
00:28:23,360 --> 00:28:28,720
the row performance 42 is is very far

714
00:28:26,240 --> 00:28:30,159
from one that would be the optimal. So

715
00:28:28,720 --> 00:28:31,919
there is a long way to go. Probably

716
00:28:30,159 --> 00:28:33,679
there is it will keep growing. Probably

717
00:28:31,919 --> 00:28:35,679
there is a limit and so probably this

718
00:28:33,679 --> 00:28:37,520
will we cannot predict all gene

719
00:28:35,679 --> 00:28:39,039
expression just for machining just

720
00:28:37,520 --> 00:28:40,240
because there is not enough information

721
00:28:39,039 --> 00:28:41,919
but I think there is still room for

722
00:28:40,240 --> 00:28:43,919
improvement there. Okay. Okay, so it's a

723
00:28:41,919 --> 00:28:46,720
good first step and here you really see

724
00:28:43,919 --> 00:28:48,399
the you know the benefits just of

725
00:28:46,720 --> 00:28:50,799
training better foundation model because

726
00:28:48,399 --> 00:28:52,880
again all the columns is the same

727
00:28:50,799 --> 00:28:55,279
algorithm it's just you change one

728
00:28:52,880 --> 00:28:58,159
component which is the the foundation

729
00:28:55,279 --> 00:29:00,240
model that you use

730
00:28:58,159 --> 00:29:03,520
um how can we go further so a couple of

731
00:29:00,240 --> 00:29:06,000
ideas um one is that we need more data I

732
00:29:03,520 --> 00:29:09,880
think any initiative to systematically

733
00:29:06,000 --> 00:29:13,679
generate and share data is is welcome

734
00:29:09,880 --> 00:29:15,520
um one one you know one of them is a is

735
00:29:13,679 --> 00:29:18,640
a is a very cool data set being

736
00:29:15,520 --> 00:29:21,279
generated by sponsored by AIN but with

737
00:29:18,640 --> 00:29:24,080
uh several hospitals in Europe and in

738
00:29:21,279 --> 00:29:25,679
the US to systemat system systematically

739
00:29:24,080 --> 00:29:27,600
generate an atlas of cancer in

740
00:29:25,679 --> 00:29:29,600
particular using special troytomics

741
00:29:27,600 --> 00:29:32,640
technologies together with single cell

742
00:29:29,600 --> 00:29:34,559
bulk exom sequencing images etc so

743
00:29:32,640 --> 00:29:36,559
that's the kind of uh you know that's

744
00:29:34,559 --> 00:29:39,679
the kind of data generation that I think

745
00:29:36,559 --> 00:29:42,640
we really support uh the the field of a

746
00:29:39,679 --> 00:29:45,039
bi and and foundation models are really

747
00:29:42,640 --> 00:29:46,399
ready to ingest all of this data, take

748
00:29:45,039 --> 00:29:49,279
this data, they will just improve the

749
00:29:46,399 --> 00:29:52,240
models and move us maybe towards more uh

750
00:29:49,279 --> 00:29:54,399
multiscale multimodel foundation models.

751
00:29:52,240 --> 00:29:56,720
And I will uh I will finish saying so

752
00:29:54,399 --> 00:29:58,320
you know we are working hard to release

753
00:29:56,720 --> 00:30:00,480
the next generation of foundation

754
00:29:58,320 --> 00:30:02,080
models. Unfortunately I cannot go to too

755
00:30:00,480 --> 00:30:04,559
many details until you know the products

756
00:30:02,080 --> 00:30:06,399
is is launched etc. But the real thing

757
00:30:04,559 --> 00:30:07,840
we're working on and I'm thrilled that I

758
00:30:06,399 --> 00:30:12,000
would love to have discussions and and

759
00:30:07,840 --> 00:30:14,960
and see other ideas is how do you you

760
00:30:12,000 --> 00:30:18,799
know integrate these modalities uh

761
00:30:14,960 --> 00:30:20,880
images genomics patient records proteins

762
00:30:18,799 --> 00:30:22,640
uh given that we have a lot you know a

763
00:30:20,880 --> 00:30:24,880
beautiful system in biology which is

764
00:30:22,640 --> 00:30:27,200
this multiscale approach we know that

765
00:30:24,880 --> 00:30:29,039
what you see in in full body is a

766
00:30:27,200 --> 00:30:31,840
consequence of molecular interactions

767
00:30:29,039 --> 00:30:34,399
but the the path from one of to them is

768
00:30:31,840 --> 00:30:37,039
is is well understood. suit conceptually

769
00:30:34,399 --> 00:30:38,960
but it's it's it's a bit hard to uh to

770
00:30:37,039 --> 00:30:40,559
model. So you know one idea for example

771
00:30:38,960 --> 00:30:42,480
is that because each foundation model

772
00:30:40,559 --> 00:30:45,200
you can see it as transforming building

773
00:30:42,480 --> 00:30:48,880
blocks into one object like a foundation

774
00:30:45,200 --> 00:30:51,120
model for proteins is how amino acids

775
00:30:48,880 --> 00:30:53,200
together from a protein. Then if you

776
00:30:51,120 --> 00:30:55,880
look at single cell foundation models it

777
00:30:53,200 --> 00:30:58,320
tells you how a set of genes and gene

778
00:30:55,880 --> 00:31:00,559
expression defines the phenotype of a

779
00:30:58,320 --> 00:31:02,080
cell. When I mentioned the tissues, it's

780
00:31:00,559 --> 00:31:03,919
a way to say, well, if you know what

781
00:31:02,080 --> 00:31:05,360
each cell is, then when you put them

782
00:31:03,919 --> 00:31:07,760
together, you have a representation of

783
00:31:05,360 --> 00:31:09,440
the tissue. So, computationally,

784
00:31:07,760 --> 00:31:12,240
mathematically, it seems to make sense

785
00:31:09,440 --> 00:31:14,080
to have some hierarchical structure in

786
00:31:12,240 --> 00:31:16,880
some in some neural network. So, this

787
00:31:14,080 --> 00:31:19,200
brings questions in AI about what is the

788
00:31:16,880 --> 00:31:21,039
good architecture of the model, but also

789
00:31:19,200 --> 00:31:23,120
what is a good objective function, what

790
00:31:21,039 --> 00:31:25,679
is a good tokenizer to transform the raw

791
00:31:23,120 --> 00:31:27,200
data into building blocks, etc. So lots

792
00:31:25,679 --> 00:31:28,799
of cool ideas and you know I'm talking

793
00:31:27,200 --> 00:31:30,880
especially I understand there are many

794
00:31:28,799 --> 00:31:32,640
pos dogs here. Uh I think there is

795
00:31:30,880 --> 00:31:35,279
enough research for all of you if you

796
00:31:32,640 --> 00:31:38,240
want to go in that field. Um thank you.

797
00:31:35,279 --> 00:31:40,320
I stop here. Uh and and I will thank you

798
00:31:38,240 --> 00:31:42,130
know the teams at AI and Bopus who did

799
00:31:40,320 --> 00:31:47,000
most of this work. Thank

800
00:31:42,130 --> 00:31:49,519
[Applause]

801
00:31:47,000 --> 00:31:53,559
you. We have we have time for one

802
00:31:49,519 --> 00:31:53,559
question. I'll go here.

803
00:31:55,919 --> 00:32:00,440
Thank you for the great presentation,

804
00:31:58,159 --> 00:32:02,640
John Fleipp. Um, you

805
00:32:00,440 --> 00:32:04,440
mentioned there's new models coming out

806
00:32:02,640 --> 00:32:07,519
every week

807
00:32:04,440 --> 00:32:10,000
and perhaps the consensus on what the

808
00:32:07,519 --> 00:32:12,440
best model for a given workflow might

809
00:32:10,000 --> 00:32:15,679
also change at a similar

810
00:32:12,440 --> 00:32:17,919
frequency. How do you ensure researchers

811
00:32:15,679 --> 00:32:22,440
are constantly equipped with the best

812
00:32:17,919 --> 00:32:25,760
model? Um, and what are the biggest

813
00:32:22,440 --> 00:32:28,320
bottlenecks to quicker and widespread

814
00:32:25,760 --> 00:32:30,320
adoption of these models? Um, making

815
00:32:28,320 --> 00:32:32,880
sure that they get in the hands of the

816
00:32:30,320 --> 00:32:37,840
researchers researchers that can apply

817
00:32:32,880 --> 00:32:40,159
them for their um for their workflows.

818
00:32:37,840 --> 00:32:42,080
Yeah, great question. So, you know, what

819
00:32:40,159 --> 00:32:45,039
I described is I think just the fact

820
00:32:42,080 --> 00:32:45,799
that this is a fastmoving field.

821
00:32:45,039 --> 00:32:48,080
uh

822
00:32:45,799 --> 00:32:49,440
so you know they are the people who

823
00:32:48,080 --> 00:32:51,200
develop these models and they are the

824
00:32:49,440 --> 00:32:53,519
people who use them. So when you ask the

825
00:32:51,200 --> 00:32:55,600
question how can can a user be sure to

826
00:32:53,519 --> 00:32:56,960
use the best model. I have no answer. I

827
00:32:55,600 --> 00:32:59,600
think you should just take the the ones

828
00:32:56,960 --> 00:33:01,840
that that are available that exist today

829
00:32:59,600 --> 00:33:03,440
knowing that I don't know if it's a good

830
00:33:01,840 --> 00:33:05,120
or bad news but probably in six months

831
00:33:03,440 --> 00:33:07,600
there will be a better one. So but you

832
00:33:05,120 --> 00:33:09,360
know in research you you just cannot say

833
00:33:07,600 --> 00:33:10,720
well I will wait six months to see

834
00:33:09,360 --> 00:33:13,279
what's the best in six months because

835
00:33:10,720 --> 00:33:16,159
it's just moving too fast. So you know

836
00:33:13,279 --> 00:33:19,640
the maybe a good answer is I think these

837
00:33:16,159 --> 00:33:22,559
benchmarks these challenges are really

838
00:33:19,640 --> 00:33:24,240
helpful. Uh and you know I've been I've

839
00:33:22,559 --> 00:33:25,840
been doing research for and science for

840
00:33:24,240 --> 00:33:27,519
quite a few years as well. What's

841
00:33:25,840 --> 00:33:29,360
complicated is when you just look at

842
00:33:27,519 --> 00:33:31,840
publications individual each of them

843
00:33:29,360 --> 00:33:33,679
saying well look my model is the best.

844
00:33:31,840 --> 00:33:35,440
Uh we've seen this was the case for

845
00:33:33,679 --> 00:33:38,159
alpha fold you know with the competition

846
00:33:35,440 --> 00:33:40,080
CASP. uh even though everyone can claim

847
00:33:38,159 --> 00:33:42,399
them all as the best the day you have a

848
00:33:40,080 --> 00:33:44,080
competition like CAS that says look

849
00:33:42,399 --> 00:33:45,840
there are many ideas but one of them is

850
00:33:44,080 --> 00:33:48,320
just so much better than the other ones

851
00:33:45,840 --> 00:33:49,679
the year after everyone is using it is

852
00:33:48,320 --> 00:33:52,000
it good or not you know we also need to

853
00:33:49,679 --> 00:33:54,960
have exploration but at least maybe the

854
00:33:52,000 --> 00:33:57,760
the simple answer to the the the first

855
00:33:54,960 --> 00:34:00,799
aspect of the question is uh trust the

856
00:33:57,760 --> 00:34:04,720
benchmarks trust the challenges etc uh

857
00:34:00,799 --> 00:34:08,839
so that um so that for today you know

858
00:34:04,720 --> 00:34:11,280
what what state of the art at least.

859
00:34:08,839 --> 00:34:13,040
Um I'm not sure I fully understood the

860
00:34:11,280 --> 00:34:15,839
second part of the question actually. I

861
00:34:13,040 --> 00:34:18,240
don't know if we if you want to

862
00:34:15,839 --> 00:34:20,720
the second part what what are the

863
00:34:18,240 --> 00:34:22,919
biggest bottlenecks to make sure that

864
00:34:20,720 --> 00:34:27,040
researchers are able to adopt these

865
00:34:22,919 --> 00:34:30,079
models. Um so say you have a specific

866
00:34:27,040 --> 00:34:32,159
model that is meant for specific use

867
00:34:30,079 --> 00:34:34,480
case. Not every single researcher that

868
00:34:32,159 --> 00:34:37,839
could be using that model is using it.

869
00:34:34,480 --> 00:34:41,919
How do you how do you tackle that? Yeah,

870
00:34:37,839 --> 00:34:44,720
I'm not sure. So bottom uh so maybe my

871
00:34:41,919 --> 00:34:47,599
one part of the answer is that a real

872
00:34:44,720 --> 00:34:49,919
foundation model at least what we what

873
00:34:47,599 --> 00:34:52,000
what what the field is trying to do uh

874
00:34:49,919 --> 00:34:55,359
is meant to be a general purpose tool

875
00:34:52,000 --> 00:34:57,839
meaning as soon as it's specific or good

876
00:34:55,359 --> 00:34:59,280
for one task and we have many model

877
00:34:57,839 --> 00:35:00,800
maybe alpha fold by the way you know I

878
00:34:59,280 --> 00:35:04,240
mentioned it as a foundation model maybe

879
00:35:00,800 --> 00:35:06,480
it's not the first version but the more

880
00:35:04,240 --> 00:35:08,320
alpha fold and and similar models are

881
00:35:06,480 --> 00:35:11,200
have been created we realize that we can

882
00:35:08,320 --> 00:35:13,200
do good straighter prediction by having

883
00:35:11,200 --> 00:35:16,560
a good foundation model of of protein

884
00:35:13,200 --> 00:35:21,119
sequences. Okay. So I said alpha may not

885
00:35:16,560 --> 00:35:22,960
be a foundation model. Uh but the later

886
00:35:21,119 --> 00:35:24,640
generations are built on foundation

887
00:35:22,960 --> 00:35:26,800
models that can predict structure that

888
00:35:24,640 --> 00:35:29,200
can predict function that can predict it

889
00:35:26,800 --> 00:35:32,640
etc. So u I'm not sure it's a good

890
00:35:29,200 --> 00:35:35,599
answer but at least I would say that uh

891
00:35:32,640 --> 00:35:37,359
in terms of foundation models the ones I

892
00:35:35,599 --> 00:35:39,520
would trust or the the ones I would

893
00:35:37,359 --> 00:35:42,240
investigate or try to build as a

894
00:35:39,520 --> 00:35:45,119
community are quite gen general purpose

895
00:35:42,240 --> 00:35:48,079
like um you know I can maybe mention the

896
00:35:45,119 --> 00:35:51,520
the AI virtual cell initiative which is

897
00:35:48,079 --> 00:35:55,040
really to say can we have a foundation

898
00:35:51,520 --> 00:35:57,280
model so AI system that is just here to

899
00:35:55,040 --> 00:36:01,040
simulate cells and we don't know for

900
00:35:57,280 --> 00:36:02,880
what what uh what purpose? But really we

901
00:36:01,040 --> 00:36:04,720
uh we just want it to be useful if you

902
00:36:02,880 --> 00:36:07,440
want to predict response to perturbation

903
00:36:04,720 --> 00:36:09,520
or if you want to uh to do cell cell

904
00:36:07,440 --> 00:36:11,520
type classification or to do other

905
00:36:09,520 --> 00:36:14,680
things.

906
00:36:11,520 --> 00:36:14,680
Thank you.

907
00:36:14,880 --> 00:36:20,440
Cool. Yeah. Let's thank the speaker one

908
00:36:16,720 --> 00:36:20,440
more time. Thank you.


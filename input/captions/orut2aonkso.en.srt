1
00:00:06,319 --> 00:00:10,960
And it's uh my great pleasure to open

2
00:00:08,480 --> 00:00:15,200
this Eric and Wendy Schmidt symposium on

3
00:00:10,960 --> 00:00:18,720
AI and and bio computing. Um, AI is not

4
00:00:15,200 --> 00:00:20,560
my field, but I'm perceptive enough to

5
00:00:18,720 --> 00:00:23,600
see that this is a pretty remarkable

6
00:00:20,560 --> 00:00:26,240
moment um for the field. And it it comes

7
00:00:23,600 --> 00:00:29,279
that remarkable moment, I think, comes

8
00:00:26,240 --> 00:00:31,640
at an interesting time in in history in

9
00:00:29,279 --> 00:00:35,280
in biomedical research because we're

10
00:00:31,640 --> 00:00:39,360
about three or four weeks away from the

11
00:00:35,280 --> 00:00:41,600
25th anniversary of the uh first draft

12
00:00:39,360 --> 00:00:43,760
sequence of the human genome project.

13
00:00:41,600 --> 00:00:46,800
And I remember feeling at that time that

14
00:00:43,760 --> 00:00:48,039
that also felt like a a special moment.

15
00:00:46,800 --> 00:00:50,800
It was hard to

16
00:00:48,039 --> 00:00:52,640
really get your head around exactly why

17
00:00:50,800 --> 00:00:55,120
it was special, but you could tell

18
00:00:52,640 --> 00:00:58,000
something remarkable was going to change

19
00:00:55,120 --> 00:01:00,640
in the world of biology and in the world

20
00:00:58,000 --> 00:01:02,960
of medicine. I think it's fair to say

21
00:01:00,640 --> 00:01:05,159
that in retrospect perhaps the

22
00:01:02,960 --> 00:01:07,920
short-term immediate benefits

23
00:01:05,159 --> 00:01:11,600
of having a human human genome sequence

24
00:01:07,920 --> 00:01:13,520
in hand were a bit overstated. But at

25
00:01:11,600 --> 00:01:16,400
the same time, I think the long-term

26
00:01:13,520 --> 00:01:19,320
benefits of having an anchoring for

27
00:01:16,400 --> 00:01:21,960
biology and medicine with with the human

28
00:01:19,320 --> 00:01:25,119
genome were also substantially

29
00:01:21,960 --> 00:01:27,040
understated. And you know if you take

30
00:01:25,119 --> 00:01:29,280
graduate students today and ask can you

31
00:01:27,040 --> 00:01:32,040
imagine you know doing biomedical

32
00:01:29,280 --> 00:01:33,960
research without that foundation of the

33
00:01:32,040 --> 00:01:37,200
genome they

34
00:01:33,960 --> 00:01:40,159
would it'd be hard to understand um how

35
00:01:37,200 --> 00:01:41,920
you could really do research um without

36
00:01:40,159 --> 00:01:43,759
without that as a as a foundation. I

37
00:01:41,920 --> 00:01:46,399
feel like there's that level of

38
00:01:43,759 --> 00:01:48,240
potential to really disrupt and

39
00:01:46,399 --> 00:01:51,880
transform how we think about biomedical

40
00:01:48,240 --> 00:01:55,600
research in the setting of a

41
00:01:51,880 --> 00:01:59,439
matured field of uh machine learning and

42
00:01:55,600 --> 00:02:02,960
and and AI. And so that's why to me this

43
00:01:59,439 --> 00:02:05,280
feels like a really remarkable pivotal

44
00:02:02,960 --> 00:02:08,800
moment where it's not clear yet I don't

45
00:02:05,280 --> 00:02:10,959
think what that new world of biology and

46
00:02:08,800 --> 00:02:12,080
medicine is going to look like. But I

47
00:02:10,959 --> 00:02:13,840
think we can all agree that it's going

48
00:02:12,080 --> 00:02:16,360
to look very different than it than it

49
00:02:13,840 --> 00:02:19,680
than it does today. And so what a

50
00:02:16,360 --> 00:02:22,000
remarkable moment to be in science when

51
00:02:19,680 --> 00:02:24,160
over the next decade you all are going

52
00:02:22,000 --> 00:02:26,959
to figure that out and then it will be

53
00:02:24,160 --> 00:02:29,040
clear. It'll still evolve but the most

54
00:02:26,959 --> 00:02:31,760
transformative change is going to happen

55
00:02:29,040 --> 00:02:35,360
over the over the decade ahead. And I I

56
00:02:31,760 --> 00:02:37,840
I mentioned this also um cognizant of

57
00:02:35,360 --> 00:02:40,319
the worrisome

58
00:02:37,840 --> 00:02:42,800
uh potential impact of decisions that

59
00:02:40,319 --> 00:02:46,200
the US federal government is making with

60
00:02:42,800 --> 00:02:49,319
respect to uh funding for biomedical

61
00:02:46,200 --> 00:02:51,680
research. But even despite that

62
00:02:49,319 --> 00:02:54,080
headwind, I still can't imagine a better

63
00:02:51,680 --> 00:02:56,720
time to be in science. That's going to

64
00:02:54,080 --> 00:02:59,040
be annoying. will slow us down a little

65
00:02:56,720 --> 00:03:02,319
bit but I don't think fundamentally

66
00:02:59,040 --> 00:03:04,560
because the drive particularly in AI and

67
00:03:02,319 --> 00:03:08,159
biio medicine is going to be too strong.

68
00:03:04,560 --> 00:03:10,640
It's going to move at an amazing pace

69
00:03:08,159 --> 00:03:14,000
you know faster I believe than advances

70
00:03:10,640 --> 00:03:17,440
in in in the genome um took place. And

71
00:03:14,000 --> 00:03:20,080
so what better time to be uh a student,

72
00:03:17,440 --> 00:03:22,640
a faculty member, a staff scientist in

73
00:03:20,080 --> 00:03:27,200
academia or in industry uh working out

74
00:03:22,640 --> 00:03:30,400
the decade ahead. So um with that um

75
00:03:27,200 --> 00:03:33,360
brief comment um I'm happy to to open

76
00:03:30,400 --> 00:03:37,200
the symposium and introduce the

77
00:03:33,360 --> 00:03:39,680
organizer of the uh sympony uh symposium

78
00:03:37,200 --> 00:03:41,680
Caroline Ooler who is also the director

79
00:03:39,680 --> 00:03:44,480
of the Eric and Wendy Schmidt Center at

80
00:03:41,680 --> 00:03:46,959
the Broad Institute and a professor uh

81
00:03:44,480 --> 00:03:50,000
at MIT and electrical engineering and

82
00:03:46,959 --> 00:03:52,159
and computer science. and we're just

83
00:03:50,000 --> 00:03:55,120
really lucky to have Caroline's vision

84
00:03:52,159 --> 00:03:56,560
and leadership um at the Schmidt Center.

85
00:03:55,120 --> 00:03:58,080
Um I unfortunately I'm going to have to

86
00:03:56,560 --> 00:04:00,480
step out but look forward to popping

87
00:03:58,080 --> 00:04:02,239
back in um uh during the day. So hope

88
00:04:00,480 --> 00:04:03,760
you have a a wonderful symposium.

89
00:04:02,239 --> 00:04:09,320
Caroline,

90
00:04:03,760 --> 00:04:09,320
[Applause]

91
00:04:09,680 --> 00:04:14,560
thank you very much Todd for opening up

92
00:04:11,760 --> 00:04:16,880
this uh symposium and welcome everyone.

93
00:04:14,560 --> 00:04:19,199
So excited to see so many of you already

94
00:04:16,880 --> 00:04:21,199
here. Um there has already been such a

95
00:04:19,199 --> 00:04:23,199
great energy in the room and outside and

96
00:04:21,199 --> 00:04:26,240
I'm just uh really looking forward to

97
00:04:23,199 --> 00:04:30,000
two exciting days of um stimulating

98
00:04:26,240 --> 00:04:31,759
research and discussions. Um so before

99
00:04:30,000 --> 00:04:33,600
getting started with the program, I

100
00:04:31,759 --> 00:04:35,919
thought I would like to say just a few

101
00:04:33,600 --> 00:04:39,280
words um about the Eric and Wendy

102
00:04:35,919 --> 00:04:44,000
Schmidt Center. So um it was launched in

103
00:04:39,280 --> 00:04:46,880
uh July 2021 um thanks to the amazing um

104
00:04:44,000 --> 00:04:49,360
generosity and vision of Eric and Wendy

105
00:04:46,880 --> 00:04:51,840
Schmidt and also thanks to the great

106
00:04:49,360 --> 00:04:54,240
support um of you know the current broad

107
00:04:51,840 --> 00:04:57,440
leadership and former broad leadership

108
00:04:54,240 --> 00:05:00,000
Todd Golop and and Eric Lander. Um it

109
00:04:57,440 --> 00:05:02,080
really took this huge team um to put

110
00:05:00,000 --> 00:05:05,120
this together and to get this started.

111
00:05:02,080 --> 00:05:07,280
Um, and I'm just very excited uh to be

112
00:05:05,120 --> 00:05:10,240
able to continue building it and bring

113
00:05:07,280 --> 00:05:12,440
together this community um that we have

114
00:05:10,240 --> 00:05:15,840
here together.

115
00:05:12,440 --> 00:05:17,680
Um, so in terms of I just wanted to say

116
00:05:15,840 --> 00:05:20,400
a few words about also what its vision

117
00:05:17,680 --> 00:05:23,120
is. Um so the Eric and Wendy Schmidt

118
00:05:20,400 --> 00:05:24,880
Center is um its vision is and and its

119
00:05:23,120 --> 00:05:27,199
goal is really to create a global

120
00:05:24,880 --> 00:05:29,440
community of researchers uh that make

121
00:05:27,199 --> 00:05:31,919
biology a key driver of foundational

122
00:05:29,440 --> 00:05:33,919
developments in machine learning to then

123
00:05:31,919 --> 00:05:36,479
create the theoretical and computational

124
00:05:33,919 --> 00:05:38,479
and algorithmic paradigms that enable us

125
00:05:36,479 --> 00:05:41,039
to understand the programs of life and

126
00:05:38,479 --> 00:05:43,360
how they are connected really across all

127
00:05:41,039 --> 00:05:46,400
scales. So from proteins to cells to

128
00:05:43,360 --> 00:05:48,160
tissues and organisms. And we really

129
00:05:46,400 --> 00:05:51,199
strongly believe that the biomedical

130
00:05:48,160 --> 00:05:53,360
sciences are you know not only uniquely

131
00:05:51,199 --> 00:05:55,600
suited to being a beneficiary of

132
00:05:53,360 --> 00:05:57,120
research in machine learning but also

133
00:05:55,600 --> 00:05:59,440
one of the greatest sources of

134
00:05:57,120 --> 00:06:01,759
inspiration for new foundational

135
00:05:59,440 --> 00:06:03,440
developments in machine learning. So we

136
00:06:01,759 --> 00:06:06,160
really want to build this two-way

137
00:06:03,440 --> 00:06:08,000
street. Um, so not just a one-way street

138
00:06:06,160 --> 00:06:10,160
of getting um bringing in machine

139
00:06:08,000 --> 00:06:12,240
learning that has been already developed

140
00:06:10,160 --> 00:06:15,199
into the bi into biology, but really

141
00:06:12,240 --> 00:06:17,199
also going the other way around um of

142
00:06:15,199 --> 00:06:19,680
changing what machine learning is today

143
00:06:17,199 --> 00:06:22,160
um through biology. And so in order to

144
00:06:19,680 --> 00:06:25,280
do this um to really build this two-way

145
00:06:22,160 --> 00:06:29,840
street um we're here um have in

146
00:06:25,280 --> 00:06:32,160
particular uh built a you know a a a a

147
00:06:29,840 --> 00:06:33,680
program for post-doal fellows where

148
00:06:32,160 --> 00:06:35,919
we're attracting machine learning

149
00:06:33,680 --> 00:06:38,560
researchers to the broad that may

150
00:06:35,919 --> 00:06:40,880
actually not have any prior biological

151
00:06:38,560 --> 00:06:43,680
background but have a strong interest in

152
00:06:40,880 --> 00:06:45,600
biology and then we're connecting them

153
00:06:43,680 --> 00:06:48,000
uh to really important biomedical

154
00:06:45,600 --> 00:06:50,160
problems um which then of course have to

155
00:06:48,000 --> 00:06:51,919
first be translated into the language of

156
00:06:50,160 --> 00:06:54,160
machine learning to make them amendable

157
00:06:51,919 --> 00:06:55,680
to computational thinking. And of

158
00:06:54,160 --> 00:06:58,240
course, these problems will not be able

159
00:06:55,680 --> 00:07:00,800
to be solved um just by one person or

160
00:06:58,240 --> 00:07:02,720
one group, but actually we require a

161
00:07:00,800 --> 00:07:05,440
really strong collaborative effort

162
00:07:02,720 --> 00:07:07,840
across disciplines to then be able to

163
00:07:05,440 --> 00:07:10,160
solve these problems. And so we're very

164
00:07:07,840 --> 00:07:11,840
excited about our post-doal program and

165
00:07:10,160 --> 00:07:13,680
all of the fellows that are here. You

166
00:07:11,840 --> 00:07:15,440
will hopefully meet many of them today.

167
00:07:13,680 --> 00:07:17,360
They're really the basis of of the

168
00:07:15,440 --> 00:07:19,520
Schmidt Center and making the scientific

169
00:07:17,360 --> 00:07:21,919
effort possible. They're bringing into

170
00:07:19,520 --> 00:07:24,319
the broad a very deep um machine

171
00:07:21,919 --> 00:07:28,000
learning background and expertise

172
00:07:24,319 --> 00:07:31,039
together with their mentors um at MIT,

173
00:07:28,000 --> 00:07:33,039
uh Harvard and and others outside and

174
00:07:31,039 --> 00:07:35,759
then they're connected to really deep

175
00:07:33,039 --> 00:07:37,840
expertise in biology um at the broad and

176
00:07:35,759 --> 00:07:39,840
this is really the bread and butter. Um

177
00:07:37,840 --> 00:07:42,000
so hopefully you'll be able to uh you

178
00:07:39,840 --> 00:07:44,000
know talk to a lot of our fellows and if

179
00:07:42,000 --> 00:07:46,720
you're a PhD student we have a call for

180
00:07:44,000 --> 00:07:49,000
post-doal fellowships um every year in

181
00:07:46,720 --> 00:07:52,479
December. So please um consider that as

182
00:07:49,000 --> 00:07:54,639
well. Um now we do want to bring in you

183
00:07:52,479 --> 00:07:57,599
know go much beyond uh the Boston

184
00:07:54,639 --> 00:08:00,080
environment um and bring in the global

185
00:07:57,599 --> 00:08:03,199
machine learning community to biomedical

186
00:08:00,080 --> 00:08:05,280
problems. Um and so we've uh decided to

187
00:08:03,199 --> 00:08:07,759
do this through the vehicle um of

188
00:08:05,280 --> 00:08:10,720
challenges or competitions

189
00:08:07,759 --> 00:08:12,319
um where we try to first identify a

190
00:08:10,720 --> 00:08:14,160
biological problem that is or a

191
00:08:12,319 --> 00:08:16,800
biomedical problem that is really

192
00:08:14,160 --> 00:08:18,360
critical to be solved but can also spur

193
00:08:16,800 --> 00:08:21,360
foundational research in machine

194
00:08:18,360 --> 00:08:24,080
learning. And so in these uh machine

195
00:08:21,360 --> 00:08:26,400
learning challenges, it's I think some

196
00:08:24,080 --> 00:08:28,479
of the first of their kind where it's

197
00:08:26,400 --> 00:08:30,479
not just about a prediction problem

198
00:08:28,479 --> 00:08:32,800
where you know we hold out some data and

199
00:08:30,479 --> 00:08:35,440
then you'll predict and uh we'll we'll

200
00:08:32,800 --> 00:08:37,519
rank all algorithms based on this but we

201
00:08:35,440 --> 00:08:39,039
want the participants to actually have

202
00:08:37,519 --> 00:08:41,680
an influence on what are the next

203
00:08:39,039 --> 00:08:43,599
experiments that we're performing. Um

204
00:08:41,680 --> 00:08:45,680
and so here you know the best teams on

205
00:08:43,599 --> 00:08:47,360
the prediction part are actually their

206
00:08:45,680 --> 00:08:48,959
experiments. So they're also going to

207
00:08:47,360 --> 00:08:50,880
tell us which experiments we would like

208
00:08:48,959 --> 00:08:52,959
to see and those experiments are

209
00:08:50,880 --> 00:08:55,200
actually going to be run. So machine

210
00:08:52,959 --> 00:08:57,279
learning researchers across the the the

211
00:08:55,200 --> 00:08:59,279
globe can have an influence on you know

212
00:08:57,279 --> 00:09:02,080
which are the next experiments to be

213
00:08:59,279 --> 00:09:04,640
run. Um and we're currently ending our

214
00:09:02,080 --> 00:09:08,160
second um challenge which was on you

215
00:09:04,640 --> 00:09:10,720
know connecting um uh images so

216
00:09:08,160 --> 00:09:13,680
pathological or pathohistological images

217
00:09:10,720 --> 00:09:15,200
to spatial transcrytoics. Um and you

218
00:09:13,680 --> 00:09:16,720
know in both of these challenges we're

219
00:09:15,200 --> 00:09:18,480
very excited. we had over a thousand

220
00:09:16,720 --> 00:09:20,800
participants. So hopefully if you didn't

221
00:09:18,480 --> 00:09:22,959
participate um the next challenge, we're

222
00:09:20,800 --> 00:09:25,760
we're preparing it. Um so we will be

223
00:09:22,959 --> 00:09:28,240
launching it um later this year. It will

224
00:09:25,760 --> 00:09:30,640
be um a somewhat of a continuation of

225
00:09:28,240 --> 00:09:33,760
the first challenge on predicting um

226
00:09:30,640 --> 00:09:36,320
unseen perturbations. Um and so stay

227
00:09:33,760 --> 00:09:38,560
tuned. Um and I really hope you will all

228
00:09:36,320 --> 00:09:40,800
be uh participating also in the next

229
00:09:38,560 --> 00:09:42,560
challenge. um so that we can all you

230
00:09:40,800 --> 00:09:44,800
know somehow push forward this field

231
00:09:42,560 --> 00:09:46,360
which requires just so many new ideas in

232
00:09:44,800 --> 00:09:49,839
order to really make

233
00:09:46,360 --> 00:09:52,160
progress. So with this um welcome to

234
00:09:49,839 --> 00:09:54,959
everyone. I'm uh super excited to get

235
00:09:52,160 --> 00:09:58,000
this started and look forward to two

236
00:09:54,959 --> 00:10:02,040
really uh great days of amazing science

237
00:09:58,000 --> 00:10:02,040
and stimulating discussions.


1
00:00:11,840 --> 00:00:15,759
Uh so today we're going to be continuing

2
00:00:13,599 --> 00:00:17,680
our probability unit. So I just want to

3
00:00:15,759 --> 00:00:19,680
remind you where we were. So you know

4
00:00:17,680 --> 00:00:22,160
when I was last lecturing I introduced

5
00:00:19,680 --> 00:00:24,960
the basics of probability. I told you

6
00:00:22,160 --> 00:00:27,439
what a sample space was and then it led

7
00:00:24,960 --> 00:00:28,720
to things like events where we talked

8
00:00:27,439 --> 00:00:30,000
about what was the probability of

9
00:00:28,720 --> 00:00:31,599
different events. We talked about

10
00:00:30,000 --> 00:00:33,440
independence.

11
00:00:31,599 --> 00:00:35,680
We talked about random variables that

12
00:00:33,440 --> 00:00:38,480
are functions from our sample space to

13
00:00:35,680 --> 00:00:40,399
real values. And once we had random

14
00:00:38,480 --> 00:00:42,079
variables, that allowed us to do a lot

15
00:00:40,399 --> 00:00:44,800
of exciting things like we could talk

16
00:00:42,079 --> 00:00:47,360
about the expectation and the variance

17
00:00:44,800 --> 00:00:48,800
of the random variables. It allowed us

18
00:00:47,360 --> 00:00:50,719
to do things like talk about

19
00:00:48,800 --> 00:00:52,320
conditioning like when we condition on

20
00:00:50,719 --> 00:00:54,079
some event in the sample space

21
00:00:52,320 --> 00:00:56,480
occurring. You know, how does that

22
00:00:54,079 --> 00:00:58,480
change the probability of other events?

23
00:00:56,480 --> 00:01:00,879
How does that change the expectation of

24
00:00:58,480 --> 00:01:02,640
random variables? And then we talked

25
00:01:00,879 --> 00:01:05,519
about this powerful tool of you know

26
00:01:02,640 --> 00:01:07,439
inclusion exclusion. And then after that

27
00:01:05,519 --> 00:01:09,119
Peter gave you a bunch of lectures on

28
00:01:07,439 --> 00:01:11,280
counting methods on generating

29
00:01:09,119 --> 00:01:13,200
functions. And the truth is for the

30
00:01:11,280 --> 00:01:14,560
introductory lectures in this class

31
00:01:13,200 --> 00:01:17,040
there are a lot of tight connections

32
00:01:14,560 --> 00:01:18,880
between probability and counting. So we

33
00:01:17,040 --> 00:01:21,280
really need both perspectives and we're

34
00:01:18,880 --> 00:01:23,280
going to go back and forth between them.

35
00:01:21,280 --> 00:01:24,799
But today we're going to cover uh one of

36
00:01:23,280 --> 00:01:26,640
the other important topics in

37
00:01:24,799 --> 00:01:29,040
probability. something that we're going

38
00:01:26,640 --> 00:01:32,000
to spend a bunch of time on which are

39
00:01:29,040 --> 00:01:36,000
called tailbounds. So the idea for a

40
00:01:32,000 --> 00:01:38,079
tailbound is to get a handle on how much

41
00:01:36,000 --> 00:01:41,040
how likely it is for random variables to

42
00:01:38,079 --> 00:01:42,960
be far away from their expectation. So

43
00:01:41,040 --> 00:01:45,520
remember that we take a random variable

44
00:01:42,960 --> 00:01:47,680
and we look at its expectation and that

45
00:01:45,520 --> 00:01:50,399
tells us you know on average what we

46
00:01:47,680 --> 00:01:52,159
expect the random variable to be. But of

47
00:01:50,399 --> 00:01:54,159
course, some random variables might have

48
00:01:52,159 --> 00:01:57,040
large averages just because they have

49
00:01:54,159 --> 00:02:00,000
some very tiny probability of having a

50
00:01:57,040 --> 00:02:02,719
gigantic value. So then we talked about

51
00:02:00,000 --> 00:02:04,640
notions like variation and variance that

52
00:02:02,719 --> 00:02:06,320
told us, you know, how well a random

53
00:02:04,640 --> 00:02:08,479
variable concentrates around its

54
00:02:06,320 --> 00:02:10,000
expectation. So today we're going to

55
00:02:08,479 --> 00:02:12,400
make that precise. We're actually going

56
00:02:10,000 --> 00:02:14,720
to get bounds on what's the probability

57
00:02:12,400 --> 00:02:17,760
that a random variable is very far away

58
00:02:14,720 --> 00:02:21,120
from its expectation. So let me tell you

59
00:02:17,760 --> 00:02:23,920
you know one simple tailbound in action

60
00:02:21,120 --> 00:02:26,640
and really the theme of today and uh

61
00:02:23,920 --> 00:02:29,280
Thursday's lecture will be we're going

62
00:02:26,640 --> 00:02:31,599
to use more and more information about

63
00:02:29,280 --> 00:02:34,160
random variables to get tighter and

64
00:02:31,599 --> 00:02:37,360
tighter control. So let's start off with

65
00:02:34,160 --> 00:02:39,599
a very basic example of you know what

66
00:02:37,360 --> 00:02:42,160
theorem needs very little information

67
00:02:39,599 --> 00:02:44,400
about my random variable but gives me a

68
00:02:42,160 --> 00:02:46,319
rudimentary baseline of you know what's

69
00:02:44,400 --> 00:02:48,400
the probability it's far away from its

70
00:02:46,319 --> 00:02:51,360
expectation.

71
00:02:48,400 --> 00:02:53,200
So this is a very simple to state and

72
00:02:51,360 --> 00:02:55,200
prove bound. It's called Marov's

73
00:02:53,200 --> 00:02:57,519
inequality.

74
00:02:55,200 --> 00:02:59,920
And here we're going to assume that X is

75
00:02:57,519 --> 00:03:01,440
not just a random variable but it's a

76
00:02:59,920 --> 00:03:04,400
non-gative

77
00:03:01,440 --> 00:03:04,400
random variable.

78
00:03:05,440 --> 00:03:12,159
Then what I claim

79
00:03:08,480 --> 00:03:16,080
is that the probability that X is larger

80
00:03:12,159 --> 00:03:21,040
than some constant C is bounded by the

81
00:03:16,080 --> 00:03:23,920
expectation of X all divided by C.

82
00:03:21,040 --> 00:03:25,440
So this makes intuitive sense because um

83
00:03:23,920 --> 00:03:28,319
you know if I have this non-gative

84
00:03:25,440 --> 00:03:30,720
random variable as C gets larger and

85
00:03:28,319 --> 00:03:33,200
larger I'm going way out into the tails

86
00:03:30,720 --> 00:03:34,959
of my random variable the probability

87
00:03:33,200 --> 00:03:37,120
that the random variable is actually

88
00:03:34,959 --> 00:03:40,319
that large should be getting smaller and

89
00:03:37,120 --> 00:03:42,640
smaller. Right now the important thing

90
00:03:40,319 --> 00:03:44,959
is that you know the expectation shows

91
00:03:42,640 --> 00:03:47,760
up on the right hand side because that

92
00:03:44,959 --> 00:03:50,640
gives us some baseline of like how large

93
00:03:47,760 --> 00:03:53,040
we expect X to be on average. So the

94
00:03:50,640 --> 00:03:56,000
larger its expectation is, the weaker my

95
00:03:53,040 --> 00:03:59,760
bound on this tail probability is. But

96
00:03:56,000 --> 00:04:02,080
as C increases, I also get some win. So

97
00:03:59,760 --> 00:04:04,080
we're going to prove this bound and then

98
00:04:02,080 --> 00:04:06,319
we'll state another correlary, an

99
00:04:04,080 --> 00:04:07,760
equivalent way to rephrase Marov's

100
00:04:06,319 --> 00:04:09,840
bound. And you can go back and forth

101
00:04:07,760 --> 00:04:12,560
between them depending on what's more

102
00:04:09,840 --> 00:04:15,519
convenient. But one thing I want to

103
00:04:12,560 --> 00:04:17,840
emphasize is that, you know, here I'm

104
00:04:15,519 --> 00:04:21,120
crucially going to need the fact that X

105
00:04:17,840 --> 00:04:23,120
is non- negative. So, just as a spoiler,

106
00:04:21,120 --> 00:04:25,600
I'm going to ask you where in this proof

107
00:04:23,120 --> 00:04:27,040
I'm really appealing to non- negativity.

108
00:04:25,600 --> 00:04:29,360
And after I give you the proof, I'm

109
00:04:27,040 --> 00:04:32,560
going to expect you guys to to tell me

110
00:04:29,360 --> 00:04:34,720
where this fact was used. So, let's

111
00:04:32,560 --> 00:04:36,720
prove this.

112
00:04:34,720 --> 00:04:38,880
And the proof for this is really just

113
00:04:36,720 --> 00:04:40,639
breaking up the expectation into

114
00:04:38,880 --> 00:04:44,160
different pieces.

115
00:04:40,639 --> 00:04:47,360
So, let's start off with our random

116
00:04:44,160 --> 00:04:50,800
variable X. We know its expectation E of

117
00:04:47,360 --> 00:04:54,840
X. And I'm gonna break this up using

118
00:04:50,800 --> 00:04:54,840
conditional expectation.

119
00:04:58,880 --> 00:05:03,840
So I'm going to break it up into two

120
00:05:00,400 --> 00:05:05,680
terms. I look at the conditional

121
00:05:03,840 --> 00:05:09,520
expectation

122
00:05:05,680 --> 00:05:13,600
that of X given that X is at least some

123
00:05:09,520 --> 00:05:16,560
value C times the probability that X is

124
00:05:13,600 --> 00:05:19,520
at least C. And then I'm going to add

125
00:05:16,560 --> 00:05:22,160
the other contribution which is the

126
00:05:19,520 --> 00:05:24,479
conditional expectation of X if that

127
00:05:22,160 --> 00:05:27,919
event does not happen if X is strictly

128
00:05:24,479 --> 00:05:30,880
less than C times the probability that X

129
00:05:27,919 --> 00:05:33,759
is less than C. So this should look

130
00:05:30,880 --> 00:05:35,840
familiar. This is basically a random

131
00:05:33,759 --> 00:05:38,240
variable version of something we covered

132
00:05:35,840 --> 00:05:40,880
way back when which is we talked about

133
00:05:38,240 --> 00:05:42,880
the law of total probability. We had

134
00:05:40,880 --> 00:05:45,759
things like the probability of some

135
00:05:42,880 --> 00:05:48,000
event B and we talked about it as the

136
00:05:45,759 --> 00:05:50,240
probability that B happens conditioned

137
00:05:48,000 --> 00:05:53,039
on event A happening times the

138
00:05:50,240 --> 00:05:54,720
probability that event A happens plus

139
00:05:53,039 --> 00:05:57,680
the probability that B happens

140
00:05:54,720 --> 00:06:00,400
conditioned on A not happening times the

141
00:05:57,680 --> 00:06:02,240
probability A does not happen. So when

142
00:06:00,400 --> 00:06:03,919
we talked about conditional probability,

143
00:06:02,240 --> 00:06:06,560
this was, you know, one of our first

144
00:06:03,919 --> 00:06:08,880
applications once we had Baze rule was

145
00:06:06,560 --> 00:06:11,360
we used it to reason using the law of

146
00:06:08,880 --> 00:06:13,840
total probability. And this is just the

147
00:06:11,360 --> 00:06:15,919
same thing, but expectations of random

148
00:06:13,840 --> 00:06:17,680
variables. Sometimes you'll hear this

149
00:06:15,919 --> 00:06:20,080
referred to as the law of total

150
00:06:17,680 --> 00:06:22,400
expectation, but it's just breaking up

151
00:06:20,080 --> 00:06:24,800
my space into two different things.

152
00:06:22,400 --> 00:06:27,120
Either this event A happens, that X is

153
00:06:24,800 --> 00:06:28,639
at least C, or it does not happen. And

154
00:06:27,120 --> 00:06:30,960
then I average the conditional

155
00:06:28,639 --> 00:06:32,639
expectation in those two different uh

156
00:06:30,960 --> 00:06:36,080
possibilities.

157
00:06:32,639 --> 00:06:38,160
Right? And so now what I claim is that

158
00:06:36,080 --> 00:06:41,199
uh you know I can look at you know each

159
00:06:38,160 --> 00:06:45,039
of these pieces. I claim that you know

160
00:06:41,199 --> 00:06:46,560
the first piece right here is at least C

161
00:06:45,039 --> 00:06:49,680
and then I'm going to pick up this

162
00:06:46,560 --> 00:06:51,759
probability of X at least C. And then I

163
00:06:49,680 --> 00:06:54,080
claim that this second piece right here

164
00:06:51,759 --> 00:06:56,880
is non- negative.

165
00:06:54,080 --> 00:06:59,520
So uh that I'm just going to drop and

166
00:06:56,880 --> 00:07:02,639
I'll get a lower bound. Right? So I've

167
00:06:59,520 --> 00:07:05,120
really just used uh the fact that you

168
00:07:02,639 --> 00:07:07,919
know the expectation of X given that X

169
00:07:05,120 --> 00:07:10,319
is at least C had better be a value at

170
00:07:07,919 --> 00:07:12,560
least C because X always takes on a

171
00:07:10,319 --> 00:07:13,919
value that's at least C. And then I'm

172
00:07:12,560 --> 00:07:16,319
still going to pick up the probability

173
00:07:13,919 --> 00:07:18,080
that that event happens. And for this

174
00:07:16,319 --> 00:07:21,360
term I'm just going to drop it because

175
00:07:18,080 --> 00:07:23,280
this term is non- negative. Right? And

176
00:07:21,360 --> 00:07:28,360
so now what I can do is I can just

177
00:07:23,280 --> 00:07:28,360
rearrange to finish the proof.

178
00:07:32,960 --> 00:07:37,759
That's it. So that's our first

179
00:07:35,280 --> 00:07:39,520
tailbound. Our tail bounds will get a

180
00:07:37,759 --> 00:07:41,599
bit more sophisticated from this. But

181
00:07:39,520 --> 00:07:44,240
this already gives us some rudimentary

182
00:07:41,599 --> 00:07:46,960
understanding of the probability that X

183
00:07:44,240 --> 00:07:48,479
is very very large. So now let me ask

184
00:07:46,960 --> 00:07:50,800
you the question that I promised I was

185
00:07:48,479 --> 00:07:53,120
going to ask you. Where in this proof

186
00:07:50,800 --> 00:07:55,840
did I use the fact that X is non-

187
00:07:53,120 --> 00:07:56,560
negative?

188
00:07:55,840 --> 00:07:59,360
>> Yeah.

189
00:07:56,560 --> 00:08:02,319
>> Uh when you were counting expectation X

190
00:07:59,360 --> 00:08:03,120
given X less than C. So we know it's

191
00:08:02,319 --> 00:08:05,440
negative.

192
00:08:03,120 --> 00:08:07,759
>> That's right. That's exactly right.

193
00:08:05,440 --> 00:08:10,400
Because if X were not a you know

194
00:08:07,759 --> 00:08:12,800
non-gative random variable, I couldn't

195
00:08:10,400 --> 00:08:14,560
say that this term is non- negative.

196
00:08:12,800 --> 00:08:16,319
Right. This term is definitely non-

197
00:08:14,560 --> 00:08:18,479
negative. But otherwise, if X took on

198
00:08:16,319 --> 00:08:20,560
negative values, this could be negative.

199
00:08:18,479 --> 00:08:23,840
and dropping it I wouldn't get an

200
00:08:20,560 --> 00:08:26,000
inequality like this. Perfect. Okay, so

201
00:08:23,840 --> 00:08:28,000
we definitely have to use this and

202
00:08:26,000 --> 00:08:30,319
that's crucial for you know marov's

203
00:08:28,000 --> 00:08:32,159
bound at least the intuition behind it.

204
00:08:30,319 --> 00:08:35,519
I mean this is the algebraic proof but

205
00:08:32,159 --> 00:08:37,440
the intuition is just that x if x had a

206
00:08:35,519 --> 00:08:40,320
very large probability of being at least

207
00:08:37,440 --> 00:08:42,320
c then its expectation could not be what

208
00:08:40,320 --> 00:08:45,279
I promised it was because the

209
00:08:42,320 --> 00:08:47,519
expectation would actually be too large.

210
00:08:45,279 --> 00:08:51,360
Okay, any questions?

211
00:08:47,519 --> 00:08:53,839
Make sense? All right.

212
00:08:51,360 --> 00:08:57,120
Okay. So, let me restate this in another

213
00:08:53,839 --> 00:08:59,440
form. Uh I'll state it as a corollary.

214
00:08:57,120 --> 00:09:01,680
This is just a restatement

215
00:08:59,440 --> 00:09:04,160
of you know marov's bound. But sometimes

216
00:09:01,680 --> 00:09:07,120
you'll find it convenient to you invoke

217
00:09:04,160 --> 00:09:11,040
it in one form versus the other. So I

218
00:09:07,120 --> 00:09:14,360
claim under the same conditions if X is

219
00:09:11,040 --> 00:09:14,360
non- negative

220
00:09:14,640 --> 00:09:18,880
then

221
00:09:17,040 --> 00:09:22,000
the probability

222
00:09:18,880 --> 00:09:23,920
that X is at least C times its

223
00:09:22,000 --> 00:09:25,920
expectation

224
00:09:23,920 --> 00:09:30,000
of X

225
00:09:25,920 --> 00:09:31,680
is at most 1 over C.

226
00:09:30,000 --> 00:09:34,240
Okay. So let me make sure we're all on

227
00:09:31,680 --> 00:09:37,240
the same page. So why is this a

228
00:09:34,240 --> 00:09:37,240
corollary?

229
00:09:38,480 --> 00:09:43,279
How do I get from here the thing I

230
00:09:40,560 --> 00:09:44,959
proved to here?

231
00:09:43,279 --> 00:09:46,399
In fact, let me make it a bit easier.

232
00:09:44,959 --> 00:09:50,360
Let me just call this a different

233
00:09:46,399 --> 00:09:50,360
constant C prime.

234
00:09:51,360 --> 00:09:54,000
Why is this a correlary? They seem

235
00:09:52,959 --> 00:09:58,880
related. Yeah,

236
00:09:54,000 --> 00:10:00,399
>> just substitute C prime C *

237
00:09:58,880 --> 00:10:01,839
C over anything else.

238
00:10:00,399 --> 00:10:05,279
>> Yeah. So let me do it the other way. let

239
00:10:01,839 --> 00:10:08,560
me substitute for C is equal to C prime

240
00:10:05,279 --> 00:10:11,519
* E ex right then I get exactly this

241
00:10:08,560 --> 00:10:13,519
bound right here and then on the right

242
00:10:11,519 --> 00:10:16,079
hand side I cancel out the E of X and I

243
00:10:13,519 --> 00:10:18,160
get 1 over C prime so this is very

244
00:10:16,079 --> 00:10:20,320
intuitive because if I have a non-gative

245
00:10:18,160 --> 00:10:22,800
random variable the probability that

246
00:10:20,320 --> 00:10:25,600
it's twice as large as its expectation

247
00:10:22,800 --> 00:10:27,600
is at most a half because otherwise if

248
00:10:25,600 --> 00:10:32,240
that probability larger than a half the

249
00:10:27,600 --> 00:10:35,120
expectation would be wrong. Okay.

250
00:10:32,240 --> 00:10:38,640
So, any questions about this?

251
00:10:35,120 --> 00:10:41,519
All right. So, um just to illustrate my

252
00:10:38,640 --> 00:10:43,360
point that, you know, in tail bounds,

253
00:10:41,519 --> 00:10:45,360
we're going to be, you know, asking for

254
00:10:43,360 --> 00:10:47,600
tighter and tighter bounds that use more

255
00:10:45,360 --> 00:10:49,839
and more information about our random

256
00:10:47,600 --> 00:10:52,880
variable. Let me do a running example,

257
00:10:49,839 --> 00:10:56,160
which we'll use as a way to check how

258
00:10:52,880 --> 00:10:58,399
much progress we're making. Okay. So

259
00:10:56,160 --> 00:11:00,800
let's do the following running example

260
00:10:58,399 --> 00:11:02,399
and we'll come back to it with our next

261
00:11:00,800 --> 00:11:06,320
tailbound.

262
00:11:02,399 --> 00:11:11,480
So in the US

263
00:11:06,320 --> 00:11:11,480
uh the average male height

264
00:11:13,120 --> 00:11:18,480
is about

265
00:11:15,120 --> 00:11:22,000
69 in. Okay.

266
00:11:18,480 --> 00:11:24,399
So we can use this fact, right, to

267
00:11:22,000 --> 00:11:27,200
reason about the probability that

268
00:11:24,399 --> 00:11:29,839
someone is super duper tall, right?

269
00:11:27,200 --> 00:11:31,839
Because X being the height of a random,

270
00:11:29,839 --> 00:11:35,680
you know, male in the US is a random

271
00:11:31,839 --> 00:11:39,200
variable. So we know its expectation and

272
00:11:35,680 --> 00:11:42,320
we can use Marov's bound and just see

273
00:11:39,200 --> 00:11:44,399
what Marov's bound tells us. It tells us

274
00:11:42,320 --> 00:11:46,240
the probability that X, which remember

275
00:11:44,399 --> 00:11:52,079
is our random variable. This would be

276
00:11:46,240 --> 00:11:54,880
the height of a randomly chosen

277
00:11:52,079 --> 00:11:57,120
US male.

278
00:11:54,880 --> 00:12:00,240
The probability that it's at least two

279
00:11:57,120 --> 00:12:07,920
times its expectation,

280
00:12:00,240 --> 00:12:10,800
which is equal to 138 in or 11t6 in.

281
00:12:07,920 --> 00:12:13,760
That probability is at most a half. So,

282
00:12:10,800 --> 00:12:15,519
we've proven this amazing fact, right?

283
00:12:13,760 --> 00:12:17,680
You're walking down the street in

284
00:12:15,519 --> 00:12:21,200
Boston. The probability you see someone

285
00:12:17,680 --> 00:12:24,880
who's above 11'6 is at most a half.

286
00:12:21,200 --> 00:12:27,200
Okay, so pretty good or maybe not. So

287
00:12:24,880 --> 00:12:29,440
see the problem is that Markov's bound

288
00:12:27,200 --> 00:12:31,600
you can actually check really is tight,

289
00:12:29,440 --> 00:12:33,040
right? It's just that real random

290
00:12:31,600 --> 00:12:34,720
variables, you know, a lot of times

291
00:12:33,040 --> 00:12:36,720
there's more information we know about

292
00:12:34,720 --> 00:12:39,120
it. Things like the variation of the

293
00:12:36,720 --> 00:12:41,360
random variable. The more information

294
00:12:39,120 --> 00:12:44,160
you tell me about the random variable,

295
00:12:41,360 --> 00:12:46,399
the tighter my tailbound will be. And

296
00:12:44,160 --> 00:12:50,240
this markov is just the get me over

297
00:12:46,399 --> 00:12:53,519
first warm-up for a tailbound.

298
00:12:50,240 --> 00:12:55,519
So we'll come back to this example. Um I

299
00:12:53,519 --> 00:12:58,240
want to, you know, make sure we still

300
00:12:55,519 --> 00:13:01,200
have the right intuition for this proof.

301
00:12:58,240 --> 00:13:03,279
So let me ask you,

302
00:13:01,200 --> 00:13:05,600
uh, you know, a diagnostic question just

303
00:13:03,279 --> 00:13:07,200
to make sure we're on the same page. I

304
00:13:05,600 --> 00:13:09,040
think probably you can guess the answer

305
00:13:07,200 --> 00:13:12,720
to this but what I really care about is

306
00:13:09,040 --> 00:13:14,240
to find an example. So does Marov's

307
00:13:12,720 --> 00:13:16,399
bound

308
00:13:14,240 --> 00:13:20,760
hold

309
00:13:16,399 --> 00:13:20,760
without non- negativity.

310
00:13:23,600 --> 00:13:28,959
Okay. So in the statement of the theorem

311
00:13:26,959 --> 00:13:31,200
I definitely assumed that the random

312
00:13:28,959 --> 00:13:33,680
variable was non- negative. In the proof

313
00:13:31,200 --> 00:13:36,800
I gave you, I definitely use the fact

314
00:13:33,680 --> 00:13:39,519
that X was non- negative. We talked

315
00:13:36,800 --> 00:13:41,279
about where we used that. But could I

316
00:13:39,519 --> 00:13:43,839
hope for some bound that looks like

317
00:13:41,279 --> 00:13:46,079
this? Even when X is not non- negative,

318
00:13:43,839 --> 00:13:48,800
maybe there's some other proof out there

319
00:13:46,079 --> 00:13:51,200
that doesn't use non- negativity that

320
00:13:48,800 --> 00:13:54,720
still bounds the probability that X is

321
00:13:51,200 --> 00:13:57,199
twice its expectation by a half or

322
00:13:54,720 --> 00:13:59,519
something like this. So I claim that

323
00:13:57,199 --> 00:14:02,079
this is spectacularly false, but this is

324
00:13:59,519 --> 00:14:04,240
good intuition. So how would I come up

325
00:14:02,079 --> 00:14:07,279
with some random variable that you know

326
00:14:04,240 --> 00:14:09,279
is has negative values and completely

327
00:14:07,279 --> 00:14:11,279
breaks any kind of statement like this

328
00:14:09,279 --> 00:14:14,079
that the expectation gives you a handle

329
00:14:11,279 --> 00:14:16,800
on the tails?

330
00:14:14,079 --> 00:14:20,160
Anyone have any intuition?

331
00:14:16,800 --> 00:14:22,560
>> Yeah, maybe you could come up with a

332
00:14:20,160 --> 00:14:24,880
random variable which has zero.

333
00:14:22,560 --> 00:14:27,040
>> Perfect. I love it.

334
00:14:24,880 --> 00:14:30,160
So this is definitely not true. It's

335
00:14:27,040 --> 00:14:33,360
spectacularly false. So let's just

336
00:14:30,160 --> 00:14:35,360
consider some X where the right hand

337
00:14:33,360 --> 00:14:39,360
side doesn't make any sense because the

338
00:14:35,360 --> 00:14:41,839
expectation is zero. So what if X is one

339
00:14:39,360 --> 00:14:46,160
with probability

340
00:14:41,839 --> 00:14:49,600
1/2 and it's minus one otherwise. The

341
00:14:46,160 --> 00:14:52,800
trouble is that the expectation of X is

342
00:14:49,600 --> 00:14:55,920
equal to zero. But the probability that

343
00:14:52,800 --> 00:14:57,519
say X is at least three times its

344
00:14:55,920 --> 00:15:00,560
expectation

345
00:14:57,519 --> 00:15:03,600
which is still zero is definitely not

346
00:15:00,560 --> 00:15:05,920
less than a third. Okay.

347
00:15:03,600 --> 00:15:08,959
So non-activity really is essential and

348
00:15:05,920 --> 00:15:10,959
sometimes these examples are very useful

349
00:15:08,959 --> 00:15:13,120
for both building intuition and

350
00:15:10,959 --> 00:15:14,639
conveying a proof to your reader. So

351
00:15:13,120 --> 00:15:17,120
these kinds of things when you start

352
00:15:14,639 --> 00:15:18,800
thinking about your term paper even if I

353
00:15:17,120 --> 00:15:20,639
didn't literally need to show this to

354
00:15:18,800 --> 00:15:23,839
you this is the good kind of thing to

355
00:15:20,639 --> 00:15:25,839
keep in mind as a pedagogical device.

356
00:15:23,839 --> 00:15:30,720
All right

357
00:15:25,839 --> 00:15:33,680
so let's uh prove our next tailbound. Uh

358
00:15:30,720 --> 00:15:36,320
this one will be fairly simple as well

359
00:15:33,680 --> 00:15:38,560
but it's much more powerful and we're

360
00:15:36,320 --> 00:15:41,760
going to get some awesome applications

361
00:15:38,560 --> 00:15:43,600
of it. And this is called Chbashev's

362
00:15:41,760 --> 00:15:45,120
bound.

363
00:15:43,600 --> 00:15:48,000
Actually I'm not even sure about the

364
00:15:45,120 --> 00:15:51,519
history because I think Chbashev's bound

365
00:15:48,000 --> 00:15:52,800
was proofed uh before marov's bound even

366
00:15:51,519 --> 00:15:55,040
though it's going to use the proof of

367
00:15:52,800 --> 00:15:57,519
marov's bound. So I don't know maybe

368
00:15:55,040 --> 00:15:59,759
Marov just looked at his proof and and

369
00:15:57,519 --> 00:16:03,199
uh you know called the thing inside it

370
00:15:59,759 --> 00:16:05,279
his own bound. So in any case now uh

371
00:16:03,199 --> 00:16:07,120
we're going to start off with any random

372
00:16:05,279 --> 00:16:09,360
variable X. So this is already very

373
00:16:07,120 --> 00:16:11,600
different than Markoff's bound because

374
00:16:09,360 --> 00:16:14,560
I'm not going to assume non- negativity.

375
00:16:11,600 --> 00:16:18,320
I don't even need it for this proof. So

376
00:16:14,560 --> 00:16:20,880
for any random variable X, what I claim

377
00:16:18,320 --> 00:16:23,360
is that the probability that the

378
00:16:20,880 --> 00:16:28,880
absolute value of X minus the

379
00:16:23,360 --> 00:16:31,040
expectation of X is larger than C. So it

380
00:16:28,880 --> 00:16:33,440
deviates not by a multiplicative factor

381
00:16:31,040 --> 00:16:37,759
of C but by some additive factor of C

382
00:16:33,440 --> 00:16:40,560
from its expectation is bounded by the

383
00:16:37,759 --> 00:16:44,880
variance of X

384
00:16:40,560 --> 00:16:47,600
all over C ^2. So this will be my you

385
00:16:44,880 --> 00:16:49,759
know standard form of chebishev's bound

386
00:16:47,600 --> 00:16:51,600
and the same way for marov's bound I

387
00:16:49,759 --> 00:16:54,160
stated it you know in one form and then

388
00:16:51,600 --> 00:16:56,959
I stated a corollary I'll do the same

389
00:16:54,160 --> 00:16:58,720
after we prove this bound but this is

390
00:16:56,959 --> 00:17:01,759
you know what I promised because now

391
00:16:58,720 --> 00:17:04,559
we're going to use extra information see

392
00:17:01,759 --> 00:17:06,640
marov's bound did not have the variance

393
00:17:04,559 --> 00:17:08,480
showing up so you have to actually be

394
00:17:06,640 --> 00:17:11,120
able to compute the variance in order to

395
00:17:08,480 --> 00:17:12,959
appeal to the chebbes bound but as we'll

396
00:17:11,120 --> 00:17:15,039
see it's going to give us much tighter

397
00:17:12,959 --> 00:17:16,959
bounds and some really cool qualitative

398
00:17:15,039 --> 00:17:19,760
corlaries.

399
00:17:16,959 --> 00:17:22,319
So let's prove uh Chbashev's bound and

400
00:17:19,760 --> 00:17:25,520
then I'll state the other corollary. The

401
00:17:22,319 --> 00:17:27,280
proof will also be short and sweet but

402
00:17:25,520 --> 00:17:30,160
it's going to have a really cool trick

403
00:17:27,280 --> 00:17:32,320
to it which is you know a hint about the

404
00:17:30,160 --> 00:17:35,520
tricks to come later when we do much

405
00:17:32,320 --> 00:17:40,120
fancier tail bounds.

406
00:17:35,520 --> 00:17:40,120
So the first thing I'm going to do,

407
00:17:41,120 --> 00:17:44,600
I can rewrite

408
00:17:46,480 --> 00:17:51,760
the quantity I care about. The

409
00:17:48,799 --> 00:17:55,440
probability that the absolute value of X

410
00:17:51,760 --> 00:17:59,600
minus E of X

411
00:17:55,440 --> 00:18:01,280
is at least C I claim is equal to the

412
00:17:59,600 --> 00:18:04,320
probability

413
00:18:01,280 --> 00:18:06,960
that X minus

414
00:18:04,320 --> 00:18:10,480
E of X

415
00:18:06,960 --> 00:18:13,200
quantity squared is at least C^ squ.

416
00:18:10,480 --> 00:18:15,200
Okay, so this is trick number one for

417
00:18:13,200 --> 00:18:17,120
Chev's bound.

418
00:18:15,200 --> 00:18:19,600
It's not a hard trick to explain, but

419
00:18:17,120 --> 00:18:22,080
this is a trick. You know, why are these

420
00:18:19,600 --> 00:18:23,360
two probabilities equal? Why am I

421
00:18:22,080 --> 00:18:27,000
allowed to say that these two

422
00:18:23,360 --> 00:18:27,000
probabilities are equal?

423
00:18:28,320 --> 00:18:32,640
It's because they're the same event,

424
00:18:30,640 --> 00:18:35,440
right? So, at the end of the day, what's

425
00:18:32,640 --> 00:18:37,120
happening in here is I have an event.

426
00:18:35,440 --> 00:18:39,600
You know, once you fix the random

427
00:18:37,120 --> 00:18:42,480
variable, I know its expectation and you

428
00:18:39,600 --> 00:18:46,400
fix C. I have this event whether or not

429
00:18:42,480 --> 00:18:48,080
X is far from its expectation. And I

430
00:18:46,400 --> 00:18:49,600
claim that these two probabilities,

431
00:18:48,080 --> 00:18:51,760
what's going on in here are two

432
00:18:49,600 --> 00:18:54,400
different events, but these events

433
00:18:51,760 --> 00:18:56,880
coincide. The only way that one event

434
00:18:54,400 --> 00:18:58,720
triggers is if the other one does too,

435
00:18:56,880 --> 00:19:02,640
just because, you know, we're taking the

436
00:18:58,720 --> 00:19:04,799
absolute value. Make sense?

437
00:19:02,640 --> 00:19:06,320
Okay, so that's trick number one for

438
00:19:04,799 --> 00:19:09,039
Chbashev.

439
00:19:06,320 --> 00:19:11,280
And now here's the really cool trick. Uh

440
00:19:09,039 --> 00:19:16,080
what we're going to do is we're going to

441
00:19:11,280 --> 00:19:17,360
define a new random variable.

442
00:19:16,080 --> 00:19:20,320
So I'm going to call this random

443
00:19:17,360 --> 00:19:22,559
variable y and it's going to be equal to

444
00:19:20,320 --> 00:19:25,360
just the thing that shows up in here on

445
00:19:22,559 --> 00:19:29,840
the right hand side. X minus the

446
00:19:25,360 --> 00:19:31,520
expectation of x quantity squared. See I

447
00:19:29,840 --> 00:19:34,400
told you in chebesev we're going to

448
00:19:31,520 --> 00:19:36,320
appeal to marov's bound you know in

449
00:19:34,400 --> 00:19:38,320
order to prove it. But if you remember

450
00:19:36,320 --> 00:19:40,400
for Marov's bound, we needed that the

451
00:19:38,320 --> 00:19:43,120
random variable we are looking at is

452
00:19:40,400 --> 00:19:45,120
non- negative. For chevbishev, I'm not

453
00:19:43,120 --> 00:19:47,039
assuming that x is non- negative to

454
00:19:45,120 --> 00:19:49,679
begin with. So what I have to do is I

455
00:19:47,039 --> 00:19:52,080
have to manufacture my own non-gative

456
00:19:49,679 --> 00:19:54,480
random variable. And that's this new

457
00:19:52,080 --> 00:19:56,559
random variable y that I just

458
00:19:54,480 --> 00:19:58,320
constructed right here. This is

459
00:19:56,559 --> 00:20:01,200
definitely non- negative because I'm

460
00:19:58,320 --> 00:20:04,480
taking the square of a value. And now I

461
00:20:01,200 --> 00:20:07,760
can appeal to Markov's bound.

462
00:20:04,480 --> 00:20:13,039
So using markoff

463
00:20:07,760 --> 00:20:17,960
on y we know that um you know this

464
00:20:13,039 --> 00:20:17,960
quantity right here which I'll call star

465
00:20:18,160 --> 00:20:25,600
is equal to the probability that y is at

466
00:20:22,080 --> 00:20:27,520
least c^2 that's literally just using

467
00:20:25,600 --> 00:20:30,640
the definition of what my random

468
00:20:27,520 --> 00:20:33,120
variable y was and now appealing to

469
00:20:30,640 --> 00:20:34,720
marov's bound which is allowed because y

470
00:20:33,120 --> 00:20:37,679
is non- negative

471
00:20:34,720 --> 00:20:42,400
This is at most the expectation

472
00:20:37,679 --> 00:20:45,280
of y all over c^2.

473
00:20:42,400 --> 00:20:47,120
Notice that my threshold here is c^Â² not

474
00:20:45,280 --> 00:20:50,080
c as in the original statement of

475
00:20:47,120 --> 00:20:54,480
marov's bound. And now what I can do is

476
00:20:50,080 --> 00:20:58,799
I can just remember what y is right. So

477
00:20:54,480 --> 00:21:03,679
y is just the expectation the y itself

478
00:20:58,799 --> 00:21:07,840
is x minus the expectation of x quantity

479
00:21:03,679 --> 00:21:10,559
squared. I still have my c ^2 and when I

480
00:21:07,840 --> 00:21:12,400
take the expectation of y this is

481
00:21:10,559 --> 00:21:16,320
literally the definition I gave you

482
00:21:12,400 --> 00:21:20,400
earlier for the variance of x. So that's

483
00:21:16,320 --> 00:21:23,039
my proof right?

484
00:21:20,400 --> 00:21:25,039
Any questions?

485
00:21:23,039 --> 00:21:27,520
Good.

486
00:21:25,039 --> 00:21:30,880
All right. So, as before, I'm going to

487
00:21:27,520 --> 00:21:33,120
state another equivalent way uh to think

488
00:21:30,880 --> 00:21:36,159
about chbashev which is sometimes a bit

489
00:21:33,120 --> 00:21:38,640
more convenient.

490
00:21:36,159 --> 00:21:42,159
So, feel free to use whichever is you

491
00:21:38,640 --> 00:21:44,880
know easier in a proof. So again for any

492
00:21:42,159 --> 00:21:46,799
random variable X

493
00:21:44,880 --> 00:21:48,400
the probability

494
00:21:46,799 --> 00:21:51,280
that

495
00:21:48,400 --> 00:21:53,200
the absolute value of X minus its

496
00:21:51,280 --> 00:21:56,159
expectation

497
00:21:53,200 --> 00:22:00,320
is larger than C * sigma of X. I'll

498
00:21:56,159 --> 00:22:04,559
define what sigma of X is at most 1 over

499
00:22:00,320 --> 00:22:08,760
C ^2 and sigma of X

500
00:22:04,559 --> 00:22:08,760
is called the standard deviation.

501
00:22:10,080 --> 00:22:16,799
and it's just defined to be the square

502
00:22:12,400 --> 00:22:18,880
root of the variance of x. Okay, so the

503
00:22:16,799 --> 00:22:21,039
same way I had the simple version of

504
00:22:18,880 --> 00:22:22,880
marov that allowed me to remember it,

505
00:22:21,039 --> 00:22:25,360
the probability that a non-gative random

506
00:22:22,880 --> 00:22:27,760
variable is twice its expectation is at

507
00:22:25,360 --> 00:22:31,280
most a half. The probability that a

508
00:22:27,760 --> 00:22:34,080
random variable is, you know, two times

509
00:22:31,280 --> 00:22:36,320
away from its expectation in terms of

510
00:22:34,080 --> 00:22:38,320
its standard deviation is at most a

511
00:22:36,320 --> 00:22:41,320
quarter.

512
00:22:38,320 --> 00:22:41,320
Okay.

513
00:22:41,440 --> 00:22:46,159
All right. So, let's go back to our

514
00:22:43,520 --> 00:22:48,799
running example and let's see, you know,

515
00:22:46,159 --> 00:22:51,799
why chbachev is a lot more useful for

516
00:22:48,799 --> 00:22:51,799
us.

517
00:23:01,840 --> 00:23:06,159
So, in particular, I need to tell you

518
00:23:03,760 --> 00:23:07,360
more information about this random

519
00:23:06,159 --> 00:23:10,559
variable.

520
00:23:07,360 --> 00:23:13,760
about the height of a random male, US

521
00:23:10,559 --> 00:23:17,240
male. And what I claim is that the

522
00:23:13,760 --> 00:23:17,240
standard deviation

523
00:23:17,919 --> 00:23:22,760
uh you know of male height

524
00:23:24,240 --> 00:23:31,600
is 2.7 in. So now we're in good shape

525
00:23:29,039 --> 00:23:35,799
because instead of using marov, we can

526
00:23:31,600 --> 00:23:35,799
instead use chbachev.

527
00:23:38,159 --> 00:23:44,000
We have the probability that x, where x

528
00:23:41,200 --> 00:23:47,200
is our same random variable as before.

529
00:23:44,000 --> 00:23:50,799
The probability that you're two standard

530
00:23:47,200 --> 00:23:57,440
deviations above average, which is the

531
00:23:50,799 --> 00:23:59,280
same thing as uh 6 foot 2.4 4 is at most

532
00:23:57,440 --> 00:24:01,440
a quarter.

533
00:23:59,280 --> 00:24:03,679
So this is still not a great bound, but

534
00:24:01,440 --> 00:24:08,080
it's at least not a nonsensical bound

535
00:24:03,679 --> 00:24:09,919
like our 11t 6 in version before. And so

536
00:24:08,080 --> 00:24:12,240
you can, you know, do the same types of

537
00:24:09,919 --> 00:24:15,039
exercise. Um, you know, when you tell me

538
00:24:12,240 --> 00:24:16,799
not just the variance of X, but you

539
00:24:15,039 --> 00:24:19,760
know, more information about the moments

540
00:24:16,799 --> 00:24:21,039
of X, you would get tighter and tighter

541
00:24:19,760 --> 00:24:24,080
bounds until you would actually get

542
00:24:21,039 --> 00:24:26,720
something pretty reasonable.

543
00:24:24,080 --> 00:24:30,080
Okay.

544
00:24:26,720 --> 00:24:32,159
All right. Um,

545
00:24:30,080 --> 00:24:34,880
so now I want to tell you now that we

546
00:24:32,159 --> 00:24:36,559
have chbashev, it may not be obvious,

547
00:24:34,880 --> 00:24:38,559
but it turns out to be very

548
00:24:36,559 --> 00:24:40,400
qualitatively powerful, not just

549
00:24:38,559 --> 00:24:43,360
numerically in these examples like

550
00:24:40,400 --> 00:24:46,480
height. So let me tell you about one

551
00:24:43,360 --> 00:24:47,840
really cool corollary. Uh, I'll state it

552
00:24:46,480 --> 00:24:51,440
as a theorem and then we'll talk about

553
00:24:47,840 --> 00:24:54,320
some applications to gambling.

554
00:24:51,440 --> 00:24:57,520
Um so chebbesev

555
00:24:54,320 --> 00:25:01,840
allows you to prove you know one of the

556
00:24:57,520 --> 00:25:03,840
most important results in tail bounds

557
00:25:01,840 --> 00:25:06,240
uh which is called the weak law of large

558
00:25:03,840 --> 00:25:08,000
numbers. Now the weak law of large

559
00:25:06,240 --> 00:25:09,600
numbers we're going to strengthen it at

560
00:25:08,000 --> 00:25:12,320
various times and get better

561
00:25:09,600 --> 00:25:15,120
quantitative bounds but already we can

562
00:25:12,320 --> 00:25:18,400
see some of the power of you know tail

563
00:25:15,120 --> 00:25:21,360
bounds. So let me state what this weak

564
00:25:18,400 --> 00:25:23,200
law of large numbers is.

565
00:25:21,360 --> 00:25:25,279
And then we're going to prove it just

566
00:25:23,200 --> 00:25:29,000
using the tailbound technology we've

567
00:25:25,279 --> 00:25:29,000
developed so far.

568
00:25:33,679 --> 00:25:37,919
Now for the weak law of large numbers

569
00:25:35,600 --> 00:25:40,080
there's um you know you have to be very

570
00:25:37,919 --> 00:25:41,679
careful with the quantifiers. So let me

571
00:25:40,080 --> 00:25:44,880
write it down and then we'll talk about

572
00:25:41,679 --> 00:25:47,600
it. So first I'm going to fix some

573
00:25:44,880 --> 00:25:50,000
positive epsilon. That'll be some

574
00:25:47,600 --> 00:25:54,840
measure of how close I want a random

575
00:25:50,000 --> 00:25:54,840
variable to be to its expectation.

576
00:25:57,039 --> 00:26:03,360
And I'm going to let you know x1

577
00:26:00,799 --> 00:26:07,400
all the way up to xn

578
00:26:03,360 --> 00:26:07,400
be independent

579
00:26:07,679 --> 00:26:10,679
copies

580
00:26:11,840 --> 00:26:20,640
of some fixed random variable x.

581
00:26:17,360 --> 00:26:24,640
And moreover, let's assume that the

582
00:26:20,640 --> 00:26:27,679
expectation of X is equal to some value

583
00:26:24,640 --> 00:26:29,440
C. And I'm also going to assume, and

584
00:26:27,679 --> 00:26:33,919
this is critical for the weak law of

585
00:26:29,440 --> 00:26:37,039
large numbers, that its variance is not

586
00:26:33,919 --> 00:26:38,799
infinity. Okay, so just some basic

587
00:26:37,039 --> 00:26:41,600
bounds that my random variable is

588
00:26:38,799 --> 00:26:44,400
somewhat well behaved.

589
00:26:41,600 --> 00:26:47,360
Well, what I'm going to do is I'm going

590
00:26:44,400 --> 00:26:49,279
to look at averages of these random

591
00:26:47,360 --> 00:26:53,200
variables as a way to try and

592
00:26:49,279 --> 00:26:55,120
approximate this expectation C. So, I'm

593
00:26:53,200 --> 00:27:00,159
going to define a new random variable

594
00:26:55,120 --> 00:27:04,799
SN. That's just going to be the average.

595
00:27:00,159 --> 00:27:08,960
It'll be 1 over little N, sum from I= 1

596
00:27:04,799 --> 00:27:10,320
to N of X I.

597
00:27:08,960 --> 00:27:12,000
So, you know, just to make sure that

598
00:27:10,320 --> 00:27:14,640
we're on the same page, let's keep some

599
00:27:12,000 --> 00:27:16,480
mental model of this in mind, right? So,

600
00:27:14,640 --> 00:27:18,640
one of the most important applications

601
00:27:16,480 --> 00:27:20,880
of the weak law of large numbers is to

602
00:27:18,640 --> 00:27:24,000
something like polling.

603
00:27:20,880 --> 00:27:26,720
So, maybe you have some random variable,

604
00:27:24,000 --> 00:27:30,240
which is the probability that a random

605
00:27:26,720 --> 00:27:32,640
person uh selected from the electorate

606
00:27:30,240 --> 00:27:35,039
votes for one candidate, candidate A

607
00:27:32,640 --> 00:27:36,960
over candidate B.

608
00:27:35,039 --> 00:27:39,840
Now you want to know what's the

609
00:27:36,960 --> 00:27:42,320
expectation of X because you want to

610
00:27:39,840 --> 00:27:44,240
know who's going to win the election. So

611
00:27:42,320 --> 00:27:46,720
you want to do this forecasting before

612
00:27:44,240 --> 00:27:49,200
election day. The natural thing you

613
00:27:46,720 --> 00:27:52,400
could try is you can try and get

614
00:27:49,200 --> 00:27:54,480
independent samples from X just by

615
00:27:52,400 --> 00:27:56,240
calling random people and asking them

616
00:27:54,480 --> 00:27:57,679
who they're going to vote for. Now there

617
00:27:56,240 --> 00:27:59,520
are a lot of issues with that. That

618
00:27:57,679 --> 00:28:02,000
won't really give you independent random

619
00:27:59,520 --> 00:28:04,320
variables. But if we pretend for the

620
00:28:02,000 --> 00:28:06,960
moment that it did, you know, each of

621
00:28:04,320 --> 00:28:09,440
these x eyes is a realization of these

622
00:28:06,960 --> 00:28:12,080
random variables, what would my polling

623
00:28:09,440 --> 00:28:14,159
scheme do? I would just choose some

624
00:28:12,080 --> 00:28:16,399
large denominator n for the number of

625
00:28:14,159 --> 00:28:19,120
people I'm going to pull. I'm going to

626
00:28:16,399 --> 00:28:20,320
average up all of their votes, right?

627
00:28:19,120 --> 00:28:23,039
Which way they're voting. Are they

628
00:28:20,320 --> 00:28:24,640
voting for candidate A or candidate B?

629
00:28:23,039 --> 00:28:27,120
And what I'm hoping is that the

630
00:28:24,640 --> 00:28:30,960
empirical average of their votes of

631
00:28:27,120 --> 00:28:34,080
these random variables converges very

632
00:28:30,960 --> 00:28:35,679
well to my true expectation so that I

633
00:28:34,080 --> 00:28:38,159
can forecast who's going to win the

634
00:28:35,679 --> 00:28:40,080
election, right? And so that's exactly

635
00:28:38,159 --> 00:28:42,000
what the weak law of large numbers tells

636
00:28:40,080 --> 00:28:43,760
us. You just have to be careful with all

637
00:28:42,000 --> 00:28:48,159
the quantifiers.

638
00:28:43,760 --> 00:28:52,640
Then what I claim is that

639
00:28:48,159 --> 00:28:57,120
the probability that Sn

640
00:28:52,640 --> 00:28:59,679
is epsilon away from the true value C

641
00:28:57,120 --> 00:29:02,480
that this quantity as you take the limit

642
00:28:59,679 --> 00:29:05,520
as the number of people you're sampling

643
00:29:02,480 --> 00:29:08,480
in your poll goes to infinity is going

644
00:29:05,520 --> 00:29:11,200
to go to zero. So there are a ton of

645
00:29:08,480 --> 00:29:14,480
quantifiers here, right? So let's say

646
00:29:11,200 --> 00:29:15,919
that I fix epsilon at the very outset. I

647
00:29:14,480 --> 00:29:18,640
want to figure out the probability

648
00:29:15,919 --> 00:29:22,799
people are voting for candidate A within

649
00:29:18,640 --> 00:29:25,039
some additive tolerance 0.01. Right? And

650
00:29:22,799 --> 00:29:28,640
so once I've fixed my epsilon, this is

651
00:29:25,039 --> 00:29:32,000
my success criteria is that my empirical

652
00:29:28,640 --> 00:29:34,159
average of the people I pull that that

653
00:29:32,000 --> 00:29:37,360
exp that empirical average should be

654
00:29:34,159 --> 00:29:39,520
within an additive 0.01 of the truth.

655
00:29:37,360 --> 00:29:42,240
And the claim is whatever you fix for

656
00:29:39,520 --> 00:29:44,559
epsilon, there's an n that's large

657
00:29:42,240 --> 00:29:47,360
enough so that the probability that

658
00:29:44,559 --> 00:29:49,679
you're far away by more than this 0.01

659
00:29:47,360 --> 00:29:51,520
is going to go to zero.

660
00:29:49,679 --> 00:29:53,679
So the weak law of large numbers is

661
00:29:51,520 --> 00:29:55,760
deliberately non-quantitative and we

662
00:29:53,679 --> 00:29:57,760
will get quantitative versions out of it

663
00:29:55,760 --> 00:30:00,080
even just from the proof and from

664
00:29:57,760 --> 00:30:02,559
strengthenings of our tail bounds. But

665
00:30:00,080 --> 00:30:05,279
it just tells you some basic conditions

666
00:30:02,559 --> 00:30:08,080
that if you're given enough samples, you

667
00:30:05,279 --> 00:30:10,559
really can approximate the expectation

668
00:30:08,080 --> 00:30:12,640
to any desired accuracy. And in the

669
00:30:10,559 --> 00:30:15,679
proof, we'll see how large little n

670
00:30:12,640 --> 00:30:18,000
needs to be. So this is quite a mouthful

671
00:30:15,679 --> 00:30:22,279
of a statement. Are there any questions

672
00:30:18,000 --> 00:30:22,279
about the weak law of large numbers?

673
00:30:24,000 --> 00:30:28,559
Give me a thumbs up if this makes sense

674
00:30:25,679 --> 00:30:31,120
at least as a statement. Okay, good. All

675
00:30:28,559 --> 00:30:33,279
right, so the order of quantifiers is

676
00:30:31,120 --> 00:30:36,240
super important for this. Now, let's

677
00:30:33,279 --> 00:30:38,080
prove the weak law of large numbers. Uh,

678
00:30:36,240 --> 00:30:41,399
the good thing is that the proof will be

679
00:30:38,080 --> 00:30:41,399
pretty straightforward

680
00:30:43,440 --> 00:30:51,600
now that we have Chebesev's bound.

681
00:30:48,799 --> 00:30:54,720
So you know first I claim that the

682
00:30:51,600 --> 00:30:56,720
expectation of SN remember that's a

683
00:30:54,720 --> 00:30:59,919
random variable itself because each of

684
00:30:56,720 --> 00:31:01,520
the X size is a random variable and I

685
00:30:59,919 --> 00:31:04,880
could first care about is its

686
00:31:01,520 --> 00:31:07,919
expectation correct right so now I can

687
00:31:04,880 --> 00:31:11,039
use linearity of expectation

688
00:31:07,919 --> 00:31:14,240
to write it out as the sum of the

689
00:31:11,039 --> 00:31:17,440
expectations of each of the individual

690
00:31:14,240 --> 00:31:20,640
XI's that form it. Now because each of

691
00:31:17,440 --> 00:31:23,120
these XI are assumed to be you know

692
00:31:20,640 --> 00:31:26,799
independent copies of this fixed random

693
00:31:23,120 --> 00:31:29,200
variable X whose expectation is C. I

694
00:31:26,799 --> 00:31:31,760
know that each of their expectations is

695
00:31:29,200 --> 00:31:33,760
C. So that means when I average their

696
00:31:31,760 --> 00:31:36,880
expectations I get the same thing back

697
00:31:33,760 --> 00:31:39,600
again. I get C. Right? So this is just

698
00:31:36,880 --> 00:31:41,840
you know a basic sanity check. If I'm

699
00:31:39,600 --> 00:31:45,039
trying to approximate the expectation of

700
00:31:41,840 --> 00:31:48,000
my random variable X with another random

701
00:31:45,039 --> 00:31:50,159
variable SN, I better have that the

702
00:31:48,000 --> 00:31:52,000
expectation of SN is equal to X,

703
00:31:50,159 --> 00:31:54,480
otherwise I'm going to have trouble. So

704
00:31:52,000 --> 00:31:56,640
this makes sense. This just means that I

705
00:31:54,480 --> 00:31:58,960
have an unbiased estimator of the thing

706
00:31:56,640 --> 00:32:01,279
that I really care about.

707
00:31:58,960 --> 00:32:02,720
Now the crucial thing is computing the

708
00:32:01,279 --> 00:32:04,960
variance. We're not going to be able to

709
00:32:02,720 --> 00:32:07,600
get by by using Marov's bound. We're

710
00:32:04,960 --> 00:32:09,200
really going to have to use CHBS. And

711
00:32:07,600 --> 00:32:11,919
that's where independence is going to

712
00:32:09,200 --> 00:32:13,760
save us. So remember for chbachev's

713
00:32:11,919 --> 00:32:16,559
bound, I need to know what the variance

714
00:32:13,760 --> 00:32:19,120
of my random variable is in order to

715
00:32:16,559 --> 00:32:21,279
quantify how close a random variable

716
00:32:19,120 --> 00:32:22,799
will be to its expectation because

717
00:32:21,279 --> 00:32:25,519
that's the thing that shows up in my

718
00:32:22,799 --> 00:32:27,120
statement of chbashev. The main action

719
00:32:25,519 --> 00:32:29,600
for the weak law of large numbers is

720
00:32:27,120 --> 00:32:32,240
just computing what this variance of sn

721
00:32:29,600 --> 00:32:37,120
is. So I can do the same thing as

722
00:32:32,240 --> 00:32:39,760
before. I can replace Sn with you know

723
00:32:37,120 --> 00:32:42,640
what it is defined as in terms of the x

724
00:32:39,760 --> 00:32:45,200
i.

725
00:32:42,640 --> 00:32:48,320
And now what happens when I scale a

726
00:32:45,200 --> 00:32:50,799
random variable by some scalar c you

727
00:32:48,320 --> 00:32:52,799
know in this case 1 / n. Well the

728
00:32:50,799 --> 00:32:55,200
variance is going to scale by a c

729
00:32:52,799 --> 00:32:57,760
squared right because I'm taking the

730
00:32:55,200 --> 00:33:01,600
expectation of some quantity squared in

731
00:32:57,760 --> 00:33:03,279
there. So this is the same thing as 1 /

732
00:33:01,600 --> 00:33:08,000
n^2

733
00:33:03,279 --> 00:33:10,960
times the variance of the sum of the x i

734
00:33:08,000 --> 00:33:13,840
from i= 1 to n.

735
00:33:10,960 --> 00:33:15,919
And now the main trick is that I claim

736
00:33:13,840 --> 00:33:19,360
that this is now equal to I'll carry

737
00:33:15,919 --> 00:33:23,919
through my 1 / n^2. I claim that this is

738
00:33:19,360 --> 00:33:26,799
equal to n times the variance

739
00:33:23,919 --> 00:33:28,880
of each of these random variables x. So

740
00:33:26,799 --> 00:33:31,120
this is the key step in the weak law of

741
00:33:28,880 --> 00:33:34,640
large numbers. This is the part that I

742
00:33:31,120 --> 00:33:38,399
want to dwell on. So why is this step

743
00:33:34,640 --> 00:33:40,240
okay? So how did I go from here to here?

744
00:33:38,399 --> 00:33:41,440
We have to remember way back when with

745
00:33:40,240 --> 00:33:42,960
what I told you when we did the

746
00:33:41,440 --> 00:33:44,080
probability unit. Yes.

747
00:33:42,960 --> 00:33:45,600
>> Because they're independent.

748
00:33:44,080 --> 00:33:48,480
>> Because they're independent. That's

749
00:33:45,600 --> 00:33:50,480
right. So remember we had things like

750
00:33:48,480 --> 00:33:52,399
the linearity of expectation. We add two

751
00:33:50,480 --> 00:33:54,240
random variables. Their expectation of

752
00:33:52,399 --> 00:33:56,720
their sum is the sum of their

753
00:33:54,240 --> 00:33:58,480
expectations. that assumed nothing about

754
00:33:56,720 --> 00:34:00,240
the random variables, it was always

755
00:33:58,480 --> 00:34:02,159
true.

756
00:34:00,240 --> 00:34:03,919
But when I talked about the variance of

757
00:34:02,159 --> 00:34:06,640
two random variables, the variance of

758
00:34:03,919 --> 00:34:09,280
the sum of two random variables is equal

759
00:34:06,640 --> 00:34:12,560
to the sum of their variances, but only

760
00:34:09,280 --> 00:34:14,480
if I have independence. So the crucial

761
00:34:12,560 --> 00:34:17,359
assumption that these are independent

762
00:34:14,480 --> 00:34:18,639
draws, you know, I need in order to get

763
00:34:17,359 --> 00:34:20,800
this step and that's where we're going

764
00:34:18,639 --> 00:34:23,919
to be winning because you can see that I

765
00:34:20,800 --> 00:34:26,159
pulled out a 1 overn^ squ and it's only

766
00:34:23,919 --> 00:34:28,000
canceling out one of these. It it'll

767
00:34:26,159 --> 00:34:30,879
cancel out this n, but I'll still have a

768
00:34:28,000 --> 00:34:32,399
1 overn left over. So that's why as I

769
00:34:30,879 --> 00:34:33,839
take more and more samples, you know,

770
00:34:32,399 --> 00:34:36,560
I'm going to get better and better

771
00:34:33,839 --> 00:34:38,720
concentration. Just to completely drive

772
00:34:36,560 --> 00:34:41,040
home the point, right? We needed

773
00:34:38,720 --> 00:34:43,200
independence in order to get this last

774
00:34:41,040 --> 00:34:45,679
step. Right? If I didn't have

775
00:34:43,200 --> 00:34:48,480
independence here, you know, what would

776
00:34:45,679 --> 00:34:50,079
my polling methodology be? I'm trying to

777
00:34:48,480 --> 00:34:52,240
get a hint about who's going to win the

778
00:34:50,079 --> 00:34:55,839
election. And I call the same guy over

779
00:34:52,240 --> 00:34:57,680
and over again and ask him his opinion.

780
00:34:55,839 --> 00:34:59,359
That would be a pretty ridiculous way to

781
00:34:57,680 --> 00:35:01,440
get an idea about who's going to win the

782
00:34:59,359 --> 00:35:04,000
election. So, you crucially need

783
00:35:01,440 --> 00:35:10,320
independence. But now we can write this

784
00:35:04,000 --> 00:35:13,359
out. This is the variance of x over n.

785
00:35:10,320 --> 00:35:15,760
And now we can just appeal to chbachev

786
00:35:13,359 --> 00:35:21,280
right and chbbeev is going to get us our

787
00:35:15,760 --> 00:35:26,880
weak law of large numbers. So by chebbev

788
00:35:21,280 --> 00:35:29,040
we know that the probability that sn

789
00:35:26,880 --> 00:35:31,359
is off from its expectation by an

790
00:35:29,040 --> 00:35:35,920
additive epsilon

791
00:35:31,359 --> 00:35:38,480
is at most the variance of sn over

792
00:35:35,920 --> 00:35:41,119
epsilon squared which our right hand

793
00:35:38,480 --> 00:35:47,119
side is the same thing as the variance

794
00:35:41,119 --> 00:35:49,119
of x over n * epsilon^ 2.

795
00:35:47,119 --> 00:35:52,320
So this tells me immediately that you

796
00:35:49,119 --> 00:35:54,960
know as I want some better and better

797
00:35:52,320 --> 00:35:58,640
target accuracy for how accurate my poll

798
00:35:54,960 --> 00:36:01,680
is maybe I don't want like 0.05 error I

799
00:35:58,640 --> 00:36:04,240
want 0.01 1 right what's going to happen

800
00:36:01,680 --> 00:36:07,599
is that my epsilon is getting five times

801
00:36:04,240 --> 00:36:11,119
as small so what do I need I need my n

802
00:36:07,599 --> 00:36:14,000
to be 25 times as big in order to get

803
00:36:11,119 --> 00:36:15,680
the same bound on the tail probability

804
00:36:14,000 --> 00:36:17,839
so actually in the course of proving the

805
00:36:15,680 --> 00:36:20,400
weak law of large numbers we even got

806
00:36:17,839 --> 00:36:23,200
quantitative bounds that tell us you

807
00:36:20,400 --> 00:36:25,440
know exactly how large our n needs to be

808
00:36:23,200 --> 00:36:29,359
instead of hiding it all within this

809
00:36:25,440 --> 00:36:33,720
limit okay so this is one of

810
00:36:29,359 --> 00:36:33,720
applications. Any questions?

811
00:36:35,200 --> 00:36:39,720
Good.

812
00:36:36,720 --> 00:36:39,720
All right.

813
00:36:41,520 --> 00:36:47,359
So, let's talk about an application to

814
00:36:43,520 --> 00:36:50,240
gambling. Uh I hope none of you all are

815
00:36:47,359 --> 00:36:53,599
big gamblers. Uh actually it turned out

816
00:36:50,240 --> 00:36:55,760
so when we bought our house in Belmont

817
00:36:53,599 --> 00:36:57,680
um we kept getting all these weird

818
00:36:55,760 --> 00:36:59,760
packages and fruits in the mail like

819
00:36:57,680 --> 00:37:01,200
very fancy things. You know around

820
00:36:59,760 --> 00:37:03,920
Christmas time people would spend us

821
00:37:01,200 --> 00:37:05,520
send us these very expensive wreaths and

822
00:37:03,920 --> 00:37:07,040
it took us a while to figure out that

823
00:37:05,520 --> 00:37:09,599
that was because the person who owned

824
00:37:07,040 --> 00:37:11,119
our place before was the CTO of

825
00:37:09,599 --> 00:37:14,640
DraftKings.

826
00:37:11,119 --> 00:37:16,480
Um so now we get a lot of uh you know

827
00:37:14,640 --> 00:37:19,760
free fruits in the mail because of

828
00:37:16,480 --> 00:37:21,440
gambling. So that's good. But um let's

829
00:37:19,760 --> 00:37:24,720
talk about an application of the weak

830
00:37:21,440 --> 00:37:26,720
law of large numbers to gambling or

831
00:37:24,720 --> 00:37:28,880
maybe a caution about why it's not a

832
00:37:26,720 --> 00:37:31,359
great idea to gamble too much especially

833
00:37:28,880 --> 00:37:33,280
in Vegas.

834
00:37:31,359 --> 00:37:37,440
So there's an important example which is

835
00:37:33,280 --> 00:37:41,119
called gamblers ruin.

836
00:37:37,440 --> 00:37:46,359
Uh so the way that it's colloially fl

837
00:37:41,119 --> 00:37:46,359
phrased is that playing a game

838
00:37:46,560 --> 00:37:51,000
with negative expected value.

839
00:37:59,119 --> 00:38:03,240
You'll eventually go broke.

840
00:38:08,880 --> 00:38:13,520
Okay, so this makes sense. You know,

841
00:38:11,440 --> 00:38:15,680
when you play uh when you gamble in

842
00:38:13,520 --> 00:38:18,240
Vegas, definitely all the games aside

843
00:38:15,680 --> 00:38:20,720
from maybe blackjack, if you're counting

844
00:38:18,240 --> 00:38:23,440
cards, have this property that they have

845
00:38:20,720 --> 00:38:25,280
negative expected value.

846
00:38:23,440 --> 00:38:27,119
And intuitively, it makes sense that if

847
00:38:25,280 --> 00:38:28,720
you have negative expected value, on

848
00:38:27,119 --> 00:38:31,520
average, you're giving up some money

849
00:38:28,720 --> 00:38:33,200
every time you play. But maybe you get

850
00:38:31,520 --> 00:38:34,960
really lucky. Maybe there's some

851
00:38:33,200 --> 00:38:37,599
probability that you just keep on

852
00:38:34,960 --> 00:38:38,960
winning, right? Well, Gamblers's ruin is

853
00:38:37,599 --> 00:38:41,520
going to tell us that that's not the

854
00:38:38,960 --> 00:38:43,359
case. That the probability that you

855
00:38:41,520 --> 00:38:46,320
don't that you go broke is going to

856
00:38:43,359 --> 00:38:49,359
converge to one as soon as the expected

857
00:38:46,320 --> 00:38:51,920
value is negative. So, let's do this for

858
00:38:49,359 --> 00:38:54,320
example with a a concrete thing. So, if

859
00:38:51,920 --> 00:38:56,800
you ignore, you know, multiplayer,

860
00:38:54,320 --> 00:38:59,040
um, you know, betting games like, uh,

861
00:38:56,800 --> 00:39:01,920
you know, Blackjack, if you just stick

862
00:38:59,040 --> 00:39:04,160
to the standard ones,

863
00:39:01,920 --> 00:39:06,720
all of the games in Vegas have negative

864
00:39:04,160 --> 00:39:12,040
expected value, but the one that has the

865
00:39:06,720 --> 00:39:12,040
least negative expected value is craps.

866
00:39:12,960 --> 00:39:18,800
Has anyone played craps before?

867
00:39:16,400 --> 00:39:21,040
No. Okay, I'm talking to the wrong

868
00:39:18,800 --> 00:39:23,680
audience. That's good.

869
00:39:21,040 --> 00:39:26,000
So, uh, craps is one where you, you

870
00:39:23,680 --> 00:39:28,240
know, roll dice and then, uh, depending

871
00:39:26,000 --> 00:39:30,160
on whether it lands on like black or

872
00:39:28,240 --> 00:39:33,359
red, you know, you make different kinds

873
00:39:30,160 --> 00:39:36,960
of wagers. And there's basically a bet

874
00:39:33,359 --> 00:39:38,720
you can make that's very close to 50/50.

875
00:39:36,960 --> 00:39:40,880
So, you have to get to that point in the

876
00:39:38,720 --> 00:39:43,200
game first. But, you know, the house

877
00:39:40,880 --> 00:39:48,520
edge, if you play that strategy in in

878
00:39:43,200 --> 00:39:48,520
craps, is just, you know, 0.0141.

879
00:39:48,960 --> 00:39:53,599
So, we can think about, you know, a

880
00:39:50,960 --> 00:39:57,440
simplified version of making that bet in

881
00:39:53,599 --> 00:39:58,720
crops that with um, you know, some

882
00:39:57,440 --> 00:40:01,040
probability you're going to win a

883
00:39:58,720 --> 00:40:05,200
dollar. And what is that probability

884
00:40:01,040 --> 00:40:08,200
going to be? Well, it'll be

885
00:40:05,200 --> 00:40:08,200
0.4929,

886
00:40:08,640 --> 00:40:14,240
right? because you want that the

887
00:40:11,280 --> 00:40:15,680
probability that you know you win uh the

888
00:40:14,240 --> 00:40:17,839
probability you lose minus the

889
00:40:15,680 --> 00:40:21,280
probability you win is equal to this you

890
00:40:17,839 --> 00:40:25,599
know house edge here okay and then

891
00:40:21,280 --> 00:40:28,160
otherwise you're going to lose a dollar

892
00:40:25,599 --> 00:40:32,839
and so what I claim is now that you know

893
00:40:28,160 --> 00:40:32,839
by weak law of large numbers

894
00:40:32,960 --> 00:40:38,800
well you can look at SN which is just

895
00:40:35,520 --> 00:40:40,560
your cumulative winnings right so you

896
00:40:38,800 --> 00:40:43,200
can add up in each game whether you win

897
00:40:40,560 --> 00:40:46,079
a dollar or you lose a dollar. Now the

898
00:40:43,200 --> 00:40:48,160
point is that that average is negative,

899
00:40:46,079 --> 00:40:50,240
right? So the probability that you're

900
00:40:48,160 --> 00:40:52,079
epsilon away from your average is

901
00:40:50,240 --> 00:40:54,560
actually going to zero as you play more

902
00:40:52,079 --> 00:40:57,200
and more games. So on average you really

903
00:40:54,560 --> 00:40:59,200
will be losing some amount of money per

904
00:40:57,200 --> 00:41:02,079
step and you will not get that lucky

905
00:40:59,200 --> 00:41:07,280
with probability converging to zero. So

906
00:41:02,079 --> 00:41:10,000
by the weak law of large numbers except

907
00:41:07,280 --> 00:41:12,000
with vanishing probability

908
00:41:10,000 --> 00:41:14,160
something that gets swallowed up by the

909
00:41:12,000 --> 00:41:17,440
limit.

910
00:41:14,160 --> 00:41:20,760
I claim the winning

911
00:41:17,440 --> 00:41:20,760
per round

912
00:41:21,920 --> 00:41:26,880
will go negative

913
00:41:24,480 --> 00:41:28,880
which of course since it's a average

914
00:41:26,880 --> 00:41:31,680
over your rounds if you play infinitely

915
00:41:28,880 --> 00:41:35,440
long you will go broke.

916
00:41:31,680 --> 00:41:37,839
So this is called gamblers's ruin. Um

917
00:41:35,440 --> 00:41:39,760
and I want to give one more motivating

918
00:41:37,839 --> 00:41:41,280
example before we take a step back and I

919
00:41:39,760 --> 00:41:44,640
tell you about another probabilistic

920
00:41:41,280 --> 00:41:47,280
tool. So you know for us uh so far we've

921
00:41:44,640 --> 00:41:50,640
been talking about tail bounds as a way

922
00:41:47,280 --> 00:41:53,280
to get a handle on uh how likely or

923
00:41:50,640 --> 00:41:56,400
unlikely it is for a random variable to

924
00:41:53,280 --> 00:41:58,800
be far away from their expectation.

925
00:41:56,400 --> 00:42:01,760
Now, it turns out that really the reason

926
00:41:58,800 --> 00:42:04,720
we care about these tailbounds isn't

927
00:42:01,760 --> 00:42:07,280
just for their own sake,

928
00:42:04,720 --> 00:42:10,160
but it really comes up in all kinds of

929
00:42:07,280 --> 00:42:12,079
applications and discrete math. So,

930
00:42:10,160 --> 00:42:14,319
we'll see probability, you know,

931
00:42:12,079 --> 00:42:16,400
throughout some of the later units in

932
00:42:14,319 --> 00:42:18,240
class, but I want to give you a little

933
00:42:16,400 --> 00:42:20,640
bit of a hint about, you know, why we

934
00:42:18,240 --> 00:42:25,200
care about tail bounds, especially when

935
00:42:20,640 --> 00:42:27,520
it comes to algorithm design. Okay,

936
00:42:25,200 --> 00:42:30,520
so let's talk about an algorithmic

937
00:42:27,520 --> 00:42:30,520
application

938
00:42:31,359 --> 00:42:39,400
and this is a real application,

939
00:42:34,800 --> 00:42:39,400
something that gets used all the time.

940
00:42:39,680 --> 00:42:49,160
So let's say that um we have we're given

941
00:42:45,040 --> 00:42:49,160
a randomized algorithm

942
00:42:54,480 --> 00:43:00,160
and let's call it

943
00:42:56,800 --> 00:43:01,920
a Q. So A is the algorithm, Q is the

944
00:43:00,160 --> 00:43:04,720
input.

945
00:43:01,920 --> 00:43:07,599
And let's say this algorithm, this

946
00:43:04,720 --> 00:43:10,079
randomized algorithm has the property

947
00:43:07,599 --> 00:43:12,000
that when we run A on Q, well, its

948
00:43:10,079 --> 00:43:14,960
answer isn't deterministic. It's a

949
00:43:12,000 --> 00:43:17,200
randomized algorithm. And let's assume

950
00:43:14,960 --> 00:43:19,680
that, you know, it gets the answer right

951
00:43:17,200 --> 00:43:24,079
more often than it gets it wrong. So

952
00:43:19,680 --> 00:43:26,400
let's say it outputs the correct answer

953
00:43:24,079 --> 00:43:30,760
with some probability.

954
00:43:26,400 --> 00:43:30,760
Let's just say 2/3.

955
00:43:31,839 --> 00:43:39,319
And otherwise it's going to output

956
00:43:35,440 --> 00:43:39,319
the incorrect answer

957
00:43:40,160 --> 00:43:43,160
otherwise.

958
00:43:43,920 --> 00:43:47,680
And the basic question we can ask is how

959
00:43:46,000 --> 00:43:50,560
many times we have to repeat this

960
00:43:47,680 --> 00:43:53,359
algorithm in order to get a good to

961
00:43:50,560 --> 00:43:55,119
boost its success probability. So one

962
00:43:53,359 --> 00:43:57,839
way to think about it you know our next

963
00:43:55,119 --> 00:44:01,839
unit after we do tail bounds is I'll be

964
00:43:57,839 --> 00:44:03,760
teaching you about modular arithmetic

965
00:44:01,839 --> 00:44:06,160
and you know the basic thing we want to

966
00:44:03,760 --> 00:44:08,240
do there is imagine I'm given some giant

967
00:44:06,160 --> 00:44:10,240
number. A lot of properties of the

968
00:44:08,240 --> 00:44:13,200
factorization of this number are going

969
00:44:10,240 --> 00:44:15,760
to affect you know how it works when we

970
00:44:13,200 --> 00:44:18,079
when we do modular arithmetic.

971
00:44:15,760 --> 00:44:19,280
And you know later on much later in the

972
00:44:18,079 --> 00:44:21,440
class we're going to talk about

973
00:44:19,280 --> 00:44:23,359
applications of modular arithmetic to

974
00:44:21,440 --> 00:44:25,599
things like cryptography.

975
00:44:23,359 --> 00:44:27,839
So communicating securely with a public

976
00:44:25,599 --> 00:44:30,960
encryption scheme. These are things that

977
00:44:27,839 --> 00:44:33,040
get used all the time in e-commerce.

978
00:44:30,960 --> 00:44:35,839
But when I'm creating a scheme for

979
00:44:33,040 --> 00:44:38,560
communicating securely, I have to start

980
00:44:35,839 --> 00:44:41,520
off with some, you know, number that's

981
00:44:38,560 --> 00:44:43,839
the product of just two primes. So what

982
00:44:41,520 --> 00:44:46,880
I can do is I can try and generate a

983
00:44:43,839 --> 00:44:48,800
random integer and hope that it's prime.

984
00:44:46,880 --> 00:44:51,599
And that turns out to work pretty well.

985
00:44:48,800 --> 00:44:53,359
You're reasonably likely to get a prime.

986
00:44:51,599 --> 00:44:56,000
But the trouble is that, you know, our

987
00:44:53,359 --> 00:44:58,800
best algorithms for determining whether

988
00:44:56,000 --> 00:45:00,480
or not a given integer is prime, they're

989
00:44:58,800 --> 00:45:02,480
randomized.

990
00:45:00,480 --> 00:45:05,200
So, you know, maybe I'm running my

991
00:45:02,480 --> 00:45:07,680
cryptographic scheme and I have some

992
00:45:05,200 --> 00:45:10,160
integer Q and I want to figure out if

993
00:45:07,680 --> 00:45:11,760
it's prime so that I can safely use it

994
00:45:10,160 --> 00:45:13,280
in the context of my secure

995
00:45:11,760 --> 00:45:15,359
communication.

996
00:45:13,280 --> 00:45:17,440
So, you have an algorithm that you know

997
00:45:15,359 --> 00:45:19,040
with twothirds probability tells you the

998
00:45:17,440 --> 00:45:21,359
right answer and otherwise tells you the

999
00:45:19,040 --> 00:45:24,400
wrong answer. But if you were wrong,

1000
00:45:21,359 --> 00:45:26,319
there's a huge penalty to pay, right? If

1001
00:45:24,400 --> 00:45:28,800
you're wrong and the thing, you know,

1002
00:45:26,319 --> 00:45:30,720
wasn't prime and you thought it was,

1003
00:45:28,800 --> 00:45:32,480
then maybe you've just leaked all of

1004
00:45:30,720 --> 00:45:34,240
this sensitive information like your

1005
00:45:32,480 --> 00:45:37,119
bank account, your social security

1006
00:45:34,240 --> 00:45:38,960
number. So maybe this failure

1007
00:45:37,119 --> 00:45:41,119
probability of a third is just not good

1008
00:45:38,960 --> 00:45:42,960
enough, right? What kind of failure

1009
00:45:41,119 --> 00:45:47,079
probability would you be okay with your

1010
00:45:42,960 --> 00:45:47,079
social security number leaking?

1011
00:45:48,160 --> 00:45:54,240
Just give me a number.

1012
00:45:50,640 --> 00:45:56,560
10us 30. Okay. I was going to say 10 the

1013
00:45:54,240 --> 00:45:58,480
minus 10, but that's that's even better.

1014
00:45:56,560 --> 00:46:00,800
Uh, you're even more paranoid than I am,

1015
00:45:58,480 --> 00:46:04,160
which is a good thing. So, you know,

1016
00:46:00,800 --> 00:46:08,000
let's say I want to get a really tiny

1017
00:46:04,160 --> 00:46:12,560
failure probability like 10us 10.

1018
00:46:08,000 --> 00:46:15,560
So, how many times should I repeat this

1019
00:46:12,560 --> 00:46:15,560
algorithm

1020
00:46:19,119 --> 00:46:23,319
to make its failure probability

1021
00:46:29,440 --> 00:46:35,760
less than 10 the minus 10. Okay, or

1022
00:46:32,720 --> 00:46:38,079
maybe even 10 the minus30.

1023
00:46:35,760 --> 00:46:39,760
So if you think about it, right, this is

1024
00:46:38,079 --> 00:46:42,000
really the setting of the weak law of

1025
00:46:39,760 --> 00:46:44,640
large numbers. It's the same kind of

1026
00:46:42,000 --> 00:46:47,040
thing. You know, each of my runs of this

1027
00:46:44,640 --> 00:46:49,680
random variable is an is a random

1028
00:46:47,040 --> 00:46:52,880
variable XI that tells me whether or not

1029
00:46:49,680 --> 00:46:55,200
Q is prime. And what I'm guaranteed is

1030
00:46:52,880 --> 00:46:57,280
that uh you know that as I take the

1031
00:46:55,200 --> 00:47:00,160
limit as the number of repetitions goes

1032
00:46:57,280 --> 00:47:02,400
to infinity the average of the number of

1033
00:47:00,160 --> 00:47:05,280
outputs right

1034
00:47:02,400 --> 00:47:08,160
uh that you know say that it's prime is

1035
00:47:05,280 --> 00:47:10,079
going to converge to 2/3 if it really is

1036
00:47:08,160 --> 00:47:11,599
prime and the number that are going to

1037
00:47:10,079 --> 00:47:14,960
say it's not prime is going to converge

1038
00:47:11,599 --> 00:47:16,560
to 2/3 if if it isn't. Right? So this is

1039
00:47:14,960 --> 00:47:19,839
the setting of the weak law of large

1040
00:47:16,560 --> 00:47:22,319
numbers. I'm just voting with runs of my

1041
00:47:19,839 --> 00:47:24,079
algorithm. And we've already seen some

1042
00:47:22,319 --> 00:47:26,480
quantitative balance from the weak law

1043
00:47:24,079 --> 00:47:29,200
of large numbers about how large n needs

1044
00:47:26,480 --> 00:47:32,560
to be in order to get some valid, you

1045
00:47:29,200 --> 00:47:34,640
know, epsilon, right?

1046
00:47:32,560 --> 00:47:36,160
And if we think about it, you know, if

1047
00:47:34,640 --> 00:47:37,599
we just think about applying the weak

1048
00:47:36,160 --> 00:47:39,760
law of large numbers, we're actually

1049
00:47:37,599 --> 00:47:43,200
going to get very pessimistic bounds

1050
00:47:39,760 --> 00:47:44,800
even here. So let's think about what uh

1051
00:47:43,200 --> 00:47:48,240
the weak law of large numbers and

1052
00:47:44,800 --> 00:47:48,240
chbishev would tell us.

1053
00:47:58,000 --> 00:48:02,560
So the weak law of large numbers slash

1054
00:48:00,480 --> 00:48:05,119
our chbachev proof that gave us a

1055
00:48:02,560 --> 00:48:06,960
quantitative bound.

1056
00:48:05,119 --> 00:48:08,720
Well, it's going to tell us that the

1057
00:48:06,960 --> 00:48:14,640
right hand side, the probability of

1058
00:48:08,720 --> 00:48:19,680
failure is bounded by the variance of X

1059
00:48:14,640 --> 00:48:22,680
n over epsilon squared. Okay. And in our

1060
00:48:19,680 --> 00:48:22,680
case,

1061
00:48:23,920 --> 00:48:28,559
you know, we can take X to be just

1062
00:48:25,920 --> 00:48:31,760
whether or not uh the output of our

1063
00:48:28,559 --> 00:48:34,720
random of our randomized algorithm is

1064
00:48:31,760 --> 00:48:37,359
correct or not.

1065
00:48:34,720 --> 00:48:43,200
And you can compute that the variance of

1066
00:48:37,359 --> 00:48:45,040
X is going to be 2/3 minus 4 9ths. So

1067
00:48:43,200 --> 00:48:47,760
you know it's some constant that's a

1068
00:48:45,040 --> 00:48:50,319
reasonable constant. And what we can do

1069
00:48:47,760 --> 00:48:54,160
is we can set

1070
00:48:50,319 --> 00:48:56,800
epsilon to be something like 1 nth. So

1071
00:48:54,160 --> 00:48:58,640
you know X is um supposed to tell us

1072
00:48:56,800 --> 00:49:00,880
whether or not the thing is prime or

1073
00:48:58,640 --> 00:49:02,960
not. We only have to set our tolerance

1074
00:49:00,880 --> 00:49:05,839
really to sort of split the difference

1075
00:49:02,960 --> 00:49:07,359
between 2/3 and 1/3, right? That's not

1076
00:49:05,839 --> 00:49:10,000
where any of the action is happening.

1077
00:49:07,359 --> 00:49:11,599
These are all just constants. But you

1078
00:49:10,000 --> 00:49:16,079
know what's going on is that the

1079
00:49:11,599 --> 00:49:18,800
probability that you know our average

1080
00:49:16,079 --> 00:49:21,040
is you know off from the truth, right?

1081
00:49:18,800 --> 00:49:24,800
We can bound it by something like you

1082
00:49:21,040 --> 00:49:26,720
know 18 over n. Now none of the other

1083
00:49:24,800 --> 00:49:28,079
computations really matter too much. You

1084
00:49:26,720 --> 00:49:30,559
can compute the variance. You can

1085
00:49:28,079 --> 00:49:32,240
compute what epsilon makes sense. But

1086
00:49:30,559 --> 00:49:35,520
the crucial thing is really the fact

1087
00:49:32,240 --> 00:49:38,720
that the n shows up in the denominator.

1088
00:49:35,520 --> 00:49:41,680
So if I want my failure probability, you

1089
00:49:38,720 --> 00:49:44,079
know, to be absolutely tiny, what kind

1090
00:49:41,680 --> 00:49:46,880
of n would I have to take? I'd have to

1091
00:49:44,079 --> 00:49:50,240
take it to be like 10 the 10 or 10 the

1092
00:49:46,880 --> 00:49:51,440
30. That would be ridiculous, right? So

1093
00:49:50,240 --> 00:49:53,599
I want to make sure that I have

1094
00:49:51,440 --> 00:49:55,839
vanishing probability of using something

1095
00:49:53,599 --> 00:49:58,240
that violates security in my crypto

1096
00:49:55,839 --> 00:50:01,200
scheme. And I just have to repeat this

1097
00:49:58,240 --> 00:50:03,680
so many times that I can't really do a

1098
00:50:01,200 --> 00:50:06,880
transaction online because it would just

1099
00:50:03,680 --> 00:50:09,680
clog up the computer. Right?

1100
00:50:06,880 --> 00:50:10,720
So this takes me to the last main topic.

1101
00:50:09,680 --> 00:50:12,960
This is something which I want to

1102
00:50:10,720 --> 00:50:15,440
introduce now. You're going to start to

1103
00:50:12,960 --> 00:50:17,839
cover it in recitation.

1104
00:50:15,440 --> 00:50:20,559
But you know this tailbound is not at

1105
00:50:17,839 --> 00:50:22,559
all you know obvious how to prove it and

1106
00:50:20,559 --> 00:50:24,640
it'll be basically the full lecture on

1107
00:50:22,559 --> 00:50:26,800
Thursday. But this was really just the

1108
00:50:24,640 --> 00:50:30,400
motivation for it, right?

1109
00:50:26,800 --> 00:50:33,920
So you see that um like I told you the

1110
00:50:30,400 --> 00:50:38,160
theme for today's lecture was the more

1111
00:50:33,920 --> 00:50:40,880
information you tell me about the random

1112
00:50:38,160 --> 00:50:44,000
variables uh the better I get for my

1113
00:50:40,880 --> 00:50:46,240
tail balance. So let's you know take a

1114
00:50:44,000 --> 00:50:49,040
minute to think about the proof of this

1115
00:50:46,240 --> 00:50:50,800
weak law of large numbers.

1116
00:50:49,040 --> 00:50:54,000
So the setting for this was that I

1117
00:50:50,800 --> 00:50:57,839
assume that the XI's are independent

1118
00:50:54,000 --> 00:51:01,280
draws from X, right? But I claim my

1119
00:50:57,839 --> 00:51:04,280
proof didn't really use full

1120
00:51:01,280 --> 00:51:04,280
independence.

1121
00:51:04,960 --> 00:51:10,160
I claim all it used was that they're

1122
00:51:08,559 --> 00:51:11,760
pair-wise

1123
00:51:10,160 --> 00:51:13,599
independent.

1124
00:51:11,760 --> 00:51:15,680
That if you look at any pair of them,

1125
00:51:13,599 --> 00:51:17,520
they're independent. But I didn't use

1126
00:51:15,680 --> 00:51:20,480
the fact that any triple or any

1127
00:51:17,520 --> 00:51:22,079
quadruple of them are independent.

1128
00:51:20,480 --> 00:51:24,720
So this requires a little bit of

1129
00:51:22,079 --> 00:51:28,400
thinking. Right? So where in my proof of

1130
00:51:24,720 --> 00:51:31,040
the week of lo uh law of large numbers

1131
00:51:28,400 --> 00:51:35,440
did I actually use independence?

1132
00:51:31,040 --> 00:51:38,079
It was only in this step right here.

1133
00:51:35,440 --> 00:51:39,839
And I didn't actually need that all of

1134
00:51:38,079 --> 00:51:41,440
these random variables are mutually

1135
00:51:39,839 --> 00:51:43,760
independent. I just needed that

1136
00:51:41,440 --> 00:51:45,280
pair-wise independent.

1137
00:51:43,760 --> 00:51:47,359
That's exactly what got me the

1138
00:51:45,280 --> 00:51:49,440
quantitative bound. But that's the

1139
00:51:47,359 --> 00:51:51,839
weakness in applying chbushev is that

1140
00:51:49,440 --> 00:51:55,280
I'm not using as much information as I

1141
00:51:51,839 --> 00:51:57,520
could hope to. Does that make sense?

1142
00:51:55,280 --> 00:52:00,000
So that's what leads me to the next

1143
00:51:57,520 --> 00:52:01,839
bound which is called the churnoff bound

1144
00:52:00,000 --> 00:52:03,520
which is not just going to use pairwise

1145
00:52:01,839 --> 00:52:05,599
independence but it's going to use you

1146
00:52:03,520 --> 00:52:07,839
know mutual independence.

1147
00:52:05,599 --> 00:52:11,599
So let's state the uh the churnoff

1148
00:52:07,839 --> 00:52:14,480
bound. This was actually proven at MIT

1149
00:52:11,599 --> 00:52:16,720
presumably in this building even which

1150
00:52:14,480 --> 00:52:19,599
is cool. So this was proven by our

1151
00:52:16,720 --> 00:52:24,240
former colleague Herman Chernoff. And

1152
00:52:19,599 --> 00:52:27,200
let's assume that X1 up to XN let them

1153
00:52:24,240 --> 00:52:30,800
be mutually independent. So this is a

1154
00:52:27,200 --> 00:52:32,960
much stronger notion of independence

1155
00:52:30,800 --> 00:52:35,760
because I need all subsets of them to be

1156
00:52:32,960 --> 00:52:37,599
independent from all other subsets. So

1157
00:52:35,760 --> 00:52:41,000
let's say they're mutually independent

1158
00:52:37,599 --> 00:52:41,000
random variables

1159
00:52:43,440 --> 00:52:52,319
and let's just say that XI is equal to 1

1160
00:52:47,520 --> 00:52:56,640
or zero with probability PI and

1161
00:52:52,319 --> 00:52:58,079
otherwise it's equal to zero.

1162
00:52:56,640 --> 00:53:00,400
Now I'm going to do the same type of

1163
00:52:58,079 --> 00:53:02,960
thing I did before. I'm going to look at

1164
00:53:00,400 --> 00:53:04,480
some kind of average or sum of these

1165
00:53:02,960 --> 00:53:07,760
random variables. So let me look at

1166
00:53:04,480 --> 00:53:10,400
capital X which is the sum from i= 1 to

1167
00:53:07,760 --> 00:53:14,559
little n of x i

1168
00:53:10,400 --> 00:53:17,359
and let me look at the expectation of x.

1169
00:53:14,559 --> 00:53:19,280
Let me call that quantity mu. But

1170
00:53:17,359 --> 00:53:23,359
remember that's the same thing as just

1171
00:53:19,280 --> 00:53:25,920
the sum from i = 1 to n of the pis. So

1172
00:53:23,359 --> 00:53:27,680
this is all just setup. I have mutually

1173
00:53:25,920 --> 00:53:30,720
independent random variables the x

1174
00:53:27,680 --> 00:53:32,559
subis. In fact, they're Bernoli random

1175
00:53:30,720 --> 00:53:34,960
variables because they just take on the

1176
00:53:32,559 --> 00:53:36,880
value one or zero. And I'm telling you

1177
00:53:34,960 --> 00:53:39,359
that the probability that they're one is

1178
00:53:36,880 --> 00:53:41,040
pi. So this is already a bit of a

1179
00:53:39,359 --> 00:53:43,599
departure from the weak law of large

1180
00:53:41,040 --> 00:53:45,680
numbers because in the weak law of large

1181
00:53:43,599 --> 00:53:49,280
numbers, I assumed that all of these

1182
00:53:45,680 --> 00:53:52,240
XI's were identical. They were all draws

1183
00:53:49,280 --> 00:53:54,319
of this random variable X.

1184
00:53:52,240 --> 00:53:56,079
Here I'm actually allowing these to be

1185
00:53:54,319 --> 00:53:58,720
different random variables. So that's

1186
00:53:56,079 --> 00:54:01,440
even one extra layer of power.

1187
00:53:58,720 --> 00:54:04,000
But the real power just comes from you

1188
00:54:01,440 --> 00:54:06,400
know the the right hand side. So let me

1189
00:54:04,000 --> 00:54:09,839
write down one form of the churnoff

1190
00:54:06,400 --> 00:54:13,680
bound. So the probability that X is very

1191
00:54:09,839 --> 00:54:20,240
far away from its average mu by some

1192
00:54:13,680 --> 00:54:23,119
delta is at most 2 * eus mu delta

1193
00:54:20,240 --> 00:54:26,119
squared over

1194
00:54:23,119 --> 00:54:26,119
3.

1195
00:54:27,359 --> 00:54:31,079
I think I need

1196
00:54:31,119 --> 00:54:38,319
the average here. Okay. Uh no.

1197
00:54:35,359 --> 00:54:40,559
Okay. All right. So this is the

1198
00:54:38,319 --> 00:54:43,760
conclusion for the churnoff bound. So

1199
00:54:40,559 --> 00:54:45,359
the important thing is really that uh

1200
00:54:43,760 --> 00:54:48,079
you know what I had on the right hand

1201
00:54:45,359 --> 00:54:50,000
side when I had Marov's bound was a kind

1202
00:54:48,079 --> 00:54:52,480
of weak bound. It looked like one over

1203
00:54:50,000 --> 00:54:55,119
C. So as you increase C, you just

1204
00:54:52,480 --> 00:54:58,160
improve the right hand side by the same

1205
00:54:55,119 --> 00:55:00,960
factor. When I had chebashev, I had a

1206
00:54:58,160 --> 00:55:03,680
one over c^ squared on the other side.

1207
00:55:00,960 --> 00:55:06,000
So the probability that I'm c away, you

1208
00:55:03,680 --> 00:55:08,480
know, was degrading still at an inverse

1209
00:55:06,000 --> 00:55:11,520
poly rate. The crucial thing is that

1210
00:55:08,480 --> 00:55:14,079
here I have an exponential rate. And

1211
00:55:11,520 --> 00:55:15,760
this is what mutual independence buys me

1212
00:55:14,079 --> 00:55:17,760
is that the probability that you're far

1213
00:55:15,760 --> 00:55:20,079
away from the average is just plummeting

1214
00:55:17,760 --> 00:55:22,960
to zero once you have this extra

1215
00:55:20,079 --> 00:55:25,040
information about independence. So the

1216
00:55:22,960 --> 00:55:27,920
churnoff bound you know there are many

1217
00:55:25,040 --> 00:55:31,040
different forms for it. Um we're going

1218
00:55:27,920 --> 00:55:33,119
to prove this next time but you know it

1219
00:55:31,040 --> 00:55:37,200
turns out that if we were to use

1220
00:55:33,119 --> 00:55:39,680
churnoff in our numerical example about

1221
00:55:37,200 --> 00:55:42,000
uh testing out primes.

1222
00:55:39,680 --> 00:55:44,800
Well, we would only have to take n our

1223
00:55:42,000 --> 00:55:48,480
number of repetitions to behave like

1224
00:55:44,800 --> 00:55:51,040
some constant times the natural log of

1225
00:55:48,480 --> 00:55:52,799
you know whatever we want to be in our

1226
00:55:51,040 --> 00:55:55,440
failure probability over here on the

1227
00:55:52,799 --> 00:55:56,960
right hand side. So if we had 10 the 10

1228
00:55:55,440 --> 00:55:59,119
really the number of repetitions would

1229
00:55:56,960 --> 00:56:02,079
be much tamer. It would just be the

1230
00:55:59,119 --> 00:56:04,400
natural log of 10 the 10. So even if I

1231
00:56:02,079 --> 00:56:06,960
put a 10 or a 30 in the exponent, it's

1232
00:56:04,400 --> 00:56:08,799
not such a giant overhead, you know, to

1233
00:56:06,960 --> 00:56:11,839
actually drive the failure probability

1234
00:56:08,799 --> 00:56:14,079
basically to zero. So that's what we'll

1235
00:56:11,839 --> 00:56:17,040
do uh next time we'll do the churnoff

1236
00:56:14,079 --> 00:56:19,440
bound. But I want to cover one last

1237
00:56:17,040 --> 00:56:22,079
topic in probability before we get to

1238
00:56:19,440 --> 00:56:23,680
the turnoff bound on Thursday. This will

1239
00:56:22,079 --> 00:56:26,160
be something that's going to you know

1240
00:56:23,680 --> 00:56:29,440
help you a lot for uh this week's

1241
00:56:26,160 --> 00:56:31,200
assignment which is a writing problem uh

1242
00:56:29,440 --> 00:56:33,440
that involves using the probabistic

1243
00:56:31,200 --> 00:56:35,920
method. So it's something we've talked a

1244
00:56:33,440 --> 00:56:37,440
little bit about on some of the pets but

1245
00:56:35,920 --> 00:56:39,839
I just want to be explicit and show you

1246
00:56:37,440 --> 00:56:41,599
some neat examples. So that'll be our

1247
00:56:39,839 --> 00:56:45,240
last topic for today is the

1248
00:56:41,599 --> 00:56:45,240
probabilistic method.

1249
00:56:48,799 --> 00:56:53,839
So you should think of this as like one

1250
00:56:50,880 --> 00:56:57,280
more important application

1251
00:56:53,839 --> 00:56:59,040
of probability tools. So so far we

1252
00:56:57,280 --> 00:57:01,280
talked about you know probability for

1253
00:56:59,040 --> 00:57:03,680
its own sake like looking at the

1254
00:57:01,280 --> 00:57:05,280
deviation of random variables. We talked

1255
00:57:03,680 --> 00:57:07,280
about probability for the sake of

1256
00:57:05,280 --> 00:57:09,680
analyzing the failure probability of

1257
00:57:07,280 --> 00:57:11,680
randomized algorithms.

1258
00:57:09,680 --> 00:57:13,680
And you know we'll also be interested in

1259
00:57:11,680 --> 00:57:15,359
using probability in the context of

1260
00:57:13,680 --> 00:57:18,319
combinotaurics.

1261
00:57:15,359 --> 00:57:20,799
It turns out that in many applications

1262
00:57:18,319 --> 00:57:23,440
there are exotic types of cominatorial

1263
00:57:20,799 --> 00:57:26,400
objects that the only way we know how to

1264
00:57:23,440 --> 00:57:29,520
reason about why they exist is by using

1265
00:57:26,400 --> 00:57:32,720
randomness. So this leads to a very

1266
00:57:29,520 --> 00:57:34,160
important paradigm in uh discrete math

1267
00:57:32,720 --> 00:57:36,079
which is called the probabilistic

1268
00:57:34,160 --> 00:57:39,040
method.

1269
00:57:36,079 --> 00:57:42,160
You can take entire classes on, you

1270
00:57:39,040 --> 00:57:45,440
know, using sophisticated tools to do

1271
00:57:42,160 --> 00:57:47,359
things like this. But let me um give you

1272
00:57:45,440 --> 00:57:49,920
the highlevel, you know, bumper sticker

1273
00:57:47,359 --> 00:57:52,160
version first before we talk about some

1274
00:57:49,920 --> 00:57:54,880
concrete applications.

1275
00:57:52,160 --> 00:57:56,960
So what we'll be interested in is we'll

1276
00:57:54,880 --> 00:58:00,000
be interested in constructing certain

1277
00:57:56,960 --> 00:58:03,440
kinds of

1278
00:58:00,000 --> 00:58:05,200
random objects or structures

1279
00:58:03,440 --> 00:58:08,000
which are exotic and have some pretty

1280
00:58:05,200 --> 00:58:10,799
wild properties. And we're going to show

1281
00:58:08,000 --> 00:58:15,280
that these things exist not by building

1282
00:58:10,799 --> 00:58:19,760
them with our own hands, but by arguing

1283
00:58:15,280 --> 00:58:22,640
that a random object

1284
00:58:19,760 --> 00:58:25,280
succeeds.

1285
00:58:22,640 --> 00:58:26,880
So that's the highle idea and you know

1286
00:58:25,280 --> 00:58:28,720
there are many instantiations of this

1287
00:58:26,880 --> 00:58:30,559
probabistic method. It depends on what

1288
00:58:28,720 --> 00:58:32,720
kinds of structures I want to prove

1289
00:58:30,559 --> 00:58:34,160
exist. We'll talk about some concrete

1290
00:58:32,720 --> 00:58:36,799
applications and we'll see how the

1291
00:58:34,160 --> 00:58:39,119
probabilistic method helps. But we're

1292
00:58:36,799 --> 00:58:42,559
going to apply this to you know another

1293
00:58:39,119 --> 00:58:45,280
important branch of applied mathematics

1294
00:58:42,559 --> 00:58:46,880
which is called uh Ramssey theory. So

1295
00:58:45,280 --> 00:58:49,680
I'll introduce both of these topics

1296
00:58:46,880 --> 00:58:53,040
right now.

1297
00:58:49,680 --> 00:58:57,880
So what's Ramsey theory? Well, let me

1298
00:58:53,040 --> 00:58:57,880
give you a famous example of it.

1299
00:59:00,079 --> 00:59:03,960
So in every party

1300
00:59:06,559 --> 00:59:11,240
with at least six people.

1301
00:59:13,119 --> 00:59:20,079
I claim that either

1302
00:59:17,599 --> 00:59:22,079
we have the situation that there are

1303
00:59:20,079 --> 00:59:24,960
three people

1304
00:59:22,079 --> 00:59:27,280
all of whom are friends with each other.

1305
00:59:24,960 --> 00:59:30,960
All pairs of these uh three people are

1306
00:59:27,280 --> 00:59:34,319
friends with each other or there are

1307
00:59:30,960 --> 00:59:37,200
three people

1308
00:59:34,319 --> 00:59:40,640
all of which are strangers

1309
00:59:37,200 --> 00:59:43,760
none of which knows the other person.

1310
00:59:40,640 --> 00:59:46,400
So Ramsey theory was actually you know

1311
00:59:43,760 --> 00:59:48,559
uh first invented or realized in in

1312
00:59:46,400 --> 00:59:50,480
Hungary where there was a Hungarian

1313
00:59:48,559 --> 00:59:54,640
sociologist who realized that you know

1314
00:59:50,480 --> 00:59:57,280
he was studying social groups of uh kids

1315
00:59:54,640 --> 01:00:01,760
and he realized that in every group of I

1316
00:59:57,280 --> 01:00:03,680
think uh 20 kids there were always four

1317
01:00:01,760 --> 01:00:05,839
a group of four people he could find who

1318
01:00:03,680 --> 01:00:07,760
all knew each other or who all didn't

1319
01:00:05,839 --> 01:00:09,920
know each other. And you might think

1320
01:00:07,760 --> 01:00:11,520
that this is a sociological phenomenon.

1321
01:00:09,920 --> 01:00:14,000
Maybe it has to do with the way kids

1322
01:00:11,520 --> 01:00:16,079
play with each other that they form some

1323
01:00:14,000 --> 01:00:18,480
sort of interconnected groups and they

1324
01:00:16,079 --> 01:00:20,559
don't know other groups. But he

1325
01:00:18,480 --> 01:00:22,880
consulted with his mathematician friends

1326
01:00:20,559 --> 01:00:24,559
including Erdos and others and he

1327
01:00:22,880 --> 01:00:26,079
realized that it wasn't a sociological

1328
01:00:24,559 --> 01:00:28,720
phenomenon. It was just the property of

1329
01:00:26,079 --> 01:00:30,880
graphs. Right? So what this is really

1330
01:00:28,720 --> 01:00:32,880
saying like the same way that we can

1331
01:00:30,880 --> 01:00:35,680
think about representing

1332
01:00:32,880 --> 01:00:37,920
um you know friendship relations with a

1333
01:00:35,680 --> 01:00:40,079
graph what we're really saying is that

1334
01:00:37,920 --> 01:00:43,119
on any graph

1335
01:00:40,079 --> 01:00:45,119
with six nodes no matter how I draw on

1336
01:00:43,119 --> 01:00:48,079
the edges and the edges represent who's

1337
01:00:45,119 --> 01:00:50,480
friends with who there must either be a

1338
01:00:48,079 --> 01:00:52,160
triangle where all the edges are present

1339
01:00:50,480 --> 01:00:53,760
or there's an anti- triangle where

1340
01:00:52,160 --> 01:00:56,880
there's a set of three and none of the

1341
01:00:53,760 --> 01:00:59,280
edges are present. So this is the basic

1342
01:00:56,880 --> 01:01:02,480
of basics of Ramssey theory is that we

1343
01:00:59,280 --> 01:01:04,400
want to show that in large enough

1344
01:01:02,480 --> 01:01:06,559
objects

1345
01:01:04,400 --> 01:01:09,440
certain kinds of ordered substructures

1346
01:01:06,559 --> 01:01:12,079
must appear because they always have to

1347
01:01:09,440 --> 01:01:14,160
happen. There's no way of avoiding it.

1348
01:01:12,079 --> 01:01:15,839
So in fact there's a pretty famous and

1349
01:01:14,160 --> 01:01:18,799
interesting example from like pop

1350
01:01:15,839 --> 01:01:21,280
culture. Um this happened like when I

1351
01:01:18,799 --> 01:01:24,240
was younger but in the you know mid 90s

1352
01:01:21,280 --> 01:01:25,920
there was a lot of um interest in

1353
01:01:24,240 --> 01:01:28,240
something called the Bible codes. Has

1354
01:01:25,920 --> 01:01:31,200
anyone heard of the Bible codes?

1355
01:01:28,240 --> 01:01:33,839
>> No. Okay. Yeah. You want to explain it?

1356
01:01:31,200 --> 01:01:35,359
>> Uh I think it's like if you like skip

1357
01:01:33,839 --> 01:01:36,559
letters in the Bible you like make

1358
01:01:35,359 --> 01:01:38,000
sentences or something.

1359
01:01:36,559 --> 01:01:40,319
>> That's right. So basically what happens

1360
01:01:38,000 --> 01:01:41,680
if you take the Hebrew translation, if

1361
01:01:40,319 --> 01:01:45,040
you take the Hebrew version of the

1362
01:01:41,680 --> 01:01:47,920
Torah, what you can do is you look at uh

1363
01:01:45,040 --> 01:01:50,400
you know evenly spaced uh characters in

1364
01:01:47,920 --> 01:01:52,319
them and if you choose the step size in

1365
01:01:50,400 --> 01:01:55,280
the right way, you can find all these

1366
01:01:52,319 --> 01:01:58,400
instances in the Torah of examples of

1367
01:01:55,280 --> 01:02:00,079
like you know uh words that cross with

1368
01:01:58,400 --> 01:02:02,240
other words which have historical

1369
01:02:00,079 --> 01:02:05,359
significance. There would be examples of

1370
01:02:02,240 --> 01:02:07,200
like famous rabbis names with the dates

1371
01:02:05,359 --> 01:02:09,680
in which they were later assassinated

1372
01:02:07,200 --> 01:02:11,359
like after the Torah was written. So

1373
01:02:09,680 --> 01:02:13,200
this was you know quite amazing because

1374
01:02:11,359 --> 01:02:16,079
you know people let their imaginations

1375
01:02:13,200 --> 01:02:17,920
run wild. Um you know they thought that

1376
01:02:16,079 --> 01:02:20,960
maybe the Torah was predicting the

1377
01:02:17,920 --> 01:02:23,839
future right in arithmetic progressions

1378
01:02:20,960 --> 01:02:26,160
in in Hebrew like uh you know you could

1379
01:02:23,839 --> 01:02:29,040
certainly write some bad movies about

1380
01:02:26,160 --> 01:02:31,760
it. uh but it turned out that it was

1381
01:02:29,040 --> 01:02:33,440
really just um you know Ramsay theory in

1382
01:02:31,760 --> 01:02:36,000
disguise and the the things that people

1383
01:02:33,440 --> 01:02:38,160
found weren't statistically significant

1384
01:02:36,000 --> 01:02:39,520
that in fact uh you could find the same

1385
01:02:38,160 --> 01:02:41,440
types of things in the Hebrew

1386
01:02:39,520 --> 01:02:43,599
translation of war and peace. So that

1387
01:02:41,440 --> 01:02:44,720
was an interesting rejoinder to it but

1388
01:02:43,599 --> 01:02:46,880
that's the kind of thing we're going to

1389
01:02:44,720 --> 01:02:49,520
do with it today. Let me tell you about

1390
01:02:46,880 --> 01:02:52,160
one example of structure that has to do

1391
01:02:49,520 --> 01:02:53,920
with arithmetic progressions and we're

1392
01:02:52,160 --> 01:02:56,000
going to use the probabilistic method to

1393
01:02:53,920 --> 01:02:58,880
prove type you know types of lower

1394
01:02:56,000 --> 01:03:01,520
bounds on these quantities or at least

1395
01:02:58,880 --> 01:03:03,760
very strong lower bounds. So let me tell

1396
01:03:01,520 --> 01:03:05,920
you the last topic for today is uh

1397
01:03:03,760 --> 01:03:08,920
something called Vander Warden's

1398
01:03:05,920 --> 01:03:08,920
theorem.

1399
01:03:10,319 --> 01:03:18,240
So let me first give you a definition.

1400
01:03:14,319 --> 01:03:21,960
So a k term

1401
01:03:18,240 --> 01:03:21,960
arithmetic progression

1402
01:03:23,920 --> 01:03:29,599
is just a very particular type of

1403
01:03:26,559 --> 01:03:32,720
structured subset.

1404
01:03:29,599 --> 01:03:36,240
So it's a set of integers

1405
01:03:32,720 --> 01:03:38,960
of the following form.

1406
01:03:36,240 --> 01:03:41,520
And I'll call it Q subAB because I'm

1407
01:03:38,960 --> 01:03:46,240
going to use it later. But it's just the

1408
01:03:41,520 --> 01:03:49,359
set of integers that looks like a a + b

1409
01:03:46,240 --> 01:03:55,280
a + 2 b

1410
01:03:49,359 --> 01:03:57,599
all the way up to a + k -1 b.

1411
01:03:55,280 --> 01:04:00,400
So this is an arithmetic progression.

1412
01:03:57,599 --> 01:04:04,000
You start off with some base number a

1413
01:04:00,400 --> 01:04:06,960
and then your steps are of size b and

1414
01:04:04,000 --> 01:04:08,559
then you go for k steps. So that's an

1415
01:04:06,960 --> 01:04:09,920
arithmetic progression. This was the

1416
01:04:08,559 --> 01:04:12,400
kind of thing that they were using in

1417
01:04:09,920 --> 01:04:14,079
the Bible codes because you would look

1418
01:04:12,400 --> 01:04:16,400
at arithmetic progressions and

1419
01:04:14,079 --> 01:04:19,440
concatenate the symbols you get at those

1420
01:04:16,400 --> 01:04:21,839
positions together.

1421
01:04:19,440 --> 01:04:23,200
And so now I can tell you this Vander

1422
01:04:21,839 --> 01:04:26,079
Warden's theorem. We're not going to

1423
01:04:23,200 --> 01:04:27,680
prove it. The proof is in the notes. Uh

1424
01:04:26,079 --> 01:04:29,839
but we're going to prove lower bounds

1425
01:04:27,680 --> 01:04:34,480
for it. So here's a really cool

1426
01:04:29,839 --> 01:04:38,799
statement. So for every k you give me

1427
01:04:34,480 --> 01:04:41,520
what I claim is that there is

1428
01:04:38,799 --> 01:04:44,160
an n

1429
01:04:41,520 --> 01:04:47,799
such that

1430
01:04:44,160 --> 01:04:47,799
any two coloring

1431
01:04:50,160 --> 01:04:56,640
of the integers one two up to n. So

1432
01:04:55,119 --> 01:04:59,200
before I get to the theorem statement,

1433
01:04:56,640 --> 01:05:02,880
right? What's going on is I want to find

1434
01:04:59,200 --> 01:05:05,119
a kerm arithmetic progression.

1435
01:05:02,880 --> 01:05:08,400
Uh and what I'm going to do is you know

1436
01:05:05,119 --> 01:05:10,079
you're going to fix some n

1437
01:05:08,400 --> 01:05:12,559
and then once you look at the integers

1438
01:05:10,079 --> 01:05:14,160
from 1 2 all the way up to n you're

1439
01:05:12,559 --> 01:05:17,359
going to color these integers with

1440
01:05:14,160 --> 01:05:20,400
either red or blue. And what I'm looking

1441
01:05:17,359 --> 01:05:23,359
for is what's called a monochromatic

1442
01:05:20,400 --> 01:05:25,359
arithmetic progression. So I want some

1443
01:05:23,359 --> 01:05:28,000
arithmetic progression of this form like

1444
01:05:25,359 --> 01:05:30,160
QAB but with the property that I look at

1445
01:05:28,000 --> 01:05:32,400
the colors of the integers along the

1446
01:05:30,160 --> 01:05:34,240
sequence that they all should be the

1447
01:05:32,400 --> 01:05:36,720
same color.

1448
01:05:34,240 --> 01:05:39,720
So this necessarily contains a

1449
01:05:36,720 --> 01:05:39,720
monochromatic

1450
01:05:42,240 --> 01:05:47,760
K term

1451
01:05:44,319 --> 01:05:49,599
AP arithmetic progression.

1452
01:05:47,760 --> 01:05:51,039
So this is the statement right again

1453
01:05:49,599 --> 01:05:53,440
there are a lot of quantifiers in this

1454
01:05:51,039 --> 01:05:55,839
so let's make sure we understand it I

1455
01:05:53,440 --> 01:05:58,400
want to find some k term arithmetic

1456
01:05:55,839 --> 01:06:01,760
progression one that's monochromatic for

1457
01:05:58,400 --> 01:06:05,280
whatever k I choose there's some large

1458
01:06:01,760 --> 01:06:08,880
enough n so that no matter how you two

1459
01:06:05,280 --> 01:06:11,599
color the integers from one two up to n

1460
01:06:08,880 --> 01:06:14,079
there's no way to avoid it somewhere in

1461
01:06:11,599 --> 01:06:16,720
that set is sitting some kind of

1462
01:06:14,079 --> 01:06:19,039
entirely red or entirely blue arithmetic

1463
01:06:16,720 --> 01:06:21,119
progression. So this is a bit of a

1464
01:06:19,039 --> 01:06:22,960
mouthful, but this is one example of,

1465
01:06:21,119 --> 01:06:25,680
you know, a much more interesting

1466
01:06:22,960 --> 01:06:27,680
version of Ramsey theory is that any

1467
01:06:25,680 --> 01:06:29,920
large enough object, which in this case

1468
01:06:27,680 --> 01:06:33,119
is a twocoloring of the integers from 1

1469
01:06:29,920 --> 01:06:35,520
2 up to n must necessarily contain this

1470
01:06:33,119 --> 01:06:38,400
ordered substructure, which in our case

1471
01:06:35,520 --> 01:06:40,480
is this monochromatic kerm arithmetic

1472
01:06:38,400 --> 01:06:42,000
progression. So this has a lot of

1473
01:06:40,480 --> 01:06:45,200
quantifiers. Are there any questions

1474
01:06:42,000 --> 01:06:46,640
about this?

1475
01:06:45,200 --> 01:06:50,319
Make sense?

1476
01:06:46,640 --> 01:06:52,240
Okay, so uh you know that's Vander

1477
01:06:50,319 --> 01:06:54,720
Warden's theorem. The proof of it is not

1478
01:06:52,240 --> 01:06:57,119
too hard, but it's just doesn't involve

1479
01:06:54,720 --> 01:07:00,160
any probability. So we might cover it

1480
01:06:57,119 --> 01:07:02,400
later. But um it turns out that

1481
01:07:00,160 --> 01:07:04,720
probability, especially using the

1482
01:07:02,400 --> 01:07:06,400
probabilistic method, is a great way to

1483
01:07:04,720 --> 01:07:08,480
prove lower bounds for this kind of

1484
01:07:06,400 --> 01:07:10,640
theorem.

1485
01:07:08,480 --> 01:07:17,880
So let's ask for quantitative things.

1486
01:07:10,640 --> 01:07:17,880
Let's let W of K be the smallest N

1487
01:07:19,599 --> 01:07:24,920
such that the property holds.

1488
01:07:27,119 --> 01:07:31,920
Now you have to be careful and unpack

1489
01:07:28,720 --> 01:07:33,520
this, right? W of K is the smallest N.

1490
01:07:31,920 --> 01:07:35,920
So that which property holds the

1491
01:07:33,520 --> 01:07:38,799
property that every two coloring of the

1492
01:07:35,920 --> 01:07:41,359
integers from one up to n necessarily

1493
01:07:38,799 --> 01:07:43,440
has a k term arithmetic progression. So

1494
01:07:41,359 --> 01:07:45,440
this property has an extra quantifier

1495
01:07:43,440 --> 01:07:49,280
because I'm not telling you what the two

1496
01:07:45,440 --> 01:07:52,920
coloring is. Right? Now um one of the

1497
01:07:49,280 --> 01:07:52,920
things you can show

1498
01:07:54,640 --> 01:08:00,640
that you can reason about small values

1499
01:07:58,480 --> 01:08:02,400
of

1500
01:08:00,640 --> 01:08:04,480
these types of quantities. So one of the

1501
01:08:02,400 --> 01:08:06,720
concrete things you can do is you can

1502
01:08:04,480 --> 01:08:09,359
ask what's the smallest n so that every

1503
01:08:06,720 --> 01:08:11,280
two coloring has a three-term arithmetic

1504
01:08:09,359 --> 01:08:13,760
progression.

1505
01:08:11,280 --> 01:08:17,520
And it turns out to not be super easy to

1506
01:08:13,760 --> 01:08:20,640
show this but one side is easy. So the

1507
01:08:17,520 --> 01:08:23,359
easy part is just to show a lower bound.

1508
01:08:20,640 --> 01:08:26,159
So we're going to prove that W of three

1509
01:08:23,359 --> 01:08:28,960
is at least nine. And the way that you

1510
01:08:26,159 --> 01:08:32,239
do this is you just construct a valid

1511
01:08:28,960 --> 01:08:35,520
twocoloring that avoids having a

1512
01:08:32,239 --> 01:08:37,520
three-term arithmetic progression. So

1513
01:08:35,520 --> 01:08:40,560
for example, maybe all of these things I

1514
01:08:37,520 --> 01:08:43,199
circle are red and everything I don't

1515
01:08:40,560 --> 01:08:45,279
circle is blue. So you can check that

1516
01:08:43,199 --> 01:08:47,920
this is a coloring of the integers from

1517
01:08:45,279 --> 01:08:49,679
1, two, all the way up to eight. And you

1518
01:08:47,920 --> 01:08:52,080
can just check by trying out different

1519
01:08:49,679 --> 01:08:55,839
choices of a and b that there is no

1520
01:08:52,080 --> 01:08:58,080
three-term arithmetic progression.

1521
01:08:55,839 --> 01:09:00,480
The fact that, you know, everything

1522
01:08:58,080 --> 01:09:02,799
that's larger than this, right, is a lot

1523
01:09:00,480 --> 01:09:04,960
harder to prove because I would have to

1524
01:09:02,799 --> 01:09:07,679
argue that when I add another number to

1525
01:09:04,960 --> 01:09:10,000
this list, not just this coloring has a

1526
01:09:07,679 --> 01:09:12,000
three-term arithmetic progression, but

1527
01:09:10,000 --> 01:09:14,080
any other twocoloring has a three-term

1528
01:09:12,000 --> 01:09:15,839
arithmetic progression. So, it involves

1529
01:09:14,080 --> 01:09:17,600
like a huge amount of brute force

1530
01:09:15,839 --> 01:09:19,440
computer search to do these kinds of

1531
01:09:17,600 --> 01:09:21,520
things.

1532
01:09:19,440 --> 01:09:22,799
But what we're going to do instead is

1533
01:09:21,520 --> 01:09:25,520
we're going to prove the following

1534
01:09:22,799 --> 01:09:27,839
theorem, which is a beautiful theorem in

1535
01:09:25,520 --> 01:09:31,040
its own right, which is we're going to

1536
01:09:27,839 --> 01:09:33,440
show nice lower bounds on W K that are

1537
01:09:31,040 --> 01:09:35,279
going to kick in for large K. So they

1538
01:09:33,440 --> 01:09:37,440
won't be tight for small values, but

1539
01:09:35,279 --> 01:09:39,520
they'll give us a good handle on, you

1540
01:09:37,440 --> 01:09:42,400
know, how large the N needs to be in

1541
01:09:39,520 --> 01:09:44,480
this Vander Warden's theorem. So here's

1542
01:09:42,400 --> 01:09:46,239
the theorem we're going to prove and

1543
01:09:44,480 --> 01:09:52,640
what remains.

1544
01:09:46,239 --> 01:09:55,520
Um what I claim is that for any k

1545
01:09:52,640 --> 01:10:00,159
w of k the smallest n such that this

1546
01:09:55,520 --> 01:10:05,760
property holds is at least<unk> of k -1

1547
01:10:00,159 --> 01:10:06,880
* 2 to the k minus one / 2.

1548
01:10:05,760 --> 01:10:08,640
So that's the thing we're going to

1549
01:10:06,880 --> 01:10:10,640
prove.

1550
01:10:08,640 --> 01:10:14,400
And the crucial thing about this which I

1551
01:10:10,640 --> 01:10:17,400
really want to explain is that is the

1552
01:10:14,400 --> 01:10:17,400
strategy.

1553
01:10:17,840 --> 01:10:23,560
What we're going to show is that a

1554
01:10:20,080 --> 01:10:23,560
random coloring

1555
01:10:26,239 --> 01:10:31,440
you know for the choice of n equal to

1556
01:10:28,159 --> 01:10:34,159
this has positive probability

1557
01:10:31,440 --> 01:10:37,480
probability greater than zero

1558
01:10:34,159 --> 01:10:37,480
of having

1559
01:10:38,159 --> 01:10:43,360
no k term

1560
01:10:41,520 --> 01:10:45,280
a.

1561
01:10:43,360 --> 01:10:47,679
So now this is making good on some of

1562
01:10:45,280 --> 01:10:49,920
the promises I made here. Right? See the

1563
01:10:47,679 --> 01:10:51,920
whole point of the probabilistic method

1564
01:10:49,920 --> 01:10:54,480
is that we want to show that certain

1565
01:10:51,920 --> 01:10:57,920
things exist even if it's hard to

1566
01:10:54,480 --> 01:11:00,239
construct them by hand. Right? So you

1567
01:10:57,920 --> 01:11:02,480
know in order to prove this theorem

1568
01:11:00,239 --> 01:11:04,239
really I have to choose some n that's

1569
01:11:02,480 --> 01:11:07,760
equal to the right hand side that's

1570
01:11:04,239 --> 01:11:11,600
equal to the roo<unk> of k minus one* 2

1571
01:11:07,760 --> 01:11:13,600
k -1 / 2. If I choose this as my n then

1572
01:11:11,600 --> 01:11:16,480
the thing I have to construct and build

1573
01:11:13,600 --> 01:11:18,800
is what is the valid two color. That's

1574
01:11:16,480 --> 01:11:21,040
very difficult, right? I could try some

1575
01:11:18,800 --> 01:11:23,600
things. They might or might not work.

1576
01:11:21,040 --> 01:11:25,120
Uh, and then I might get stuck. But it

1577
01:11:23,600 --> 01:11:26,960
turns out that the way we're going to

1578
01:11:25,120 --> 01:11:29,280
show that there is a coloring that

1579
01:11:26,960 --> 01:11:31,440
avoids kter term arithmetic progressions

1580
01:11:29,280 --> 01:11:34,080
is just by showing that a random one

1581
01:11:31,440 --> 01:11:36,560
works with positive probability. So

1582
01:11:34,080 --> 01:11:39,040
that's what the probabilistic method is.

1583
01:11:36,560 --> 01:11:41,440
And uh, you know, let's execute the

1584
01:11:39,040 --> 01:11:44,960
strategy. So just to make sure we're on

1585
01:11:41,440 --> 01:11:47,360
the same page, what I'm going to do is

1586
01:11:44,960 --> 01:11:49,920
I'm going to consider

1587
01:11:47,360 --> 01:11:55,000
a random variable X that's going to be

1588
01:11:49,920 --> 01:11:55,000
equal to the number of monochromatic

1589
01:11:56,560 --> 01:12:02,480
K term

1590
01:11:59,360 --> 01:12:04,480
APS. I'm just going to count. So you

1591
01:12:02,480 --> 01:12:06,640
give me a random coloring. The dumbest

1592
01:12:04,480 --> 01:12:08,640
thing we could do is we randomly decide

1593
01:12:06,640 --> 01:12:10,400
independently for each integer whether

1594
01:12:08,640 --> 01:12:12,480
it's red or blue. And we're going to

1595
01:12:10,400 --> 01:12:14,640
show that that works. And we're going to

1596
01:12:12,480 --> 01:12:16,800
be interested in this random variable X.

1597
01:12:14,640 --> 01:12:20,800
That's the number of monochromatic K

1598
01:12:16,800 --> 01:12:22,640
term APS in my random coloring.

1599
01:12:20,800 --> 01:12:24,640
Now

1600
01:12:22,640 --> 01:12:26,719
the basis for you know making the

1601
01:12:24,640 --> 01:12:28,800
strategy make sense is really this very

1602
01:12:26,719 --> 01:12:30,320
simple lema

1603
01:12:28,800 --> 01:12:32,560
that's going to remind you of things we

1604
01:12:30,320 --> 01:12:34,159
did earlier in lecture. Right? what I

1605
01:12:32,560 --> 01:12:36,480
claim and this is just a general

1606
01:12:34,159 --> 01:12:38,000
statement but it'll make it'll explain

1607
01:12:36,480 --> 01:12:42,400
why the strategy makes sense in the

1608
01:12:38,000 --> 01:12:45,800
first place. Suppose X is a non-gative

1609
01:12:42,400 --> 01:12:45,800
random variable

1610
01:12:46,719 --> 01:12:53,640
and let's say it's integer valued

1611
01:12:50,239 --> 01:12:53,640
random variable

1612
01:12:54,640 --> 01:13:03,199
and let's say that the expectation of X

1613
01:12:58,960 --> 01:13:07,440
is less than one then what I claim is

1614
01:13:03,199 --> 01:13:09,199
that the probability that X equals Z is

1615
01:13:07,440 --> 01:13:11,760
strictly positive.

1616
01:13:09,199 --> 01:13:13,360
So this is the basis for our strategy

1617
01:13:11,760 --> 01:13:16,000
because the way we're going to show that

1618
01:13:13,360 --> 01:13:17,600
a good two-coloring exists is we're

1619
01:13:16,000 --> 01:13:19,120
going to look at this random variable X

1620
01:13:17,600 --> 01:13:21,920
that's non- negative. It counts the

1621
01:13:19,120 --> 01:13:24,480
number of monochromatic kerm APS it's

1622
01:13:21,920 --> 01:13:27,280
integer valued and as soon as we can

1623
01:13:24,480 --> 01:13:28,880
show its expectation is less than one

1624
01:13:27,280 --> 01:13:30,640
that means that the probability that

1625
01:13:28,880 --> 01:13:34,640
it's actually equal to zero and there's

1626
01:13:30,640 --> 01:13:37,360
no k term APS is strictly positive. So

1627
01:13:34,640 --> 01:13:39,199
this is the basis for our strategy. So

1628
01:13:37,360 --> 01:13:42,320
let's prove this lema. This lema is

1629
01:13:39,199 --> 01:13:44,800
super simple. But then let's execute

1630
01:13:42,320 --> 01:13:47,040
using the strategy in the case of Vander

1631
01:13:44,800 --> 01:13:48,400
Warden's theorem.

1632
01:13:47,040 --> 01:13:50,960
So we can just write out the

1633
01:13:48,400 --> 01:13:54,080
expectation, right? So the expectation

1634
01:13:50,960 --> 01:13:57,360
of X because it's integer valued is the

1635
01:13:54,080 --> 01:14:02,000
sum from I= 0 to infinity of the

1636
01:13:57,360 --> 01:14:04,560
probability that X equals I * I. But

1637
01:14:02,000 --> 01:14:07,679
this is less than or this is um lower

1638
01:14:04,560 --> 01:14:10,080
bounded by the sum from i equals 1 to

1639
01:14:07,679 --> 01:14:12,880
infinity. So I've dropped the first term

1640
01:14:10,080 --> 01:14:15,520
and then I'm going to drop the i because

1641
01:14:12,880 --> 01:14:17,679
each of these i's is at least one.

1642
01:14:15,520 --> 01:14:20,239
Right? And this quantity right here on

1643
01:14:17,679 --> 01:14:24,239
the right hand side is just one minus

1644
01:14:20,239 --> 01:14:25,760
the probability that x equals zero by

1645
01:14:24,239 --> 01:14:28,400
definition.

1646
01:14:25,760 --> 01:14:31,920
So now if I rearrange this I'm going to

1647
01:14:28,400 --> 01:14:34,400
get that the probability of X uh you

1648
01:14:31,920 --> 01:14:36,719
know being equal to zero is lower

1649
01:14:34,400 --> 01:14:39,440
bounded by one minus the expectation of

1650
01:14:36,719 --> 01:14:42,440
X and the expectation of X is less than

1651
01:14:39,440 --> 01:14:42,440
one.

1652
01:14:42,800 --> 01:14:47,840
So that simple proof is the basis for

1653
01:14:45,040 --> 01:14:50,880
our strategy because all we have to do

1654
01:14:47,840 --> 01:14:55,520
now is we just have to compute what the

1655
01:14:50,880 --> 01:14:57,840
expectation of X is. I told you what

1656
01:14:55,520 --> 01:15:00,080
X represents, what random variable it

1657
01:14:57,840 --> 01:15:02,560
is. I told you the fact that we're doing

1658
01:15:00,080 --> 01:15:04,800
a random coloring. And I told you what

1659
01:15:02,560 --> 01:15:07,440
the strategy is of how to reason about

1660
01:15:04,800 --> 01:15:09,280
the probability that X is zero. So all

1661
01:15:07,440 --> 01:15:12,239
that's left is really just to compute

1662
01:15:09,280 --> 01:15:14,480
this expectation of X and hope that it's

1663
01:15:12,239 --> 01:15:18,360
less than one.

1664
01:15:14,480 --> 01:15:18,360
So let's just compute

1665
01:15:18,640 --> 01:15:26,719
expectation of X. So I'm going to let

1666
01:15:23,280 --> 01:15:31,600
I AB denote the relevant indicator

1667
01:15:26,719 --> 01:15:35,239
variables. It'll be one if QAB

1668
01:15:31,600 --> 01:15:35,239
is monochromatic

1669
01:15:36,080 --> 01:15:40,400
and otherwise it'll be zero because

1670
01:15:39,040 --> 01:15:42,320
these are just the events that are going

1671
01:15:40,400 --> 01:15:45,199
to help me get a handle on what my

1672
01:15:42,320 --> 01:15:48,080
random variable X is. X is just summing

1673
01:15:45,199 --> 01:15:51,280
up all of these indicator variables. So

1674
01:15:48,080 --> 01:15:54,719
in particular then X the thing I want to

1675
01:15:51,280 --> 01:16:00,480
keep track of is the sum over all AB

1676
01:15:54,719 --> 01:16:03,120
pairs such that QAB is a subset of 1 2

1677
01:16:00,480 --> 01:16:05,520
up to N. Those are the only arithmetic

1678
01:16:03,120 --> 01:16:09,280
progressions I'll consider

1679
01:16:05,520 --> 01:16:12,480
of this quantity I AB.

1680
01:16:09,280 --> 01:16:14,480
And now we're good, right? Because what

1681
01:16:12,480 --> 01:16:18,560
I claim

1682
01:16:14,480 --> 01:16:20,880
is that the expectation of IAB, the

1683
01:16:18,560 --> 01:16:23,840
probability that you know this event

1684
01:16:20,880 --> 01:16:26,960
happens that this arithmetic progression

1685
01:16:23,840 --> 01:16:29,040
QAB is monochromatic.

1686
01:16:26,960 --> 01:16:32,719
I claim that this is very simple to

1687
01:16:29,040 --> 01:16:34,320
compute. It's equal to 1 / 2 the K minus

1688
01:16:32,719 --> 01:16:35,760
one.

1689
01:16:34,320 --> 01:16:38,960
So just to make sure we're on the same

1690
01:16:35,760 --> 01:16:43,520
page, right? So IB is the indicator

1691
01:16:38,960 --> 01:16:45,920
event for QAB being monochromatic.

1692
01:16:43,520 --> 01:16:48,400
Remember Q is a K term arithmetic

1693
01:16:45,920 --> 01:16:50,560
progression. So why is this probability

1694
01:16:48,400 --> 01:16:53,679
true? What's the you know oneline proof

1695
01:16:50,560 --> 01:16:55,840
of this?

1696
01:16:53,679 --> 01:16:57,440
I'm fixing a particular arithmetic

1697
01:16:55,840 --> 01:16:58,560
progression.

1698
01:16:57,440 --> 01:17:00,640
Why is the chance that it's

1699
01:16:58,560 --> 01:17:02,320
monochromatic going down exponentially

1700
01:17:00,640 --> 01:17:05,320
with the length of the arithmetic

1701
01:17:02,320 --> 01:17:05,320
progression?

1702
01:17:05,920 --> 01:17:09,560
Who can help me out?

1703
01:17:15,280 --> 01:17:17,040
>> Yeah.

1704
01:17:15,840 --> 01:17:18,880
>> Choose the color of each term

1705
01:17:17,040 --> 01:17:20,880
independently with probability half and

1706
01:17:18,880 --> 01:17:22,000
then multiply by two because you have

1707
01:17:20,880 --> 01:17:24,239
two different

1708
01:17:22,000 --> 01:17:27,360
>> Perfect. That's exactly right. So the

1709
01:17:24,239 --> 01:17:31,120
proof of this is exactly what he said

1710
01:17:27,360 --> 01:17:33,199
which is that once we pick the color

1711
01:17:31,120 --> 01:17:35,360
the first color

1712
01:17:33,199 --> 01:17:37,679
I'm just rephrasing the proof slightly.

1713
01:17:35,360 --> 01:17:39,360
So, we just pick the first color, namely

1714
01:17:37,679 --> 01:17:41,520
the color of A, the first term that

1715
01:17:39,360 --> 01:17:43,280
shows up in our arithmetic progression.

1716
01:17:41,520 --> 01:17:45,840
The only choice, you know, let's say A

1717
01:17:43,280 --> 01:17:48,159
was red. Then A plus B had better be

1718
01:17:45,840 --> 01:17:50,400
red. A plus 2 B it better be red. A plus

1719
01:17:48,159 --> 01:17:53,440
3 B and so on.

1720
01:17:50,400 --> 01:17:57,000
Then all the other colors must match.

1721
01:17:53,440 --> 01:17:57,000
All the other colors

1722
01:17:58,320 --> 01:18:04,679
in QAB

1723
01:18:01,199 --> 01:18:04,679
must match.

1724
01:18:04,960 --> 01:18:10,080
And that's the proof because they're k

1725
01:18:07,199 --> 01:18:12,800
minus one other things. So now we're in

1726
01:18:10,080 --> 01:18:14,640
good shape. We just have one very last

1727
01:18:12,800 --> 01:18:16,960
ingredient and then we'll get our bound

1728
01:18:14,640 --> 01:18:21,440
to follow which is I have to tell you

1729
01:18:16,960 --> 01:18:25,440
how many qabs there are. Right.

1730
01:18:21,440 --> 01:18:29,480
Lastly, I claim

1731
01:18:25,440 --> 01:18:29,480
the number of valid

1732
01:18:29,760 --> 01:18:34,320
AB pairs which induce an arithmetic

1733
01:18:32,320 --> 01:18:40,080
progression which you know stays in the

1734
01:18:34,320 --> 01:18:42,640
integers from 1 to n is at most n * n /

1735
01:18:40,080 --> 01:18:44,480
k minus one. So the way to think about

1736
01:18:42,640 --> 01:18:46,480
it, remember our arithmetic progression

1737
01:18:44,480 --> 01:18:49,840
starts at a and then it goes a plus b

1738
01:18:46,480 --> 01:18:52,719
and a + 2 b all the way up to a plus k

1739
01:18:49,840 --> 01:18:54,719
minus 1 * b. So in order for this

1740
01:18:52,719 --> 01:18:57,520
arithmetic progression to stay in the

1741
01:18:54,719 --> 01:18:59,920
integers from 1 to n, I better choose my

1742
01:18:57,520 --> 01:19:02,080
a to be at most n otherwise it's not

1743
01:18:59,920 --> 01:19:04,719
going to be in the set. And then my b,

1744
01:19:02,080 --> 01:19:06,400
it better be at most n over k minus one

1745
01:19:04,719 --> 01:19:06,480
because I'm going to add b k k k k k k k

1746
01:19:06,400 --> 01:19:07,280
k k k k k k k k k k k k k k k k k k k k

1747
01:19:06,480 --> 01:19:09,679
k k k k k k k k k k k k k k minus one

1748
01:19:07,280 --> 01:19:12,239
times. So if it were larger than this, I

1749
01:19:09,679 --> 01:19:15,360
would fall outside the set. So putting

1750
01:19:12,239 --> 01:19:21,440
this all together, we know that the

1751
01:19:15,360 --> 01:19:23,280
expectation of X is at most n^2 over K

1752
01:19:21,440 --> 01:19:26,320
minus one. That's the number of valid

1753
01:19:23,280 --> 01:19:30,719
things times the expectation of each of

1754
01:19:26,320 --> 01:19:33,600
these IABs, which is 1 / 2 KUS1.

1755
01:19:30,719 --> 01:19:37,440
And now you can check that that implies

1756
01:19:33,600 --> 01:19:43,760
that if n is less than this quantity I

1757
01:19:37,440 --> 01:19:46,320
told you k minus one time 2 k -1 / 2

1758
01:19:43,760 --> 01:19:50,800
then it implies that the expectation of

1759
01:19:46,320 --> 01:19:52,800
x is less than one. So that's our proof.

1760
01:19:50,800 --> 01:19:54,560
So this is a very beautiful but subtle

1761
01:19:52,800 --> 01:19:57,520
proof right because of the way we're

1762
01:19:54,560 --> 01:19:59,360
using probability. I want to show that w

1763
01:19:57,520 --> 01:20:01,440
of k is large because I want to

1764
01:19:59,360 --> 01:20:04,400
construct a valid two coloring that

1765
01:20:01,440 --> 01:20:05,760
avoids all arithmetic progressions. What

1766
01:20:04,400 --> 01:20:08,320
I'm going to do is I'm going to reason

1767
01:20:05,760 --> 01:20:11,040
about the random variable that counts

1768
01:20:08,320 --> 01:20:12,880
the number of k term aps as a way to

1769
01:20:11,040 --> 01:20:15,040
argue that there is a good two coloring

1770
01:20:12,880 --> 01:20:16,880
to begin with and the rest of it is a

1771
01:20:15,040 --> 01:20:19,440
computation using linearity of

1772
01:20:16,880 --> 01:20:21,520
expectation. But that allows us to prove

1773
01:20:19,440 --> 01:20:23,920
that these exotic objects which are hard

1774
01:20:21,520 --> 01:20:26,880
to actually build and construct must

1775
01:20:23,920 --> 01:20:28,080
exist even if we can't find them.

1776
01:20:26,880 --> 01:20:29,920
So that's one of the cool things about

1777
01:20:28,080 --> 01:20:32,480
the probabilistic method. Sometimes you

1778
01:20:29,920 --> 01:20:34,239
can show you know very exotic things

1779
01:20:32,480 --> 01:20:36,320
exist even though we don't know how to

1780
01:20:34,239 --> 01:20:39,120
build them from scratch and we'll do

1781
01:20:36,320 --> 01:20:41,440
some more applications of this uh later

1782
01:20:39,120 --> 01:20:43,600
too and next time and we'll also cover

1783
01:20:41,440 --> 01:20:47,960
the churnoff bound. So we'll stop there

1784
01:20:43,600 --> 01:20:47,960
and I'll see you guys on Thursday.


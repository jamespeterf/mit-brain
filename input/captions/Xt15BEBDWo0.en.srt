1
00:00:00,080 --> 00:00:04,880
All righty. So, thank y'all for being

2
00:00:02,000 --> 00:00:07,040
here. Uh we can just have a very as a

3
00:00:04,880 --> 00:00:10,160
casual presentation. Uh questions can

4
00:00:07,040 --> 00:00:11,759
come in basically um almost anytime. Uh

5
00:00:10,160 --> 00:00:13,920
so just feel free to raise your hand and

6
00:00:11,759 --> 00:00:16,320
um I'll get to you. So yeah, very happy

7
00:00:13,920 --> 00:00:19,680
to be here again and uh we can get

8
00:00:16,320 --> 00:00:21,840
started. So we see AI development um and

9
00:00:19,680 --> 00:00:23,600
efforts towards regulating these systems

10
00:00:21,840 --> 00:00:25,920
um increasingly becoming centralized in

11
00:00:23,600 --> 00:00:28,679
western countries um despite the impacts

12
00:00:25,920 --> 00:00:31,039
of AI um and other systems transcending

13
00:00:28,679 --> 00:00:32,800
borders. We see western corporations

14
00:00:31,039 --> 00:00:35,280
that are at the frontier uh quote

15
00:00:32,800 --> 00:00:37,040
unquote of AI development be largely

16
00:00:35,280 --> 00:00:39,120
reliant on the African continent um

17
00:00:37,040 --> 00:00:41,920
alongside others um for natural

18
00:00:39,120 --> 00:00:44,239
resources like tantelum, cobalt um and

19
00:00:41,920 --> 00:00:45,920
tungsten uh which form the GPUs that

20
00:00:44,239 --> 00:00:48,399
power these large language models or

21
00:00:45,920 --> 00:00:50,559
large AI models excuse me um also known

22
00:00:48,399 --> 00:00:52,480
as foundation models as coined by

23
00:00:50,559 --> 00:00:54,879
Stanford. And we also see these human

24
00:00:52,480 --> 00:00:57,520
resources uh particularly from data

25
00:00:54,879 --> 00:00:59,680
annotation and also content moderation

26
00:00:57,520 --> 00:01:02,879
um which are used to train um and refine

27
00:00:59,680 --> 00:01:04,960
AI systems. Given that we see Africa um

28
00:01:02,879 --> 00:01:07,680
or Africa is seen um as the next

29
00:01:04,960 --> 00:01:09,119
frontier um for AI development um also

30
00:01:07,680 --> 00:01:11,439
something that Sam Alman recently

31
00:01:09,119 --> 00:01:13,439
mentioned uh we see that digital

32
00:01:11,439 --> 00:01:15,920
resources like data that advance the

33
00:01:13,439 --> 00:01:18,240
capabilities of AI um will likely become

34
00:01:15,920 --> 00:01:20,320
the next commodity that's exploited um

35
00:01:18,240 --> 00:01:22,799
by foreign entities. And so this could

36
00:01:20,320 --> 00:01:26,159
potentially fuel, if not already, this

37
00:01:22,799 --> 00:01:28,000
new era of techno neo colonialism. We

38
00:01:26,159 --> 00:01:30,320
see that these current concerns, excuse

39
00:01:28,000 --> 00:01:32,799
me, um along with issues of bias,

40
00:01:30,320 --> 00:01:35,439
disinformation, uh climate impacts, um

41
00:01:32,799 --> 00:01:38,000
and economic inequality, uh elevate a

42
00:01:35,439 --> 00:01:40,159
need for comprehensive and a robust

43
00:01:38,000 --> 00:01:42,720
alongside harmonized AI and data

44
00:01:40,159 --> 00:01:44,560
regulation efforts across Africa. Um

45
00:01:42,720 --> 00:01:46,399
this will this talk will talk about many

46
00:01:44,560 --> 00:01:48,640
of these aspects particularly focusing

47
00:01:46,399 --> 00:01:51,119
on AI and data governance the bridging

48
00:01:48,640 --> 00:01:53,600
the AI ecosystem in the continent um and

49
00:01:51,119 --> 00:01:55,920
then also thinking about some priorities

50
00:01:53,600 --> 00:01:58,600
um to democratize African participation

51
00:01:55,920 --> 00:02:01,200
um in AI development and

52
00:01:58,600 --> 00:02:03,680
governance. Um so we see that when it

53
00:02:01,200 --> 00:02:05,439
comes to AI progress across the world,

54
00:02:03,680 --> 00:02:07,759
we AI development is primarily

55
00:02:05,439 --> 00:02:10,800
centralized in countries like China, uh

56
00:02:07,759 --> 00:02:12,959
the US, uh Canada, the UK, and also

57
00:02:10,800 --> 00:02:14,720
those throughout the um the EU EU,

58
00:02:12,959 --> 00:02:17,280
excuse me. Uh this includes countries

59
00:02:14,720 --> 00:02:18,959
like France um and Germany. However,

60
00:02:17,280 --> 00:02:21,680
we've begun to also see a lot of

61
00:02:18,959 --> 00:02:23,440
progress um from African grassroots AI

62
00:02:21,680 --> 00:02:24,879
and machine learning communities that

63
00:02:23,440 --> 00:02:27,520
have really helped to fill in some of

64
00:02:24,879 --> 00:02:29,040
these capacity gaps um of accessing

65
00:02:27,520 --> 00:02:31,200
traditional AI and machine learning

66
00:02:29,040 --> 00:02:33,200
education uh particularly from these

67
00:02:31,200 --> 00:02:35,440
universities and also tertiary uh

68
00:02:33,200 --> 00:02:38,959
institutions that offer these masters

69
00:02:35,440 --> 00:02:40,640
and PhD level courses and programs. So

70
00:02:38,959 --> 00:02:43,040
across the continent uh we see

71
00:02:40,640 --> 00:02:45,840
organizations like Masakane um and Ghana

72
00:02:43,040 --> 00:02:48,720
NLP developing data sets and machine

73
00:02:45,840 --> 00:02:51,280
translation tools to help expand access

74
00:02:48,720 --> 00:02:53,120
to low resource African languages. We

75
00:02:51,280 --> 00:02:56,000
also see efforts like deep learning and

76
00:02:53,120 --> 00:02:57,680
daba AI Saturdays Legos and also data

77
00:02:56,000 --> 00:03:00,640
science Africa um and data science

78
00:02:57,680 --> 00:03:03,040
Nigeria um among many others helping to

79
00:03:00,640 --> 00:03:05,040
grow um and enhance these communities of

80
00:03:03,040 --> 00:03:07,840
AI researchers. And so they offer things

81
00:03:05,040 --> 00:03:10,159
like study groups um and even up to uh

82
00:03:07,840 --> 00:03:11,760
workshops and large conferences like

83
00:03:10,159 --> 00:03:14,159
deep learning in Nadaba which will be

84
00:03:11,760 --> 00:03:15,920
held later this year in Kaggali. And so

85
00:03:14,159 --> 00:03:17,599
outside of natural language processing

86
00:03:15,920 --> 00:03:19,840
we also see these specialized AI

87
00:03:17,599 --> 00:03:22,000
communities um also beginning to form.

88
00:03:19,840 --> 00:03:24,640
And so they focus on healthcare um like

89
00:03:22,000 --> 00:03:26,959
Cisson Botique in South Africa um and

90
00:03:24,640 --> 00:03:29,360
then also African AI focusing on

91
00:03:26,959 --> 00:03:31,360
sustainability. And then we also

92
00:03:29,360 --> 00:03:33,440
fortunately I began to see a bit more

93
00:03:31,360 --> 00:03:35,360
let's say diversity in terms of where

94
00:03:33,440 --> 00:03:37,760
these communities are focused. And so

95
00:03:35,360 --> 00:03:40,319
within Francois Africa we have

96
00:03:37,760 --> 00:03:42,720
organizations like AI hub synagal and

97
00:03:40,319 --> 00:03:45,440
also Kami in Cameroon. Um and then also

98
00:03:42,720 --> 00:03:48,480
in northern Africa uh we have Morocco AI

99
00:03:45,440 --> 00:03:50,760
the Tunisian AI society and also Zer AI

100
00:03:48,480 --> 00:03:53,120
um in

101
00:03:50,760 --> 00:03:54,640
Algeria. when it comes to academic AI

102
00:03:53,120 --> 00:03:56,480
research, I'm particularly fond of this,

103
00:03:54,640 --> 00:03:57,760
you know, as a computer scientist and,

104
00:03:56,480 --> 00:04:00,159
you know, someone who has gone through

105
00:03:57,760 --> 00:04:02,000
extensive academic training. And so, um,

106
00:04:00,159 --> 00:04:04,400
it's great to also see that we've, uh,

107
00:04:02,000 --> 00:04:06,239
begun to see more progress, um, in AI

108
00:04:04,400 --> 00:04:07,920
research labs across the continent. And

109
00:04:06,239 --> 00:04:11,120
many of this have been, uh, traced to

110
00:04:07,920 --> 00:04:12,879
the 2020, uh, 4-year 20 million Canadian

111
00:04:11,120 --> 00:04:15,040
dollars, um, AI for development in

112
00:04:12,879 --> 00:04:17,919
Africa initiative, um, also known as AI

113
00:04:15,040 --> 00:04:20,400
for D. And so this is funded by um the

114
00:04:17,919 --> 00:04:23,120
IDRC which is Canad Canada's like

115
00:04:20,400 --> 00:04:24,960
international aid agency and also CEDA

116
00:04:23,120 --> 00:04:27,360
uh which is Sweden's um international

117
00:04:24,960 --> 00:04:29,759
development agency. We also see these

118
00:04:27,360 --> 00:04:31,120
notable academic labs um AI labs

119
00:04:29,759 --> 00:04:34,560
particularly begun to rise on the

120
00:04:31,120 --> 00:04:36,400
continent um in countries uh like Uganda

121
00:04:34,560 --> 00:04:39,280
uh with uh the AI and data science

122
00:04:36,400 --> 00:04:41,120
research lab um at Mccur University. I'm

123
00:04:39,280 --> 00:04:43,520
also the data science for social impact

124
00:04:41,120 --> 00:04:45,840
lab um at the University of Ptoria in

125
00:04:43,520 --> 00:04:47,680
South Africa and also the AI and

126
00:04:45,840 --> 00:04:50,639
robotics lab at the University of Lagos

127
00:04:47,680 --> 00:04:53,040
in Nigeria. There are also more formal

128
00:04:50,639 --> 00:04:54,639
degree programs um arising in AI machine

129
00:04:53,040 --> 00:04:56,000
learning. Um I know some of you are

130
00:04:54,639 --> 00:04:58,000
familiar with the African master of

131
00:04:56,000 --> 00:04:59,840
machine intelligence um that's offered

132
00:04:58,000 --> 00:05:02,000
by the African African Institute for

133
00:04:59,840 --> 00:05:04,560
Mathematical Sciences and then also

134
00:05:02,000 --> 00:05:08,160
masters um in AI from the University of

135
00:05:04,560 --> 00:05:09,759
Maitius um and a bachelor um in AI uh

136
00:05:08,160 --> 00:05:11,360
which is offered by Kumasi Technical

137
00:05:09,759 --> 00:05:14,000
University in Ghana. And so it's really

138
00:05:11,360 --> 00:05:17,320
great to see AI degrees um being offered

139
00:05:14,000 --> 00:05:19,840
at these very uh relatively early

140
00:05:17,320 --> 00:05:22,000
stages. When it comes to the um market

141
00:05:19,840 --> 00:05:24,479
map for AI in Africa, we've also seen a

142
00:05:22,000 --> 00:05:26,000
lot of growth uh particularly in uh

143
00:05:24,479 --> 00:05:27,759
countries that have already been known

144
00:05:26,000 --> 00:05:29,919
as tech hubs on the continent. So this

145
00:05:27,759 --> 00:05:32,800
includes countries like Nigeria, uh

146
00:05:29,919 --> 00:05:35,680
South Africa, uh Kenya, Tunisia, and

147
00:05:32,800 --> 00:05:36,880
Egypt. Um I'll talk about Tunisia um in

148
00:05:35,680 --> 00:05:39,280
a bit because they have a very

149
00:05:36,880 --> 00:05:41,120
interesting use case in terms of um a

150
00:05:39,280 --> 00:05:43,120
startup that arised um out of the

151
00:05:41,120 --> 00:05:45,360
country as well. And so these startups

152
00:05:43,120 --> 00:05:48,080
they focus on um a range of fields that

153
00:05:45,360 --> 00:05:50,720
include healthcare, language generation,

154
00:05:48,080 --> 00:05:53,120
robotics and also just generally show a

155
00:05:50,720 --> 00:05:54,479
lot of promise to help uh address some

156
00:05:53,120 --> 00:05:56,000
of these fundamental development

157
00:05:54,479 --> 00:05:58,880
problems but not you know obviously

158
00:05:56,000 --> 00:06:01,360
solve them completely.

159
00:05:58,880 --> 00:06:03,680
So um according to startup list Africa

160
00:06:01,360 --> 00:06:05,680
there are 85 ASRBs on the continent um

161
00:06:03,680 --> 00:06:09,280
that have received cumulative funding of

162
00:06:05,680 --> 00:06:12,479
about $262 million. Um the top 10 have

163
00:06:09,280 --> 00:06:14,880
commanded about 300 238 million um and

164
00:06:12,479 --> 00:06:18,080
the top three have commanded $27 million

165
00:06:14,880 --> 00:06:19,919
or 28 million um or so. And so this is

166
00:06:18,080 --> 00:06:21,520
again not a comprehensive list. Uh it's

167
00:06:19,919 --> 00:06:24,800
honestly sometimes a bit hard to

168
00:06:21,520 --> 00:06:26,639
determine uh what if a startup is purely

169
00:06:24,800 --> 00:06:28,880
an AI startup or leveraging AI in their

170
00:06:26,639 --> 00:06:31,280
operations, but this is one of the best

171
00:06:28,880 --> 00:06:34,080
analysis that I could find um as of late

172
00:06:31,280 --> 00:06:35,520
last year or so.

173
00:06:34,080 --> 00:06:37,319
Oh, go ahead. Yeah. Do you know if

174
00:06:35,520 --> 00:06:39,960
there's any theme

175
00:06:37,319 --> 00:06:45,360
to

176
00:06:39,960 --> 00:06:47,280
those particular task in general?

177
00:06:45,360 --> 00:06:48,880
Uh, I would say for me like I also did

178
00:06:47,280 --> 00:06:51,120
analysis for a book chapter I wrote, but

179
00:06:48,880 --> 00:06:54,000
this is like really early. It was it was

180
00:06:51,120 --> 00:06:55,600
published in January of 2023, but we did

181
00:06:54,000 --> 00:06:57,759
the analysis basically like way before

182
00:06:55,600 --> 00:06:59,360
Chad GBT came out. And so I feel like I

183
00:06:57,759 --> 00:07:01,599
saw a lot of fintech startups like

184
00:06:59,360 --> 00:07:03,440
adding AI for like identity

185
00:07:01,599 --> 00:07:05,759
verification. Um, you know, fraud

186
00:07:03,440 --> 00:07:08,000
detection. Um, we didn't really see like

187
00:07:05,759 --> 00:07:10,000
a lot of growth in terms of um, say like

188
00:07:08,000 --> 00:07:12,080
language generation or NLP stuff. Uh,

189
00:07:10,000 --> 00:07:14,080
which we do see a lot of like grassroots

190
00:07:12,080 --> 00:07:15,599
efforts focused on now. So I think a lot

191
00:07:14,080 --> 00:07:17,599
of it is focused on finance. We do see

192
00:07:15,599 --> 00:07:18,880
like healthcare and medicine. So not

193
00:07:17,599 --> 00:07:20,560
healthare uh healthcare and also

194
00:07:18,880 --> 00:07:22,560
agriculture. I think agriculture is

195
00:07:20,560 --> 00:07:26,639
probably um one of the main areas that

196
00:07:22,560 --> 00:07:28,960
we see too. So cool. Thank you.

197
00:07:26,639 --> 00:07:30,720
All right. So now um we get to insidep

198
00:07:28,960 --> 00:07:34,400
which is actually one of the most

199
00:07:30,720 --> 00:07:36,400
successful or not the most successful um

200
00:07:34,400 --> 00:07:39,919
AI startups to come out of Africa. And

201
00:07:36,400 --> 00:07:42,400
so in 2023 um it was acquired for $680

202
00:07:39,919 --> 00:07:44,960
million um by biiointech which is a

203
00:07:42,400 --> 00:07:47,919
German far pharmaceutical company um and

204
00:07:44,960 --> 00:07:50,560
it was founded in Tunisia in 2014

205
00:07:47,919 --> 00:07:52,560
um and it has more than 400 uh employees

206
00:07:50,560 --> 00:07:55,440
across the world at different offices

207
00:07:52,560 --> 00:07:57,840
like in London, Paris, Berlin, Tunis,

208
00:07:55,440 --> 00:08:00,560
Lagos, Cape Town, Boston and San

209
00:07:57,840 --> 00:08:03,039
Francisco. And so incident focuses on um

210
00:08:00,560 --> 00:08:05,360
decision-making AI systems for biology,

211
00:08:03,039 --> 00:08:07,120
logistics, electrical design um and

212
00:08:05,360 --> 00:08:09,680
energy. And one of the co-founders,

213
00:08:07,120 --> 00:08:11,440
Karim Buger, he's a really um I would

214
00:08:09,680 --> 00:08:14,080
say a prominent voice within the African

215
00:08:11,440 --> 00:08:16,080
AI ecosystem space um and also supports

216
00:08:14,080 --> 00:08:18,319
AI startups and educational efforts

217
00:08:16,080 --> 00:08:20,639
across Africa too. Uh which is great to

218
00:08:18,319 --> 00:08:22,560
see um that as well. He also returns

219
00:08:20,639 --> 00:08:23,919
back to Tunisia to found Insta Deepep.

220
00:08:22,560 --> 00:08:27,680
And so this is something I think that's

221
00:08:23,919 --> 00:08:29,919
also um really inspiring as well. And so

222
00:08:27,680 --> 00:08:32,479
this research uh comes from Afrey Labs

223
00:08:29,919 --> 00:08:34,080
which is a network organization um that

224
00:08:32,479 --> 00:08:36,719
you know supports innovation hubs and

225
00:08:34,080 --> 00:08:38,399
centers across Africa. Um and this work

226
00:08:36,719 --> 00:08:40,159
is analyzed by Techabal which is

227
00:08:38,399 --> 00:08:42,399
basically like a tech publication within

228
00:08:40,159 --> 00:08:45,600
Africa. And they showed that basically

229
00:08:42,399 --> 00:08:48,160
50% of AI um African AI startups um are

230
00:08:45,600 --> 00:08:50,720
just in seven countries. And so again um

231
00:08:48,160 --> 00:08:53,040
as um mentioned or showed um in one of

232
00:08:50,720 --> 00:08:55,680
the maps earlier we do see a lot of

233
00:08:53,040 --> 00:08:57,680
correlation between basically this these

234
00:08:55,680 --> 00:09:00,480
existing tech hubs like South Africa,

235
00:08:57,680 --> 00:09:04,080
Nigeria um Egypt and the correlation

236
00:09:00,480 --> 00:09:06,800
with where AI startups are as well. And

237
00:09:04,080 --> 00:09:08,800
this is a book chapter I mentioned um on

238
00:09:06,800 --> 00:09:11,200
responsible AI in Africa published in

239
00:09:08,800 --> 00:09:13,120
January 2023. Um and so the analysis

240
00:09:11,200 --> 00:09:15,760
honestly is a bit outdated because you

241
00:09:13,120 --> 00:09:19,120
know um of you know the ChachiBC's

242
00:09:15,760 --> 00:09:22,160
launch um in November of 2022. Um but we

243
00:09:19,120 --> 00:09:23,600
analyzed 102 AI startups um just to

244
00:09:22,160 --> 00:09:25,519
really understand the problems they

245
00:09:23,600 --> 00:09:27,920
addressed um and the implications that

246
00:09:25,519 --> 00:09:30,320
this has for the wider um African

247
00:09:27,920 --> 00:09:32,959
startup ecosystem. And very similar to

248
00:09:30,320 --> 00:09:35,360
the prior slide uh we did see that um

249
00:09:32,959 --> 00:09:36,640
there was not that much diversity in

250
00:09:35,360 --> 00:09:38,560
terms of where these startups were

251
00:09:36,640 --> 00:09:41,120
located. And I think this is also just a

252
00:09:38,560 --> 00:09:42,959
big issue because um investors are

253
00:09:41,120 --> 00:09:44,880
particularly are are more likely to

254
00:09:42,959 --> 00:09:47,040
invest in English-sp speakaking African

255
00:09:44,880 --> 00:09:50,080
countries because a lot of investors in

256
00:09:47,040 --> 00:09:52,399
African startups are from the US um UK

257
00:09:50,080 --> 00:09:53,920
and similar regions like that. And so we

258
00:09:52,399 --> 00:09:56,560
see a lot of exclusion you know from

259
00:09:53,920 --> 00:09:58,399
franophhone and also lucophone Africa.

260
00:09:56,560 --> 00:10:00,800
So, you know, as we continue to grow the

261
00:09:58,399 --> 00:10:02,959
AI ecosystem across Africa, it'll be

262
00:10:00,800 --> 00:10:05,040
really essential um that AI services

263
00:10:02,959 --> 00:10:07,519
built on the continent um also serve

264
00:10:05,040 --> 00:10:11,760
these diverse um linguistic communities

265
00:10:07,519 --> 00:10:13,519
and um cultural communities as well.

266
00:10:11,760 --> 00:10:16,079
And so there's so many challenges um

267
00:10:13,519 --> 00:10:19,040
across AI AI ecosystem and not just you

268
00:10:16,079 --> 00:10:20,519
know dedicated to AI particularly um but

269
00:10:19,040 --> 00:10:23,200
we have things like infrastructure

270
00:10:20,519 --> 00:10:26,480
education a digital literacy and just

271
00:10:23,200 --> 00:10:28,399
unequal access to ICT um resources and

272
00:10:26,480 --> 00:10:30,959
services that have impacted the African

273
00:10:28,399 --> 00:10:32,560
continent for decades. And so this um

274
00:10:30,959 --> 00:10:34,480
you know impacts things like

275
00:10:32,560 --> 00:10:36,160
infrastructure obviously particularly

276
00:10:34,480 --> 00:10:38,399
when we consider the large amounts of

277
00:10:36,160 --> 00:10:40,240
data um that are needed to train AI

278
00:10:38,399 --> 00:10:42,079
systems um and the high number of

279
00:10:40,240 --> 00:10:45,120
computing resources that are consumed in

280
00:10:42,079 --> 00:10:47,279
this process and so again infrastructure

281
00:10:45,120 --> 00:10:49,839
really challenges um the abilities of

282
00:10:47,279 --> 00:10:52,240
African uh researchers and developers to

283
00:10:49,839 --> 00:10:54,640
innovate in this space um we've seen

284
00:10:52,240 --> 00:10:56,720
that um particularly uh many challenges

285
00:10:54,640 --> 00:10:59,120
with internet access um and the

286
00:10:56,720 --> 00:11:01,839
international telecommunications union

287
00:10:59,120 --> 00:11:04,000
um as estimated that about from um in

288
00:11:01,839 --> 00:11:07,240
2011 um internet penetration across the

289
00:11:04,000 --> 00:11:11,279
continent was about 8% um and it grew to

290
00:11:07,240 --> 00:11:12,800
36% um in 2021 and the numbers honestly

291
00:11:11,279 --> 00:11:15,279
um haven't really changed that much. I

292
00:11:12,800 --> 00:11:17,519
think we had some issues with um with

293
00:11:15,279 --> 00:11:20,640
issues exacerbated by the COVID pandemic

294
00:11:17,519 --> 00:11:24,480
as well. Um so I I think it's around 45%

295
00:11:20,640 --> 00:11:27,040
now but we'll have to to look at that.

296
00:11:24,480 --> 00:11:28,640
Uh fortunately we also see um a lot of

297
00:11:27,040 --> 00:11:30,079
efforts that have begun to focus on

298
00:11:28,640 --> 00:11:33,279
improving connectivity across the

299
00:11:30,079 --> 00:11:35,920
continent. Um this u map on the screen

300
00:11:33,279 --> 00:11:38,320
details the two Africa cable and so this

301
00:11:35,920 --> 00:11:40,480
is the longest uh subc internet cable

302
00:11:38,320 --> 00:11:42,560
that's ever been designed. Um it's

303
00:11:40,480 --> 00:11:44,800
currently under deployment and has 46

304
00:11:42,560 --> 00:11:48,160
connections uh to landbased networks

305
00:11:44,800 --> 00:11:50,560
across 33 countries in Africa uh Asia

306
00:11:48,160 --> 00:11:53,440
and Europe. And so again, we only know

307
00:11:50,560 --> 00:11:55,560
that internet is uh access uh is only

308
00:11:53,440 --> 00:11:57,839
just one aspect of a successful AI

309
00:11:55,560 --> 00:11:59,760
ecosystem. And so we also see other

310
00:11:57,839 --> 00:12:02,399
challenges across Africa that include

311
00:11:59,760 --> 00:12:05,120
things like digital literacy um talent

312
00:12:02,399 --> 00:12:07,760
AI talent concentration and also having

313
00:12:05,120 --> 00:12:11,560
access to these uh relevant data sets to

314
00:12:07,760 --> 00:12:13,680
build and train these um AI

315
00:12:11,560 --> 00:12:15,120
models. So building upon these

316
00:12:13,680 --> 00:12:16,720
infrastructure challenges um this

317
00:12:15,120 --> 00:12:19,200
research is really interesting. and it

318
00:12:16,720 --> 00:12:21,839
comes from the Oxford Internet Institute

319
00:12:19,200 --> 00:12:24,800
and shows that AI compute is also um

320
00:12:21,839 --> 00:12:27,839
unequally distributed globally. So their

321
00:12:24,800 --> 00:12:30,240
work classifies countries um basically

322
00:12:27,839 --> 00:12:31,920
excuse me into three categories. Uh so

323
00:12:30,240 --> 00:12:34,160
we have the compute north uh where

324
00:12:31,920 --> 00:12:36,959
predominantly rich countries um host

325
00:12:34,160 --> 00:12:39,519
data centers uh with the latest GPUs for

326
00:12:36,959 --> 00:12:41,920
training uh these frontier AI models.

327
00:12:39,519 --> 00:12:43,680
And then we also have the compute south

328
00:12:41,920 --> 00:12:45,680
uh which essentially are um these

329
00:12:43,680 --> 00:12:48,480
predominantly middle inome countries

330
00:12:45,680 --> 00:12:50,480
that host older GPUs um that are

331
00:12:48,480 --> 00:12:52,639
relevant for deploying but not necess

332
00:12:50,480 --> 00:12:54,959
but not necessarily excuse me training

333
00:12:52,639 --> 00:12:56,399
this frontier AI models. And then we

334
00:12:54,959 --> 00:12:58,560
have compute desert which you can

335
00:12:56,399 --> 00:13:01,360
basically see like right in the middle

336
00:12:58,560 --> 00:13:04,079
um of the map and also around Russia and

337
00:13:01,360 --> 00:13:06,639
similar areas where countries have no

338
00:13:04,079 --> 00:13:08,320
cloud AI compute at all and they may

339
00:13:06,639 --> 00:13:10,959
have necessarily like data centers but

340
00:13:08,320 --> 00:13:13,120
that this um doesn't necessarily count

341
00:13:10,959 --> 00:13:16,800
um data centers that are uh specifically

342
00:13:13,120 --> 00:13:18,639
used for non AI purposes. Again we see

343
00:13:16,800 --> 00:13:21,440
these disparities um with you know

344
00:13:18,639 --> 00:13:23,279
regions like Africa, Latin America um

345
00:13:21,440 --> 00:13:25,600
the Caribbean and also Oceanana

346
00:13:23,279 --> 00:13:28,079
specifically around the smaller um

347
00:13:25,600 --> 00:13:30,480
islands not having a lot of access you

348
00:13:28,079 --> 00:13:32,279
know to these specific compute uh

349
00:13:30,480 --> 00:13:34,480
clusters as

350
00:13:32,279 --> 00:13:36,480
well. And then also very interesting

351
00:13:34,480 --> 00:13:38,320
work um a lot of the uh researchers from

352
00:13:36,480 --> 00:13:40,720
this project are actually here at MIT.

353
00:13:38,320 --> 00:13:42,959
Um and so this is uh from the data

354
00:13:40,720 --> 00:13:46,000
provenence initiative and so this work

355
00:13:42,959 --> 00:13:48,320
was um I think mainly published starting

356
00:13:46,000 --> 00:13:50,000
from 2024 and I know they also had

357
00:13:48,320 --> 00:13:51,920
papers at Iclear and some other

358
00:13:50,000 --> 00:13:54,880
conferences as well. Um and so they

359
00:13:51,920 --> 00:13:57,279
conducted a widescale audit of data sets

360
00:13:54,880 --> 00:13:59,440
that were used to train AI systems and

361
00:13:57,279 --> 00:14:02,240
they found extreme disparities um in the

362
00:13:59,440 --> 00:14:04,959
global representation um of data sets

363
00:14:02,240 --> 00:14:08,199
and found that less than 0.2 um of a

364
00:14:04,959 --> 00:14:10,639
percent uh comes from Africa um or South

365
00:14:08,199 --> 00:14:13,199
America. Again um we see that these

366
00:14:10,639 --> 00:14:15,120
issues of underrepresentation um impact

367
00:14:13,199 --> 00:14:17,040
the development of AI systems. And this

368
00:14:15,120 --> 00:14:18,959
is something I wrote recently um for the

369
00:14:17,040 --> 00:14:21,279
international AI safety report uh that

370
00:14:18,959 --> 00:14:23,360
was chaired by professor Yosua Benjio.

371
00:14:21,279 --> 00:14:26,320
Um and this leads to bias and also

372
00:14:23,360 --> 00:14:28,639
unequal performance um of these tools on

373
00:14:26,320 --> 00:14:31,760
global languages, cultures and also

374
00:14:28,639 --> 00:14:31,760
value systems as

375
00:14:31,800 --> 00:14:36,399
well. And so now uh we get to the topic

376
00:14:34,639 --> 00:14:38,000
of digital literacy which is honestly

377
00:14:36,399 --> 00:14:40,639
something I think it's a bit hard to

378
00:14:38,000 --> 00:14:42,480
really address uh because people have to

379
00:14:40,639 --> 00:14:44,639
act have access to these digital

380
00:14:42,480 --> 00:14:46,880
technologies in the first place. um to

381
00:14:44,639 --> 00:14:49,199
really become literate in a sense and

382
00:14:46,880 --> 00:14:51,920
the World Bank shows that um out of all

383
00:14:49,199 --> 00:14:54,079
world regions uh subsaharan Africa has

384
00:14:51,920 --> 00:14:56,639
the lowest percentage of citizens that

385
00:14:54,079 --> 00:14:58,959
are equipped with digital skills and so

386
00:14:56,639 --> 00:15:01,600
this equals to about half of the average

387
00:14:58,959 --> 00:15:04,320
level um of digital literacy or digital

388
00:15:01,600 --> 00:15:06,880
skills adoption that we see globally.

389
00:15:04,320 --> 00:15:08,720
Thus, we also have to ensure that um AI

390
00:15:06,880 --> 00:15:11,120
is accessible to these broader

391
00:15:08,720 --> 00:15:13,040
nontechnical populations um across

392
00:15:11,120 --> 00:15:15,760
Africa, particularly when it comes to

393
00:15:13,040 --> 00:15:18,160
women uh youth and older adults um who

394
00:15:15,760 --> 00:15:20,160
tend to be excluded um from digital

395
00:15:18,160 --> 00:15:21,680
technologies as well. And so efforts,

396
00:15:20,160 --> 00:15:23,920
you know, that are focused on um

397
00:15:21,680 --> 00:15:26,399
literacy and and and other things and

398
00:15:23,920 --> 00:15:30,800
media training as well um have to ensure

399
00:15:26,399 --> 00:15:32,480
that these populations are included.

400
00:15:30,800 --> 00:15:33,680
Go ahead. Oh, sorry. Just one question.

401
00:15:32,480 --> 00:15:35,760
What's usually counted in digital

402
00:15:33,680 --> 00:15:37,040
woodshake? Is it like navigate the web

403
00:15:35,760 --> 00:15:38,880
email or is it like something more

404
00:15:37,040 --> 00:15:41,120
specific? Yeah, I think it's yes uh some

405
00:15:38,880 --> 00:15:43,680
of those. I don't have the specific uh I

406
00:15:41,120 --> 00:15:44,959
would say measures or metrics from what

407
00:15:43,680 --> 00:15:46,720
the World Bank measures, but I think

408
00:15:44,959 --> 00:15:48,160
it's a lot of that. I don't think social

409
00:15:46,720 --> 00:15:49,440
media is included. I think it's really

410
00:15:48,160 --> 00:15:51,920
just like sending text messages,

411
00:15:49,440 --> 00:15:54,079
accessing email. They probably do being

412
00:15:51,920 --> 00:15:58,279
able to do like a basic search on some

413
00:15:54,079 --> 00:15:58,279
search platform. So, yeah.

414
00:16:00,000 --> 00:16:05,040
Is that a good?

415
00:16:03,440 --> 00:16:08,160
Yeah, it's hard to say because I think

416
00:16:05,040 --> 00:16:10,079
like for search many people would not

417
00:16:08,160 --> 00:16:13,600
necessarily do that well. I think like

418
00:16:10,079 --> 00:16:15,519
for communication like uh texting um and

419
00:16:13,600 --> 00:16:17,519
also like calling I think like people

420
00:16:15,519 --> 00:16:19,360
would score a bit higher on that. Um but

421
00:16:17,519 --> 00:16:21,279
when it comes like information seeking

422
00:16:19,360 --> 00:16:23,120
and access I think that's also a big

423
00:16:21,279 --> 00:16:24,399
challenge too. And then you know it's

424
00:16:23,120 --> 00:16:26,240
definitely changed with all you know the

425
00:16:24,399 --> 00:16:30,240
disinformation and misinformation too.

426
00:16:26,240 --> 00:16:32,160
So yeah, thank you. Um and so this is um

427
00:16:30,240 --> 00:16:34,480
this slide talks about the respective

428
00:16:32,160 --> 00:16:36,079
concentration um and production of AI

429
00:16:34,480 --> 00:16:38,800
talent something that I've also written

430
00:16:36,079 --> 00:16:41,759
about um and what we consider basically

431
00:16:38,800 --> 00:16:43,279
where AI talent um is concentrated. We

432
00:16:41,759 --> 00:16:46,079
have mainly two countries. So this is

433
00:16:43,279 --> 00:16:48,480
the US um and also China. And so India

434
00:16:46,079 --> 00:16:50,240
is also really an interesting uh place

435
00:16:48,480 --> 00:16:52,160
but they have I would say a lot of

436
00:16:50,240 --> 00:16:54,560
attrition which is also known as like

437
00:16:52,160 --> 00:16:56,800
brain drain um because developers you

438
00:16:54,560 --> 00:17:00,320
know from India you know often go to the

439
00:16:56,800 --> 00:17:02,880
Canada, US, the UK to basically seek um

440
00:17:00,320 --> 00:17:05,880
these like tech jobs and also AI jobs as

441
00:17:02,880 --> 00:17:05,880
well.

442
00:17:05,919 --> 00:17:08,640
However, we've seen some interesting

443
00:17:07,199 --> 00:17:10,640
research um this was published in the

444
00:17:08,640 --> 00:17:11,959
Harvard Business Review um that shows

445
00:17:10,640 --> 00:17:14,480
that there are many hot spots

446
00:17:11,959 --> 00:17:15,919
particularly a lot within India and also

447
00:17:14,480 --> 00:17:18,400
within other global south global

448
00:17:15,919 --> 00:17:21,360
majority countries um in cities like

449
00:17:18,400 --> 00:17:23,600
Johannesburg, Nairobi and Lagos um also

450
00:17:21,360 --> 00:17:26,160
be quickly becoming AI hotspots within a

451
00:17:23,600 --> 00:17:29,200
continent and again um these cities

452
00:17:26,160 --> 00:17:31,280
basically kind of correspond uh to I

453
00:17:29,200 --> 00:17:33,200
would say like the countries that are

454
00:17:31,280 --> 00:17:35,039
already hotspots for tech Thailand as

455
00:17:33,200 --> 00:17:37,280
well. Um so it would be really great to

456
00:17:35,039 --> 00:17:38,640
see how this evolves um over the next

457
00:17:37,280 --> 00:17:41,840
couple years to include some of the

458
00:17:38,640 --> 00:17:41,840
smaller markets across

459
00:17:42,280 --> 00:17:46,640
Africa. And something which is really

460
00:17:44,559 --> 00:17:48,480
interesting is that um I mentioned

461
00:17:46,640 --> 00:17:51,039
branding pre previously. This is also an

462
00:17:48,480 --> 00:17:52,400
issue that affects African countries uh

463
00:17:51,039 --> 00:17:54,559
particularly more so in the service

464
00:17:52,400 --> 00:17:56,799
domain. So we see a lot of um like

465
00:17:54,559 --> 00:17:58,799
medical workers um and also domestic

466
00:17:56,799 --> 00:18:00,640
workers leaving the continent um you

467
00:17:58,799 --> 00:18:03,520
know for the Middle East and also other

468
00:18:00,640 --> 00:18:06,320
countries as well. Um and so this uh

469
00:18:03,520 --> 00:18:09,679
report is basically um this uh image uh

470
00:18:06,320 --> 00:18:12,480
is analysis or uh report of the 2021

471
00:18:09,679 --> 00:18:15,039
Africa developer ecosystem um initiative

472
00:18:12,480 --> 00:18:18,000
that was uh detailed by Google. And so

473
00:18:15,039 --> 00:18:21,120
they estimate that about 38% of African

474
00:18:18,000 --> 00:18:22,880
developers um they work in Africa for a

475
00:18:21,120 --> 00:18:25,360
company that has its headquarters

476
00:18:22,880 --> 00:18:26,880
outside of the continent. And so they

477
00:18:25,360 --> 00:18:28,880
haven't necessarily updated this report

478
00:18:26,880 --> 00:18:31,039
recently. Um, I've also seen

479
00:18:28,880 --> 00:18:32,880
organizations like OECD report on these

480
00:18:31,039 --> 00:18:35,280
stats. Um, so I'm not sure what the

481
00:18:32,880 --> 00:18:38,480
trend is for AI jobs. Um, but I know

482
00:18:35,280 --> 00:18:40,559
that uh, for example, Microsoft, IBM,

483
00:18:38,480 --> 00:18:43,280
and Google have big AI hubs on the

484
00:18:40,559 --> 00:18:45,600
continent. And so um, I assume they they

485
00:18:43,280 --> 00:18:47,840
also have a higher concentration um, of

486
00:18:45,600 --> 00:18:50,960
AI talent um, compared to other like

487
00:18:47,840 --> 00:18:52,880
local companies as well. And so again um

488
00:18:50,960 --> 00:18:54,960
you know for AI talent within Africa or

489
00:18:52,880 --> 00:18:57,120
just for the African AI ecosystem to

490
00:18:54,960 --> 00:18:59,760
grow um more broadly there has to be

491
00:18:57,120 --> 00:19:01,600
efforts um that encourage people to stay

492
00:18:59,760 --> 00:19:03,840
um and be well compensated you know for

493
00:19:01,600 --> 00:19:06,400
the labor that they contribute um to

494
00:19:03,840 --> 00:19:08,200
developing researching and also building

495
00:19:06,400 --> 00:19:10,880
um AI

496
00:19:08,200 --> 00:19:12,640
systems. And so I'll talk uh about AI

497
00:19:10,880 --> 00:19:14,400
and data governance in Africa. It'll be

498
00:19:12,640 --> 00:19:16,160
very broad. Uh there's so many different

499
00:19:14,400 --> 00:19:17,520
developments that are happening.

500
00:19:16,160 --> 00:19:20,320
actually recently found out that Kot

501
00:19:17,520 --> 00:19:22,480
Divvois um announced or developed or

502
00:19:20,320 --> 00:19:25,280
sorry released um their respective AI

503
00:19:22,480 --> 00:19:27,600
strategy and data strategy around March

504
00:19:25,280 --> 00:19:29,120
20th or so. So it's good to see a lot of

505
00:19:27,600 --> 00:19:32,080
progress and uh good to see that my

506
00:19:29,120 --> 00:19:34,640
slides are becoming um outdated about

507
00:19:32,080 --> 00:19:36,799
every month or so.

508
00:19:34,640 --> 00:19:39,280
So uh the Carnegie Council for Ethics

509
00:19:36,799 --> 00:19:41,400
and International Affairs defines AI

510
00:19:39,280 --> 00:19:43,440
governance um as a set of rules,

511
00:19:41,400 --> 00:19:46,080
regulations, ethical and technical

512
00:19:43,440 --> 00:19:48,240
frameworks and similar mechanisms that

513
00:19:46,080 --> 00:19:51,200
guide the development and deployment of

514
00:19:48,240 --> 00:19:52,559
AI technologies. Um I also find that you

515
00:19:51,200 --> 00:19:54,559
know if you talk to me that data

516
00:19:52,559 --> 00:19:57,280
governance is also a very essential

517
00:19:54,559 --> 00:19:59,440
aspect of AI governance particularly as

518
00:19:57,280 --> 00:20:01,280
it provides protections um over how

519
00:19:59,440 --> 00:20:03,919
personal information is collected,

520
00:20:01,280 --> 00:20:06,400
stored uh transferred um and also

521
00:20:03,919 --> 00:20:08,559
provides data subjects with the ability

522
00:20:06,400 --> 00:20:10,640
um to have control um over their

523
00:20:08,559 --> 00:20:12,799
information and also rights to be

524
00:20:10,640 --> 00:20:15,679
informed uh regarding personal data

525
00:20:12,799 --> 00:20:18,480
breaches which have become uh a bigger

526
00:20:15,679 --> 00:20:20,640
or more higher in occurrence, excuse me.

527
00:20:18,480 --> 00:20:23,280
um you know due to many issues around

528
00:20:20,640 --> 00:20:24,960
the pandemic but also limited capacity

529
00:20:23,280 --> 00:20:26,960
um you know of companies across the

530
00:20:24,960 --> 00:20:30,080
continent to have effective safeguards

531
00:20:26,960 --> 00:20:32,720
for data and so again um given that we

532
00:20:30,080 --> 00:20:34,880
see that uh data has a fundamental role

533
00:20:32,720 --> 00:20:37,520
in training machine learning models um

534
00:20:34,880 --> 00:20:40,080
evaluating AI systems uh refining

535
00:20:37,520 --> 00:20:42,640
predictive models and also improving AI

536
00:20:40,080 --> 00:20:44,559
enabled services um enacting effective

537
00:20:42,640 --> 00:20:46,799
data governance can also form the

538
00:20:44,559 --> 00:20:49,760
foundation of robust and comprehensive

539
00:20:46,799 --> 00:20:52,000
AI governance measures.

540
00:20:49,760 --> 00:20:54,280
Um over the past 5 years a global

541
00:20:52,000 --> 00:20:56,640
interest in regulating AI has also grown

542
00:20:54,280 --> 00:20:59,280
dramatically. Um we see this effort uh

543
00:20:56,640 --> 00:21:02,240
this graphic from authority hacker um

544
00:20:59,280 --> 00:21:04,720
shows basically the world stage or state

545
00:21:02,240 --> 00:21:07,520
um of global AI regulation and they

546
00:21:04,720 --> 00:21:09,559
break it down into four tiers. And so um

547
00:21:07,520 --> 00:21:11,840
they detail countries that have enacted

548
00:21:09,559 --> 00:21:13,919
regulation um initiated regulatory

549
00:21:11,840 --> 00:21:16,159
efforts um those who are actively

550
00:21:13,919 --> 00:21:18,159
working towards regulation and also

551
00:21:16,159 --> 00:21:20,080
those who have no regulation. And so

552
00:21:18,159 --> 00:21:21,760
again similar to some of the other maps

553
00:21:20,080 --> 00:21:23,760
I've shown um throughout the

554
00:21:21,760 --> 00:21:26,640
presentation we honestly see like Africa

555
00:21:23,760 --> 00:21:28,080
sticks out a little bit. Um and I would

556
00:21:26,640 --> 00:21:29,520
say like again there's a lot of

557
00:21:28,080 --> 00:21:32,159
progress. There are about 17 countries

558
00:21:29,520 --> 00:21:34,000
or so um that have made formal AI

559
00:21:32,159 --> 00:21:36,559
strategies. There's technically only one

560
00:21:34,000 --> 00:21:39,440
country um on the continent that has an

561
00:21:36,559 --> 00:21:41,039
AI policy, which is Wanda. Um but it's

562
00:21:39,440 --> 00:21:43,919
still in draft stage and hasn't been

563
00:21:41,039 --> 00:21:45,200
fully enacted. And so uh I don't even

564
00:21:43,919 --> 00:21:46,960
know if they're highlighted on the

565
00:21:45,200 --> 00:21:49,919
screen, but it's a very small country.

566
00:21:46,960 --> 00:21:52,960
So yeah. Uh and so again, while we see

567
00:21:49,919 --> 00:21:55,840
that the EU has um led global regulatory

568
00:21:52,960 --> 00:21:57,520
AI efforts, um we also see countries

569
00:21:55,840 --> 00:22:00,320
across the global majority or global

570
00:21:57,520 --> 00:22:03,280
south uh making progress. And so Brazil

571
00:22:00,320 --> 00:22:06,559
actually had um a recent AI law uh that

572
00:22:03,280 --> 00:22:09,600
was approved in December 2024. Um again,

573
00:22:06,559 --> 00:22:11,440
but I um also mentioned uh or talked to

574
00:22:09,600 --> 00:22:13,760
some people that there's also been a

575
00:22:11,440 --> 00:22:15,919
interesting influence of tech companies

576
00:22:13,760 --> 00:22:19,120
um on these regulations. Um there were

577
00:22:15,919 --> 00:22:20,720
some provisions in the uh draft um AI

578
00:22:19,120 --> 00:22:23,120
law from Brazil that were actually

579
00:22:20,720 --> 00:22:24,880
weakened because of lobbying. And so

580
00:22:23,120 --> 00:22:27,320
unfortunately I I do expect this to

581
00:22:24,880 --> 00:22:30,400
continue um in some

582
00:22:27,320 --> 00:22:32,240
manner. And then again um or just more

583
00:22:30,400 --> 00:22:34,080
more broadly uh we see that the

584
00:22:32,240 --> 00:22:35,919
increasing development and adoption of

585
00:22:34,080 --> 00:22:37,520
AI have really drastically or

586
00:22:35,919 --> 00:22:39,760
dramatically shifted practices around

587
00:22:37,520 --> 00:22:41,039
data. Um this has spurred the uh

588
00:22:39,760 --> 00:22:43,360
development of new industries

589
00:22:41,039 --> 00:22:45,520
particularly like data um labeling and

590
00:22:43,360 --> 00:22:47,280
content moderation. Um and then also

591
00:22:45,520 --> 00:22:49,120
revealed new forms of exploitation

592
00:22:47,280 --> 00:22:51,280
particularly um from these respective

593
00:22:49,120 --> 00:22:53,919
fields that I mentioned. um these new

594
00:22:51,280 --> 00:22:56,159
complexities um around data production

595
00:22:53,919 --> 00:22:58,559
uh refinement and also use have really

596
00:22:56,159 --> 00:23:00,240
impacted African countries and also

597
00:22:58,559 --> 00:23:02,240
again um elevates the need for

598
00:23:00,240 --> 00:23:05,520
comprehensive governance and um

599
00:23:02,240 --> 00:23:07,840
enforcement measures. So about 38 out of

600
00:23:05,520 --> 00:23:10,880
55 African Union member states. Um so

601
00:23:07,840 --> 00:23:13,440
this is 54 African countries and also uh

602
00:23:10,880 --> 00:23:16,000
the disputed territory of uh Western

603
00:23:13,440 --> 00:23:18,080
Sahara. Um also known as the Sari Arab

604
00:23:16,000 --> 00:23:21,039
Republic and they have enacted formal

605
00:23:18,080 --> 00:23:23,600
data uh protection regulations and 15

606
00:23:21,039 --> 00:23:26,720
out of 38 were enacted in the past 5

607
00:23:23,600 --> 00:23:29,120
years and 26 out of these 38 were

608
00:23:26,720 --> 00:23:30,640
enacted in the past decade. And so we

609
00:23:29,120 --> 00:23:34,799
saw the first data protection law come

610
00:23:30,640 --> 00:23:36,720
into play um in 2001 by Cabo Verde. And

611
00:23:34,799 --> 00:23:38,799
then also we see that there's been a lot

612
00:23:36,720 --> 00:23:40,960
of progress recently over the past year.

613
00:23:38,799 --> 00:23:43,360
Uh we see countries like Malawi um

614
00:23:40,960 --> 00:23:47,840
enacting a data protection law in June

615
00:23:43,360 --> 00:23:49,919
2024 um and Ethiopia in July 2024. And

616
00:23:47,840 --> 00:23:52,640
then as of yet we see that there are

617
00:23:49,919 --> 00:23:55,280
draft laws that are still in progress um

618
00:23:52,640 --> 00:23:58,080
from countries that include Namibia,

619
00:23:55,280 --> 00:24:00,080
South Sudan um and the Gabia. So we hope

620
00:23:58,080 --> 00:24:03,159
to see a bit more progress um towards

621
00:24:00,080 --> 00:24:06,400
data protection um in these countries

622
00:24:03,159 --> 00:24:09,360
soon. And then also um aside from these

623
00:24:06,400 --> 00:24:10,960
country specific efforts uh we also see

624
00:24:09,360 --> 00:24:13,120
um efforts from regional economic

625
00:24:10,960 --> 00:24:15,520
communities uh basically which serve as

626
00:24:13,120 --> 00:24:17,840
like economic blocks across Africa um

627
00:24:15,520 --> 00:24:19,120
and also entities like the African Union

628
00:24:17,840 --> 00:24:21,120
uh which I've been fortunate to work

629
00:24:19,120 --> 00:24:23,600
with um on different initiatives

630
00:24:21,120 --> 00:24:26,080
particularly the AUAI strategy um which

631
00:24:23,600 --> 00:24:27,600
I'll detail in a following slide and so

632
00:24:26,080 --> 00:24:30,880
they've introduced these data protection

633
00:24:27,600 --> 00:24:34,080
acts and also like cyber security um and

634
00:24:30,880 --> 00:24:37,120
personal um data protection. This is

635
00:24:34,080 --> 00:24:39,120
actually ratified um in 2023

636
00:24:37,120 --> 00:24:42,720
uh 9 years after it was formally

637
00:24:39,120 --> 00:24:44,799
adopted. Uh it was drafted in 2011 um in

638
00:24:42,720 --> 00:24:46,960
Malabo which is in Equatorial Guinea uh

639
00:24:44,799 --> 00:24:50,640
which is where the name comes from and

640
00:24:46,960 --> 00:24:53,279
was uh came into force on June 8th 2023

641
00:24:50,640 --> 00:24:54,960
um after being ratified by Moritania uh

642
00:24:53,279 --> 00:24:57,679
which was the 15th country that was

643
00:24:54,960 --> 00:25:00,880
needed for full ratification um to take

644
00:24:57,679 --> 00:25:02,640
effect. Um unfortunately this is I would

645
00:25:00,880 --> 00:25:04,640
say protection or this framework is not

646
00:25:02,640 --> 00:25:06,880
necessarily enforceable. And so this is

647
00:25:04,640 --> 00:25:08,960
something I think that the the AU um

648
00:25:06,880 --> 00:25:11,360
will also have to work towards um as we

649
00:25:08,960 --> 00:25:14,679
expand efforts for data governance and

650
00:25:11,360 --> 00:25:17,440
AI governance um across

651
00:25:14,679 --> 00:25:19,279
Africa. And so regional efforts um have

652
00:25:17,440 --> 00:25:21,760
also something I would say I'm a bit

653
00:25:19,279 --> 00:25:23,360
more bullish on in terms of um them

654
00:25:21,760 --> 00:25:25,440
being able to provide more sufficient

655
00:25:23,360 --> 00:25:27,840
protections uh for different African

656
00:25:25,440 --> 00:25:29,840
countries. And so we see efforts um on

657
00:25:27,840 --> 00:25:31,760
data protection um that have been

658
00:25:29,840 --> 00:25:34,640
implemented by the economic community of

659
00:25:31,760 --> 00:25:36,320
West African states um most probably one

660
00:25:34,640 --> 00:25:39,120
of the most prominent economic blocks

661
00:25:36,320 --> 00:25:40,400
within Africa um known as EcoAs and we

662
00:25:39,120 --> 00:25:43,039
also have the southern African

663
00:25:40,400 --> 00:25:45,279
development community um known as SEDC

664
00:25:43,039 --> 00:25:48,240
and also the East African African

665
00:25:45,279 --> 00:25:50,000
Community excuse me um and then fortunat

666
00:25:48,240 --> 00:25:52,320
unfortunately uh we haven't seen any

667
00:25:50,000 --> 00:25:54,960
regional governance measures um proposed

668
00:25:52,320 --> 00:25:57,520
or enacted by the Arab McGregor Union

669
00:25:54,960 --> 00:25:59,840
which consists of a lot of um Sahel and

670
00:25:57,520 --> 00:26:02,159
um northern African states. Um and then

671
00:25:59,840 --> 00:26:04,880
also we have another community for uh

672
00:26:02,159 --> 00:26:07,440
Sahel Saharin states um and the economic

673
00:26:04,880 --> 00:26:08,960
community of central African states and

674
00:26:07,440 --> 00:26:11,200
honestly particularly when it comes to

675
00:26:08,960 --> 00:26:13,520
central Africa there um unfortunately

676
00:26:11,200 --> 00:26:16,000
happens to be I would say a lot of

677
00:26:13,520 --> 00:26:18,880
conflict um that you know definitely

678
00:26:16,000 --> 00:26:21,279
delays uh the um development and

679
00:26:18,880 --> 00:26:23,120
enactment you know of data regulation

680
00:26:21,279 --> 00:26:25,600
and you know probably will you know

681
00:26:23,120 --> 00:26:27,679
follow on to AI regulation and also

682
00:26:25,600 --> 00:26:30,000
within ECOAS as well we have three

683
00:26:27,679 --> 00:26:32,559
countries that actually left the block

684
00:26:30,000 --> 00:26:35,520
um due to you know different uh regional

685
00:26:32,559 --> 00:26:38,000
and cultural differences and so um I

686
00:26:35,520 --> 00:26:40,480
think we stand to see a little a lack of

687
00:26:38,000 --> 00:26:42,600
cohesion unfortunately um across these

688
00:26:40,480 --> 00:26:46,080
respective

689
00:26:42,600 --> 00:26:48,320
efforts and so uh this work um this

690
00:26:46,080 --> 00:26:49,600
graphic is from lawyers of Africa and

691
00:26:48,320 --> 00:26:51,039
basically that does a lot of work around

692
00:26:49,600 --> 00:26:53,360
AI and data governance across the

693
00:26:51,039 --> 00:26:54,799
continent um and more generally um

694
00:26:53,360 --> 00:26:57,360
there's research from the African

695
00:26:54,799 --> 00:27:00,240
Observatory on AI um that shows that

696
00:26:57,360 --> 00:27:04,159
only 75 out of 55 African Union member

697
00:27:00,240 --> 00:27:06,559
states um have a policy strategy plan or

698
00:27:04,159 --> 00:27:08,480
guideline on AI. And so this includes

699
00:27:06,559 --> 00:27:11,279
like a ministerial or presidential

700
00:27:08,480 --> 00:27:13,679
statement or a fully blown um or

701
00:27:11,279 --> 00:27:16,720
developed strategy document like that of

702
00:27:13,679 --> 00:27:18,960
Maitius, Nigeria, Rwanda and other

703
00:27:16,720 --> 00:27:20,799
countries as well. And so again as I

704
00:27:18,960 --> 00:27:23,039
mentioned uh Rwanda is the only African

705
00:27:20,799 --> 00:27:26,000
country that has introduced a formal AI

706
00:27:23,039 --> 00:27:27,679
policy. Um again it's yet to be enacted.

707
00:27:26,000 --> 00:27:30,080
So we hope to see a lot of progress. Um

708
00:27:27,679 --> 00:27:32,960
I was actually in Kaggali um earlier

709
00:27:30,080 --> 00:27:35,039
this month for the um a global AI summit

710
00:27:32,960 --> 00:27:36,799
on Africa and so there was a lot of

711
00:27:35,039 --> 00:27:40,000
progress like a new declaration for

712
00:27:36,799 --> 00:27:42,960
African AI and so I hope to see um

713
00:27:40,000 --> 00:27:45,440
movements towards um enactment of AI

714
00:27:42,960 --> 00:27:49,600
regulations or policies um in the near

715
00:27:45,440 --> 00:27:52,640
future. Go ahead. Um so can I ask what

716
00:27:49,600 --> 00:27:54,320
are some of the like similarities or the

717
00:27:52,640 --> 00:27:57,520
difference between like what the like

718
00:27:54,320 --> 00:27:57,520
the EU's polic

719
00:28:00,240 --> 00:28:05,360
Yeah, I would say like um when we think

720
00:28:02,399 --> 00:28:08,000
about AU um AU member states, countries

721
00:28:05,360 --> 00:28:09,520
um the thing is because like there isn't

722
00:28:08,000 --> 00:28:10,960
advanced AI development, a lot of the

723
00:28:09,520 --> 00:28:12,720
plans are really focused on like how can

724
00:28:10,960 --> 00:28:14,799
we leverage AI like in the across these

725
00:28:12,720 --> 00:28:16,720
different sectors. So a lot of them and

726
00:28:14,799 --> 00:28:18,080
I when I worked on the AUA strategy it's

727
00:28:16,720 --> 00:28:20,480
like focused on like healthcare,

728
00:28:18,080 --> 00:28:22,399
education, agriculture and many of the

729
00:28:20,480 --> 00:28:24,960
like state level or national level uh

730
00:28:22,399 --> 00:28:26,880
policy excuse me strategy documents also

731
00:28:24,960 --> 00:28:29,200
mimic this as well. Um we don't

732
00:28:26,880 --> 00:28:30,799
necessarily see like you know the EU

733
00:28:29,200 --> 00:28:32,480
talking about oh we want to leverage

734
00:28:30,799 --> 00:28:35,520
again a agriculture because you know

735
00:28:32,480 --> 00:28:37,200
they already have to an to an extent. Um

736
00:28:35,520 --> 00:28:39,600
and there they I would say there's like

737
00:28:37,200 --> 00:28:42,000
more of um I guess people call this like

738
00:28:39,600 --> 00:28:45,039
a human rights approach or framework to

739
00:28:42,000 --> 00:28:46,960
governing AI. um even though the EUA act

740
00:28:45,039 --> 00:28:49,360
does fall short um particularly when it

741
00:28:46,960 --> 00:28:50,720
comes to covering migrants and and other

742
00:28:49,360 --> 00:28:53,039
um issues around border control and

743
00:28:50,720 --> 00:28:55,360
immigration um and they have separate

744
00:28:53,039 --> 00:28:58,399
provisions you know for that um I

745
00:28:55,360 --> 00:28:59,679
unfortunately I don't see and I wanted

746
00:28:58,399 --> 00:29:00,880
to say like you know African countries

747
00:28:59,679 --> 00:29:03,440
are thinking about developing and

748
00:29:00,880 --> 00:29:04,720
implementing AI in responsible ways but

749
00:29:03,440 --> 00:29:07,360
they don't necessarily take the

750
00:29:04,720 --> 00:29:10,399
forefront um of like these respective

751
00:29:07,360 --> 00:29:12,880
approaches compared to uh like how the

752
00:29:10,399 --> 00:29:15,039
EU has I would say positioned themselves

753
00:29:12,880 --> 00:29:18,600
to be. So those would probably be the

754
00:29:15,039 --> 00:29:21,279
main differences I see. Yeah. Cool.

755
00:29:18,600 --> 00:29:23,679
Question is like how much heterogeneity

756
00:29:21,279 --> 00:29:27,640
is there in sort of policies sort of at

757
00:29:23,679 --> 00:29:30,640
the highest levels of

758
00:29:27,640 --> 00:29:33,200
densities policies. Yeah. I would say

759
00:29:30,640 --> 00:29:35,520
for me I just you know see a lot of

760
00:29:33,200 --> 00:29:37,520
similarities or homogeneity um across

761
00:29:35,520 --> 00:29:39,919
these strategy documents and sometimes

762
00:29:37,520 --> 00:29:42,559
like you know you you start to see that

763
00:29:39,919 --> 00:29:44,000
they become very repetitive but um I

764
00:29:42,559 --> 00:29:45,919
know that countries are also trying to

765
00:29:44,000 --> 00:29:47,919
understand how AI aligns best with their

766
00:29:45,919 --> 00:29:49,039
respective national priorities. Um I

767
00:29:47,919 --> 00:29:51,279
don't think there honestly there's

768
00:29:49,039 --> 00:29:53,760
enough emphasis on doing that. Uh for

769
00:29:51,279 --> 00:29:55,840
example um I I'll talk about Angola

770
00:29:53,760 --> 00:29:57,760
later but um the country is actually

771
00:29:55,840 --> 00:29:59,200
very focused on oil and I don't think

772
00:29:57,760 --> 00:30:01,360
they have a they yeah they don't have an

773
00:29:59,200 --> 00:30:04,080
AI strategy um I know they do have a

774
00:30:01,360 --> 00:30:06,240
data protection strategy and so um I

775
00:30:04,080 --> 00:30:08,760
assume like any document they develop uh

776
00:30:06,240 --> 00:30:10,720
will probably more so align with

777
00:30:08,760 --> 00:30:12,559
basically you know trying to understand

778
00:30:10,720 --> 00:30:15,440
how AI can augment their respective like

779
00:30:12,559 --> 00:30:17,039
oil petroleum gas sector um as well and

780
00:30:15,440 --> 00:30:18,880
so I think that other African countries

781
00:30:17,039 --> 00:30:20,399
should take similar approaches but you

782
00:30:18,880 --> 00:30:23,760
know obviously there are other concerns

783
00:30:20,399 --> 00:30:29,000
concerns we um around climate um ethical

784
00:30:23,760 --> 00:30:29,000
uh issues and and bias as well. So yeah,

785
00:30:33,840 --> 00:30:37,440
China is comparable to the

786
00:30:42,440 --> 00:30:46,440
US China

787
00:31:04,480 --> 00:31:08,399
Yeah. So I would say it's still I would

788
00:31:07,120 --> 00:31:10,240
say hard to understand like China's

789
00:31:08,399 --> 00:31:12,399
influence on the African AI ecosystem. I

790
00:31:10,240 --> 00:31:13,760
think you know they've had uh really or

791
00:31:12,399 --> 00:31:15,679
made like really great progress and

792
00:31:13,760 --> 00:31:18,320
influence basically on infrastructure.

793
00:31:15,679 --> 00:31:21,760
So, you know, like ports, um, you know,

794
00:31:18,320 --> 00:31:24,880
um, airports, uh, roads, uh, shipping

795
00:31:21,760 --> 00:31:27,840
rails, railways, all that stuff. Um,

796
00:31:24,880 --> 00:31:28,880
it's interesting because I felt like

797
00:31:27,840 --> 00:31:30,480
there were a lot of the development

798
00:31:28,880 --> 00:31:32,720
agencies from Europe actually were

799
00:31:30,480 --> 00:31:36,880
playing a big role. So like GIZ from um

800
00:31:32,720 --> 00:31:38,399
from Germany um IDRC CEDA um USA a

801
00:31:36,880 --> 00:31:41,120
little bit now you know it's obviously

802
00:31:38,399 --> 00:31:44,240
like not really you know doing anything

803
00:31:41,120 --> 00:31:46,240
now but um and so a lot of my

804
00:31:44,240 --> 00:31:48,240
understanding or just like belief in a

805
00:31:46,240 --> 00:31:49,919
way was that these development agencies

806
00:31:48,240 --> 00:31:52,080
were essentially trying to counter

807
00:31:49,919 --> 00:31:54,640
China's influence in a way particularly

808
00:31:52,080 --> 00:31:56,000
especially the US um because they had um

809
00:31:54,640 --> 00:31:58,000
like this effort that was announced in

810
00:31:56,000 --> 00:32:01,120
the Biden administration um I think like

811
00:31:58,000 --> 00:32:03,600
global AI sharing something like that um

812
00:32:01,120 --> 00:32:05,360
I'm not sure if it will continue or not.

813
00:32:03,600 --> 00:32:07,120
Um and so I think again like China is

814
00:32:05,360 --> 00:32:09,039
actually very well positioned um to

815
00:32:07,120 --> 00:32:11,200
really start supporting like fundamental

816
00:32:09,039 --> 00:32:14,720
African research. Um again not sure how

817
00:32:11,200 --> 00:32:16,559
much that is happening. Um, but I think

818
00:32:14,720 --> 00:32:20,240
again they I don't like to see you know

819
00:32:16,559 --> 00:32:22,799
Africa be a I don't know like a ground

820
00:32:20,240 --> 00:32:25,360
or like a what am I I'm trying to say

821
00:32:22,799 --> 00:32:26,799
just like uh a place for people to kind

822
00:32:25,360 --> 00:32:28,559
of like pick and choose you know how

823
00:32:26,799 --> 00:32:30,240
they did with you know with the um

824
00:32:28,559 --> 00:32:31,919
Berlin convention and all that stuff as

825
00:32:30,240 --> 00:32:33,760
well. Um but you know honest

826
00:32:31,919 --> 00:32:36,559
unfortunately that's happening. Um I

827
00:32:33,760 --> 00:32:37,760
think the the long-term game or goal

828
00:32:36,559 --> 00:32:39,360
would be to move towards like

829
00:32:37,760 --> 00:32:40,960
sovereignty, data sovereignty, AA

830
00:32:39,360 --> 00:32:42,399
sovereignty, but we're still very much

831
00:32:40,960 --> 00:32:44,320
far away from there. But I think in the

832
00:32:42,399 --> 00:32:47,600
meantime, like African countries also

833
00:32:44,320 --> 00:32:50,080
have to understand um how they can best

834
00:32:47,600 --> 00:32:52,720
um like leverage AI um in ways that meet

835
00:32:50,080 --> 00:32:55,440
their national goals. And unfortunately

836
00:32:52,720 --> 00:32:58,120
um I would say like to the US's I say

837
00:32:55,440 --> 00:33:00,480
like dislike um many African countries

838
00:32:58,120 --> 00:33:02,640
ideologically align more so with China

839
00:33:00,480 --> 00:33:05,039
and Russia you know than with you know

840
00:33:02,640 --> 00:33:07,200
US and other democratic countries and so

841
00:33:05,039 --> 00:33:08,960
I think this is also something that um

842
00:33:07,200 --> 00:33:11,279
many governments are considering in

843
00:33:08,960 --> 00:33:12,399
terms of how they set up their alliances

844
00:33:11,279 --> 00:33:14,799
um with international development

845
00:33:12,399 --> 00:33:18,279
agencies or the countries themselves.

846
00:33:14,799 --> 00:33:18,279
Thank you so much.

847
00:33:22,960 --> 00:33:29,880
Mhm. Yeah.

848
00:33:26,880 --> 00:33:29,880
Mhm.

849
00:33:34,919 --> 00:33:38,919
Yeah. Mhm.

850
00:33:39,559 --> 00:33:43,120
Yeah. Yeah. This is a very tough

851
00:33:41,519 --> 00:33:45,919
question. It seems like you know you're

852
00:33:43,120 --> 00:33:47,480
well verssed in it um a bit yourself but

853
00:33:45,919 --> 00:33:49,840
I would say for

854
00:33:47,480 --> 00:33:52,559
me I don't even know if it's possible to

855
00:33:49,840 --> 00:33:54,240
do that now just because like the way of

856
00:33:52,559 --> 00:33:56,720
like I guess like AI diffusion or how

857
00:33:54,240 --> 00:33:58,640
like AI models um and tools and systems

858
00:33:56,720 --> 00:34:00,799
are spread across African countries and

859
00:33:58,640 --> 00:34:02,320
also just generally the world like we

860
00:34:00,799 --> 00:34:03,600
would really have to like start from the

861
00:34:02,320 --> 00:34:05,279
ground up but we don't have the

862
00:34:03,600 --> 00:34:08,399
resources you know to build these

863
00:34:05,279 --> 00:34:09,839
systems um or tools like natively um in

864
00:34:08,399 --> 00:34:11,599
ways you know again that align with

865
00:34:09,839 --> 00:34:14,159
African value systems

866
00:34:11,599 --> 00:34:17,240
um and also you know comprehensively

867
00:34:14,159 --> 00:34:20,399
integrate African data sets as well and

868
00:34:17,240 --> 00:34:22,159
so yeah I think again we're a bit far

869
00:34:20,399 --> 00:34:24,480
past that and it would really again take

870
00:34:22,159 --> 00:34:27,119
like kind of a revolution or just like a

871
00:34:24,480 --> 00:34:29,040
reframing or rethinking in terms of how

872
00:34:27,119 --> 00:34:31,839
um African researchers lead in AI

873
00:34:29,040 --> 00:34:33,599
development and also like um approach

874
00:34:31,839 --> 00:34:36,560
and also like what kind of models that

875
00:34:33,599 --> 00:34:38,000
they take um or methodology excuse me to

876
00:34:36,560 --> 00:34:42,639
build these systems in the first place.

877
00:34:38,000 --> 00:34:45,440
So thank you. Go ahead. So, how much of

878
00:34:42,639 --> 00:34:48,000
the strategy is sort of

879
00:34:45,440 --> 00:34:49,599
thinking about like starting from the

880
00:34:48,000 --> 00:34:51,919
ground up and building something

881
00:34:49,599 --> 00:34:55,520
natively versus like what's the right

882
00:34:51,919 --> 00:34:57,359
strategy to Vietnam?

883
00:34:55,520 --> 00:34:58,320
Like the vision.

884
00:34:57,359 --> 00:34:59,520
Yeah. Yeah, unfortunately I don't see

885
00:34:58,320 --> 00:35:02,480
like you know the building from the

886
00:34:59,520 --> 00:35:04,960
ground up um happening or being

887
00:35:02,480 --> 00:35:06,560
mentioned in these documents because um

888
00:35:04,960 --> 00:35:08,079
unfortunately I would say like African

889
00:35:06,560 --> 00:35:10,880
countries or researchers have become

890
00:35:08,079 --> 00:35:12,400
reliant um on these you know open source

891
00:35:10,880 --> 00:35:15,200
or models which you know happen to be

892
00:35:12,400 --> 00:35:17,280
more so open weight um like for example

893
00:35:15,200 --> 00:35:19,920
llama and like fine-tuning them and I

894
00:35:17,280 --> 00:35:21,839
think honestly it it's a bit of an

895
00:35:19,920 --> 00:35:23,760
easier way to approach AI development

896
00:35:21,839 --> 00:35:25,520
but again I don't think it's the right

897
00:35:23,760 --> 00:35:27,440
approach because I don't think these

898
00:35:25,520 --> 00:35:30,320
models are particularly built

899
00:35:27,440 --> 00:35:32,720
um you know for African linguistic

900
00:35:30,320 --> 00:35:34,079
context um which is something that I

901
00:35:32,720 --> 00:35:35,680
think that's why we need to really

902
00:35:34,079 --> 00:35:38,240
invest in this fundamental AI research

903
00:35:35,680 --> 00:35:40,079
across the continent um and then also

904
00:35:38,240 --> 00:35:42,720
even just like when we consider cultural

905
00:35:40,079 --> 00:35:44,960
needs and nuances and even like you know

906
00:35:42,720 --> 00:35:47,359
the size of these models are is really

907
00:35:44,960 --> 00:35:48,640
not feasible in general um so I would

908
00:35:47,359 --> 00:35:50,800
love to see more of that being

909
00:35:48,640 --> 00:35:54,160
integrated but it's really not

910
00:35:50,800 --> 00:35:56,560
unfortunately yeah awesome great yeah

911
00:35:54,160 --> 00:35:58,720
thanks for the great questions everyone

912
00:35:56,560 --> 00:36:00,880
Yeah. So now um I'll talk about um the

913
00:35:58,720 --> 00:36:03,040
AUA AI strategy. Not honestly won't go

914
00:36:00,880 --> 00:36:05,119
too deep into it, but um it basically

915
00:36:03,040 --> 00:36:08,079
aims to provide guidance um to African

916
00:36:05,119 --> 00:36:10,400
countries um to harness AI um to meet

917
00:36:08,079 --> 00:36:13,119
Africa's development aspirations. And

918
00:36:10,400 --> 00:36:15,680
this basically is a quote from um uh the

919
00:36:13,119 --> 00:36:17,839
the AI strategy itself. and they

920
00:36:15,680 --> 00:36:20,240
mentioned that the goal um is also to

921
00:36:17,839 --> 00:36:22,320
improve the well-being of African people

922
00:36:20,240 --> 00:36:24,240
um while promoting ethical use,

923
00:36:22,320 --> 00:36:25,839
minimizing potential risk and also

924
00:36:24,240 --> 00:36:28,400
leveraging different opportunities that

925
00:36:25,839 --> 00:36:31,200
AI could potentially bring. And so the

926
00:36:28,400 --> 00:36:33,599
African Union Executive Council endorsed

927
00:36:31,200 --> 00:36:36,480
the continental AI strategy during the

928
00:36:33,599 --> 00:36:38,320
45th ordinary session in Acra, Ghana. Um

929
00:36:36,480 --> 00:36:41,119
this happened last year from July 18th

930
00:36:38,320 --> 00:36:43,839
to 19th. Um and it was formally formally

931
00:36:41,119 --> 00:36:45,839
released on August 9th and it's expected

932
00:36:43,839 --> 00:36:48,240
to be fully endorsed by the AU head of

933
00:36:45,839 --> 00:36:49,920
state. Um I think it was supposed to

934
00:36:48,240 --> 00:36:53,200
happen earlier this year at the AU

935
00:36:49,920 --> 00:36:54,480
summit but it is still um in the process

936
00:36:53,200 --> 00:36:56,640
of you know going into full

937
00:36:54,480 --> 00:36:58,480
implementation and so again still

938
00:36:56,640 --> 00:37:00,880
waiting to understand how this framework

939
00:36:58,480 --> 00:37:03,520
will be binding and also whether or not

940
00:37:00,880 --> 00:37:06,079
the AU will um improve enforcement

941
00:37:03,520 --> 00:37:08,640
capacity um to ensure that African all

942
00:37:06,079 --> 00:37:11,440
African countries or AU member states um

943
00:37:08,640 --> 00:37:14,079
can be on uh the path to developing AI

944
00:37:11,440 --> 00:37:16,560
strategies and eventually AI policies

945
00:37:14,079 --> 00:37:17,599
which is the end goal.

946
00:37:16,560 --> 00:37:19,359
So now let's talk about some

947
00:37:17,599 --> 00:37:20,640
implications of AI in Africa. I think uh

948
00:37:19,359 --> 00:37:22,880
this is what a lot of people will be

949
00:37:20,640 --> 00:37:24,560
interested in. Um and I'm sure you are

950
00:37:22,880 --> 00:37:27,040
aware of the different challenges

951
00:37:24,560 --> 00:37:30,079
particularly you know from AI being

952
00:37:27,040 --> 00:37:31,960
purported or like posed um as a way to

953
00:37:30,079 --> 00:37:34,560
help African countries fasttrack

954
00:37:31,960 --> 00:37:36,320
development. Um and so again we know

955
00:37:34,560 --> 00:37:38,240
that these technologies are you know

956
00:37:36,320 --> 00:37:40,240
filled with different risk um and

957
00:37:38,240 --> 00:37:42,000
implica and implications. Um

958
00:37:40,240 --> 00:37:44,480
particularly we see that a lot of

959
00:37:42,000 --> 00:37:47,000
literature um on bias and limitations of

960
00:37:44,480 --> 00:37:49,839
AI uh really focused on domains like

961
00:37:47,000 --> 00:37:51,440
healthcare, employment and policing. Um

962
00:37:49,839 --> 00:37:54,000
unfortunately we do see a lot of this

963
00:37:51,440 --> 00:37:55,280
work focused um on western context and

964
00:37:54,000 --> 00:37:57,599
this is something I've you know written

965
00:37:55,280 --> 00:37:59,920
about you know mentioning how you know

966
00:37:57,599 --> 00:38:01,680
things social constructs like race may

967
00:37:59,920 --> 00:38:03,920
not necessarily be applicable across

968
00:38:01,680 --> 00:38:06,240
contexts like Africa you know suffering

969
00:38:03,920 --> 00:38:07,720
countries like South Africa for example

970
00:38:06,240 --> 00:38:10,400
um where we do see these racial

971
00:38:07,720 --> 00:38:12,400
stratifications um but again I think

972
00:38:10,400 --> 00:38:14,880
it's really important to emphasize or

973
00:38:12,400 --> 00:38:16,960
promote um you know contextual AI

974
00:38:14,880 --> 00:38:19,200
research that really understands things

975
00:38:16,960 --> 00:38:20,880
like cast and tribe and religion and

976
00:38:19,200 --> 00:38:22,800
also the intersections of these

977
00:38:20,880 --> 00:38:25,280
identities um to really promote this

978
00:38:22,800 --> 00:38:27,680
contextual understanding um of bias and

979
00:38:25,280 --> 00:38:29,440
the implications of AI across Africa and

980
00:38:27,680 --> 00:38:32,720
also across the rest of the the global

981
00:38:29,440 --> 00:38:34,720
south or uh the global majority. And so,

982
00:38:32,720 --> 00:38:36,960
um, this is a stat I mention a lot. Um,

983
00:38:34,720 --> 00:38:39,680
and we see that, um, African countries

984
00:38:36,960 --> 00:38:42,720
are spending about a billion dollars a

985
00:38:39,680 --> 00:38:44,400
year, um, on surveillance, uh, contracts

986
00:38:42,720 --> 00:38:47,440
with companies that are based, um, in

987
00:38:44,400 --> 00:38:50,240
the US, the UK, uh, China, across the

988
00:38:47,440 --> 00:38:52,160
EU, and also Israel. In these countries,

989
00:38:50,240 --> 00:38:54,160
uh, we see that these technologies um,

990
00:38:52,160 --> 00:38:56,640
have been used to unjustly hold citizens

991
00:38:54,160 --> 00:38:58,000
in detention um, and also um, because

992
00:38:56,640 --> 00:39:00,400
they've made critical posts to the

993
00:38:58,000 --> 00:39:01,760
governments and also track activities of

994
00:39:00,400 --> 00:39:03,200
journalists. Um there's a really

995
00:39:01,760 --> 00:39:05,599
prominent jour journalist in Eastern

996
00:39:03,200 --> 00:39:08,000
Africa uh eastern southern Africa uh

997
00:39:05,599 --> 00:39:09,680
Gregory Gone um who has actually been

998
00:39:08,000 --> 00:39:12,079
jailed and um talked about his

999
00:39:09,680 --> 00:39:14,560
experiences um you know dealing with a

1000
00:39:12,079 --> 00:39:17,480
AI enabled surveillance because um of

1001
00:39:14,560 --> 00:39:19,680
his outspokenenness against

1002
00:39:17,480 --> 00:39:21,520
governments. We've also seen and this is

1003
00:39:19,680 --> 00:39:23,599
a very prominent topic at the moment

1004
00:39:21,520 --> 00:39:25,119
which is great um about the harms that

1005
00:39:23,599 --> 00:39:27,440
you know data annotators and content

1006
00:39:25,119 --> 00:39:29,680
moderators have faced um particularly

1007
00:39:27,440 --> 00:39:32,320
within Africa Kenya is seen as the hot

1008
00:39:29,680 --> 00:39:34,720
spot or the hub um for AI development

1009
00:39:32,320 --> 00:39:36,800
and particularly like AI labeling and

1010
00:39:34,720 --> 00:39:39,280
content moderation uh within the

1011
00:39:36,800 --> 00:39:40,880
continent and again I think because you

1012
00:39:39,280 --> 00:39:43,839
see that many African countries have

1013
00:39:40,880 --> 00:39:46,560
issues um around you know unemployment

1014
00:39:43,839 --> 00:39:48,720
and even undermployment um that you know

1015
00:39:46,560 --> 00:39:51,359
this say data exploitation

1016
00:39:48,720 --> 00:39:53,760
And also uh you know this form of labor

1017
00:39:51,359 --> 00:39:55,440
may become more widespread because you

1018
00:39:53,760 --> 00:39:57,440
know there's a lot of young people in

1019
00:39:55,440 --> 00:39:59,200
Africa they're looking for opportunities

1020
00:39:57,440 --> 00:40:01,200
um and you know data labeling is

1021
00:39:59,200 --> 00:40:04,000
relatively easy to do um you know

1022
00:40:01,200 --> 00:40:06,240
despite the strenuous task and and other

1023
00:40:04,000 --> 00:40:08,480
issues associated with it as well. Um

1024
00:40:06,240 --> 00:40:10,960
again we do see a lack um you know of

1025
00:40:08,480 --> 00:40:13,119
robust data protections um and AI

1026
00:40:10,960 --> 00:40:15,040
policies throughout the continent's our

1027
00:40:13,119 --> 00:40:17,359
strategies at the moment uh which we're

1028
00:40:15,040 --> 00:40:19,280
you know are mainly focused on um and I

1029
00:40:17,359 --> 00:40:22,160
could think this will have a greater

1030
00:40:19,280 --> 00:40:24,800
impact um because you or lead to greater

1031
00:40:22,160 --> 00:40:27,599
levels of misuse um as AI continues to

1032
00:40:24,800 --> 00:40:29,680
grow um in reach again you know I don't

1033
00:40:27,599 --> 00:40:31,839
want to highlight Africa as being slow

1034
00:40:29,680 --> 00:40:33,920
in the AI regulation race because

1035
00:40:31,839 --> 00:40:36,960
technically you know the EU AI act is

1036
00:40:33,920 --> 00:40:39,599
the most uh prominent legislation. Um,

1037
00:40:36,960 --> 00:40:42,160
and I think mainly the most like only

1038
00:40:39,599 --> 00:40:43,520
the only enacted regulation, excuse me.

1039
00:40:42,160 --> 00:40:46,240
But again, there's still a lot of

1040
00:40:43,520 --> 00:40:50,839
efforts um that African countries need

1041
00:40:46,240 --> 00:40:50,839
to focus on as well. Go ahead.

1042
00:41:02,319 --> 00:41:06,160
Mhm.

1043
00:41:04,400 --> 00:41:07,680
Yeah.

1044
00:41:06,160 --> 00:41:11,400
you saying that the potential of AI for

1045
00:41:07,680 --> 00:41:11,400
that? Yes. Okay.

1046
00:41:11,560 --> 00:41:14,960
Uh yeah, I know Google's doing this. Um

1047
00:41:14,000 --> 00:41:17,119
they have a really interesting like

1048
00:41:14,960 --> 00:41:18,800
flood forecasting tool um that they've

1049
00:41:17,119 --> 00:41:20,319
been leveraging and actually has been

1050
00:41:18,800 --> 00:41:22,560
helpful in predicting floods across

1051
00:41:20,319 --> 00:41:24,800
Africa also mainly across the world too

1052
00:41:22,560 --> 00:41:26,720
and um they have been able to like

1053
00:41:24,800 --> 00:41:28,400
integrate this or allow governments to

1054
00:41:26,720 --> 00:41:31,680
leverage this information to like help

1055
00:41:28,400 --> 00:41:33,280
with like uh warning systems and

1056
00:41:31,680 --> 00:41:34,960
everything. Um there's also a really

1057
00:41:33,280 --> 00:41:36,560
interesting project um from the

1058
00:41:34,960 --> 00:41:39,520
distributed air research institute led

1059
00:41:36,560 --> 00:41:41,200
by Tim Gabru um and one of the fellows

1060
00:41:39,520 --> 00:41:43,520
there um I always I don't want to

1061
00:41:41,200 --> 00:41:45,440
pronounce her name wrong but uh Resa J

1062
00:41:43,520 --> 00:41:47,520
Safala uh she is in South Africa and

1063
00:41:45,440 --> 00:41:49,760
she's actually leveraged um AI based

1064
00:41:47,520 --> 00:41:52,079
geospatial mapping to actually map like

1065
00:41:49,760 --> 00:41:53,760
apartheid um and understanding like the

1066
00:41:52,079 --> 00:41:56,400
differences in housing and also just

1067
00:41:53,760 --> 00:41:57,680
like geographic or geographical like um

1068
00:41:56,400 --> 00:41:59,839
you know structures and everything like

1069
00:41:57,680 --> 00:42:01,280
that too. So um that work is super

1070
00:41:59,839 --> 00:42:03,760
interesting and I think there's many

1071
00:42:01,280 --> 00:42:05,200
more implications for um a lot of work

1072
00:42:03,760 --> 00:42:07,920
you know actually from like MIT

1073
00:42:05,200 --> 00:42:10,720
researchers and um I my colleagues like

1074
00:42:07,920 --> 00:42:12,720
Lily Zoo uh for example she's starting a

1075
00:42:10,720 --> 00:42:14,800
professorship at Colombia and I think

1076
00:42:12,720 --> 00:42:16,480
next year later this year um she's done

1077
00:42:14,800 --> 00:42:19,280
a lot of work on like conservation and

1078
00:42:16,480 --> 00:42:21,440
like mapping using AI too. So, um I

1079
00:42:19,280 --> 00:42:24,160
think there's a lot of um Oh, sorry.

1080
00:42:21,440 --> 00:42:26,240
They Lily was at Harvard, excuse me. Um

1081
00:42:24,160 --> 00:42:28,160
uh but uh Meen Tombbe was like the

1082
00:42:26,240 --> 00:42:30,079
professor that was uh like leading or

1083
00:42:28,160 --> 00:42:32,640
steering that work too. Um so there's a

1084
00:42:30,079 --> 00:42:34,480
lot of I think like promise in that

1085
00:42:32,640 --> 00:42:36,800
domain and I I actually think it's one

1086
00:42:34,480 --> 00:42:40,400
of the use cases of AI that I'm a bit

1087
00:42:36,800 --> 00:42:42,560
more I would say like fond of. So yeah.

1088
00:42:40,400 --> 00:42:44,079
Cool. All right.

1089
00:42:42,560 --> 00:42:45,760
So yeah, so this is some work um that

1090
00:42:44,079 --> 00:42:47,920
I've done over the past uh like year and

1091
00:42:45,760 --> 00:42:50,000
a half or so um that really under tries

1092
00:42:47,920 --> 00:42:51,839
to like unpack um the growing discourse

1093
00:42:50,000 --> 00:42:53,440
on the negative impacts um of

1094
00:42:51,839 --> 00:42:55,440
technologies like generative AI for

1095
00:42:53,440 --> 00:42:57,760
example. Um this work was really focused

1096
00:42:55,440 --> 00:42:59,599
on myths and disinformation um

1097
00:42:57,760 --> 00:43:01,200
particularly in the context of African

1098
00:42:59,599 --> 00:43:03,680
elections and other democratic

1099
00:43:01,200 --> 00:43:06,240
processes. um because you know not just

1100
00:43:03,680 --> 00:43:08,880
in the US but within Africa we've seen a

1101
00:43:06,240 --> 00:43:10,720
lot um of interesting usage um in terms

1102
00:43:08,880 --> 00:43:15,040
of how you know these tools have had an

1103
00:43:10,720 --> 00:43:16,800
impact um again on elections. Go ahead.

1104
00:43:15,040 --> 00:43:19,079
One of the things that at least has been

1105
00:43:16,800 --> 00:43:24,599
true to my

1106
00:43:19,079 --> 00:43:24,599
friends a lot of missing disinformation.

1107
00:43:25,440 --> 00:43:30,319
Yeah. How is that true here? How hard is

1108
00:43:27,680 --> 00:43:30,319
it to

1109
00:43:31,720 --> 00:43:36,560
study Twitter?

1110
00:43:34,240 --> 00:43:38,560
Yeah. Yes. I would say like very similar

1111
00:43:36,560 --> 00:43:40,240
for Africa too. And we also see like how

1112
00:43:38,560 --> 00:43:42,079
disinformation and misinformation also

1113
00:43:40,240 --> 00:43:44,800
moves offline particularly through like

1114
00:43:42,079 --> 00:43:46,960
radio um and also like print media too.

1115
00:43:44,800 --> 00:43:48,240
So, this actually makes it even harder

1116
00:43:46,960 --> 00:43:49,760
um because we know like there's some

1117
00:43:48,240 --> 00:43:51,359
social media companies, I'm not sure if

1118
00:43:49,760 --> 00:43:52,960
Twitter's still doing this. Um but

1119
00:43:51,359 --> 00:43:54,880
basically like if you know the community

1120
00:43:52,960 --> 00:43:56,800
notes and if you saw something they

1121
00:43:54,880 --> 00:43:58,960
would actually notify you after you saw

1122
00:43:56,800 --> 00:44:00,480
it as well. Um it's very hard to do that

1123
00:43:58,960 --> 00:44:02,319
you know through you know these

1124
00:44:00,480 --> 00:44:04,880
encrypted platforms like WhatsApp uh

1125
00:44:02,319 --> 00:44:07,119
signal etc. And again even more so

1126
00:44:04,880 --> 00:44:10,079
harder for um you know print and and

1127
00:44:07,119 --> 00:44:12,000
radio media as well. Uh so I don't think

1128
00:44:10,079 --> 00:44:14,720
we have any good statistics um on this

1129
00:44:12,000 --> 00:44:16,720
in Africa and I think just because it's

1130
00:44:14,720 --> 00:44:19,000
a a measurement problem um that's really

1131
00:44:16,720 --> 00:44:21,520
hard to to focus on. So yeah.

1132
00:44:19,000 --> 00:44:23,040
Cool. All right. And so when it comes to

1133
00:44:21,520 --> 00:44:25,440
this information just to give a very

1134
00:44:23,040 --> 00:44:28,480
brief um definition it's the intentional

1135
00:44:25,440 --> 00:44:31,200
creation and spread of deliberative

1136
00:44:28,480 --> 00:44:33,040
sorry deliberately deceptive information

1137
00:44:31,200 --> 00:44:35,520
um to mislead or influence people

1138
00:44:33,040 --> 00:44:37,119
communities and also institutions. Um

1139
00:44:35,520 --> 00:44:38,119
again we see that African countries

1140
00:44:37,119 --> 00:44:40,400
particularly struggle with

1141
00:44:38,119 --> 00:44:43,280
disinformation and research um from

1142
00:44:40,400 --> 00:44:45,680
Wasammen and Madrid morales shows that

1143
00:44:43,280 --> 00:44:48,240
media consumers in countries like Kenya,

1144
00:44:45,680 --> 00:44:50,400
Nigeria and South Africa are regularly

1145
00:44:48,240 --> 00:44:52,240
exposed to disinformation.

1146
00:44:50,400 --> 00:44:54,480
Uh we've also see that these issues

1147
00:44:52,240 --> 00:44:56,880
around dis and misinformation have been

1148
00:44:54,480 --> 00:44:58,800
exacerbated by the growth um um or

1149
00:44:56,880 --> 00:45:00,720
access of information you know through

1150
00:44:58,800 --> 00:45:02,880
platforms like social media and then

1151
00:45:00,720 --> 00:45:05,280
again even you know further exacerbated

1152
00:45:02,880 --> 00:45:07,400
by the introduction of generative AI um

1153
00:45:05,280 --> 00:45:09,280
in content

1154
00:45:07,400 --> 00:45:11,839
production and so when it comes to

1155
00:45:09,280 --> 00:45:14,240
African elections uh we've seen a lot of

1156
00:45:11,839 --> 00:45:17,359
different uh interesting use cases of

1157
00:45:14,240 --> 00:45:19,359
generative AI um and I think something

1158
00:45:17,359 --> 00:45:21,040
that I would love to see in future work

1159
00:45:19,359 --> 00:45:23,599
it's not a focus of mine at the moment,

1160
00:45:21,040 --> 00:45:25,839
but really understanding like the usage

1161
00:45:23,599 --> 00:45:28,400
and impact um of AI across African

1162
00:45:25,839 --> 00:45:30,240
elections. Um there's been reports and

1163
00:45:28,400 --> 00:45:32,560
surveys that show you know that African

1164
00:45:30,240 --> 00:45:35,440
governments are actively already um

1165
00:45:32,560 --> 00:45:38,200
leveraging AI to assist uh with um

1166
00:45:35,440 --> 00:45:40,240
processes like authentication um voter

1167
00:45:38,200 --> 00:45:42,960
registration management and also

1168
00:45:40,240 --> 00:45:44,800
engagement and also you know some things

1169
00:45:42,960 --> 00:45:47,920
like detecting cyber threats um and

1170
00:45:44,800 --> 00:45:50,640
aiding in oversight um and decision-m

1171
00:45:47,920 --> 00:45:52,480
and so we've seen a lot of um AI uh

1172
00:45:50,640 --> 00:45:54,800
generated propaganda that have

1173
00:45:52,480 --> 00:45:57,440
influenced um elections or even

1174
00:45:54,800 --> 00:46:00,240
precipitated coups um in countries like

1175
00:45:57,440 --> 00:46:01,920
Nigeria, Burkina Faso and Sineagal. And

1176
00:46:00,240 --> 00:46:04,480
this really underscores the need for

1177
00:46:01,920 --> 00:46:06,119
more comprehensive um detection and

1178
00:46:04,480 --> 00:46:08,560
mitigation efforts as

1179
00:46:06,119 --> 00:46:11,599
well. And so this report was from

1180
00:46:08,560 --> 00:46:13,599
December 20 uh November 2024. Um but

1181
00:46:11,599 --> 00:46:16,240
Ghana held their elections in December

1182
00:46:13,599 --> 00:46:19,119
of last year and show that the incumbent

1183
00:46:16,240 --> 00:46:21,520
political party within Ghana was using

1184
00:46:19,119 --> 00:46:24,160
AI to spread misinformation about

1185
00:46:21,520 --> 00:46:25,920
opposing candidates. Um but actually I

1186
00:46:24,160 --> 00:46:28,640
don't it's also hard to understand the

1187
00:46:25,920 --> 00:46:31,200
impact of dis this and misinformation um

1188
00:46:28,640 --> 00:46:33,520
on voter um I would say I would say

1189
00:46:31,200 --> 00:46:36,480
intentions or choices because the

1190
00:46:33,520 --> 00:46:38,319
opposing candidate party actually won um

1191
00:46:36,480 --> 00:46:40,960
and so we saw that they saw that there

1192
00:46:38,319 --> 00:46:43,040
were tweets um that were using AI

1193
00:46:40,960 --> 00:46:44,480
generated profile images and also they

1194
00:46:43,040 --> 00:46:47,839
would post between certain times of the

1195
00:46:44,480 --> 00:46:51,359
day um and Ghana time or Ghanaian time

1196
00:46:47,839 --> 00:46:52,880
um as well. And so the again as I

1197
00:46:51,359 --> 00:46:55,520
mentioned the opposing party actually

1198
00:46:52,880 --> 00:46:57,119
won. So uh would love to see if there

1199
00:46:55,520 --> 00:46:59,680
have been like further analysis trying

1200
00:46:57,119 --> 00:47:02,319
to unpack um the actual influence of

1201
00:46:59,680 --> 00:47:04,240
this content. And so this is a really

1202
00:47:02,319 --> 00:47:07,440
interesting case and I like to bring it

1203
00:47:04,240 --> 00:47:09,280
up because it happened um in 2018 and so

1204
00:47:07,440 --> 00:47:11,200
this is when I would say like GANs were

1205
00:47:09,280 --> 00:47:13,359
really coming into play and you know

1206
00:47:11,200 --> 00:47:15,200
obviously way before tools like chatbt

1207
00:47:13,359 --> 00:47:18,480
and you know other image generators like

1208
00:47:15,200 --> 00:47:20,960
Dolly and and and Mjourney and others

1209
00:47:18,480 --> 00:47:24,160
and so we've seen that um political

1210
00:47:20,960 --> 00:47:26,880
propaganda has shown to impact coups um

1211
00:47:24,160 --> 00:47:29,839
before during and after they happen and

1212
00:47:26,880 --> 00:47:32,240
so this happened um in 2018 December

1213
00:47:29,839 --> 00:47:34,400
2018 and this is a video that claimed to

1214
00:47:32,240 --> 00:47:36,800
depict Ali Bango uh who was the

1215
00:47:34,400 --> 00:47:38,800
president of Gabon at the time and it

1216
00:47:36,800 --> 00:47:40,640
stirred concern on social media because

1217
00:47:38,800 --> 00:47:42,880
people noticed that um there were

1218
00:47:40,640 --> 00:47:45,839
unnatural expressions you know his eyes

1219
00:47:42,880 --> 00:47:47,440
weren't moving um his lips were not

1220
00:47:45,839 --> 00:47:49,760
necessarily super consistent with the

1221
00:47:47,440 --> 00:47:52,079
words um and also the posture was

1222
00:47:49,760 --> 00:47:54,480
unnatural you know for him because he

1223
00:47:52,079 --> 00:47:57,040
was suspected to be very ill um and

1224
00:47:54,480 --> 00:47:58,960
undergoing treatment and so reports

1225
00:47:57,040 --> 00:48:00,720
claimed that uh you know this video

1226
00:47:58,960 --> 00:48:03,520
raised concerns about his ability to

1227
00:48:00,720 --> 00:48:06,560
rule and actually sparked a coup uh in

1228
00:48:03,520 --> 00:48:08,720
January of 2019, but it later failed. Um

1229
00:48:06,560 --> 00:48:10,720
and so again um you know this has been

1230
00:48:08,720 --> 00:48:13,280
happening you know for you know about

1231
00:48:10,720 --> 00:48:14,800
seven years if not longer now. And so I

1232
00:48:13,280 --> 00:48:17,280
think there still needs to be a bit more

1233
00:48:14,800 --> 00:48:19,319
awareness in terms of how generative AI

1234
00:48:17,280 --> 00:48:21,280
and even you know more recent

1235
00:48:19,319 --> 00:48:23,079
technologies continue to impact

1236
00:48:21,280 --> 00:48:26,000
different processes across

1237
00:48:23,079 --> 00:48:29,200
Africa. And so in Bkina Foso's most

1238
00:48:26,000 --> 00:48:30,559
recent coup um in September 2022 um

1239
00:48:29,200 --> 00:48:33,839
there's actually a really interesting

1240
00:48:30,559 --> 00:48:36,880
series of AI generated images or videos

1241
00:48:33,839 --> 00:48:38,720
um from Americanbased pan-Africanist and

1242
00:48:36,880 --> 00:48:41,599
so they appear to express support for

1243
00:48:38,720 --> 00:48:43,359
the new regime um and these videos were

1244
00:48:41,599 --> 00:48:45,760
initially detected on Twitter and

1245
00:48:43,359 --> 00:48:47,440
Facebook and were also shared um by

1246
00:48:45,760 --> 00:48:49,440
videos uh by people who actually

1247
00:48:47,440 --> 00:48:51,680
received these videos through WhatsApp.

1248
00:48:49,440 --> 00:48:54,880
Um the videos were created um from the

1249
00:48:51,680 --> 00:48:56,720
AI generated application Synthesia um

1250
00:48:54,880 --> 00:48:59,920
and the company actually confirmed the

1251
00:48:56,720 --> 00:49:02,400
user banned them um but they never ideal

1252
00:48:59,920 --> 00:49:06,160
uh reveal the identity of the person

1253
00:49:02,400 --> 00:49:09,280
also. Are we good on time? I'm not sure.

1254
00:49:06,160 --> 00:49:11,200
Okay, cool. Okay, cool. No worries.

1255
00:49:09,280 --> 00:49:12,640
Cool. Yeah. So again, we see that

1256
00:49:11,200 --> 00:49:14,559
generative AA has a really strong

1257
00:49:12,640 --> 00:49:17,119
potential to impact democratic processes

1258
00:49:14,559 --> 00:49:19,599
across Africa uh primarily in elections.

1259
00:49:17,119 --> 00:49:21,119
Um again I'm asked you know there have

1260
00:49:19,599 --> 00:49:23,599
been a lot of coups particularly within

1261
00:49:21,119 --> 00:49:26,480
the sahilian region um within west

1262
00:49:23,599 --> 00:49:28,640
western Africa and so I think there's a

1263
00:49:26,480 --> 00:49:30,640
lot more potential or possibilities to

1264
00:49:28,640 --> 00:49:33,440
understand um you know the role of

1265
00:49:30,640 --> 00:49:35,599
generative AI um in any of any of these

1266
00:49:33,440 --> 00:49:37,359
respective events and so kind of just to

1267
00:49:35,599 --> 00:49:39,920
wrap up um I'll talk about some AI

1268
00:49:37,359 --> 00:49:42,319
policy opportunities uh for Africa and

1269
00:49:39,920 --> 00:49:44,079
really again thinking about we have so

1270
00:49:42,319 --> 00:49:46,160
many pressing challenges um this

1271
00:49:44,079 --> 00:49:48,079
includes refining social services uh

1272
00:49:46,160 --> 00:49:49,280
tackling insec security, uh, planning

1273
00:49:48,079 --> 00:49:51,599
for climate change, building

1274
00:49:49,280 --> 00:49:54,720
infrastructure, um, and also fighting

1275
00:49:51,599 --> 00:49:56,000
corruption. Um, and so sometimes, in my

1276
00:49:54,720 --> 00:49:59,040
opinion, they really take greater

1277
00:49:56,000 --> 00:50:00,559
precedence over regulating AI. And so,

1278
00:49:59,040 --> 00:50:02,559
however, I think there, you know, are

1279
00:50:00,559 --> 00:50:04,000
efforts needed by African countries to

1280
00:50:02,559 --> 00:50:06,400
concurrently work towards addressing

1281
00:50:04,000 --> 00:50:09,440
these issues and also developing robust

1282
00:50:06,400 --> 00:50:11,359
data and AI regulation. And so, this is

1283
00:50:09,440 --> 00:50:13,680
a paper um, I wrote with some colleagues

1284
00:50:11,359 --> 00:50:16,160
last year um, that focused on uh, case

1285
00:50:13,680 --> 00:50:18,400
studies of policy development in Africa.

1286
00:50:16,160 --> 00:50:20,640
Um and so we show that you know African

1287
00:50:18,400 --> 00:50:22,800
countries face a range of challenges um

1288
00:50:20,640 --> 00:50:24,800
in meeting their technological potential

1289
00:50:22,800 --> 00:50:27,040
and you know this includes weak or

1290
00:50:24,800 --> 00:50:29,680
insufficient data protection regimes um

1291
00:50:27,040 --> 00:50:31,680
and then also um a lack or complications

1292
00:50:29,680 --> 00:50:33,599
in achieving robust oversight frameworks

1293
00:50:31,680 --> 00:50:36,160
and then honestly like limited uh

1294
00:50:33,599 --> 00:50:38,160
resources to devote specifically to um

1295
00:50:36,160 --> 00:50:41,119
AI governance and development and I

1296
00:50:38,160 --> 00:50:43,599
mentioned Angola and because of their

1297
00:50:41,119 --> 00:50:46,800
respective priorities in terms of um

1298
00:50:43,599 --> 00:50:49,520
scaling um the oil petroleum ecosystem

1299
00:50:46,800 --> 00:50:52,079
AI honestly isn't as a priority is not a

1300
00:50:49,520 --> 00:50:53,920
priority for the country and so just to

1301
00:50:52,079 --> 00:50:57,040
wrap up um these are some of the I would

1302
00:50:53,920 --> 00:50:59,119
say areas I think you know are most

1303
00:50:57,040 --> 00:51:01,119
essential it's not super comprehensive I

1304
00:50:59,119 --> 00:51:03,040
don't think it's meant to be but really

1305
00:51:01,119 --> 00:51:04,640
thinking about how um African

1306
00:51:03,040 --> 00:51:06,559
governments can focus on strengthening

1307
00:51:04,640 --> 00:51:08,640
data and computing infrastructure uh

1308
00:51:06,559 --> 00:51:11,200
which is you know obviously helpful for

1309
00:51:08,640 --> 00:51:13,520
things outside of AI um also really

1310
00:51:11,200 --> 00:51:15,839
thinking about increasing this regional

1311
00:51:13,520 --> 00:51:17,359
and and continental cooperation

1312
00:51:15,839 --> 00:51:18,960
um particularly you know as I mentioned

1313
00:51:17,359 --> 00:51:22,240
the role of these regional economic

1314
00:51:18,960 --> 00:51:23,599
communities um in order to bolster um

1315
00:51:22,240 --> 00:51:26,319
countries that don't necessarily have

1316
00:51:23,599 --> 00:51:28,400
the individual capacity um to enact and

1317
00:51:26,319 --> 00:51:30,880
draft regulations and then also really

1318
00:51:28,400 --> 00:51:32,559
thinking about um enhancing AI and data

1319
00:51:30,880 --> 00:51:34,800
governance also including things like

1320
00:51:32,559 --> 00:51:37,440
reform uh which is uh something I've

1321
00:51:34,800 --> 00:51:39,520
read written about recently as well um

1322
00:51:37,440 --> 00:51:41,760
and then you know obviously to help

1323
00:51:39,520 --> 00:51:44,079
support AI ecosystems there needs to be

1324
00:51:41,760 --> 00:51:46,400
efforts to expand AI education um and

1325
00:51:44,079 --> 00:51:48,400
also employment opportunities um many of

1326
00:51:46,400 --> 00:51:50,240
which will come through entrepreneurship

1327
00:51:48,400 --> 00:51:52,240
um as we've seen in the case of the US

1328
00:51:50,240 --> 00:51:54,319
for example um and then again something

1329
00:51:52,240 --> 00:51:56,160
I'm very fun um I would say passionate

1330
00:51:54,319 --> 00:51:59,200
about is accelerating fundamental AI

1331
00:51:56,160 --> 00:52:01,680
research um because you know African uh

1332
00:51:59,200 --> 00:52:03,359
AI that's used in Africa uh needs to be

1333
00:52:01,680 --> 00:52:05,599
developed you know to fit the contextual

1334
00:52:03,359 --> 00:52:07,760
needs um and the daily realities of

1335
00:52:05,599 --> 00:52:09,040
Africans um and then finally um

1336
00:52:07,760 --> 00:52:10,880
something something I don't think that

1337
00:52:09,040 --> 00:52:13,760
is addressed enough is really just

1338
00:52:10,880 --> 00:52:16,160
improving this um public engagement uh

1339
00:52:13,760 --> 00:52:18,240
within AI and really having just like

1340
00:52:16,160 --> 00:52:20,240
the average person understand you know

1341
00:52:18,240 --> 00:52:22,720
about data governance, data privacy, you

1342
00:52:20,240 --> 00:52:24,480
know AI regulation as well um and

1343
00:52:22,720 --> 00:52:27,040
soliciting input from these um

1344
00:52:24,480 --> 00:52:29,680
stakeholders before you know uh

1345
00:52:27,040 --> 00:52:31,680
strategies or policies come into action

1346
00:52:29,680 --> 00:52:34,160
um and then also ensuring that um they

1347
00:52:31,680 --> 00:52:36,559
are included in processes to refine um

1348
00:52:34,160 --> 00:52:39,119
and improve um you know policies and

1349
00:52:36,559 --> 00:52:41,040
strategies as well. Um so I'll end here

1350
00:52:39,119 --> 00:52:42,720
and take any questions but thank you all

1351
00:52:41,040 --> 00:52:44,160
for attending. I know it's a very busy

1352
00:52:42,720 --> 00:52:49,079
point in the semester. Um, so I

1353
00:52:44,160 --> 00:52:49,079
appreciate the the participation. So,


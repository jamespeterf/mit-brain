1
00:00:00,781 --> 00:00:03,864
(graphics whooshing)

2
00:00:06,450 --> 00:00:10,117
So, let's look at the next question.

3
00:00:10,117 --> 00:00:14,790
"Large language models often
generate code that looks right,

4
00:00:14,790 --> 00:00:16,410
but fails in practice.

5
00:00:16,410 --> 00:00:20,850
So, how do we make this
systems more reliable?"

6
00:00:20,850 --> 00:00:22,980
So, this is actually
a really good question

7
00:00:22,980 --> 00:00:24,180
because this is a question

8
00:00:24,180 --> 00:00:27,540
that the programming systems
community has been working on

9
00:00:27,540 --> 00:00:29,760
actually with a fair bit of success

10
00:00:29,760 --> 00:00:31,800
over the last two decades.

11
00:00:31,800 --> 00:00:35,520
You know, I remember when
I had my first laptop,

12
00:00:35,520 --> 00:00:39,000
I could never run it
probably for more than a day

13
00:00:39,000 --> 00:00:41,280
without the machine crashing, right?

14
00:00:41,280 --> 00:00:43,110
And compared to that,

15
00:00:43,110 --> 00:00:45,390
the level of reliability
that we have today

16
00:00:45,390 --> 00:00:49,080
in our computer systems is
actually quite remarkable.

17
00:00:49,080 --> 00:00:52,110
And a lot of it is due to techniques

18
00:00:52,110 --> 00:00:53,970
that we have developed over the years

19
00:00:53,970 --> 00:00:58,970
to analyze programs, to
help find bugs and software,

20
00:00:59,190 --> 00:01:01,140
to help even identify

21
00:01:01,140 --> 00:01:03,720
certain kinds of security vulnerabilities.

22
00:01:03,720 --> 00:01:05,760
Now, the tools are not perfect,

23
00:01:05,760 --> 00:01:09,300
which is why we still have
lots of buggy software.

24
00:01:09,300 --> 00:01:11,700
And they do have one major shortcoming,

25
00:01:11,700 --> 00:01:14,760
which is that they tend
to be pretty hard to use

26
00:01:14,760 --> 00:01:18,510
and require a very high level of expertise

27
00:01:18,510 --> 00:01:19,343
in order to use them,

28
00:01:19,343 --> 00:01:23,250
which is why you really
only see them used at,

29
00:01:23,250 --> 00:01:24,930
you know, some of the largest companies

30
00:01:24,930 --> 00:01:28,590
like Amazon, or Microsoft, or Google,

31
00:01:28,590 --> 00:01:30,660
and mostly, for those places

32
00:01:30,660 --> 00:01:32,730
where the stakes are very high, right?

33
00:01:32,730 --> 00:01:35,880
Where you have the core
infrastructure software,

34
00:01:35,880 --> 00:01:38,940
where the cost of an error is very high.

35
00:01:38,940 --> 00:01:43,940
I do think that one of the
big open areas for research

36
00:01:44,100 --> 00:01:48,210
is how do we bring the
benefits of many of these tools

37
00:01:48,210 --> 00:01:49,590
and many of these techniques

38
00:01:49,590 --> 00:01:52,890
that today are mostly
restricted to the lab

39
00:01:52,890 --> 00:01:54,660
and to some of the largest companies,

40
00:01:54,660 --> 00:01:57,150
and how do we put them at the fingertips

41
00:01:57,150 --> 00:01:59,850
of everyday developers?

42
00:01:59,850 --> 00:02:01,200
I think that's going to be

43
00:02:01,200 --> 00:02:05,730
one of the really interesting
stories in the next few years.

44
00:02:05,730 --> 00:02:07,650
And it could potentially lead

45
00:02:07,650 --> 00:02:10,230
to very dramatic improvements
in software quality

46
00:02:10,230 --> 00:02:11,730
if we do it right.

47
00:02:11,730 --> 00:02:13,170
Let's go on to our next question.

48
00:02:13,170 --> 00:02:17,370
This is again, a question
about some research

49
00:02:17,370 --> 00:02:21,150
that my group has done in
the last couple of years.

50
00:02:21,150 --> 00:02:23,610
So the question says, "Your LINC framework

51
00:02:23,610 --> 00:02:26,460
combines LLMs with symbolic reasoning.

52
00:02:26,460 --> 00:02:29,610
Is this hybrid path the key to safer,

53
00:02:29,610 --> 00:02:33,330
more trustworthy AI in programming?"

54
00:02:33,330 --> 00:02:35,910
Yes. So, a little bit of context.

55
00:02:35,910 --> 00:02:36,870
What is LINC?

56
00:02:36,870 --> 00:02:40,860
In collaboration with several
of our colleagues here at MIT,

57
00:02:40,860 --> 00:02:43,800
I had a privilege of
participating in this LINC project

58
00:02:43,800 --> 00:02:46,110
a couple of years ago where we explored,

59
00:02:46,110 --> 00:02:49,650
what happens if when a language model

60
00:02:49,650 --> 00:02:52,560
is dealing with a question that involves

61
00:02:52,560 --> 00:02:54,480
some detailed logical reasoning?

62
00:02:54,480 --> 00:02:56,910
Instead of just outputting the question,

63
00:02:56,910 --> 00:02:59,760
it translates the question
to a formal notation

64
00:02:59,760 --> 00:03:04,470
that can be given to an
automated reasoning engine,

65
00:03:04,470 --> 00:03:08,160
that can then come back and
produce a reliable answer

66
00:03:08,160 --> 00:03:09,690
and produce that answer.

67
00:03:09,690 --> 00:03:12,600
And this is part of a broader agenda

68
00:03:12,600 --> 00:03:14,520
that we have been pushing for some time

69
00:03:14,520 --> 00:03:17,280
around neuro-symbolic techniques

70
00:03:17,280 --> 00:03:20,550
that combine a lot of the
very important benefits

71
00:03:20,550 --> 00:03:21,840
of neural networks

72
00:03:21,840 --> 00:03:25,530
with the kind of very
precise symbolic reasoning

73
00:03:25,530 --> 00:03:27,570
that machines are very good at.

74
00:03:27,570 --> 00:03:28,860
In the context of programming,

75
00:03:28,860 --> 00:03:30,510
this is especially important

76
00:03:30,510 --> 00:03:33,180
because some of the properties of software

77
00:03:33,180 --> 00:03:35,040
that we really, really care about,

78
00:03:35,040 --> 00:03:39,390
such as the lack of
security vulnerabilities,

79
00:03:39,390 --> 00:03:42,840
such as having very precise control

80
00:03:42,840 --> 00:03:44,640
over the behavior of the software,

81
00:03:44,640 --> 00:03:47,040
a lot of those things really require

82
00:03:47,040 --> 00:03:50,100
very detailed, logical reasoning.

83
00:03:50,100 --> 00:03:52,830
And so, I think a lot of the energy

84
00:03:52,830 --> 00:03:55,440
that we're going to see in the near future

85
00:03:55,440 --> 00:03:59,970
is going to be into how do
we get these language models

86
00:03:59,970 --> 00:04:02,310
and these AI tools that we have today

87
00:04:02,310 --> 00:04:06,390
to make better use of logic
and symbolic reasoning

88
00:04:06,390 --> 00:04:09,930
in those cases where precision
really, really matters.

89
00:04:09,930 --> 00:04:11,330
Let's take another question.

90
00:04:14,137 --> 00:04:16,590
"You've said that the
core ethical challenge

91
00:04:16,590 --> 00:04:20,310
is ensuring machines do what
we want and only what we want.

92
00:04:20,310 --> 00:04:25,107
How does that principle shape
the future of AI programming?"

93
00:04:26,280 --> 00:04:28,260
I think this actually very tied

94
00:04:28,260 --> 00:04:32,610
to the question we had
before around verification.

95
00:04:32,610 --> 00:04:35,850
I do think that we have a
responsibility to make sure

96
00:04:35,850 --> 00:04:39,000
that the software that we
put out there in the world,

97
00:04:39,000 --> 00:04:40,800
that we actually have some confidence

98
00:04:40,800 --> 00:04:44,100
that it's going to do
what we expect it to do.

99
00:04:44,100 --> 00:04:45,450
That it's not going to have

100
00:04:45,450 --> 00:04:47,910
these gaping security vulnerabilities

101
00:04:47,910 --> 00:04:51,600
that today leave a lot
of people vulnerable

102
00:04:51,600 --> 00:04:53,310
to cyber criminals,

103
00:04:53,310 --> 00:04:56,250
to loss of their private data,

104
00:04:56,250 --> 00:05:00,600
and leave our whole infrastructure
potentially vulnerable.

105
00:05:00,600 --> 00:05:03,510
And so, this is directly
tied to this question

106
00:05:03,510 --> 00:05:05,970
of how do we make sure

107
00:05:05,970 --> 00:05:07,650
that the software we put out there

108
00:05:07,650 --> 00:05:11,790
is actually going to behave
as we expect it to behave?

109
00:05:11,790 --> 00:05:13,470
The big thing about software

110
00:05:13,470 --> 00:05:17,723
is that we do have a lot
of tools to help us ensure

111
00:05:17,723 --> 00:05:21,180
that software does what
we expect it to do.

112
00:05:21,180 --> 00:05:24,990
And so I think it is
going to be, in many ways,

113
00:05:24,990 --> 00:05:27,450
society-wide choice that we have to make,

114
00:05:27,450 --> 00:05:31,200
to push for software
quality to be a priority.

115
00:05:31,200 --> 00:05:33,420
To make sure that the software

116
00:05:33,420 --> 00:05:35,580
that is put out there in the world,

117
00:05:35,580 --> 00:05:38,160
actually is fit for purpose

118
00:05:38,160 --> 00:05:40,310
and it's going to do
what we want it to do.

119
00:05:42,570 --> 00:05:47,570
So the next question is one
that I actually get asked a lot.

120
00:05:49,447 --> 00:05:52,890
"Should students still learn
programming the hard way

121
00:05:52,890 --> 00:05:57,890
or should education shift
toward human-AI collaboration?"

122
00:05:59,280 --> 00:06:03,060
So I think there's a couple
of layers to this question.

123
00:06:03,060 --> 00:06:07,230
So there's no question that
learning to program early on

124
00:06:07,230 --> 00:06:10,290
is hard, right?

125
00:06:10,290 --> 00:06:11,460
For many people,

126
00:06:11,460 --> 00:06:15,210
this is the first time
they are encountering

127
00:06:15,210 --> 00:06:18,810
this need to describe something
at this level of precision,

128
00:06:18,810 --> 00:06:22,710
and with the level of
care that is required

129
00:06:22,710 --> 00:06:25,830
in order to get a program
that actually works.

130
00:06:25,830 --> 00:06:26,850
To some extent,

131
00:06:26,850 --> 00:06:29,580
LLMs are going to be very helpful

132
00:06:29,580 --> 00:06:32,580
in helping students get
through that early phase

133
00:06:32,580 --> 00:06:34,770
where nothing they program works

134
00:06:34,770 --> 00:06:38,790
and where it's very
easy to get frustrated.

135
00:06:38,790 --> 00:06:42,180
However, once you get
past that initial stage

136
00:06:42,180 --> 00:06:45,120
and once you're more
proficient in the tools,

137
00:06:45,120 --> 00:06:46,980
I think a lot of the
things that we teach today

138
00:06:46,980 --> 00:06:49,170
are things that are still going to be

139
00:06:49,170 --> 00:06:51,570
very, very important in the future.

140
00:06:51,570 --> 00:06:55,800
How do you take a big, hard
problem and decompose it

141
00:06:55,800 --> 00:07:00,800
in a way that allows you to
solve every piece one at a time?

142
00:07:01,350 --> 00:07:04,350
How do you actually think through

143
00:07:04,350 --> 00:07:05,970
all the different contingencies

144
00:07:05,970 --> 00:07:08,130
and all the different
things that can go wrong

145
00:07:08,130 --> 00:07:11,400
as users are using your software?

146
00:07:11,400 --> 00:07:15,570
How do you think about the
software not just as an artifact

147
00:07:15,570 --> 00:07:17,730
that is trying to solve a problem now,

148
00:07:17,730 --> 00:07:20,970
but as an artifact that is
going to have to survive

149
00:07:20,970 --> 00:07:25,410
potentially over decades
and evolve as requirements?

150
00:07:25,410 --> 00:07:27,030
All of those are things

151
00:07:27,030 --> 00:07:29,370
that are still going to
be very, very important

152
00:07:29,370 --> 00:07:31,680
for students to learn.

153
00:07:31,680 --> 00:07:34,500
That said, of course it's
going to be very important

154
00:07:34,500 --> 00:07:37,530
that students know how to
think through this question

155
00:07:37,530 --> 00:07:39,900
using the most advanced tools

156
00:07:39,900 --> 00:07:42,150
and the tools that they
are going to be using

157
00:07:42,150 --> 00:07:44,370
in their professional life.

158
00:07:44,370 --> 00:07:46,833
I don't think there is a tension,

159
00:07:48,030 --> 00:07:49,380
at least in the case of programming,

160
00:07:49,380 --> 00:07:52,320
between students learning
how to use these tools

161
00:07:52,320 --> 00:07:55,920
but also learning the fundamentals.

162
00:07:55,920 --> 00:07:56,823
Next question.

163
00:07:58,627 --> 00:08:01,710
"What is your preferred
programming language?"

164
00:08:01,710 --> 00:08:03,420
Oh, this is actually a hard question.

165
00:08:03,420 --> 00:08:04,710
I think it really depends

166
00:08:04,710 --> 00:08:08,040
on what you are trying
to accomplish, right?

167
00:08:08,040 --> 00:08:12,480
So for example, there are
research languages like Haskell,

168
00:08:12,480 --> 00:08:15,570
created by academics for researchers

169
00:08:15,570 --> 00:08:18,930
that are just beautiful in
terms of the abstractions

170
00:08:18,930 --> 00:08:20,640
and the power that they provide.

171
00:08:20,640 --> 00:08:22,320
But I probably wouldn't use them

172
00:08:22,320 --> 00:08:24,960
to create a new website, for example.

173
00:08:24,960 --> 00:08:27,780
People in the programming
languages community

174
00:08:27,780 --> 00:08:31,410
tend to look down on
JavaScript, for example,

175
00:08:31,410 --> 00:08:36,410
as a language that is full
of holes and inconsistencies,

176
00:08:36,600 --> 00:08:40,950
and problems that programmers
are constantly tripping over.

177
00:08:40,950 --> 00:08:44,250
And it is true, it has
lots and lots of warts,.

178
00:08:44,250 --> 00:08:46,560
But it's also a really expressive language

179
00:08:46,560 --> 00:08:48,660
with remarkable infrastructure

180
00:08:48,660 --> 00:08:51,780
that actually allows you to
build things very, very quickly

181
00:08:51,780 --> 00:08:55,770
and deploy them without a lot of hassle.

182
00:08:55,770 --> 00:08:59,310
So I think the right
language for your problem

183
00:08:59,310 --> 00:09:01,890
is going to depend on what
you're trying to accomplish.

184
00:09:01,890 --> 00:09:03,060
I think the most important thing

185
00:09:03,060 --> 00:09:07,140
is for everybody to have
a broad set of languages

186
00:09:07,140 --> 00:09:09,180
that they are familiar
with and proficient with

187
00:09:09,180 --> 00:09:12,243
so that they can actually pick
the best tool for the job.

188
00:09:16,380 --> 00:09:19,027
And now we have our last question.

189
00:09:19,027 --> 00:09:22,110
"What are some AI-assisted
software engineering tools

190
00:09:22,110 --> 00:09:24,390
you use to enhance productivity?

191
00:09:24,390 --> 00:09:27,480
And what are the optimal ways to use them

192
00:09:27,480 --> 00:09:30,960
without compromising your own learning?"

193
00:09:30,960 --> 00:09:33,240
So that's a really good question.

194
00:09:33,240 --> 00:09:36,690
Most of the programming that
I do on a regular basis,

195
00:09:36,690 --> 00:09:39,030
I use Cursor.

196
00:09:39,030 --> 00:09:42,030
I also use ChatGPT.

197
00:09:42,030 --> 00:09:45,330
Both of them are very
useful in their own way,

198
00:09:45,330 --> 00:09:48,690
and I find they are especially useful

199
00:09:48,690 --> 00:09:51,150
for some of the aspect of programming

200
00:09:51,150 --> 00:09:53,220
that I don't particularly like.

201
00:09:53,220 --> 00:09:56,880
For example, once you
put all the functionality

202
00:09:56,880 --> 00:09:58,650
into a function,

203
00:09:58,650 --> 00:10:00,517
writing all the little checks to say,

204
00:10:00,517 --> 00:10:03,210
"Oh, make sure the input is correct

205
00:10:03,210 --> 00:10:05,700
and make sure you're throwing
the right error message

206
00:10:05,700 --> 00:10:06,720
when this happens," right?

207
00:10:06,720 --> 00:10:09,990
These tools are actually
amazing for things like that.

208
00:10:09,990 --> 00:10:11,610
They're also really, really good,

209
00:10:11,610 --> 00:10:13,740
for example, when running experiments,

210
00:10:13,740 --> 00:10:16,170
in helping you build a
lot of the scaffolding

211
00:10:16,170 --> 00:10:20,610
that is required to run
experiments, and collect data,

212
00:10:20,610 --> 00:10:22,770
and even plot that data.

213
00:10:22,770 --> 00:10:27,770
So I do think that one of
the things that is important

214
00:10:28,230 --> 00:10:32,820
as you work with these tools
more on a regular basis

215
00:10:32,820 --> 00:10:34,740
is building that intuition

216
00:10:34,740 --> 00:10:37,080
about what are the kind of problems

217
00:10:37,080 --> 00:10:39,510
that you can easily delegate to the tool

218
00:10:39,510 --> 00:10:41,670
and will usually do a good job at,

219
00:10:41,670 --> 00:10:43,500
and what are the things where

220
00:10:43,500 --> 00:10:45,090
you shouldn't even bother, right?

221
00:10:45,090 --> 00:10:47,820
Where you're just better off focusing

222
00:10:47,820 --> 00:10:49,830
and taking out your pencil and paper

223
00:10:49,830 --> 00:10:52,260
and thinking clearly through
what you're trying to do,

224
00:10:52,260 --> 00:10:55,650
and then just writing the code yourself.

225
00:10:55,650 --> 00:10:58,530
And that intuition is not
going to be set in stone.

226
00:10:58,530 --> 00:11:02,370
The tools are evolving quite rapidly.

227
00:11:02,370 --> 00:11:06,840
But I do think that maintaining
that internal mental model

228
00:11:06,840 --> 00:11:08,490
of what you can delegate

229
00:11:08,490 --> 00:11:10,620
and what you have to do for yourself

230
00:11:10,620 --> 00:11:13,680
is really important in using
these tools productively.

231
00:11:13,680 --> 00:11:17,820
And so these are all the
questions that I have today.

232
00:11:17,820 --> 00:11:19,440
I hope you had a good time.

233
00:11:19,440 --> 00:11:22,470
I certainly enjoyed
answering all your questions,

234
00:11:22,470 --> 00:11:26,313
and I look forward to being here again.


1
00:00:01,129 --> 00:00:02,526
(logo whooshes)

2
00:00:02,526 --> 00:00:05,850
(text chitters)

3
00:00:05,850 --> 00:00:09,840
- So next we have, "How do
you weigh the social balances

4
00:00:09,840 --> 00:00:12,390
of equipping AI with
human-like intelligence

5
00:00:12,390 --> 00:00:13,470
and how does your work aim

6
00:00:13,470 --> 00:00:17,160
to integrate AI into
society in a positive way?"

7
00:00:17,160 --> 00:00:19,080
Ultimately, I'm an optimist.

8
00:00:19,080 --> 00:00:21,420
I think that there is a positive future

9
00:00:21,420 --> 00:00:24,300
for AI integrating into society.

10
00:00:24,300 --> 00:00:28,710
I have had the dream since
childhood of, you know, robots

11
00:00:28,710 --> 00:00:30,660
that are human-like that interact with us.

12
00:00:30,660 --> 00:00:32,010
I really think there can be a positive

13
00:00:32,010 --> 00:00:33,810
and valuable future

14
00:00:33,810 --> 00:00:36,333
with powerful AI systems
living alongside us.

15
00:00:37,230 --> 00:00:39,810
However, it is definitely true
that there are a lot of ways

16
00:00:39,810 --> 00:00:41,193
that this could go wrong.

17
00:00:42,030 --> 00:00:44,190
So my own current approach

18
00:00:44,190 --> 00:00:47,250
to dealing with that kind
of trade off is to say,

19
00:00:47,250 --> 00:00:51,330
I wanna focus on
understanding these systems,

20
00:00:51,330 --> 00:00:55,425
not necessarily being the
one who's going to deploy

21
00:00:55,425 --> 00:00:56,460
and make the big systems.

22
00:00:56,460 --> 00:00:59,640
So I get to kind of step back
and just act as a scientist

23
00:00:59,640 --> 00:01:00,960
and try to understand,

24
00:01:00,960 --> 00:01:02,820
what are the principles of intelligence?

25
00:01:02,820 --> 00:01:05,010
How do current AI systems work?

26
00:01:05,010 --> 00:01:07,320
What are they good at,
what are they not good at?

27
00:01:07,320 --> 00:01:09,750
And that's a position that I quite enjoy

28
00:01:09,750 --> 00:01:10,860
and I'm quite comfortable with

29
00:01:10,860 --> 00:01:13,140
because I think that
understanding these things

30
00:01:13,140 --> 00:01:15,270
and developing the science of these things

31
00:01:15,270 --> 00:01:17,220
is just going to pay off for society.

32
00:01:17,220 --> 00:01:18,750
It will allow us to make good choices

33
00:01:18,750 --> 00:01:21,480
about how to integrate
them into the world.

34
00:01:21,480 --> 00:01:24,180
But that is going to be
a hard policy decision

35
00:01:24,180 --> 00:01:26,163
later on in the future.

36
00:01:27,420 --> 00:01:29,670
What do you see as the key challenges

37
00:01:29,670 --> 00:01:31,500
for generative video models

38
00:01:31,500 --> 00:01:33,060
and what other emerging trends

39
00:01:33,060 --> 00:01:35,310
in generative AI pique my interest?

40
00:01:35,310 --> 00:01:37,710
Yeah, generative video models
are really, really cool.

41
00:01:37,710 --> 00:01:40,380
They're the current
thing that's taking off.

42
00:01:40,380 --> 00:01:43,320
So there's maybe two big challenges here.

43
00:01:43,320 --> 00:01:47,730
The first challenge is
that videos are really big.

44
00:01:47,730 --> 00:01:49,320
They are a lot of frames.

45
00:01:49,320 --> 00:01:52,230
So imagine if it's hard
to make a single image,

46
00:01:52,230 --> 00:01:54,780
well, a video is like thousands of frames,

47
00:01:54,780 --> 00:01:56,430
thousands of images.

48
00:01:56,430 --> 00:01:59,400
So the amount of compute
and the amount of memory

49
00:01:59,400 --> 00:02:01,440
and resources required to generate a video

50
00:02:01,440 --> 00:02:04,590
is just a lot more than to
generate a single photo.

51
00:02:04,590 --> 00:02:06,810
So we're gonna have to make
these systems more efficient.

52
00:02:06,810 --> 00:02:07,950
That's one problem.

53
00:02:07,950 --> 00:02:11,610
The other hard thing
about video generation

54
00:02:11,610 --> 00:02:15,900
is physical accuracy and
physical consistency.

55
00:02:15,900 --> 00:02:17,640
So if you've ever seen one

56
00:02:17,640 --> 00:02:19,530
of these video generative models,

57
00:02:19,530 --> 00:02:22,620
like the Sora model, maybe from OpenAI,

58
00:02:22,620 --> 00:02:23,910
what you might have noticed is

59
00:02:23,910 --> 00:02:25,620
it kind of looks like a dream.

60
00:02:25,620 --> 00:02:27,690
It looks like you're in some
dream world where objects

61
00:02:27,690 --> 00:02:30,330
are just kind of popping
in and out of existence,

62
00:02:30,330 --> 00:02:33,210
the geometry changes when
the camera pans around

63
00:02:33,210 --> 00:02:34,530
and it returns to where it started.

64
00:02:34,530 --> 00:02:36,900
You might have entirely new content.

65
00:02:36,900 --> 00:02:38,970
There's a video I saw of the a chair

66
00:02:38,970 --> 00:02:41,460
that's kinda morphing out
of the sand on a beach

67
00:02:41,460 --> 00:02:44,610
and forming the legs and
everything is a bit dreamlike

68
00:02:44,610 --> 00:02:46,320
and physically unrealistic.

69
00:02:46,320 --> 00:02:48,420
These things are
definitely getting better,

70
00:02:48,420 --> 00:02:49,830
but they're not quite there

71
00:02:49,830 --> 00:02:51,810
in terms of their physical accuracy

72
00:02:51,810 --> 00:02:53,070
and that's one of the big challenges

73
00:02:53,070 --> 00:02:55,110
that people are working on now.

74
00:02:55,110 --> 00:02:56,490
There was one other part to that question

75
00:02:56,490 --> 00:02:57,960
so let me go to this.

76
00:02:57,960 --> 00:03:00,000
What generative AI methods

77
00:03:00,000 --> 00:03:02,340
are piquing my interest beyond videos

78
00:03:02,340 --> 00:03:04,890
and the one that I'm really excited about

79
00:03:04,890 --> 00:03:08,040
is what is called generative world models.

80
00:03:08,040 --> 00:03:10,470
So generative world models are methods

81
00:03:10,470 --> 00:03:13,170
that try to make not just
like a video or an image,

82
00:03:13,170 --> 00:03:17,160
but a whole world, a whole
simulation of the world.

83
00:03:17,160 --> 00:03:19,440
So that means something
that I can, you know,

84
00:03:19,440 --> 00:03:22,740
step into and interact
with like a video game.

85
00:03:22,740 --> 00:03:26,070
I can intervene and you know,

86
00:03:26,070 --> 00:03:28,080
throw an object and it
will bounce, you know,

87
00:03:28,080 --> 00:03:29,610
against the geometry in this world.

88
00:03:29,610 --> 00:03:32,310
So think of like a game
or a simulation engine.

89
00:03:32,310 --> 00:03:34,620
And people are trying to
make generative models

90
00:03:34,620 --> 00:03:36,450
where I could like type in text

91
00:03:36,450 --> 00:03:38,130
and it will generate
this whole world for me.

92
00:03:38,130 --> 00:03:40,230
I'd say, "Make me a video game on Mars

93
00:03:40,230 --> 00:03:42,420
where I can, you know,
jump on different platforms

94
00:03:42,420 --> 00:03:43,253
and do a back flip,"

95
00:03:43,253 --> 00:03:45,330
and then it just makes that game for you.

96
00:03:45,330 --> 00:03:48,810
So this is something that's
not quite available yet

97
00:03:48,810 --> 00:03:52,500
but is coming very quickly
and I'm excited about it.

98
00:03:52,500 --> 00:03:53,970
Not just because it could be used

99
00:03:53,970 --> 00:03:55,860
to make fun video games,

100
00:03:55,860 --> 00:03:58,200
but actually because it's like a new way

101
00:03:58,200 --> 00:04:00,210
of doing simulation.

102
00:04:00,210 --> 00:04:03,120
And simulation has a fundamental role

103
00:04:03,120 --> 00:04:05,130
in engineering and in science.

104
00:04:05,130 --> 00:04:06,510
We often use simulation

105
00:04:06,510 --> 00:04:09,720
to test out ideas and to make decisions.

106
00:04:09,720 --> 00:04:12,360
If I have a generative simulation,
I can do that same type

107
00:04:12,360 --> 00:04:15,480
of simulation-based engineering
in my generative model.

108
00:04:15,480 --> 00:04:17,610
So one thing that we've
been doing recently

109
00:04:17,610 --> 00:04:22,380
is trying to train and
develop robots in simulation

110
00:04:22,380 --> 00:04:23,940
and then deploy the robots in the world.

111
00:04:23,940 --> 00:04:25,920
So the robot can interact
with a simulation,

112
00:04:25,920 --> 00:04:29,160
it's safe, they're not
going to break anything.

113
00:04:29,160 --> 00:04:32,730
They can maybe drive as a
self-driving car in a simulation.

114
00:04:32,730 --> 00:04:34,890
It's okay if they get into
a crash in a simulation

115
00:04:34,890 --> 00:04:36,390
and they can learn from their mistakes

116
00:04:36,390 --> 00:04:39,210
how to behave in a safer way.

117
00:04:39,210 --> 00:04:42,300
And then we deploy that
technology into the world.

118
00:04:42,300 --> 00:04:45,060
So, previously, people used

119
00:04:45,060 --> 00:04:48,510
classical physics
simulations of the world.

120
00:04:48,510 --> 00:04:50,400
And now what is happening
is we're starting

121
00:04:50,400 --> 00:04:53,640
to use generative models
as our simulation engine.

122
00:04:53,640 --> 00:04:56,160
We recently have a project
which we call LucidSim,

123
00:04:56,160 --> 00:04:58,170
which tries to use generative AI

124
00:04:58,170 --> 00:05:00,420
as the simulation engine
for training robots.

125
00:05:02,437 --> 00:05:04,170
"Can you walk us through the process

126
00:05:04,170 --> 00:05:07,440
of how an AI system learns
to understand images?"

127
00:05:07,440 --> 00:05:10,710
So there are kind of two different ways

128
00:05:10,710 --> 00:05:15,030
that you currently can train
an AI to understand images.

129
00:05:15,030 --> 00:05:19,893
One way is via generative
AI, via generative modeling.

130
00:05:20,814 --> 00:05:22,230
So the basic idea here

131
00:05:22,230 --> 00:05:26,220
is that if I have a model

132
00:05:26,220 --> 00:05:28,200
that can make images,

133
00:05:28,200 --> 00:05:29,850
then it must have understood something

134
00:05:29,850 --> 00:05:31,890
about the visual world, right?

135
00:05:31,890 --> 00:05:33,157
It's kinda like this Feynman quote,

136
00:05:33,157 --> 00:05:35,730
"What I can't create, I don't understand."

137
00:05:35,730 --> 00:05:38,040
And you know, presumably,
what I can create,

138
00:05:38,040 --> 00:05:39,630
I do better understand.

139
00:05:39,630 --> 00:05:42,420
So if a model has been trained

140
00:05:42,420 --> 00:05:45,240
to be able to make images
and videos and worlds,

141
00:05:45,240 --> 00:05:47,730
then it must understand
something about the world.

142
00:05:47,730 --> 00:05:49,620
And indeed that's what we see happening.

143
00:05:49,620 --> 00:05:52,530
Some of the current really
effective image processing

144
00:05:52,530 --> 00:05:54,450
and image understanding algorithms

145
00:05:54,450 --> 00:05:57,930
work by just trying to
generate visual content

146
00:05:57,930 --> 00:05:59,490
and then by generating the content,

147
00:05:59,490 --> 00:06:02,310
they learn how to interpret
the content as well.

148
00:06:02,310 --> 00:06:07,110
The other way that current
systems learn to process

149
00:06:07,110 --> 00:06:10,800
and understand images is
what I alluded to before,

150
00:06:10,800 --> 00:06:14,100
which is self-supervised learning

151
00:06:14,100 --> 00:06:16,080
where you take an image

152
00:06:16,080 --> 00:06:20,220
and you just try to predict
some property of the image

153
00:06:20,220 --> 00:06:21,450
from some other property.

154
00:06:21,450 --> 00:06:24,450
So you try to predict missing
pixels from observed pixels.

155
00:06:24,450 --> 00:06:25,680
Or imagine a video.

156
00:06:25,680 --> 00:06:26,520
You might try to predict

157
00:06:26,520 --> 00:06:29,880
what is the next frame gonna
be given the previous frame.

158
00:06:29,880 --> 00:06:31,620
If you can make these
types of predictions,

159
00:06:31,620 --> 00:06:34,650
you must understand something
about the world around you.

160
00:06:34,650 --> 00:06:36,420
If I can predict what
I'll see in the future,

161
00:06:36,420 --> 00:06:39,870
I must have an understanding
of how objects move,

162
00:06:39,870 --> 00:06:43,260
the idea that a ball travels
in a parabola when I throw it.

163
00:06:43,260 --> 00:06:44,460
So these types of understanding

164
00:06:44,460 --> 00:06:45,810
come out of making predictions

165
00:06:45,810 --> 00:06:48,487
and that's the second way of
doing visual understanding.

166
00:06:48,487 --> 00:06:51,030
"How is your group working
toward improving the quality

167
00:06:51,030 --> 00:06:52,500
and quantity of synthetic data

168
00:06:52,500 --> 00:06:54,780
to train generative AI models?

169
00:06:54,780 --> 00:06:56,670
And how can this type of data teach robots

170
00:06:56,670 --> 00:06:58,830
to learn visually from their errors?"

171
00:06:58,830 --> 00:07:00,780
Yeah, I'm really excited
about the prospect

172
00:07:00,780 --> 00:07:03,150
of using synthetic data
from generative models

173
00:07:03,150 --> 00:07:05,520
to improve AI systems.

174
00:07:05,520 --> 00:07:07,110
This is an area where there's actually

175
00:07:07,110 --> 00:07:09,120
a lot of confusion right now

176
00:07:09,120 --> 00:07:10,080
and there's a lot of debate

177
00:07:10,080 --> 00:07:13,803
about when synthetic data
can be useful or not useful.

178
00:07:14,640 --> 00:07:17,640
So one thing that people worry about is

179
00:07:17,640 --> 00:07:21,390
that if the internet just becomes polluted

180
00:07:21,390 --> 00:07:25,050
with a lot of output from language models

181
00:07:25,050 --> 00:07:28,020
and just fake data, then
maybe this is going to,

182
00:07:28,020 --> 00:07:29,400
we're gonna lose touch with reality

183
00:07:29,400 --> 00:07:31,530
and the future models
that are trained on that

184
00:07:31,530 --> 00:07:33,900
will just get worse and worse and worse.

185
00:07:33,900 --> 00:07:36,570
And there are some cases
in which that might happen

186
00:07:36,570 --> 00:07:38,610
and we have to watch out for that.

187
00:07:38,610 --> 00:07:39,540
But what I'm working on

188
00:07:39,540 --> 00:07:41,040
and what I'm a lot more excited about

189
00:07:41,040 --> 00:07:43,440
is kind of the optimistic outlook

190
00:07:43,440 --> 00:07:46,740
that models can potentially
make synthetic data

191
00:07:46,740 --> 00:07:49,830
that's actually better
than the data that trained,

192
00:07:49,830 --> 00:07:51,570
the real data that trained
the model in the first place.

193
00:07:51,570 --> 00:07:54,300
Like synthetic data can
be better than real data.

194
00:07:54,300 --> 00:07:57,090
And there are various ways
in which that can happen.

195
00:07:57,090 --> 00:07:58,800
And we're basically working on algorithms

196
00:07:58,800 --> 00:08:01,080
that try to achieve that.

197
00:08:01,080 --> 00:08:04,800
So for example, I might
have a generative model

198
00:08:04,800 --> 00:08:07,650
that can be steered or intervened on,

199
00:08:07,650 --> 00:08:09,060
like a human can actually go in

200
00:08:09,060 --> 00:08:11,730
and change the parameters
of the model to steer it,

201
00:08:11,730 --> 00:08:14,010
to make data that is more positive

202
00:08:14,010 --> 00:08:16,890
or more useful for some
kind of downstream task.

203
00:08:16,890 --> 00:08:17,850
There are methods,

204
00:08:17,850 --> 00:08:20,550
like one called reinforcement
learning from human feedback,

205
00:08:20,550 --> 00:08:21,690
that essentially do that.

206
00:08:21,690 --> 00:08:22,890
They take a model

207
00:08:22,890 --> 00:08:25,170
and they kind of steer it
toward human preferences

208
00:08:25,170 --> 00:08:27,930
of what is considered to be better data.

209
00:08:27,930 --> 00:08:29,220
So this is just one example

210
00:08:29,220 --> 00:08:30,810
of how you can make synthetic data

211
00:08:30,810 --> 00:08:32,970
that is better than real data.

212
00:08:32,970 --> 00:08:34,350
And I think that there's just

213
00:08:34,350 --> 00:08:36,600
a really interesting
future along those lines.

214
00:08:36,600 --> 00:08:38,130
The question was also also asking

215
00:08:38,130 --> 00:08:40,650
about how we're using this for robotics.

216
00:08:40,650 --> 00:08:42,780
And that goes back to
this LucidSim project

217
00:08:42,780 --> 00:08:45,570
that I talked about in the previous answer

218
00:08:45,570 --> 00:08:48,880
where we are trying to create world models

219
00:08:50,130 --> 00:08:51,540
in which you can train a robot.

220
00:08:51,540 --> 00:08:53,100
So it's a simulation,

221
00:08:53,100 --> 00:08:56,730
augmented with generative
models and generative AI,

222
00:08:56,730 --> 00:08:59,280
that can create all
types of diverse content

223
00:08:59,280 --> 00:09:01,680
and imagine all types
of different scenarios

224
00:09:01,680 --> 00:09:04,260
so that if I train my robot in that world,

225
00:09:04,260 --> 00:09:05,970
it will become robust

226
00:09:05,970 --> 00:09:08,730
and competent in all of
these different scenarios.

227
00:09:08,730 --> 00:09:09,720
So this is a place

228
00:09:09,720 --> 00:09:11,580
where generative models and synthetic data

229
00:09:11,580 --> 00:09:14,013
can teach our next
generation of AI systems.

230
00:09:15,907 --> 00:09:18,180
"Looking ahead to the next 10 years,

231
00:09:18,180 --> 00:09:21,300
what do you envision next
for AI in image processing?"

232
00:09:21,300 --> 00:09:24,180
I really think that the future of AI

233
00:09:24,180 --> 00:09:28,320
is much more going to
be about the integration

234
00:09:28,320 --> 00:09:30,870
of all of our sensory modalities

235
00:09:30,870 --> 00:09:33,540
and all of our other problems in AI

236
00:09:33,540 --> 00:09:35,310
into a more kind of holistic approach,

237
00:09:35,310 --> 00:09:37,020
this embodied intelligence approach,

238
00:09:37,020 --> 00:09:41,100
this human-like agent that I
mentioned at the beginning.

239
00:09:41,100 --> 00:09:43,410
So I'm not sure that image processing,

240
00:09:43,410 --> 00:09:45,720
as like a sub area of AI,

241
00:09:45,720 --> 00:09:49,020
will be the most exciting
thing in the future.

242
00:09:49,020 --> 00:09:53,010
I think it's more about how
you integrate images and sounds

243
00:09:53,010 --> 00:09:55,290
and touch signals, all
the modalities together.

244
00:09:55,290 --> 00:09:57,480
You add language to the pipeline,

245
00:09:57,480 --> 00:09:59,550
you get the field of
natural language processing

246
00:09:59,550 --> 00:10:01,110
to talk to the field of computer vision,

247
00:10:01,110 --> 00:10:03,000
to talk to the field of robotics.

248
00:10:03,000 --> 00:10:04,950
So, to me, the future of image processing

249
00:10:04,950 --> 00:10:07,200
and computer vision is
more about integration

250
00:10:07,200 --> 00:10:08,940
with other areas of AI.

251
00:10:08,940 --> 00:10:09,840
And I think we're at a time

252
00:10:09,840 --> 00:10:11,790
when that is gonna be really effective.

253
00:10:13,050 --> 00:10:15,517
So the last question is,

254
00:10:15,517 --> 00:10:18,240
"Are multimodal world models possible?

255
00:10:18,240 --> 00:10:20,880
Kind of combining
discriminative, generative,

256
00:10:20,880 --> 00:10:23,370
and perceptual understanding
in a single model."

257
00:10:23,370 --> 00:10:24,360
Okay, this is perfect

258
00:10:24,360 --> 00:10:27,270
because this follows exactly
on my previous response.

259
00:10:27,270 --> 00:10:29,550
I think, yes, this is the exciting future

260
00:10:29,550 --> 00:10:31,050
is these multimodal systems

261
00:10:31,050 --> 00:10:33,180
and these multi-model systems as well

262
00:10:33,180 --> 00:10:35,550
where there's different
models all interacting,

263
00:10:35,550 --> 00:10:37,140
all becoming more and more unified

264
00:10:37,140 --> 00:10:39,480
in how they understand the world

265
00:10:39,480 --> 00:10:42,993
and thereby becoming more
effective and accurate and robust.

266
00:10:44,130 --> 00:10:46,200
So there's a lot of work in this area

267
00:10:46,200 --> 00:10:49,560
of combining a vision system
with a language system,

268
00:10:49,560 --> 00:10:52,860
deploying that on a robot potentially.

269
00:10:52,860 --> 00:10:55,950
And I think it's just a really
interesting area right now.

270
00:10:55,950 --> 00:10:57,900
All of these different
ways of modeling the world,

271
00:10:57,900 --> 00:11:00,660
like the way that a language
model models the world

272
00:11:00,660 --> 00:11:03,660
and the way that a vision
model models the world

273
00:11:03,660 --> 00:11:07,500
are becoming more and more
alike in a measurable way.

274
00:11:07,500 --> 00:11:12,060
So the representations inside
the latest language models

275
00:11:12,060 --> 00:11:15,480
and the representations inside
the latest vision models

276
00:11:15,480 --> 00:11:19,410
are becoming more alike in in
their mathematical properties.

277
00:11:19,410 --> 00:11:20,400
So we have this idea

278
00:11:20,400 --> 00:11:22,980
that we call the platonic
representation hypothesis,

279
00:11:22,980 --> 00:11:24,750
that there's maybe some ultimate,

280
00:11:24,750 --> 00:11:28,500
like unified representation,
this platonic entity,

281
00:11:28,500 --> 00:11:30,300
and all of these different modalities

282
00:11:30,300 --> 00:11:33,090
and sensors and problems are projections

283
00:11:33,090 --> 00:11:35,700
and reflections of that
underlying central thing.

284
00:11:35,700 --> 00:11:37,110
And we really wanna find that thing

285
00:11:37,110 --> 00:11:38,100
and that will be a way

286
00:11:38,100 --> 00:11:39,930
of unifying these different parts of AI,

287
00:11:39,930 --> 00:11:42,930
these different sensory processes,
into a common framework.

288
00:11:42,930 --> 00:11:45,270
And that's one of our ongoing projects.

289
00:11:45,270 --> 00:11:46,950
That's it for the questions.

290
00:11:46,950 --> 00:11:49,500
It was really fun to get
a chance to answer them

291
00:11:49,500 --> 00:11:51,990
and think about these
really interesting topics.

292
00:11:51,990 --> 00:11:53,970
So thank you for taking the time

293
00:11:53,970 --> 00:11:55,620
and I'll see you in the next one.

